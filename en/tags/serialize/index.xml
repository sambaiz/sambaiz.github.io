<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>serialize on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/serialize/</link>
    <description>Recent content in serialize on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Tue, 16 Aug 2022 21:26:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/en/tags/serialize/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why can Athena v2 fail to query map columns in parquet source tables</title>
      <link>https://www.sambaiz.net/en/article/415/</link>
      <pubDate>Tue, 16 Aug 2022 21:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/415/</guid>
      <description>Output logs containing map fields as json etc., convert it to parquet with Glue Studio, and execute queries with Athena, then the queries can succeed or fail depending on the table.&#xA;Columnar format Parquet structure and read optimization - sambaiz-net&#xA;type Log struct { A map[string]int } =&amp;gt; {&amp;#34;A&amp;#34;:{&amp;#34;B&amp;#34;:10,&amp;#34;C&amp;#34;:20}} The parquet metadata is as follows and the information about map is lost.&#xA;$ parquet meta test.parquet File path: test.parquet Created by: parquet-glue version 1.</description>
    </item>
    <item>
      <title>Columnar format Parquet structure and read optimization</title>
      <link>https://www.sambaiz.net/en/article/386/</link>
      <pubDate>Fri, 03 Dec 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/386/</guid>
      <description>Parquet is a columnar format mainly used in the Hadoop ecosystem. Compared to row-based formats like CSV, unnecessary columns can be skipped. Besides, there is a mechanics to read only rows that are needed, so queries can be executed efficiently.&#xA;Format Rows are horizontally partitioned into some Row Groups, and the Column Chunks of each column are arranged in order. Column Chunks are divided into Pages, and compression and encoding are performed in that unit.</description>
    </item>
  </channel>
</rss>
