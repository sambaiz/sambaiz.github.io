<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Serialize on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/serialize/</link>
    <description>Recent content in Serialize on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Tue, 16 Aug 2022 21:26:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/en/tags/serialize/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why can Athena v2 fail to query map columns in parquet source tables</title>
      <link>https://www.sambaiz.net/en/article/415/</link>
      <pubDate>Tue, 16 Aug 2022 21:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/415/</guid>
      <description>&lt;p&gt;Output logs containing map fields as json etc., convert it to parquet with Glue Studio, and execute queries with Athena, then the queries can succeed or fail depending on the table.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/386/&#34;&gt;Columnar format Parquet structure and read optimization - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;type&lt;/span&gt; Log &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;struct&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    A &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#8be9fd&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#8be9fd&#34;&gt;int&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;=&amp;gt; {&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;:{&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#bd93f9&#34;&gt;10&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;C&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#bd93f9&#34;&gt;20&lt;/span&gt;}}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Columnar format Parquet structure and read optimization</title>
      <link>https://www.sambaiz.net/en/article/386/</link>
      <pubDate>Fri, 03 Dec 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/386/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/apache/parquet-format&#34;&gt;Parquet&lt;/a&gt; is a columnar format mainly used in the Hadoop ecosystem.&#xA;Compared to row-based formats like CSV, unnecessary columns can be skipped. Besides, there is a mechanics to read only rows that are needed, so queries can be executed efficiently.&lt;/p&gt;&#xA;&lt;h2 id=&#34;formathttpsgithubcomapacheparquet-formatblobmasterreadmemdfile-format&#34;&gt;&lt;a href=&#34;https://github.com/apache/parquet-format/blob/master/README.md#file-format&#34;&gt;Format&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/386/images/format.gif&#34; width=&#34;601&#34; height=&#34;478&#34; alt=&#34;https://github.com/apache/parquet-format#file-format&#34;&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;Rows are horizontally partitioned into some &lt;a href=&#34;https://github.com/apache/parquet-format/blob/parquet-format-2.2.0-rc1/src/thrift/parquet.thrift#L490&#34;&gt;Row Groups&lt;/a&gt;, and the &lt;a href=&#34;https://github.com/apache/parquet-format/blob/parquet-format-2.2.0-rc1/src/thrift/parquet.thrift#L474&#34;&gt;Column Chunks&lt;/a&gt; of each column are arranged in order. Column Chunks are divided into &lt;a href=&#34;https://github.com/apache/parquet-format/blob/parquet-format-2.2.0-rc1/src/thrift/parquet.thrift#L387&#34;&gt;Pages&lt;/a&gt;, and compression and encoding are performed in that unit.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
