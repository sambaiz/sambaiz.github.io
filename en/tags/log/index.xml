<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>log on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/log/</link>
    <description>Recent content in log on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Fri, 08 Apr 2022 12:11:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/en/tags/log/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About newrelic-lambda-extension and how it works telemetry without CloudWatch Logs</title>
      <link>https://www.sambaiz.net/en/article/401/</link>
      <pubDate>Fri, 08 Apr 2022 12:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/401/</guid>
      <description>Theare are two methods to send Lambda logs to New Relic. First is a conventional method that uses a Lambda function aws-log-ingestion to subscribe and transfer CloudWatch Logs, and second is a method that uses a Lambda layer newrelic-lambda-extension. The latter send trace logs etc. without outputting to CloudWatch Logs so it can minimize the cost.
Install Doing newrelic-lambda integrations install, Secret containing API Key Layer refers is deployed.
$ pip3 install newrelic-lambda-cli $ newrelic-lambda integrations install \  --nr-account-id &amp;lt;account id&amp;gt; \  --nr-api-key &amp;lt;api key&amp;gt; \  --linked-account-name &amp;lt;linked account name&amp;gt; \  --enable-license-key-secret \  --aws-profile &amp;lt;aws_profile_name&amp;gt; --aws-region &amp;lt;aws_region&amp;gt; Validating New Relic credentials Retrieving integration license key Creating the AWS role for the New Relic AWS Lambda Integration Waiting for stack creation to complete.</description>
    </item>
    
    <item>
      <title>Monitor infrastructure and applications with New Relic</title>
      <link>https://www.sambaiz.net/en/article/399/</link>
      <pubDate>Wed, 30 Mar 2022 19:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/399/</guid>
      <description>New Relic is a SaaS that monitors infrastructure and applications, and there is Datadog as a similar service. It seems that the pricing plans were changed drastically in 2020, and it charges according to the transfer volume and the number of admin users. Therefore compared to Datadog, which charges for hosts and additional features, there is an advantage when managing a large number of instances with a small number of people.</description>
    </item>
    
    <item>
      <title>Generate data with TPC-DS Connector for Glue</title>
      <link>https://www.sambaiz.net/en/article/393/</link>
      <pubDate>Tue, 18 Jan 2022 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/393/</guid>
      <description>Previously, I tried to generate 250GB of data with Athena&amp;rsquo;s TPC-DS Connector and output it to S3 but it timed out even if I increased the Lambda resource to the maximum, so I do it with Glue this time.
Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net
Subscribe and activate TPC-DS connector for Glue.
 Write a script like following. The scale is in GB, the same as Athena&amp;rsquo;s one.</description>
    </item>
    
    <item>
      <title>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog</title>
      <link>https://www.sambaiz.net/en/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/392/</guid>
      <description>Redshift Serverless Redshift Serverless is a new feature which can use Redshift, a petabyte-scale DWH without the instance, announced at this year&amp;rsquo;s re:Invent. It is available existing features such as Redshift Spectrum, refer to S3 directly, Federated Query to RDS, and Redshift ML. I&amp;rsquo;m happy with this update as it is costly to keep the instance running for occasional usage such as analytics.
The cost is charged for at least 1 minute RPU time and storage.</description>
    </item>
    
    <item>
      <title>Generate data with TPC-DS Connector in Athena&#39;s Federated Query</title>
      <link>https://www.sambaiz.net/en/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/391/</guid>
      <description>Athena&amp;rsquo;s Federated Query is a feature to execute queries on non-S3 data sources such as DynamoDB and RDS through Lambda function which is a data sources connector.
Implement Athena&amp;rsquo;s data source connectors and user defined functions (UDF)
 This article uses TPC-DS Connector in the AWS official repository. It generates the data of TPC-DS, which is a database benchmark in Decision Support.
Although it is in the official repository, it is a custom connector, so you need to build it yourself.</description>
    </item>
    
    <item>
      <title>Columnar format Parquet structure and Read optimization</title>
      <link>https://www.sambaiz.net/en/article/386/</link>
      <pubDate>Fri, 03 Dec 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/386/</guid>
      <description>Parquet is a columnar format mainly used in the Hadoop ecosystem. Compared to row-based formats like CSV, unnecessary data is not read so queries can be executed efficiently.
Structure Data is horizontally partitioned to some Row Groups. A column is splitted into some Column Chunks, and a Column Chunk has some Pages which is an unit of compressing and encoding.
File structure is like following and it contains some Row Groups which have Column Chunks of each columns and metadata.</description>
    </item>
    
  </channel>
</rss>
