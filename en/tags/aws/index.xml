<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>aws on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/aws/</link>
    <description>Recent content in aws on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 13 Nov 2022 15:34:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/en/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Monitor AWS costs with New Relic</title>
      <link>https://www.sambaiz.net/en/article/424/</link>
      <pubDate>Sun, 13 Nov 2022 15:34:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/424/</guid>
      <description>Visualize Billing metrics There are Billing metrics in CloudWatch, so if you are sending all metrics in us-east-1 with Cloud Metric Streams, you can refer them with a query as follows.
SELECT max(`aws.billing.EstimatedCharges`) - min(`aws.billing.EstimatedCharges`) as daily_usage FROM Metric WHERE aws.Namespace = &amp;#39;AWS/Billing&amp;#39; AND `metricName` = &amp;#39;aws.billing.EstimatedCharges&amp;#39; AND `aws.billing.ServiceName` IS NOT NULL FACET monthOf(`timestamp`), `aws.billing.ServiceName` TIMESERIES 2 day SLIDE BY 1 day SINCE 4 week ago The values are accumulated monthly, so daily costs can be shown with taking differences from previous day&amp;rsquo;s one with Sliding window.</description>
    </item>
    
    <item>
      <title>Monitor and optimize costs with AWS Cost Management</title>
      <link>https://www.sambaiz.net/en/article/422/</link>
      <pubDate>Thu, 10 Nov 2022 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/422/</guid>
      <description>AWS Cost Management is a feature group for monitoring, forecasting, and optimizing costs. Billing has similar features. Billing is for managing present costs whereas Cost Management seems to target future costs.
Cost Explorer Cost Explorer can show costs grouped and filtered by services and regions etc.
With filtering with Usage type filter, you can see costs for data transfer from ELB and EC2.
Budgets Budgets can notice that set budgets have been exceeded and report the usage with email etc.</description>
    </item>
    
    <item>
      <title>Create a role that can assume with OIDC from GitHub Actions with CDK</title>
      <link>https://www.sambaiz.net/en/article/421/</link>
      <pubDate>Sun, 30 Oct 2022 02:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/421/</guid>
      <description>aws-actions/configure-aws-credentials is an action that assumes a role, and it also supports authentication with an access key, but JWT issued by GitHub OIDC Provider enables to access to API securely without setting credential. OpenID ConnectのIDトークンの内容と検証 - sambaiz-net To trust the external provider, it is necessary to register the certificate thumbprint of</description>
    </item>
    
    <item>
      <title>Develop Spark Applications in Scala, deploy with GitHub Actions, and perform remote debugging on EMR</title>
      <link>https://www.sambaiz.net/en/article/420/</link>
      <pubDate>Fri, 21 Oct 2022 23:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/420/</guid>
      <description>Spark provides Java and Python APIs in addition to Scala, which is used for developing Spark itself. You can choose among them depending on the technical stack and technologies used in other components, etc.
While Python is highly compatible with data analysis and machine learning skill sets, it needs to be converted with Py4J, so it has disadvantage in terms of the performance.
What is Apache Spark, RDD, DataFrame, DataSet, Action and Transformation - sambaiz-net</description>
    </item>
    
    <item>
      <title>Aggregate logs of spark running on an EMR cluster with Fluent Bit</title>
      <link>https://www.sambaiz.net/en/article/416/</link>
      <pubDate>Sun, 04 Sep 2022 14:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/416/</guid>
      <description>If Spark jobs run on Cluster mode, the logs are not outputted to step/ directory, so it is hard to check it on the console, so try aggregating them to New Relic, etc.
Launch an EMR cluster with AWS CLI and run Spark applications - sambaiz-net
Monitor infrastructure and applications with New Relic - sambaiz-net
Option 1. Sending logs with self installed fluent bit Install Fluent Bit that is memory saving fluentd, and send logs with it.</description>
    </item>
    
    <item>
      <title>Why can Athena v2 fail to query map columns in parquet source tables</title>
      <link>https://www.sambaiz.net/en/article/415/</link>
      <pubDate>Tue, 16 Aug 2022 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/415/</guid>
      <description>Output logs containing map fields as json etc., convert it to parquet with Glue Studio, and execute queries with Athena, then the queries can succeed or fail depending on the table.
Columnar format Parquet structure and read optimization - sambaiz-net
type Log struct { A map[string]int } =&amp;gt; {&amp;#34;A&amp;#34;:{&amp;#34;B&amp;#34;:10,&amp;#34;C&amp;#34;:20}} The parquet metadata is as follows and the information about map is lost.
$ parquet meta test.parquet File path: test.parquet Created by: parquet-glue version 1.</description>
    </item>
    
    <item>
      <title>Settings for running Spark on EMR</title>
      <link>https://www.sambaiz.net/en/article/414/</link>
      <pubDate>Sat, 13 Aug 2022 19:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/414/</guid>
      <description>EMR and Glue are managed services that run Spark applications on AWS. Glue is easy to run ETL jobs with serverless, while EMR allows fine-tuning of resources and parameters. In other words, if the settings are not appropriate, the resources cannot be fully used, and tasks can fail due to OOM even if there is excess memory.
In the CLI, settings can be passed as json string or a file with &amp;ndash;configurations.</description>
    </item>
    
    <item>
      <title>Deploy a container to ECS on Fargate, execute commands by ECS Exec, and perform port forwarding by Session Manager</title>
      <link>https://www.sambaiz.net/en/article/410/</link>
      <pubDate>Sat, 23 Jul 2022 13:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/410/</guid>
      <description>When investigating an application running in a remote non-container environment, sshd is often running, so commands can be executed with SSH connection. On the other hand, sshd isn&amp;rsquo;t usually running in a container environment, so it can&amp;rsquo;t be executed similarly. If absolutely necessary, there is a way to run sshd, but it would be better to avoid it in terms of opening ports and managing keys. In this article, command</description>
    </item>
    
    <item>
      <title>Launch an EMR cluster with AWS CLI and run Spark applications</title>
      <link>https://www.sambaiz.net/en/article/409/</link>
      <pubDate>Wed, 22 Jun 2022 00:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/409/</guid>
      <description>Amazon EMR is the service that launches a cluster installed Spark, Hive, and Presto on EC2 or EKS. While Glue, the managed Spark service, can easily run Spark ETL jobs with serverless, EMR has the advantage of excellent cost performance by spot instances etc., and also fine-tuning is available, but now that EMR Serverless has been released, the difference has narrowed a little. Glue also has handy features such as</description>
    </item>
    
    <item>
      <title>Settings for querying tables of other accounts with Athena</title>
      <link>https://www.sambaiz.net/en/article/405/</link>
      <pubDate>Tue, 17 May 2022 23:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/405/</guid>
      <description>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net Borrower Account that executes the query needs to access the resources of Owner Account having Data Catalog and the data. There are some ways to access resources of other accounts, such as access tokens or AssumeRole, but in this case, the role used to execute queries also needs the permission of the Borrower Account&amp;rsquo;s Athena,</description>
    </item>
    
    <item>
      <title>Implement Athena&#39;s data source connectors and user defined functions (UDF)</title>
      <link>https://www.sambaiz.net/en/article/402/</link>
      <pubDate>Sat, 23 Apr 2022 18:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/402/</guid>
      <description>Athena has a feature called Federate Query that can access data sources other than S3 using Lambda as a connector, and the official repository provides connectors for various data sources such as BigQuery and Snowflake, but you can also implement your own. This article, implement the minimum connector while referring to Example Connector and run it. The full codes has been pushed to GitHub.
Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net</description>
    </item>
    
    <item>
      <title>About newrelic-lambda-extension and how it works telemetry without CloudWatch Logs</title>
      <link>https://www.sambaiz.net/en/article/401/</link>
      <pubDate>Fri, 08 Apr 2022 12:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/401/</guid>
      <description>Theare are two methods to send Lambda logs to New Relic. First is a conventional method that uses a Lambda function aws-log-ingestion to subscribe and transfer CloudWatch Logs, and second is a method that uses a Lambda layer newrelic-lambda-extension. The latter send trace logs etc. without outputting to CloudWatch Logs so it can minimize the cost. Install Doing newrelic-lambda integrations install, Secret containing API Key Layer refers is deployed. $</description>
    </item>
    
    <item>
      <title>Monitor infrastructure and applications with New Relic</title>
      <link>https://www.sambaiz.net/en/article/399/</link>
      <pubDate>Wed, 30 Mar 2022 19:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/399/</guid>
      <description>New Relic is a SaaS that monitors infrastructure and applications, and there is Datadog as a similar service. It seems that the pricing plans were changed drastically in 2020, and it charges according to the transfer volume and the number of admin users. Therefore compared to Datadog, which charges for hosts and additional features, there is an advantage when managing a large number of instances with a small number of</description>
    </item>
    
    <item>
      <title>Compare Redshift Serverless and Athena performances by TPC-DS queries</title>
      <link>https://www.sambaiz.net/en/article/397/</link>
      <pubDate>Sun, 20 Feb 2022 01:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/397/</guid>
      <description>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net
Compare the performance between Redshift Serverless (Preview) and Athena by queries of TPC-DS, which is a database benchmark.
(PS: 2022-07-13) Following values were calculated at the rate at the time of preview. When it became GA, the rate dropped by about 30%.
Generate data with TPC-DS Connector for Glue - sambaiz-net
First, executed the following query to the json and parquet data.</description>
    </item>
    
    <item>
      <title>Generate data with TPC-DS Connector for Glue</title>
      <link>https://www.sambaiz.net/en/article/393/</link>
      <pubDate>Tue, 18 Jan 2022 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/393/</guid>
      <description>Previously, I tried to generate 250GB of data with Athena&amp;rsquo;s TPC-DS Connector and output it to S3 but it timed out even if I increased the Lambda resource to the maximum, so I do it with Glue this time.
Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net
Subscribe and activate TPC-DS connector for Glue.
Write a script like following. The scale is in GB, the same as Athena&amp;rsquo;s one.</description>
    </item>
    
    <item>
      <title>Redshift Serverless and other serverless ETL services, run query with Glue Data Catalog</title>
      <link>https://www.sambaiz.net/en/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/392/</guid>
      <description>Redshift Serverless Redshift Serverless is a new feature that can use Redshift, a petabyte-scale DWH without launching an instance, announced at this year&amp;rsquo;s re:Invent. It is available existing features such as Redshift Spectrum, refer to S3 directly, Federated Query to RDS, and Redshift ML. I&amp;rsquo;m happy with this update as it is costly to keep the instance running for occasional usage such as analytics. The cost is charged for at</description>
    </item>
    
    <item>
      <title>Generate data with TPC-DS Connector in Athena&#39;s Federated Query</title>
      <link>https://www.sambaiz.net/en/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/391/</guid>
      <description>Athena&amp;rsquo;s Federated Query is a feature to execute queries on non-S3 data sources such as DynamoDB and RDS through Lambda function which is a data sources connector. Implement Athena&amp;rsquo;s data source connectors and user defined functions (UDF) - sambaiz-net This article uses TPC-DS Connector in the AWS official repository. It generates the data of TPC-DS, which is a database benchmark in Decision Support. Although it is in the official repository,</description>
    </item>
    
    <item>
      <title>Spark Web UI: Monitor Job Stages, Tasks distribution and SQL plan</title>
      <link>https://www.sambaiz.net/en/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/382/</guid>
      <description>Spark Web UI is a tool for monitoring Jobs and Executors. Get Dockerfile that runs Spark based on maven: 3.6-amazoncorretto-8 from aws-glue-samples, and start History Server with the path of EventLog output by Glue and authentication information to get it. $ git clone https://github.com/aws-samples/aws-glue-samples.git $ cd aws-glue-samples/utilities/Spark_UI/glue-3_0/ $ docker build -t glue/sparkui:latest . $ docker run -it -e SPARK_HISTORY_OPTS=&amp;#34;$SPARK_HISTORY_OPTS -Dspark.history.fs.logDirectory=s3a://path_to_eventlog -Dspark.hadoop.fs.s3a.access.key=$AWS_ACCESS_KEY_ID -Dspark.hadoop.fs.s3a.secret.key=$AWS_SECRET_ACCESS_KEY&amp;#34; -p 18080:18080 glue/sparkui:latest &amp;#34;/opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer&amp;#34; Now, you can</description>
    </item>
    
    <item>
      <title>Athena (Presto) and Glue (Spark) can return different values when running the same query</title>
      <link>https://www.sambaiz.net/en/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/370/</guid>
      <description>AWS has multiple managed services that aggregate with SQL-like queries. If queries are executed ad-hoc, Presto-based Athena, which can quickly and easily query to tables in Glue&amp;rsquo;s data catalog, is handy, while if heavy queries are executed in batch, Spark-based Glue, which can avoid resource and time limitation, can be better. Therefore, they can be used properly depending on the case.
Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net</description>
    </item>
    
    <item>
      <title>Enable Job Bookmark of AWS Glue to process from the records following ones executed previously</title>
      <link>https://www.sambaiz.net/en/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/333/</guid>
      <description>Job Bookmark of AWS Glue is a feature that saves what records are processed, and prevent it from being executed next time. Parquet and ORC, which were not supported before 1.0, are now supported. AWS GlueでCSVを加工しParquetに変換してパーティションを切りA</description>
    </item>
    
  </channel>
</rss>
