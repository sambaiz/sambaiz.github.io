<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>aws on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/aws/</link>
    <description>Recent content in aws on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 20 Feb 2022 01:49:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/en/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Performance comparison between Redshift Serverless and Athena using TPC-DS queries</title>
      <link>https://www.sambaiz.net/en/article/397/</link>
      <pubDate>Sun, 20 Feb 2022 01:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/397/</guid>
      <description>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net
Compare the performance between Redshift Serverless and Athena by queries of TPC-DS, which is a database benchmark.
Generate data with TPC-DS Connector for Glue - sambaiz-net
First, execute the following query to the json and parquet data.
select /* TPC-DS query96.tpl 0.1 */ count(*) from store_sales ,household_demographics ,time_dim, store where ss_sold_time_sk = time_dim.t_time_sk and ss_hdemo_sk = household_demographics.</description>
    </item>
    
    <item>
      <title>Generate data with TPC-DS Connector for Glue</title>
      <link>https://www.sambaiz.net/en/article/393/</link>
      <pubDate>Tue, 18 Jan 2022 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/393/</guid>
      <description>Previously, I tried to generate 250GB of data with Athena&amp;rsquo;s TPC-DS Connector and output it to S3 but it timed out even if I increased the Lambda resource to the maximum, so I do it with Glue this time.
Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net
Subscribe and activate TPC-DS connector for Glue.
 Write a script like following. The scale is in GB, the same as Athena&amp;rsquo;s one.</description>
    </item>
    
    <item>
      <title>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog</title>
      <link>https://www.sambaiz.net/en/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/392/</guid>
      <description>Redshift Serverless Redshift Serverless is a new feature which can use Redshift, a petabyte-scale DWH without the instance, announced at this year&amp;rsquo;s re:Invent. It is available existing features such as Redshift Spectrum, refer to S3 directly, Federated Query to RDS, and Redshift ML. I&amp;rsquo;m happy with this update as it is costly to keep the instance running for occasional usage such as analytics.
The cost is charged for at least 1 minute RPU time and storage.</description>
    </item>
    
    <item>
      <title>Generate data with TPC-DS Connector in Athena&#39;s Federated Query</title>
      <link>https://www.sambaiz.net/en/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/391/</guid>
      <description>Athena&amp;rsquo;s Federated Query is a feature to execute queries on non-S3 data sources such as DynamoDB and RDS through Lambda function which is a data sources connector.
 This article uses TPC-DS Connector in the AWS official repository. It generates the data of TPC-DS, which is a database benchmark in Decision Support.
Although it is in the official repository, it is a custom connector, so you need to build it yourself.</description>
    </item>
    
    <item>
      <title>Spark Web UI: Monitor Job Stages, Tasks distribution and SQL plan</title>
      <link>https://www.sambaiz.net/en/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/382/</guid>
      <description>Spark Web UI is a tool for monitoring Jobs and Executors.
Get Dockerfile that runs Spark based on maven: 3.6-amazoncorretto-8 from aws-glue-samples, and start History Server with the path of EventLog output by Glue and authentication information to get it.
 $ git clone https://github.com/aws-samples/aws-glue-samples.git $ cd aws-glue-samples/utilities/Spark_UI/glue-3_0/ $ docker build -t glue/sparkui:latest . $ docker run -it -e SPARK_HISTORY_OPTS=&amp;#34;$SPARK_HISTORY_OPTS-Dspark.history.fs.logDirectory=s3a://path_to_eventlog -Dspark.hadoop.fs.s3a.access.key=$AWS_ACCESS_KEY_ID-Dspark.hadoop.fs.s3a.secret.key=$AWS_SECRET_ACCESS_KEY&amp;#34; -p 18080:18080 glue/sparkui:latest &amp;#34;/opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer&amp;#34; Now, you can access http://localhost:18080 and select Application.</description>
    </item>
    
    <item>
      <title>Enable Job Bookmark of AWS Glue to process from the records following ones executed previously</title>
      <link>https://www.sambaiz.net/en/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/333/</guid>
      <description>Job Bookmark of AWS Glue is a feature that saves what records are processed, and prevent it from being executed next time. Parquet and ORC, which were not supported before 1.0, are now supported.
AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net
Bookmark is available if Job Bookmark is enabled, call DynamicFrame methods with a transaction_ctx, and call job.commit().
For example, following job that counts a table and outputs it doesn&amp;rsquo;t count records previously counted if Bookmark is available, so it outputs not total but difference count from the previous time.</description>
    </item>
    
  </channel>
</rss>
