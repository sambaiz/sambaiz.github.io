<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Etl on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/etl/</link>
    <description>Recent content in Etl on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Wed, 23 Oct 2024 01:17:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/en/tags/etl/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Read and run WordCount Sample on Dataflow, managed ETL service using Apache Beam</title>
      <link>https://www.sambaiz.net/en/article/501/</link>
      <pubDate>Wed, 23 Oct 2024 01:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/501/</guid>
      <description>&lt;p&gt;GCP&amp;rsquo;s Dataflow is a managed service for streaming and batch ETL using &lt;a href=&#34;https://beam.apache.org/&#34;&gt;Apache Beam&lt;/a&gt;, an open-source software for building data processing pipelines. It can stream data from PubSub to BigQuery and perform machine learning etc. &lt;a href=&#34;https://cloud.google.com/dataflow/pricing&#34;&gt;Pricing&lt;/a&gt; is based on the resources used for job execution and the amount of data shuffled.&lt;/p&gt;&#xA;&lt;p&gt;Basic data migration can be performed without coding by using &lt;a href=&#34;https://cloud.google.com/dataflow/docs/guides/templates/provided-templates&#34;&gt;templates provided by Google&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/501/images/googletemplate.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/501/images/googletemplate_hu_a54aa18d76055b43.png&#34; width=&#34;600&#34; height=&#34;319&#34; alt=&#34;templates provided by Google&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;Let&amp;rsquo;s run the sample Word Count.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Install Livy on EMR on EKS and run Spark jobs from local Jupyter notebooks with Sparkmagic</title>
      <link>https://www.sambaiz.net/en/article/486/</link>
      <pubDate>Wed, 22 May 2024 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/486/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://livy.apache.org/&#34;&gt;Apache Livy&lt;/a&gt; provides a REST API for interacting with Spark clusters, and &lt;a href=&#34;https://github.com/jupyter-incubator/sparkmagic&#34;&gt;Sparkmagic&lt;/a&gt; calls this API to run jobs on remote Spark clusters from Jupyter Notebooks. It is also used by Athena for Apache Spark, and being able to run jobs interactively and check the results is useful for debugging and running ad-hoc queries.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/438/&#34;&gt;Athena for Apache Spark の Notebook で DataFrame.toPandas().plot() した際の日本語が文字化けしないようにする - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Make EMR clusters&#39; scale-in faster with Task nodes</title>
      <link>https://www.sambaiz.net/en/article/445/</link>
      <pubDate>Sun, 19 Mar 2023 22:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/445/</guid>
      <description>&lt;p&gt;EMR cluster &lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html&#34;&gt;consists&lt;/a&gt; of a Master (primary) node and Core nodes and Task nodes.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/427/&#34;&gt;How Hadoop YARN allocates resources to applications and check how much resources are allocated - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Resources of both core nodes and task nodes are used to run tasks, but core nodes are HDFS&amp;rsquo;s DataNode while task nodes aren&amp;rsquo;t.&#xA;Therefore, core nodes need to be decommissioned and then terminated to prevent data loss, but replication bandwidth is limited to prevent spikes, so &lt;a href=&#34;https://aws.amazon.com/jp/blogs/big-data/best-practices-for-resizing-and-automatic-scaling-in-amazon-emr/&#34;&gt;it takes time&lt;/a&gt; to scale in.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Launch an EKS cluster and register it to EMR on EKS with CDK to run Spark jobs</title>
      <link>https://www.sambaiz.net/en/article/434/</link>
      <pubDate>Mon, 02 Jan 2023 14:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/434/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/emr-eks.html&#34;&gt;EMR on EKS&lt;/a&gt; is a feature to run Spark on EKS.&#xA;While normal EMR also manages Hadoop clusters, EMR on EKS is only responsible for starting containers.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/409/&#34;&gt;Launch an EMR cluster with AWS CLI and run Spark applications - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;By running on Kubernetes, you can use tools and functions for Kubernetes to manage and monitor, and utilize resources left over if you have an existing cluster.&#xA;It also enables to use knowledge about Kubernetes learned from other applications for aggregation and analysis, and also may be vice versa.&#xA;However, some knowledge about Kubernetes and EKS is required.&#xA;You can start using normal EMR without knowledge of YARN, but I think EMR on EKS will be difficult to even operate with no knowledge.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Retry processing consisting of multiple Tasks with Callbacks in Airflow</title>
      <link>https://www.sambaiz.net/en/article/432/</link>
      <pubDate>Sun, 18 Dec 2022 17:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/432/</guid>
      <description>&lt;p&gt;When processing a task in an EMR cluster, add a Step to the EMR cluster with EmrAddStepsOperator, and then wait for its execution to end with EmrStepSensor.&#xA;When the Step fails, only the Sensor fails, so there is a problem that the Step is not re-executed even if it is retried.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/428/&#34;&gt;Create an environment of Amazon Managed Workflow for Apache Airflow (MWAA) with CDK and run a workflow - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Express dependencies on past tasks in Airflow</title>
      <link>https://www.sambaiz.net/en/article/429/</link>
      <pubDate>Wed, 30 Nov 2022 09:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/429/</guid>
      <description>&lt;p&gt;If past aggregated values are required for periodic aggregation and such a workflow is simply executed periodically, subsequent processing will fail in a chain reaction when the processing fails or hasn&amp;rsquo;t been completed in time.&#xA;Airflow allows you to describe dependencies on past tasks in the following way.&#xA;This makes it possible to wait for the past aggregation to finish or to re-execute only dependent tasks collectively in the event of failure.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Create an environment of Amazon Managed Workflow for Apache Airflow (MWAA) with CDK and run a workflow</title>
      <link>https://www.sambaiz.net/en/article/428/</link>
      <pubDate>Mon, 28 Nov 2022 19:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/428/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/managed-workflows-for-apache-airflow&#34;&gt;Amazon Managed Workflow for Apache Airflow (MWAA)&lt;/a&gt; is a managed service of &lt;a href=&#34;https://airflow.apache.org/&#34;&gt;Apache Airflow&lt;/a&gt;.&#xA;Unlike Step Functions that is serverless, it &lt;a href=&#34;https://aws.amazon.com/managed-workflows-for-apache-airflow/pricing/&#34;&gt;costs&lt;/a&gt; per an instance hour,&#xA;but Airflow&amp;rsquo;s abundant features and third-party&amp;rsquo;s, including AWS, &lt;a href=&#34;https://airflow.apache.org/docs/#providers-packagesdocsapache-airflow-providersindexhtml&#34;&gt;providers packages&lt;/a&gt; are available.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/425/&#34;&gt;Run Apache Airflow with Docker Compose and execute a workflow - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Step Functions doesn&amp;rsquo;t support execution from the middle of the workflow currently, so retrying a very long workflow can be hard.&#xA;Also, if you include the input value in an array of object values such as args of EmrAddStep, you need to process it into an array with Lambda in advance.&#xA;If you feel inconvenienced with such things now, migrating to MWAA may be a option.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Run Apache Airflow with Docker Compose and execute a workflow</title>
      <link>https://www.sambaiz.net/en/article/425/</link>
      <pubDate>Sat, 19 Nov 2022 16:52:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/425/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://airflow.apache.org/&#34;&gt;Apache Airflow&lt;/a&gt; is an OSS that schedules workflows and visualize pipelines.&#xA;It is scalable and has abundant features.&#xA;Also, it can be extended with your own Operators in addition to third-party, such as AWS and Slack, &lt;a href=&#34;https://airflow.apache.org/docs/#providers-packagesdocsapache-airflow-providersindexhtml&#34;&gt;providers packages&lt;/a&gt; existing in the repository.&lt;/p&gt;&#xA;&lt;h2 id=&#34;run-airflow&#34;&gt;&lt;a href=&#34;https://airflow.apache.org/docs/apache-airflow/2.4.3/howto/docker-compose/index.html&#34;&gt;Run Airflow&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Download docker-compose.yaml.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ curl -LfO &amp;#39;https://airflow.apache.org/docs/apache-airflow/2.4.3/docker-compose.yaml&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ cat docker-compose.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;x-airflow-common&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;amp;airflow-common&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;image&lt;/span&gt;: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.4.3}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;volumes&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - ./dags:/opt/airflow/dags&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - ./logs:/opt/airflow/logs&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - ./plugins:/opt/airflow/plugins&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;services&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;postgres&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;image&lt;/span&gt;: postgres:13&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;redis&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;image&lt;/span&gt;: redis:latest&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;airflow-webserver&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;: &lt;span style=&#34;color:#ff79c6&#34;&gt;*airflow-common&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;command&lt;/span&gt;: webserver&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;ports&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - &lt;span style=&#34;color:#bd93f9&#34;&gt;8080&lt;/span&gt;:&lt;span style=&#34;color:#bd93f9&#34;&gt;8080&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;airflow-scheduler&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;: &lt;span style=&#34;color:#ff79c6&#34;&gt;*airflow-common&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;command&lt;/span&gt;: scheduler&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;airflow-worker&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;: &lt;span style=&#34;color:#ff79c6&#34;&gt;*airflow-common&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;command&lt;/span&gt;: celery worker&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;airflow-triggerer&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;: &lt;span style=&#34;color:#ff79c6&#34;&gt;*airflow-common&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;command&lt;/span&gt;: triggerer&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;airflow-init&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;: &lt;span style=&#34;color:#ff79c6&#34;&gt;*airflow-common&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;airflow-cli&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;: &lt;span style=&#34;color:#ff79c6&#34;&gt;*airflow-common&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;profiles&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - debug&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;flower&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;: &lt;span style=&#34;color:#ff79c6&#34;&gt;*airflow-common&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;command&lt;/span&gt;: celery flower&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;profiles&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - flower&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff79c6&#34;&gt;ports&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - &lt;span style=&#34;color:#bd93f9&#34;&gt;5555&lt;/span&gt;:&lt;span style=&#34;color:#bd93f9&#34;&gt;5555&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;volumes&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;postgres-db-volume&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;First, run &amp;ldquo;docker compose up airflow-init&amp;rdquo; to initialize data stores.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Develop Spark Applications in Scala, deploy with GitHub Actions, and perform remote debugging on EMR</title>
      <link>https://www.sambaiz.net/en/article/420/</link>
      <pubDate>Fri, 21 Oct 2022 23:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/420/</guid>
      <description>&lt;p&gt;Spark provides Java and Python APIs in addition to Scala, which is used for developing Spark itself.&#xA;You can choose among them depending on the technical stack and technologies used in other components, etc.&lt;/p&gt;&#xA;&lt;p&gt;While Python has highly compatible with data analysis and machine learning skill sets and easy to edit and run on Glue Studio, the error is hard to understand, and the performance also has disadvantages because it needs to exchange the data between JVM and Python Workers.&#xA;Also, if the Python interpreter, which is not controlled by the JVM, try to use more memory than a resource manager such as YARN has allocated, the executor can be killed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Build Spark and debug it remotely at IntelliJ</title>
      <link>https://www.sambaiz.net/en/article/419/</link>
      <pubDate>Sun, 09 Oct 2022 19:06:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/419/</guid>
      <description>&lt;h2 id=&#34;build-at-the-command-prompt&#34;&gt;&lt;a href=&#34;https://spark.apache.org/docs/3.3.0/building-spark.html&#34;&gt;Build at the command prompt&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ git clone &lt;span style=&#34;color:#6272a4&#34;&gt;--branch v3.3.0 --depth 1 https://github.com/apache/spark.git &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Install Java 8 with &lt;a href=&#34;https://asdf-vm.com/guide/getting-started.html#_3-install-asdf&#34;&gt;asdf&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ brew install asdf&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ echo &lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;e &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;\n. $(brew --prefix asdf)/libexec/asdf.sh&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ${ZDOTDIR:&lt;span style=&#34;color:#ff79c6&#34;&gt;-~&lt;/span&gt;}&lt;span style=&#34;color:#ff79c6&#34;&gt;/&lt;/span&gt;.zshrc&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf &lt;span style=&#34;color:#6272a4&#34;&gt;--version&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#6272a4&#34;&gt;&lt;/span&gt;v0.&lt;span style=&#34;color:#bd93f9&#34;&gt;10&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;2&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf plugin&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;add&lt;/span&gt; java&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf list&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;all&lt;/span&gt; java&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf install java corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf &lt;span style=&#34;color:#ff79c6&#34;&gt;global&lt;/span&gt; java corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ echo &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;. ~/.asdf/plugins/java/set-java-home.zsh&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;~/&lt;/span&gt;.zprofile&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ java &lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;version&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;openjdk &lt;span style=&#34;color:#ff79c6&#34;&gt;version&lt;/span&gt; &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;1.8.0_342&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenJDK Runtime Environment Corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt; (build &lt;span style=&#34;color:#bd93f9&#34;&gt;1&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;_342&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;b07)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenJDK &lt;span style=&#34;color:#bd93f9&#34;&gt;64&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;Bit&lt;/span&gt; Server VM Corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt; (build &lt;span style=&#34;color:#bd93f9&#34;&gt;25&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;b07, mixed &lt;span style=&#34;color:#ff79c6&#34;&gt;mode&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Check the build&amp;rsquo;s success.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;MAVEN_OPTS&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;-Xss64m -Xmx2g -XX:ReservedCodeCacheSize=1g&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./build/mvn -DskipTests clean package&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;build-at-intellij&#34;&gt;&lt;a href=&#34;https://spark.apache.org/developer-tools.html&#34;&gt;Build at IntelliJ&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Open codes as Maven Project from &amp;ldquo;New &amp;gt; Project from Existing Sources.&amp;rdquo;&#xA;There is JDK in ~/.asdf/installs/java/, so make hidden directory visible with &amp;ldquo;Command + Shift + .&amp;rdquo;, and choose it.&#xA;After that, run &amp;ldquo;Generate Sources and Update Folders For All Projects&amp;rdquo; from Maven window, and then Build Project becomes successful.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why can Athena v2 fail to query map columns in parquet source tables</title>
      <link>https://www.sambaiz.net/en/article/415/</link>
      <pubDate>Tue, 16 Aug 2022 21:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/415/</guid>
      <description>&lt;p&gt;Output logs containing map fields as json etc., convert it to parquet with Glue Studio, and execute queries with Athena, then the queries can succeed or fail depending on the table.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/386/&#34;&gt;Columnar format Parquet structure and read optimization - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;type&lt;/span&gt; Log &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;struct&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    A &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#8be9fd&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#8be9fd&#34;&gt;int&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;=&amp;gt; {&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;:{&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#bd93f9&#34;&gt;10&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;C&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#bd93f9&#34;&gt;20&lt;/span&gt;}}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The parquet metadata is as follows and the information about map is lost.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ parquet meta test.parquet&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;File path:  test.parquet&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Created by: parquet-glue version 1.8.2&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Properties:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  org.apache.spark.sql.parquet.row.metadata: &lt;span style=&#34;color:#ff79c6&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;struct&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;fields&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ff79c6&#34;&gt;[{&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ff79c6&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;struct&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;fields&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ff79c6&#34;&gt;[{&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;integer&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;nullable&amp;#34;&lt;/span&gt;:true,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ff79c6&#34;&gt;{}}&lt;/span&gt;,&lt;span style=&#34;color:#ff79c6&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;C&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;integer&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;nullable&amp;#34;&lt;/span&gt;:true,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ff79c6&#34;&gt;{}}]}&lt;/span&gt;,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;nullable&amp;#34;&lt;/span&gt;:true,&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ff79c6&#34;&gt;{}}]}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Schema:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message glue_schema &lt;span style=&#34;color:#ff79c6&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  optional group A &lt;span style=&#34;color:#ff79c6&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optional int32 B;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optional int32 C;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Row group 0:  count: &lt;span style=&#34;color:#bd93f9&#34;&gt;1&lt;/span&gt;  116.00 B records  start: &lt;span style=&#34;color:#bd93f9&#34;&gt;4&lt;/span&gt;  total&lt;span style=&#34;color:#ff79c6&#34;&gt;(&lt;/span&gt;compressed&lt;span style=&#34;color:#ff79c6&#34;&gt;)&lt;/span&gt;: &lt;span style=&#34;color:#bd93f9&#34;&gt;116&lt;/span&gt; B total&lt;span style=&#34;color:#ff79c6&#34;&gt;(&lt;/span&gt;uncompressed&lt;span style=&#34;color:#ff79c6&#34;&gt;)&lt;/span&gt;:112 B &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;type&lt;/span&gt;      encodings count     avg size   nulls   min / max&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A.B  INT32     S   _     &lt;span style=&#34;color:#bd93f9&#34;&gt;1&lt;/span&gt;         58.00 B    &lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;       &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;10&amp;#34;&lt;/span&gt; / &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;10&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A.C  INT32     S   _     &lt;span style=&#34;color:#bd93f9&#34;&gt;1&lt;/span&gt;         58.00 B    &lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;       &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;20&amp;#34;&lt;/span&gt; / &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;20&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If set this column type to map, I thought queries always fail, but if both key and value&amp;rsquo;s type are set to value&amp;rsquo;s one, queries themselves succeed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Settings for running Spark on EMR</title>
      <link>https://www.sambaiz.net/en/article/414/</link>
      <pubDate>Sat, 13 Aug 2022 19:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/414/</guid>
      <description>&lt;p&gt;EMR and Glue are managed services that run Spark applications on AWS.&#xA;Glue is easy to run ETL jobs with serverless, while EMR allows fine-tuning of resources and parameters.&#xA;In other words, if the settings are not appropriate, the resources cannot be fully used, and tasks can fail due to OOM even if there is excess memory.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/414/images/resource.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/414/images/resource_hu_c68de87341fa4011.png&#34; width=&#34;600&#34; height=&#34;356&#34; alt=&#34;a resource that isn&amp;#39;t fully used&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;In the CLI, settings can be passed as json string or a file with &amp;ndash;configurations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Launch an EMR cluster with AWS CLI and run Spark applications</title>
      <link>https://www.sambaiz.net/en/article/409/</link>
      <pubDate>Wed, 22 Jun 2022 00:05:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/409/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/emr/&#34;&gt;Amazon EMR&lt;/a&gt; is the service that launches a cluster installed Spark, Hive, and Presto on EC2 or EKS. While Glue, the managed Spark service, can easily run Spark ETL jobs with serverless, EMR has the advantage of excellent cost performance by spot instances etc., and also fine-tuning is available, but now that &lt;a href=&#34;https://aws.amazon.com/jp/emr/serverless/&#34;&gt;EMR Serverless&lt;/a&gt; has been released, the difference has narrowed a little. Glue also has handy features such as &lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html&#34;&gt;DynamicFrame&lt;/a&gt;, which doesn&amp;rsquo;t need to be specified the schema, and Bookmark, which makes processing being executed from the previous continuation. However, if heavy processing is executed repeatedly, it can be expensive, besides, it causes to reach quotas such as DPU, so it would be better to use it properly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Settings for querying tables of other accounts with Athena</title>
      <link>https://www.sambaiz.net/en/article/405/</link>
      <pubDate>Tue, 17 May 2022 23:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/405/</guid>
      <description>&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/405/images/structure.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/405/images/structure_hu_6504d01ea0a575e6.png&#34; width=&#34;600&#34; height=&#34;197&#34; alt=&#34;Structure&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/392/&#34;&gt;Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Borrower Account that executes the query needs to access the resources of Owner Account having Data Catalog and the data.&#xA;There are some ways to access resources of other accounts, such as access tokens or AssumeRole, but in this case, the role used to execute queries also needs the permission of the Borrower Account&amp;rsquo;s Athena, so it should be allowed to access resources of both accounts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Implement Athena&#39;s data source connectors and user defined functions (UDF)</title>
      <link>https://www.sambaiz.net/en/article/402/</link>
      <pubDate>Sat, 23 Apr 2022 18:09:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/402/</guid>
      <description>&lt;p&gt;Athena has a feature called Federate Query that can access data sources other than S3 using Lambda as a connector, and&#xA;&lt;a href=&#34;https://github.com/awslabs/aws-athena-query-federation&#34;&gt;the official repository&lt;/a&gt; provides connectors for various data sources such as BigQuery and Snowflake, but you can also implement your own.&#xA;This article, implement the minimum connector while referring to &lt;a href=&#34;https://github.com/awslabs/aws-athena-query-federation/tree/master/athena-example&#34;&gt;Example Connector&lt;/a&gt; and run it. The full codes has been pushed to &lt;a href=&#34;https://github.com/sambaiz/athena-connector-udf-example&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/391/&#34;&gt;Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Compare Redshift Serverless and Athena performances by TPC-DS queries</title>
      <link>https://www.sambaiz.net/en/article/397/</link>
      <pubDate>Sun, 20 Feb 2022 01:49:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/397/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/392/&#34;&gt;Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Compare the performance between Redshift Serverless (Preview) and Athena by queries of TPC-DS, which is a database benchmark.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;(PS: 2022-07-13) Following values were calculated at the rate at the time of preview. When it became &lt;a href=&#34;https://aws.amazon.com/jp/blogs/aws/amazon-redshift-serverless-now-generally-available-with-new-capabilities/&#34;&gt;GA&lt;/a&gt;, the rate dropped by about 30%.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/393/&#34;&gt;Generate data with TPC-DS Connector for Glue - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;First, executed the following query to the json and parquet data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Generate data with TPC-DS Connector for Glue</title>
      <link>https://www.sambaiz.net/en/article/393/</link>
      <pubDate>Tue, 18 Jan 2022 21:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/393/</guid>
      <description>&lt;p&gt;Previously, I tried to generate 250GB of data with Athena&amp;rsquo;s TPC-DS Connector and output it to S3 but it timed out even if I increased the Lambda resource to the maximum, so I do it with Glue this time.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/391/&#34;&gt;Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Subscribe and activate &lt;a href=&#34;https://aws.amazon.com/marketplace/pp/prodview-xtty6azr4xgey&#34;&gt;TPC-DS connector&lt;/a&gt; for Glue.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/393/images/activate.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/393/images/activate_hu_838d08cc29ec6674.png&#34; width=&#34;450&#34; height=&#34;370&#34; alt=&#34;Activate TPC-DS connector for Glue&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;Write a script like following. The scale is in GB, the same as Athena&amp;rsquo;s one.&#xA;Tables are added to a catalog at the time of upload.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Redshift Serverless and other serverless ETL services, run query with Glue Data Catalog</title>
      <link>https://www.sambaiz.net/en/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/392/</guid>
      <description>&lt;h2 id=&#34;redshift-serverless&#34;&gt;Redshift Serverless&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/redshift/redshift-serverless/&#34;&gt;Redshift Serverless&lt;/a&gt; is a new feature that can use Redshift, a petabyte-scale DWH without launching an instance, announced at this year&amp;rsquo;s re:Invent.&#xA;It is available existing features such as &lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html&#34;&gt;Redshift Spectrum&lt;/a&gt;, refer to S3 directly, &lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/federated-overview.html&#34;&gt;Federated Query&lt;/a&gt; to RDS, and &lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/machine_learning.html&#34;&gt;Redshift ML&lt;/a&gt;.&#xA;I&amp;rsquo;m happy with this update as it is costly to keep the instance running for occasional usage such as analytics.&lt;/p&gt;&#xA;&lt;p&gt;The &lt;a href=&#34;https://aws.amazon.com/redshift/pricing&#34;&gt;cost&lt;/a&gt; is charged for at least 1 minute &lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html#serverless-considerations&#34;&gt;RPU&lt;/a&gt; time and storage. RPU is a resource unit that contains 2vCPU and 16GiB memory and scales automatically.&#xA;The rate is &lt;strong&gt;$0.45/RPU hour&lt;/strong&gt; in Oregon, whereas Tokyo is set relatively high at &lt;strong&gt;$0.70/RPU hour&lt;/strong&gt;.&#xA;Since dc2.large (2vCPU, 15 GiB memory) instance is &lt;strong&gt;$0.314/hour&lt;/strong&gt; on-demand in Tokyo, if the resource usage is not over 40% on average due to like infrequent use or irregularity, it seems that the cost can be suppressed.&#xA;If RI is applied to the maximum, the rate becomes &lt;strong&gt;$0.110/hour&lt;/strong&gt; so the threshold drop to 15%, but there is also an operational advantage that you do not have to worry about the scale. In addition, there is no charge for the load amount of Redshift Spectrum.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Generate data with TPC-DS Connector in Athena&#39;s Federated Query</title>
      <link>https://www.sambaiz.net/en/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/391/</guid>
      <description>&lt;p&gt;Athena&amp;rsquo;s &lt;a href=&#34;https://docs.aws.amazon.com/athena/latest/ug/connect-to-a-data-source.html&#34;&gt;Federated Query&lt;/a&gt; is a feature to execute queries on non-S3 data sources such as DynamoDB and RDS through Lambda function which is a data sources connector.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/402/&#34;&gt;Implement Athena&amp;rsquo;s data source connectors and user defined functions (UDF) - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/391/images/datasource.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/391/images/datasource_hu_db42a44fc1fb3cc3.png&#34; width=&#34;372&#34; height=&#34;370&#34; alt=&#34;Data sources&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;This article uses TPC-DS Connector in the &lt;a href=&#34;https://github.com/awslabs/aws-athena-query-federation/tree/master/athena-tpcds&#34;&gt;AWS official repository&lt;/a&gt;. It generates the data of &lt;a href=&#34;http://www.tpc.org/tpcds/&#34;&gt;TPC-DS&lt;/a&gt;, which is a database benchmark in Decision Support.&lt;/p&gt;&#xA;&lt;p&gt;Although it is in the official repository, it is a custom connector, so you need to build it yourself. Basically, you can do it according to &lt;a href=&#34;https://github.com/awslabs/aws-athena-query-federation/tree/master/athena-tpcds#readme&#34;&gt;README&lt;/a&gt;, but it fails to build in jdk16, so install jdk8.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Treat Spark struct as map to expand to multiple rows with explode</title>
      <link>https://www.sambaiz.net/en/article/384/</link>
      <pubDate>Wed, 13 Oct 2021 02:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/384/</guid>
      <description>&lt;p&gt;When you &lt;a href=&#34;https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrameReader.json.html&#34;&gt;read data&lt;/a&gt; without specifying schema in Spark, the schema is automatically determined from the input as follows.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/415/&#34;&gt;Why can Athena v2 fail to query map columns in parquet source tables - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#6272a4&#34;&gt;# {&amp;#34;aaa&amp;#34;:123,&amp;#34;ccc&amp;#34;:[123],&amp;#34;eee&amp;#34;:{&amp;#34;fff&amp;#34;:123},&amp;#34;hhh&amp;#34;:null}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;json(&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;s3://hogefuga/testjson/&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;printSchema()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;root&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt; |-- aaa: long (nullable = true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt; |-- ccc: array (nullable = true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt; |    |-- element: long (containsNull = true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt; |-- eee: struct (nullable = true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt; |    |-- fff: long (nullable = true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt; |-- hhh: string (nullable = true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This works well in most cases, but if the field that assumes map is determined as struct, or if the field is determined as string as it contains only null, processings may fail by mismatch of function inputs.&#xA;&lt;a href=&#34;https://spark.apache.org/docs/3.1.1/api/sql/index.html#explode&#34;&gt;explode()&lt;/a&gt; is a function that expands array and map into multiple rows.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark Web UI: Monitor Job Stages, Tasks distribution and SQL plan</title>
      <link>https://www.sambaiz.net/en/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/382/</guid>
      <description>&lt;p&gt;Spark &lt;a href=&#34;https://spark.apache.org/docs/latest/web-ui.html&#34;&gt;Web UI&lt;/a&gt; is a tool for monitoring Jobs and Executors.&lt;/p&gt;&#xA;&lt;p&gt;Get Dockerfile that runs Spark based on maven:3.6-amazoncorretto-8 from &lt;a href=&#34;https://github.com/aws-samples/aws-glue-samples/tree/b76ad0583bdc66e9e5a903f9da3a953c9f6aac4f&#34;&gt;aws-glue-samples&lt;/a&gt;, and &lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui-history.html#monitor-spark-ui-history-local&#34;&gt;start&lt;/a&gt; &lt;a href=&#34;https://spark.apache.org/docs/latest/monitoring.html&#34;&gt;History Server&lt;/a&gt; with the path of EventLog output by Glue and authentication information to get it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/382/images/eventlog-settings.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/382/images/eventlog-settings_hu_75f3daf3dc9d5627.png&#34; width=&#34;385&#34; height=&#34;167&#34; alt=&#34;Output EventLog config&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ git clone https://github.com/aws-samples/aws-glue-samples.git&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;cd&lt;/span&gt; aws-glue-samples/utilities/Spark_UI/glue-3_0/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ docker build -t glue/sparkui:latest .&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ docker run -it -e &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;SPARK_HISTORY_OPTS&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;$SPARK_HISTORY_OPTS&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt; -Dspark.history.fs.logDirectory=s3a://path_to_eventlog &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;-Dspark.hadoop.fs.s3a.access.key=&lt;/span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;$AWS_ACCESS_KEY_ID&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt; -Dspark.hadoop.fs.s3a.secret.key=&lt;/span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;$AWS_SECRET_ACCESS_KEY&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-p 18080:18080 glue/sparkui:latest &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;/opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, you can access http://localhost:18080 and select Application.&#xA;The timeline of executing Jobs and adding Executors is displayed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athena (Presto) and Glue (Spark) can return different values when running the same query</title>
      <link>https://www.sambaiz.net/en/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/370/</guid>
      <description>&lt;p&gt;AWS has multiple managed services that aggregate with SQL-like queries.&#xA;If queries are executed ad-hoc, Presto-based Athena, which can quickly and easily query to tables in Glue&amp;rsquo;s data catalog, is handy, while if heavy queries are executed in batch, Spark-based Glue, which can avoid resource and time limitation, can be better. Therefore, they can be used properly depending on the case.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/392/&#34;&gt;Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Enable Job Bookmark of AWS Glue to process from the records following ones executed previously</title>
      <link>https://www.sambaiz.net/en/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/333/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/monitor-continuations.html&#34;&gt;Job Bookmark&lt;/a&gt; of AWS Glue is a feature that saves what records are processed, and prevent it from being executed next time.&#xA;Parquet and ORC, which were not supported before 1.0, are now supported.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/203/&#34;&gt;AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is Apache Spark, RDD, DataFrame, DataSet, Action and Transformation</title>
      <link>https://www.sambaiz.net/en/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/208/</guid>
      <description>&lt;h2 id=&#34;what-is-spark&#34;&gt;What is Spark?&lt;/h2&gt;&#xA;&lt;p&gt;Spark is high-performance general-purpose distributed processing system.&#xA;It is used with distributed storage such as HDFS and S3, and cluster managers such as Hadoop YARN.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/126/&#34;&gt;HDFS(Hadoop Distributed File System)とは - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/427/&#34;&gt;How Hadoop YARN allocates resources to applications and check how much resources are allocated - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;It can be processed faster than Hadoop&amp;rsquo;s MapReduce by storing the intermediate data in memory.&#xA;There are APIs for Java, Scala, Python, R.&#xA;While python is easy to write, performance suffers due to interaction with JVM.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Launch Hive execution environment with Cloudera Docker Image and execute query to JSON log</title>
      <link>https://www.sambaiz.net/en/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/128/</guid>
      <description>&lt;h2 id=&#34;what-is-hive&#34;&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/Home#Home-ApacheHive&#34;&gt;What is Hive&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Hive is a data warehouse software built on Hadoop, which can access data sources such as HDFS with HiveSQL, an extended SQL.&#xA;Sending a query, the job runs on MapReduce, Spark or Tez.&#xA;It has fault tolerance and is mainly used in batch processing.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/126/&#34;&gt;What is HDFS(Hadoop Distributed File System) - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://prestodb.io/&#34;&gt;Presto&lt;/a&gt;, which access data sources with SQL likewise, can execute the query faster than Hive by parallelizing tasks and having intermediate data on memory, so it is suitable for an ad-hoc purpose.&#xA;On the other hand, if the intermediate data is large, it &lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/top-10-performance-tuning-tips-for-amazon-athena/&#34;&gt;takes a long time or can be failed&lt;/a&gt;.&#xA;Presto can refer to &lt;strong&gt;Hive metastore&lt;/strong&gt; with &lt;a href=&#34;https://prestodb.io/docs/current/connector/hive.html&#34;&gt;Hive Connector&lt;/a&gt;, so it can share the schema with Hive and query to it.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
