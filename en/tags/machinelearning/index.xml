<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machinelearning on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/machinelearning/</link>
    <description>Recent content in Machinelearning on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Thu, 12 Dec 2024 01:30:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/en/tags/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building a game AI for Animal Shogi using Monte Carlo Tree Search (MCTS)</title>
      <link>https://www.sambaiz.net/en/article/515/</link>
      <pubDate>Thu, 12 Dec 2024 01:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/515/</guid>
      <description>&lt;p&gt;Monte Carlo Tree Search (MCTS) is an algorithm used for searching optimal moves in game AI such as AlphaGo. Similar algorithms include the minimax, which exhaustively searches for the best moves assuming the opponent always makes the worst possible moves, and the alpha-beta pruning, which improves efficiency through pruning. While these algorithms require assigning evaluation values to intermediate board status, Monte Carlo Tree Search can evaluate the move based on the win/loss results of randomly playing out the game.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Run AutoML jobs with no code using SageMaker Canvas Custom models</title>
      <link>https://www.sambaiz.net/en/article/458/</link>
      <pubDate>Thu, 16 Nov 2023 23:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/458/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/sagemaker/canvas/&#34;&gt;SageMaker Canvas&lt;/a&gt; provides an interface for using pre-trained models provided by &lt;a href=&#34;https://aws.amazon.com/sagemaker/jumpstart/&#34;&gt;SageMaker JumpStart&lt;/a&gt; and&#xA;a feature to run jobs of &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development.html&#34;&gt;SageMaker Autopilot&lt;/a&gt;, an AutoML feature, with no code.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/458/images/ready-to-use-model.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/458/images/ready-to-use-model_hu_3d6b9625cbb51105.png&#34; width=&#34;600&#34; height=&#34;307&#34; alt=&#34;Pre-trained model&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;Note that if you finish using SageMaker Canvas, you need to &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-log-out.html&#34;&gt;log out&lt;/a&gt; explicitly, or you will continue to be &lt;a href=&#34;https://aws.amazon.com/sagemaker/canvas/pricing&#34;&gt;charged&lt;/a&gt; for the workspace instance.&lt;/p&gt;&#xA;&lt;p&gt;In this article, I try to run AutoML jobs with &lt;a href=&#34;https://aws.amazon.com/getting-started/hands-on/machine-learning-tutorial-generate-predictions-without-writing-code/?nc1=h_ls&#34;&gt;tutorial&lt;/a&gt; datasets, product descriptions and shipping logs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fine-tuning OpenAI&#39;s GPT with Japanese Prime Minister&#39;s speech in the Diet</title>
      <link>https://www.sambaiz.net/en/article/452/</link>
      <pubDate>Mon, 11 Sep 2023 23:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/452/</guid>
      <description>&lt;p&gt;OpenAI provides APIs to &lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat/create&#34;&gt;create conversation&lt;/a&gt;&#xA;and &lt;a href=&#34;https://platform.openai.com/docs/api-reference/embeddings/create&#34;&gt;convert text to vector&lt;/a&gt;,&#xA;and also &lt;a href=&#34;https://platform.openai.com/docs/guides/fine-tuning&#34;&gt;fine-tune&lt;/a&gt; models with your own dataset,&#xA;which enables us to improve the quality of the output or save the cost of few-shot learning.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#6272a4&#34;&gt;# !pip install openai&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;import&lt;/span&gt; openai&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#ff79c6&#34;&gt;as&lt;/span&gt; np&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;response &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; openai&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;ChatCompletion&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;create(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  model&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;gpt-3.5-turbo&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  messages&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;[{&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#6272a4&#34;&gt;# &amp;#34;system&amp;#34;, &amp;#34;user&amp;#34;, or &amp;#34;assistant&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;Is this a pen?&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  }],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  temperature&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;0.5&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;print&lt;/span&gt;(response&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;choices[&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;message)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;{&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;  &amp;#34;role&amp;#34;: &amp;#34;assistant&amp;#34;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;  &amp;#34;content&amp;#34;: &amp;#34;As an AI, I don&amp;#39;t have the ability to see or perceive objects. Therefore, I cannot determine if something is a pen or not based on visual cues.&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;embedding &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; openai&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;Embedding&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;create(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  model&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;text-embedding-ada-002&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#6272a4&#34;&gt;# https://platform.openai.com/docs/guides/embeddings/embedding-models&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;response&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;choices[&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;message&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;content&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;print&lt;/span&gt;(embedding&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;data[&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;embedding[:&lt;span style=&#34;color:#bd93f9&#34;&gt;5&lt;/span&gt;]) &lt;span style=&#34;color:#6272a4&#34;&gt;# [-0.02444140985608101, -0.015481687150895596, 0.009029921144247055, 0.0035672972444444895, -0.006072063464671373]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;len&lt;/span&gt;(embedding&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;data[&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;embedding)) &lt;span style=&#34;color:#6272a4&#34;&gt;# 1536&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#6272a4&#34;&gt;# https://platform.openai.com/docs/guides/embeddings/limitations-risks&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#6272a4&#34;&gt;# https://github.com/openai/openai-python/blob/5d50e9e3b39540af782ca24e65c290343d86e1a9/openai/embeddings_utils.py#L65C1-L65C1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#50fa7b&#34;&gt;cosine_similarity&lt;/span&gt;(a, b):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ff79c6&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;dot(a, b) &lt;span style=&#34;color:#ff79c6&#34;&gt;/&lt;/span&gt; (np&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;norm(a) &lt;span style=&#34;color:#ff79c6&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;norm(b))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cosine_similarity(embedding&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;data[&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;embedding, embedding&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;data[&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;embedding) &lt;span style=&#34;color:#6272a4&#34;&gt;# 1.0&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ready-for-the-dataset&#34;&gt;Ready for the dataset&lt;/h2&gt;&#xA;&lt;p&gt;Collect questions and answers to the Prime Minister or his deputy with &lt;a href=&#34;https://kokkai.ndl.go.jp/api.html&#34;&gt;API for the Japanese Diet Minutes Search System&lt;/a&gt;,&#xA;output them in the &lt;a href=&#34;https://platform.openai.com/docs/guides/fine-tuning/example-format&#34;&gt;format&lt;/a&gt; for fine-tuning.&#xA;There are very long questions and answers in the speeches, but they are excluded mainly for the sake of &lt;a href=&#34;https://openai.com/pricing&#34;&gt;cost&lt;/a&gt; of learning.&#xA;I noticed later that I could get them in JSON.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploy Japanese LLMs in TGI Container with SageMaker&#39;s HuggingFaceModel and generate texts</title>
      <link>https://www.sambaiz.net/en/article/451/</link>
      <pubDate>Tue, 05 Sep 2023 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/451/</guid>
      <description>&lt;p&gt;Recently, some Japanese LLMs have been released in Hugging Face,&#xA;such as &lt;a href=&#34;https://huggingface.co/cyberagent/open-calm-7b&#34;&gt;OpenCALM-7B&lt;/a&gt; by CyberAgent and&#xA;&lt;a href=&#34;https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b&#34;&gt;ELYZA-japanese-Llama-2-7b&lt;/a&gt; by ELYZA, spun-out from Matsuo Lab., University of Tokyo.&#xA;SageMaker SDK has a HuggingFaceModel class, which can be used to deploy a model by specifying the model ID.&#xA;Also, if you press the deploy button in Hugging Face, you can see the minimum code to run the model in SageMaker.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/451/images/deploy.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/451/images/deploy_hu_f7bb6db0337fc228.png&#34; width=&#34;600&#34; height=&#34;216&#34; alt=&#34;Deploy button&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;get_huggingface_llm_image_uri() returns the image_uri of &lt;a href=&#34;https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-text-generation-inference-containers&#34;&gt;HuggingFace Text Generation Inference Containers&lt;/a&gt;.&#xA;&lt;a href=&#34;https://aws.amazon.com/blogs/machine-learning/announcing-the-launch-of-new-hugging-face-llm-inference-containers-on-amazon-sagemaker&#34;&gt;This&lt;/a&gt; is a DLC (Deep Learning Container) of&#xA;&lt;a href=&#34;https://github.com/huggingface/text-generation-inference&#34;&gt;Text Generation Inference (TGI)&lt;/a&gt;, which is an OSS by Hugging Face that performs parallel processing on multiple GPUs to generate text quickly.&#xA;&lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/g5/&#34;&gt;ml.g5.12xlarge&lt;/a&gt; has 4 GPUs, so I set SM_NUM_GPUS to 4, which is referenced by &lt;a href=&#34;https://github.com/huggingface/text-generation-inference/blob/62fc40103079bc27e97194ef69e9e34a180b0a85/sagemaker-entrypoint.sh#L14&#34;&gt;sagemaker-entrypoint.sh&lt;/a&gt; in the TGI repository.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Check how job parameters of SageMaker Batch Transform work from called functions in entrypoint and its arguments</title>
      <link>https://www.sambaiz.net/en/article/448/</link>
      <pubDate>Mon, 14 Aug 2023 18:16:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/448/</guid>
      <description>&lt;p&gt;SageMaker &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html&#34;&gt;Batch Transform&lt;/a&gt; is a feature that runs a one-time batch inference job.&#xA;It calls the entrypoint function of the Model as in the case of inference endpoints. I check how job parameters work from the function and its arguments.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/290/&#34;&gt;SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;from&lt;/span&gt; sagemaker.transformer &lt;span style=&#34;color:#ff79c6&#34;&gt;import&lt;/span&gt; Transformer&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;transformer &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; Transformer(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  model_name&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;model_name,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  instance_type&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;ml.m5.xlarge&amp;#39;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  instance_count&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;1&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  output_path&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;s3://&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;{&lt;/span&gt;os&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;getenv(&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;S3_BUCKET&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f1fa8c&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;/output/&amp;#39;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#6272a4&#34;&gt;# strategy=&amp;#39;SingleRecord&amp;#39;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#6272a4&#34;&gt;# max_payload=1,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#6272a4&#34;&gt;# assemble_with=&amp;#39;Line&amp;#39;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#6272a4&#34;&gt;# accept=&amp;#39;application/json&amp;#39;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;transformer&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;transform(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  data&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;s3://&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;{&lt;/span&gt;os&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;getenv(&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;S3_BUCKET&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f1fa8c&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;/batch_input/&amp;#39;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  content_type&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;application/json&amp;#39;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#6272a4&#34;&gt;# compression_type=&amp;#39;Gzip&amp;#39;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#6272a4&#34;&gt;# split_type=&amp;#39;Line&amp;#39;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#6272a4&#34;&gt;# output_filter=&amp;#34;$[&amp;#39;SageMakerOutput&amp;#39;,&amp;#39;value&amp;#39;]&amp;#34;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#6272a4&#34;&gt;# join_source=&amp;#39;Input&amp;#39;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Looking at the Transformer class in the SageMaker Inference Toolkit, I found that the following functions are called in &lt;a href=&#34;https://github.com/aws/sagemaker-inference-toolkit/blob/2ed6f3d19daffccab390d8e9142c9c39c9932271/src/sagemaker_inference/transformer.py#L241&#34;&gt;transform_fn()&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Create a cost-optimized real-time inference endpoint with SageMaker Inference Recommender</title>
      <link>https://www.sambaiz.net/en/article/447/</link>
      <pubDate>Thu, 15 Jun 2023 09:38:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/447/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender.html&#34;&gt;SageMaker Inference Recommender&lt;/a&gt; is a feature to recommend endpoint&amp;rsquo;s instance types and settings.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/290/&#34;&gt;SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;I try running an Inference Recommender job for a PyTorch model created in the past and setting up an inference endpoint with the lowest cost instance type.&#xA;The full code is on &lt;a href=&#34;https://github.com/sambaiz/sagemaker-inference-recommendation-test&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;default&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender-instance-recommendation.html&#34;&gt;Default&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;First, run a job with Default JobType and npy input that default inference handler supports.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Preprocess data with SageMaker Processing, train model with Training and record the parameters and accuracy with Experiments</title>
      <link>https://www.sambaiz.net/en/article/442/</link>
      <pubDate>Thu, 04 May 2023 19:20:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/442/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html&#34;&gt;SageMaker Experiments&lt;/a&gt; is a feature to record parameters and metrics&#xA;of &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html&#34;&gt;Processing&lt;/a&gt;&#xA;and &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html&#34;&gt;Training&lt;/a&gt; jobs etc.&#xA;In this article, I track from preprocessing to learning as a Run in Experiments and confirm that multiple results can be compared.&lt;/p&gt;&#xA;&lt;p&gt;The full code is on &lt;a href=&#34;https://github.com/sambaiz/sagemaker-processing-training-experiments-test&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;sagemaker-experiments&#34;&gt;SageMaker Experiments&lt;/h2&gt;&#xA;&lt;p&gt;experiments.Run() creates an Experiment if it hasn&amp;rsquo;t existed yet and starts a Run.&#xA;Previously, it was a separate library called sagemaker-experiments, but now it is &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-additional-sdk.html&#34;&gt;integrated&lt;/a&gt; into sagemaker.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clustering by k-means method with MLlib of Spark</title>
      <link>https://www.sambaiz.net/en/article/446/</link>
      <pubDate>Sun, 09 Apr 2023 17:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/446/</guid>
      <description>&lt;p&gt;Spark has &lt;a href=&#34;https://spark.apache.org/docs/latest/ml-guide.html&#34;&gt;MLlib&lt;/a&gt; which is a library for machine learning.&#xA;This article, try clustering using &lt;a href=&#34;https://spark.apache.org/docs/latest/ml-clustering.html#k-means&#34;&gt;Kmeans&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;K-means is a clustering method that randomly assigns each data to one of a pre-determined number of clusters first, computes the center of each cluster,&#xA;and then updates the cluster assignment of each data to the cluster whose center is closest, which repeats until convergence.&#xA;Kmeans is implemented in k-means++ that converges faster, and its default distance measure is euclidean.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
