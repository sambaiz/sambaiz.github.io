<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/hadoop/</link>
    <description>Recent content in Hadoop on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 19 Mar 2023 22:51:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/en/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Make EMR clusters&#39; scale-in faster with Task nodes</title>
      <link>https://www.sambaiz.net/en/article/445/</link>
      <pubDate>Sun, 19 Mar 2023 22:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/445/</guid>
      <description>&lt;p&gt;EMR cluster &lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html&#34;&gt;consists&lt;/a&gt; of a Master (primary) node and Core nodes and Task nodes.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/427/&#34;&gt;How Hadoop YARN allocates resources to applications and check how much resources are allocated - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Resources of both core nodes and task nodes are used to run tasks, but core nodes are HDFS&amp;rsquo;s DataNode while task nodes aren&amp;rsquo;t.&#xA;Therefore, core nodes need to be decommissioned and then terminated to prevent data loss, but replication bandwidth is limited to prevent spikes, so &lt;a href=&#34;https://aws.amazon.com/jp/blogs/big-data/best-practices-for-resizing-and-automatic-scaling-in-amazon-emr/&#34;&gt;it takes time&lt;/a&gt; to scale in.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Scheduler which allocates resources in Hadoop YARN, and Dominant Resource Fairness (DRF)</title>
      <link>https://www.sambaiz.net/en/article/433/</link>
      <pubDate>Sat, 24 Dec 2022 22:15:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/433/</guid>
      <description>&lt;p&gt;YARN&amp;rsquo;s ResourceManager consists of ApplicationsManager, which receives applications from clients and launches ApplicationMaster, and &lt;a href=&#34;https://github.com/apache/hadoop/blob/release-3.3.5-RC0/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/YarnScheduler.java&#34;&gt;Scheduler&lt;/a&gt;, which receives requests from ApplicationMaster and allocates resources.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/427/&#34;&gt;How Hadoop YARN allocates resources to applications and check how much resources are allocated - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;scheduler&#34;&gt;Scheduler&lt;/h2&gt;&#xA;&lt;p&gt;Scheduler has &lt;a href=&#34;https://github.com/apache/hadoop/tree/release-3.3.5-RC0/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler&#34;&gt;implementations&lt;/a&gt;&#xA;such as &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html&#34;&gt;CapacityScheduler&lt;/a&gt;, which aims to maximize the throughput in multi-tenant clusters, and&#xA;&lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/FairScheduler.html&#34;&gt;FairScheduler&lt;/a&gt;, which allocates fair resources to all applications.&#xA;You can choose to use which one with yarn.resourcemanager.scheduler.class, and CapacityScheduler is used in EMR by default.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How Hadoop YARN allocates resources to applications and check how much resources are allocated</title>
      <link>https://www.sambaiz.net/en/article/427/</link>
      <pubDate>Wed, 23 Nov 2022 18:15:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/427/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html&#34;&gt;YARN&lt;/a&gt; is a module that manages resources of a Hadoop cluster and schedules.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-hadoop-yarn-allocates-resources-to-applicationshttpshadoopapacheorgdocsstablehadoop-yarnhadoop-yarn-sitewritingyarnapplicationshtml&#34;&gt;&lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html&#34;&gt;How Hadoop YARN allocates resources to applications&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Once &lt;strong&gt;ResourceManager (RM)&lt;/strong&gt; receives an application from a client, it launches &lt;strong&gt;ApplicationMaster (AM)&lt;/strong&gt; and passes information for executing the application.&#xA;ApplicationMaster asks ResourceManager for allocating resources. After allocated, next it communicates with &lt;strong&gt;NodeManagers (NMs)&lt;/strong&gt; running on each node, and then starts containers and runs the application.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Settings for running Spark on EMR</title>
      <link>https://www.sambaiz.net/en/article/414/</link>
      <pubDate>Sat, 13 Aug 2022 19:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/414/</guid>
      <description>&lt;p&gt;EMR and Glue are managed services that run Spark applications on AWS.&#xA;Glue is easy to run ETL jobs with serverless, while EMR allows fine-tuning of resources and parameters.&#xA;In other words, if the settings are not appropriate, the resources cannot be fully used, and tasks can fail due to OOM even if there is excess memory.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/414/images/resource.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/414/images/resource_hu1325476225419147310.png&#34; width=&#34;600&#34; height=&#34;356&#34; alt=&#34;a resource that isn&amp;#39;t fully used&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;In the CLI, settings can be passed as json string or a file with &amp;ndash;configurations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Launch an EMR cluster with AWS CLI and run Spark applications</title>
      <link>https://www.sambaiz.net/en/article/409/</link>
      <pubDate>Wed, 22 Jun 2022 00:05:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/409/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/emr/&#34;&gt;Amazon EMR&lt;/a&gt; is the service that launches a cluster installed Spark, Hive, and Presto on EC2 or EKS. While Glue, the managed Spark service, can easily run Spark ETL jobs with serverless, EMR has the advantage of excellent cost performance by spot instances etc., and also fine-tuning is available, but now that &lt;a href=&#34;https://aws.amazon.com/jp/emr/serverless/&#34;&gt;EMR Serverless&lt;/a&gt; has been released, the difference has narrowed a little. Glue also has handy features such as &lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html&#34;&gt;DynamicFrame&lt;/a&gt;, which doesn&amp;rsquo;t need to be specified the schema, and Bookmark, which makes processing being executed from the previous continuation. However, if heavy processing is executed repeatedly, it can be expensive, besides, it causes to reach quotas such as DPU, so it would be better to use it properly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Columnar format Parquet structure and read optimization</title>
      <link>https://www.sambaiz.net/en/article/386/</link>
      <pubDate>Fri, 03 Dec 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/386/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/apache/parquet-format&#34;&gt;Parquet&lt;/a&gt; is a columnar format mainly used in the Hadoop ecosystem.&#xA;Compared to row-based formats like CSV, unnecessary columns can be skipped. Besides, there is a mechanics to read only rows that are needed, so queries can be executed efficiently.&lt;/p&gt;&#xA;&lt;h2 id=&#34;formathttpsgithubcomapacheparquet-formatblobmasterreadmemdfile-format&#34;&gt;&lt;a href=&#34;https://github.com/apache/parquet-format/blob/master/README.md#file-format&#34;&gt;Format&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/386/images/format.gif&#34; width=&#34;601&#34; height=&#34;478&#34; alt=&#34;https://github.com/apache/parquet-format#file-format&#34;&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;Rows are horizontally partitioned into some &lt;a href=&#34;https://github.com/apache/parquet-format/blob/parquet-format-2.2.0-rc1/src/thrift/parquet.thrift#L490&#34;&gt;Row Groups&lt;/a&gt;, and the &lt;a href=&#34;https://github.com/apache/parquet-format/blob/parquet-format-2.2.0-rc1/src/thrift/parquet.thrift#L474&#34;&gt;Column Chunks&lt;/a&gt; of each column are arranged in order. Column Chunks are divided into &lt;a href=&#34;https://github.com/apache/parquet-format/blob/parquet-format-2.2.0-rc1/src/thrift/parquet.thrift#L387&#34;&gt;Pages&lt;/a&gt;, and compression and encoding are performed in that unit.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Launch Hive execution environment with Cloudera Docker Image and execute query to JSON log</title>
      <link>https://www.sambaiz.net/en/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/128/</guid>
      <description>&lt;h2 id=&#34;what-is-hivehttpscwikiapacheorgconfluencedisplayhivehomehome-apachehive&#34;&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/Home#Home-ApacheHive&#34;&gt;What is Hive&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Hive is a data warehouse software built on Hadoop, which can access data sources such as HDFS with HiveSQL, an extended SQL.&#xA;Sending a query, the job runs on MapReduce, Spark or Tez.&#xA;It has fault tolerance and is mainly used in batch processing.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/en/article/126/&#34;&gt;What is HDFS(Hadoop Distributed File System) - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://prestodb.io/&#34;&gt;Presto&lt;/a&gt;, which access data sources with SQL likewise, can execute the query faster than Hive by parallelizing tasks and having intermediate data on memory, so it is suitable for an ad-hoc purpose.&#xA;On the other hand, if the intermediate data is large, it &lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/top-10-performance-tuning-tips-for-amazon-athena/&#34;&gt;takes a long time or can be failed&lt;/a&gt;.&#xA;Presto can refer to &lt;strong&gt;Hive metastore&lt;/strong&gt; with &lt;a href=&#34;https://prestodb.io/docs/current/connector/hive.html&#34;&gt;Hive Connector&lt;/a&gt;, so it can share the schema with Hive and query to it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is HDFS(Hadoop Distributed File System)</title>
      <link>https://www.sambaiz.net/en/article/126/</link>
      <pubDate>Mon, 14 Aug 2017 22:52:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/126/</guid>
      <description>&lt;h2 id=&#34;what-is-hdfs&#34;&gt;What is HDFS&lt;/h2&gt;&#xA;&lt;p&gt;HDFS stands for Hadoop Distributed File System, one of the implementations of file systems for Hadoop, and other implementations include local files and S3. It distributes the disk I/O, which is a big problem when the data size is enormous and makes a block size, a unit for reading and writing, big to reduce the seek cost and improve the throughput.&lt;/p&gt;&#xA;&lt;p&gt;You can see disk I/O can be a bottleneck from &lt;a href=&#34;https://gist.github.com/jboner/2841832&#34;&gt;the data&lt;/a&gt; that while communication within the data center takes about 0.5ms for a round trip, seeking takes 10ms, and reading 1MB takes 20ms.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
