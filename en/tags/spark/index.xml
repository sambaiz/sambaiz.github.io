<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/spark/</link>
    <description>Recent content in spark on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Wed, 13 Oct 2021 02:30:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/en/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Treat Spark struct as map to expand to multiple rows with explode</title>
      <link>https://www.sambaiz.net/en/article/384/</link>
      <pubDate>Wed, 13 Oct 2021 02:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/384/</guid>
      <description>When you read data without specifying schema in Spark, the schema is automatically determined from the input as follows.
# {&amp;#34;aaa&amp;#34;:123,&amp;#34;ccc&amp;#34;:[123],&amp;#34;eee&amp;#34;:{&amp;#34;fff&amp;#34;:123},&amp;#34;hhh&amp;#34;:null} df = spark.read.json(&amp;#34;s3://hogefuga/testjson/&amp;#34;) df.printSchema() &amp;#39;&amp;#39;&amp;#39; root |-- aaa: long (nullable = true) |-- ccc: array (nullable = true) | |-- element: long (containsNull = true) |-- eee: struct (nullable = true) | |-- fff: long (nullable = true) |-- hhh: string (nullable = true) &amp;#39;&amp;#39;&amp;#39; This works well in most cases, but if the field that assumes map is determined as struct, or if the field is determined as string as it contains only null, processings may fail by mismatch of function inputs.</description>
    </item>
    
    <item>
      <title>Spark Web UI: Monitor Job Stages, Tasks distribution and SQL plan</title>
      <link>https://www.sambaiz.net/en/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/382/</guid>
      <description>Spark Web UI is a tool for monitoring Jobs and Executors.
Get Dockerfile that runs Spark based on maven: 3.6-amazoncorretto-8 from aws-glue-samples, and start History Server with the path of EventLog output by Glue and authentication information to get it.
$ git clone https://github.com/aws-samples/aws-glue-samples.git $ cd aws-glue-samples/utilities/Spark_UI/glue-3_0/ $ docker build -t glue/sparkui:latest . $ docker run -it -e SPARK_HISTORY_OPTS=&amp;#34;$SPARK_HISTORY_OPTS-Dspark.history.fs.logDirectory=s3a://path_to_eventlog -Dspark.hadoop.fs.s3a.access.key=$AWS_ACCESS_KEY_ID-Dspark.hadoop.fs.s3a.secret.key=$AWS_SECRET_ACCESS_KEY&amp;#34; -p 18080:18080 glue/sparkui:latest &amp;#34;/opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer&amp;#34; Now, you can access http://localhost:18080 and select Application.</description>
    </item>
    
    <item>
      <title>What is Apache Spark, RDD, DataFrame, DataSet, Action and Transformation</title>
      <link>https://www.sambaiz.net/en/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/208/</guid>
      <description>What is Spark? Spark is high-performance general-purpose distributed processing system. It is used with distributed storage such as HDFS and S3, and cluster managers such as Hadoop YARN. It can be processed faster than Hadoop&amp;rsquo;s MapReduce by storing the intermediate data in memory. There are APIs for Java, Scala, Python, R. While python is easy to write, performance suffers due to interaction with JVM.
HDFS(Hadoop Distributed File System)とは - sambaiz-net</description>
    </item>
    
  </channel>
</rss>
