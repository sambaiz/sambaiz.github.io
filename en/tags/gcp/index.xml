<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gcp on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/tags/gcp/</link>
    <description>Recent content in Gcp on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sat, 16 Nov 2024 21:55:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/en/tags/gcp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Creating new tables in BigQuery by processing data with SQL using dbt</title>
      <link>https://www.sambaiz.net/en/article/509/</link>
      <pubDate>Sat, 16 Nov 2024 21:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/509/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.getdbt.com/docs/introduction&#34;&gt;dbt&lt;/a&gt; is a tool for transforming data using SQL or Python. There is dbt Core, an OSS CLI that provides basic functionality, and dbt Cloud, a service that &lt;a href=&#34;https://www.getdbt.com/product/dbt-core-vs-dbt-cloud&#34;&gt;includes&lt;/a&gt; a browser-based IDE, CI, alerts, and more. This article is for dbt Core.&lt;/p&gt;&#xA;&lt;p&gt;Install dbt Core and the &lt;a href=&#34;https://docs.getdbt.com/docs/connect-adapters&#34;&gt;adapters&lt;/a&gt; for data platforms. In addition to officially maintained ones like BigQuery, Spark, and Snowflake, community adapters are also available.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ python -m venv dbt-env&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;source&lt;/span&gt; dbt-env/bin/activate&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ python -m pip install dbt-core dbt-bigquery&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ dbt --version&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Core:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - installed: 1.8.8&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - latest:    1.8.8 - Up to date!&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Plugins:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - bigquery: 1.8.3 - Up to date!&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://docs.getdbt.com/reference/commands/init&#34;&gt;dbt init&lt;/a&gt; is used to create a project.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Read and run WordCount Sample on Dataflow, managed ETL service using Apache Beam</title>
      <link>https://www.sambaiz.net/en/article/501/</link>
      <pubDate>Wed, 23 Oct 2024 01:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/501/</guid>
      <description>&lt;p&gt;GCP&amp;rsquo;s Dataflow is a managed service for streaming and batch ETL using &lt;a href=&#34;https://beam.apache.org/&#34;&gt;Apache Beam&lt;/a&gt;, an open-source software for building data processing pipelines. It can stream data from PubSub to BigQuery and perform machine learning etc. &lt;a href=&#34;https://cloud.google.com/dataflow/pricing&#34;&gt;Pricing&lt;/a&gt; is based on the resources used for job execution and the amount of data shuffled.&lt;/p&gt;&#xA;&lt;p&gt;Basic data migration can be performed without coding by using &lt;a href=&#34;https://cloud.google.com/dataflow/docs/guides/templates/provided-templates&#34;&gt;templates provided by Google&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/501/images/googletemplate.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/501/images/googletemplate_hu4494795615599063853.png&#34; width=&#34;600&#34; height=&#34;319&#34; alt=&#34;templates provided by Google&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;Let&amp;rsquo;s run the sample Word Count.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Avoiding OOM in count-distinct operations on massive datasets using HyperLogLog&#43;&#43;, a probabilistic cardinality estimation algorithm</title>
      <link>https://www.sambaiz.net/en/article/497/</link>
      <pubDate>Mon, 02 Sep 2024 21:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/497/</guid>
      <description>&lt;p&gt;When counting unique elements, such as the number of users in access logs, we often execute queries like &amp;ldquo;count(distinct column_name)&amp;rdquo;. For massive datasets, regular count() operations can be scaled by splitting the data and summing the results. However, this method doesn&amp;rsquo;t work with distinct operations, which can lead to extreme slowdowns due to memory shortages or, in the worst case, failure due to OOM errors.&lt;/p&gt;&#xA;&lt;p&gt;This issue is known as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Count-distinct_problem&#34;&gt;Count-distinct problem (cardinality estimation problem)&lt;/a&gt;, and several algorithms have been proposed to estimate cardinality (unique count) without retaining all elements. One of them is HyperLogLog, and its improved version, HyperLogLog++, is widely implemented as &lt;a href=&#34;https://github.com/apache/spark/blob/c58148da5496245403b55c3fc423d35f3a669c79/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/FunctionRegistry.scala#L469&#34;&gt;approx_count_distinct()&lt;/a&gt; in Spark and &lt;a href=&#34;https://github.com/prestodb/presto/blob/2bceaa02b982f2b10d4d577fac9b3c8944c36ace/presto-main/src/main/java/com/facebook/presto/operator/aggregation/ApproximateCountDistinctAggregation.java#L40&#34;&gt;approx_distinct()&lt;/a&gt; in Presto.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
