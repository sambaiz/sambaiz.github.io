<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">

  
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NCML2RV');</script>
  

  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
  <link rel="stylesheet" href="/css/destyle.css">
  <style>
    body {
        background-color: #f1f1f1;
        line-height: 1.3;
        
        font-family: "Helvetica Neue", 
            Arial, 
            "Hiragino Kaku Gothic ProN",
            "Hiragino Sans",
            "BIZ UDPGothic",
            Meiryo,
            sans-serif;
    }

    table {
        margin-block-start: 1.5rem;
        margin-block-end: 1.5rem;
    }

    table th,table td{
        padding: 0.2rem 1.0rem;
    }

    table tr{
        border-bottom: solid 1px #eee;
    }

    .languages {
        position: absolute;
        top: 10px;
        right: 15px;
        font-size: 1.2rem;
        color: #3a9240;
    }

    header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
    }

    header>.title {
        font-size: 1.875rem;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns {
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns-item {
        display: inline-block;
        margin: 3px;
    }

    .filmarks {
        display: inline-block;
        width: 32px;
        height: 32px;
        margin-top: 3px;
        background: url(/image/filmarks.svg) no-repeat;
        background-size: 450%;
    }

    header>.tags {
        display: flex;
        justify-content: center;
        align-items: center;
        font-size: 1.2rem;
        max-width: 1000px;
        margin: auto;
        padding: 0 20px;
    }

    header>.tags .others {
        font-weight: bold;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
    }

    .nl {
        display: inline-block;
    }

    .cell {
        background-color: #fff;
        border-radius: 5px;
        padding: 10px;
        box-shadow: 0 1px 1px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
    }

    time {
        color: #333;
    }

    .tag {
        color: #3a9240;
        margin: 0 5px;
    }

    .tag:hover {
        text-decoration: underline;
    }

     
    .paging {
        display: inline-block;
        font-size: 1.25rem;
        margin: 10px 10px;
    }

    .paging.next {
        float: right;
    }


     
    .list>.title {
        font-size: 1.75rem;
        margin: 0 0 10px 10px;
    }

     
    .grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(262px, 1fr));
        gap: 20px;
        margin: 0 10px;
    }

    .grid-nl {
        width: 100%;
    }

    .grid-cell {
        height: 11.25rem;
        overflow: hidden;
        box-sizing: content-box;
    }

    .grid-cell>.title {
        font-size: 1.4rem;
        word-wrap: break-word;
    }

     
    .single {
        margin: 0 10px 10px 10px;
        line-height: 1.5;
    }

    @media screen and (min-width: 768px) {
        .single .cell {
            padding: 10px 20px;
        }
    }

    .single-header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
        line-height: 1.3;
    }

    .single-header h1 {
        font-size: 2rem;
        font-weight: bold;
    }

    .single h2 {
        font-size: 1.8rem;
        border-bottom: 1px solid #ddd;
        margin-block-start: 1.875rem;
    }

    .single h3 {
        font-size: 1.5rem;
        margin-block-start: 1.5rem;
    }

    .single h4 {
        font-size: 1.2rem;
        margin-block-start: 1rem;
    }

    .single a {
        color: #3a9240;
    }

    .single a:hover {
        text-decoration: underline;
    }

    .single p {
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    code {
        
        font-family: ui-monospace, SFMono-Regular, SF Mono, Menlo, Consolas, Liberation Mono, monospace;
    }

    .single p>code, .single li>code {
        padding: 0 0.2rem;
        display: inline-block;
        overflow: auto;
        max-width: 100%;
        vertical-align: bottom;
    }

    .single strong {
        color: #d2691e;
        font-weight: normal;
    }

    .single .highlight {
        box-shadow: 0 1px 1px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
        margin-block-start: 1rem;
        margin-block-end: 1rem;
        font-size: 0.875rem;
    }

    .single .img_container {
        margin-block-start: 0.1rem;
        margin-block-end: 0.1rem;
        text-align: center;
    }

    .single img {
        border: 1px solid #ddd;
    }

    .single .highlight>pre {
        padding: 10px;
        overflow-x: auto;
    }

    .single img {
        max-width: 100%;
    }

    .single blockquote {
        border-left: 5px solid #ddd;
        color: #777;
        padding: 1rem 0 1rem 1rem;
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single blockquote > p {
        margin-block-start: 0;
        margin-block-end: 0;
    }

    .single hr {
        color: #bbb;
        margin-block-start: 1.5rem;
        margin-block-end: 1.5rem;
    }

    .single ul {
        list-style-type: disc;
        padding-left: 1.5em;
        margin-block-end: 0.4rem;
    }
</style>
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">
  <link rel="icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">

  <meta name="theme-color" content="#41a248">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@sambaiz">
  
  <title>Deploy Japanese LLMs in TGI Container with SageMaker&#39;s HuggingFaceModel and generate texts - sambaiz-net</title>
  <meta name="twitter:title" content="Deploy Japanese LLMs in TGI Container with SageMaker&#39;s HuggingFaceModel and generate texts - sambaiz-net">
  <meta property='og:title' content="Deploy Japanese LLMs in TGI Container with SageMaker&#39;s HuggingFaceModel and generate texts - sambaiz-net">
  <meta property="og:type" content="article">
  
  <meta name="description" content="HuggingFace Text Generation Inference Containers is a Deep Learning Container for Hugging Face&#39;s OSS Text Generation Inference (TGI) that performs parallel processing on multiple GPUs to generate text quickly">
  <meta name="twitter:description" content="HuggingFace Text Generation Inference Containers is a Deep Learning Container for Hugging Face&#39;s OSS Text Generation Inference (TGI) that performs parallel processing on multiple GPUs to generate text quickly">
  
  

  <meta property="og:url" content="https://www.sambaiz.net/en/article/451/">
  <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
  <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />

  
  
  <link rel="alternate" hreflang="ja" href="https://www.sambaiz.net/article/451/" />
  
  <link rel="alternate" hreflang="x-default" href="https://www.sambaiz.net/article/451/" />
  
  
  <link rel="alternate" hreflang="en" href="https://www.sambaiz.net/en/article/451/" />
  
  
  

  
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id": "https://www.sambaiz.net/"
    },
    "headline": "Deploy Japanese LLMs in TGI Container with SageMaker's HuggingFaceModel and generate texts",
    "datePublished": "2023-09-05T23:55:00JST",
    "dateModified": "2023-09-05T23:55:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "url": "https://www.sambaiz.net/",
      "image": "https://www.sambaiz.net/images/my.jpg"
    },
    "publisher": {
      "@type": "Person",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.sambaiz.net/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https://www.sambaiz.net/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "HuggingFace Text Generation Inference Containers is a Deep Learning Container for Hugging Face's OSS Text Generation Inference (TGI) that performs parallel processing on multiple GPUs to generate text quickly"
  }
</script>
</head>

<body>
  
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NCML2RV"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  
  <div>
    <div class="languages">
      
      <ul>
          
          <li>
              <a href="https://www.sambaiz.net/article/451/">日本語</a>
          </li>
          
      </ul>
      
    </div>

    <header>
      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" alt="icon" />
        <a class="nl" href='/en/'>
          <h1>sambaiz-net</h1>
        </a>
      </div>

      <div class="sns">
        <div class="sns-item">
          <a class="nl" href="https://github.com/sambaiz">
            <img src="/image/github.png" width="30px" height="30px" alt="github">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://www.google.com/maps/contrib/102687103399829824749/photos">
            <img src="/image/googlemaps.svg" width="30px" height="30px" alt="google maps">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://boardgamearena.com/player?id=83835726">
            <img src="/image/boardgamearena.webp" width="30px" height="30px" alt="board game arena">
          </a>
        </div>
      </div>
      <div class="tags">
        <div>
          
          <a class="tag" href="/tags/aws/">
            aws</a>
          
          <a class="tag" href="/tags/golang/">
            golang</a>
          
          <a class="tag" href="/tags/machinelearning/">
            machinelearning</a>
          
          <a class="tag" href="/tags/kubernetes/">
            kubernetes</a>
          
          <a class="tag" href="/tags/python/">
            python</a>
          
          <a class="tag" href="/tags/etl/">
            etl</a>
          
          <a class="tag" href="/tags/web/">
            web</a>
          
          <a class="tag" href="/tags/fluentd/">
            fluentd</a>
          
          <a class="tag" href="/tags/linux/">
            linux</a>
          
          <a class="tag" href="/tags/spark/">
            spark</a>
          
          <a class="tag others" href="/tags/">...</a>
        </div>
      </div>
    </header>

<div class="container">
  <article class="single">
    <div class="cell">
      <div class="single-header">
        <h1>Deploy Japanese LLMs in TGI Container with SageMaker&#39;s HuggingFaceModel and generate texts</h1>
        <time>2023-09-05</time>
        <a class="tag" href='/en/tags/aws/'>aws</a><a class="tag" href='/en/tags/machinelearning/'>machinelearning</a>
      </div>
      <p>Recently, some Japanese LLMs have been released in Hugging Face,
such as <a href="https://huggingface.co/cyberagent/open-calm-7b">OpenCALM-7B</a> by CyberAgent and
<a href="https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b">ELYZA-japanese-Llama-2-7b</a> by ELYZA, spun-out from Matsuo Lab., University of Tokyo.
SageMaker SDK has a HuggingFaceModel class, which can be used to deploy a model by specifying the model ID.
Also, if you press the deploy button in Hugging Face, you can see the minimum code to run the model in SageMaker.</p>




<div class="img_container"><a href="/article/451/images/deploy.png">
    <img style="max-width: 100%; width: auto; height: auto;" src="/article/451/images/deploy_hu09d77cf3c21870a45fcc8591ef63a488_135315_600x370_fit_lanczos_3.png" width="600" height="216" alt="Deploy button">
</a></div>


<p>get_huggingface_llm_image_uri() returns the image_uri of <a href="https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-text-generation-inference-containers">HuggingFace Text Generation Inference Containers</a>.
<a href="https://aws.amazon.com/blogs/machine-learning/announcing-the-launch-of-new-hugging-face-llm-inference-containers-on-amazon-sagemaker">This</a> is a DLC (Deep Learning Container) of
<a href="https://github.com/huggingface/text-generation-inference">Text Generation Inference (TGI)</a>, which is an OSS by Hugging Face that performs parallel processing on multiple GPUs to generate text quickly.
<a href="https://aws.amazon.com/ec2/instance-types/g5/">ml.g5.12xlarge</a> has 4 GPUs, so I set SM_NUM_GPUS to 4, which is referenced by <a href="https://github.com/huggingface/text-generation-inference/blob/62fc40103079bc27e97194ef69e9e34a180b0a85/sagemaker-entrypoint.sh#L14">sagemaker-entrypoint.sh</a> in the TGI repository.</p>
<p>If the version of the sagemaker library is old, the deployment could fail, so I updated it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#6272a4"># !pip install sagemaker==2.182.0</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> sagemaker
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> sagemaker.huggingface <span style="color:#ff79c6">import</span> HuggingFaceModel, get_huggingface_llm_image_uri
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>hub <span style="color:#ff79c6">=</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#39;HF_MODEL_ID&#39;</span>: <span style="color:#f1fa8c">&#39;cyberagent/open-calm-7b&#39;</span>, <span style="color:#6272a4"># or elyza/ELYZA-japanese-Llama-2-7b</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#39;HF_MODEL_REVISION&#39;</span>: <span style="color:#f1fa8c">&#39;276a5fb67510554e11ef191a2da44c919acccdf5&#39;</span>, <span style="color:#6272a4"># or 976887c5891284db204320860bb84b71d598063e</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#39;SM_NUM_GPUS&#39;</span>: <span style="color:#f1fa8c">&#39;4&#39;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>image_uri <span style="color:#ff79c6">=</span> get_huggingface_llm_image_uri(<span style="color:#f1fa8c">&#34;huggingface&#34;</span>, version<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;0.9.3&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;image_uri: </span><span style="color:#f1fa8c">{</span>image_uri<span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>) <span style="color:#6272a4"># 763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi0.9.3-gpu-py39-cu118-ubuntu20.04</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>huggingface_model <span style="color:#ff79c6">=</span> HuggingFaceModel(
</span></span><span style="display:flex;"><span>  image_uri<span style="color:#ff79c6">=</span>image_uri,
</span></span><span style="display:flex;"><span>  env<span style="color:#ff79c6">=</span>hub,
</span></span><span style="display:flex;"><span>  role<span style="color:#ff79c6">=</span>sagemaker<span style="color:#ff79c6">.</span>get_execution_role(), <span style="color:#6272a4"># available if run on SageMaker Studio</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>predictor <span style="color:#ff79c6">=</span> huggingface_model<span style="color:#ff79c6">.</span>deploy(
</span></span><span style="display:flex;"><span>  initial_instance_count<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>,
</span></span><span style="display:flex;"><span>  instance_type<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;ml.g5.12xlarge&#34;</span>,
</span></span><span style="display:flex;"><span>  container_startup_health_check_timeout<span style="color:#ff79c6">=</span><span style="color:#bd93f9">300</span>,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>You can see parameters that can be passed to predict() in <a href="https://huggingface.github.io/text-generation-inference/#/Text%20Generation%20Inference/generate">TGI&rsquo;s API Docs</a> or in the code.
I passed the following inputs, which includes examples for Few-shot, and the model started to output not only the answer but also the next question, so I specified the stop param.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#ff79c6">%</span>time
</span></span><span style="display:flex;"><span>outputs <span style="color:#ff79c6">=</span> predictor<span style="color:#ff79c6">.</span>predict({
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;inputs&#34;</span>: <span style="color:#f1fa8c">&#34;Q: 世界で1番目に高い山は？ A: エベレスト</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">Q: 日本で1番目に高い山は？ A: 富士山</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">Q: 日本で2番目に高い山は？ A: &#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;parameters&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;stop&#34;</span>: [<span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>],
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;details&#34;</span>: <span style="color:#ff79c6">True</span>,
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>})
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(outputs)
</span></span></code></pre></div><p>When I ran this, both models returned the result in 5-6 µs. Btw, the correct answer is 北岳.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-js" data-lang="js"><span style="display:flex;"><span><span style="color:#6272a4">// open-calm-7b 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>[
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#39;generated_text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;Q: 世界で1番目に高い山は？ A: エベレスト\nQ: 日本で1番目に高い山は？ A: 富士山\nQ: 日本で2番目に高い山は？ A: 槍ヶ岳\n&#39;</span>, 
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#39;details&#39;</span><span style="color:#ff79c6">:</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;finish_reason&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;stop_sequence&#39;</span>, 
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;generated_tokens&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">3</span>, 
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;seed&#39;</span><span style="color:#ff79c6">:</span> None, 
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;prefill&#39;</span><span style="color:#ff79c6">:</span> [], 
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;tokens&#39;</span><span style="color:#ff79c6">:</span> [
</span></span><span style="display:flex;"><span>        {<span style="color:#f1fa8c">&#39;id&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">19597</span>, <span style="color:#f1fa8c">&#39;text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;槍&#39;</span>, <span style="color:#f1fa8c">&#39;logprob&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">0.59814453</span>, <span style="color:#f1fa8c">&#39;special&#39;</span><span style="color:#ff79c6">:</span> False}, 
</span></span><span style="display:flex;"><span>        {<span style="color:#f1fa8c">&#39;id&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">25157</span>, <span style="color:#f1fa8c">&#39;text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;ヶ岳&#39;</span>, <span style="color:#f1fa8c">&#39;logprob&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">0.11425781</span>, <span style="color:#f1fa8c">&#39;special&#39;</span><span style="color:#ff79c6">:</span> False}, 
</span></span><span style="display:flex;"><span>        {<span style="color:#f1fa8c">&#39;id&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">186</span>, <span style="color:#f1fa8c">&#39;text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;\n&#39;</span>, <span style="color:#f1fa8c">&#39;logprob&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">0.19836426</span>, <span style="color:#f1fa8c">&#39;special&#39;</span><span style="color:#ff79c6">:</span> False}
</span></span><span style="display:flex;"><span>      ]
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span><span style="color:#6272a4">// ELYZA-japanese-Llama-2-7b    
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>[
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#39;generated_text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;Q: 世界で1番目に高い山は？ A: エベレスト\nQ: 日本で1番目に高い山は？ A: 富士山\nQ: 日本で2番目に高い山は？ A: 北岳\n&#39;</span>, 
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#39;details&#39;</span><span style="color:#ff79c6">:</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;finish_reason&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;stop_sequence&#39;</span>, 
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;generated_tokens&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">5</span>, 
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;seed&#39;</span><span style="color:#ff79c6">:</span> None, 
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;prefill&#39;</span><span style="color:#ff79c6">:</span> [], 
</span></span><span style="display:flex;"><span>      <span style="color:#f1fa8c">&#39;tokens&#39;</span><span style="color:#ff79c6">:</span> [
</span></span><span style="display:flex;"><span>        {<span style="color:#f1fa8c">&#39;id&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">30662</span>, <span style="color:#f1fa8c">&#39;text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;北&#39;</span>, <span style="color:#f1fa8c">&#39;logprob&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">1.6376953</span>, <span style="color:#f1fa8c">&#39;special&#39;</span><span style="color:#ff79c6">:</span> False}, 
</span></span><span style="display:flex;"><span>        {<span style="color:#f1fa8c">&#39;id&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">232</span>, <span style="color:#f1fa8c">&#39;text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;&#39;</span>, <span style="color:#f1fa8c">&#39;logprob&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">0.60302734</span>, <span style="color:#f1fa8c">&#39;special&#39;</span><span style="color:#ff79c6">:</span> False}, 
</span></span><span style="display:flex;"><span>        {<span style="color:#f1fa8c">&#39;id&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">181</span>, <span style="color:#f1fa8c">&#39;text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;&#39;</span>, <span style="color:#f1fa8c">&#39;logprob&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">0.011375427</span>, <span style="color:#f1fa8c">&#39;special&#39;</span><span style="color:#ff79c6">:</span> False}, 
</span></span><span style="display:flex;"><span>        {<span style="color:#f1fa8c">&#39;id&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">182</span>, <span style="color:#f1fa8c">&#39;text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;岳&#39;</span>, <span style="color:#f1fa8c">&#39;logprob&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">0.0010786057</span>, <span style="color:#f1fa8c">&#39;special&#39;</span><span style="color:#ff79c6">:</span> False}, 
</span></span><span style="display:flex;"><span>        {<span style="color:#f1fa8c">&#39;id&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#bd93f9">13</span>, <span style="color:#f1fa8c">&#39;text&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#f1fa8c">&#39;\n&#39;</span>, <span style="color:#f1fa8c">&#39;logprob&#39;</span><span style="color:#ff79c6">:</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">0.40161133</span>, <span style="color:#f1fa8c">&#39;special&#39;</span><span style="color:#ff79c6">:</span> False}
</span></span><span style="display:flex;"><span>      ]
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p><a href="https://github.com/huggingface/text-generation-inference/blob/033230ae667101d2d8d8bcd4952442fa348ef951/clients/python/text_generation/types.py#L23">temperature</a> is a parameter dividing logits that will be passed to softmax function e(x_i)/sum(e(x)),
and if it&rsquo;s less than 1, the difference between the probabilities of tokens will be exponentially wider, and if it&rsquo;s greater than 1, it will be narrower.
This can be used to adjust the diversity of generated sentences.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#ff79c6">//</span> <span style="color:#8be9fd;font-style:italic">open</span><span style="color:#ff79c6">-</span>calm<span style="color:#ff79c6">-</span><span style="color:#bd93f9">7</span>b 
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(predictor<span style="color:#ff79c6">.</span>predict({
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#34;inputs&#34;</span>: <span style="color:#f1fa8c">&#34;今日はとっても楽しかったね。明日は&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#34;parameters&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0.1</span>,
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>})) <span style="color:#6272a4"># [{&#39;generated_text&#39;: &#39;今日はとっても楽しかったね。明日は、お別れ遠足。お天気が心配だけど、元気に幼稚園に来てね。&#39;}]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(predictor<span style="color:#ff79c6">.</span>predict({
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#34;inputs&#34;</span>: <span style="color:#f1fa8c">&#34;今日はとっても楽しかったね。明日は&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#34;parameters&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">5</span>,
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>})) <span style="color:#6272a4"># [{&#39;generated_text&#39;: &#39;今日はとっても楽しかったね。明日はフレッシュ東京五輪to暖かく酸素軍第たどり着椅濃厚と言え年度が成立料金MMako始まってませたあなたも共催その間に&#39;}]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">//</span> ELYZA<span style="color:#ff79c6">-</span>japanese<span style="color:#ff79c6">-</span>Llama<span style="color:#ff79c6">-</span><span style="color:#bd93f9">2</span><span style="color:#ff79c6">-</span><span style="color:#bd93f9">7</span>b
</span></span><span style="display:flex;"><span>[{<span style="color:#f1fa8c">&#39;generated_text&#39;</span>: <span style="color:#f1fa8c">&#39;今日はとっても楽しかったね。明日はお休みだから、ゆっくり休んでね。&#39;</span>}]
</span></span><span style="display:flex;"><span>[{<span style="color:#f1fa8c">&#39;generated_text&#39;</span>: <span style="color:#f1fa8c">&#39;今日はとっても楽しかったね。明日はoccup episodes and Köm x Linux social Јplaightkehr Национальistent chang rect ils spot Point計&#39;</span>}]
</span></span></code></pre></div><p>Clean up.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>predictor<span style="color:#ff79c6">.</span>delete_model()
</span></span><span style="display:flex;"><span>predictor<span style="color:#ff79c6">.</span>delete_endpoint()
</span></span></code></pre></div><h2 id="references">References</h2>
<p><a href="https://hackernoon.com/softmax-temperature-and-prediction-diversity">Softmax Temperature and Prediction Diversity  | HackerNoon</a></p>

    </div>
  </article>
</div>

</div>
</body>

</html>