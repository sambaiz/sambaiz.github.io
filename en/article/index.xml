<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Articles on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/article/</link>
    <description>Recent content in Articles on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Thu, 09 Jun 2022 20:05:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/en/article/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Characteristics of Metrics and Events in New Relic and queries in NRQL</title>
      <link>https://www.sambaiz.net/en/article/408/</link>
      <pubDate>Thu, 09 Jun 2022 20:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/408/</guid>
      <description>New Relic categorizes telemetry data into Metrics, Events, Logs and Traces, called MELT. Sent data can be queried in NRQL, standard SQL-like queries, shown on a dashboard, and targeted as alert conditions, but sometimes desired data can&amp;rsquo;t be obtained depending on the data type. Metrics Periodically aggregated and sent data. Having aggregated data, the transfer cost can be reduced and track the long-term trend, but there is a trade-off that</description>
    </item>
    
    <item>
      <title>Maximum flow and minimum cut problem, Ford–Fulkerson algorithm</title>
      <link>https://www.sambaiz.net/en/article/407/</link>
      <pubDate>Sun, 05 Jun 2022 18:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/407/</guid>
      <description>Maximum flow problem Maximum flow promlem is a problem that maximizes the flow from the source to the sink in the network consisting of paths with capacity. There are contraints such as capacity, equivalency of input and output amount for each nodes, and all of the data emitted from the source must be sent to the sink. Minimum cut problem Minimum cut problem is a problem that minimizes capacity of</description>
    </item>
    
    <item>
      <title>Calculate partial sum with Segment Tree or Bineary Indexed Tree (BIT)</title>
      <link>https://www.sambaiz.net/en/article/406/</link>
      <pubDate>Sun, 29 May 2022 19:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/406/</guid>
      <description>Segment Tree Segment Tree is a complete binary tree which can calculate partial sum at O(log n) by having the calculation results in each partials as node. In the following example, the calculated value is sum, but if it is the minimum value, Range Minimum Query (RMQ) can be solved and if it is the sorted list, merge sort is processed. When updating the value, recalculate in order from the</description>
    </item>
    
    <item>
      <title>Settings for querying tables of other accounts with Athena</title>
      <link>https://www.sambaiz.net/en/article/405/</link>
      <pubDate>Tue, 17 May 2022 23:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/405/</guid>
      <description>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net First, make it possible to access resources and Glue Data Catalog of the Owner Account from the Borrower Account which executes queries. There are some ways to access resources of other accounts, such as Owner Account&amp;rsquo;s user credentials or AssumeRole, but in this case, the role used to execute queries also needs the Athena permission</description>
    </item>
    
    <item>
      <title>How faster is sending/receiving values by UNIX domain socket than starting new processes when executing commands</title>
      <link>https://www.sambaiz.net/en/article/404/</link>
      <pubDate>Fri, 06 May 2022 20:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/404/</guid>
      <description>For example when some procedures are written in different languages and they are repeatedly executed as different commands, overhead such as memory allocation occurs when creating a process. One of solutions to avoid this is to keep the process running and pass input/output value with interprocess communication. In this article I make a command in Go and benchmark to see how much the throughput differs.
For speedy interprocess communication on UNIX, besides shared memory, pipes and UNIX domain sockets are used.</description>
    </item>
    
    <item>
      <title>Make asking about codes and debugging efficient with New Relic CodeStream</title>
      <link>https://www.sambaiz.net/en/article/403/</link>
      <pubDate>Wed, 04 May 2022 22:43:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/403/</guid>
      <description>New Relic CodeStream is a plugin which is useful to ask about codes, create issue or PR and debug on IDE for IntelliJ, VSCode and so on. Install Install the plugin to IDE and set the integretion. Comment You can comment to code blocks to ask about it, or create an issue. If Slack integration is set, following post is submited. By Open in IDE button, you can jump to</description>
    </item>
    
    <item>
      <title>Implement Athena&#39;s data source connectors and user defined functions (UDF)</title>
      <link>https://www.sambaiz.net/en/article/402/</link>
      <pubDate>Sat, 23 Apr 2022 18:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/402/</guid>
      <description>Athena has a feature called Federate Query that can access data sources other than S3 using Lambda as a connector, and the official repository provides connectors for various data sources such as BigQuery and Snowflake, but you can also implement your own. This article, implement the minimum connector while referring to Example Connector and run it. The full codes has been pushed to GitHub.
Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net</description>
    </item>
    
    <item>
      <title>About newrelic-lambda-extension and how it works telemetry without CloudWatch Logs</title>
      <link>https://www.sambaiz.net/en/article/401/</link>
      <pubDate>Fri, 08 Apr 2022 12:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/401/</guid>
      <description>Theare are two methods to send Lambda logs to New Relic. First is a conventional method that uses a Lambda function aws-log-ingestion to subscribe and transfer CloudWatch Logs, and second is a method that uses a Lambda layer newrelic-lambda-extension. The latter send trace logs etc. without outputting to CloudWatch Logs so it can minimize the cost. Install Doing newrelic-lambda integrations install, Secret containing API Key Layer refers is deployed. $</description>
    </item>
    
    <item>
      <title>Query resources with NerdGraph, New Relic&#39;s GraphQL API</title>
      <link>https://www.sambaiz.net/en/article/400/</link>
      <pubDate>Fri, 01 Apr 2022 22:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/400/</guid>
      <description>NerdGraph is New Relic&amp;rsquo;s GraphQL API and it can be used for querying resources or migrating it.
curl -X POST https://api.newrelic.com/graphql \ -H &amp;#39;Content-Type: application/json&amp;#39; \ -H &amp;#39;API-Key: *****&amp;#39; \ -d &amp;#39;{ &amp;#34;query&amp;#34;: &amp;#34;{ requestContext { userId apiKey } actor { user { name } } }&amp;#34; }&amp;#39; | jq { &amp;#34;data&amp;#34;: { &amp;#34;actor&amp;#34;: { &amp;#34;user&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;Taiki Sakamoto&amp;#34; } }, &amp;#34;requestContext&amp;#34;: { &amp;#34;apiKey&amp;#34;: &amp;#34;*****&amp;#34;, &amp;#34;userId&amp;#34;: &amp;#34;*****&amp;#34; } } } If select resources in GraphiQL explorer, the query is generated.</description>
    </item>
    
    <item>
      <title>Monitor infrastructure and applications with New Relic</title>
      <link>https://www.sambaiz.net/en/article/399/</link>
      <pubDate>Wed, 30 Mar 2022 19:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/399/</guid>
      <description>New Relic is a SaaS that monitors infrastructure and applications, and there is Datadog as a similar service. It seems that the pricing plans were changed drastically in 2020, and it charges according to the transfer volume and the number of admin users. Therefore compared to Datadog, which charges for hosts and additional features, there is an advantage when managing a large number of instances with a small number of</description>
    </item>
    
    <item>
      <title>Performance comparison between Redshift Serverless and Athena using TPC-DS queries</title>
      <link>https://www.sambaiz.net/en/article/397/</link>
      <pubDate>Sun, 20 Feb 2022 01:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/397/</guid>
      <description>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net
Compare the performance between Redshift Serverless and Athena by queries of TPC-DS, which is a database benchmark.
Generate data with TPC-DS Connector for Glue - sambaiz-net
First, execute the following query to the json and parquet data.
select /* TPC-DS query96.tpl 0.1 */ count(*) from store_sales ,household_demographics ,time_dim, store where ss_sold_time_sk = time_dim.t_time_sk and ss_hdemo_sk = household_demographics.</description>
    </item>
    
    <item>
      <title>Generate data with TPC-DS Connector for Glue</title>
      <link>https://www.sambaiz.net/en/article/393/</link>
      <pubDate>Tue, 18 Jan 2022 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/393/</guid>
      <description>Previously, I tried to generate 250GB of data with Athena&amp;rsquo;s TPC-DS Connector and output it to S3 but it timed out even if I increased the Lambda resource to the maximum, so I do it with Glue this time.
Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net
Subscribe and activate TPC-DS connector for Glue.
 Write a script like following. The scale is in GB, the same as Athena&amp;rsquo;s one.</description>
    </item>
    
    <item>
      <title>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog</title>
      <link>https://www.sambaiz.net/en/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/392/</guid>
      <description>Redshift Serverless Redshift Serverless is a new feature which can use Redshift, a petabyte-scale DWH without launching an instance, announced at this year&amp;rsquo;s re:Invent. It is available existing features such as Redshift Spectrum, refer to S3 directly, Federated Query to RDS, and Redshift ML. I&amp;rsquo;m happy with this update as it is costly to keep the instance running for occasional usage such as analytics. The cost is charged for at</description>
    </item>
    
    <item>
      <title>Generate data with TPC-DS Connector in Athena&#39;s Federated Query</title>
      <link>https://www.sambaiz.net/en/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/391/</guid>
      <description>Athena&amp;rsquo;s Federated Query is a feature to execute queries on non-S3 data sources such as DynamoDB and RDS through Lambda function which is a data sources connector. Implement Athena&amp;rsquo;s data source connectors and user defined functions (UDF) - sambaiz-net This article uses TPC-DS Connector in the AWS official repository. It generates the data of TPC-DS, which is a database benchmark in Decision Support. Although it is in the official repository,</description>
    </item>
    
    <item>
      <title>Check if there is a cycle in the undirected graph by Union-Find Tree</title>
      <link>https://www.sambaiz.net/en/article/390/</link>
      <pubDate>Sun, 12 Dec 2021 16:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/390/</guid>
      <description>Union-Find Tree Union-Find Tree is a data structure having some disjoint sets and can do &amp;ldquo;Union&amp;rdquo; which merges two sets, and &amp;ldquo;Find&amp;rdquo; which checks if two elements are in the same set with amortized O(α(n)) (α(n) is an inverse Ackermann function and smaller than log(n)). &amp;ldquo;Union&amp;rdquo; connects the tree with the smaller rank to under side so that merged tree</description>
    </item>
    
    <item>
      <title>Flutter&#39;s Navigator and AuroRoute</title>
      <link>https://www.sambaiz.net/en/article/389/</link>
      <pubDate>Sat, 11 Dec 2021 16:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/389/</guid>
      <description>Navigator Flutter&amp;rsquo;s Navigator is a screen transition class by stacking Routes and has APIs such as push() and pop().
 import &amp;#39;package:flutter/material.dart&amp;#39;; void main() { runApp(const MyApp()); } class MyApp extends StatelessWidget { const MyApp({Key? key}) : super(key: key); @override Widget build(BuildContext context) { return MaterialApp( title: &amp;#39;Navigation Test&amp;#39;, theme: ThemeData( primarySwatch: Colors.blue, ), home: const Page1(), ); } } class Page1 extends StatelessWidget { const Page1({Key? key}) : super(key: key); @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: const Text(&amp;#34;page1&amp;#34;), ), body: ListView.</description>
    </item>
    
    <item>
      <title>Build iOS/Android/Web App by Flutter</title>
      <link>https://www.sambaiz.net/en/article/388/</link>
      <pubDate>Sun, 05 Dec 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/388/</guid>
      <description>Flutter is a cross-platform framework by Google. In addition to iOS/Android, Web became stable in version 2.0 which is released in March of this year, and Windows/Mac/Linux is beta. Unlike React Native which uses native UI, Flutter uses its own UI. In addition to Material, iOS-style Cupertino is also available, but unless it branches etc., it become the same looks regardless of the platform.
Build the environment Build the environment according to the official Get started.</description>
    </item>
    
    <item>
      <title>Implement Rabin–Karp algorithm in C&#43;&#43;</title>
      <link>https://www.sambaiz.net/en/article/387/</link>
      <pubDate>Sat, 04 Dec 2021 22:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/387/</guid>
      <description>Rabin–Karp algorithm is a string-searching algorithm using rolling hash. Rolling hash can be made with O(1) by removing a first element from the previous hash and adding a next element to it. There are various hash functions which can do it, but for example, when simply summing up character codes, the hashes will collide just because the same character is contained,</description>
    </item>
    
    <item>
      <title>Columnar format Parquet structure and Read optimization</title>
      <link>https://www.sambaiz.net/en/article/386/</link>
      <pubDate>Fri, 03 Dec 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/386/</guid>
      <description>Parquet is a columnar format mainly used in the Hadoop ecosystem. Compared to row-based formats like CSV, unnecessary data is not read so queries can be executed efficiently.
Structure Data is horizontally partitioned to some Row Groups. A column is splitted into some Column Chunks, and a Column Chunk has some Pages which is an unit of compressing and encoding.
File structure is like following and it contains some Row Groups which have Column Chunks of each columns and metadata.</description>
    </item>
    
    <item>
      <title>struct and class in C&#43;&#43;</title>
      <link>https://www.sambaiz.net/en/article/385/</link>
      <pubDate>Tue, 30 Nov 2021 18:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/385/</guid>
      <description>class and struct in C++ are functionally equivalent but class is private by default as opposed to struct being public. class is used for encapsulation and if it has public fields and few methods, it seems that struct is used generally. #include &amp;lt;iostream&amp;gt;using namespace std; class C { int value; public: C(int value) { this-&amp;gt;value = value; } int func() { return value; }; }; struct S { S(int value)</description>
    </item>
    
    <item>
      <title>Treat Spark struct as map to expand to multiple rows with explode</title>
      <link>https://www.sambaiz.net/en/article/384/</link>
      <pubDate>Wed, 13 Oct 2021 02:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/384/</guid>
      <description>When you read data without specifying schema in Spark, the schema is automatically determined from the input as follows. # {&amp;#34;aaa&amp;#34;:123,&amp;#34;ccc&amp;#34;:[123],&amp;#34;eee&amp;#34;:{&amp;#34;fff&amp;#34;:123},&amp;#34;hhh&amp;#34;:null} df = spark.read.json(&amp;#34;s3://hogefuga/testjson/&amp;#34;) df.printSchema() &amp;#39;&amp;#39;&amp;#39; root |-- aaa: long (nullable = true) |-- ccc: array (nullable = true) | |-- element: long (containsNull = true) |-- eee: struct (nullable = true) | |-- fff: long (nullable = true) |-- hhh: string (nullable = true) &amp;#39;&amp;#39;&amp;#39; This works well in</description>
    </item>
    
    <item>
      <title>Spark Web UI: Monitor Job Stages, Tasks distribution and SQL plan</title>
      <link>https://www.sambaiz.net/en/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/382/</guid>
      <description>Spark Web UI is a tool for monitoring Jobs and Executors. Get Dockerfile that runs Spark based on maven: 3.6-amazoncorretto-8 from aws-glue-samples, and start History Server with the path of EventLog output by Glue and authentication information to get it. $ git clone https://github.com/aws-samples/aws-glue-samples.git $ cd aws-glue-samples/utilities/Spark_UI/glue-3_0/ $ docker build -t glue/sparkui:latest . $ docker run -it -e SPARK_HISTORY_OPTS=&amp;#34;$SPARK_HISTORY_OPTS-Dspark.history.fs.logDirectory=s3a://path_to_eventlog -Dspark.hadoop.fs.s3a.access.key=$AWS_ACCESS_KEY_ID-Dspark.hadoop.fs.s3a.secret.key=$AWS_SECRET_ACCESS_KEY&amp;#34; -p 18080:18080 glue/sparkui:latest &amp;#34;/opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer&amp;#34; Now, you can access http://localhost:18080</description>
    </item>
    
    <item>
      <title>Enable Job Bookmark of AWS Glue to process from the records following ones executed previously</title>
      <link>https://www.sambaiz.net/en/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/333/</guid>
      <description>Job Bookmark of AWS Glue is a feature that saves what records are processed, and prevent it from being executed next time. Parquet and ORC, which were not supported before 1.0, are now supported. AWS GlueでCSVを加工しParquetに変換してパーティションを切りA</description>
    </item>
    
    <item>
      <title>Python with structural subtyping by Protocol</title>
      <link>https://www.sambaiz.net/en/article/325/</link>
      <pubDate>Fri, 12 Feb 2021 02:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/325/</guid>
      <description>In Python that has no interface syntax, it can assure that the function can be called by checking the function existance with hasattr(). However, this method needs to insert asserting each time and the error cannot be known until runtime. class ImplClass(): def foo(self): print(&amp;#34;ok&amp;#34;) class NoImplClass(): pass def call(d): assert hasattr(d, &amp;#39;foo&amp;#39;) d.foo() if __name__ == &amp;#34;__main__&amp;#34;: call(ImplClass()) # =&amp;gt; ok call(NoImplClass()) # =&amp;gt; AssertionError If you describe Type</description>
    </item>
    
    <item>
      <title>What is Apache Spark, RDD, DataFrame, DataSet, Action and Transformation</title>
      <link>https://www.sambaiz.net/en/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/208/</guid>
      <description>What is Spark? Spark is high-performance general-purpose distributed processing system. It is used with distributed storage such as HDFS and S3, and cluster managers such as Hadoop YARN. It can be processed faster than Hadoop&amp;rsquo;s MapReduce by storing the intermediate data in memory. There are APIs for Java, Scala, Python, R. While python is easy to write, performance suffers due to interaction with JVM. HDFS(Hadoop Distributed File Sys</description>
    </item>
    
    <item>
      <title>Increase the maximum number of file descriptors</title>
      <link>https://www.sambaiz.net/en/article/41/</link>
      <pubDate>Thu, 08 Dec 2016 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/en/article/41/</guid>
      <description>What is file descriptors? File desecriptors is an identifier for interacting with an outside of a process. In POSIX, it is an int type, 0 is stdin, 1 is stdout, and 2 is stderr. It is assigned by a system call such as open() to open files and devices, and socket() to create sockets to communicate with other processes. Maximum number of file descriptors There is a limit on the</description>
    </item>
    
  </channel>
</rss>
