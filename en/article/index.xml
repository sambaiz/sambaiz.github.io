<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Articles on sambaiz-net</title>
    <link>https://www.sambaiz.net/en/article/</link>
    <description>Recent content in Articles on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Wed, 13 Mar 2024 23:32:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/en/article/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Create a CloudFront Distribution with ALB and S3 as origins using CDK</title>
      <link>https://www.sambaiz.net/en/article/474/</link>
      <pubDate>Wed, 13 Mar 2024 23:32:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/474/</guid>
      <description>Amazon CloudFront is a CDN service, and it can improve latency and reduce the load on the origin by caching responses on edge servers. The main use case is distributing static files from origins such as S3, but it is also possible to return dynamic responses by placing it in front of ALB etc. In that case, the cache needs to be disabled, so the number of requests to the origin won&amp;rsquo;t be reduced, but the load will be reduced somewhat as connections can be reused.</description>
    </item>
    <item>
      <title>What do etcd, a distributed KVS with Raft, a consensus algorithm choose in the CAP/PACELC Theorem</title>
      <link>https://www.sambaiz.net/en/article/473/</link>
      <pubDate>Mon, 11 Mar 2024 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/473/</guid>
      <description>etcd is a distributed KVS that is also used in Kubernetes. Raspberry PiでおうちKubernetesクラスタを構築する - sambaiz-net Kubernetes docs say that etcd is a consistent and highly-available key value store, and so I wondered it compromises partition tolerance (P) in the CAP theorem. However, it feels difficult to</description>
    </item>
    <item>
      <title>Try logrotate sidecar in Kubernetes</title>
      <link>https://www.sambaiz.net/en/article/472/</link>
      <pubDate>Thu, 07 Mar 2024 01:05:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/472/</guid>
      <description>Develop an application outputting logs, package main import ( &amp;#34;os&amp;#34; &amp;#34;time&amp;#34; &amp;#34;github.com/sirupsen/logrus&amp;#34; ) func main() { logFile, err := os.OpenFile(&amp;#34;/var/log/app/test.log&amp;#34;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil { logrus.Fatal(&amp;#34;failed to open file&amp;#34;, err) } logrus.SetOutput(logFile) i := 0 ticker := time.NewTicker(1 * time.Millisecond) for { &amp;lt;-ticker.C logrus.Print(i) i++ } } create image logrotate installed, $ cat Dockerfile_logrotate FROM alpine:latest RUN apk add --no-cache logrotate # RUN echo &amp;#39;/usr/sbin/logrotate /etc/logrotate.d/logrotate.conf&amp;#39; &amp;gt; /etc/periodic/daily/logrotate</description>
    </item>
    <item>
      <title>Install AWS Load Balancer Controller on EKS cluster with CDK and set up ALB Ingress</title>
      <link>https://www.sambaiz.net/en/article/471/</link>
      <pubDate>Mon, 26 Feb 2024 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/471/</guid>
      <description>AWS Load Balancer Controller is a controller that creates and manages ELBs for Kubernetes resources. It can be installed with a service account granted the required policies and Helm Chart. const role = new iam.Role(scope, &amp;#39;LoadBalancerServiceAccountRole&amp;#39;, { assumedBy: new iam.WebIdentityPrincipal( cluster.openIdConnectProvider.openIdConnectProviderArn, { StringEquals: new cdk.CfnJson( scope, &amp;#39;LoadBalancerServiceAccountRoleStringEquals&amp;#39;, { value: { [`${cluster.clusterOpenIdConnectIssuer}:aud`]: &amp;#39;sts.amazonaws.com&amp;#39;, [`${cluster.clusterOpenIdConnectIssuer}:sub`]: &amp;#39;system:serviceaccount:kube-system:aws-load-balancer-controller&amp;#39;, }, } ), } ), inlinePolicies: { &amp;#39;loadbalancercontroller&amp;#39;: iam.PolicyDocument.fromJson({ &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;,</description>
    </item>
    <item>
      <title>Live reload Go application running on local K8s using air and remote debug using delve from VSCode</title>
      <link>https://www.sambaiz.net/en/article/470/</link>
      <pubDate>Wed, 21 Feb 2024 19:41:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/470/</guid>
      <description>Live reload using air air is a tool that performs live reload for Go applications. $ go install github.com/cosmtrek/air@latest air init makes a settings file. $ air init $ cat .air.toml root = &amp;#34;.&amp;#34; tmp_dir = &amp;#34;tmp&amp;#34; [build] args_bin = [] bin = &amp;#34;./tmp/main&amp;#34; cmd = &amp;#34;go build -o ./tmp/main .&amp;#34; delay = 1000 ... For server code as follows, package main import ( &amp;#34;context&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;os/signal&amp;#34; &amp;#34;syscall&amp;#34; )</description>
    </item>
    <item>
      <title>Describe resources required only in the environment with Kustomize Component</title>
      <link>https://www.sambaiz.net/en/article/469/</link>
      <pubDate>Thu, 15 Feb 2024 09:41:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/469/</guid>
      <description>I tried to run a DB only in the local environment with Kustomize, but an error occurred as follows. kustomizeでkubernetesのmanifestを環境ごとに生成する - sambaiz-net $ tree manifest manifest ├── base │ ├</description>
    </item>
    <item>
      <title>Call AWS API with AwsCustomResource in CDK</title>
      <link>https://www.sambaiz.net/en/article/468/</link>
      <pubDate>Tue, 30 Jan 2024 22:19:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/468/</guid>
      <description>When you need to pass values that can be obtained only after createing resources in CDK, you may want to call Describe API. Normally, to do someting like this that is not managed by CloudFormation, you need to prepare your own lambda function and create a CustomResource, but if you just want to call AWS APIs, you can use AwsCustomResource.&#xA;import * as cdk from &amp;#39;aws-cdk-lib&amp;#39;; import { Construct } from &amp;#39;constructs&amp;#39;; import * as ec2 from &amp;#39;aws-cdk-lib/aws-ec2&amp;#39;; import * as eks from &amp;#39;aws-cdk-lib/aws-eks&amp;#39;; import { KubectlV27Layer } from &amp;#39;@aws-cdk/lambda-layer-kubectl-v27&amp;#39;; export class CdkCallAwsApiTestStack extends cdk.</description>
    </item>
    <item>
      <title>See traffic denied by SG or Network ACL with VPC Flow Logs and CloudWatch Logs Insights</title>
      <link>https://www.sambaiz.net/en/article/467/</link>
      <pubDate>Mon, 22 Jan 2024 23:48:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/467/</guid>
      <description>There are security groups and network ACLs settings to allow or deny traffic within the VPC. In security groups, responses to requests allowed inbound are allowed regardless of the outbound settings, but network ACLs are stateless for each request and response.&#xA;Once traffic is denied by these settings, the action field in VPC Flow Logs becomes REJECT, so if you output it to CloudWatch Logs, you can see the number of rejections of specific enis for each src/dst by executing the following query with Insights.</description>
    </item>
    <item>
      <title>Install newrelic-bundle to EKS cluster with CDK and monitor it</title>
      <link>https://www.sambaiz.net/en/article/466/</link>
      <pubDate>Sat, 13 Jan 2024 21:07:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/466/</guid>
      <description>NewRelic Kubernetes Integration has various components, and nri-bundle Helm Chart bundles them. Proceeding with Guided install, the parameters to pass are generated, so I copied them to CDK. Looking at the chart, credentials can be passed as strings as it is or Secrets, so I imported them from SecretsManager with External Secrets. Install External Secrets Operator with CDK and make Secrets Manager data available as Kubernetes Secret - sambaiz-net const</description>
    </item>
    <item>
      <title>Install External Secrets Operator with CDK and make Secrets Manager data available as Kubernetes Secret</title>
      <link>https://www.sambaiz.net/en/article/465/</link>
      <pubDate>Thu, 11 Jan 2024 20:15:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/465/</guid>
      <description>External Secrets Operator (ESO) is an Operator that creates Kubernetes Secrets from secrets stored in external services, and is the successor to the deprecated Kubernetes External Secrets (KES). In this article, I install it with CDK and create a Secret that contains data from Secrets Manager. First, create an IAM Role to be granted to a ServiceAccount and install the operator with Helm Chart. const externalSecretsRole = new iam.Role(this, &amp;#39;ExternalSecretsRole&amp;#39;,</description>
    </item>
    <item>
      <title>Visualize the time spend on tasks on Google Calendar using Jira, Toggl, and Make</title>
      <link>https://www.sambaiz.net/en/article/464/</link>
      <pubDate>Thu, 11 Jan 2024 09:25:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/464/</guid>
      <description>I&amp;rsquo;ve used various services to manage my private tasks, and lately I&amp;rsquo;ve been using Jira. I had impression that Jira was difficult to use, but it seems that a next-generation project was released in 2018, and now it feels good.&#xA;If you record the time taken for a task using Jira alone, you need to enter it manually as shown below, but by installing a third-party Toggl Integration for Jira, you can use the Toggl&amp;rsquo;s start/stop button, and when you stop it, the measured time will be reflected in Jira.</description>
    </item>
    <item>
      <title>Improve slow code with cProfile and line_profile in Python</title>
      <link>https://www.sambaiz.net/en/article/463/</link>
      <pubDate>Wed, 03 Jan 2024 23:15:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/463/</guid>
      <description>I implemented heap sort in Python, but it was much slower than the one using built-in heapq.&#xA;class Heap: def __init__(self, values, compare): self.heap = values self.compare = compare for i in reversed(range(len(self.heap) // 2)): self.__down(i) def push(self, value): self.heap.append(value) self.__up(len(self.heap) - 1) def delete(self, idx): if idx &amp;gt;= len(self.heap): return self.heap[idx], self.heap[len(self.heap) - 1] = \ self.heap[len(self.heap) - 1], self.heap[idx] self.heap.pop() self.__down(idx) self.__up(idx) def pop(self): if len(self.heap) == 0: return None ret = self.</description>
    </item>
    <item>
      <title>git pull a private repository on docker build by mounting 1Password SSH agent</title>
      <link>https://www.sambaiz.net/en/article/462/</link>
      <pubDate>Wed, 27 Dec 2023 19:50:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/462/</guid>
      <description>When building a docker image, it may need to pull a private repository. Mounting a secret key as a secret works, but someone may be using an SSH agent such as 1Password&amp;rsquo;s one. Specifying the SSH agent&amp;rsquo;s socket or the key as &amp;ndash;ssh, Dockerfile doesn&amp;rsquo;t need to care about the difference. Buildkitとは - sambaiz-net SSH_AUTH_SOCK is referred by default. $ export</description>
    </item>
    <item>
      <title>Find bugs caused by unexpected input in Go with Fuzzing</title>
      <link>https://www.sambaiz.net/en/article/461/</link>
      <pubDate>Sun, 17 Dec 2023 13:24:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/461/</guid>
      <description>Fuzzing is a test method that uses random data as input, and is supported since Go 1.18.&#xA;Let&amp;rsquo;s test the following FizzBuzz function.&#xA;func FizzBuzz(n uint64) string { if n%3 == 0 { if n%5 == 0 { return &amp;#34;FizzBuzz&amp;#34; } return &amp;#34;Fizz&amp;#34; } if n%5 == 0 { return &amp;#34;Buzz&amp;#34; } return strconv.Itoa(int(n)) } First, we do a table-driven test.&#xA;func TestFizzBuzz(t *testing.T) { testcases := []struct { title string in uint64 out string }{ {&amp;#34;A multiple of 3 returns Fizz&amp;#34;, 3, &amp;#34;Fizz&amp;#34;}, {&amp;#34;A multiple of 5 returns Buzz&amp;#34;, 5, &amp;#34;Buzz&amp;#34;}, {&amp;#34;A multiple of 3 and 5 returns FizzBuzz&amp;#34;, 15, &amp;#34;FizzBuzz&amp;#34;}, {&amp;#34;Otherwise returns number string&amp;#34;, 1, &amp;#34;1&amp;#34;}, } for _, testcase := range testcases { t.</description>
    </item>
    <item>
      <title>IP address exhaustion with EKS cluster and migration to IPv6</title>
      <link>https://www.sambaiz.net/en/article/460/</link>
      <pubDate>Fri, 15 Dec 2023 01:02:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/460/</guid>
      <description>When I ran a large application on an EKS cluster, the subnet&amp;rsquo;s IP addresses ran out. Reason for IP address exhaustion Pod IP addresses are assigned by ipamd (IP Address Management Daemon) of VPC CNI, and these are from the instance&amp;rsquo;s secondary IP addresses. The number of secondary IP addresses are controlled with WARM_ENI_TARGET (Default: 1), which is the number of spare ENIs, or WARM_IP_TARGET (Default: None), which is the</description>
    </item>
    <item>
      <title>Setting security groups for EKS cluster&#39;s nodes created with CDK</title>
      <link>https://www.sambaiz.net/en/article/459/</link>
      <pubDate>Tue, 05 Dec 2023 20:59:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/459/</guid>
      <description>aws_eks.Cluster in CDK has a securityGroup field, but this is an SG associated with the ENI of the control plane, not the node. If it is not passed, it will be automatically created.&#xA;Then, where is the SG settings for EKS cluster&amp;rsquo;s nodes? It is in the node group&amp;rsquo;s auto scaling group.&#xA;When you create an EKS cluster with CDK and DefaultCapacityType is NODEGROUP, which is the default, manged node group is created, which consists of defaultCapacity nodes and EKS performs drain etc.</description>
    </item>
    <item>
      <title>Run AutoML jobs with no code using SageMaker Canvas Custom models</title>
      <link>https://www.sambaiz.net/en/article/458/</link>
      <pubDate>Thu, 16 Nov 2023 23:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/458/</guid>
      <description>SageMaker Canvas provides an interface for using pre-trained models provided by SageMaker JumpStart and a feature to run jobs of SageMaker Autopilot, an AutoML feature, with no code. Note that if you finish using SageMaker Canvas, you need to log out explicitly, or you will continue to be charged for the workspace instance. In this article, I try to run AutoML jobs with tutorial datasets, product descriptions and shipping logs.</description>
    </item>
    <item>
      <title>Create resources required for EC2 instance without public IPv4 but IPv6 address to communicate with the Internet</title>
      <link>https://www.sambaiz.net/en/article/457/</link>
      <pubDate>Mon, 06 Nov 2023 09:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/457/</guid>
      <description>Public IPv4 addresses will start being charged like EIPs soon, so I would like to migrate them to IPv6 recently. In this article, I construct an IPv6 environment with CDK and check the resources required to communicate with the Internet and the behavior.&#xA;(PS: 2024-01-29) In v2.122.0, ipProtocol: ec2.IpProtocol.DUAL_STACK was added to ec2.Vpc, which creates resources for IPv6 automatically.&#xA;Create a VPC IPv6 block assigned to VPC is fixed length /56 and one assigned to subnets is also fixed length /64.</description>
    </item>
    <item>
      <title>Read container/heap package in Go</title>
      <link>https://www.sambaiz.net/en/article/456/</link>
      <pubDate>Sun, 05 Nov 2023 21:48:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/456/</guid>
      <description>Go standard library has container/heap package which can be used to implement min/max heap and priority queue using this interface. It was implemented long time ago and there is a proposal to use Generics. C++ STLのContainersとAlgorithms - sambaiz-net type Interface interface { sort.Interface Push(x any) //</description>
    </item>
    <item>
      <title>Install Karpenter on an EKS cluster with CDK to auto-scale flexibility and quickly</title>
      <link>https://www.sambaiz.net/en/article/455/</link>
      <pubDate>Fri, 13 Oct 2023 20:35:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/455/</guid>
      <description>Karpenter is an OSS that scales a Kubernetes cluster developed by AWS. Compared to Cluster Autoscaler, it can perform fast and flexible provisioning not through Auto Scaling Group. It supports only EKS so far, but it seems to have possibility to support other cloud providers.&#xA;(PS: 2023-12-06) now available on AKS&#xA;In this article, I install Karpenter on an EKS cluster with CDK, and confirm the cluster to be auto-scaled when the number of replicas is changed.</description>
    </item>
    <item>
      <title>Passing command line arguments to functions and methods with python-fire</title>
      <link>https://www.sambaiz.net/en/article/454/</link>
      <pubDate>Tue, 26 Sep 2023 09:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/454/</guid>
      <description>python-fire is a library to create CLI tools from Python objects.&#xA;$ pip install fire Just wrap with fire.Fire() to pass command line arguments to functions and methods.&#xA;$ cat main.py import fire class FizzBuzz: def fizzbuzz(self, num): ret = &amp;#34;&amp;#34; if num % 3 == 0: ret += &amp;#34;fizz&amp;#34; if num % 5 == 0: ret += &amp;#34;buzz&amp;#34; if len(ret) != 0: return ret return str(num) def fizzbuzzs(self, nums): return [self.</description>
    </item>
    <item>
      <title>Content scripts and Service workers in Chrome extension</title>
      <link>https://www.sambaiz.net/en/article/453/</link>
      <pubDate>Mon, 18 Sep 2023 22:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/453/</guid>
      <description>Content scripts Content scripts are scripts that run in the context of web pages and are mainly used for DOM operations. CSS and JS are inserted into pages that match the matches field of the content_scripts field in the Manifest. Insertion timing is before DOM construction for CSS and can be specified by run_at field for JS. Default is document_idle, so it is guaranteed to be inserted after window.onload. $</description>
    </item>
    <item>
      <title>Fine-tuning OpenAI&#39;s GPT with Japanese Prime Minister&#39;s speech in the Diet</title>
      <link>https://www.sambaiz.net/en/article/452/</link>
      <pubDate>Mon, 11 Sep 2023 23:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/452/</guid>
      <description>OpenAI provides APIs to create conversation and convert text to vector, and also fine-tune models with your own dataset, which enables us to improve the quality of the output or save the cost of few-shot learning. # !pip install openai import openai import numpy as np response = openai.ChatCompletion.create( model=&amp;#34;gpt-3.5-turbo&amp;#34;, messages=[{ &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;, # &amp;#34;system&amp;#34;, &amp;#34;user&amp;#34;, or &amp;#34;assistant&amp;#34; &amp;#34;content&amp;#34;: &amp;#34;Is this a pen?&amp;#34; }], temperature=0.5, ) print(response.choices[0].message) &amp;#39;&amp;#39;&amp;#39; { &amp;#34;role&amp;#34;:</description>
    </item>
    <item>
      <title>Deploy Japanese LLMs in TGI Container with SageMaker&#39;s HuggingFaceModel and generate texts</title>
      <link>https://www.sambaiz.net/en/article/451/</link>
      <pubDate>Tue, 05 Sep 2023 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/451/</guid>
      <description>Recently, some Japanese LLMs have been released in Hugging Face, such as OpenCALM-7B by CyberAgent and ELYZA-japanese-Llama-2-7b by ELYZA, spun-out from Matsuo Lab., University of Tokyo. SageMaker SDK has a HuggingFaceModel class, which can be used to deploy a model by specifying the model ID. Also, if you press the deploy button in Hugging Face, you can see the minimum code to run the model in SageMaker. get_huggingface_llm_image_uri() returns the</description>
    </item>
    <item>
      <title>Check how job parameters of SageMaker Batch Transform work from called functions in entrypoint and its arguments</title>
      <link>https://www.sambaiz.net/en/article/448/</link>
      <pubDate>Mon, 14 Aug 2023 18:16:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/448/</guid>
      <description>SageMaker Batch Transform is a feature that runs a one-time batch inference job. It calls the entrypoint function of the Model as in the case of inference endpoints. I check how job parameters work from the function and its arguments. SageMakerで学習したPyTorchのモデルをElas</description>
    </item>
    <item>
      <title>Solve an incompatible version conflict problem in Java by relocation and custom ClassLoader</title>
      <link>https://www.sambaiz.net/en/article/443/</link>
      <pubDate>Tue, 08 Aug 2023 22:44:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/443/</guid>
      <description>When your Java application occurs an incompatible version conflict problem, even if you build uber-jar, classes in the jar are not preferentially loaded but loaded by the classpath order. At that time, if there are incompatible classes, it will be in a state called JAR hell, and NoSuchMethodError or unintended behavior can occur at runtime. Say you have legacylib.jar containing guava 17.0 and modernlib.jar containing guava 32.1, and the former</description>
    </item>
    <item>
      <title>Cause and solution of timeout when ssh_connect() in libssh is executed with ssm-over-ssh as ProxyCommand</title>
      <link>https://www.sambaiz.net/en/article/450/</link>
      <pubDate>Sun, 30 Jul 2023 16:54:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/450/</guid>
      <description>When I connect to RDS in Private subnet, I found that Sequel Ace running in Sandbox Mode can&amp;rsquo;t do SSH tunneling with ssh-over-ssm as ProxyCommand, so I tried TablePlus introduced in this Issue, but it also failed.&#xA;SSH connection to EC2 instance through Session Manager with ssh-over-ssm - sambaiz-net&#xA;I enabled SSH Debug Log from Help, and found that libssh was used. So I tried executing ssh_connect() but it timed out after the connection.</description>
    </item>
    <item>
      <title>SSH connection to EC2 instance through Session Manager with ssh-over-ssm</title>
      <link>https://www.sambaiz.net/en/article/449/</link>
      <pubDate>Thu, 29 Jun 2023 07:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/449/</guid>
      <description>Session Manager can execute commands and port forwarding by itself. Besides, it also supports SSH connection with &amp;ndash;document-name AWS-StartSSHSession. The content of this document is sessionType Port same as AWS-StartPortForwardingSession, and SSM Agent establishes a TCP connection to the target port.&#xA;Deploy a container to ECS on Fargate, execute commands by ECS Exec, and perform port forwarding by Session Manager - sambaiz-net&#xA;This allows you to copy files with scp and use tools such as DB clients to perform SSH port forwarding.</description>
    </item>
    <item>
      <title>Create a cost-optimized real-time inference endpoint with SageMaker Inference Recommender</title>
      <link>https://www.sambaiz.net/en/article/447/</link>
      <pubDate>Thu, 15 Jun 2023 09:38:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/447/</guid>
      <description>SageMaker Inference Recommender is a feature to recommend endpoint&amp;rsquo;s instance types and settings. SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする - sambaiz-net I</description>
    </item>
    <item>
      <title>Preprocess data with SageMaker Processing, train model with Training and record the parameters and accuracy with Experiments</title>
      <link>https://www.sambaiz.net/en/article/442/</link>
      <pubDate>Thu, 04 May 2023 19:20:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/442/</guid>
      <description>SageMaker Experiments is a feature to record parameters and metrics of Processing and Training jobs etc. In this article, I track from preprocessing to learning as a Run in Experiments and confirm that multiple results can be compared. The full code is on GitHub. SageMaker Experiments experiments.Run() creates an Experiment if it hasn&amp;rsquo;t existed yet and starts a Run. Previously, it was a separate library called sagemaker-experiments, but now it</description>
    </item>
    <item>
      <title>Clustering by k-means method with MLlib of Spark</title>
      <link>https://www.sambaiz.net/en/article/446/</link>
      <pubDate>Sun, 09 Apr 2023 17:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/446/</guid>
      <description>Spark has MLlib which is a library for machine learning. This article, try clustering using Kmeans.&#xA;K-means is a clustering method that randomly assigns each data to one of a pre-determined number of clusters first, computes the center of each cluster, and then updates the cluster assignment of each data to the cluster whose center is closest, which repeats until convergence. Kmeans is implemented in k-means++ that converges faster, and its default distance measure is euclidean.</description>
    </item>
    <item>
      <title>Make EMR clusters&#39; scale-in faster with Task nodes</title>
      <link>https://www.sambaiz.net/en/article/445/</link>
      <pubDate>Sun, 19 Mar 2023 22:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/445/</guid>
      <description>EMR cluster consists of a Master (primary) node and Core nodes and Task nodes.&#xA;How Hadoop YARN allocates resources to applications and check how much resources are allocated - sambaiz-net&#xA;Resources of both core nodes and task nodes are used to run tasks, but core nodes are HDFS&amp;rsquo;s DataNode while task nodes aren&amp;rsquo;t. Therefore, core nodes need to be decommissioned and then terminated to prevent data loss, but replication bandwidth is limited to prevent spikes, so it takes time to scale in.</description>
    </item>
    <item>
      <title>Enable S3 versioning to retrieve accidentally overwritten or deleted objects</title>
      <link>https://www.sambaiz.net/en/article/444/</link>
      <pubDate>Wed, 15 Mar 2023 22:35:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/444/</guid>
      <description>Versioning is settings of S3 Bucket. When enabled, all PUT data will remain with the version ID, and on DELETE, a delete marker is put as the latest version without actually deleting. If you GET an object whose latest version is a delete marker, it returns Not found like when there is no object, but if you delete the delete marker version, you can get that object again.&#xA;If you delete an object with the version, the delete marker is not created.</description>
    </item>
    <item>
      <title>Expresses a strength of the correlation between a categorical variable and a objective variable with the correlation ratio</title>
      <link>https://www.sambaiz.net/en/article/441/</link>
      <pubDate>Thu, 09 Mar 2023 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/441/</guid>
      <description>Pearson&amp;rsquo;s Product-Moment Correlation coefficient, calculated from the covariance \(\mathrm{Cov}(x,y) = E[(x - \bar{x})(y - \bar{y})]\) and the standard deviation \(\sigma_x = \sqrt{E[(x-\bar{x})^2]}\), is usually used for expressing the correlation. $$ \rho_{xy} = \frac{\mathrm{Cov}(x,y)}{\sigma_x \sigma_y} $$ However, since this coefficient expresses linear correlation between quantitative variables, it cannot be used for categorical variables, which are qualitative variables. The correlation between a qualitative and a quantitative variable can be expressed as the</description>
    </item>
    <item>
      <title>Create über-jar containing dependent libraries with sbt-assembly</title>
      <link>https://www.sambaiz.net/en/article/440/</link>
      <pubDate>Sun, 05 Mar 2023 22:01:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/440/</guid>
      <description>sbt-assembly is a sbt plugin to create über-jar (fat-jar) containing dependent libraries.&#xA;$ cat peojcts/plugins.sbt addSbtPlugin(&amp;#34;com.eed3si9n&amp;#34; % &amp;#34;sbt-assembly&amp;#34; % &amp;#34;2.1.1&amp;#34;) $ sbt assembly $ java -jar ./target/scala-2.13/sbt-assembly-test-0.1.0-SNAPSHOT.jar Hello world! If multiple JARs, including the dependencies of the dependent library, contain files with the same path and the contents are different, &amp;ldquo;Deduplicate found different file contents&amp;rdquo; errors occur. In that case, set how to resolve it in assemblyMergeStrategy.&#xA;$ cat build.sbt .</description>
    </item>
    <item>
      <title>Implement AVL tree, self-balancing binary search tree, in Go and confirm that the height is kept minimum</title>
      <link>https://www.sambaiz.net/en/article/439/</link>
      <pubDate>Sat, 25 Feb 2023 00:54:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/439/</guid>
      <description>AVL tree is one of the self-balancing binary search trees, which is a kind of binary search tree, and by keeping the height to a minimum, the computational complexity for operations can be reduced. Each time the tree is changed, if there is a height difference of 2 or more between left and right trees, they are rebalanced with rotation. Another self-balancing binary search tree example is a red-black tree.</description>
    </item>
    <item>
      <title>Compare the speed of calling a shared library built in Go from Java with JNI and JNA</title>
      <link>https://www.sambaiz.net/en/article/437/</link>
      <pubDate>Sun, 29 Jan 2023 23:58:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/437/</guid>
      <description>JNI (Java Native Interface) is an interface to enable Java to call native codes in C/C++ executed outside JVM and enable native codes to call codes in Java. This makes it possible to speed up heavy processing and share processing across multiple platforms. JNA (Java Native Access), a library, is also available to call native codes from Java, and it is easier to use and makes effort to minimize the</description>
    </item>
    <item>
      <title>Benchmark Java codes with JMH</title>
      <link>https://www.sambaiz.net/en/article/435/</link>
      <pubDate>Sat, 28 Jan 2023 17:48:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/435/</guid>
      <description>JMH (Java Microbenchmark Harness) is a benchmark tool for JVM languages. If you execute small codes naively, the performance can be better than actual due to optimization such as JIT compile that is not performed in the real case that whole codes are large. JMH prevent the optimization from being applied, so it seems that it can benchmark accurately.&#xA;Create a project according to the README and try to run the benchmark.</description>
    </item>
    <item>
      <title>Python&#39;s built-in containers and collections.deque</title>
      <link>https://www.sambaiz.net/en/article/436/</link>
      <pubDate>Mon, 09 Jan 2023 16:32:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/436/</guid>
      <description>(C)Python has deque in the collections module in addition to build-in containers such as list, tuple, dict and set. $ python3 --version Python 3.10.7 list list is implemented with not linked-list but variable-length arrays. C++ STLのContainersとAlgorithms - sambaiz-net a = [&amp;#39;d&amp;#39;, &amp;#39;ae&amp;#39;, &amp;#39;ff&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;] print(a[2:-1])</description>
    </item>
    <item>
      <title>Launch an EKS cluster and register it to EMR on EKS with CDK to run Spark jobs</title>
      <link>https://www.sambaiz.net/en/article/434/</link>
      <pubDate>Mon, 02 Jan 2023 14:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/434/</guid>
      <description>EMR on EKS is a feature to run Spark on EKS. While normal EMR also manages Hadoop clusters, EMR on EKS is only responsible for starting containers. Launch an EMR cluster with AWS CLI and run Spark applications - sambaiz-net By running on Kubernetes, you can use tools and functions for Kubernetes to manage and monitor, and utilize resources left over if you have an existing cluster. It also enables</description>
    </item>
    <item>
      <title>The Scheduler which allocates resources in Hadoop YARN, and Dominant Resource Fairness (DRF)</title>
      <link>https://www.sambaiz.net/en/article/433/</link>
      <pubDate>Sat, 24 Dec 2022 22:15:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/433/</guid>
      <description>YARN&amp;rsquo;s ResourceManager consists of ApplicationsManager, which receives applications from clients and launches ApplicationMaster, and Scheduler, which receives requests from ApplicationMaster and allocates resources.&#xA;How Hadoop YARN allocates resources to applications and check how much resources are allocated - sambaiz-net&#xA;Scheduler Scheduler has implementations such as CapacityScheduler, which aims to maximize the throughput in multi-tenant clusters, and FairScheduler, which allocates fair resources to all applications. You can choose to use which one with yarn.</description>
    </item>
    <item>
      <title>Retry processing consisting of multiple Tasks with Callbacks in Airflow</title>
      <link>https://www.sambaiz.net/en/article/432/</link>
      <pubDate>Sun, 18 Dec 2022 17:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/432/</guid>
      <description>When processing a task in an EMR cluster, add a Step to the EMR cluster with EmrAddStepsOperator, and then wait for its execution to end with EmrStepSensor. When the Step fails, only the Sensor fails, so there is a problem that the Step is not re-executed even if it is retried.&#xA;Create an environment of Amazon Managed Workflow for Apache Airflow (MWAA) with CDK and run a workflow - sambaiz-net</description>
    </item>
    <item>
      <title>Check records of operations for AWS resources with CloudTrail</title>
      <link>https://www.sambaiz.net/en/article/431/</link>
      <pubDate>Tue, 06 Dec 2022 21:12:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/431/</guid>
      <description>AWS CloudTrail records AWS API call history, which is used for security auditing and other services such as GuardDuty.&#xA;Check security issues detected by GuardDuty, Inspector, and Macie, etc. in AWS Security Hub collectively - sambaiz-net&#xA;Event history Event history is recorded per region by default, which is free. The retention period is 90 days, and data events, such as Lambda&amp;rsquo;s invoke and object-level operations in S3, are not included.</description>
    </item>
    <item>
      <title>Check security issues detected by GuardDuty, Inspector, and Macie, etc. in AWS Security Hub collectively</title>
      <link>https://www.sambaiz.net/en/article/430/</link>
      <pubDate>Sun, 04 Dec 2022 10:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/430/</guid>
      <description>AWS Security Hub is a service that allows you to collectively check security issues detected by various services&#xA;Security standards Security Hub supports following security standards, and they are enabled, rules are added to AWS Config.&#xA;AWS Foundational Security Best Practices: Best practices for each service [ACM.1] Imported and ACM-issued certificates should be renewed after a specified time period [CloudFront.1] CloudFront distributions should have a default root object configured Center for Internet Security (CIS) AWS Foundations Benchmark: Meet the requirements for certification by the security standardized organization CIS established by the NSA, etc.</description>
    </item>
    <item>
      <title>Express dependencies on past tasks in Airflow</title>
      <link>https://www.sambaiz.net/en/article/429/</link>
      <pubDate>Wed, 30 Nov 2022 09:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/429/</guid>
      <description>If past aggregated values are required for periodic aggregation and such a workflow is simply executed periodically, subsequent processing will fail in a chain reaction when the processing fails or hasn&amp;rsquo;t been completed in time. Airflow allows you to describe dependencies on past tasks in the following way. This makes it possible to wait for the past aggregation to finish or to re-execute only dependent tasks collectively in the event of failure.</description>
    </item>
    <item>
      <title>Create an environment of Amazon Managed Workflow for Apache Airflow (MWAA) with CDK and run a workflow</title>
      <link>https://www.sambaiz.net/en/article/428/</link>
      <pubDate>Mon, 28 Nov 2022 19:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/428/</guid>
      <description>Amazon Managed Workflow for Apache Airflow (MWAA) is a managed service of Apache Airflow. Unlike Step Functions that is serverless, it costs per an instance hour, but Airflow&amp;rsquo;s abundant features and third-party&amp;rsquo;s, including AWS, providers packages are available. Run Apache Airflow with Docker Compose and execute a workflow - sambaiz-net Step Functions doesn&amp;rsquo;t support execution from the middle of the workflow currently, so retrying a very long workflow can be</description>
    </item>
    <item>
      <title>How Hadoop YARN allocates resources to applications and check how much resources are allocated</title>
      <link>https://www.sambaiz.net/en/article/427/</link>
      <pubDate>Wed, 23 Nov 2022 18:15:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/427/</guid>
      <description>YARN is a module that manages resources of a Hadoop cluster and schedules.&#xA;How Hadoop YARN allocates resources to applications Once ResourceManager (RM) receives an application from a client, it launches ApplicationMaster (AM) and passes information for executing the application. ApplicationMaster asks ResourceManager for allocating resources. After allocated, next it communicates with NodeManagers (NMs) running on each node, and then starts containers and runs the application.&#xA;The Scheduler which allocates resources in Hadoop YARN, and Dominant Resource Fairness (DRF) - sambaiz-net</description>
    </item>
    <item>
      <title>Pass AWS credentials to services for Docker Compose</title>
      <link>https://www.sambaiz.net/en/article/426/</link>
      <pubDate>Wed, 23 Nov 2022 15:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/426/</guid>
      <description>When you run a docker container locally, you can mount ~/.aws to pass AWS credentials, and similarly, you can do that with volumes in Docker Compose. Besides, there is also a secrets field. According to the document, it looks to depend on Swarm, but actually, it can run standalone. However, this is for development, and it seems to just bind the file.&#xA;version: &amp;#39;3&amp;#39; secrets: aws_creds: file: ~/.aws services: aws_cli: image: amazon/aws-cli:2.</description>
    </item>
    <item>
      <title>Run Apache Airflow with Docker Compose and execute a workflow</title>
      <link>https://www.sambaiz.net/en/article/425/</link>
      <pubDate>Sat, 19 Nov 2022 16:52:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/425/</guid>
      <description>Apache Airflow is an OSS that schedules workflows and visualize pipelines. It is scalable and has abundant features. Also, it can be extended with your own Operators in addition to third-party, such as AWS and Slack, providers packages existing in the repository.&#xA;Run Airflow Download docker-compose.yaml.&#xA;$ curl -LfO &amp;#39;https://airflow.apache.org/docs/apache-airflow/2.4.3/docker-compose.yaml&amp;#39; $ cat docker-compose.yaml ... x-airflow-common: &amp;amp;airflow-common image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.4.3} ... volumes: - ./dags:/opt/airflow/dags - ./logs:/opt/airflow/logs - ./plugins:/opt/airflow/plugins ... services: postgres: image: postgres:13 .</description>
    </item>
    <item>
      <title>Monitor AWS costs with New Relic</title>
      <link>https://www.sambaiz.net/en/article/424/</link>
      <pubDate>Sun, 13 Nov 2022 15:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/424/</guid>
      <description>Visualize Billing metrics There are Billing metrics in CloudWatch, so if you are sending all metrics in us-east-1 with Cloud Metric Streams, you can refer them with a query as follows.&#xA;SELECT max(`aws.billing.EstimatedCharges`) - min(`aws.billing.EstimatedCharges`) as daily_usage FROM Metric WHERE aws.Namespace = &amp;#39;AWS/Billing&amp;#39; AND `metricName` = &amp;#39;aws.billing.EstimatedCharges&amp;#39; AND `aws.billing.ServiceName` IS NOT NULL FACET monthOf(`timestamp`), `aws.billing.ServiceName` TIMESERIES 2 day SLIDE BY 1 day SINCE 4 week ago The values are accumulated monthly, so daily costs can be shown with taking differences from previous day&amp;rsquo;s one with Sliding window.</description>
    </item>
    <item>
      <title>Enumerated types and extending existing types in Scala 2/3</title>
      <link>https://www.sambaiz.net/en/article/423/</link>
      <pubDate>Sat, 12 Nov 2022 23:35:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/423/</guid>
      <description>Scala 2 Scala 2 doesn&amp;rsquo;t have an enum like Java, so Enumeration or case object are used. Besides, you can add fields to existing types by importing implicit class,&#xA;sealed trait Animal object Animal { case object Dog extends Animal case object Cat extends Animal } object Converter { implicit class AnimalConverter(animal: Animal) { def hello() = animal match { case Animal.Dog =&amp;gt; &amp;#34;wan!&amp;#34; case Animal.Cat =&amp;gt; &amp;#34;nya!&amp;#34; } } } import Converter.</description>
    </item>
    <item>
      <title>Monitor and optimize costs with AWS Cost Management</title>
      <link>https://www.sambaiz.net/en/article/422/</link>
      <pubDate>Thu, 10 Nov 2022 21:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/422/</guid>
      <description>AWS Cost Management is a feature group for monitoring, forecasting, and optimizing costs. Billing has similar features. Billing is for managing present costs whereas Cost Management seems to target future costs.&#xA;Cost Explorer Cost Explorer can show costs grouped and filtered by services and regions etc.&#xA;With filtering with Usage type filter, you can see costs for data transfer from ELB and EC2.&#xA;Budgets Budgets can notice that set budgets have been exceeded and report the usage with email etc.</description>
    </item>
    <item>
      <title>Create a role that can assume with OIDC from GitHub Actions with CDK</title>
      <link>https://www.sambaiz.net/en/article/421/</link>
      <pubDate>Sun, 30 Oct 2022 02:33:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/421/</guid>
      <description>aws-actions/configure-aws-credentials is an action that assumes a role, and it also supports authentication with an access key, but JWT issued by GitHub OIDC Provider enables to access to API securely without setting credential. OpenID ConnectのIDトークンの内容と検証 - sambaiz-net To trust the external provider, it is necessary to register the certificate thumbprint of</description>
    </item>
    <item>
      <title>Develop Spark Applications in Scala, deploy with GitHub Actions, and perform remote debugging on EMR</title>
      <link>https://www.sambaiz.net/en/article/420/</link>
      <pubDate>Fri, 21 Oct 2022 23:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/420/</guid>
      <description>Spark provides Java and Python APIs in addition to Scala, which is used for developing Spark itself. You can choose among them depending on the technical stack and technologies used in other components, etc.&#xA;While Python has highly compatible with data analysis and machine learning skill sets and easy to edit and run on Glue Studio, the error is hard to understand, and the performance also has disadvantages because it needs to exchange the data between JVM and Python Workers.</description>
    </item>
    <item>
      <title>Build Spark and debug it remotely at IntelliJ</title>
      <link>https://www.sambaiz.net/en/article/419/</link>
      <pubDate>Sun, 09 Oct 2022 19:06:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/419/</guid>
      <description>Build at the command prompt $ git clone --branch v3.3.0 --depth 1 https://github.com/apache/spark.git Install Java 8 with asdf. $ brew install asdf $ echo -e &amp;#34;\n. $(brew --prefix asdf)/libexec/asdf.sh&amp;#34; &amp;gt;&amp;gt; ${ZDOTDIR:-~}/.zshrc $ asdf --version v0.10.2 $ asdf plugin-add java $ asdf list-all java $ asdf install java corretto-8.342.07.3 $ asdf global java corretto-8.342.07.3 $ echo &amp;#34;. ~/.asdf/plugins/java/set-java-home.zsh&amp;#34; &amp;gt;&amp;gt; ~/.zprofile $ java -version openjdk version &amp;#34;1.8.0_342&amp;#34; OpenJDK Runtime Environment Corretto-8.342.07.3 (build</description>
    </item>
    <item>
      <title>Implement scripts running in Alfred Workflows with deanishe/awgo</title>
      <link>https://www.sambaiz.net/en/article/418/</link>
      <pubDate>Mon, 26 Sep 2022 12:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/418/</guid>
      <description>deanishe/awgo is a library to implement scripts running in Alfred Workflows. It enables to output Script Filter JSON to pass values to the next object with NewItem(), access keychain, and check logs with MagicAction by calling wf.Args() and passing workflow:log as arguments. The code is executed every time a character is typed by default, so it would be better to cache results of API calls, etc. as follows. There are</description>
    </item>
    <item>
      <title>Aggregate logs of spark running on an EMR cluster with Fluent Bit</title>
      <link>https://www.sambaiz.net/en/article/416/</link>
      <pubDate>Sun, 04 Sep 2022 14:44:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/416/</guid>
      <description>If Spark jobs run on Cluster mode, the logs are not outputted to step/ directory, so it is hard to check it on the console, so try aggregating them to New Relic.&#xA;Launch an EMR cluster with AWS CLI and run Spark applications - sambaiz-net&#xA;Monitor infrastructure and applications with New Relic - sambaiz-net&#xA;Option 1. Sending logs with self installed fluent bit Install Fluent Bit that is memory saving fluentd, and send logs with it.</description>
    </item>
    <item>
      <title>Why can Athena v2 fail to query map columns in parquet source tables</title>
      <link>https://www.sambaiz.net/en/article/415/</link>
      <pubDate>Tue, 16 Aug 2022 21:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/415/</guid>
      <description>Output logs containing map fields as json etc., convert it to parquet with Glue Studio, and execute queries with Athena, then the queries can succeed or fail depending on the table.&#xA;Columnar format Parquet structure and read optimization - sambaiz-net&#xA;type Log struct { A map[string]int } =&amp;gt; {&amp;#34;A&amp;#34;:{&amp;#34;B&amp;#34;:10,&amp;#34;C&amp;#34;:20}} The parquet metadata is as follows and the information about map is lost.&#xA;$ parquet meta test.parquet File path: test.parquet Created by: parquet-glue version 1.</description>
    </item>
    <item>
      <title>Settings for running Spark on EMR</title>
      <link>https://www.sambaiz.net/en/article/414/</link>
      <pubDate>Sat, 13 Aug 2022 19:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/414/</guid>
      <description>EMR and Glue are managed services that run Spark applications on AWS. Glue is easy to run ETL jobs with serverless, while EMR allows fine-tuning of resources and parameters. In other words, if the settings are not appropriate, the resources cannot be fully used, and tasks can fail due to OOM even if there is excess memory.&#xA;In the CLI, settings can be passed as json string or a file with &amp;ndash;configurations.</description>
    </item>
    <item>
      <title>Exploring the cause of OOM that occurred in Java from GC logs and heap dumps</title>
      <link>https://www.sambaiz.net/en/article/413/</link>
      <pubDate>Thu, 11 Aug 2022 08:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/413/</guid>
      <description>Visualize GC logs Output GC logs. -Xloggc:/tmp/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps $ cat /tmp/gc.log 2022-08-08T16:35:30.738+0000: [GC (Allocation Failure) [PSYoungGen: 638269K-&amp;gt;3108K(665600K)] 2017703K-&amp;gt;1382542K(2063872K), 0.0084360 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] 2022-08-08T16:35:31.320+0000: [GC (Allocation Failure) [PSYoungGen: 640548K-&amp;gt;2565K(666624K)] 2019982K-&amp;gt;1382000K(2064896K), 0.0086070 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] 2022-08-08T16:35:31.878+0000: [GC (Allocation Failure) [PSYoungGen: 640005K-&amp;gt;2565K(667136K)] 2019440K-&amp;gt;1382000K(2065408K), 0.0086495 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] 2022-08-08T16:35:32.451+0000: [GC (Allocation Failure) [PSYoungGen: 643589K-&amp;gt;3301K(668672K)] 2023024K-&amp;gt;1382736K(2066944K), 0.0087513 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] Opening this</description>
    </item>
    <item>
      <title>Call Go functions from browser JavaScript with WebAssembly</title>
      <link>https://www.sambaiz.net/en/article/412/</link>
      <pubDate>Sat, 30 Jul 2022 00:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/412/</guid>
      <description>Pushing the button, the function implemented in Go is called, and it updates the value of text.&#xA;$ go version go version go1.18 darwin/amd64 Go can refer variables and call functions in js with syscall/js package. By breaking changes of Go 1.12, NewCallback() is renamed to FuncOf(). The function must return the value that has a type js.ValueOf() expects, so if returns a struct, an error occurs.&#xA;package main import ( &amp;#34;strconv&amp;#34; &amp;#34;syscall/js&amp;#34; ) func increment(this js.</description>
    </item>
    <item>
      <title>Debug a Java application running on a remote machine by enabling JDWP</title>
      <link>https://www.sambaiz.net/en/article/411/</link>
      <pubDate>Sun, 24 Jul 2022 21:59:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/411/</guid>
      <description>Enable JDWP If -agentlib:jdwp is passed on starting, JDWP(Java Debug Wire Protocol), which is used for communicating between debugger and JVM, is enabled.&#xA;transport=dt_socket,server=y,address=*:5005: Listen debugger on port 5005. Prior to Java 8, *: is not required. suspend=n: Don&amp;rsquo;t suspend the JVM immediately before the main class is loaded For applications that terminate when processing is finished, you can start the debugger in advance and then run the application with server=n to connect to the debugger.</description>
    </item>
    <item>
      <title>Deploy a container to ECS on Fargate, execute commands by ECS Exec, and perform port forwarding by Session Manager</title>
      <link>https://www.sambaiz.net/en/article/410/</link>
      <pubDate>Sat, 23 Jul 2022 13:45:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/410/</guid>
      <description>When investigating an application running in a remote non-container environment, sshd is often running, so commands can be executed with SSH connection. On the other hand, sshd isn&amp;rsquo;t usually running in a container environment, so it can&amp;rsquo;t be executed similarly. If absolutely necessary, there is a way to run sshd, but it would be better to avoid it in terms of opening ports and managing keys. In this article, command</description>
    </item>
    <item>
      <title>Launch an EMR cluster with AWS CLI and run Spark applications</title>
      <link>https://www.sambaiz.net/en/article/409/</link>
      <pubDate>Wed, 22 Jun 2022 00:05:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/409/</guid>
      <description>Amazon EMR is the service that launches a cluster installed Spark, Hive, and Presto on EC2 or EKS. While Glue, the managed Spark service, can easily run Spark ETL jobs with serverless, EMR has the advantage of excellent cost performance by spot instances etc., and also fine-tuning is available, but now that EMR Serverless has been released, the difference has narrowed a little. Glue also has handy features such as</description>
    </item>
    <item>
      <title>Characteristics of Metrics and Events in New Relic and queries in NRQL</title>
      <link>https://www.sambaiz.net/en/article/408/</link>
      <pubDate>Thu, 09 Jun 2022 20:05:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/408/</guid>
      <description>New Relic categorizes telemetry data into Metrics, Events, Logs and Traces, called MELT. Sent data can be queried in NRQL, standard SQL-like queries, shown on a dashboard, and targeted as alert conditions, but sometimes desired value can&amp;rsquo;t be obtained depending on the data type. Metrics Periodically aggregated and sent data. Having aggregated data, the transfer cost can be reduced and track the long-term trend, but there is a trade-off that</description>
    </item>
    <item>
      <title>Maximum flow and minimum cut problem, Ford–Fulkerson algorithm</title>
      <link>https://www.sambaiz.net/en/article/407/</link>
      <pubDate>Sun, 05 Jun 2022 18:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/407/</guid>
      <description>Maximum flow problem Maximum flow promlem is a problem that maximizes the flow from the source to the sink in the network consisting of paths with capacity. It is necessary not to exceed the capacity and to equal input and output amount for each node. Besides, all of the data emitted from the source must be sent to the sink. Minimum cut problem Minimum cut problem is a problem that</description>
    </item>
    <item>
      <title>Calculate partial sum with Segment Tree or Bineary Indexed Tree (BIT)</title>
      <link>https://www.sambaiz.net/en/article/406/</link>
      <pubDate>Sun, 29 May 2022 19:18:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/406/</guid>
      <description>Segment Tree Segment Tree is a complete binary tree which can calculate partial sum at O(log n) by having the calculation results in each partials as node. In the following example, the calculated value is sum, but if it is the minimum value, Range Minimum Query (RMQ) can be solved and if it is the sorted list, merge sort is processed. When updating the value, recalculate in order from the</description>
    </item>
    <item>
      <title>Settings for querying tables of other accounts with Athena</title>
      <link>https://www.sambaiz.net/en/article/405/</link>
      <pubDate>Tue, 17 May 2022 23:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/405/</guid>
      <description>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net Borrower Account that executes the query needs to access the resources of Owner Account having Data Catalog and the data. There are some ways to access resources of other accounts, such as access tokens or AssumeRole, but in this case, the role used to execute queries also needs the permission of the Borrower Account&amp;rsquo;s Athena,</description>
    </item>
    <item>
      <title>How faster is sending/receiving values by UNIX domain socket than starting new processes when executing commands</title>
      <link>https://www.sambaiz.net/en/article/404/</link>
      <pubDate>Fri, 06 May 2022 20:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/404/</guid>
      <description>For example when some procedures are written in different languages and they are repeatedly executed as different commands, overhead such as memory allocation occurs when creating a process. One of solutions to avoid this is to keep the process running and pass input/output value with interprocess communication. In this article I make a command in Go and benchmark to see how much the throughput differs.&#xA;For speedy interprocess communication on UNIX, besides shared memory, pipes and UNIX domain sockets are used.</description>
    </item>
    <item>
      <title>Make asking about codes and debugging efficient with New Relic CodeStream</title>
      <link>https://www.sambaiz.net/en/article/403/</link>
      <pubDate>Wed, 04 May 2022 22:43:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/403/</guid>
      <description>New Relic CodeStream is a plugin which is useful to ask about codes, create issue or PR and debug on IDE for IntelliJ, VSCode and so on. Install Install the plugin to IDE and set the integretion. Comment You can comment to code blocks to ask about it, or create an issue. If Slack integration is set, following post is submited. By &amp;ldquo;Open in IDE&amp;rdquo; button, you can jump to</description>
    </item>
    <item>
      <title>Implement Athena&#39;s data source connectors and user defined functions (UDF)</title>
      <link>https://www.sambaiz.net/en/article/402/</link>
      <pubDate>Sat, 23 Apr 2022 18:09:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/402/</guid>
      <description>Athena has a feature called Federate Query that can access data sources other than S3 using Lambda as a connector, and the official repository provides connectors for various data sources such as BigQuery and Snowflake, but you can also implement your own. This article, implement the minimum connector while referring to Example Connector and run it. The full codes has been pushed to GitHub.&#xA;Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net</description>
    </item>
    <item>
      <title>About newrelic-lambda-extension and how it works telemetry without CloudWatch Logs</title>
      <link>https://www.sambaiz.net/en/article/401/</link>
      <pubDate>Fri, 08 Apr 2022 12:11:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/401/</guid>
      <description>Theare are two methods to send Lambda logs to New Relic. First is a conventional method that uses a Lambda function aws-log-ingestion to subscribe and transfer CloudWatch Logs, and second is a method that uses a Lambda layer newrelic-lambda-extension. The latter send trace logs etc. without outputting to CloudWatch Logs so it can minimize the cost. Install Doing newrelic-lambda integrations install, Secret containing API Key Layer refers is deployed. $</description>
    </item>
    <item>
      <title>Query resources with NerdGraph, New Relic&#39;s GraphQL API</title>
      <link>https://www.sambaiz.net/en/article/400/</link>
      <pubDate>Fri, 01 Apr 2022 22:02:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/400/</guid>
      <description>NerdGraph is New Relic&amp;rsquo;s GraphQL API and it can be used for querying resources or migrating it.&#xA;curl -X POST https://api.newrelic.com/graphql \ -H &amp;#39;Content-Type: application/json&amp;#39; \ -H &amp;#39;API-Key: *****&amp;#39; \ -d &amp;#39;{ &amp;#34;query&amp;#34;: &amp;#34;{ requestContext { userId apiKey } actor { user { name } } }&amp;#34; }&amp;#39; | jq { &amp;#34;data&amp;#34;: { &amp;#34;actor&amp;#34;: { &amp;#34;user&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;Taiki Sakamoto&amp;#34; } }, &amp;#34;requestContext&amp;#34;: { &amp;#34;apiKey&amp;#34;: &amp;#34;*****&amp;#34;, &amp;#34;userId&amp;#34;: &amp;#34;*****&amp;#34; } } } If select resources in GraphiQL explorer, the query is generated.</description>
    </item>
    <item>
      <title>Monitor infrastructure and applications with New Relic</title>
      <link>https://www.sambaiz.net/en/article/399/</link>
      <pubDate>Wed, 30 Mar 2022 19:11:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/399/</guid>
      <description>New Relic is a SaaS that monitors infrastructure and applications, and there is Datadog as a similar service. It seems that the pricing plans were changed drastically in 2020, and it charges according to the transfer volume and the number of admin users. Therefore compared to Datadog, which charges for hosts and additional features, there is an advantage when managing a large number of instances with a small number of</description>
    </item>
    <item>
      <title>Compare Redshift Serverless and Athena performances by TPC-DS queries</title>
      <link>https://www.sambaiz.net/en/article/397/</link>
      <pubDate>Sun, 20 Feb 2022 01:49:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/397/</guid>
      <description>Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net&#xA;Compare the performance between Redshift Serverless (Preview) and Athena by queries of TPC-DS, which is a database benchmark.&#xA;(PS: 2022-07-13) Following values were calculated at the rate at the time of preview. When it became GA, the rate dropped by about 30%.&#xA;Generate data with TPC-DS Connector for Glue - sambaiz-net&#xA;First, executed the following query to the json and parquet data.</description>
    </item>
    <item>
      <title>Generate data with TPC-DS Connector for Glue</title>
      <link>https://www.sambaiz.net/en/article/393/</link>
      <pubDate>Tue, 18 Jan 2022 21:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/393/</guid>
      <description>Previously, I tried to generate 250GB of data with Athena&amp;rsquo;s TPC-DS Connector and output it to S3 but it timed out even if I increased the Lambda resource to the maximum, so I do it with Glue this time.&#xA;Generate data with TPC-DS Connector in Athena&amp;rsquo;s Federated Query - sambaiz-net&#xA;Subscribe and activate TPC-DS connector for Glue.&#xA;Write a script like following. The scale is in GB, the same as Athena&amp;rsquo;s one.</description>
    </item>
    <item>
      <title>Redshift Serverless and other serverless ETL services, run query with Glue Data Catalog</title>
      <link>https://www.sambaiz.net/en/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/392/</guid>
      <description>Redshift Serverless Redshift Serverless is a new feature that can use Redshift, a petabyte-scale DWH without launching an instance, announced at this year&amp;rsquo;s re:Invent. It is available existing features such as Redshift Spectrum, refer to S3 directly, Federated Query to RDS, and Redshift ML. I&amp;rsquo;m happy with this update as it is costly to keep the instance running for occasional usage such as analytics. The cost is charged for at</description>
    </item>
    <item>
      <title>Generate data with TPC-DS Connector in Athena&#39;s Federated Query</title>
      <link>https://www.sambaiz.net/en/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/391/</guid>
      <description>Athena&amp;rsquo;s Federated Query is a feature to execute queries on non-S3 data sources such as DynamoDB and RDS through Lambda function which is a data sources connector. Implement Athena&amp;rsquo;s data source connectors and user defined functions (UDF) - sambaiz-net This article uses TPC-DS Connector in the AWS official repository. It generates the data of TPC-DS, which is a database benchmark in Decision Support. Although it is in the official repository,</description>
    </item>
    <item>
      <title>Check if there is a cycle in the undirected graph by Union-Find Tree</title>
      <link>https://www.sambaiz.net/en/article/390/</link>
      <pubDate>Sun, 12 Dec 2021 16:39:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/390/</guid>
      <description>Union-Find Tree Union-Find Tree is a data structure having some disjoint sets and can do &amp;ldquo;Union&amp;rdquo; which merges two sets, and &amp;ldquo;Find&amp;rdquo; which checks if two elements are in the same set with amortized O(α(n)) (α(n) is an inverse Ackermann function and smaller than log(n)). &amp;ldquo;Union&amp;rdquo; connects the tree with the smaller rank to under side so that merged tree</description>
    </item>
    <item>
      <title>Flutter&#39;s Navigator and AuroRoute</title>
      <link>https://www.sambaiz.net/en/article/389/</link>
      <pubDate>Sat, 11 Dec 2021 16:39:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/389/</guid>
      <description>Navigator Flutter&amp;rsquo;s Navigator is a screen transition class by stacking Routes and has APIs such as push() and pop().&#xA;import &amp;#39;package:flutter/material.dart&amp;#39;; void main() { runApp(const MyApp()); } class MyApp extends StatelessWidget { const MyApp({Key? key}) : super(key: key); @override Widget build(BuildContext context) { return MaterialApp( title: &amp;#39;Navigation Test&amp;#39;, theme: ThemeData( primarySwatch: Colors.blue, ), home: const Page1(), ); } } class Page1 extends StatelessWidget { const Page1({Key? key}) : super(key: key); @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: const Text(&amp;#34;page1&amp;#34;), ), body: ListView.</description>
    </item>
    <item>
      <title>Build iOS/Android/Web App by Flutter</title>
      <link>https://www.sambaiz.net/en/article/388/</link>
      <pubDate>Sun, 05 Dec 2021 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/388/</guid>
      <description>Flutter is a cross-platform framework by Google. In addition to iOS/Android, Web became stable in version 2.0 which is released in March of this year, and Windows/Mac/Linux is beta. Unlike React Native which uses native UI, Flutter uses its own UI. In addition to Material, iOS-style Cupertino is also available, but unless it branches etc., it become the same looks regardless of the platform.&#xA;Build the environment Build the environment according to the official Get started.</description>
    </item>
    <item>
      <title>Implement Rabin–Karp algorithm in C&#43;&#43;</title>
      <link>https://www.sambaiz.net/en/article/387/</link>
      <pubDate>Sat, 04 Dec 2021 22:38:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/387/</guid>
      <description>Rabin–Karp algorithm is a string-searching algorithm using rolling hash. Rolling hash can be made with O(1) by removing a first element from the previous hash and adding a next element to it. There are various hash functions which can do it, but for example, when simply summing up character codes, the hashes will collide just because the same character is contained,</description>
    </item>
    <item>
      <title>Columnar format Parquet structure and read optimization</title>
      <link>https://www.sambaiz.net/en/article/386/</link>
      <pubDate>Fri, 03 Dec 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/386/</guid>
      <description>Parquet is a columnar format mainly used in the Hadoop ecosystem. Compared to row-based formats like CSV, unnecessary columns can be skipped. Besides, there is a mechanics to read only rows that are needed, so queries can be executed efficiently.&#xA;Format Rows are horizontally partitioned into some Row Groups, and the Column Chunks of each column are arranged in order. Column Chunks are divided into Pages, and compression and encoding are performed in that unit.</description>
    </item>
    <item>
      <title>struct and class in C&#43;&#43;</title>
      <link>https://www.sambaiz.net/en/article/385/</link>
      <pubDate>Tue, 30 Nov 2021 18:12:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/385/</guid>
      <description>class and struct in C++ are functionally equivalent but class is private by default as opposed to struct being public. class is used for encapsulation and if it has public fields and few methods, it seems that struct is used generally. #include &amp;lt;iostream&amp;gt; using namespace std; class C { int value; public: C(int value) { this-&amp;gt;value = value; } int func() { return value; }; }; struct S { S(int</description>
    </item>
    <item>
      <title>Treat Spark struct as map to expand to multiple rows with explode</title>
      <link>https://www.sambaiz.net/en/article/384/</link>
      <pubDate>Wed, 13 Oct 2021 02:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/384/</guid>
      <description>When you read data without specifying schema in Spark, the schema is automatically determined from the input as follows. Why can Athena v2 fail to query map columns in parquet source tables - sambaiz-net # {&amp;#34;aaa&amp;#34;:123,&amp;#34;ccc&amp;#34;:[123],&amp;#34;eee&amp;#34;:{&amp;#34;fff&amp;#34;:123},&amp;#34;hhh&amp;#34;:null} df = spark.read.json(&amp;#34;s3://hogefuga/testjson/&amp;#34;) df.printSchema() &amp;#39;&amp;#39;&amp;#39; root |-- aaa: long (nullable = true) |-- ccc: array (nullable = true) | |-- element: long (containsNull = true) |-- eee: struct (nullable = true) | |-- fff:</description>
    </item>
    <item>
      <title>Spark Web UI: Monitor Job Stages, Tasks distribution and SQL plan</title>
      <link>https://www.sambaiz.net/en/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/382/</guid>
      <description>Spark Web UI is a tool for monitoring Jobs and Executors. Get Dockerfile that runs Spark based on maven:3.6-amazoncorretto-8 from aws-glue-samples, and start History Server with the path of EventLog output by Glue and authentication information to get it. $ git clone https://github.com/aws-samples/aws-glue-samples.git $ cd aws-glue-samples/utilities/Spark_UI/glue-3_0/ $ docker build -t glue/sparkui:latest . $ docker run -it -e SPARK_HISTORY_OPTS=&amp;#34;$SPARK_HISTORY_OPTS -Dspark.history.fs.logDirectory=s3a://path_to_eventlog -Dspark.hadoop.fs.s3a.access.key=$AWS_ACCESS_KEY_ID -Dspark.hadoop.fs.s3a.secret.key=$AWS_SECRET_ACCESS_KEY&amp;#34; -p 18080:18080 glue/sparkui:latest &amp;#34;/opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer&amp;#34; Now, you can access</description>
    </item>
    <item>
      <title>Athena (Presto) and Glue (Spark) can return different values when running the same query</title>
      <link>https://www.sambaiz.net/en/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/370/</guid>
      <description>AWS has multiple managed services that aggregate with SQL-like queries. If queries are executed ad-hoc, Presto-based Athena, which can quickly and easily query to tables in Glue&amp;rsquo;s data catalog, is handy, while if heavy queries are executed in batch, Spark-based Glue, which can avoid resource and time limitation, can be better. Therefore, they can be used properly depending on the case.&#xA;Redshift Serverless and other serverless aggregation services, run query with Glue Data Catalog - sambaiz-net</description>
    </item>
    <item>
      <title>Enable Job Bookmark of AWS Glue to process from the records following ones executed previously</title>
      <link>https://www.sambaiz.net/en/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/333/</guid>
      <description>Job Bookmark of AWS Glue is a feature that saves what records are processed, and prevent it from being executed next time. Parquet and ORC, which were not supported before 1.0, are now supported. AWS GlueでCSVを加工しParquetに変換してパーティションを切りA</description>
    </item>
    <item>
      <title>Python with structural subtyping by Protocol</title>
      <link>https://www.sambaiz.net/en/article/325/</link>
      <pubDate>Fri, 12 Feb 2021 02:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/325/</guid>
      <description>In Python that has no interface syntax, it can assure that the function can be called by checking the function existance with hasattr(). However, this method needs to insert asserting each time and the error cannot be known until runtime. class ImplClass(): def foo(self): print(&amp;#34;ok&amp;#34;) class NoImplClass(): pass def call(d): assert hasattr(d, &amp;#39;foo&amp;#39;) d.foo() if __name__ == &amp;#34;__main__&amp;#34;: call(ImplClass()) # =&amp;gt; ok call(NoImplClass()) # =&amp;gt; AssertionError If you describe Type</description>
    </item>
    <item>
      <title>What is Apache Spark, RDD, DataFrame, DataSet, Action and Transformation</title>
      <link>https://www.sambaiz.net/en/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/208/</guid>
      <description>What is Spark? Spark is high-performance general-purpose distributed processing system. It is used with distributed storage such as HDFS and S3, and cluster managers such as Hadoop YARN. HDFS(Hadoop Distributed File System)とは - sambaiz-net How Hadoop YARN allocates resources to applications and check how much resources are allocated - sambaiz-net It can be processed faster than Hadoop&amp;rsquo;s MapReduce by storing the intermediate</description>
    </item>
    <item>
      <title>Launch Hive execution environment with Cloudera Docker Image and execute query to JSON log</title>
      <link>https://www.sambaiz.net/en/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/128/</guid>
      <description>What is Hive Hive is a data warehouse software built on Hadoop, which can access data sources such as HDFS with HiveSQL, an extended SQL. Sending a query, the job runs on MapReduce, Spark or Tez. It has fault tolerance and is mainly used in batch processing. What is HDFS(Hadoop Distributed File System) - sambaiz-net Presto, which access data sources with SQL likewise, can execute the query faster than Hive</description>
    </item>
    <item>
      <title>What is HDFS(Hadoop Distributed File System)</title>
      <link>https://www.sambaiz.net/en/article/126/</link>
      <pubDate>Mon, 14 Aug 2017 22:52:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/126/</guid>
      <description>What is HDFS HDFS stands for Hadoop Distributed File System, one of the implementations of file systems for Hadoop, and other implementations include local files and S3. It distributes the disk I/O, which is a big problem when the data size is enormous and makes a block size, a unit for reading and writing, big to reduce the seek cost and improve the throughput.&#xA;You can see disk I/O can be a bottleneck from the data that while communication within the data center takes about 0.</description>
    </item>
    <item>
      <title>Options for SSH port forwarding</title>
      <link>https://www.sambaiz.net/en/article/42/</link>
      <pubDate>Sat, 17 Dec 2016 12:15:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/42/</guid>
      <description>Forward connection to localhost:8080 to example2.com:80 through example.com. This is generally used when the target server cannot be accessed directly from the local or when the port is not open to the public.&#xA;-L: Do port forwarding -N: Don&amp;rsquo;t execute commands -f: Run in the background $ ssh hoge@example.com -Nf -L 8080:example2.com:80 $ curl localhost:8080 # =&amp;gt; example2.com:80 </description>
    </item>
    <item>
      <title>Increase the maximum number of file descriptors</title>
      <link>https://www.sambaiz.net/en/article/41/</link>
      <pubDate>Thu, 08 Dec 2016 21:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/41/</guid>
      <description>What is file descriptors? File desecriptors is an identifier for interacting with an outside of a process. In POSIX, it is an int type, 0 is stdin, 1 is stdout, and 2 is stderr. It is assigned by a system call such as open() to open files and devices, and socket() to create sockets to communicate with other processes. Maximum number of file descriptors There is a limit on the</description>
    </item>
    <item>
      <title>About JVM Heap space and Full GC</title>
      <link>https://www.sambaiz.net/en/article/35/</link>
      <pubDate>Mon, 14 Nov 2016 23:46:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/en/article/35/</guid>
      <description>Heap space Heap space is a dynamically allocated memory space that is divided into a new generation and an old generation in JVM. By the way, the heap space containing the loaded classes and methods was called the Permanent space, but since Java8, it has been replaced by the Metaspace and has been placed in native memory. New generation The New generation is further divided into the following space. Eden:</description>
    </item>
  </channel>
</rss>
