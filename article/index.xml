<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Articles on sambaiz-net</title>
    <link>https://www.sambaiz.net/article/</link>
    <description>Recent content in Articles on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 05 Jul 2020 21:26:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/article/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>時系列データの定常性</title>
      <link>https://www.sambaiz.net/article/279/</link>
      <pubDate>Sun, 05 Jul 2020 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/279/</guid>
      <description>時系列の各時間tでのデータをそれぞれの分布から抽出された確率変数R_tとして扱い、次の性質を定義する。
 弱定常性(weak stationarity): 各分布の平均E(R_t) = μがtに依らず一定で、lagkのデータとの共分散である自己共分散Cov(R_t, R_{t-k}) = E[(R_t - E(R_t))(R_{t-k} - E(R_{t-k}))] = γ_kがlagのみに依存する(つまり分散γ_0も一定) 強定常性(strict stationarity): 任意のt,kに対する(R_t, R_{t+1}, ..., R_{t+k})の同時分布が同一  つまり弱定常性を持つデータは、一定の平均のまわりの一定の振れ幅の中で、それ以前の値にlagに応じた影響を受けながら推移することになる。単に定常性と言う場合この弱定常性のことを指す。
弱定常性の条件は同一の分布でなくても平均と分散、自己共分散が一定ならば満たされるため、強定常性の条件は満たさないことがある。 逆に強定常性を持つ場合は弱定常性も持ちそうだが、強定常性の条件は平均や分散(1次と2次のモーメント)を必須としないので必ずしも正しくない。 同一の分布からそれぞれ独立に抽出した列であるi.i.d.(independently and identically distributed, 独立同一分布)系列は強定常性を持つが、 その分布が平均と分散が定義されないコーシー分布のような場合は弱定常性を持たないことになる。
確率変数の列を確率過程(stochastic process)と呼び、定常性を持つものを定常過程(stationary process)と呼ぶ。
参考 現場ですぐ使える時系列データ分析～データサイエンティストのための基礎知識〜
CHAPTER 4. STATIONARY TS MODELS
定常性についてのまとめ ｜ Developers.IO
第１章「離散時間確率過程」</description>
    </item>
    
    <item>
      <title>SwiftのクラスをObjective-CのClass型に渡してinitしたときに落ちるパターン</title>
      <link>https://www.sambaiz.net/article/284/</link>
      <pubDate>Sun, 28 Jun 2020 23:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/284/</guid>
      <description>Objective-Cのクラスは基本的にNSObjectをルートクラスに持ち、そのinit()が継承またはオーバーライドされるが、 SwiftのクラスはNSObjectを継承していなかったり他のdesignated initializerが存在することでinit()が存在しないことや、default initializerのために明示的なinit()が存在しない場合がある。
Swiftのdesignated/convenience/required/default initializerと継承 - sambaiz-net
そんなクラスのMetatypeをObjective-CのClass型に代入してinitするとどうなるか確認する。
SwiftのMetatypeとMetadata - sambaiz-net
#import &amp;lt;Foundation/Foundation.h&amp;gt; @interface Hoge: NSObject @property (weak, nonatomic) id &amp;lt;HogeDelegate&amp;gt; delegate; @property Class klass; - (void)fuga; @end #import &amp;quot;Hoge.h&amp;quot; #import &amp;lt;UIKit/UIKit.h&amp;gt; @implementation Hoge - (void)fuga { dispatch_async(dispatch_get_main_queue(), ^{ [[_klass alloc] init]; }); } @end func f() { var hoge = Hoge() hoge.klass = B.self hoge.fuga() }  init()を実装したクラス: 実行時にUnrecognized selector -[***.B init]で落ちる  init()を実装しないでdefault initializerが存在する場合も同様。
class B{ init() {} }  NSObjectを継承したクラス: 落ちない  class B: NSObject{ }  NSObjectを継承し、init()以外のdesignated initializerを実装したクラス: 実行時にUse of unimplemented initializer &#39;init()&#39; for class &#39;***.</description>
    </item>
    
    <item>
      <title>SwiftのARCとweak、delegateが呼ばれなかったりObjective-Cで返り値が0やNOになる原因</title>
      <link>https://www.sambaiz.net/article/283/</link>
      <pubDate>Sat, 27 Jun 2020 23:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/283/</guid>
      <description>SwiftやObjective-CはARC (Automatic Reference Counting)という仕組みでメモリを管理していて、 インスタンスへの参照カウントが0になったときにそのメモリが開放される。昔は参照カウントの増減を手動でやっていたが今はARCが自動でやってくれる。
class X { deinit { print(&amp;quot;deinit X&amp;quot;) } } var x: X? = X() print(&amp;quot;inited X&amp;quot;) x = nil print(&amp;quot;setted nil&amp;quot;) /* inited X deinit X setted nil */ 通常それでうまく働くが、次のように循環参照するといずれの参照カウントも0にならずメモリリークする。
protocol SomeDeleagete: AnyObject { func foo() -&amp;gt; Int } class A { var b: B init() { self.b = B() self.b.delegate = self } deinit { print(&amp;quot;deinit A&amp;quot;) } } extension A: SomeDeleagete { func foo() -&amp;gt; Int { return 100 } } class B { var delegate: SomeDeleagete?</description>
    </item>
    
    <item>
      <title>SwiftのMetatypeとMetadata</title>
      <link>https://www.sambaiz.net/article/282/</link>
      <pubDate>Thu, 25 Jun 2020 20:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/282/</guid>
      <description>ObjcのClass型のように インスタンスではなくクラスそのものを取りたい場合、SwiftではFoo.Typeで表せるMetatypeを用いる。 値はクラスからはFoo.selfで、インスタンスからはtype(of: Foo())で得られる。 初期化の際はサブクラスにも存在することが保証されるrequired initializerを呼ぶか、継承できないfinal classである必要がある。
Swiftのdesignated/convenience/required/default initializerと継承 - sambaiz-net
class Foo { required init() {} func aaa() -&amp;gt; String { return &amp;quot;foo.aaa&amp;quot; } } class Bar: Foo { override func aaa() -&amp;gt; String { return &amp;quot;bar.aaa&amp;quot; } } class Hoge { func aaa() -&amp;gt; String { return &amp;quot;hoge.aaa&amp;quot; } } func initFooAndCallFunc(type: Any.Type) -&amp;gt; String { guard let fooType = type as? Foo.Type else { return &amp;quot;this is not Foo&amp;quot; } return fooType.</description>
    </item>
    
    <item>
      <title>Swiftのassociatedtypeとtype erasure</title>
      <link>https://www.sambaiz.net/article/281/</link>
      <pubDate>Wed, 24 Jun 2020 23:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/281/</guid>
      <description>associatedtypeはprotocolのジェネリクスのようなもので、複数の型に対応した定義を書くことができる。
protocol P1 { associatedtype T func some(x: T) func some2(x: T) } class C1: P1 { func some(x: Int) { print(x) } /* // ambiguous inference of associated type &#39;T&#39;: &#39;String&#39; vs. &#39;Int&#39; func some2(x: String) { print(x) } */ func some2(x: Int) { print(x) } } class C2: P1 { func some(x: Int) { print(x) } // OK func some2&amp;lt;T&amp;gt;(x: T) { print(x) } } 通常、protocolはexistential typeとして変数の型に指定できるが、 associatedtypeが含まれるとその型が不明なので指定できない。</description>
    </item>
    
    <item>
      <title>Swiftのdesignated/convenience/required/default initializerと継承</title>
      <link>https://www.sambaiz.net/article/280/</link>
      <pubDate>Tue, 23 Jun 2020 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/280/</guid>
      <description>Initialization — The Swift Programming Language (Swift 5.3)
designated initializerはプライマリなinitializerで、全ての初期化されていないプロパティを初期化し、スーパークラスのinit()を呼んでチェーンを作る。 convenience initializerは利便性のためのinitializerで、他のinitializerを呼んで最終的にdesignated initializerが呼ばれるようにする。 required initializerは継承が必須なinitializerで、サブクラスにも存在することが保証される。
class A: NSObject { var some: String // designated initializer override init() { print(&amp;quot;designated&amp;quot;) some = &amp;quot;foo&amp;quot; } // designated &amp;amp; required initializer required init(_ str: String) { print(&amp;quot;required \(str)&amp;quot;) some = &amp;quot;bar&amp;quot; } convenience init(_ num: Int) { self.init() print(&amp;quot;convenience \(num)&amp;quot;) } convenience init(num2: Int) { self.init(num2) print(&amp;quot;convenience2 \(num2)&amp;quot;) } } designated initializerはクラスに一つ以上存在する必要があるが、次のように全てのプロパティが初期化されている場合default initializerが作られる。</description>
    </item>
    
    <item>
      <title>Pythonで時系列データを検定(Shapiro-Wilk test, runs test, Ljung-Box test)する</title>
      <link>https://www.sambaiz.net/article/273/</link>
      <pubDate>Sun, 21 Jun 2020 01:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/273/</guid>
      <description>統計的仮説検定 - sambaiz-net
テストデータ Dominick&amp;rsquo;s datasetのビールの週売上データを使う。 UPC(Universal Product Code)に対応する商品データと、店(STORE)で週(WEEK)に売れた数(MOVE)と価格(PRICE)、収益(PROFIT)を含むMovementデータがCSVで提供されている。
これらをカレントディレクトリに置いてJupyter Notebookを立ち上げる。
$ docker run -p 8888:8888 -v `pwd`:/home/jovyan/work jupyter/datascience-notebook start-notebook.sh ロードしてplotしてみる。
import pandas as pd df = pd.read_csv(&#39;./wber.csv&#39;, usecols=[&#39;STORE&#39;, &#39;WEEK&#39;, &#39;UPC&#39;, &#39;MOVE&#39;, &#39;PRICE&#39;, &#39;PROFIT&#39;]) agg = df[df[&#39;STORE&#39;] == 5].groupby([&#39;WEEK&#39;]).sum().loc[:, [&#39;MOVE&#39;, &#39;PROFIT&#39;]] agg.plot() この内、中央の区間の値や差分に対してα=0.05で検定する。
Shapiro-Wilk test 帰無仮説は&amp;quot;正規分布に従っている&amp;rdquo;。p&amp;gt;αとなり帰無仮説は棄却されず、正規分布に従うとみなせる。
from scipy import stats W, p = stats.shapiro(agg[&#39;PROFIT&#39;].loc[230:310]) print(f&#39;p={p:.3f}&#39;) # p=0.183 runs test 帰無仮説は&amp;quot;2値の数列の値がランダムである&amp;rdquo;。runというのは数列の連続して増加/減少している部分のことで、帰無仮説が正しい場合数列に含まれるrunの数は次の平均と分散の正規分布に従う。
updown = agg[&#39;PROFIT&#39;].loc[230:310].diff().map(lambda x: x &amp;gt; 0) Np = updown.value_counts()[True] Nf = updown.</description>
    </item>
    
    <item>
      <title>iOSのnibで作ったViewにCustom Classを対応させて描画する</title>
      <link>https://www.sambaiz.net/article/278/</link>
      <pubDate>Fri, 05 Jun 2020 05:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/278/</guid>
      <description>nibとUIViewを継承したCustomViewクラスを作成し、nibにLabelを配置して@IBOutletと繋げた。
import Foundation import UIKit import viewframework class CustomView: UIView { @IBOutlet weak var labelview: UILabel? } このCustomViewをnibのViewと対応させるのに次の2通りの方法がある。
ルートのViewのCustom Classとして設定する nibのルートのViewのCustom ClassをCustomViewにすると、UINib.instantiate()でCustomViewのrequired init?(coder: NSCoder)が呼ばれインスタンスが作られるので、 それをaddSubViewすることで描画できる。
import UIKit class ViewController: UIViewController { override func viewDidLoad() { super.viewDidLoad() let customView = UINib(nibName: &amp;quot;CustomView&amp;quot;, bundle: Bundle(for: type(of: self))).instantiate(withOwner: nil, options: nil).first as! CustomView customView.labelview?.text = &amp;quot;OK&amp;quot; view.addSubview(customView) } } File&amp;rsquo;s OwnerのCustom Classとして設定する nibのFile&amp;rsquo;s OwnerのCustom ClassをCustomViewにし、 CustomView内でwithOwner: selfでnibをロードすると@IBOutletにインスタンスが詰まるので、ルートのViewも繋げておいてそれをaddSubViewすればCustomView以下にnibのヒエラルキーそのまま描画される。 Custom ClassがUIViewである必要は必ずしもなくロードしたviewを親のviewに直接addSubViewしても良い。
import Foundation import UIKit class CustomView: UIView { @IBOutlet var view: UIView!</description>
    </item>
    
    <item>
      <title>C&#43;&#43;でnext_permutationを使わずに順列を列挙する</title>
      <link>https://www.sambaiz.net/article/277/</link>
      <pubDate>Wed, 03 Jun 2020 01:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/277/</guid>
      <description>Permutations - LeetCode
配列が渡されてそれを並び替えてできる全ての順列を返す問題。 まさにSTLのalgorithmに辞書順で次の順列を返すnext_permutation()というのがあって次のようにするだけでできてしまう。
vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; ret; sort(nums.begin(), nums.end()); do { ret.push_back(nums); } while (next_permutation(nums.begin(), nums.end())); return ret; せっかくなのでこれを使わず実装してみた。 あるindexの要素とそれ以降の全ての要素をそれぞれswapすることでそのindexに入り得る全ての値を網羅し、 それら全ての配列に対して対象のindexを一つ増やして同じ処理を再帰的に繰り返す。
class Solution { public: vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; permute(vector&amp;lt;int&amp;gt;&amp;amp; nums) { return _permute(nums, 0); } vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; _permute(vector&amp;lt;int&amp;gt; nums, int swap_index) { vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; ret; if (swap_index &amp;gt;= nums.size()) { return {nums}; } for(int i = swap_index; i &amp;lt; nums.size(); i++) { swap(nums[swap_index], nums[i]); auto v = _permute(nums, swap_index+1); copy(v.begin(), v.end(), back_inserter(ret)); swap(nums[swap_index], nums[i]); } return ret; } }; </description>
    </item>
    
    <item>
      <title>SwiftのURLSession</title>
      <link>https://www.sambaiz.net/article/276/</link>
      <pubDate>Sun, 31 May 2020 02:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/276/</guid>
      <description>SwiftのURLSessionは ネットワーク通信を行うURLSessionTaskを生成するオブジェクト。
func request(_ session: URLSession) -&amp;gt; () -&amp;gt; Void { return { guard let url = URL(string: &amp;quot;https://api.publicapis.org/health&amp;quot;) else { return } var request = URLRequest(url: url) request.httpMethod = &amp;quot;GET&amp;quot; request.addValue(&amp;quot;application/json&amp;quot;, forHTTPHeaderField: &amp;quot;content-type&amp;quot;) let task = session.dataTask(with: request) { data, response, error in guard let httpResponse = response as? HTTPURLResponse else { print(&amp;quot;not http response \(error)&amp;quot;) return } guard httpResponse.statusCode / 100 == 2 else { print(&amp;quot;bad status code: \(httpResponse.</description>
    </item>
    
    <item>
      <title>SwiftのJSONEncoder/DecoderとCodable protocol</title>
      <link>https://www.sambaiz.net/article/275/</link>
      <pubDate>Tue, 26 May 2020 01:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/275/</guid>
      <description>SwiftのJSONEncoder/Decoderは JSON文字列をCodable(Encodable &amp;amp; Decodable) protocolを実装したClassやStructにエンコード/デコードするオブジェクト。
全ての変数がCodableで、特に何もする必要がない場合はCodableを付ければうまくいく。 String、Int、Doubleといったstandard libraryの型や、DateやDataなどFoundationの型はCodableになっている。
CodingKeyでフィールド名のマッピングができる。デコード時にOptionalでないフィールドが足りなかったり型が異なると例外が飛び、エンコード時にはnilを無視する。
struct Foo: Codable { var nums: [Int] var str: String enum CodingKeys: String, CodingKey { case nums = &amp;quot;numbers&amp;quot; case str } } var data = &amp;quot;&amp;quot;&amp;quot; { &amp;quot;numbers&amp;quot;: [100, 120], &amp;quot;str&amp;quot;: &amp;quot;Aaa&amp;quot; } &amp;quot;&amp;quot;&amp;quot;.data(using: .utf8)! let json = try! JSONDecoder().decode(Foo.self, from: data) print(json.str) // =&amp;gt; Aaa let enc = try! JSONEncoder().encode(json) print(String(data: enc, encoding: .utf8)!) // =&amp;gt; {&amp;quot;numbers&amp;quot;:[100,120],&amp;quot;str&amp;quot;:&amp;quot;Aaa&amp;quot;} var data = &amp;quot;&amp;quot;&amp;quot; { &amp;quot;numbers&amp;quot;: [100, 120], } &amp;quot;&amp;quot;&amp;quot;.</description>
    </item>
    
    <item>
      <title>VPCエンドポイント</title>
      <link>https://www.sambaiz.net/article/274/</link>
      <pubDate>Sat, 23 May 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/274/</guid>
      <description>VPCエンドポイントは PrivateLink対応のサービスおよび、S3やDynamoとAWSネットワーク内で接続するためのエンドポイント。 インターネットに出ない分セキュアでゲートウェイへの負荷も抑えられる。 料金は時間あたりとトラフィック量による。
VPCエンドポイントを使うためにアプリケーション側に手を入れる必要はなく、 S3とDynamoがサポートしているGatewayのエンドポイントではルートテーブルによって、 その他多くのサービスがサポートしているInterfaceのエンドポイントでは名前解決の時点で向き先が変わるようになっている。
まずVPCのDNS ResolutionとDNS HostnamesをtrueにしてPrivate DNSで名前解決されるようにしておく必要がある。 エンドポイントを作成する際の設定項目は対象サービスと、VPCとSubnet、SGとサービスによってはPolicy。 サービスと1:1対応しているわけではなく、例えばECSの場合は次の3つのエンドポイントが必要。
com.amazonaws.region.ecs-agent com.amazonaws.region.ecs-telemetry com.amazonaws.region.ecs 作成するとSubnet内にエンドポイントとそれに紐づくENIが立ち、インターネットゲートウェイなしでもAPIが叩けるようになった。</description>
    </item>
    
    <item>
      <title>統計的仮説検定</title>
      <link>https://www.sambaiz.net/article/271/</link>
      <pubDate>Sun, 10 May 2020 23:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/271/</guid>
      <description>統計的仮説検定(statistical hypothesis test)は母集団に対するある仮説が妥当だと言えるか標本から判断する手法。 棄却(reject)されることが期待される帰無仮説(null hypothesis)H_0と、それに相対する本命の対立仮説(alternative hypothesis)H_1を立て、 検定統計量を出し、帰無仮説が正しい場合での確率分布でそれより外れた値が観測される確率であるp値が、設定した有意水準α(0.05にすることが多い)を下回れば帰無仮説が棄却され対立仮説が受容(accept)される。 有意水準はあくまで帰無仮説を棄却できるかのラインなので、それを上回ったからといって帰無仮説が受容できる程度に妥当である保証はないが、事実上受容することも少なくない。
母集団が特定の分布に従うと仮定しそのパラメータである平均や分散などを用いるパラメトリックな手法と、そうでないノンパラメトリックな手法がある。 パラメトリックな手法の方が、帰無仮説が誤っている場合にそれを棄却する確率である検出力が高いが、標本数が小さい場合は分布を仮定することが難しいためノンパラメトリックな手法の方が適している。
t-検定 正規分布を仮定するパラメトリックな手法。ちなみに正規分布かどうかの検定としてShapiro–Wilkの検定などがある。
平均μの正規表現に従うn個の標本から計算される次の確率変数Tが、自由度n-1のt-分布に従うことを利用する。
確率分布(二項分布/ポアソン分布/正規分布/カイ二乗分布/t分布) - sambaiz-net
標本 (1.1, 1.5, 1.2, 1.3, 1.4) に対して帰無仮説&amp;quot;平均1.0の正規分布に従う&amp;quot;で検定してみる。
n = 5 bar{X} = (1.1 + 1.5 + 1.2 + 1.3 + 1.4) / 5 = 1.3 s^2 = ((1.1 - 1.3)^2 + (1.5 - 1.3)^2 + (1.2 - 1.3)^2 + (1.3 - 1.3)^2 + (1.4 - 1.3)^2) / (5 - 1) = 0.025 T = ((1.</description>
    </item>
    
    <item>
      <title>C&#43;&#43;でO(1)で読み書きできるLRUキャッシュを実装する</title>
      <link>https://www.sambaiz.net/article/270/</link>
      <pubDate>Sun, 26 Apr 2020 18:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/270/</guid>
      <description>LRU Cache - LeetCode
最初次のようなコードを書いたがタイムアウトしてしまった。 C++のstd::mapは二分木で実装されているので各操作にO(log n)かかり、dequeの先頭への挿入はO(1)でできるが重複するキーを探して削除するのにO(n^2)かかってしまう。
C++ STLのContainersとAlgorithms - sambaiz-net
class LRUCache { public: deque&amp;lt;int&amp;gt; Q; // key map&amp;lt;int, int&amp;gt; V; // &amp;lt;key, value&amp;gt; int cap = 0; LRUCache(int capacity) { cap = capacity; } int get(int key) { if (V.count(key) != 0) { for (int i = 0; i &amp;lt; Q.size(); i++) { if (Q[i] == key) { Q.erase(Q.begin() + i); break; } } Q.push_front(key); return V[key]; } return -1; } void put(int key, int value) { if (cap == 0) { return; } if (get(key) == -1) { if (Q.</description>
    </item>
    
    <item>
      <title>Goで参照型の変数に代入し値を変更したとき元の値に影響がある場合とない場合</title>
      <link>https://www.sambaiz.net/article/269/</link>
      <pubDate>Sat, 25 Apr 2020 22:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/269/</guid>
      <description>サンプル用struct。
package main import ( &amp;quot;encoding/json&amp;quot; &amp;quot;fmt&amp;quot; ) type Data struct { Value string ValueP *string `json:&amp;quot;,omitempty&amp;quot;` Slice []Data `json:&amp;quot;,omitempty&amp;quot;` SliceP []*Data `json:&amp;quot;,omitempty&amp;quot;` } func NewData() *Data { return &amp;amp;Data{ Value: &amp;quot;no-changed&amp;quot;, ValueP: &amp;amp;[]string{&amp;quot;no-changed&amp;quot;}[0], Slice: []Data{ Data{ Value: &amp;quot;no-changed&amp;quot;, }, Data{ Value: &amp;quot;no-changed&amp;quot;, }, }, SliceP: []*Data{ &amp;amp;Data{ Value: &amp;quot;no-changed&amp;quot;, }, }, } } 参照を取って値を取る アドレスは変わらず、そのフィールドを書き換えると当然元々の値も書き換わる。 各要素が順番に代入されるfor-rangeでのループも他と同じく参照型でないなら変わらず、参照型なら変わる。
func main() { s := NewData() fmt.Printf(&amp;quot;%p %p %p\n&amp;quot;, s, s.ValueP, s.Slice) // 0xc00009a000 0xc000010240 0xc00009c000 s2tmp := &amp;amp;s s2 := *s2tmp fmt.</description>
    </item>
    
    <item>
      <title>Goのcipher packageに実装されている暗号利用モードのベンチマーク</title>
      <link>https://www.sambaiz.net/article/268/</link>
      <pubDate>Sun, 12 Apr 2020 23:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/268/</guid>
      <description>暗号利用モードはブロック長より長いメッセージに対してどのようにブロック暗号を適用するかのアルゴリズム。
ブロック暗号 ブロック暗号は固定長のブロックを暗号化/復号する共通鍵暗号で、入力と同じ長さの出力を返す暗号化/復号関数からなる。 アメリカ国立標準技術研究所（NIST) が標準暗号として採用したAES (Rijndael) が有名。 最も単純な暗号利用モードとして、メッセージをブロックに分割してそれぞれ独立に適用する Electronic Codebook (ECB) というのがあるが、 鍵とブロックが同じなら毎回同じ出力になってしまうため、メッセージのパターンが残ってしまうのとリプレイ攻撃に弱い問題があり使われない。 また、メッセージがブロック長の整数倍になるようにパディングが必要。
Goのcrypto/cipher packageに実装されている暗号化利用モード Goのcrypto/cipher packageには次の暗号化利用モードが実装されている。
$ go version go version go1.14 darwin/amd64 Cipher Block Chaining (CBC) メッセージをブロックに分割し、前段の暗号文(最初はランダムなIV)と入力ブロックのXORを取ったものが暗号文で、 これを復号関数にかけて前段の暗号文とのXORを取って復号する。IVは平文のまま暗号文の前に付けるなどする。 IVがないと最初のブロックが復号できず、暗号文の一部が破損すると次のブロックまで復号できない。 ECBと同様パディングが必要。最も広く使われているらしい。
最後のブロックの暗号文をMAC(Message Authentication Code)とするCBC-MACでは最初のブロックの改変を防ぐためIVが0固定で、 任意のメッセージの最初のブロックを他のメッセージのMACとXORを取って後ろに結合することで、それまでの影響を打ち消し任意のメッセージ単体のMACと同じ値にする Length extension attackが成立する。そのためメッセージを固定長にするかメッセージ長を先頭に入れるなどの対策が必要。
Goではパディングは自分でやる必要がある。
func (x *cbcEncrypter) CryptBlocks(dst, src []byte) { if len(src)%x.blockSize != 0 { panic(&amp;quot;crypto/cipher: input not full blocks&amp;quot;) } if len(dst) &amp;lt; len(src) { panic(&amp;quot;crypto/cipher: output smaller than input&amp;quot;) } if subtle.</description>
    </item>
    
    <item>
      <title>Bellman–Ford法とDijkstra法で最短経路問題を解く</title>
      <link>https://www.sambaiz.net/article/267/</link>
      <pubDate>Wed, 01 Apr 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/267/</guid>
      <description>Bellman–Ford法とDijkstra法で最短経路問題を解く。
Bellman-Ford法 始点の距離が0、それ以外の頂点の距離が無限大な初期状態から、 全辺を見て各辺を通るとしたときに現在の距離を下回るなら更新する、というのを繰り返すアルゴリズム。 辺の重みは負でも問題ないが、総和が負の値になる閉路が存在する場合、そこで無限ループしてしまうので決まらない。 その場合を除けば、頂点の数を|V|、辺の数を|E|とすると、繰り返しは|V|-1回で終わり、計算量はO(|V||E|)になる。
Dijkstra法 同じく始点の距離が0、それ以外の頂点の距離が無限大な初期状態から、 まだ選ばれていない頂点の中から最小の距離のものを1つ選んでその最短距離を確定させ、そこから伸びている辺を見て更新していく、というのを繰り返す。 Bellman-Ford法が全ての頂点から同時に探索するのに対してDijkstra法は始点から着実に進んでいくイメージ。 頂点を選ぶ/取り除くのにO(log|V|)かかる二分ヒープのpriority queueで実装すると計算量はO((|E|+|V|)log|V|)となる。 Bellman-Ford法より高速だが、負の重みがあると選んだ頂点の現在の距離が最短であることが確定しないので適用できない。
Cheapest Flights Within K Stops - LeetCode 乗継K回以内のフライトの最安値を返す問題。
There are n cities connected by m flights. Each flight starts from city u and arrives at v with a price w. Now given all the cities and flights, together with starting city src and the destination dst, your task is to find the cheapest price from src to dst with up to k stops.</description>
    </item>
    
    <item>
      <title>作ったライブラリをCocoaPods/Carthageでimportする</title>
      <link>https://www.sambaiz.net/article/266/</link>
      <pubDate>Sat, 28 Mar 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/266/</guid>
      <description>CocoaPods 長らく使われている依存ライブラリ管理ツール。
$ sudo gem install cocoapods $ pod --version 1.9.1 podspec まずはライブラリ側の作業。podspecを埋めていく。 Trunkに上げないPodに依存する場合、spec.dependency では :git や :path を指定できないので、アプリ側のPodfileで指定する。
$ ls SampleFramework	SampleFramework.xcodeproj	SampleFrameworkTests $ pod spec create SampleFrameworkSambaiz Specification created at SampleFrameworkSambaiz.podspec $ cat SampleFrameworkSambaiz.podspec Pod::Spec.new do |spec| spec.name = &#39;SampleFrameworkSambaiz&#39; spec.version = &#39;0.0.2&#39; spec.license = { :type =&amp;gt; &#39;MIT&#39;, :file =&amp;gt; &#39;LICENSE&#39; } spec.homepage = &#39;https://github.com/sambaiz/ios-sample-framework&#39; spec.authors = { &#39;Taiki Sakamoto&#39; =&amp;gt; &#39;godgourd@gmail.com&#39; } spec.summary = &#39;Sample Framework&#39; spec.</description>
    </item>
    
    <item>
      <title>iOSのipa(app)のProfileを異なるTeamのものに置き換えて実機で動かす</title>
      <link>https://www.sambaiz.net/article/265/</link>
      <pubDate>Tue, 24 Mar 2020 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/265/</guid>
      <description>Profileを置き換えて有効期限やDevice IDを更新する。
iOSアプリのProvisioning profile - sambaiz-net
codesignでの試み .ipa をunzipすると .app が出てくる。
$ unzip my-test-app.ipa $ tree Payload/ Payload/ └── my-test-app.app ├── Base.lproj │ └── LaunchScreen.storyboardc │ ├── 01J-lp-oVM-view-Ze5-6b-2t3.nib │ ├── Info.plist │ └── UIViewController-01J-lp-oVM.nib ├── Info.plist ├── PkgInfo ├── _CodeSignature │ └── CodeResources ├── embedded.mobileprovision └── my-test-app codesign で entitlements を確認する。
$ codesign -d --entitlements :- my-test-app.app &amp;gt; entitlements.plist $ cat entitlements.plist &amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt; &amp;lt;!DOCTYPE plist PUBLIC &amp;quot;-//Apple//DTD PLIST 1.</description>
    </item>
    
    <item>
      <title>iOSアプリのProvisioning Profile</title>
      <link>https://www.sambaiz.net/article/264/</link>
      <pubDate>Tue, 24 Mar 2020 21:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/264/</guid>
      <description>アプリを実機にデプロイするために必要なもの。 App ID (prefix + Bundle ID)やインストール可能なDevice ID、 コード署名に用いた Apple発行の証明書などを含む。これらが一致しないとインストールできない。
次のTypeのProfileが存在する。
 development profile: 開発用のprofile。TeamのDeviceで動かす。 ad hoc profile: テスト用のprofile。UDIDを登録したDeviceに配布できる。 AccountにDevice family (iPhone, iPad, etc.)ごとに100台まで登録可能。 App Store profile: App Storeに上げるためのprofile。  $ ls ~/Library/MobileDevice/Provisioning\ Profiles ****.mobileprovision ... $ security cms -D -i ~/Library/MobileDevice/Provisioning\ Profiles/****.mobileprovision &amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt; &amp;lt;!DOCTYPE plist PUBLIC &amp;quot;-//Apple//DTD PLIST 1.0//EN&amp;quot; &amp;quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&amp;quot;&amp;gt; &amp;lt;plist version=&amp;quot;1.0&amp;quot;&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;AppIDName&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;XC net sambaiz test-app&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;ApplicationIdentifierPrefix&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;string&amp;gt;****&amp;lt;/string&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;CreationDate&amp;lt;/key&amp;gt; &amp;lt;date&amp;gt;2020-03-18T11:05:13Z&amp;lt;/date&amp;gt; &amp;lt;key&amp;gt;Platform&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;string&amp;gt;iOS&amp;lt;/string&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;IsXcodeManaged&amp;lt;/key&amp;gt; &amp;lt;true/&amp;gt; &amp;lt;key&amp;gt;DeveloperCertificates&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;data&amp;gt;****&amp;lt;/data&amp;gt; &amp;lt;data&amp;gt;****&amp;lt;/data&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;Entitlements&amp;lt;/key&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;application-identifier&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;****.</description>
    </item>
    
    <item>
      <title>Goのツールのバージョンをgo.modで指定する</title>
      <link>https://www.sambaiz.net/article/263/</link>
      <pubDate>Sun, 22 Mar 2020 01:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/263/</guid>
      <description>依存moduleと同様にツールもバージョンを指定し、挙動や出力が変わらないようにする。
Tools as dependencies
まず次の tools.go のようなファイルを作ってimportし、 go mod tidy で消えないようにする。 build tagが付いているので通常のbuild時には影響を及ぼさない。
$ cat tools.go // +build tools package pkg import ( _ &amp;quot;golang.org/x/lint/golint&amp;quot; ) 次にGOBINを変更して go install し指定したディレクトリにバイナリを持ってきてこれを実行する。
export GOBIN:=$(PWD)/bin $(GOBIN)/golint: go install golang.org/x/lint/golint .PHONY: test test: $(GOBIN)/golint go test -v ./pkg/... bin/golint ./pkg/... </description>
    </item>
    
    <item>
      <title>Go Modulesのreplaceでforkしたコードのimportを書き換えずにfork後のpackageに向ける</title>
      <link>https://www.sambaiz.net/article/262/</link>
      <pubDate>Sun, 01 Mar 2020 21:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/262/</guid>
      <description>Goはimportの際に相対パスやモジュール名ではなくgithub.com/foo/barのようなフルパスで指定するため、forkしたコードを使うと参照するpackageは元のままになってしまう。Go Modulesのreplace directiveを使うとコードを書き換えずに依存先を変えることができる。相対パスも使える。
When should I use the replace directive? · golang/go Wiki · GitHub
module example.com/me/hello require ( example.com/foo/bar v0.0.0 ) replace ( example.com/foo/bar/aaa =&amp;gt; ./ example.com/foo/bar/bbb =&amp;gt; example.com/hoge/bar/bbb v1.0.0 ) fork元のmodule。文字列を出力するだけのもの。
$ cat go-something/lib/lib.go package lib import &amp;quot;fmt&amp;quot; func Do() { fmt.Println(&amp;quot;this is original&amp;quot;) } $ cat go-something/main.go package main import &amp;quot;github.com/sambaiz/go-something/lib&amp;quot; func main() { lib.Do() } $ go run go-something/main.go this is original fork先のmodule。出力する文字列を変えている。
$ cat go-something-fork/lib/lib.go package lib import &amp;quot;fmt&amp;quot; func Do() { fmt.</description>
    </item>
    
    <item>
      <title>Go Modulesのproxyとsumdb</title>
      <link>https://www.sambaiz.net/article/261/</link>
      <pubDate>Sat, 29 Feb 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/261/</guid>
      <description>Module Mirror and Checksum Database Launched - The Go Blog
Go1.13からデフォルトで使われるようになったGo Modulesのミラーとchecksumを返すサーバー。 Googleによって運営されている。
 proxy.golang.org index.golang.org: proxyで利用可能なmoduleとバージョンの一覧 sum.golang.org  $ curl &amp;quot;https://proxy.golang.org/github.com/labstack/echo/v4/@v/v4.1.14.mod&amp;quot; module github.com/labstack/echo/v4 go 1.12 require ( github.com/dgrijalva/jwt-go v3.2.0+incompatible github.com/labstack/gommon v0.3.0 github.com/mattn/go-colorable v0.1.4 // indirect github.com/mattn/go-isatty v0.0.11 // indirect github.com/stretchr/testify v1.4.0 github.com/valyala/fasttemplate v1.1.0 golang.org/x/crypto v0.0.0-20191227163750-53104e6ec876 golang.org/x/net v0.0.0-20191209160850-c0dbc17a3553 // indirect golang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8 // indirect golang.org/x/text v0.3.2 // indirect ) $ wget &amp;quot;https://proxy.golang.org/github.com/labstack/echo/v4/@v/v4.1.14.zip&amp;quot; $ curl &amp;quot;https://index.golang.org/index?since=2020-02-28T09:00:00.000000Z&amp;amp;limit=5&amp;quot; {&amp;quot;Path&amp;quot;:&amp;quot;github.com/openebs/api&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v0.0.0-20200228085622-f3442fff37bf&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:00:05.62813Z&amp;quot;} {&amp;quot;Path&amp;quot;:&amp;quot;github.com/dirkarnez/dirk-commons&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v0.0.0-20200228090031-1926f326c678&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:00:50.00608Z&amp;quot;} {&amp;quot;Path&amp;quot;:&amp;quot;github.com/jfrog-solutiontest/food&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v4.107.0+incompatible&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:01:10.76502Z&amp;quot;} {&amp;quot;Path&amp;quot;:&amp;quot;github.com/nexus49/dapr-components&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v0.0.0-20200228090009-67e985bdc953&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:01:15.618406Z&amp;quot;} {&amp;quot;Path&amp;quot;:&amp;quot;github.com/Krajiyah/ble-sdk&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v0.0.7-0.20200228090109-03b5ffe425a0&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:01:23.38344Z&amp;quot;} $ curl &amp;quot;https://sum.</description>
    </item>
    
    <item>
      <title>DAX (DynamoDB Accelerator)の特性と挙動確認</title>
      <link>https://www.sambaiz.net/article/260/</link>
      <pubDate>Wed, 26 Feb 2020 23:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/260/</guid>
      <description>DAXとは DAXはDynamoDBの前段に置かれるマネージドなインメモリキャッシュで、 Read速度の向上(数ms-&amp;gt;数百μs)とテーブルのRead Capacityの節約に効果がある。
DynamoDBとSDKのAPIの互換性があるため置き換えるだけで使えるようになっている。 クライアントの実装としてはHTTPではない独自のプロトコルで通信している点が異なる。
クラスタ作成時に指定するのはノード数とインスタンスタイプで、 ノード数はスループットに、インスタンスタイプはスループットとメモリ量(キャッシュヒット率)に影響する。 複数のノードがある場合、一つがWriteするプライマリーノードになり、他はリードレプリカになる。 なのでノード数を増やしてもWriteのスループットは上がらない。プライマリーノードに問題が発生したら自動でフェイルオーバーする。 ノードは最大10個まで増減できるが、インスタンスタイプは変更できない。最大10個というのは足りるのかと思ったが、数百万RPS捌けるようなので十分そうだ。
インスタンスに対して時間課金が発生し、可用性のために3ノード以上にすることが推奨されている。 そのため、リクエストがそれほどなかったり、キャッシュミスばかりだとインスタンス代の方が高くつくこともあるが、 そこそこReadするなら目に見えてコスト削減されるはずだ。ただしどれくらい次の整合性を許容できるかによる。
キャッシュの整合性 DAXはDynamoDBとは異なり、結果整合性のある読み込み(Eventually Consistent Reads)のみをサポートしているので、プライマリノードにキャッシュされ、全てのノードにレプリケーションが完了するまでの間は異なる結果を返す可能性がある。また、DAXからDynamoDBへのリクエストも結果整合性のある読み込みで行われる。
リクエストの結果は、Itemがなかった場合のネガティブキャッシュも含めて、 Item Cache(GetItem,BatchGetItem)とQuery Cache(Query,Scan)にキャッシュされ、 それぞれパラメータグループで設定されたTTLが過ぎるか、LRUアルゴリズムによって破棄される。 TTLのデフォルトは5分。
書き込みリクエストが来るとまずDynamoDBに書き込んで成功したことを確認してからキャッシュしてレスポンスを返す。 この際Item Cacheは更新されるが、Query Cacheは更新されずTTL/LRUによって破棄されるまで同じ値を返し続けてしまう。 もし問題がある場合は、TTLを短くするかDynamoDBを直接見に行くことになるが、そうするとDAXの効果が薄れてしまう。 また、大量のデータを書き込むと、その分レイテンシが増加したり、それらがすべてキャッシュに乗ることで既存のものがLRUで追い出されてキャッシュヒット率が悪くなることがあり、それらを回避するため直接書き込むという選択肢もあるが、Item Cacheが更新されないことを許容する必要がある。
取れるメトリクス CPU使用率や、キャッシュヒット数、各リクエスト数や接続数が取れる。
ノードごとのCPU使用率も取れる。Writeやキャッシュミスによるプライマリーノードの負荷の高まりに注意。 レイテンシが大きくなり接続数が増える悪循環に陥る。
プライマリーノードのCPU使用率が80%程度でテーブルのキャパシティに余裕があってもリクエストがスロットリングされることがあり、一つ上のインスタンスタイプでクラスタを作り直したところ解消した。 この際、いきなり全リクエストが新クラスタに送られることで膨大なキャッシュミスが発生し、 テーブルのキャパシティを超過したりプライマリーノードに負荷が集中しないように、 Route53で割合で解決されるようにしたが、これはうまく流れてくれた。
挙動確認 DAX/DynamoへリクエストするだけだったらLambdaでも良いが、負荷をかけるのでECS上にアプリケーションをデプロイすることにした。 以前作ったBoilerplateベースで、コードはここ。
ECSでアプリケーションを動かすBoilerplateを作った - sambaiz-net
TableとDAXのClusterを作成。
createDynamoTable() { return new dynamodb.Table(this, &#39;DynamoTable&#39;, { tableName: &amp;quot;dax-test-table&amp;quot;, partitionKey: { name: &#39;id&#39;, type: dynamodb.AttributeType.STRING }, readCapacity: 50, writeCapacity: 50, }); } createDaxCluster(subnetIds: string[]) { const subnetGroup = new dax.</description>
    </item>
    
    <item>
      <title>ECSでアプリケーションを動かすBoilerplateを作った</title>
      <link>https://www.sambaiz.net/article/259/</link>
      <pubDate>Mon, 24 Feb 2020 16:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/259/</guid>
      <description>https://github.com/sambaiz/ecs-boilerplate
ECS上でアプリケーションを動かすBoilerplateを作った。CDKでデプロイする。以前Digdagを動かしたときのを汎用的にしたもの。
CDKでECS+Fargate上にDigdagを立ててCognito認証を挟む - sambaiz-net
new ECSStack(app, &#39;ECSBoilerplateSampleStack&#39;, { /* // If vpcAttributes is not specified, new VPC is created. vpcAttributes: { vpcId: &#39;&#39;, availabilityZones: [], publicSubnetIds: [], privateSubnetIds: [], }, // DNS record. Even if this is not specified, you can access with ELB domain (***.elb.amazonaws.com) route53: { zoneId: &#39;&#39;, zoneName: &#39;example.com&#39;, recordName: &#39;foo&#39;, }, // Certificate Manager ARN. Required if accessing with HTTPS acmArn: &#39;arn:aws:acm:****&#39; // default values containerPort: 8080, cpu: 256, memoryLimitMiB: 512, minCapacity: 1, maxCapacity: 5, scaleCPUPercent: 80 */ }); CDKがECRへのpushまでやってくれるのでcdk deployすれば動き始め、削除するときもStackを消せばよい。</description>
    </item>
    
    <item>
      <title>AndroidのListViewで再利用されるViewのgetGlobalVisibleRect()が意図した値を返さない</title>
      <link>https://www.sambaiz.net/article/257/</link>
      <pubDate>Tue, 11 Feb 2020 01:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/257/</guid>
      <description>ListViewのViewの再利用 まずはListViewのViewが再利用されていることを確認する。
package com.example.listviewglobalvisiblerect import android.widget.BaseAdapter import android.content.Context import android.view.View import android.view.ViewGroup import android.app.Activity import android.graphics.Color import android.graphics.Rect import android.util.Log import android.widget.TextView data class SampleData(val id: Long, val value: String) class SampleAdapter: BaseAdapter { private val context: Context private val items: List&amp;lt;SampleData&amp;gt; private val views = ArrayList&amp;lt;View&amp;gt;() constructor(context: Context, items: List&amp;lt;SampleData&amp;gt;) { this.context = context this.items = items } override fun getCount(): Int { return items.size } override fun getItem(position: Int): Any { return items.</description>
    </item>
    
    <item>
      <title>Buildkitとは</title>
      <link>https://www.sambaiz.net/article/258/</link>
      <pubDate>Tue, 11 Feb 2020 01:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/258/</guid>
      <description>Buildkitは高速でセキュアなコンテナイメージのビルドツール。 Docker本体にも18.09から統合され、 DOCKER_BUILDKIT=1 docker build するとBuildkitが使われるようになった。
LLB (low-level builder) BuildkitはDockerfileなどをLLBという中間言語にコンパイルする。 LLBは依存関係を表すDAG(Directed acyclic graph; 有向非巡回グラフ)で、 protobufで定義されている。 これによって処理を並列に実行したり、Dockerfileを変更してもそれ以降のステージのキャッシュを全て破棄する必要がなくなった。
--mount=type=cache Dockerfileを変更しても残せるキャッシュ。
# syntax = docker/dockerfile:1.1-experimental FROM golang RUN --mount=type=cache,target=/root/.cache/go-build \ go build ... --mount=type=secret 秘密鍵など一度ADDしてしまったファイルは最終的に消してもレイヤ上に残ってしまうが、--mount=type=secret でマウントすると残らない。
# syntax = docker/dockerfile:1.1-experimental FROM alpine:20200122 RUN apk add --no-cache git openssh RUN --mount=type=secret,id=ssh,dst=/root/.ssh/id_rsa \ ssh-keyscan -H github.com &amp;gt;&amp;gt; /root/.ssh/known_hosts &amp;amp;&amp;amp; \ git clone ... $ DOCKER_BUILDKIT=1 docker build --secret id=ssh,src=./id_rsa . 参考 Introducing BuildKit - Moby Blog</description>
    </item>
    
    <item>
      <title>SwiftでGCDのDispatchQueueに処理を投げて並列実行させる</title>
      <link>https://www.sambaiz.net/article/256/</link>
      <pubDate>Sat, 25 Jan 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/256/</guid>
      <description>GCD (Grand Central Dispatch)はmacOSやiOSのマルチコア環境で、 効率的に並列処理を実行するための仕組み。 OperationQueueというのもあるが、これもGCD上で動く。
DispatchQueue 処理をどのスレッドで実行するか管理するキュー。 どこからでも参照できるmainとglobalのキュー以外に新しくキューを作成することもできる。 labelは衝突しないようにreverse-DNS nameにすることが推奨されている。
DispatchQueue.main.async {} DispatchQueue.global(qos: .default).async {} DispatchQueue.global(qos: .background).async {} DispatchQueue(label: &amp;quot;net.sambaiz.serial_dispatch_queue&amp;quot;).async {} DispatchQueue(label: &amp;quot;net.sambaiz.concurrent_dispatch_queue&amp;quot;, attributes: .concurrent).async {} sync/async ブロッキングするsync()としないasync()。排他制御ではないのに注意。
DispatchQueue.global().async { print(&amp;quot;async&amp;quot;) DispatchQueue.main.sync { print(&amp;quot;sync&amp;quot;) } print(&amp;quot;done&amp;quot;) } print(&amp;quot;run&amp;quot;) run async sync done serial/concurrent 処理を単一のスレッドで行う(serial)か、複数のスレッドで行う(concurrent)かはキューによって決まり、 メインスレッドで動かすmainはserial、globalはconcurrentになっている。 自作のキューの場合は作成時に attributes: .concurrent を渡すとconcurrentになり、渡さないとserialになる。
まずはconcurrentの例から。
for i in 1...3 { DispatchQueue.global().async { print(&amp;quot;start concurrent \(i) thread: \(Thread.current)&amp;quot;) print(&amp;quot;return concurrent \(i) thread: \(Thread.current)&amp;quot;) } } print(&amp;quot;return thread: \(Thread.</description>
    </item>
    
    <item>
      <title>貪欲法(Greedy algorithm)で問題を解く</title>
      <link>https://www.sambaiz.net/article/255/</link>
      <pubDate>Mon, 13 Jan 2020 21:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/255/</guid>
      <description>貪欲法(Greedy algorithm)は問題を分割し、それぞれにおいて貪欲に最適な選択をしていくアルゴリズムの総称。 必ずしも最適解になるとは限らないが、うまくいけば簡潔に計算量を減らすことができる。
Best Time to Buy and Sell Stock II - LeetCode 配列で株価が与えられ、売買して得られる最大の利益を返す問題。
Say you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (i.e., buy one and sell one share of the stock multiple times). Example 1: Input: [7,1,5,3,6,4] Output: 7 Explanation: Buy on day 2 (price = 1) and sell on day 3 (price = 5), profit = 5-1 = 4.</description>
    </item>
    
    <item>
      <title>Objective-CでFrameworkを作りSwiftからimportする</title>
      <link>https://www.sambaiz.net/article/254/</link>
      <pubDate>Sun, 12 Jan 2020 17:41:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/254/</guid>
      <description>Frameworkの作成 New -&amp;gt; ProjectでFrameworkをLanguage Objective-Cで作成。
最低限の実装とHeaderを書いた。このHeaderはBuild PhasesのHeadersにPublicとして登録されている。
 TestObjcFramework.m  #import &amp;lt;Foundation/Foundation.h&amp;gt; void hello() { NSLog(@&amp;quot;hello&amp;quot;); };  TestObjcFramework.h  #import &amp;lt;UIKit/UIKit.h&amp;gt; //! Project version number for TestObjcFramework. FOUNDATION_EXPORT double TestObjcFrameworkVersionNumber; //! Project version string for TestObjcFramework. FOUNDATION_EXPORT const unsigned char TestObjcFrameworkVersionString[]; // In this header, you should import all the public headers of your framework using statements like #import &amp;lt;TestObjcFramework/PublicHeader.h&amp;gt; void hello(void); arm64(実機)/x86_64(Simulator)両方で使えるUniversal Frameworkをビルドするため、 New -&amp;gt; TargetでAggregateを作成し、Build PhasesのNew Run Script Phaseで、 各環境でxcodebuildしてlipoでUniversal Binaryにする次のスクリプトを追加する。</description>
    </item>
    
    <item>
      <title>C&#43;&#43; STLのContainersとAlgorithms</title>
      <link>https://www.sambaiz.net/article/253/</link>
      <pubDate>Sat, 04 Jan 2020 21:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/253/</guid>
      <description>STL(Standard Template Library)はC++の標準ライブラリ。 その名の通りtemplateで実装され、様々な型で使えるようになっている。
// https://github.com/microsoft/STL/blob/1e8b8d4eef4b2dddeb7533c5231c876383bd0ea6/stl/inc/algorithm#L3501 template &amp;lt;class _RanIt, class _Pr&amp;gt; void sort(const _RanIt _First, const _RanIt _Last, _Pr _Pred) { // order [_First, _Last), using _Pred _Adl_verify_range(_First, _Last); const auto _UFirst = _Get_unwrapped(_First); const auto _ULast = _Get_unwrapped(_Last); _Sort_unchecked(_UFirst, _ULast, _ULast - _UFirst, _Pass_fn(_Pred)); } 以下の例はC++14で、
$ g++-8 -dM -E -x c++ /dev/null | grep -F __cplusplus #define __cplusplus 201402L 全部入りHeader bits/stdc++.h をincludeし、std:: を省略している。
#include &amp;lt;bits/stdc++.h&amp;gt; using namespace std; Containers データを保存するオブジェクト。</description>
    </item>
    
    <item>
      <title>MacのVSCodeでC&#43;&#43;を書く環境構築</title>
      <link>https://www.sambaiz.net/article/252/</link>
      <pubDate>Sat, 04 Jan 2020 01:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/252/</guid>
      <description>Extension  C/C++  を入れてHello Worldを書いたところ、stdio.hが見つからず#includeの行に赤線が付いた。
#include &amp;lt;stdio.h&amp;gt; int main(void) { printf(&amp;quot;Hello World!\n&amp;quot;); return 0; } Command Palletteから C/C++: Edit Configurations (JSON) を選ぶと .vscode/c_cpp_properties.json が生成されるので編集していく。
Xcode 10から/usr/includeにHeaderファイルが置かれなくなったようなのでincludePathにXcodeのSDKのパスを追加する。
$ xcode-select --install $ xcrun --show-sdk-path /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk $ ls -l /Library/Developer/CommandLineTools/SDKs/ total 0 drwxr-xr-x 7 root wheel 224 7 23 08:49 MacOSX.sdk lrwxr-xr-x 1 root wheel 10 7 23 08:48 MacOSX10.14.sdk -&amp;gt; MacOSX.sdk $ ls /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/ | grep &amp;quot;stdio.h&amp;quot; _stdio.h stdio.h ついでにcompilerPathをclangにした。これはIntelliSenseをうまく働かせるための設定らしい。 clangはLLVMバックエンドのC/C++コンパイラで、Macだとgccコマンドもclangを指すようになっている。</description>
    </item>
    
    <item>
      <title>動的計画法(DP)で計算結果を再利用して計算量を減らす</title>
      <link>https://www.sambaiz.net/article/251/</link>
      <pubDate>Mon, 30 Dec 2019 19:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/251/</guid>
      <description>動的計画法(DP, Dynamic Programming)は記録した計算結果を、帰納的に求められるより大きな計算で利用するアルゴリズムの総称。 例えば、フィボナッチ数列の項f(x)を求めるのに、f(x-1)とf(x-2)の結果を記録しておけばそれらを足すだけで済む。
いくつか問題を解いてみる。
Longest Common Subsequence 最長共通部分列問題。
Given two strings text1 and text2, return the length of their longest common subsequence. Example 1: Input: text1 = &amp;quot;abcde&amp;quot;, text2 = &amp;quot;ace&amp;quot; Output: 3 Explanation: The longest common subsequence is &amp;quot;ace&amp;quot; and its length is 3. 単純に毎回一から探索するとO(n^3)になるが、 ヒントにあるように、それぞれの文字列に1文字足したときに それが同じ文字ならその分伸ばした DP[i - 1][j - 1] + 1 となり 違う文字ならそのまま max(DP[i - 1][j], DP[i][j - 1]) となる ことに気付けると毎回探索しなくてよくなりO(n^2)にできる。
class Solution { public: int longestCommonSubsequence(string text1, string text2) { vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; DP(text1.</description>
    </item>
    
    <item>
      <title>LA,ディズニーランドからre:Inventに参加しグランドキャニオンへドライブしてきた</title>
      <link>https://www.sambaiz.net/article/250/</link>
      <pubDate>Sun, 22 Dec 2019 23:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/250/</guid>
      <description>一昨年、去年と参加したGoogle I/Oのチケットが今年は当たらなかったので、前から行ってみたかったAWSのre:Inventに参加することにした。 会場はラスベガスで、会期は12/2-6。前後の土日ともう2日つなげて現地時間10日間の旅程にした。 去年、カナダのバンクーバーから西海岸のシアトル、ポートランド、サンフランシスコは巡ったので、今回はまだ訪れていないロサンゼルスからスタートすることにした。会期後はグランドキャニオンまで足を伸ばす。
準備 例年通りExpediaで航空券と宿を取り、加えてラスベガスからグランドキャニオンへ行くためにレンタカーを予約した。 I/O会期中のシリコンバレー近辺とは異なり、ラスベガスのホテルは本当に安くて、OYO(元フーターズ)が一泊2千円で取れた。 re:Inventは65000人規模のイベントなんだが現地のUberドライバー曰く、最大20万人規模のイベントもやったりするらしいのでキャパシティは十分そうだ。 多くの人が申し込むJTBのツアーはホテルのグレードを考えてもかなり割高に感じた。
LAでは北のハリウッド、南のアナハイム、ディズニーランドまで行くことを考えてダウンタウンに宿を取った。 価格だけで選ぶとスキッド・ロウといった危ないエリアの近くになりかねないので注意が必要だ。 ディズニーのチケットも事前に購入した。2パークいけるパークホッパーチケットに、色々な特典を含むMaxPassを付けて$214。 高い日のPeak料金ではあるんだが、家族連れで来たら大変じゃないかと思う。
ラスベガスといえばカジノとショーの街だというし、シルク・ドゥ・ソレイユ Oのチケットを買った。 チケットを印刷するのを忘れていたので現地のFedex Officeで印刷した。ファイルを添付してメールを送るとコードが送られてくるので、それを印刷機に入力するだけで簡単。
アメリカでの運転は初めてで往復できるか不安だったので、グランドキャニオンの南、フラッグスタッフという町の空港で乗り捨てられるAlamoで予約した。 日本でも5年は走っていないペーパードライバーなので、2時間出張教習してもらい、後はタイムズのカーシェアで練習した。 それと免許センターで国際免許を発行した。特に試験とかはなくて手数料だけ払えばもらえる。警察署でも発行してくれるようだが即日発行ではないようだ。
今回のSIMはこれ。
Amazon.co.jp： 【AT&amp;amp;T】ハワイ・アメリカ本土 プリペイドSIM 30日 データ容量8GB 大容量通話付き: 家電・カメラ
回線はAT&amp;amp;Tで、30日、8GB、テザリング可で電話もできる(香港の番号だが国際通話ができる)と、申し分ないスペックに対して安すぎるのが若干不安だったが、 ドキュメント通り現地でSIMを挿してAPNを作成したらすぐにつながり、その後も全く問題なかった。すごい。
LA/ディズニーランド 行きの航空券が関空乗り継ぎだった。国内線スタートの良いところは搭乗時間の締め切りが国際線よりはるかに緩いことで、実際それに救われた。
10時間ほどのフライトでLAXに到着。Lax-itというライドシェア用の乗り場を目指す。 国際線ターミナルからは逆のところにあるので、ひっきりなしに走っているシャトルバスに乗る。 Uberをこの辺りに呼ぶとLax-it内のポート番号が表示される仕様だ。
ホテルにチェックイン後、Cole&amp;rsquo;sという店のDip sandwitchを食べに行く。サンドイッチを肉汁のスープに浸して食べる。 カフェみたいなのをイメージしていったら酒場で緊張した。
地下鉄でハリウッドに移動。運賃はTapというカードにチャージする仕組み。 持ってなかったら$2くらい余分に払うと自販機から出てくる。距離に関係なく同一運賃。 このカードでMetroのバスにも乗れるが、バスではチャージできないそうなので乗る場合は少し余分に入れておく。 ただ、結局バスは乗らなかった。ディズニーランド行きのバスもあっておそらく最安なんだが、 Localなのでとても時間がかかるし、サウス・ロサンゼルスというこれまた治安悪いエリアを突っ切るのが怖かったからだ。
ハリウッドではWalk of Fameの有名人の名前プレートを見ながら散歩していた。途中ハリウッドサインが見えたが想像していたより遠い。
せっかくなのでビバリーヒルズのロデオドライブにも行ってきた。表参道みたいな感じであまり用がなかった。
次の日はディズニーランドに行く前にGrand Central MarketのEggslutで朝食を取った。8時開店で8時半には着いたんだが、既に20人くらいの行列ができている人気店だ。 よく分からなかったのでslutというのを注文した。食べるまで気づかなかったんだが星野珈琲のモーニングのあれだ。美味しい。
Uberでディズニーランドに向かう。そういえばアプリ入れてないなと思ってPlayストアで調べたがひっかからない。もしやと思って調べてみると
は？？しょうがないのでアカウントの地域をアメリカに切り替えて入れた。1年間変更できず、日本向けのアプリをダウンロードできなくなった。納得いかない。 ともあれ、これでアプリからファストパスが取れるようになった。ファストパスは30分に1回取れるが、既に持ってるものを消費しなくてはいけない。 人気のアトラクションはかなり先の時間になってしまうか取れなくなってしまうので、 東京と同様のアトラクションが結構あるディズニーランドパークよりカリフォルニアアドベンチャーの方を先に回った方が良さそう。 ただ、パークの方でもスターウォーズのエリアはかなり作り込んであって新鮮だし、写真を撮ってくれる人もいるので暗くなる前に行くべきかもしれない。 撮ってもらった写真はMaxPassならアプリからダウンロードできる。一人って言ったら、&amp;ldquo;Oh, Solo&amp;quot;って言われたのにうまく反応できなくて悔しい。
カリフォルニアアドベンチャーの方はカーズのアトラクションが一番人気で、ファストパスを取るならそれが最有力だと思う。 スピード感がありながらフワッとする感じはなくて楽しかった。 撮影ポイントがあって出たところのモニターにアプリに入力するコードが表示されているんだが、 切り替わるのが早すぎるので、カメラで撮るなりして一旦コードだけ控えておいたほうが良い。 あとミッキーの顔が書かれた観覧車にも乗った。Swingするのに乗ったら、それこそバイキングかってぐらい揺らしてきて 泣きそうになった。実際泣き出す子もいると思う。
パークの城が東京で見るのと違うなと思ったら、こっちの城はシンデレラ城じゃなくて眠れる森の美女の城らしい。
行きのUberは$40くらいだったのに対して帰りは$60くらいかかった。需要と供給だ。
ラスベガス/re:Invent re:Invent前日にLAXからLASへ。 もう降りたところからスロットマシンが置いてあってさすがカジノの街だ。ここのUber乗り場はパーキングにある。</description>
    </item>
    
    <item>
      <title>SwiftのError enumとtry, if case</title>
      <link>https://www.sambaiz.net/article/249/</link>
      <pubDate>Sun, 24 Nov 2019 23:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/249/</guid>
      <description>Error Handling — The Swift Programming Language (Swift 5.1)
SwiftではErrorをenumで列挙でき、次の例でいうsomeParamのようにAssociated valuesを含めることもできる。 throwすると他の言語ではスタックトレースを作るので重い処理になるが、Swiftは作らないのでreturnするようにエラーを返せる。
import UIKit enum SampleError: Error { case ReasonFoo case ReasonBar(someParam: Int) } func errorFunc() throws -&amp;gt; String { throw SampleError.ReasonBar(someParam: 100) } throws付きの関数を呼ぶ際はdo-catchするtryか、nilが返るtry?、落ちるtry!のいずれかを付ける。 Associated valuesがある場合、==は使えず、if case .ReasonBar = errorのように比較する。
do { try errorFunc() } catch SampleError.ReasonFoo { print(&amp;quot;foo!&amp;quot;) } catch SampleError.ReasonBar(let someParam) { print(&amp;quot;bar! \(someParam)&amp;quot;) // =&amp;gt; bar! 100 } do { try errorFunc() } catch let error { if case .</description>
    </item>
    
    <item>
      <title>SwiftのXMLParser</title>
      <link>https://www.sambaiz.net/article/248/</link>
      <pubDate>Sun, 24 Nov 2019 23:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/248/</guid>
      <description>SwiftのXMLParserはイベント駆動のparser。
import UIKit class ParserSample: NSObject { private let parser: XMLParser init(data: Data) { parser = XMLParser(data: data) super.init() parser.delegate = self } func parse() { guard parser.parse() else { guard let err = parser.parserError else { print(&amp;quot;parse error but unknown reason&amp;quot;) return } print(&amp;quot;parse error: \(err.localizedDescription)&amp;quot;) return } print(&amp;quot;after parse()&amp;quot;) } } XMLParserDelegateでイベントを拾ってオブジェクトに詰めるなりする。全て実装する必要はなく、この例ではタグの開始と文字列、CDATA、エラー、パース終了時の関数を実装している。
extension ParserSample: XMLParserDelegate { func parser(_ parser: XMLParser, didStartElement elementName: String, namespaceURI: String?, qualifiedName qName: String?, attributes attributeDict: [String : String] = [:]) { print(&amp;quot;parsing &amp;lt;\(elementName)&amp;gt;&amp;quot;) if elementName == &amp;quot;ERROR&amp;quot; { self.</description>
    </item>
    
    <item>
      <title>ECS(EC2)のCloudFormation最小構成</title>
      <link>https://www.sambaiz.net/article/247/</link>
      <pubDate>Fri, 15 Nov 2019 20:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/247/</guid>
      <description>EC2でECSのServiceを動かすCFnテンプレートを書く。以前Fargateで動かしたものを一部再利用する。
ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する - sambaiz-net
EC2で動かす場合、自分でリソースが不足しないようにインスタンスのスケールを気遣うことになるが、VPC外での実行やprivilegedをtrueにするなどEC2でしかできないことがある。あと同リソースで比較すると安い。
まずはEC2インスタンス以外のリソースを書く。LaunchType以外はFargateのときとほぼ同じ。 LBなしでバッチのようなものを動かすことを想定した最小構成。
ECSCluster: Type: AWS::ECS::Cluster Properties: ClusterName: &#39;test-cluster&#39; LogGroup: Type: AWS::Logs::LogGroup Properties: LogGroupName: &#39;test-task-log-group&#39; RetentionInDays: 1 TaskDefinition: Type: AWS::ECS::TaskDefinition Properties: RequiresCompatibilities: - EC2 Cpu: &#39;256&#39; Memory: &#39;512&#39; ContainerDefinitions: - Name: &#39;app&#39; Image: &#39;busybox&#39; EntryPoint: - &#39;sh&#39; - &#39;-c&#39; Command: - &#39;while true; do echo &amp;quot;{\&amp;quot;foo\&amp;quot;:1000,\&amp;quot;time\&amp;quot;:\&amp;quot;2019-05-09T20:00:00+09:00\&amp;quot;}&amp;quot;; sleep 10; done&#39; Essential: &#39;true&#39; LogConfiguration: LogDriver: &#39;awslogs&#39; Options: awslogs-group: !Ref LogGroup awslogs-region: &#39;ap-northeast-1&#39; awslogs-stream-prefix: &#39;app&#39; Environment: - Name: &#39;TZ&#39; Value: &#39;Asia/Tokyo&#39; Volumes: - Name: &#39;varlog&#39; ECSService: Type: AWS::ECS::Service Properties: Cluster: !</description>
    </item>
    
    <item>
      <title>単調性のある式の解を二分法で数値的に求める</title>
      <link>https://www.sambaiz.net/article/246/</link>
      <pubDate>Mon, 28 Oct 2019 22:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/246/</guid>
      <description>AtCoder Beginner Contest 144の D - Water Bottleをやってみた。
高橋君は、底面が1辺 a cm の正方形であり、高さが b cm であるような直方体型の水筒を持っています。(水筒の厚みは無視できます。) この水筒の中に体積 x cm^3 の水を入れ、底面の正方形の1辺を軸として、この水筒を徐々に傾けます。 水を溢れさせずに水筒を傾けることができる最大の角度を求めてください。 水を溢れさせずに水筒を傾けることができる最大の角度を度数法で出力せよ。 出力は、ジャッジの出力との絶対誤差または相対誤差が10^6以下のとき正解と判定される。 水が溢れるパターンは次の2通りあって、水が入っている、または入ってない部分の三角柱を除いた部分の体積がxになるようなθをatanで出せる。
解説を見ると、これに加えて二分法を使って数値的に求める解法も紹介されていた。 二分法というのは解が含まれる区間の中間での値を求め、その値が解より小さいか大きいかによって二分したどちらかの区間を選ぶ操作を繰り返すことで区間の幅を狭めて解を求めるアルゴリズム。収束条件として式に単調性がある必要があるが、θに対してこぼれる限界の水の体積の式は単調減少するので用いることができる。 解説にもコードが付いていたがまずは見ずに書いてみた。
#include &amp;lt;iostream&amp;gt; #include &amp;lt;cmath&amp;gt; #include &amp;lt;iomanip&amp;gt; using namespace std; double waterVolume(int a, int b, double rad) { if (rad &amp;lt; atan(1.0 * b / a)) { return a * a * b - (a * (a * tan(rad)) / 2 * a); } else { return b * (b * tan(M_PI / 2 - rad)) / 2 * a; } } int main() { double a, b, x; cin &amp;gt;&amp;gt; a &amp;gt;&amp;gt; b &amp;gt;&amp;gt; x; double min = 0, max = M_PI / 2; while (true) { double m = (min + max) / 2; double vol = waterVolume(a, b, m); if (abs(vol - x) &amp;lt; pow(10, -6)) { cout &amp;lt;&amp;lt; setprecision(8) &amp;lt;&amp;lt; m / M_PI * 180 &amp;lt;&amp;lt; endl; return 0; } else if (vol &amp;gt; x) { min = m; } else { max = m; } } } 解説のコードでは、パターンの判定でa * tan(theta) &amp;lt;= bを使っているのと、有限回のループでxを上回らない最大のθを探すようになっていた。</description>
    </item>
    
    <item>
      <title>goyaccでparserを生成しLispのcons,car,cdrの式を評価する</title>
      <link>https://www.sambaiz.net/article/244/</link>
      <pubDate>Tue, 15 Oct 2019 09:41:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/244/</guid>
      <description>GoでLispのcons,car,cdrの式を評価したい。 流れとしては字句解析器(lexer, tokenizer, scanner)でソースコードを分割しtoken列にして、構文解析器(parser)で構文木を作るなりして評価できるようにする。
$ brew install clisp $ clisp &amp;gt; (cons 1 ()) (1) &amp;gt; (cons () 1) (NIL . 1) &amp;gt; (car (cons 1 (cons 2 3))) 1 &amp;gt; (cdr (cons 1 (cons 2 3))) (2 . 3) Goの字句解析器と構文解析器 Goの字句解析器と構文解析器がGoが実装されているので見てみる。
go/scanner ソースコードを分割してgo/tokenにする。
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;go/token&amp;quot; &amp;quot;go/scanner&amp;quot; ) func main() { var sc scanner.Scanner src := []byte(`(&amp;quot;A&amp;quot; + &amp;quot;B&amp;quot;) + &amp;quot;C&amp;quot;`) errorHandler := func(pos token.Position, msg string) { fmt.</description>
    </item>
    
    <item>
      <title>ISUCON9予選と本選に出た</title>
      <link>https://www.sambaiz.net/article/243/</link>
      <pubDate>Sat, 05 Oct 2019 23:41:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/243/</guid>
      <description>ISUCONはLINEが運営しているIikanjini Speed Up CONtestで、Webサービスをチューニングしベンチマークのスコアを競う。 @hiderberqと@satoshunと出た。初出場。
前 @hiderberqに誘ってもらいチームSsstohが結成された。言語はGoで行くと決めて3回くらい集まって過去問を少しやった。
予選 会社が計画停電だったので話せるネットカフェでやった。 デプロイスクリプトを整えてnginxのアクセスログをalpで見られるようにする準備や MySQLのSlow Queryを出すところまでは良かったが、pprofのエンドポイントを叩くタイミングが悪くて profileが出力できずbcryptがボトルネックであることに最後まで気づけなかった。 最後そろそろ複数マシンで動かすかという段になったが、時間があまり残っていなかったしうまく動かすことができなかった。急いでやって最後のベンチマークがFailするよりはましだったかもしれない。仕様をたいして読まなかったのでキャンペーンの数値が変えられることも忘れていた。仕様を読み込むのは本当に重要。 これはだめだなと思ったらなぜか通過していた。600チーム中20位だ。ありがとう@satoshun。
ISUCON9 予選ログ - stsnブログ
間 pprofやnginxのLB、あとMySQLのEXPLAINを練習した。あとAPMを用意していった。
K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする - sambaiz-net
本選 本選はLINE本社、新宿のミライナタワーで行われる。ミライナタワー改札というのがあってアクセスが良い。 会場のカフェスペースもソファー席や座敷もあったりして良いスペースだった。
受付でかっこいいTシャツとイカしたステッカーを獲得。
ベンチマークが最初からFailするようになってて大変だった。 急いで開発したという設定で、コードや設定に不要なものが多く含まれていて翻弄された。 ロジックが複雑でこれを何とかしないと始まらないのではと思ったが、インデックスによってFailしなくなったのでそんなことはなかった。
昼には弁当が来た。美味しい。
午後はサーバーを1台再起不能にした。あとはN+1をやって終了。表彰と講評。ブラウザチェックNGで参考記録になったが、スコアは3611で17位相当だった。 1位の白金動物園は35801、2位のnilは29704(しかも一人で)とスコアを見ると全くかなわないという感じ。 ただN+1やインデックスなど基本的なところは押さえていたようだったので、まずはそのステージを超えなくてはいけなかった。 また一通りインメモリにデータを持ったら負荷のパラメータである日数を伸ばしたときにOOMになった。 今回はメモリが少なかったのでSQLの修正でスコアを上げられるようになっていたそうだ。
全てが終わり懇親会が始まった。
感想 普段クラウドのマネージドなサービスや金で解決することに慣れているとこんなに何もできないものかと愕然した。チームの二人には申し訳なさがある。 テーブルの変更などこれやるの億劫だなというところも上位チームは普通にやっていたりして要所の見極めや実装力が足りなかったり、 なんでこれができなかったんだというポイントが多々あるので練度が低く、本番の焦燥感に打ち負けた。 その点では本選まで来れたことは今後の資産になるだろうし、とても楽しかったので実質優勝だ。嬉しい。 運営にも感謝だ。</description>
    </item>
    
    <item>
      <title>HTTPのCache-Control Header</title>
      <link>https://www.sambaiz.net/article/242/</link>
      <pubDate>Fri, 04 Oct 2019 14:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/242/</guid>
      <description>HTTPでCache-Control Headerを付けてレスポンスすると、 クライアントにキャッシュさせてリクエストの回数やレスポンスの通信量を削減することができる。CDNによって挙動が異なるようなので注意が必要。
CDN切り替え作業における、Web版メルカリの個人情報流出の原因につきまして - Mercari Engineering Blog
また、Vary Headerで クライアントが送るHeaderの値が前回と異なる場合にリクエストが送られるようにでき、 Access-Control-Allow-Origin でOriginの値を返す場合、Vary: Origin のようにしないと 他のOriginからのリクエスト時にキャッシュされたHeaderを読んでしまいCORSエラーになってしまう。
max-age キャッシュが有効な秒数を表す。s-maxageというのもあってこれはプロキシやCDNといった共有キャッシュでのみ適用される時間。 Expires Headerがあったとしてもこれらが優先される。
Cache-Control: max-age=30 private 単一ユーザー向けのレスポンスであることを表し、共有キャッシュに保存させないようにする。
Cache-Control: private, max-age=30 no-cache ETag付きのリクエストを毎回投げる。 ETagはリソースの識別子を表すHeaderで、 前回返ってきたETagをリクエストのIf-None-Match Headerで渡すと、変更されてない場合は代わりに304 Not Modifiedが返るのでキャッシュを使い、帯域を節約できる。 つまり文字通りキャッシュされないというわけではなく、304が返ってきたらキャッシュしたデータが使われる。
no-store キャッシュさせない。毎回リクエストが飛びレスポンスが返る。
max-ageもExpires Headerもない場合でもLast-Modified Headerがあれば キャッシュされるのでキャッシュさせたくない場合は明示的に書いたほうがよい。
参考 HTTP キャッシュ | Web Fundamentals | Google Developers
IPA ISEC　セキュア・プログラミング講座：Webアプリケーション編　第5章 暴露対策：プロキシキャッシュ対策</description>
    </item>
    
    <item>
      <title>K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする</title>
      <link>https://www.sambaiz.net/article/241/</link>
      <pubDate>Tue, 01 Oct 2019 23:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/241/</guid>
      <description>Elastic Cloud on Kubernetes (ECK)で Kubernetesクラスタ上にElasticsearch, KibanaとAPM Serverを立ち上げ、外部のGo製APIサーバーのリクエストをトレースする。 クラスタはGKEで作成し、ノードプールはn2-highmem-4(2vCPU, 13GB)の3台にした。
インストール ElasticSearchやKibana, APM ServerのCRDやelastic-operatorなどをインストールする。
KubernetesのCustom Resource Definition(CRD)とCustom Controller - sambaiz-net
$ kubectl apply -f https://download.elastic.co/downloads/eck/0.9.0/all-in-one.yaml customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/trustrelationships.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created clusterrole.rbac.authorization.k8s.io/elastic-operator created clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created namespace/elastic-system created statefulset.apps/elastic-operator created secret/webhook-server-secret created serviceaccount/elastic-operator created $ kubectl get pod -n elastic-system NAME READY STATUS RESTARTS AGE elastic-operator-0 1/1 Running 1 91s $ kubectl -n elastic-system logs -f statefulset.apps/elastic-operator ... {&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1569230702.0881083,&amp;quot;logger&amp;quot;:&amp;quot;kubebuilder.controller&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;Starting workers&amp;quot;,&amp;quot;controller&amp;quot;:&amp;quot;elasticsearch-controller&amp;quot;,&amp;quot;worker count&amp;quot;:1} {&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1569230702.</description>
    </item>
    
    <item>
      <title>MySQLのslow queryを出してEXPLAINしてインデックスを張る</title>
      <link>https://www.sambaiz.net/article/240/</link>
      <pubDate>Sat, 21 Sep 2019 22:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/240/</guid>
      <description>MySQLのslow queryを出してEXPLAINしてインデックスを張るのを ISUCON9の予選問題でやってみる。
$ mysql --version mysql Ver 8.0.17 for osx10.14 on x86_64 (Homebrew) slow_query_logをONにすると実行時間がlong_query_timeを超えていてmin_examined_row_limit以上の行を返すクエリがslow query logに出力される。 log_queries_not_using_indexesが有効ならインデックスを使用してないクエリもログに出て、 log_throttle_queries_not_using_indexesでその分あたりの数を制限できる。 MySQL 8.0.14から追加されたlog_slow_extraをONにするとフィールドが追加される。
mysql&amp;gt; show variables like &#39;%slow%&#39;; +---------------------------+-----------------------------------+ | Variable_name | Value | +---------------------------+-----------------------------------+ | log_slow_admin_statements | OFF | | log_slow_extra | OFF | | log_slow_slave_statements | OFF | | slow_launch_time | 2 | | slow_query_log | OFF | | slow_query_log_file | /usr/local/var/mysql/mbp-slow.log | +---------------------------+-----------------------------------+ 6 rows in set (0.00 sec) mysql&amp;gt; show variables like &#39;%long_query%&#39;; +-----------------+-----------+ | Variable_name | Value | +-----------------+-----------+ | long_query_time | 10.</description>
    </item>
    
    <item>
      <title>Ansibleでnginxを入れてLoad Balancingさせる</title>
      <link>https://www.sambaiz.net/article/239/</link>
      <pubDate>Tue, 17 Sep 2019 09:42:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/239/</guid>
      <description>EC2でUbuntu Server 18.04 LTS (ami-07d0cf3af28718ef8) の t3.medium (2vCPU, 4GiB) インスタンスを3台立ち上げた。この内1台をLB用とし、2台のAppサーバーに負荷分散させる。
https://github.com/sambaiz/ansible-nginx-lb-example
nginx.conf LBとAppのnginx.conf。upstreamはデフォルトでラウンドロビンする。
$ cat conf/lb/nginx.conf ... http { ... upstream app-server { server ip-172-31-94-208.ec2.internal; server ip-172-31-88-90.ec2.internal; } server { listen 80; server_name .compute-1.amazonaws.com; access_log /var/log/nginx/app-server.log main; location / { proxy_pass http://app-server; } } } $ cat conf/app/nginx.conf ... http { ... server { listen 80; server_name .compute-1.amazonaws.com; location / { proxy_pass http://127.0.0.1:8080; } } } Ansibleの実行 まずInventoryを書いて疎通確認する。
$ pip install --user ansible $ cat hosts [lb] ec2-3-227-2-54.</description>
    </item>
    
    <item>
      <title>Goのnet/http/pprofでCPUやMemoryをprofileする流れと内部実装</title>
      <link>https://www.sambaiz.net/article/238/</link>
      <pubDate>Mon, 16 Sep 2019 13:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/238/</guid>
      <description>Goのnet/http/pprofは pprofで可視化できるprofile.protoを返すAPIを提供するpackage。 profileを出力する方法はほかにもあるが、サーバーのような動き続けるアプリケーションのprofileを取るのに使う。
go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる - sambaiz-net
profileを取る import _ &amp;quot;net/http/pprof&amp;quot;してhttp.ListenAndServe()する。
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;net/http&amp;quot; _ &amp;quot;net/http/pprof&amp;quot; &amp;quot;time&amp;quot; &amp;quot;golang.org/x/crypto/bcrypt&amp;quot; ) func handler(w http.ResponseWriter, r *http.Request) { for i := 0; i &amp;lt; 3; i++ { bcrypt.GenerateFromPassword([]byte(&amp;quot;PASSWORD&amp;quot;), bcrypt.DefaultCost) } arr := []int{} for i := 0; i &amp;lt; 10000; i++ { arr = append(arr, i) } fmt.Fprintf(w, &amp;quot;OK&amp;quot;) } func main() { http.HandleFunc(&amp;quot;/foo&amp;quot;, handler) fmt.Println(&amp;quot;Listening on :8080&amp;quot;) if err := http.</description>
    </item>
    
    <item>
      <title>User NamespaceでrootになってNetwork Namespaceを作りvethとNATで外と通信する</title>
      <link>https://www.sambaiz.net/article/237/</link>
      <pubDate>Fri, 06 Sep 2019 02:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/237/</guid>
      <description>LinuxのNamespaceはuidやpid、networkなどを分離できる機能で、Dockerなどのコンテナ技術で使われている。
# Amazon Linux 2 (ami-0ff21806645c5e492) $ uname -r 4.14.138-114.102.amzn2.x86_64 User NamespaceでRootになる rootでないと正常終了しないコードを書いた。
$ cat /tmp/root_only.sh #!/bin/sh if [ &amp;quot;$(id -u)&amp;quot; != &amp;quot;0&amp;quot; ]; then echo &amp;quot;you are not root...&amp;quot; exit 1 fi echo &amp;quot;you are root!&amp;quot; 実際ec2-userではexit 1になる。
$ id -u 1000 $ sh /tmp/root_only.sh; echo $? you are not root... 1 User Namespaceを作る。rootでないとそれ以外のNamespaceは作れない。
$ unshare --net unshare: unshare failed: Operation not permitted $ unshare --user $ id uid=65534(nfsnobody) gid=65534(nfsnobody) groups=65534(nfsnobody) $ echo $$ 3537 他のshellを開き、Namespaceの外側からuid_mapを書き込む。 外側の1000から始まるuidを、このNamespaceの0から始まるuidに範囲1でマッピングする。</description>
    </item>
    
    <item>
      <title>SystemdのService</title>
      <link>https://www.sambaiz.net/article/236/</link>
      <pubDate>Fri, 30 Aug 2019 00:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/236/</guid>
      <description>SystemdはLinuxで動くServiceの管理などを行うデーモン。initの後継でchkconfig/servicceの代わりにsystemctlコマンドを使う。
$ systemctl start name.service $ systemctl stop name.service $ systemctl status name.service $ systemctl enable name.service $ systemctl disable name.service Serviceの一覧を見る。
$ systemctl list-units --type service --all UNIT LOAD ACTIVE SUB DESCRIPTION accounts-daemon.service loaded active running Accounts Service acpid.service loaded active running ACPI event daemon apparmor.service loaded active exited LSB: AppArmor initialization apport.service loaded active exited LSB: automatic crash report generation $ systemctl list-unit-files --type service UNIT FILE STATE accounts-daemon.</description>
    </item>
    
    <item>
      <title>PR上でCDKのレビューやデプロイを行うツールcdkbotを作った</title>
      <link>https://www.sambaiz.net/article/235/</link>
      <pubDate>Thu, 29 Aug 2019 22:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/235/</guid>
      <description>sambaiz/cdkbot
PRのコメントで/diffや/deployと打つとcdk diffやcdk deployが走る。 diffを見てレビューし、良ければ/deployでデプロイし完了するとmergeされる。
以前CircleCIでmerge時にdeployされる仕組みを作った。
CDK/CircleCI/GitHubでAWSリソース管理リポジトリを作る - sambaiz-net
ただ、この仕組みだと CFnの実行時エラーのためにデプロイできない状態のものがmasterブランチにmergeされてしまい、その修正のために何回も試行錯誤のPRを出すことになったり、 Stack間の依存がある場合リソースを削除するとcdk deployによって依存解決された順序だと失敗してしまうという問題があった。 cdkbotでは必要ならデプロイするStackを選べて、完了してからmergeすることでこれらの問題を解決した。 また、AWS外のCIにとても強い権限を与えていたがそれも必要なくなった。
単純にブランチの状態でデプロイしてしまうと古い状態に巻き戻ってしまう可能性があるので、内部でbaseブランチをmergeしていたり、 ラベルによってそのPRがデプロイ可能かどうかを制御していたりする。 最低限デプロイできるようになってから、この辺りの仕組みを整えるまでに存外に時間がかかった。
Serverless Application Repositoryに公開してあるので簡単にインストールできる。
AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net
 追記 (2019-10-26): ap-northeast-1に対応していないのと、ECSのリソースを作成できないため、Serverless Application Repositoryに公開するのはやめた。makeでインストールできる。 Lambda環境でできない処理をECSで実行する - sambaiz-net
 外部コマンド gitやnpmといった外部コマンドを実行する必要があるが、標準では入っていないのでLambda Layerで入れている。
Lambda上でnpm installできるLayerを作った - sambaiz-net
Go moduleのキャッシュ Dockerコンテナ内でテストを実行しているが、毎回go moduleの解決が走ることで時間はかかるし、テザリングの容量に大打撃を受けたので、 ローカルのキャッシュをコピーするようにした。
test: docker build -t cdkbot-npmbin ./npm-lambda-layer docker build -t cdkbot-test -f ./test/Dockerfile . docker rm -f cdkbot-test || true docker run -itd --name cdkbot-test cdkbot-test /bin/sh docker cp .</description>
    </item>
    
    <item>
      <title>CDKでECS&#43;Fargate上にDigdagを立ててCognito認証を挟む</title>
      <link>https://www.sambaiz.net/article/234/</link>
      <pubDate>Wed, 31 Jul 2019 03:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/234/</guid>
      <description>AWSでワークフローエンジンDigdagを立てるにあたりスケールを見越してECS+Fargateで動かす。 全体のコードはGitHubにある。
FargateでECSを使う - sambaiz-net
リソースはCDKで作る。最近GAになったので高レベルのクラスを積極的に使っている。
AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする - sambaiz-net
$ npm run cdk -- --version 1.2.0 (build 6b763b7) VPC FargateなのでVPCが必要。 テンプレートを書くとSubnetやRouteTable、NATGatewayなど記述量が多くなるところだが、CDKだとこれだけで済む。
CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net
const vpc = new ec2.Vpc(this, &#39;VPC&#39;, { cidr: props.vpcCidr, natGateways: 1, maxAzs: 2, subnetConfiguration: [ { name: &#39;digdag-public&#39;, subnetType: ec2.SubnetType.PUBLIC, }, { name: &#39;digdag-private&#39;, subnetType: ec2.SubnetType.PRIVATE, }, { name: &#39;digdag-db&#39;, subnetType: ec2.SubnetType.ISOLATED, } ] }) DB DigdagはPostgreSQLを使う。
const db = new rds.DatabaseCluster(this, &#39;DBCluster&#39;, { engine: rds.</description>
    </item>
    
    <item>
      <title>Lambda上でnpm installできるLayerを作った</title>
      <link>https://www.sambaiz.net/article/233/</link>
      <pubDate>Tue, 23 Jul 2019 23:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/233/</guid>
      <description>Lambda上でnpm installするためにnpmとnode, npmrc入りのLambda Layerを作った。 GitHubにある。
Lambda Layerでバイナリやライブラリを切り出す - sambaiz-net
まずは/usr/bin/npmをそのまま入れて実行してみた。
FROM lambci/lambda-base:build WORKDIR /opt RUN curl -sL https://rpm.nodesource.com/setup_12.x | bash - &amp;amp;&amp;amp; \ yum install -y nodejs &amp;amp;&amp;amp; \ mkdir bin &amp;amp;&amp;amp; \ cp /usr/bin/node bin/node &amp;amp;&amp;amp; \ cp /usr/bin/npm bin/ &amp;amp;&amp;amp; \ zip -yr /tmp/npm-layer.zip ./* $ docker build -t npmbin . $ docker run npmbin cat /tmp/npm-layer.zip &amp;gt; npm-layer.zip &amp;amp;&amp;amp; unzip npm-layer.zip -d layer 相対パスでの参照に失敗したようだが対象のパスが見当たらない。
internal/modules/cjs/loader.js:628 throw err; ^ Error: Cannot find module &#39;.</description>
    </item>
    
    <item>
      <title>Lambda Layerでバイナリやライブラリを切り出す</title>
      <link>https://www.sambaiz.net/article/232/</link>
      <pubDate>Mon, 22 Jul 2019 21:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/232/</guid>
      <description>Lambdaで実行したい外部コマンドがある場合、通常バイナリをパッケージに含めることになりデプロイに時間がかかってしまう。
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;os/exec&amp;quot; &amp;quot;github.com/aws/aws-lambda-go/events&amp;quot; &amp;quot;github.com/aws/aws-lambda-go/lambda&amp;quot; ) func handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) { cmd := exec.Command(&amp;quot;git&amp;quot;, &amp;quot;clone&amp;quot;, &amp;quot;https://github.com/sambaiz/foobar.git&amp;quot;, &amp;quot;/tmp/repo&amp;quot;) output, err := cmd.CombinedOutput() if err != nil { return events.APIGatewayProxyResponse{ Body: fmt.Sprintf(&amp;quot;%s %s&amp;quot;, string(output), err.Error()), StatusCode: 500, }, nil } return events.APIGatewayProxyResponse{ Body: string(output), StatusCode: 200, }, nil } func main() { lambda.Start(handler) } exec: &amp;quot;git&amp;quot;: executable file not found in $PATH Lambda Layerを使うと ライブラリやバイナリを切り出すことができ、複数Functionで共有することもできる。 ディレクトリをzipにしてLayerに指定すると中身が/optに展開され、/opt/binにはPATHが、/opt/libにはLD_LIBRARY_PATHが通るほか、 言語ごとのパッケージ置き場がある。</description>
    </item>
    
    <item>
      <title>AWS SAMとGoでPRのコメントに対して返事を返すGitHub Appを作る</title>
      <link>https://www.sambaiz.net/article/231/</link>
      <pubDate>Fri, 19 Jul 2019 21:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/231/</guid>
      <description>GitHub Appはリポジトリにインストールできるアプリケーションで、 Access TokenやOAuth Appと異なり ユーザーとは独立した権限を与えて実行することができる。
今回はPRの特定のコメントに反応して返事を返すAppを作る。
AWS SAMでデプロイする。全体のコードはGitHubにある。
AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net
GitHub Appの作成 Settings &amp;gt; Developer settings から作成できる。いろいろ項目はあるが、NameとHomepage URL、Webhook URLを入れればひとまず作成はできる。 Webhook URLはあとで決まるので適当な値を入れておく。必須にはなっていないがリクエストを検証するため適当なWebhook secretも入れる。 PermissionsはPull requestsではなくIssueのRead &amp;amp; Writeが必要で、 さらにそうすると表示されるようになるSubscribe to eventsのIssue commentにチェックを入れる。
作成すると秘密鍵がダウンロードできるのでSecretsmanagerに上げておき、LambdaのRoleにもこれを取得できるRoleを付ける。
AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する - sambaiz-net
$ aws secretsmanager create-secret --name GitHubCdkAppSecretKey --secret-string $(cat private-key.pem) Policies: - PolicyName: read-cdk-github-app-secret-key PolicyDocument: Version: &amp;quot;2012-10-17&amp;quot; Statement: - Effect: Allow Action: secretsmanager:GetSecretValue Resource: &amp;lt;secret-key arn&amp;gt; Webhooksのリクエスト内容 設定でチェックを入れたeventが起きると次のようなリクエストが送られてくる。 Headerの X-GitHub-Event によってbodyの中身が決まり、 X-Hub-Signature と、bodyと設定したWebhook secretから生成したHMACのMAC値を比較することで リクエストを検証することができる。</description>
    </item>
    
    <item>
      <title>KaggleのHouse Prices CompetitionをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/230/</link>
      <pubDate>Tue, 09 Jul 2019 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/230/</guid>
      <description>以前TitanicをやったXGBoostでHome Prices Competitionに挑戦する。
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
import pandas as pd df_train = pd.read_csv(&#39;house-prices/train.csv&#39;) df_test= pd.read_csv(&#39;house-prices/test.csv&#39;) 欠損値の処理 以前確認したように欠損値が含まれるので一つずつ見ていって埋めていく。
KaggleのHome Prices CompetitionのKernelからデータの探り方を学ぶ - sambaiz-net
import numpy as np def fillna(df): # PoolQC: Pool quality print(np.unique(df[&#39;PoolQC&#39;].values.tolist())) # [&#39;Ex&#39; &#39;Fa&#39; &#39;Gd&#39; &#39;nan&#39;] df[&amp;quot;PoolQC&amp;quot;] = df[&amp;quot;PoolQC&amp;quot;].fillna(&amp;quot;None&amp;quot;) # MiscFeature: Miscellaneous feature not covered in other categories print(np.unique(df[&#39;MiscFeature&#39;].values.tolist())) # [&#39;Gar2&#39; &#39;Othr&#39; &#39;Shed&#39; &#39;TenC&#39; &#39;nan&#39;] df[&amp;quot;MiscFeature&amp;quot;] = df[&amp;quot;MiscFeature&amp;quot;].fillna(&amp;quot;None&amp;quot;) # Alley: Type of alley access print(np.unique(df[&#39;Alley&#39;].values.tolist())) # [&#39;Grvl&#39; &#39;Pave&#39; &#39;nan&#39;] df[&amp;quot;Alley&amp;quot;] = df[&amp;quot;Alley&amp;quot;].</description>
    </item>
    
    <item>
      <title>ColabでKaggleのAPIを呼んで学習データのダウンロードと提出を行う</title>
      <link>https://www.sambaiz.net/article/229/</link>
      <pubDate>Tue, 09 Jul 2019 01:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/229/</guid>
      <description>Colabではランタイムがリセットされるたびにファイルが消えてしまうのでその度に学習データをアップロードするのが面倒。 そこでKaggle APIでファイルを持ってきてついでに提出まで行う。
Notebookを公開することも考えてなるべく認証情報を直書きしたくないのでGoogle DriveをマウントしてそこからTokenを持ってくることにする。 KaggleのMy AccountからAPI Tokenを発行しGoogle Driveに上げておく。
from google.colab import drive drive.mount(&#39;/content/gdrive&#39;) ! mkdir -p ~/.kaggle ! cp &amp;quot;gdrive/My Drive/kaggle/kaggle.json&amp;quot; ~/.kaggle/ ! pip install kaggle --upgrade ! kaggle config view competitions downloadでファイルをダウンロードしてくる。
! kaggle competitions download house-prices-advanced-regression-techniques -p house-prices import pandas as pd df_train = pd.read_csv(&#39;house-prices/train.csv&#39;) df_test= pd.read_csv(&#39;house-prices/test.csv&#39;) competitions submitで提出し、 competitions submissionsで提出履歴とスコアが見える。 リーダーボードはcompetitions leaderboardで取得できる。
! kaggle competitions submit house-prices-advanced-regression-techniques -f submit.csv -m &amp;quot;test submission&amp;quot; ! kaggle competitions submissions house-prices-advanced-regression-techniques !</description>
    </item>
    
    <item>
      <title>Cognito UserPoolのPreSignUp時に呼ばれるLambdaで登録ユーザーを制限する</title>
      <link>https://www.sambaiz.net/article/228/</link>
      <pubDate>Sun, 07 Jul 2019 17:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/228/</guid>
      <description>サードパーティのIdPからCognitoにSignUpできるようにする場合、特定のドメインのメールアドレスといったような制限をかけたいことがある。 PreSignUp時のLambdaでこれを弾いてやることでUserPoolに入らないようにすることができる。
Lambda CognitoEventUserPoolsPreSignupを受け取って返す。
package main import ( &amp;quot;errors&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;github.com/aws/aws-lambda-go/events&amp;quot; &amp;quot;github.com/aws/aws-lambda-go/lambda&amp;quot; ) func handler(event events.CognitoEventUserPoolsPreSignup) (events.CognitoEventUserPoolsPreSignup, error) { fmt.Printf(&amp;quot;PreSignup of user: %s\n&amp;quot;, event.UserName) if event.Request.UserAttributes[&amp;quot;email&amp;quot;] != &amp;quot;godgourd@gmail.com&amp;quot; { return event, errors.New(&amp;quot;Forbidden&amp;quot;) } return event, nil } func main() { lambda.Start(handler) } リソース UserPoolのLambdaConfigでトリガーを設定できる。 CognitoからLambdaを呼べるPermissionが必要。
UserPool: Type: AWS::Cognito::UserPool Properties: ... LambdaConfig: PreSignUp: !GetAtt PresignupLambdaFunction.Arn UserPoolLambdaInvokePermission: Type: AWS::Lambda::Permission Properties: Action: lambda:invokeFunction Principal: cognito-idp.amazonaws.com FunctionName: !GetAtt PresignupLambdaFunction.Arn SourceArn: arn:aws:cognito-idp:&amp;lt;region&amp;gt;:&amp;lt;account_id&amp;gt;:userpool/* なおALBのActionでCognito認証を入れると登録失敗時に500エラーになってしまう。これを回避するには自前でやるしかないのかもしれない。
LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net</description>
    </item>
    
    <item>
      <title>LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす</title>
      <link>https://www.sambaiz.net/article/227/</link>
      <pubDate>Wed, 03 Jul 2019 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/227/</guid>
      <description>ALBのTargetとしてLambdaが選択できるようになり、 若干の時間課金が発生する代わりに柔軟にルーティングできるAPI Gatewayのように使えるようになった。 ActionとしてCognito認証を入れて認証に失敗したらログイン画面を表示させる。
API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く - sambaiz-net
ACMで証明書を発行する HTTPSでListenするため証明書が必要。 AWS Certificate Manager (ACM)でAWSで使える証明書を無料で発行でき参照できる。 外部で取ったドメインでもよい。 検証方法はDNSとメールとで選ぶことができて、DNSで行う場合Route53ならワンクリックで検証用のCNAMEレコードを作成できる。 検証までやや時間がかかるのでちゃんと通ってるかnslookupで確認しといた方がよい。
Application Load Balancer (ALB) 次の要素から構成されるL7のロードバランサー。
 Listener: 指定したプロトコルとポートでリクエストを受ける。 ListenerRule: パスやHeaderなどの値を条件にどのTargetGroupにルーティングするかのルール。 TargetGroup: ルーティングする1つ以上のTarget。Instance, IP, Lambdaが選べる。  Ruleの作成 Serverless FrameworkではALBのenentを付けるだけでLambdaに向くRuleが作成されるが、そこにはCognitoを追加できなさそうなので使っていない。OnUnauthenticatedRequestで認証失敗時の挙動を選択できる。UserPoolとSecretありのClientはあらかじめ作っておく。コールバックURLにはhttps://&amp;lt;domain&amp;gt;/oauth2/idpresponseを追加する。
API Gatewayだとタイムアウトの上限が30秒なのに対してALBはLambdaの上限まで待てる。
$ cat serverless.yml service: alb-cognito-auth-example frameworkVersion: &amp;quot;&amp;gt;=1.28.0 &amp;lt;2.0.0&amp;quot; provider: name: aws runtime: go1.x region: ap-northeast-1 package: exclude: - ./** include: - ./bin/** functions: privateapi: handler: bin/privateapi timeout: 30 resources: Resources: ALBTargetGroup: DependsOn: InvokeLambdaPermissionForALB Type: AWS::ElasticLoadBalancingV2::TargetGroup Properties: Name: &amp;quot;private-lambda-target-group&amp;quot; TargetType: &amp;quot;lambda&amp;quot; Targets: - Id: !</description>
    </item>
    
    <item>
      <title>API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く</title>
      <link>https://www.sambaiz.net/article/226/</link>
      <pubDate>Wed, 03 Jul 2019 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/226/</guid>
      <description>ブラウザから直接API GatewayのエンドポイントにアクセスしたときにCognitoのTokenで認証し、失敗したらログイン画面を表示させる。 API GatewayでCognitoの認証をかける場合、AuthorizerでUserPoolを指定するのが最も簡単なパターンだが、 これだとHeaderにTokenを付けてアクセスする必要があり認証に失敗するとUnauthorizedが返る。
Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる - sambaiz-net
なおAPI GatewayではなくALBをLambdaの前段に挟めば今回やることが簡単に実現できる。
LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net
準備 UserPoolとClientを作成する。 CloudFormationで作成する場合SchemaのMutableのデフォルトがfalseなのに注意。変えると作り直される。
Resources: Userpool: Type: AWS::Cognito::UserPool Properties: AdminCreateUserConfig: AllowAdminCreateUserOnly: false Schema: - Mutable: true Name: email Required: true - Mutable: true Name: name Required: true UsernameAttributes: - email UserPoolName: testpool UserpoolClient: Type: AWS::Cognito::UserPoolClient Properties: UserPoolId: Ref: Userpool ClientName: testclient GenerateSecret: true 今回はフェデレーションでGoogleアカウントでログインできるようにする。 ややこしい用語であるがID Poolのフェデレーティッドアイデンティティとは異なる。
UserPoolのドメインや、GoogleのOAuth Client IDの発行とAttributes Mapping、Clientの設定はCloudFormationでできないので手でやる。 Attributes Mappingで変えられるがusernameは変更不可な値なのでsubのままにしておく。
設定が終わったら https://&amp;lt;user-pool-domain&amp;gt;/login?client_id=&amp;lt;client-id&amp;gt;&amp;amp;redirect_uri=&amp;lt;redirect-uri&amp;gt;&amp;amp;response_type=code にアクセスし、&amp;lt;redirect-uri&amp;gt;?code=&amp;lt;code&amp;gt; までリダイレクトされることを確認する。 invalid_requestとだけ出てしまった場合はClientのAuthorization code grantにチェックが入っているか確認する。</description>
    </item>
    
    <item>
      <title>ReactのFunction ComponentとHooks</title>
      <link>https://www.sambaiz.net/article/225/</link>
      <pubDate>Thu, 20 Jun 2019 19:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/225/</guid>
      <description>久々にcreate-react-appを実行したら コンポーネントがReact.ComponentのクラスではなくFunction Componentになっていた。
Function Component Function Componentは関数で書かれるStateを持たないコンポーネントで、 簡潔に書けるだけではなくReact.createElement()と比べて45%くらい速いらしい。
45% Faster React Functional Components, Now – Missive App – Medium
const App: React.FC = () =&amp;gt; { return ( &amp;lt;div className=&amp;quot;App&amp;quot;&amp;gt; {FunctionalComponent({title: &amp;quot;HELLO FC&amp;quot;})} &amp;lt;/div&amp;gt; ); } interface Props { title: string } const FunctionalComponent: React.FC&amp;lt;Props&amp;gt; = (props) =&amp;gt; { return ( &amp;lt;div&amp;gt; {props.title} &amp;lt;/div&amp;gt; ); } v16.6でリリースされた React.memo()を使うと PureComponent のようにpropsが変わらない場合は再レンダリングさせなくすることができる。
const App: React.FC = () =&amp;gt; { return ( &amp;lt;div className=&amp;quot;App&amp;quot;&amp;gt; &amp;lt;FunctionalComponent title=&amp;quot;HELLO FC&amp;quot; /&amp;gt; &amp;lt;/div&amp;gt; ); } interface Props { title: string } const FunctionalComponent = React.</description>
    </item>
    
    <item>
      <title>AWS DeepRacerを始める</title>
      <link>https://www.sambaiz.net/article/224/</link>
      <pubDate>Mon, 10 Jun 2019 23:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/224/</guid>
      <description>AWS DeepRacerは自走する1/18スケールのレーシングカーで、 SageMakerやRoboMakerなどを使って強化学習し、実機を走らせたりバーチャルのDeepRacerリーグで競うことができる。 カメラの画像の処理や、強化学習のアルゴリズムの実装の必要はなく、報酬関数だけで動いてくれるので敷居が低い。
強化学習とDQN(Deep Q-network) - sambaiz-net
設定項目 Action space 取りうるアクションである速度とステアリングの組み合わせのリスト。次の項目から生成される。
 Maximum steering angle (1 - 30) Steering angle granularity (3, 5, 7) Maximum speed (0.8 - 8) Speed granularity (1, 2, 3) Loss type (Mean square error, Huber) Number of experience episodes between each policy-updating iteration (5 - 100)  Reward function 強化学習の報酬関数。次の入力パラメータを用いて実装する。
{ &amp;quot;all_wheels_on_track&amp;quot;: Boolean, # flag to indicate if the vehicle is on the track &amp;quot;x&amp;quot;: float, # vehicle&#39;s x-coordinate in meters &amp;quot;y&amp;quot;: float, # vehicle&#39;s y-coordinate in meters &amp;quot;distance_from_center&amp;quot;: float, # distance in meters from the track center &amp;quot;is_left_of_center&amp;quot;: Boolean, # Flag to indicate if the vehicle is on the left side to the track center or not.</description>
    </item>
    
    <item>
      <title>CDK/CircleCI/GitHubでAWSリソース管理リポジトリを作る</title>
      <link>https://www.sambaiz.net/article/223/</link>
      <pubDate>Mon, 20 May 2019 09:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/223/</guid>
      <description>AWS CDKでリソースを記述し、PullRequestに対して自動でcdk diffで変更があるものを表示して、mergeしたときにcdk deployする。 全体のコードはGitHubにある。
AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする - sambaiz-net
 追記 (2019-08-29): このフローで起こったいくつかの問題を解決するため新しいツールを作った。 PR上でCDKのレビューやデプロイを行うツールcdkbotを作った - sambaiz-net
 CI Userの作成 まずcdkコマンドを実行するためのCI Userを作成する。これはCDK管理外のスタックで、AWSコンソール上から手動で上げる。
AWSのAssumeRole - sambaiz-net
AssumeRoleしかできないCIUserからCIAssumeRoleをassumeすることにした。
AWSTemplateFormatVersion: &#39;2010-09-09&#39; Resources: CIAssumeRole: Type: &#39;AWS::IAM::Role&#39; Properties: RoleName: &#39;CIAssumeRole&#39; ManagedPolicyArns: - &#39;arn:aws:iam::aws:policy/AdministratorAccess&#39; AssumeRolePolicyDocument: Version: &#39;2012-10-17&#39; Statement: - Effect: &#39;Allow&#39; Principal: AWS: - !Ref AWS::AccountId Action: - &#39;sts:AssumeRole&#39; CIGroup: Type: &#39;AWS::IAM::Group&#39; Properties: GroupName: &#39;CI&#39; CIPolicies: Type: &#39;AWS::IAM::Policy&#39; Properties: PolicyName: &#39;CI&#39; PolicyDocument: Statement: - Effect: Allow Action: &#39;sts:AssumeRole&#39; Resource: !</description>
    </item>
    
    <item>
      <title>AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする</title>
      <link>https://www.sambaiz.net/article/222/</link>
      <pubDate>Sun, 19 May 2019 01:43:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/222/</guid>
      <description>AWS CDK(Cloud Development Kit)はTypeScriptやJavaなどのコードから CloudFormationのテンプレートを生成して差分を確認しデプロイできる公式のツール。まだdeveloper preview。
$ npm i -g aws-cdk $ cdk --version 0.33.0 (build 50d71bf) $ mkdir cdk-vpc $ cd cdk-vpc $ cdk init app --language=typescript CloudFormationのリソースと対応するCfnFooや、それを内部で作成する高レベル(L2)のResource ClassFooが実装されている。 ただし、現状CfnFooに対応するResource Classが存在しないものや、複数のリソースを内部で作成するResource Classが存在する。 例えば、ec2.VpcはCfnVPCだけではなく、Public/Private Subnet、NATGatewayまでまとめて一般的な構成で作る。Resource Classはまだ変更が多い。
CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net
型があり補完が効くので通常のテンプレートと比べて書きやすいし、ループしたりすることもできる。
import * as cdk from &#39;@aws-cdk/cdk&#39; import * as ec2 from &#39;@aws-cdk/aws-ec2&#39; interface Export { vpc: ec2.Vpc } export class VPCStack extends cdk.Stack { protected deployEnv: string export: Export constructor(scope: cdk.</description>
    </item>
    
    <item>
      <title>ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する</title>
      <link>https://www.sambaiz.net/article/221/</link>
      <pubDate>Thu, 09 May 2019 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/221/</guid>
      <description>DAEMONを動かすことはできず、 fluentd logdriverもサポートされていないFargateで、 サイドカーとしてFluentdのコンテナを動かしてアプリケーションのログをS3に送る。 全体のコードはGitHubにある。
FargateでECSを使う - sambaiz-net
Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net
Fluentd 必要なプラグインと設定ファイルを入れたイメージを作る。
FROM fluent/fluentd:v1.4-1 USER root COPY ./fluent.conf /fluentd/etc/ # install plugin RUN apk add --update-cache --virtual .build-deps sudo build-base ruby-dev \ &amp;amp;&amp;amp; gem install fluent-plugin-s3 -v 1.0.0 --no-document \ &amp;amp;&amp;amp; gem install uuidtools \ &amp;amp;&amp;amp; gem sources --clear-all \ &amp;amp;&amp;amp; apk del .build-deps \ &amp;amp;&amp;amp; rm -rf /var/cache/apk/* \ /home/fluent/.gem/ruby/*/cache/*.gem # set timezone (Alpine) RUN apk --update-cache add tzdata &amp;amp;&amp;amp; \ cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime &amp;amp;&amp;amp; \ apk del tzdata &amp;amp;&amp;amp; \ rm -rf /var/cache/apk/* fluent.</description>
    </item>
    
    <item>
      <title>カテゴリカル変数をLabel/OneHotEncoderやget_dummiesで変換する</title>
      <link>https://www.sambaiz.net/article/220/</link>
      <pubDate>Mon, 06 May 2019 15:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/220/</guid>
      <description>data = [&amp;quot;tokyo&amp;quot;, &amp;quot;berlin&amp;quot;, &amp;quot;tokyo&amp;quot;, &amp;quot;paris&amp;quot;, &amp;quot;amsterdam&amp;quot;, &amp;quot;paris&amp;quot;, &amp;quot;amsterdam&amp;quot;, &amp;quot;berlin&amp;quot;] partial_data = data[:3] scikit-learnのpreprocessing.LabelEncoderでカテゴリカル変数を数値のラベルに変換できる。
from sklearn import preprocessing le = preprocessing.LabelEncoder() le.fit(data) print(le.classes_) # [&#39;amsterdam&#39; &#39;berlin&#39; &#39;paris&#39; &#39;tokyo&#39;] encoded = le.transform(partial_data) print(encoded) # [3 1 3] print(le.inverse_transform(encoded)) # [&#39;tokyo&#39; &#39;berlin&#39; &#39;tokyo&#39;] preprocessing.OneHotEncoder でone hot vectorに変換できる。
oh = preprocessing.OneHotEncoder() oh.fit([[d] for d in data]) print(oh.categories_[0]) # [&#39;amsterdam&#39; &#39;berlin&#39; &#39;paris&#39; &#39;tokyo&#39;] encoded = oh.transform([[d] for d in partial_data]).toarray() print(encoded) # [[0. 0. 0.</description>
    </item>
    
    <item>
      <title>DatadogのAWS integrationとAlertの設定をTerraformで行う</title>
      <link>https://www.sambaiz.net/article/219/</link>
      <pubDate>Sat, 04 May 2019 19:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/219/</guid>
      <description>DatadogのAWS integrationとAlertの設定をTerraformで行い、バージョン管理やレビューできるようにする。 全体のコードはGitHubに置いてある。
AWS Integration まずdatadog_integration_awsでAWS integrationの設定を作成してExternalIDを取得し、Policy/Roleを作成する。必要な権限はドキュメントを参照。
resource &amp;quot;datadog_integration_aws&amp;quot; &amp;quot;test&amp;quot; { account_id = &amp;quot;${var.aws_account_id}&amp;quot; role_name = &amp;quot;${var.aws_integration_role_name}&amp;quot; filter_tags = [&amp;quot;datadog:1&amp;quot;] } data &amp;quot;aws_iam_policy_document&amp;quot; &amp;quot;datadog_aws_integration_assume_role&amp;quot; { statement { actions = [&amp;quot;sts:AssumeRole&amp;quot;] principals { type = &amp;quot;AWS&amp;quot; identifiers = [&amp;quot;arn:aws:iam::464622532012:root&amp;quot;] } condition { test = &amp;quot;StringEquals&amp;quot; variable = &amp;quot;sts:ExternalId&amp;quot; values = [ &amp;quot;${datadog_integration_aws.test.external_id}&amp;quot;, ] } } } Datadog providerにはないSlackなどその他のintegrationは手動で設定する必要がある。 また、Logも集める場合Serverless Application Repositoryから公式のDatadog-Log-Forwarderを入れて AWS IntegrationのところにLambdaのARNを入れるのも手動。
Alert datadog_monitorでAlertを作成する。 今回はLambdaの実行が失敗したときと、WARNという文字列が含まれるログが一定数出力されたときにAlertを飛ばすようにしてみた。 なおinfoやwarnといったログレベルはjsonのlevelフィールドに入れればデフォルトのpipelineでマップされるので通常は文字列比較などする必要はない。
初めに作るときは一度画面で意図通りアラートが飛ぶものを作成し、クエリなどをコピーするのが確実。
resource &amp;quot;datadog_monitor&amp;quot; &amp;quot;lambda-error-alert&amp;quot; { name = &amp;quot;lambda-error-alert&amp;quot; type = &amp;quot;metric alert&amp;quot; message = &amp;quot;Error occurred.</description>
    </item>
    
    <item>
      <title>Box-Cox transformationで非正規分布のデータを正規分布に近づける</title>
      <link>https://www.sambaiz.net/article/218/</link>
      <pubDate>Tue, 30 Apr 2019 17:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/218/</guid>
      <description>Box-Cox Transormationは次の式による変換。λ=0のときはlog(x)。
λが1より大きい場合は小さな値の間隔が圧縮され、小さい場合は大きな値の間隔が圧縮されるように変換される。
import numpy as np from scipy.special import boxcox1p import matplotlib.pyplot as plt from bokeh.plotting import figure from bokeh.io import output_notebook, show output_notebook() p = figure( title=&amp;quot;Box-Cox Transformations&amp;quot;, x_axis_label=&#39;x&#39;, y_axis_label=&#39;λ&#39;, ) for lam in [-1, 0, 1, 2]: v = np.array([boxcox1p(i, lam) for i in range(10)]) v = v / v.max() p.line(v, lam) p.circle(v, lam, size=8) show(p) これによって左右非対称な分布を対称(skew=0)な正規分布に近づけることができる。 以前正規分布に近づけるのに対数を取ったが、これはBox-Cox transformationの1ケースだといえる。
KaggleのHome Prices CompetitionのKernelからデータの探り方を学ぶ - sambaiz-net
試しに適当な左右非対称な分布のデータを変換してみる。
import pandas as pd import seaborn as sns p = np.</description>
    </item>
    
    <item>
      <title>CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる</title>
      <link>https://www.sambaiz.net/article/217/</link>
      <pubDate>Sat, 13 Apr 2019 23:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/217/</guid>
      <description>CircleCI 2.1からOrbというjobをパッケージ化したものが使えるようになり、 自分でjobを書かずとも様々な処理を実行させることができるようになった。
CircleCI 2.0でDocker imageをbuildしてタグを付けてContainer Registryに上げる - sambaiz-net
今回は
 aws-ecr slack  を使ってdocker buildしてECRにpushし、バージョンタグが付いている場合はSlackに通知させる。
AWS_ACCESS_KEY_IDとAWS_SECRET_ACCESS_KEYを環境変数に入れて、ECRのリポジトリを作成し、 SlackのwebhookのURLを発行しておく。
version: 2.1 orbs: aws-ecr: circleci/aws-ecr@3.1.0 slack: circleci/slack@2.3.0 executors: default: machine: true environment: ECR_REPO: &#39;test-ecr-push&#39; AWS_ECR_ACCOUNT_URL: &#39;&amp;lt;account_id&amp;gt;.dkr.ecr.&amp;lt;region&amp;gt;.amazonaws.com&#39; AWS_REGION: &#39;&amp;lt;region&amp;gt;&#39; CLUSTER_NAME: &#39;test&#39; jobs: notify_slack: executor: default steps: - slack/status: success_message: &#39;${ECR_REPO}:${CIRCLE_TAG} was released&#39; webhook: &#39;https://hooks.slack.com/services/******&#39; workflows: build-push: jobs: - aws-ecr/build_and_push_image: name: &amp;amp;build_version &#39;build-version&#39; executor: default repo: &#39;${ECR_REPO}&#39; tag: &#39;${CIRCLE_TAG}&#39; filters: branches: ignore: /.*/ tags: only: /^v.</description>
    </item>
    
    <item>
      <title>KaggleのHouse Prices CompetitionのKernelからデータの探り方を学ぶ</title>
      <link>https://www.sambaiz.net/article/216/</link>
      <pubDate>Mon, 08 Apr 2019 21:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/216/</guid>
      <description>Kaggleの家の売値を予測するCompetitionのKernelからデータの探り方を学ぶ。
Comprehensive data exploration with Python
正規化 予測する値であるSalePriceの分布を出すと、やや左に寄った非対称の分布をしている。
import pandas as pd import seaborn as sns df = pd.read_csv(&#39;train.csv&#39;) df[&#39;SalePrice&#39;].describe() count 1460.000000 mean 180921.195890 std 79442.502883 min 34900.000000 25% 129975.000000 50% 163000.000000 75% 214000.000000 max 755000.000000 scipy.stats.probplot()で 生成できる、2つの分布(今回はSalePriceの分布と正規分布)の同じ分位数の値をプロットしたQ-Q (quantile-quantile) plotを見ても直線で表されている正規分布から外れていることが分かる。 本来のQ-Q plotではこの直線は同じ分位数に同じ値が来るy=xに引かれるが、この関数が生成するプロットはxがスケールされているのでそうなっていない。
from scipy import stats import matplotlib.pyplot as plt res = stats.probplot(df[&#39;SalePrice&#39;], dist=&#39;norm&#39;, plot=plt) 正規分布であることが望ましいので対数をとって近づけてやる。
import numpy as np res = stats.probplot(np.log(df[&#39;SalePrice&#39;]), dist=&#39;norm&#39;, plot=plt) なお、この変換はBox-Cox transformationのλ=0のときにあたる。
Box-Cox transformationで非正規分布のデータを正規分布に近づける - sambaiz-net</description>
    </item>
    
    <item>
      <title>React, Material-UI, Unstated, RechartsでTODOを作った</title>
      <link>https://www.sambaiz.net/article/215/</link>
      <pubDate>Thu, 28 Mar 2019 17:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/215/</guid>
      <description>コード
create-react-app create-react-appでアプリを作成した。 TypeScriptを有効にしている。
$ npx create-react-app react-todo-unstated --typescript $ cd react-todo-unstated $ tree src/ src/ ├── App.css ├── App.test.tsx ├── App.tsx ├── index.css ├── index.tsx ├── logo.svg ├── react-app-env.d.ts └── serviceWorker.ts $ npm start Material-UI UIはMaterial-UIでUIで作った。
$ npm install --save @material-ui/core @material-ui/icons public/index.htmlにRobotoフォントを入れた。
&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://fonts.googleapis.com/css?family=Roboto:300,400,500&amp;quot;&amp;gt; Unstated UnstatedはReact v16からのContext APIを使ったStateを管理するための薄いライブラリ。
$ npm install --save unstated Stateを持つContainerを作る。
class TodoContainer extends Container&amp;lt;TodoState&amp;gt; { state: TodoState = { newTodo: &amp;quot;&amp;quot;, todos: [], isCreating: false }; changeNewTodo(newTodo: string) { this.</description>
    </item>
    
    <item>
      <title>HI-VAE(Heterogeneous-Incomple VAE)の論文を読んで処理を追う</title>
      <link>https://www.sambaiz.net/article/214/</link>
      <pubDate>Fri, 22 Mar 2019 20:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/214/</guid>
      <description>HI-VAE(Heterogeneous-Incomple VAE)は現実のデータセットにありがちな連続値と離散値が混ざっていたり欠損値を含んでいるものを扱えるようにしたVAE。
論文: Alfredo Nazabal, Pablo M. Olmos, Zoubin Ghahramani, Isabel Valera (2018) Handling Incomplete Heterogeneous Data using VAEs
生成モデルVAE(Variational Autoencoder) - sambaiz-net
GitHubにTensorFlow実装が上がっているので論文と合わせて追ってみる。
入力データ 入力データdata.csvと、そのスキーマdata_types.csvが用意されていて、 様々なtypeのデータが含まれる24次元のデータセットであることが分かる。
type,dim,nclass pos,1, cat,3,3 cat,7,7 cat,4,4 count,1, ordinal,11,11 ordinal,11,11 ordinal,11,11 ordinal,11,11 ordinal,11,11 ordinal,11,11 real,1, real,1, real,1, real,1, real,1, real,1, pos,1, pos,1, pos,1, pos,1, pos,1, pos,1, cat,2,2 これに対して、xx%の確率でランダムな次元を欠損値として扱う際に対象とする行と次元を表す Missingxx_y.csvがある。
2,1 3,1 ... 29985,24 29998,24 typeごとのデータの扱い real(実数値) 標準化してencoderに入力し、decoderでは正規分布の平均と分散を 出力し サンプリングしてデータを生成する。
pos(正の実数) 対数を標準化してencoderに入力し、decoderでは正規分布の平均と分散を 出力し サンプリングしたデータをexp()で元のレンジに戻す。
count 対数を取ってencoderに入力し、decoderではポアソン分布の平均λを 出力し サンプリングしてデータを生成する。</description>
    </item>
    
    <item>
      <title>VAEでエンコードしたMNISTの潜在空間をt-SNEで可視化する</title>
      <link>https://www.sambaiz.net/article/213/</link>
      <pubDate>Sun, 10 Mar 2019 19:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/213/</guid>
      <description>t-SNEは多次元のデータを2,3次元上にマッピングして可視化できるようにする手法の一つで、 Stochastic Neighbor Embedding(SNE, 確率的近傍埋め込み)という手法をベースに、t分布を用いるなどして改良したもの。
Visualizing Data using t-SNE
SNE まず入力データ間の類似度をユークリッド距離を用いた次の条件付き確率p_{j|i}で表す。 これはx_iを中心とした正規分布上で、確率密度に基づいて隣り合うデータを選ぶ場合x_jが選ばれる確率となる。
同様に出力データでも次の条件付き確率q_{j|i}を計算する。σ=1/sqrt(2)とする。
この分布間のKL情報量を勾配降下法で最小化していくことで出力を最適化するのがSME。
自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net
ロジスティック回帰の尤度と交差エントロピーと勾配降下法 - sambaiz-net
t-SNE t-SNEでは条件付き確率ではなく同時確率を用いる。また、qを自由度1のt分布で表す。
MNISTの潜在空間をt-SNEで可視化した結果 以前作ったVAEのMNISTモデルの潜在空間を scikit-learnのTSNEで可視化する。
PyTorchでVAEのモデルを実装してMNISTの画像を生成する - sambaiz-net
%matplotlib inline import matplotlib.pyplot as plt from sklearn.manifold import TSNE from random import random colors = [&amp;quot;red&amp;quot;, &amp;quot;green&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;orange&amp;quot;, &amp;quot;purple&amp;quot;, &amp;quot;brown&amp;quot;, &amp;quot;fuchsia&amp;quot;, &amp;quot;grey&amp;quot;, &amp;quot;olive&amp;quot;, &amp;quot;lightblue&amp;quot;] def visualize_zs(zs, labels): plt.figure(figsize=(10,10)) points = TSNE(n_components=2, random_state=0).fit_transform(zs) for p, l in zip(points, labels): plt.scatter(p[0], p[1], marker=&amp;quot;${}$&amp;quot;.</description>
    </item>
    
    <item>
      <title>PyTorchでVAEのモデルを実装してMNISTの画像を生成する</title>
      <link>https://www.sambaiz.net/article/212/</link>
      <pubDate>Thu, 07 Mar 2019 19:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/212/</guid>
      <description>PyTorchでVAEを実装しMNISTの画像を生成する。
生成モデルVAE(Variational Autoencoder) - sambaiz-net
学習データ datasetsのMNIST画像を使う。
from torchvision import datasets, transforms transform = transforms.Compose([ transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))]) dataset_train = datasets.MNIST( &#39;~/mnist&#39;, train=True, download=True, transform=transform) dataset_valid = datasets.MNIST( &#39;~/mnist&#39;, train=False, download=True, transform=transform) dataloader_train = utils.data.DataLoader(dataset_train, batch_size=1000, shuffle=True, num_workers=4) dataloader_valid = utils.data.DataLoader(dataset_valid, batch_size=1000, shuffle=True, num_workers=4) VAE それぞれ3層のEncoderとDecoder。
import torch import torch.nn as nn import torch.nn.functional as F device = &#39;cuda&#39; class VAE(nn.Module): def __init__(self, z_dim): super(VAE, self).__init__() self.dense_enc1 = nn.Linear(28*28, 200) self.</description>
    </item>
    
    <item>
      <title>SageMaker NotebookでGitリポジトリにSSHでpush/pullできるようにする</title>
      <link>https://www.sambaiz.net/article/211/</link>
      <pubDate>Mon, 04 Mar 2019 22:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/211/</guid>
      <description>Sagemaker NotebookはAWSの機械学習のワークフローを提供するSageMakerの一部である マネージドなJupyter Notebooksで、可視化などはもちろん、ここから複数インタンスでの学習ジョブを実行したりすることができる。
Git統合 によってノートブック作成時にGitHubなどのリポジトリを指定すると前もって持ってきてくれるようになったが、 今のところHTTPSエンドポイントにしか対応していないようで、ユーザー名・パスワードまたはトークンといった個人に紐づく認証情報が必要になる。 今回はこの機能を使わずに、ライフサイクル設定でssh鍵を置き、これでpush/pullできるようにする。
パスフレーズなしの鍵を作って公開鍵を対象リポジトリのDeployKeyに登録してread/writeできるようにする。
$ mkdir sagemaker-sshkey $ cd sagemaker-sshkey $ ssh-keygen -t rsa -b 4096 -f id_rsa -N &amp;quot;&amp;quot; $ pbcopy &amp;lt; id_rsa.pub 秘密鍵はSSMのParameter Storeに登録する。
AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する - sambaiz-net
$ aws ssm put-parameter --name &amp;quot;sagemaker-sshkey&amp;quot; --value &amp;quot;`cat id_rsa`&amp;quot; --type String --overwrite $ aws ssm get-parameters --names &amp;quot;sagemaker-sshkey&amp;quot; ライフサイクル設定でノートブック開始時に次のスクリプトが実行されるようにする。 このスクリプトはrootで実行される。Parameter Storeが読める権限をNotebookのIAMに付けておく。
#!/bin/bash set -e su - ec2-user &amp;lt;&amp;lt;EOF cd /home/ec2-user aws ssm get-parameters --names &amp;quot;sagemaker-sshkey&amp;quot; | jq -r &amp;quot;.</description>
    </item>
    
    <item>
      <title>生成モデルGAN(Generative Adversarial Network)</title>
      <link>https://www.sambaiz.net/article/210/</link>
      <pubDate>Fri, 22 Feb 2019 23:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/210/</guid>
      <description>GAN(Generative Adversarial Network)は生成器Gと、データが本物かどうか識別する識別器Dを交互に最適化していく生成モデル。 データの評価は識別器によって行われるので、VAEと異なり分布を仮定して尤度を用いる必要がなく、より良いデータが生成できるが、 GとDを交互に最適化した結果振動してしまいナッシュ均衡に収束せず、またどちらかが先に最適化されてしまうと 同じようなデータばかり生成してしまうmode collapseや勾配が消えてしまったりして うまく学習できないことがある。
生成モデルVAE(Variational Autoencoder) - sambaiz-net
識別器(Discriminator) 生成されたデータの分布をp_g(x)、真のデータの分布をp_{data}(x)として、同数のデータにそれぞれy=0, 1のラベルを付ける。 識別器D(x)はyが0か1かの分類モデルで、負の交差エントロピー誤差V(D)を最大化するように学習する。
最適化したあとのDをD^とすると、目的関数V(D^)はJensen-Shannon(JS)ダイバージェンスを使って表せる。これを最小化するのがGANの目的。
生成器(Generator) p_dataとp_gのJSダイバージェンスが小さくなるように学習する。生成器Gを学習するための目的関数は次の通りで、これを最小化する。</description>
    </item>
    
    <item>
      <title>Chrome ExtensionsとChrome Apps</title>
      <link>https://www.sambaiz.net/article/209/</link>
      <pubDate>Tue, 19 Feb 2019 23:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/209/</guid>
      <description>Chrome Extrnsions ツールバーに表示され、ChromeのAPIを呼んで色々できる拡張機能で、manifestとhtml, js, cssなどから構成される。 開発中はディレクトリごとchrome://extensions/から読み込むとインストールでき、ツールバーにアイコンが表示される。
test-chrome-extension
manifest.json manifest_version, name, versionと、brower_actionかpage_actionのどちらかはRequired。
{ &amp;quot;manifest_version&amp;quot;: 2, &amp;quot;name&amp;quot;: &amp;quot;test-chrome-extension&amp;quot;, &amp;quot;version&amp;quot;: &amp;quot;1.0&amp;quot;, &amp;quot;icons&amp;quot;: { &amp;quot;128&amp;quot;: &amp;quot;images/icon-128.png&amp;quot; }, &amp;quot;page_action&amp;quot;: { &amp;quot;default_icon&amp;quot;: { &amp;quot;32&amp;quot;: &amp;quot;images/icon-32.png&amp;quot; } }, &amp;quot;options_page&amp;quot;: &amp;quot;options.html&amp;quot;, &amp;quot;background&amp;quot;: { &amp;quot;scripts&amp;quot;: [ &amp;quot;background.js&amp;quot; ], &amp;quot;persistent&amp;quot;: false }, &amp;quot;permissions&amp;quot;: [ &amp;quot;declarativeContent&amp;quot;, &amp;quot;storage&amp;quot; ], &amp;quot;content_security_policy&amp;quot;: &amp;quot;script-src &#39;self&#39;; object-src &#39;self&#39;&amp;quot; }  page_action  常にツールバーに表示されているbrowser_actionに対して、限られたページでのみ有効なAction。 有効かどうかは declarativeContent.onPageChangedの conditionsや、tags.onUpdatedのリスナー内で制御する。
 options_page: &amp;ldquo;拡張機能のオプション&amp;quot;で表示されるページ background  インストール時や更新時など必要なときにロードされるスクリプト。イベントリスナーはここで設定する。
chrome.runtime.onInstalled.addListener(() =&amp;gt; { chrome.declarativeContent.onPageChanged.removeRules(undefined, () =&amp;gt; { chrome.</description>
    </item>
    
    <item>
      <title>Apache SparkのRDD, DataFrame, DataSetとAction, Transformation</title>
      <link>https://www.sambaiz.net/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/208/</guid>
      <description>Sparkとは ハイパフォーマンスな汎用分散処理システム。 HDFSやS3といった分散ストレージとHadoop YARNといったクラスタマネージャと共に使われる。 中間データをメモリに置いておくことでHadoopのMapReduceよりも高速に処理することができる。 APIはJava, Scala, Python, Rのものがあって、 Pythonは手軽に書ける一方、パフォーマンスはJVMとのやりとりが発生するため落ちる。
HDFS(Hadoop Distributed File System)とは - sambaiz-net
RDDとDataFrameとDataSet RDD(Resilient Distributed Dataset)はSpark Coreの低レベルな インタフェースで、 型を持つイミュータブルな分散コレクション。
DataFrameはSpark SQLのテーブル状で型を持たないデータ形式で、 Tungstenというバイトレベルの最適化や Catalystというクエリのオプティマイザが効くので自分でRDDのAPIを呼ぶよりパフォーマンスが良い。
DataSetは型を持つDataFrameで、Spark 2.0からはDataFrameもDataset[Row]のエイリアスになった。
ActionとTransformation 外部への出力といった副作用を持つActionに対して RDDを返すだけの処理をTransformationという。 Transformationは都度実行されるのではなく Actionが実行される際に、依存関係を表すDAG(Directed Acyclic Graph) をもとに必要なものが遅延評価される。DAGはWeb UIで可視化できる。 また、ネットワークやノードの障害によって計算結果が失われても依存関係をたどり、 並列に計算することで高速に復旧できるようになっている。
narrow dependencyとwide dependency TransformationはRDDのパーティションに対して各Executorが並列に実行する。 mapやfilterなどの、見るパーティションが単一か他と被らない依存関係をnarrow dependencyといって、 そのExecutorだけで処理が完結するためパイプラインでまとめて実行でき速い。 一方、groupByKeyなどの一つのパーティションが複数のパーティションの処理で必要とされる依存関係をwide dependencyといって、 そのパーティションをExecutorが持っていない場合、コストが高いシャッフルが発生する。 シャッフルを必要としない一連の実行単位をstageという。
参考 High Performance Spark - O&amp;rsquo;Reilly Media
RDD vs DataFrames and Datasets: A Tale of Three Apache Spark APIs</description>
    </item>
    
    <item>
      <title>AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する</title>
      <link>https://www.sambaiz.net/article/207/</link>
      <pubDate>Sun, 10 Feb 2019 16:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/207/</guid>
      <description>AWS SAM (Serverless Application Model)はAWS公式の サーバーレスアプリケーションのビルドツール。 CloudFormationのテンプレートを設定ファイルに書くことでLambda関数と共にイベントトリガーや他のリソースも含めてデプロイでき、 その点でServerless Frameworkと立ち位置が近いが、向こうがLambda以外のサーバーレス環境にも対応していたり、 プラグインによって機能拡張できるようになっている一方、こちらは比較的薄いツールになっている。 ただ、Serverless Application Repositoryで公開するにはSAMの形式にする必要があり、 Serverless FrameworkにもSAMのテンプレートを出力するプラグインがある。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
SAM CLIのインストール $ brew tap aws/tap $ brew install aws-sam-cli $ sam --version SAM CLI, version 0.11.0 init initすると次の構成のディレクトリが作られる。
$ sam init --runtime go1.x -n test-sam $ cd test-sam/ $ ls Makefile	README.md	hello-world	template.yaml template.yamlの中に関数の設定やCloudFormationのテンプレートを書く。
$ cat template.yaml AWSTemplateFormatVersion: &#39;2010-09-09&#39; Transform: AWS::Serverless-2016-10-31 Description: &amp;gt; test-sam Sample SAM Template for test-sam # More info about Globals: https://github.</description>
    </item>
    
    <item>
      <title>CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う</title>
      <link>https://www.sambaiz.net/article/206/</link>
      <pubDate>Sun, 03 Feb 2019 17:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/206/</guid>
      <description>Aurora ServerlessはオートスケールするAuroraで、 使ったAurora Capacity Unit (ACU)によって料金が発生するため、 使用頻度が少なかったり変動するアプリケーションにおいて安くRDBを使うことができる。 インスタンスを立てると最低でも月3000円くらいかかるが、Serverlessだとほとんどストレージ分から運用することができて趣味でも使いやすい。 ただしLambdaと同様に常に同等のリソースを使っている状態だとインスタンスと比べて割高になる。
今回はLambdaで使う。 Serverlessと名前には付いているが用途としてはLambdaに限らず、 むしろコンテナの数が容易に増え得るLambdaは同時接続数が問題になるRDBと一般に相性が良くない。 現在Betaの、コネクションを張らずにHTTPSでクエリを投げられるData APIはこの問題を解消すると思われるが、トランザクションが張れなかったり、レスポンスサイズに制限があるようだ。今回はコンソール上から初期クエリを流すためにData APIを有効にしている。
他の選択肢として、DynamoDBは現状最有力で最近トランザクションもサポートされたがSQLのように複雑なクエリは投げられない。 Athenaはクエリは投げられるがそこそこ時間がかかるし、INSERT/UPDATEはできずクエリごとに料金が発生する。
Serverless Frameworkを使ってリソースを作成しデプロイする。リポジトリはここ。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
VPCの作成 Aurora Serverlessの制限の一つとしてVPC内からしか接続しかできないというものがある。ということでVPCから作成していく。以前Terraformで作ったのと同じリソースをCloudFormationで作る。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
LambdaをVPC内で動かすとコンテナ起動時にENIも作成するため立ち上がりの際時間がかかる。必要なら定期的に呼び出して削除されないようにする。 また、今回はテストのため/24でVPCを切っているが、小さいとENIのIPアドレスが枯渇する可能性がある。
 VPC  TestVPC: Type: AWS::EC2::VPC Properties: CidrBlock: 172.32.0.0/24 Tags: - Key: Name Value: test-vpc  Subnet  Aurora Serverlessのために少なくとも2つのサブネットが必要。
TestPublicSubnet: Type: AWS::EC2::Subnet Properties: VpcId: !Ref TestVPC CidrBlock: 172.32.0.0/25 AvailabilityZone: us-east-1d Tags: - Key: Name Value: test-public-subnet1 TestPrivateSubnet1: Type: AWS::EC2::Subnet Properties: VpcId: !</description>
    </item>
    
    <item>
      <title>PyTorchでMNISTする</title>
      <link>https://www.sambaiz.net/article/205/</link>
      <pubDate>Sat, 19 Jan 2019 23:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/205/</guid>
      <description>PyTorchはFacebookによるOSSの機械学習フレームワーク。 TensorFlow(v1)よりも簡単に使うことができる。 TensorFlow 2.0ではPyTorchのようにDefine-by-runなeager executionがデフォルトになるのに加え、パッケージも整理されるようなのでいくらか近くなると思われる。
使い方 インストール Colabで動かす。まずpipでインストール。
!pip install torch torchvision autograd(自動微分) Tensorは自身が作成された関数の参照.grad_fnを持ち、backward()が呼ばれるとbackpropしてrequires_grad=TrueなTensorの勾配を自動で計算し.gradに入れてくれる。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
import torch x = torch.randn(4, 4) y = torch.randn(4, 1) w = torch.randn(4, 1, requires_grad=True) b = torch.randn(1, requires_grad=True) y_pred = torch.matmul(x, w) + b loss = (y_pred - y).pow(2).sum() print(x.grad, w.grad) # None None loss.backward() print(x.grad, w.grad) # None tensor([...]) with torch.no_grad(): y_eval = torch.matmul(x, w) + b print(y_eval.requires_grad) # False Module nnパッケージにLinearやConv2dといったModuleが実装されていて、次のように呼び出すとforward()が 呼ばれ順伝播する。</description>
    </item>
    
    <item>
      <title>AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する</title>
      <link>https://www.sambaiz.net/article/204/</link>
      <pubDate>Mon, 07 Jan 2019 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/204/</guid>
      <description>DBのパスワードやAPIトークンといった認証情報をバージョン管理するコードや設定ファイル上に書くとOSS化など公開範囲を広げるときにやや困るし漏れるリスクが高まるのでなるべく避けたい。 そこでSSMのParameter Storeに値を置き、実行時やデプロイ時に参照する。
SSMのParameter StoreとSecrets Manager Systems Manager (SSM)はAWSのリソースを可視化したり操作を自動化したりするサービス群で、 設定を持つParameter Storeはその一つ。値は暗号化して持つこともできる。 料金はかからない。
SSMのParameter Storeと似たような別のAWSのサービスに Secrets Managerというのがあって、RDSなどと連携してLambdaによって定期的に新しい値を生成しローテーションさせることができる。 ただし料金がシークレットの件数($0.4/月)とAPIコール($0.05/10000回)でかかる。
CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net
今はParamter StoreとSecrets Managerが統合されていて、Parameter StoreのAPIでどちらも参照できるようだ。 今回はローテーションしないので単純に料金がかからないParameter Storeの方に書き込むことにする。 ただし、Parameter Storeは現状一度に大量のリクエストが飛ぶような使い方をするとRate exceededになってしまう問題がある。
実行時の値取得 実行時に値を取得するのはこんな感じ。
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws/awserr&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws/session&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/service/ssm&amp;quot; ) type Parameter struct { ssm *ssm.SSM } func newParameter(sess *session.Session) *Parameter { return &amp;amp;Parameter{ ssm: ssm.New(sess), } } func (s *Parameter) Get(name string, decrypt bool) (string, error) { param, err := s.</description>
    </item>
    
    <item>
      <title>AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する</title>
      <link>https://www.sambaiz.net/article/203/</link>
      <pubDate>Tue, 01 Jan 2019 17:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/203/</guid>
      <description>AWS GlueはマネージドなETL(Extract/Transform/Load)サービスで、Sparkを使ってS3などにあるデータを読み込み加工して変換出力したり、AthenaやRedshift Spectrumで参照できるデータカタログを提供する。 今回はS3のCSVを読み込んで加工し、列指向フォーマットParquetに変換しパーティションを切って出力、その後クローラを回してデータカタログにテーブルを作成してAthenaで参照できることを確認する。
料金はジョブがDPU(4vCPU/16GBメモリ)時間あたり$0.44(最低2DPU/10分)かかる。 また、クローラも同様にDPUで課金される。結構高い。
なお、AthenaのCTASでもParquetを出力することができる。 出力先にファイルがないようにする必要があったり重いクエリは失敗することがあるが手軽で良い。
import * as athena from &#39;athena-client&#39; const clientConfig: athena.AthenaClientConfig = { bucketUri: &#39;s3://*****/*****&#39; skipFetchResult: true, }; const awsConfig: athena.AwsConfig = { region: &#39;us-east-1&#39;, }; const client = athena.createClient(clientConfig, awsConfig); (async () =&amp;gt; { await client.execute(` CREATE TABLE ***** WITH ( format = &#39;PARQUET&#39;, external_location = &#39;s3://*****&#39; ) AS ( SELECT ~~ ) })(); 開発用エンドポイント ジョブの立ち上がりにやや時間がかかるため開発用エンドポイントを立ち上げておくとDPUが確保されて効率よく開発できる。 立ち上げている間のDPUの料金がかかる。つまりずっとジョブを実行し続けているようなもので結構高くつくので終わったら閉じるようにしたい。
ローカルやEC2から自分で開発用エンドポイントにsshしてNotebookを立てることもできるが、 コンソールから立ち上げたNotebookは最初からつながっていて鍵の登録も必要なくて楽。
ssh -i private-key-file-path -NTL 9007:169.</description>
    </item>
    
    <item>
      <title>強化学習とDQN(Deep Q-network)</title>
      <link>https://www.sambaiz.net/article/202/</link>
      <pubDate>Tue, 18 Dec 2018 01:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/202/</guid>
      <description>強化学習というのは将来に得られる報酬を最大化するような行動を学習していくもの。
状態価値関数による学習 状態sのときに取る行動aを決定する方策(Policy)をπ(s)、次の状態s&amp;rsquo;を予測するモデルをP(s,a,s&amp;rsquo;)、直後に得られる即時報酬r_{t+1}を予測するモデルをR(s,a)とすると、将来得られる報酬の期待値である状態価値関数Vπは次の式で再帰的に表すことができ、この形式をベルマン方程式という。 同じ報酬なら早くに得られた方が良いという考えから将来の報酬rは1ステップ遅れるたびに割引率γが掛けられる。
どんな状態においても状態価値関数を最大化させる最適方策π*を探すにあたり、定義通り将来の報酬を待つのではなく、即時報酬Rで状態価値関数Vを更新していく。これをTD(Temporal difference)学習という。
取り得る状態数が多いと収束するまでの時間が長くなる問題があって、これを価値関数の近似によって解消するのがDQN。
DQN (Deep Q-Network) DNNでQ学習を行う。Q学習というのは状態sのときに行動aしたときの報酬の期待値である行動価値関数Qを最大化させるように学習させるもので、 最も良かった行動でQを更新していく。 未知の行動を探索するかどうかはバンディットアルゴリズムのε-greedyによって確率的に決定し、学習が進むにつれて確率は下がっていく。
前もってランダムに行動と結果をサンプリングしておき学習の際に使う、ER(Experience Replay)というテクニックが使われる。 これによって実行回数が減るだけではなく、時系列的な相関を減らし効率的に学習させることができる。
またmain-networkとは別に、同じ形式のtarget-networkを作ってQ(s&#39;=s_{t+1}, a)の値を出すのに使う。 target-networkのパラメータはmain-networkのものを定期的に同期させる以外では更新しないことで学習を安定させることができる。 これをFixed Target Q-Networkという。
参考 強化学習の基礎
第14回　深層強化学習DQN（Deep Q-Network）の解説｜Tech Book Zone Manatee</description>
    </item>
    
    <item>
      <title>生成モデルVAE(Variational Autoencoder)</title>
      <link>https://www.sambaiz.net/article/201/</link>
      <pubDate>Tue, 11 Dec 2018 00:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/201/</guid>
      <description>生成モデルというのはデータの分布をモデリングしてそこから新しいデータを生成するもの。 VAEは入力xに対して何らかの分布を仮定し、例えばガウス分布(正規分布)だとすると平均μと分散σを推論し、 これをz=μ+(σ・ε) (ε~N(0,1))の潜在変数に変換して生成モデルへの入力とし、その出力の尤度が最大化するように学習させる。
Variational Autoencoderという名前はこの分布を推論して生成する流れがAutoencoderの形式と似ているところから来ている。 Autoencoder(自己符号化器)というのはある入力をエンコードしてデコードしたときに入力と同じものを出力するように学習させたもので、 これによって次元削減された潜在変数zが得られる。
推論モデルの確率分布をq、生成モデルの確率分布をpとする。対数尤度log{p}を計算したいが潜在変数zが訓練データにないので周辺化する(1)。 これを変換していくと(2)のようになり、第二項のKL情報量は0以上の値になるので第一項のLを最大化することが対数尤度の最大化につながる。 このLをEvidence Lower Bound (ELBO)といい、推論モデルのパラメータφと生成モデルのパラメータθを交互に最適化して これを最大化させることで尤度の下界を引き上げていく。
自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net
生成モデルがベルヌーイ分布、p(z)が標準正規分布とするとELBOは次のようになる。
第一項が再生成誤差。第二項によってp(z)とq(z|x)が近づくように学習し正則化され、zの各次元が独立になっていく。 これにβ&amp;gt;1を掛けるとさらに独立性が増し、次元ごとに、人であれば性別や年齢のような、disentangle(もつれを解く)された特徴を持つことができる。これをβ-VAEという。
PyTorchでVAEのモデルを実装してMNISTの画像を生成する - sambaiz-net
VAEは分布を仮定して尤度によって学習するため、真の分布にはないところの生成データが良くない問題がある。 VAE以外の生成モデルとしてGAN(Generative Adversarial Networks)があって、これはデータの分布を仮定せずより近い分布から良いデータを生成するのを目指す。
生成モデルGAN(Generative Adversarial Network) - sambaiz-net
参考 Kerasで学ぶAutoencoder
Carl Doersch (2016) Tutorial on Variational Autoencoders
Variational Autoencoder徹底解説 - Qiita</description>
    </item>
    
    <item>
      <title>Encoder-Decoder RNNのAttention</title>
      <link>https://www.sambaiz.net/article/200/</link>
      <pubDate>Sat, 01 Dec 2018 23:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/200/</guid>
      <description>Encoder-Decoder RNNは入力用のEncoderと出力用のDecoderの2つのLSTMを組み合わせたもので、EncoderのStateはDecoderに繋げる。
したがって入力データはDecoderに渡されるStateにまとめられることになるが、 出力ごとに入力時系列の重要な部分は異なるため、特定の部分に注目できるようにすると良い結果が期待できる。 次の論文ではAttention Layerを追加することでこれを行い翻訳の精度を向上させている。
Minh-Thang Luong, Hieu Pham, Christopher D. Manning (2015) Effective Approaches to Attention-based Neural Machine Translation
Attention LayerはEncoderの出力とDecoderの対象の出力からどの部分を重要とするかを表すAlign weights a(t)と Encoderの出力を掛けたものをContext vector c(t)として出力する。 scoreにはそのまま掛けたものや(h_{dec}h_{enc})、重みとDecoderの出力のみを掛ける(Wh_{dec})といったものが使われる。</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</title>
      <link>https://www.sambaiz.net/article/199/</link>
      <pubDate>Tue, 27 Nov 2018 09:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/199/</guid>
      <description>TPU(Tensor Processing Unit)は Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。 一般的なGPUと比べて15~30倍もの性能が出る らしく検索や翻訳などGoogleのサービスでも使われている。
TPUを使える環境として、無料で使えるJupyter NotebooksのGoogle Colabと GCPのCloud TPUがある。ColabのTPUも裏側ではCloud TPUが動いている。 Cloud TPUを直に使うとVMから接続して使うことになるので、TPUの料金に加えてVMの料金もかかる。
モデルのTPU対応 CNNのモデルをTPUEstimatorでTPUに対応させる。
EstimatorはTensorFlowの高レベルAPIで、 train()、 evaluate()、 predict()、 export_saved_model() といったモデルの学習から保存まで必要な機能を一通り提供する。
初めは比較的低レベルのAPIを使おうとしていたが、XLA(Accelerated Linear Algebra)によるコンパイルがうまくいかないなど様々な問題にあたって大変だったので使っておくと良いと思う。 それでもトライアンドエラーの繰り返しで、典型的なものはTroubleshootingにあるが、ないものは調べるなりしてなんとかやっていくしかない。
定数などの定義。BATCH_SIZEはCloud TPUのシャード数の8で割り切れる値にする必要がある。
import pandas as pd from sklearn.model_selection import train_test_split import tensorflow as tf import numpy as np flags = tf.app.flags flags.DEFINE_boolean(&#39;use_tpu&#39;, True, &#39;use tpu or not&#39;) tf.app.flags.DEFINE_string(&#39;f&#39;, &#39;&#39;, &#39;kernel&#39;) FLAGS = flags.FLAGS EPOCH_NUM = 100 BATCH_SIZE = 800 # must be divisible by number of replicas 8 EVAL_BATCH_SIZE = 800 SHARD_NUM = 8 # A single Cloud TPU has 8 shards.</description>
    </item>
    
    <item>
      <title>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する</title>
      <link>https://www.sambaiz.net/article/198/</link>
      <pubDate>Wed, 14 Nov 2018 02:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/198/</guid>
      <description>Batch Normalizationとは Deep Learningでは各層の学習を同時に行うため、前の層の変更によって各層の入力の分布が変わってしまうinternal covariate shiftという現象が起こり、そのためにパラメータの初期化をうまくやる必要があったり、学習率を大きくできず多くのステップを要する。 以下の論文で発表されたBatch Normalization(BN)は各層の入力を正規化して分布を固定することでこれを解決するというもの。 画像認識のコンテストILSVRC 2015で1位を取ったResNet(Residual Network)でも使われている。
Sergey Ioffe, Christian Szegedy (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
具体的にはWx+bと活性化関数の間にBNの層を入れる。μ、σ^2は入力xの平均と分散。 単に正規化するだけでは表現力が下がってしまうのでγとβでスケールやシフトできるようにする。これらの変数は他のパラメータと同様に学習させる。
TensorFlowでの確認 TensorFlowではbatch_normalization()がすでに実装されているのでこれを使う。
以下のCNNで学習率を高めに設定しBNありなしの結果を比較する。学習データはmnist。MonitoredSessionでcostをsummaryとして出力しTensorBoardで見られるようにしている。
TensorBoardでsummaryやグラフを見る - sambaiz-net
TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net
import pandas as pd import numpy as np import tensorflow as tf from sklearn.model_selection import train_test_split from sklearn.utils import shuffle from sklearn.metrics import accuracy_score train = pd.read_csv(&#39;./train.csv&#39;) (x_train, x_valid ,y_train, y_valid) = train_test_split( train.</description>
    </item>
    
    <item>
      <title>TensorFlow&#43;numpyでData Augmentationして画像の学習データを増やす</title>
      <link>https://www.sambaiz.net/article/197/</link>
      <pubDate>Sun, 11 Nov 2018 15:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/197/</guid>
      <description>Data Augmentationは学習データを加工したものを学習データに加えることで数を増やすというもの。 加工したデータには通常元のものと同じラベルが付くことになるが、 例えば画像を反転や回転させても元々のものと同じだと認識されるべきだとしたら妥当だ。 つまり、なんでもすれば良いわけではなくデータセットに応じた、元のデータと同じラベルが付くような加工をする必要があり、 裏を返せばそのような違いがあっても同じものであることをモデルに学習させることができる。
今回はData Augmentationで行われる加工をTensorFlowやnumpyの関数でおなじみLennaの画像に行う。
必要なパッケージと画像をimportする。Jupyter Notebooksで実行する。
%matplotlib inline from PIL import Image import matplotlib.pyplot as plt import numpy as np import tensorflow as tf im = Image.open(&amp;quot;lenna.png&amp;quot;, &amp;quot;r&amp;quot;) Flipping  flip_left_right() random_flip_left_right() flip_up_down() random_flip_up_down()  左右と上下の反転。randomは1/2で反転する。
fliph = tf.image.flip_left_right(im) flipv = tf.image.flip_up_down(im) with tf.Session() as sess: results = sess.run([fliph, flipv]) plt.imshow(np.hstack(results)) Rotating  rot90()  反時計周りに90度回転させる。
rot90 = tf.image.rot90(im) with tf.Session() as sess: results = sess.run([rot90]) plt.</description>
    </item>
    
    <item>
      <title>FargateでECSを使う</title>
      <link>https://www.sambaiz.net/article/196/</link>
      <pubDate>Fri, 09 Nov 2018 00:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/196/</guid>
      <description>ECSはAWSのコンテナオーケストレーションサービス。 クラスタはEC2上に立てることもできるが、その場合Auto Scalingグループの設定やスケールイン時のdrainなどを考慮する必要がある。 Fargateで起動するとサーバーレスで実行でき、バックエンドの管理が必要がなくなる。 料金は割り当てたvCPUとメモリによって、最低1分の1秒単位で課金される。 Lambdaと同じくリソースあたりでいうとオンデマンドのEC2と比較して割高。ただし柔軟にリソースが指定できる分いくらか差は縮まる。
特にバッチ処理のように常にリソースが必要ないTaskは都度インスタンスを立ち上げるのも面倒なので良いと思う。 Lambdaと比較すると、実行環境を自由に作れるのと実行時間に制限がないというところが良いが、 Taskを作るトリガーは現状cronだけなのでそれ以外のイベントで実行したい場合はLambdaと組み合わせる必要がある。
AWSにはKubernetesクラスタを立てられるEKSもあるが、こちらはまだFargateに対応していない。 もしかしたら今月末のre:Inventで何か発表されるかもしれない。
Clusterの作成 まずはClusterを作成する。
$ aws ecs create-cluster --cluster-name test Taskの登録 イメージやポートマッピング、ヘルスチェックや割り当てるリソースといったContainer definition を含むTask definitionを書く。 Fargateの場合networkModeはawsvpc固定になる。
{ &amp;quot;family&amp;quot;: &amp;quot;test-task&amp;quot;, &amp;quot;networkMode&amp;quot;: &amp;quot;awsvpc&amp;quot;, &amp;quot;containerDefinitions&amp;quot;: [ { &amp;quot;name&amp;quot;: &amp;quot;nginx&amp;quot;, &amp;quot;image&amp;quot;: &amp;quot;nginx:1.15&amp;quot;, &amp;quot;portMappings&amp;quot;: [ { &amp;quot;containerPort&amp;quot;: 80, &amp;quot;hostPort&amp;quot;: 80, &amp;quot;protocol&amp;quot;: &amp;quot;tcp&amp;quot; } ], &amp;quot;essential&amp;quot;: true } ], &amp;quot;requiresCompatibilities&amp;quot;: [ &amp;quot;FARGATE&amp;quot; ], &amp;quot;cpu&amp;quot;: &amp;quot;256&amp;quot;, &amp;quot;memory&amp;quot;: &amp;quot;512&amp;quot; } Taskを登録する。
$ aws ecs register-task-definition --cli-input-json file://$(pwd)/task.json $ aws ecs list-task-definitions &amp;quot;taskDefinitionArns&amp;quot;: [ &amp;quot;arn:aws:ecs:ap-northeast-1:*****:task-definition/test-task:1&amp;quot; ] } Taskを実行 run-taskでTaskを実行できる。 外からアクセスできるようにPublicIPを割り当てている。</description>
    </item>
    
    <item>
      <title>TensorFlowのtf.data API</title>
      <link>https://www.sambaiz.net/article/195/</link>
      <pubDate>Sat, 03 Nov 2018 18:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/195/</guid>
      <description>Importing Data | TensorFlow
データを読み込み変換してイテレートする入力パイプラインを作るAPI。 通常、学習にGPU/TPUを使う場合CPU処理の間はアイドル状態となりボトルネックになるが、 パイプライン処理を行うことでCPUとGPU/TPUがなるべくアイドル状態にならないようになり、 学習時間が短縮される。
Datasetの作成 from_tensor_slices()でDatasetを作成する。
dataset = tf.data.Dataset.from_tensor_slices( {&amp;quot;a&amp;quot;: tf.random_uniform([4]), &amp;quot;b&amp;quot;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)}) print(dataset.output_types) # {&#39;a&#39;: tf.float32, &#39;b&#39;: tf.int32} print(dataset.output_shapes) # {&#39;a&#39;: TensorShape([]), &#39;b&#39;: TensorShape([Dimension(100)])} 引数にnumpyのndarrayを渡すとtf.constant()で変換されてグラフに乗る。
dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3))) print(dataset.output_types) # &amp;lt;dtype: &#39;int64&#39;&amp;gt; print(dataset.output_shapes) # (3,) データが1GBを超える場合グラフのシリアライズ上限を超えてしまうことがある。後述するinitializableイテレータの初期化時にndarrayを渡すとこれを避けられる。
tf.contrib.data.CsvDatasetでCSVからDatasetを作ることもできる。
$ cat file1.csv a,b,c,d 1,2,3,4 2,3,4,5 6,7,8,9 filenames = [&amp;quot;file1.csv&amp;quot;] record_defaults = [tf.float32] * 2 # Two required float columns dataset = tf.contrib.data.CsvDataset(filenames, record_defaults, header=True, select_cols=[1,3]) print(dataset.</description>
    </item>
    
    <item>
      <title>同じ/異なるオリジンのiframeの中からできること</title>
      <link>https://www.sambaiz.net/article/194/</link>
      <pubDate>Wed, 24 Oct 2018 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/194/</guid>
      <description>同じ/異なるオリジンのiframeの中からできることを確認する。同じオリジンというのは ホストだけではなくプロトコルやポート番号も同じということ。
検証用ページ 3つのiframeがあるページを作った。 それぞれabout:blankで動的に書き込むのと、同じオリジンのhtmlを参照しているものと、異なるオリジンのhtmlを参照しているもの。
$ cat index.html &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;style type=&amp;quot;text/css&amp;quot;&amp;gt; p{ width:100px; height:100px; background:#999; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;p&amp;gt;parent&amp;lt;/p&amp;gt; &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;about:blank&amp;quot; id=&amp;quot;if1&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt; var parentValue = &amp;quot;PARENT&amp;quot;; window.addEventListener(&amp;quot;message&amp;quot;, (event) =&amp;gt; { console.log(`message from ${event.origin}: ${event.data}`); }, false); &amp;lt;/script&amp;gt; &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;./iframe.html&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;https://*****.ngrok.io/iframe.html&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;./index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 1つ目のiframeの中にscriptタグなどを書き込むJS。
$ cat index.js const el = document.getElementById(&amp;quot;if1&amp;quot;); const doc = el.contentDocument; const p = doc.createElement(&#39;p&#39;); p.textContent = &amp;quot;child&amp;quot;; doc.body.appendChild(p); var scriptTag = doc.</description>
    </item>
    
    <item>
      <title>Goで高速にJSONを扱うライブラリeasyjsonとfastjson</title>
      <link>https://www.sambaiz.net/article/193/</link>
      <pubDate>Wed, 24 Oct 2018 01:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/193/</guid>
      <description>easyjson easyjsonは次のようなstructごとのコードを自動生成してReflectionなしで高速にJSON Marshal/Unmarshalできるようにするライブラリ。
$ go get -u github.com/mailru/easyjson/... $ cat struct.go package a type Foo struct { A string `json:&amp;quot;a,omitempty&amp;quot;` B *Bar } type Bar struct { C []int `json:&amp;quot;c&amp;quot;` D map[string]int `json:&amp;quot;d&amp;quot;` } $ easyjson -all struct.go $ cat struct_easyjson.go ... func easyjson9f2eff5fEncodeGithubComSambaizBenchjsonA(out *jwriter.Writer, in Foo) { out.RawByte(&#39;{&#39;) first := true _ = first if in.A != &amp;quot;&amp;quot; { const prefix string = &amp;quot;,\&amp;quot;a\&amp;quot;:&amp;quot; if first { first = false out.</description>
    </item>
    
    <item>
      <title>MLPと誤差逆伝搬法(Backpropagation)</title>
      <link>https://www.sambaiz.net/article/192/</link>
      <pubDate>Sun, 21 Oct 2018 19:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/192/</guid>
      <description>MLP(多層パーセプトロン)は入力層と出力層の間に隠れ層を重ねることによって、 ロジスティック回帰(単純パーセプトロン)ではできなかった非線形分離をできるようにしたニューラルネットワークモデル。
ロジスティック回帰の尤度と交差エントロピー誤差と勾配降下法 - sambaiz-net
入出力がx、y、層の数がLでl層目での重みとバイアスをW^(l), b^(l)、活性化関数をf^(l)、活性化関数適用前後をu^(l)とh^(l)とし、入力層を0層目とすると各層での演算は以下の式で表される。
活性化関数は非線形で微分可能な関数で、計算速度や勾配消失の面でReLUが最有力。
ニューラルネットワークと活性化関数 - sambaiz-net
各層の最適なWとbを探すのにロジスティック回帰と同様に勾配降下法を使うことができる。 誤差関数は分類の場合は交差エントロピーが、回帰の場合は平均二乗誤差(MSE, Mean Squared Error) または外れ値に引っ張られづらくしたHuber損失などが使われる。
隠れ層の勾配はそれより後ろの層での演算が影響するので、入力から出力への順伝搬に対して 出力から入力への逆伝播で誤差の情報を前の層に伝播させていく。これを誤差逆伝播法(Backpropagation)という。
出力から遠くなればなるほど連鎖律が長くなっていくが、途中までは後ろの層と共通になっている。 ということで順伝搬時のhを保存しておき一つ後ろの層のWと誤差δを渡してやれば必要最小限の演算で済み、実行時間を短くすることができる。
参考 深層学習</description>
    </item>
    
    <item>
      <title>ロジスティック回帰の尤度と交差エントロピーと勾配降下法</title>
      <link>https://www.sambaiz.net/article/191/</link>
      <pubDate>Sun, 14 Oct 2018 23:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/191/</guid>
      <description>ロジスティック回帰 単純パーセプトロンの活性化関数を0/1のステップ関数ではなく0~1のシグモイド関数σにしたモデルで、分類の確率を返すことができる。
ニューラルネットワークと活性化関数 - sambaiz-net
線形分離不可能な場合はうまくいかない。入力と出力の間に隠れ層があるMLPでは非線形分離もできる。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
尤度関数と交差エントロピー誤差関数 尤度(likelihood)関数はXという事象が観察されたときにC=tである尤もらしさを表す関数。 例えば、6面ダイスを2回振って両方1の目が出た(X)ときに1の目が出る確率が1/6(C)である尤度は(1/6)*(1/6)=1/36となる。
学習ではモデルのパラメータw,bを、各入力x(x1,x2,&amp;hellip;,xn)に対して正解であるC=tの尤度の和が最大になるように最適化していく。 通常のロジスティック回帰では二値分類を行うので正解データtは{0,1}とし、P(C=1) = 1-P(C=0)となる。
ただ、このままだと積になっていて計算しづらいので、対数を取って和にして、 損失として扱うため負の数にする。これを交差エントロピー誤差関数という。 この値を最小化させるということは尤度を最大化させることになる。
自己情報量、エントロピー、KL情報量、交差エントロピー - sambaiz-net
勾配降下法 誤差をw,bでそれぞれ偏微分したのを引いてパラメータを更新していき、 勾配が0になるような値を探す。
ηは学習率で正の小さな値にする。 大きすぎると収束しないが、小さすぎても収束に必要なステップ数が増え、さらに局所最適解で止まってしまう可能性が高まるので 最初は大きくして徐々に小さくしていったりする。
ほかに局所最適解で止まるのを避ける手法として、サンプル全体ではなく毎回異なる一部を使う(Minibatch)確率的勾配降下法(SGD: Stochastic Gradient Descent)や、SGDに慣性を追加したMomentumなどがある。
多クラスロジスティック回帰 活性化関数をsoftmax関数にすると多クラス分類できる。
多クラスの場合の正解データtは{0,1,2,&amp;hellip;}といったようにはせず 正解のindexだけ1でほかは0のone-hot vectorで表し、尤度関数、交差エントロピー誤差関数は以下のようになる。
偏微分するとこうなる。
あとは同様に勾配降下法でパラメータを更新していく。
参考 詳解 ディープラーニング ~TensorFlow・Kerasによる時系列データ処理~</description>
    </item>
    
    <item>
      <title>Kubernetesでliveness/readinessProbeのexec commandが実行される流れ</title>
      <link>https://www.sambaiz.net/article/190/</link>
      <pubDate>Sat, 06 Oct 2018 16:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/190/</guid>
      <description>Kubernetesのliveness/readinessProbe はPodが生きているか/リクエストを受けられるかの判定で、 後者はアプリケーションの起動に時間がかかる場合などに使われる。 ヘルスチェックのようなエンドポイントを叩くのはhttpGetでできるが、任意のcommandを実行することもできる。
livenessProbe: httpGet: path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome Manifestに書かれたProbeは、 各ノードで動いているkubeletが Podが追加されたときにworkerを 作って runProbe()で実行させている。
if p.Exec != nil { glog.V(4).Infof(&amp;quot;Exec-Probe Pod: %v, Container: %v, Command: %v&amp;quot;, pod, container, p.Exec.Command) command := kubecontainer.ExpandContainerCommandOnlyStatic(p.Exec.Command, container.Env) return pb.exec.Probe(pb.newExecInContainer(container, containerID, command, timeout)) } まずcommandに含まれる$( )で囲まれた文字列を Expand() で存在すればcontainerのenvの値に置き換える。
その後、 RunInContainer()で、 コンテナランタイムがK8s標準のCRI(Container Runtime Interface)に対応している場合はそのAPIの、 対応していない場合は~shimパッケージのExecSync()が呼ばれ、コンテナ内でcommandを実行させて結果を受け取り、終了コードが0でなければエラーとする。
$( )でenvの値が使えることを確認する。
$ kubectl config use-context docker-for-desktop $ cat test.yaml --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: &amp;quot;test&amp;quot; spec: replicas: 1 template: metadata: labels: app: &amp;quot;test&amp;quot; spec: containers: - name: &amp;quot;test&amp;quot; image: &amp;quot;alpine&amp;quot; command: [&amp;quot;top&amp;quot;] env: - name: TEST value: &amp;quot;foobar&amp;quot; ports: - containerPort: 5000 name: grpc readinessProbe: exec: command: - test - $(TEST) - = - foobar initialDelaySeconds: 0 timeoutSeconds: 1 $ kubectl apply test.</description>
    </item>
    
    <item>
      <title>MySQLのtime_zoneとgo-sql-driver/mysqlの設定</title>
      <link>https://www.sambaiz.net/article/189/</link>
      <pubDate>Tue, 02 Oct 2018 22:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/189/</guid>
      <description>MySQLのtime_zoneとgo-sql-driver/mysqlの設定による挙動を確認する。
&amp;gt; select version(); +-----------+ | version() | +-----------+ | 5.7.21 | +-----------+ タイムゾーンがロードされていない場合はロードする。
&amp;gt; select count(*) from mysql.time_zone \\G; *************************** 1. row *************************** count(*): 0 $ mysql_tzinfo_to_sql /usr/share/zoneinfo/ | mysql -u root mysql time_zoneはデフォルト値のSYSTEM。つまりJSTで、my.cnfのdefault-time-zoneで変更できる。 NOW()もJSTの時間を返している。
&amp;gt; show variables like &#39;%time_zone%&#39;; +------------------+--------+ | Variable_name | Value | +------------------+--------+ | system_time_zone | JST | | time_zone | SYSTEM | +------------------+--------+ &amp;gt; SELECT NOW(); mysql&amp;gt; SELECT NOW() \G; *************************** 1. row *************************** NOW(): 2018-10-02 20:26:29 DATETIMEはそのまま格納され返される。 TIMESTAMPはUTCに変換して格納され、 返すときにtime_zoneに変換される。 したがってtime_zoneを変更するとDATETIMEは変わらず、TIMESTAMPは変わる。</description>
    </item>
    
    <item>
      <title>PythonのType Hintsとmypy</title>
      <link>https://www.sambaiz.net/article/188/</link>
      <pubDate>Sun, 30 Sep 2018 14:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/188/</guid>
      <description>動的型付け言語であるPythonで型アノテーションを書けるようにするための構文。 PEP 484で提案され、Python 3.5で実装された。 実行には影響せず、mypyのようなツールで静的解析したりするために使われる。
mypyをインストールする。
$ python -m pip install -U mypy 以下のように引数と返り値に型を書くと、型が誤っている場合にmypyで検知できるようになる。
$ cat main.py def foo(n: int) -&amp;gt; str: return str(n) print(foo(3)) print(foo(&#39;3&#39;)) $ python main.py 3 3 $ mypy main.py main.py:5: error: Argument 1 to &amp;quot;foo&amp;quot; has incompatible type &amp;quot;str&amp;quot;; expected &amp;quot;int&amp;quot; また、Type HintsがないライブラリなどのためにStubファイルを別に作って型を書くこともできるようにもなっている。デフォルトではStubがないモジュールはエラーになってしまうので必要に応じてignore_missing_importする。 mypy.iniやsetup.cfgに設定を書くと自動で使われる。
$ cat main.py import numpy as np $ mypy main.py main.py:1: error: No library stub file for module &#39;numpy&#39; main.py:1: note: (Stub files are from https://github.</description>
    </item>
    
    <item>
      <title>numpyの関数</title>
      <link>https://www.sambaiz.net/article/187/</link>
      <pubDate>Sun, 23 Sep 2018 23:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/187/</guid>
      <description>ndarrayの生成 ndarrayはnumpyの多次元の配列を表すオブジェクトで、[start:stop:step, &amp;hellip;]の indexでアクセスできる。
x = np.array([[1, 2, 3, 4], [2, 4, 6, 8]]) print(x[0, 1]) # 2 print(x[0,1:-1]) # [2 3] print(x[:,2]) # [3 6] print(x[:,::2]) # [[1 3] [2 6]] print(x[1,::-1]) # [8 6 4 2]  array() fromiter()  arrayやiteratableオブジェクトからndarrayを生成する。
print(np.array([1, 2, 3])) # [1 2 3] def generate(): for x in range(3): yield x x = np.fromiter(generate(), dtype=float) print(x) # [ 0. 1. 2.]  zeros() ones() full()  引数で渡したshapeを特定の値で埋めたndarrayを生成する。</description>
    </item>
    
    <item>
      <title>cert-managerで生成した証明書をIstioのGatewayに設定してHTTPS対応する</title>
      <link>https://www.sambaiz.net/article/186/</link>
      <pubDate>Thu, 13 Sep 2018 21:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/186/</guid>
      <description>cert-managerはTLSの証明書を自動で生成し管理するK8sのアドオン。 Istioにも含まれていて、これを使ってLet&amp;rsquo;s Encryptで証明書を生成しGatewayに設定することでHTTPS対応することができる。
デフォルトではcert-managerは入らないのでenabled=trueにしてインストールする。 最初に入るLet&amp;rsquo;s EncryptのClusterIssuerはエラーになったので消す。
IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net
$ helm install install/kubernetes/helm/istio --name istio --namespace istio-system --set certmanager.enabled=true $ kubectl delete ClusterIssuer --all 確認用にBookInfoを動かす。
$ kubectl label namespace default istio-injection=enabled $ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml $ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml Let&amp;rsquo;s Encryptで使われているACMEプロトコルのドメイン認証(Challenge)には /.well-known/acme-challenge/{token}でHTTPレスポンスを返すHTTP Challenge(http-01)と DNSのTXTレコードに書き込むDNS Challenge(dns-01)がある。 HTTP Challengeは手軽に達成できる一方、CAからアクセスできるようにする必要がある。今回はDNS Challengeでやる。 cert-managerはCloud DNSやRoute53などに対応していて、今回はCloudflareを使う。
DNSに書き込めるようにするためCloudflareのMy ProfileからGlobal API Keyを持ってきてBase64デコードしSecretに入れる。 改行コードが含まれないように-nを付ける。
$ echo -n ***** | base64 apiVersion: v1 kind: Secret metadata: name: cloudflare-api-key namespace: istio-system type: Opaque data: api-key: ***** Let&amp;rsquo;s EncryptのClusterIssuerと証明書を生成するドメインのCertificateを作成する。 serverのURLはStatusのページから確認できる。 本番のURLはレート制限があるので、まずはFakeの証明書が生成されるstgで試すとよい。</description>
    </item>
    
    <item>
      <title>IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する</title>
      <link>https://www.sambaiz.net/article/185/</link>
      <pubDate>Sun, 02 Sep 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/185/</guid>
      <description>IstioはEnvoyというProxyをSidecarとしてPodに入れてトラフィックを通すことでマイクロサービスのRoutingやTelemetryをサービスのコードに手を入れずに行うことができるサービスメッシュ。 もともとEnvoy自体は単体で、コネクションを張りっぱなしのgRPC(HTTP/2)をK8sのServiceのL4ロードバランサーでは分散できない問題の解決方法の一つとして 各PodのIPの一覧を返すHeadless Serviceと使われていたが、各Manifestに入れたりConfigMapを編集したりする必要があり少し面倒だった。 Istioにするとそれらが省けて、さらに賢いRoutingやモニタリングの仕組みまで付いてくるのでとても便利だ。
インストール IstioをダウンロードしてきてHelmでインストールする。Istioには様々なコンポーネントが含まれているが、パラメータでインストールするものを選択することができる。
KubernetesのパッケージマネージャーHelmを使う - sambaiz-net
今回はデフォルトではfalseになっているGrafana/Jaeger/Kialiをtrueにしてほぼ全て入るようにしている。
RBACが有効な場合はServiceAccountを作ってcluster-adminあるいは必要なRoleをBindしておく。
RBACが有効なGKEでHelmを使う - sambaiz-net
$ curl -L https://git.io/getLatestIstio | sh - $ cd istio-1.0.1/ # helm init --service-account tiller $ helm install install/kubernetes/helm/istio --name istio --namespace istio-system --set grafana.enabled=true --set grafana.persist=true --set grafana.storageClassName=standard --set tracing.enabled=true --set kiali.enabled=true $ kubectl get pod -n istio-system NAME READY STATUS RESTARTS AGE grafana-598678cbb-bglbq 1/1 Running 0 3m istio-citadel-6f9887d776-tvdg8 1/1 Running 0 3m istio-egressgateway-84d78d84bf-zpxrq 1/1 Running 0 3m istio-galley-556f5558f5-hk2r8 1/1 Running 0 3m istio-ingressgateway-78cccbddbb-gh2xl 1/1 Running 0 3m istio-pilot-799845f56d-l777d 2/2 Running 0 3m istio-policy-7666fcd574-nbx8s 2/2 Running 0 3m istio-sidecar-injector-7b6589c9-m7x77 1/1 Running 0 3m istio-statsd-prom-bridge-55965ff9c8-s6dmj 1/1 Running 0 3m istio-telemetry-844c8d6bff-9trcf 2/2 Running 0 3m istio-tracing-77f9f94b98-g7v6f 1/1 Running 0 3m kiali-bdf7fdc78-9lpd4 1/1 Running 0 3m prometheus-7456f56c96-drhlq 1/1 Running 0 3m default namespaceにラベルを貼って自動でEnvoyが各PodにInjectionされるようにする。</description>
    </item>
    
    <item>
      <title>nohupし忘れた時間のかかる処理をdisownしてexit後も実行させ続ける</title>
      <link>https://www.sambaiz.net/article/184/</link>
      <pubDate>Thu, 23 Aug 2018 00:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/184/</guid>
      <description>時間がかかるコマンドを実行する場合、通常はnohupで実行し ターミナル終了時に飛ぶSIGHUP(SIGnal Hang UP)を無視させることで exitしても実行させ続けることができる。
$ nohup ./foo &amp;amp; ただnohupを付けずに実行し始めてから思ったより時間がかかるということもある。 その場合は、Ctrl+Zで一旦停止してからbgでバックラウンドで実行するようにしてdisown -hでSIGHUPが送られないようにできる。 disownはシェルのジョブテーブルから削除するコマンドで、そのままでもSIGHUPが送られないようにできるが、 -hを付けるとジョブテーブルから削除せずに済む。
$ jobs [1]+ 停止 ./foo $ bg 1 $ jobs [1]+ 実行中 ./foo $ disown -h %1 </description>
    </item>
    
    <item>
      <title>CircleCI 2.0でDocker imageをbuildしてタグを付けてContainer Registryに上げる</title>
      <link>https://www.sambaiz.net/article/183/</link>
      <pubDate>Wed, 22 Aug 2018 23:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/183/</guid>
      <description>(追記: 2019-04-13) 2.1からのOrbを使うと自分でjobを書かなくてもよくなる CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる - sambaiz-net
 masterにpushしたときと、リリースタグを切ったときにビルドされるようにする。
version: 2 jobs: build: docker: - image: google/cloud-sdk environment: GCP_PROJECT: &amp;lt;project_name&amp;gt; IMAGE_NAME: &amp;lt;image_name&amp;gt; steps: - checkout - setup_remote_docker: version: 18.05.0-ce - run: name: gcloud auth command: | echo $GCLOUD_SERVICE_KEY | base64 --decode &amp;gt; ${HOME}/gcloud-service-key.json gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json gcloud --quiet auth configure-docker - run: name: docker build &amp;amp; push command: | docker build -t asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} . docker tag asia.</description>
    </item>
    
    <item>
      <title>KubernetesのCustom Resource Definition(CRD)とCustom Controller</title>
      <link>https://www.sambaiz.net/article/182/</link>
      <pubDate>Thu, 09 Aug 2018 23:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/182/</guid>
      <description>K8sではDeploymentを作成したときにReplicaSetも作成されるようにしたり、 Load Balancer Serviceを作成したときにGCPなどその環境に応じたLoad Balancerも作成されるようにしたりするため、Controllerがそれらを監視してAPIを呼んでいる。
GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net
Controllerは単なるAPIを呼ぶアプリケーションなので自分でCustom Controllerを作成してDeploymentとしてデプロイすることもできる。 また、監視する対象もpodsやdeploymentsといった標準のAPIだけではなく、 Custom Resource で拡張したものを使うことができる。
特定のアプリケーションのためのControllerはOperatorとも呼ばれる。
CustomResourceDefinition(CRD) Custom Resourceを定義する。
apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: crontabs.stable.example.com spec: # REST APIで使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt; group: stable.example.com version: v1 # Namespaced か Cluster scope: Namespaced names: # 複数形 URLに使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;/&amp;lt;plural&amp;gt; plural: crontabs # 単数形 CLIなどで使われる singular: crontab # manifestで使う kind: CronTab shortNames: - ct $ kubectl create -f crd.yaml $ kubectl get crd NAME AGE crontabs.</description>
    </item>
    
    <item>
      <title>KubernetesのNetworkPolicy Resource</title>
      <link>https://www.sambaiz.net/article/181/</link>
      <pubDate>Mon, 30 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/181/</guid>
      <description>Network Policies - Kubernetes
PodのトラフィックをラベルやIPアドレスで許可するためのResource。AWSのセキュリティグループやGCPのファイアウォールルールのようなもの。 GKEでは今のところデフォルトでオフになっているので--enable-network-policyを付けてクラスタを作成する必要がある。
以前作成したmulti podのアプリケーションで挙動を確認する。
GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net
$ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE clusterip-app ClusterIP 10.23.247.54 &amp;lt;none&amp;gt; 80/TCP 48m loadbalancer-app LoadBalancer 10.23.244.137 35.224.130.196 80:31508/TCP 48m nodeport-app NodePort 10.23.246.215 &amp;lt;none&amp;gt; 80:32181/TCP 48m ... $ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/ 200 作成するNetworkPolicyは以下の二つで、いずれも対象はapp: nodeport-appのラベルが付いたPod。 一つ目は対象Podへのリクエストを一旦全て拒否する。 二つ目はnodeport-access: &amp;quot;true&amp;quot;のラベルが付いたPodから対象Podへの8080ポートのリクエストを許可するもの。 今回は設定しないがegressも設定できる。
$ cat networkPolicies.yaml --- # Default deny all ingress traffic apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: default-deny spec: podSelector: matchLabels: app: nodeport-app --- apiVersion: networking.</description>
    </item>
    
    <item>
      <title>GCPのCloud Pub/Sub</title>
      <link>https://www.sambaiz.net/article/180/</link>
      <pubDate>Thu, 26 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/180/</guid>
      <description>スケーラビリティに優れるメッセージングミドルウェア。 データはPullするだけではなくhttpsのエンドポイントにPushすることもでき、Cloud Dataflowを通してBigQueryやCloud MLに繋げることもできる。GAEのTaskQueueのように遅延させる機能は今のところない。
GAEのTaskQueue - sambaiz-net
料金はPublish/Pull/Pushしたデータ容量による。1TB送ると$60くらい。
Goのクライアントライブラリで動かしてみる。 まずTopicを作成して50件Publishした後、Subsriptionを作成して、再び50件Publishする。 Publishできるデータは10MB未満。
topic, err := client.CreateTopic(ctx, topicName) if err != nil { panic(err) } var wg sync.WaitGroup for i := 0; i &amp;lt; 50; i++ { wg.Add(1) go func() { if _, err := topic.Publish(ctx, &amp;amp;pubsub.Message{Data: []byte(strconv.Itoa(i))}).Get(ctx); err != nil { log.Fatalf(&amp;quot;Publish error: %s&amp;quot;, err.Error()) } else { log.Printf(&amp;quot;Publish successful: %d&amp;quot;, i) } wg.Done() }() wg.Wait() } log.Printf(&amp;quot;Create Subscription&amp;quot;) sub := createSubscription(ctx, client, topic, subscriptionName) for i := 50; i &amp;lt; 100; i++ { wg.</description>
    </item>
    
    <item>
      <title>Destributed TensorFlowの流れとSavedModelの出力</title>
      <link>https://www.sambaiz.net/article/179/</link>
      <pubDate>Wed, 25 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/179/</guid>
      <description>Distributed TensorFlow クラスタを組んでGraphを分散実行する。
クラスタは
 master: sessionを作成し、workerを制御する worker: 計算を行う ps(parameter server): 変数の値を持ち、更新する  のjobからなり、gRPCの
 Master Service Worker Service  でやり取りする。
TensorFlow serverを立てる 各jobとURLのmapをClusterSpecにして jobとindexと併せてServerDefを作って Serverを立てる。
{ &amp;quot;master&amp;quot;: [ &amp;quot;check-tf-config-master-34z8-0:2222&amp;quot; ], &amp;quot;ps&amp;quot;: [ &amp;quot;check-tf-config-ps-34z8-0:2222&amp;quot;, &amp;quot;check-tf-config-ps-34z8-1:2222&amp;quot; ], &amp;quot;worker&amp;quot;: [ &amp;quot;check-tf-config-worker-34z8-0:2222&amp;quot;, &amp;quot;check-tf-config-worker-34z8-1:2222&amp;quot; ] } cluster_spec_object = tf.train.ClusterSpec(cluster_spec) server_def = tf.train.ServerDef( cluster=cluster_spec_object.as_cluster_def(), protocol=&amp;quot;grpc&amp;quot;, job_name=job_name, # worker, master, ps task_index=0) server = tf.train.Server(server_def) psのjobではserver.join()して待ち構える。
if job_name == &amp;quot;ps&amp;quot;: server.join() else: # build model WorkerにGraphを割り当てる workerのdeviceにGraphを割り当てる。 deviceは/job:worker/replica:0/task:0/device:GPU:0 のようなフォーマットで表される。</description>
    </item>
    
    <item>
      <title>GAEのTaskQueue</title>
      <link>https://www.sambaiz.net/article/178/</link>
      <pubDate>Sun, 15 Jul 2018 16:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/178/</guid>
      <description>GCPのマネージドなQueueサービスとしてGAEのTaskQueueがあることを教えてもらったので動かしてみる。 PushQueueとPullQueueがあって、それぞれおおよそAWSのSNSとSQSに相当する。PushQueueの場合はHTTPのリクエストとしてGAEのサービスに投げられる。PullQueueはCloud Tasks APIを使えばGAE外からも使えるらしいがまだalpha。
設定ファイルqueue.yamlはこんな感じ。bucket_sizeは最大同時実行数で空いていたらrateで埋められていく。
queue: - name: default rate: 10/m bucket_size: 5 retry_parameters: min_backoff_seconds: 10 max_backoff_seconds: 300 bucket_sizeの最大は500なのでこれ以上の性能が必要な場合は複数のQueueに分けるか Cloud Pub/Subを使うことになる。ただし、At-Least-Onceなのでレコードが重複しても問題ないように作る必要がある。SQSも同じ。
GCPのCloud Pub/Sub - sambaiz-net
アプリケーション /にアクセスすると2つのTaskをdefaultのTaskQueueにDelay25秒でPOSTする。 Taskによるリクエストは/workerで受け、30%の確率で500エラーを返すようにしている。
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;io/ioutil&amp;quot; &amp;quot;math/rand&amp;quot; &amp;quot;net/http&amp;quot; &amp;quot;net/url&amp;quot; &amp;quot;strconv&amp;quot; &amp;quot;time&amp;quot; &amp;quot;google.golang.org/appengine&amp;quot; &amp;quot;google.golang.org/appengine/log&amp;quot; &amp;quot;google.golang.org/appengine/taskqueue&amp;quot; ) func main() { http.HandleFunc(&amp;quot;/&amp;quot;, handler) http.HandleFunc(&amp;quot;/worker&amp;quot;, handlerQueue) appengine.Main() } func handler(w http.ResponseWriter, r *http.Request) { ctx := appengine.NewContext(r) // POST body: name=a%26&amp;amp;value=20 t := taskqueue.NewPOSTTask(&amp;quot;/worker&amp;quot;, map[string][]string{&amp;quot;name&amp;quot;: {&amp;quot;a&amp;amp;&amp;quot;}, &amp;quot;time&amp;quot;: {strconv.</description>
    </item>
    
    <item>
      <title>WebSocketでの通信内容をWiresharkで見る</title>
      <link>https://www.sambaiz.net/article/177/</link>
      <pubDate>Tue, 10 Jul 2018 23:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/177/</guid>
      <description>Webで双方向通信するためのプロトコル、WebSocketでの通信内容をWiresharkで見る。
アプリケーション サーバー package main import ( &amp;quot;context&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;io&amp;quot; &amp;quot;net/http&amp;quot; &amp;quot;golang.org/x/net/websocket&amp;quot; ) type Payload struct { A string } func Handler(ws *websocket.Conn) { ctx, cancel := context.WithCancel(context.Background()) go func() { var payload Payload for { err := websocket.JSON.Receive(ws, &amp;amp;payload) if err != nil { if err == io.EOF { fmt.Println(&amp;quot;connection closed&amp;quot;) } else { fmt.Println(err) } cancel() break } fmt.Println(payload.A) } }() websocket.JSON.Send(ws, Payload{A: &amp;quot;a&amp;quot;}) select { case &amp;lt;-ctx.Done(): } } func main() { http.</description>
    </item>
    
    <item>
      <title>DOMの(next/previous)SiblingとElementSiblingの値</title>
      <link>https://www.sambaiz.net/article/176/</link>
      <pubDate>Wed, 04 Jul 2018 23:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/176/</guid>
      <description>Siblingは兄弟姉妹という意味
&amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt; &amp;lt;li id=&amp;quot;li2&amp;quot;&amp;gt;2&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;3&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;script&amp;gt; const el = document.querySelector(&amp;quot;li#li2&amp;quot;); &amp;lt;/script&amp;gt; Sibling elのpreviousSiblingを取ると&amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt;になると思いきや、その直前の空白や改行を含むtext nodeが返る。 それらが全くない場合隣のElementが返ることになる。
const el2 = el.previousSibling; console.log(`previousSibling: ${el2.nodeName} &amp;quot;${el2.textContent}&amp;quot;`); /* #text &amp;quot; &amp;quot; */ const el4 = el.nextSibling; console.log(`nextSibling: ${el4.nodeName} &amp;quot;${el4.textContent}&amp;quot;`); // LI &amp;quot;3&amp;quot; ElementSibling 多くの場合で意図した結果が返るのはこっち。
const el3 = el.previousElementSibling; console.log(`previousElementSibling: ${el3.nodeName} &amp;quot;${el3.textContent}&amp;quot;`); // LI &amp;quot;1&amp;quot; const el5 = el.nextElementSibling; console.log(`nextElementSibling: ${el5.nodeName} &amp;quot;${el5.textContent}&amp;quot;`); // LI &amp;quot;3&amp;quot; firstChildとfirstElementChildなどの関係も同じ。存在を忘れていてひっかかった。
const el6 = document.querySelector(&amp;quot;ul&amp;quot;).firstChild; console.log(`firstChild: ${el6.nodeName} &amp;quot;${el6.textContent}&amp;quot;`); /* fistChild: #text &amp;quot; &amp;quot; */ </description>
    </item>
    
    <item>
      <title>TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー</title>
      <link>https://www.sambaiz.net/article/175/</link>
      <pubDate>Sun, 01 Jul 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/175/</guid>
      <description>MonitoredSession
deprecatedになったSupervisorの後継。
MonitoredTrainingSessionで学習用のMonitoredSessionを生成する。 このコンストラクタの引数でcheckpoint_dirを渡すと内部でCheckpointSaverHookが 追加されるようになっていて、restoreしたり指定したタイミングでsaveしたりしてくれる。
なので今回明示的に渡すhooksは 指定したstepに到達したら止めてくれる、StopAtStepHookのみ。
should_stop()がTrueな状態でsession.run()しようとするとRun called even after should_stop requested.のエラーが出るため、 今回は新しいsessionを作ってAccuracyを返しているが、hookでやった方がrestoreする必要がないので良さそうだ。
Destributed TensorFlowの流れとSavedModelの出力 - sambaiz-net
全体のコードはここ。
def train(self, learning_rate, variable_default_stddev, bias_default, last_step=800): test_images = self.images[:500] test_labels = self.labels[:500] train_batch = Batch(self.images[500:], self.labels[500:]) with tf.Graph().as_default(): global_step=tf.train.get_or_create_global_step() g = MNIST_CNN(learning_rate, variable_default_stddev, bias_default).graph() saver = tf.train.Saver() savedir = &#39;./ckpt-{}-{}-{}&#39;.format(learning_rate, variable_default_stddev, bias_default) hooks = [ tf.train.StopAtStepHook(last_step=last_step) ] with tf.train.MonitoredTrainingSession( hooks=hooks, checkpoint_dir=savedir, save_checkpoint_secs = 300, ) as sess: sess.run(global_step) while not sess.should_stop(): # step = sess.</description>
    </item>
    
    <item>
      <title>GoのgRPC ServerのInterceptor(recovery/auth/zap/prometheus)</title>
      <link>https://www.sambaiz.net/article/174/</link>
      <pubDate>Tue, 26 Jun 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/174/</guid>
      <description>grpc-goはInterceptor(Middleware)でhandlerの前後で処理を行うことができる。 UnaryとStreamでシグネチャが異なる。
type UnaryServerInterceptor func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (resp interface{}, err error) type StreamServerInterceptor func(srv interface{}, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error func UnaryServerInterceptor(opts ...Option) grpc.UnaryServerInterceptor { return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) { resp, err := handler(newCtx, req) fmt.Println(resp) return resp, err } } 今回は良く使うgo-grpc-middlewareの
 recovery auth zap prometehus  Interceptorの挙動を確認する。
proto UnaryなRPCとBidirectional streaming(client, server共にstream)なRPCを一つずつ用意する。
$ cat protos/sample/service.</description>
    </item>
    
    <item>
      <title>GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress</title>
      <link>https://www.sambaiz.net/article/173/</link>
      <pubDate>Sat, 23 Jun 2018 15:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/173/</guid>
      <description>疎通確認用アプリケーション GETでは200を返し、POSTではURLにGETリクエストを送ってステータスコードを返す。
package main import ( &amp;quot;encoding/json&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;io/ioutil&amp;quot; &amp;quot;net/http&amp;quot; ) type PostBody struct { URL string `json:&amp;quot;url&amp;quot;` } func handler(w http.ResponseWriter, r *http.Request) { if r.Method == http.MethodGet { fmt.Fprintln(w, &amp;quot;ok&amp;quot;) } else if r.Method == http.MethodPost { data, err := ioutil.ReadAll(r.Body) if err != nil { w.WriteHeader(http.StatusInternalServerError) fmt.Fprintln(w, err.Error()) return } p := PostBody{} if err := json.Unmarshal(data, &amp;amp;p); err != nil { w.WriteHeader(http.StatusBadRequest) fmt.Fprintln(w, err.Error()) return } resp, err := http.</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをsave/loadする</title>
      <link>https://www.sambaiz.net/article/172/</link>
      <pubDate>Fri, 22 Jun 2018 01:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/172/</guid>
      <description>SavedModelBuilderで モデルを言語に依存しないSavedModelのprotobufにして保存できる。 SavedModelにはSaverによって出力されるCheckpointを共有する一つ以上のMetaGraphDefを含む。
import tensorflow as tf def build_signature(signature_inputs, signature_outputs): return tf.saved_model.signature_def_utils.build_signature_def( signature_inputs, signature_outputs, tf.saved_model.signature_constants.REGRESS_METHOD_NAME) def save(sess, export_dir, signature_def_map): builder = tf.saved_model.builder.SavedModelBuilder(export_dir) builder.add_meta_graph_and_variables( sess, [tf.saved_model.tag_constants.SERVING], signature_def_map=signature_def_map ) builder.save() import shutil import os.path export_dir = &amp;quot;./saved_model&amp;quot; if os.path.exists(export_dir): shutil.rmtree(export_dir) with tf.Graph().as_default(): a = tf.placeholder(tf.float32, name=&amp;quot;a&amp;quot;) b = tf.placeholder(tf.float32, name=&amp;quot;b&amp;quot;) c = tf.add(a, b, name=&amp;quot;c&amp;quot;) v = tf.placeholder(tf.float32, name=&amp;quot;v&amp;quot;) w = tf.Variable(0.0, name=&amp;quot;w&amp;quot;) x = w.assign(tf.add(v, w)) sv = tf.train.Supervisor() with sv.managed_session() as sess: print(sess.</description>
    </item>
    
    <item>
      <title>ksonnetでkubernetesのmanifestを環境ごとに生成/applyする</title>
      <link>https://www.sambaiz.net/article/171/</link>
      <pubDate>Wed, 20 Jun 2018 01:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/171/</guid>
      <description>ksonnetはJSONのテンプレートエンジンjsonnetからk8sのmanifestを環境ごとに生成してapplyするツール。kubeflowでも使われている。
$ brew install ksonnet/tap/ks $ ks version ksonnet version: 0.11.0 jsonnet version: v0.10.0 client-go version: init まずks initしてディレクトリを作成する。
$ kubectl config current-context minikube $ ks init kstest $ cd kstest $ ls app.yaml	components	environments	lib	vendor $ cat app.yaml apiVersion: 0.1.0 environments: default: destination: namespace: default server: https://192.168.99.100:8443 k8sVersion: v1.10.0 path: default kind: ksonnet.io/app name: kstest registries: incubator: gitVersion: commitSha: 40285d8a14f1ac5787e405e1023cf0c07f6aa28c refSpec: master protocol: github uri: github.com/ksonnet/parts/tree/master/incubator version: 0.</description>
    </item>
    
    <item>
      <title>Pandasの操作</title>
      <link>https://www.sambaiz.net/article/170/</link>
      <pubDate>Wed, 13 Jun 2018 23:47:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/170/</guid>
      <description>SeriesとDataframe import pandas as pd import numpy as np s = pd.Series([1,3]) print(s[1]) # 3 print(s.values) # [1 3] (ndarray) dates = pd.date_range(&#39;2014-11-01 10:00&#39;,periods=3, freq=&#39;2H&#39;) print(dates) # DatetimeIndex([&#39;2014-11-01 10:00:00&#39;, &#39;2014-11-01 12:00:00&#39;, &#39;2014-11-01 14:00:00&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;2H&#39;) datestr = lambda d: pd.to_datetime(d).strftime(&#39;%Y-%m-%d %H:%M&#39;) df = pd.DataFrame({ &#39;A&#39; : 1., &#39;B&#39; : pd.Series(range(6), index=pd.date_range(&#39;2014-11-01 10:00&#39;,periods=6, freq=&#39;H&#39;)), &#39;C&#39; : [9, 1, 5], }, index=dates) df2 = pd.DataFrame({ &#39;D&#39; : range(3), }, index=dates) print(df) |(index) |A |B|C| |-------------------|---|-|-| |2014-11-01 10:00:00|1.</description>
    </item>
    
    <item>
      <title>ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す</title>
      <link>https://www.sambaiz.net/article/169/</link>
      <pubDate>Sun, 10 Jun 2018 17:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/169/</guid>
      <description>ベイズ最適化で良いハイパーパラメータを総当りのグリッドサーチより効率的に探す。
まず現在の最大値を超える確率や期待値を出力とする獲得関数を決めて、ガウス過程(GP)に従うと仮定する。 ガウス過程は回帰関数の確率モデルで、任意の入力(x1, x2, &amp;hellip; , xn)に対応する出力(y1, y2, &amp;hellip;, yn)がガウス分布(=正規分布)に従うというもの。 これによって予測されるまだ試していない入力での期待値や分散から次に試す値を決める。
今回はKaggleのTitanicのチュートリアルを、チューニングなしのランダムフォレストとXGBoostで解いたときの結果と比較して、ベイズ最適化によるハイパーパラメータで精度が向上するか確認する。
KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
ランダムフォレスト Pythonのベイズ最適化のライブラリ、BayesianOptimizationを使う。
$ pip install bayesian-optimization RandomForestClassifierのハイパーパラメータ
 n_estimators: 木の数 min_samples_split: ノードを分割するのに必要な最小サンプル数 max_features: 分割するときに考慮する特徴量の割合  の値を探すため、BayesianOptimizationに最大化したい値(精度)とパラメータの範囲を渡す。
from sklearn.model_selection import cross_val_score from sklearn.ensemble import RandomForestClassifier from bayes_opt import BayesianOptimization import pandas as pd def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/168/</link>
      <pubDate>Sat, 02 Jun 2018 18:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/168/</guid>
      <description>XGBoostは高性能なGradient Boostingのライブラリ。 Boostingというのはアンサンブル学習の種類の一つで、ランダムフォレストのように弱学習器をそれぞれ並列に学習するBaggingに対して、 順番に前回までの結果を受けながら学習し、結果をまとめる際にそれぞれの重みを掛けるもの。 XGBoostではランダムフォレストと同様に決定木を弱学習器とする。
KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net
$ pip install xgboost データの前処理はランダムフォレストと同じようにした。 パラメータの objective(目的関数)には二値分類なのでbinary:logisticを指定し、確率が返るのでroundして出力している。
import pandas as pd import xgboost as xgb from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int) df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1) return df def train(df): train_x = df.</description>
    </item>
    
    <item>
      <title>Istio v0.7でEnvoy Proxyを付けるまで</title>
      <link>https://www.sambaiz.net/article/167/</link>
      <pubDate>Tue, 29 May 2018 22:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/167/</guid>
      <description>追記(2018-09-01) v1.0となりHelmでのインストールも問題なくできるようになった。Istio-AuthがCitadelという名前になっていたりDeprecatedになってるAPIもある
IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net
 Istioとは マイクロサービス間のネットワークの、ロードバランシングや認証、モニタリングなどを担うサービスメッシュのOSS。 概念は抽象化されていて、Kubernetes以外でもサポートされている。 通信をコントロールするdata-planeのEnvoyと、Envoyを管理するcontrol-planeのPilot, Mixer, Istio-Authからなる。
Envoy Sidecarとしてデプロイされる、サービスメッシュでの全ての通信を通すプロキシ。 アプリケーションのコードに手を入れる必要がないので言語に縛られない。 CNCFのプロジェクトの一つで、 Istio用にオリジナルから拡張されている。 ロードバランシングやヘルスチェックなどを行い、メトリクスを取る。
Mixer サービスメッシュ全体のアクセスコントロールや、Envoyからデータを集めてログに出したりモニタリングしたりする。 プラグインよってAWSやGCPといったインフラバックエンドの差異が吸収される。
Pilot サービスディスカバリしてEnvoyのトラフィックを制御する。A/Bテストやカナリアリリースをする場合や、障害に対応して適切にルーティングを行うことができる。
Istio-Auth サービスやエンドユーザーの認証を行い、ポリシーに従ってアクセス制御する。
Istioのインストール ローカルのminikubeに環境を作る。 apiserver.Admission.PluginNamesでは立ち上がらなかったので代わりに apiserver.admission-controlを指定している。
$ minikube version minikube version: v0.27.0 $ minikube start \ --extra-config=apiserver.admission-control=&amp;quot;NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota&amp;quot; \ --kubernetes-version=v1.9.0 $ kubectl config current-context minikube istioを持ってきてapplyする。 Helmも用意されていて将来的にそっちで入れるのが推奨になりそうだ。
$ curl -L https://git.io/getLatestIstio | sh - $ cd istio-0.7.1/ $ kubectl apply -f install/kubernetes/istio-auth.yaml 作成されたserviceとpodはこんな感じ。
$ kubectl get svc -o name -n istio-system NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE istio-ingress LoadBalancer 10.</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
      <link>https://www.sambaiz.net/article/166/</link>
      <pubDate>Tue, 29 May 2018 09:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/166/</guid>
      <description>ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成し並列に学習するアンサンブル学習のBaggingという種類の手法。 決定木なので特徴量の影響が分かりやすく、単一の決定木と比べて過学習を防ぐことができる。
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
train.csvとtest.csvをKaggleからダウンロードする。 csvにはタイタニックの乗客者リストが含まれ、test.csvには生還したかを表すSurvivedが抜けている。 これを予測するのがこのコンペティションの目的だ。
データのうちFareやAge、Embarkedは入っていないものがあって、これらの欠損値をどう扱うという問題がある。
df = pd.read_csv(&#39;./train.csv&#39;) print(len(df)) print(df.isnull().sum()) 891 PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 連続値をとるFareとAgeは平均を取り、Embarkedは欠損値用の値にしてみた。数値化できないものについては除いている。
def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).</description>
    </item>
    
    <item>
      <title>TerraformでGKEクラスタとBigQueryを立てる</title>
      <link>https://www.sambaiz.net/article/165/</link>
      <pubDate>Tue, 29 May 2018 02:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/165/</guid>
      <description>GKEクラスタからBigQueryを読み書きすることを想定している。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net
GKE  google_container_cluster  oauth_scopeにbigqueryを付けている。
resource &amp;quot;google_container_cluster&amp;quot; &amp;quot;sample&amp;quot; { name = &amp;quot;${var.cluster_name}&amp;quot; description = &amp;quot;sample k8s cluster&amp;quot; zone = &amp;quot;${var.gcp_zone}&amp;quot; initial_node_count = &amp;quot;${var.initial_node_count}&amp;quot; master_auth { username = &amp;quot;${var.master_username}&amp;quot; password = &amp;quot;${var.master_password}&amp;quot; } node_config { machine_type = &amp;quot;${var.node_machine_type}&amp;quot; disk_size_gb = &amp;quot;${var.node_disk_size}&amp;quot; oauth_scopes = [ &amp;quot;https://www.googleapis.com/auth/compute&amp;quot;, &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;, &amp;quot;https://www.googleapis.com/auth/logging.write&amp;quot;, &amp;quot;https://www.googleapis.com/auth/monitoring&amp;quot;, &amp;quot;https://www.googleapis.com/auth/bigquery&amp;quot;, ] } } variable &amp;quot;env&amp;quot; { description = &amp;quot;system env&amp;quot; } variable &amp;quot;gcp_zone&amp;quot; { description = &amp;quot;GCP zone, e.</description>
    </item>
    
    <item>
      <title>カナダのバンクーバーから南へ5都市周ってGoogleI/Oに行ってきた</title>
      <link>https://www.sambaiz.net/article/164/</link>
      <pubDate>Mon, 28 May 2018 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/164/</guid>
      <description>去年と連続でチケットが当たって2回目の参加。 前回はニューヨークで大変な目にあったが、 今回はI/OがGWの次の週だったので日程に余裕があり、カナダのバンクーバーから、ビクトリア、アメリカに入ってポートエンジェルス、シアトル、ポートランドと南下していって会場のマウンテンビューを目指すことにした。
準備 前回と同じ基本的にExpediaで航空券やホテルは取って、各業者のサイトで都市間の移動に使うフェリーやバスや電車を予約して、 あとアメリカのeSTAのようにカナダにもeTAというのがあって申請した。
前回は空港からマンハッタンのT-mobileのショップにたどり着くまでネット回線がなく、地図すら空港のwifi頼みで大変な思いをした。 今回はカナダも行くので事前にAmazonでカナダも対応しているプランのSIMを購入して業者にアクティベートしてもらうことにした。
今回は夜出発だったので時間に余裕があったが、念のため前日から万札を何枚か財布に入れておいた。つまるところ、現金とネットさえあればなんとでもなるのだ。
バンクーバー 空港から出ても怪しい人を見かけないし、駅の人も愛想良く案内してくれる。 アナウンスもはっきりしているので聞き取りやすく券売機のUIもわかりやすい。 駅の券売機で交通ICカードCompassを手に入れれば、電車・バス共に乗ることができる。 Uberは走っていないがバスが発達していて大体事足りる。バス停の標識も比較的低い位置にあって気付きやすい。
バスから降りるとき皆Thank youと言ってるのは良い感じだ。財布を落としたり傘を忘れたりしても皆で教えてくれるし、人が親切で治安が良くて安心感がある。
アジア系の飲食店が多い。漢字が併記されているのもよく見る。
朝食はJethro&amp;rsquo;s Fine Grubという店で取った。ダウンタウンからは少し離れてるのに待ちが発生していた。
これを食べてからGranville Islandという店が並んでいるところに行ってきた。 Public Marketにはソーセージやお菓子などが売ってたりするんだけど、腹が一向に空かないし、中には座れず外はとても寒かったので何も買わずに帰ってきた。
ビクトリア BC Ferries ConnectorというバスがバンクーバーのPublic Central Stationから出ていて、これに乗るとそのままフェリーに乗り込んでビクトリアまで行くことができる。船内のカフェテリアにカナダらしい食べ物プーティンがあったので頼んでみたら思ったより量が多く、15分前ぐらいのアナウンスでバスに戻らないと普通に置いてかれるので、なんとかコーラで流し込んだ。
ビクトリアのダウンタウンに到着後、バスで1時間くらいかけて北へButchers Gardenという庭園に向かった。 ビクトリアには交通ICカードがないので、車内で5ドル払って1日乗車券をもらって乗る。 この時期は色とりどりのチューリップが咲いていて、歩いているだけで良い香りがする。
そのほかに鹿おどしのある日本庭園や、イタリア庭園もあったりする。
このためにビクトリアを訪れてもよいぐらい満足度が高かった。
朝食はBlueFox Caffeという店でEggs Pacificoというサーモンとアボカドのエッグベネディクトを頼んだ。 付け合わせの芋が多いが、とても美味しい。1日1食の日々がしばらく続く。
ポートエンジェルス(オリンピック半島) ビクトリアの州議事堂の近くから出ているBlack Ball Ferry Lineに乗ってポートエンジェルスに移動する。 予約しても受付でチケットを受け取る必要がある。乗る前に入国審査を受けて、I-94Aという紙をパスポートに貼ってもらった。 料金が6ドルかかる。カードでも払えるがカナダドルでは払えなかった。
町の自転車屋で電動自転車を借りて、まずはオリンピック国立公園のビジターセンターを目指した。ここで10ドル払うと入園券みたいなののとマップがもらえる。 どこに行くつもりか、と聞かれたので何も考えてないと答えると、比較的近くにあるHurricane Ridgeという所を教えてもらったのでそこを目指すことにした。
オフシーズンだからか道を工事していて所々コンディションが悪い。しかもずっと上り坂だ。 それでも電動アシストの力を借りて登っていったのだが、途中でまさかの電池切れ。しょうがないので町に引き返してその日は終わり。返すとき顛末を説明したら割り引いてくれた。
次の日はバスでMarymere fallsという小さな滝のトレッキングコースに行った。散歩みたいなコースですぐ終わってしまったので、 途中の分岐にあったStormKingというコースにも入ってみたら、傾斜が延々と続く山登りコースだった。終盤END OF MAINTAINED TRAILの標識よりあとはいろいろ厳しくなり、勇気と気合いでロープをつかみながら登っていくことになる。
頂上からはCrescent Lakeがその名の通り三日月に見える。景色はよいのだけど足場が狭くて立っているだけで怖い。
シアトル ポートエンジェルスからバスでシアトルへ。Olympic Bus Linesのバスで、クッキーが配られた。
シアトルのホテルは高かったのでAirBnbを使ってみた。ナンバーロック式の部屋だったので、ホストとはメッセージのやりとりだけで済んだし、親切にも日本語のガイドブックまで用意しておいてくれた。
まず、交通ICカードOrcaを手に入れようと、駅の自販機にクレジットカードを入れたところ出てこなくなってしまった。駅員はいないので、なんとか引き抜こうと頑張っていたところ、親切な人がペンチを借りてきてくれてなんとか引き抜くことができた。よかった。 ただ、こんな苦労して手に入れたOrcaも2回ぐらいしか使わなかった。というのもバス停が他の標識と混在して分かりづらく、Uberに迎えに来てもらった方が楽だったからだ。相乗りのUber Poolならバスの倍くらいで乗ることができる。
気を取り直して、Amazonの本部、Day 1に行ってきた。前から予約すれば社内ツアーもあるみたいだけど、今回の目的はこの1階にある、今年オープンしたレジ無しコンビニのAmazon Goだ。</description>
    </item>
    
    <item>
      <title>Macでの開発環境構築メモ</title>
      <link>https://www.sambaiz.net/article/163/</link>
      <pubDate>Sat, 14 Apr 2018 14:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/163/</guid>
      <description>新しいMBPを買ったので開発環境の構築でやったことを残しておく
設定  アクセシビリティから3本指スクロールを有効にする ホットコーナーの左上にLaunchPad、右上にデスクトップを割り当てている 画面をなるべく広く使うためにDockは左に置いて自動的に隠す  bash_profile パッケージマネージャ以外で持ってきたバイナリは${HOME}/binに置くことにする。
touch ~/.bash_profile mkdir ${HOME}/bin echo &amp;quot;export PATH=\$PATH:${HOME}/bin&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile HomeBrew &amp;amp; Cask /usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot; brew tap caskroom/cask 一般的なアプリケーション/コマンドのインストール XcodeとUnityとLINEは手動で入れる。
brew cask install google-chrome kap visual-studio-code slack kindle brew install jq gibo mysql wget Git git config --global user.name sambaiz git config --global user.email godgourd@gmail.com Docker &amp;amp; K8s brew cask install docker virtualbox minikube brew install docker kubernetes-helm fish bash前提で書かれたスクリプトも多いので、デフォルトシェルにはしない。</description>
    </item>
    
    <item>
      <title>Pythonのasyncioで非同期にリクエストを飛ばす</title>
      <link>https://www.sambaiz.net/article/162/</link>
      <pubDate>Sat, 14 Apr 2018 13:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/162/</guid>
      <description>Pythonのasyncioはイベントループを回してシングルスレッドで並行に非同期処理を行う。 マルチスレッドで並列に実行するのがthreadingで、 マルチプロセスで並列に実行するのがmultiprocessing。
import asyncio async def sleep(s): await asyncio.sleep(s) print(s) return s loop = asyncio.get_event_loop() loop.run_until_complete(sleep(5)) coros = [sleep(3), sleep(2)] futures = asyncio.gather(*coros) loop.run_until_complete(futures) print(futures.result()) loop.close() $ python main.py 5 2 3 [3, 2] get_event_loop() でイベントループを取得し、 gather()で処理をまとめたりして、 run_until_complete()で Futureの完了を待ち、 結果を取得してイベントループをclose()している。
async defを付けた関数はCoroutineとなり、 ensure_future()でFutureのサブクラスの、イベントループで実行させるTaskにすることができる。 run_until_complete()はそのままCoroutineを投げてもensure_future()でwrapしてくれる。
httpクライアントrequestsはBlockingするようなので、asyncioに対応しているaiohttpを使ってリクエストしてみる。
import aiohttp import asyncio import async_timeout async def fetch(session, url): print(&amp;quot;{} start&amp;quot;.format(url)) async with async_timeout.timeout(10): async with session.get(url) as response: text = await response.text() print(&amp;quot;{} done&amp;quot;.</description>
    </item>
    
    <item>
      <title>Kubernetes,Helmで負荷試験ツールLocustを立てる</title>
      <link>https://www.sambaiz.net/article/161/</link>
      <pubDate>Sun, 18 Mar 2018 22:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/161/</guid>
      <description>OSSの負荷試験ツールLocustをK8sクラスタに立てる。 K8sならworkerの増減も簡単だし、HelmのChartもあるので立てるのも楽。
LocustはPython製で、以下のようなコードで処理を書くことができる。
@task(10)のように括弧の中に数字を書いて実行される割合を偏らせることもできる。 異なるTaskSetに対応するユーザーを複数作ることもできて、こちらもweightで重みを付けられる。 ユーザー数はあとでWeb上から入力する。
$ mkdir tasks $ cat tasks/tasks.py from locust import HttpLocust, TaskSet, task class ElbTasks(TaskSet): @task def task1(self): with client.get(&amp;quot;/&amp;quot;, catch_response=True) as response: if response.content != &amp;quot;Success&amp;quot;: response.failure(&amp;quot;Got wrong response&amp;quot;) class ElbWarmer(HttpLocust): task_set = ElbTasks min_wait = 1000 max_wait = 3000 stableにChartはあるが、今のところtasksの中を書き換えなくてはいけないようなので、forkしてきてtasksの中を書き換え、package して、helm repo index でこれを参照するindex.yamlを生成した。
 追記(2020-03-11): 今はConfigmapを自分で作成し --set worker.config.configmapName=*** することでforkしなくてもよくなった kubectl create configmap locust-worker-configs --from-file tasks/tasks.py
 $ helm package . $ helm repo index .</description>
    </item>
    
    <item>
      <title>RBACが有効なGKEでHelmを使う</title>
      <link>https://www.sambaiz.net/article/160/</link>
      <pubDate>Sun, 18 Mar 2018 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/160/</guid>
      <description>k8sのパッケージマネージャーHelmを使う - sambaiz-net
$ helm version Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.8.2&amp;quot;, GitCommit:&amp;quot;a80231648a1473929271764b920a8e346f6de844&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} Server: &amp;amp;version.Version{SemVer:&amp;quot;v2.8.2&amp;quot;, GitCommit:&amp;quot;a80231648a1473929271764b920a8e346f6de844&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} GKEでhelm initしてhelm installしたところ以下のエラーが返ってきた。
Error: release my-locust failed: namespaces &amp;quot;default&amp;quot; is forbidden: User &amp;quot;system:serviceaccount:kube-system:default&amp;quot; cannot get namespaces in the namespace &amp;quot;default&amp;quot;: Unknown user &amp;quot;system:serviceaccount:kube-system:default&amp;quot; GKEではデフォルトでK8sのRBAC(Role-Based Access Control)が有効になっているため、Tillerインスタンスに権限を与える必要がある。
ということでTiller用にnamespaceを切って、その中では好きにできるRoleと、Tillerが使うServiceAccountを作成し、RoleBindingで紐づける。
kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: tiller-manager namespace: tiller-world rules: - apiGroups: [&amp;quot;&amp;quot;, &amp;quot;extensions&amp;quot;, &amp;quot;apps&amp;quot;] resources: [&amp;quot;*&amp;quot;] verbs: [&amp;quot;*&amp;quot;] --- apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: tiller-world --- kind: RoleBinding apiVersion: rbac.</description>
    </item>
    
    <item>
      <title>Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る</title>
      <link>https://www.sambaiz.net/article/159/</link>
      <pubDate>Tue, 13 Mar 2018 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/159/</guid>
      <description>Logging AgentをNodeレベルのDaemonSetとして動かすのではなく、Podの中にSidecar Containerとして動かす。その分リソースは食うけど、独立した設定で動かせる。
アプリケーション https://github.com/sambaiz/go-logging-sample
Goで定期的にログを出すサンプルコードを書いたのでこれを使う。 viperで設定を持ち、 zapでログを出力する。 あとSIGINTを拾ってSync()してGraceful Shutdownするようにしている。
Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net
multistage-buildして、GKEで動かすのでContainer Registryに上げる。
$ docker build -t go-logging-sample . $ docker tag go-logging-sample gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1 $ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample Fluentdの設定 fluent-plugin-bigqueryプラグインを使う。
projectとdataset、パーティションの日付分割テーブルに入れる場合は、auto_create_tableできないのでtableも作成しておく。
fluentdの設定はConfigMapで持つ。
apiVersion: v1 kind: ConfigMap metadata: name: fluentd-config data: fluent.conf: | &amp;lt;source&amp;gt; @type tail format json path /var/log/app.log pos_file /var/log/app.log.pos tag bigquery &amp;lt;/source&amp;gt; &amp;lt;match bigquery&amp;gt; @type bigquery method load &amp;lt;buffer time&amp;gt; @type file path /var/log/bigquery.*.buffer timekey 1d flush_at_shutdown true &amp;lt;/buffer&amp;gt; auth_method	compute_engine project &amp;lt;project-name&amp;gt; dataset &amp;lt;dataset-name&amp;gt; table &amp;lt;table-name&amp;gt;$%Y%m%d fetch_schema true ignore_unknown_values true	&amp;lt;/match&amp;gt; プラグイン入りのfluentdイメージもビルドして上げる。</description>
    </item>
    
    <item>
      <title>MySQL InnoDBのロックの挙動</title>
      <link>https://www.sambaiz.net/article/158/</link>
      <pubDate>Sat, 03 Mar 2018 19:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/158/</guid>
      <description>https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html
トランザクション分離レベルはデフォルトのREPEATABLE-READ。
&amp;gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@GLOBAL.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 準備 DBを立ち上げてテーブルとレコードを入れる。
$ cat schema_and_data.sql CREATE TABLE a ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, name VARCHAR(128) NOT NULL ); CREATE TABLE b ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, a_id BIGINT UNSIGNED NOT NULL, FOREIGN KEY (a_id) REFERENCES a (id) ); INSERT INTO a (id, name) VALUES (1, &#39;1&#39;); INSERT INTO a (id, name) VALUES (2, &#39;2&#39;); INSERT INTO a (id, name) VALUES (3, &#39;3&#39;); INSERT INTO a (id, name) VALUES (8, &#39;8&#39;); INSERT INTO a (id, name) VALUES (9, &#39;9&#39;); INSERT INTO a (id, name) VALUES (10, &#39;10&#39;); $ cat start.</description>
    </item>
    
    <item>
      <title>Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる</title>
      <link>https://www.sambaiz.net/article/157/</link>
      <pubDate>Sun, 25 Feb 2018 23:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/157/</guid>
      <description>UserPoolを作成。デフォルト設定はこんな感じ。 必須項目や、確認メールの文面などを自由にカスタマイズでき、 登録時などのタイミングでLambdaを発火させることもできる。
作成したUserPoolにアプリクライアントを追加する。 ブラウザで使うのでクライアントシークレットはなし。
クライアント側 amazon-cognito-identity-jsを使う。
依存するjsを持ってくる。
$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/amazon-cognito-identity.min.js $ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/aws-cognito-sdk.min.js Sign UpからAPIを呼ぶところまでのボタンを並べた。 SignInするとOIDC標準のトークンがそのページのドメインのLocal Storageに書かれる。
OpenID ConnectのIDトークンの内容と検証 - sambaiz-net
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.idToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.accessToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.refreshToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.clockDrift CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.LastAuthUser APIを呼ぶときはidTokenをAuthorization Headerに乗せる。
&amp;lt;button id=&amp;quot;signUp&amp;quot;&amp;gt;Sign Up&amp;lt;/button&amp;gt; &amp;lt;p&amp;gt;&amp;lt;label&amp;gt;Code:&amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;code&amp;quot;&amp;gt;&amp;lt;/label&amp;gt;&amp;lt;/p&amp;gt; &amp;lt;button id=&amp;quot;confirm&amp;quot;&amp;gt;Confirm&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;signIn&amp;quot;&amp;gt;Sign In&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;whoAmI&amp;quot;&amp;gt;Who am I?&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;requestAPI&amp;quot;&amp;gt;Request API with token&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;signOut&amp;quot;&amp;gt;Sign Out&amp;lt;/button&amp;gt; &amp;lt;script src=&amp;quot;aws-cognito-sdk.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script src=&amp;quot;amazon-cognito-identity.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script&amp;gt; const USER_NAME = &amp;quot;*****&amp;quot;; const USER_PASSWORD = &amp;quot;*****&amp;quot;; const USER_EMAIL = &amp;quot;*****&amp;quot;; class CognitoUserPoolAuth { constructor(UserPoolId, clientId, apiEndpoint) { const poolData = { UserPoolId : UserPoolId, ClientId : clientId }; this.</description>
    </item>
    
    <item>
      <title>ブラウザのwindow間の値渡し</title>
      <link>https://www.sambaiz.net/article/156/</link>
      <pubDate>Fri, 23 Feb 2018 02:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/156/</guid>
      <description>直接Windowを参照する オリジン(プロトコル+ポート+ホスト)が同じ場合は、親はopen()した返り値で、子はwindow.openerで相手のwindowが取れて、直接参照したりDOMを操作したりすることもできる。
同じ/異なるオリジンのiframeの中からできること - sambaiz-net
$ cat index.html &amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Open window&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;btn2&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt; &amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; let win2; const button = document.getElementById(&amp;quot;btn&amp;quot;); button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; { window.foo = &amp;quot;bar from window1&amp;quot;; win2 = window.open(&amp;quot;index2.html&amp;quot;); }, false); const button2 = document.getElementById(&amp;quot;btn2&amp;quot;); button2.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; { if (win2) { win2.close(); } }, false); &amp;lt;/script&amp;gt; $ cat index2.html &amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt; &amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; console.log(window.aaa); const parentWindow = window.opener; const view = document.</description>
    </item>
    
    <item>
      <title>Serverless FrameworkでLambdaをデプロイする</title>
      <link>https://www.sambaiz.net/article/155/</link>
      <pubDate>Sun, 11 Feb 2018 23:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/155/</guid>
      <description>Serverless FrameworkでLambda Functionをデプロイする。 Apexが基本的にFunction自体のデプロイしかしないのに対して、こちらはeventの設定なども諸々やってくれて強い。
ApexでLambdaをデプロイする - sambaiz-net
$ npm install -g serverless $ serverless version 1.26.0 ApexではFunctionごとにディレクトリが作られたが、ServerlessではServiceごとに作られ、 一つのService内で複数のFunctionを定義できる。handlerは同じでも異なっていてもよい。
Apexの形式の場合、共通の処理をWebpackなどで各Functionに持って来たり、 同じような処理の複数のFunctionを立てる際はコピーする必要があったが、 こちらは必要最小限の変更でそれらを行うことができる。
templateからServiceをcreateする。
$ serverless create --template aws-nodejs --path testservice $ ls testservice/ handler.js	serverless.yml 設定ファイルserverless.yml にはLambdaの基本的なもののほかに、VPCやevent、IAM Roleなども書けて、これらはdeploy時に作られるCloudFormationのstackによって管理される。必要なら生のCloudFormationの設定も書ける。
ApexでもTerraformによって管理することができるが、書くのはこちらの方がはるかに楽。
ApexでデプロイしたLambdaのトリガーをTerraformで管理する - sambaiz-net
$ cat sesrverless.yml service: testservice provider: name: aws profile: foobar region: ap-northeast-1 runtime: nodejs6.10 memorySize: 512 timeout: 10 functions: hello: handler: handler.hello events: - http: path: hello/world method: get cors: true deployすると{service}-{stage}-{function}のFunctionが作られる。 今回の場合はtestservice-prd-test。stageをymlでも指定しなかった場合はデフォルト値のdevになる。</description>
    </item>
    
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。 全体のコードはここ。
入力 以下の関数によって生成した1次元のデータ列。 これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。
def make_time_series_data(size): data = [] for i in range(size): data.append(sin(random.normalvariate(i,0.1)*0.1)) return np.reshape(np.array(data, dtype=np.float32), (size,1)) def make_batch(data, batch_size, num_steps, num_dimensions, name=None): epoch_size = data.size // (batch_size*num_steps*num_dimensions) data = np.lib.stride_tricks.as_strided( data, shape= (epoch_size, batch_size, num_steps+1, num_dimensions), strides=( 4*batch_size*num_steps*num_dimensions, 4*num_steps*num_dimensions, 4*num_dimensions, 4 # bytes ), writeable=False ) return data[:, :, :-1], data[:, :, 1:] モデル input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。 lossはMSE(Mean squared error)。OptimizerはGradientDecentOptimizerを使っている。
チュートリアルでは自力で各time_stepの値を入れていたけど、 今回はdynamic_rnn()に任せている。
class Model(object): def __init__(self, config, is_training=False): # config self.</description>
    </item>
    
    <item>
      <title>xorm reverseでDBスキーマからGoのstructを生成する</title>
      <link>https://www.sambaiz.net/article/153/</link>
      <pubDate>Sat, 10 Feb 2018 15:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/153/</guid>
      <description>GoのORMのxormにはxorm reverseというDBのスキーマから以下のようなテンプレートに沿ったGoのstructなどを生成するツールがある。
package {{.Model}} import ( {{range .Imports}}&amp;quot;{{.}}&amp;quot;{{end}} ) {{range .Tables}} type {{Mapper .Name}} struct { {{$table := .}} {{range .Columns}}	{{Mapper .Name}}	{{Type .}} {{end}} } {{end}} リポジトリにあるテンプレートにxorm用テンプレートとgo用のテンプレートが用意されているように、単体で使うこともできる。 また、テンプレートを書く言語としてもGo以外にC++もサポートしている。
xormのcmdとドライバをインストール。
$ go get github.com/go-xorm/cmd/xorm $ go get github.com/go-sql-driver/mysql $ xorm Version: 0.2.0524 様々な型のカラムを含むテーブルで試す。
$ cat schema.sql CREATE TABLE table1 ( n_tinyint TINYINT, n_int INT, n_int_unsigned INT UNSIGNED NOT NULL DEFAULT 1, n_bigint BIGINT, n_float FLOAT, n_double DOUBLE, d_date DATE, d_datetime DATETIME, s_char CHAR(64), s_varchar VARCHAR(64), s_text TEXT, s_json JSON, b_binary BLOB, e_enum ENUM(&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;) ) $ cat setup.</description>
    </item>
    
    <item>
      <title>DatadogのLambda Integrationで気象データを送ってアラートを飛ばす</title>
      <link>https://www.sambaiz.net/article/152/</link>
      <pubDate>Mon, 05 Feb 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/152/</guid>
      <description>最近朝が寒くて布団から出るのがつらい。雨や雪が降っていたら尚更のこと、それならそれで現状を把握する必要がある。 そこで、無料から使える気象API OpenWeatherMapのデータをdatadogに送って、特に寒い日や雨雪が降るような朝にはアラートを飛ばすことにした。
インスタンスが立っていたらDataDog AgentのDogStatsD経由で送ることができ、 そうでなければ通常はAPIを呼ぶことになるんだけど、Lambdaでは、AWS Integrationを設定すると有効になるLambda Integrationによって MONITORING|unix_epoch_timestamp|value|metric_type|my.metric.name|#tag1:value,tag2のフォーマットでconsole.logするだけでメトリクスが送られるようになっている。
const axios = require(&#39;axios&#39;); const CITY = &#39;Shibuya&#39;; const API_KEY = &#39;*****&#39;; const WEATHER_API = `http://api.openweathermap.org/data/2.5/weather?q=${CITY}&amp;amp;units=metric&amp;amp;appid=${API_KEY}`; const METRIC_COUNTER = &#39;counter&#39;; const METRIC_GAUGE = &#39;gauge&#39;; const monitor = (metricName, metricType, value, tags) =&amp;gt; { const unixEpochTimestamp = Math.floor(new Date().getTime()); console.log(`MONITORING|${unixEpochTimestamp}|${value}|${metricType}|${metricName}|#${tags.join(&#39;,&#39;)}`); }; exports.handler = async (event, context, callback) =&amp;gt; { const data = (await axios.get(WEATHER_API)).data const namePrefix = &#39;livinginfo.weather&#39; monitor(`${namePrefix}.temperature`, METRIC_GAUGE, data.main.temp, []) monitor(`${namePrefix}.</description>
    </item>
    
    <item>
      <title>ローカルでビルドしたimageをminikubeで使う</title>
      <link>https://www.sambaiz.net/article/151/</link>
      <pubDate>Thu, 01 Feb 2018 22:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/151/</guid>
      <description>$ minikube version minikube version: v0.25.0 $ kubectl version Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;9&amp;quot;, GitVersion:&amp;quot;v1.9.2&amp;quot;, GitCommit:&amp;quot;5fa2db2bd46ac79e5e00a4e6ed24191080aa463b&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2018-01-18T21:11:08Z&amp;quot;, GoVersion:&amp;quot;go1.9.2&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;} $ kubectl config current-context minikube $ minikube status minikube: Running cluster: Running kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100 dockerコマンドがminikube VM内で動いているdocker daemonを参照するようにする。
$ minikube docker-env export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot; export DOCKER_HOST=&amp;quot;tcp://192.168.99.100:2376&amp;quot; export DOCKER_CERT_PATH=&amp;quot;/Users/sambaiz/.minikube/certs&amp;quot; $ eval $(minikube docker-env) $ docker info --format &#39;{{json .Name}}&#39; &amp;quot;minikube&amp;quot; ビルドするDockerfile。nginxが立ち上がるだけ。
FROM nginx 何もタグを付けない(:latest)とcreate時にDockerレジストリからpullしにいって失敗してしまうため、タグ付きでビルドする。
$ docker build -t my/myapp:1.</description>
    </item>
    
    <item>
      <title>Chromeで任意のscriptを読み込まれる前に差し替える</title>
      <link>https://www.sambaiz.net/article/150/</link>
      <pubDate>Thu, 01 Feb 2018 21:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/150/</guid>
      <description>ChromeのDevToolsではSourcesからscriptを書き換えられるようになっているが、 一行目にbreakpointを挟んで更新するとそこで止まるので読み込まれる前に差し替えることができる。 ページの読み込み時に呼ばれるSDKやライブラリの影響範囲を調べたりデバッグしたりするのに便利。
確認用jsとhtml
console.log(&amp;quot;original&amp;quot;) &amp;lt;script src=&amp;quot;index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; 読み込み時に実行されるconsole.logの文章を変えた。</description>
    </item>
    
    <item>
      <title>Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す</title>
      <link>https://www.sambaiz.net/article/149/</link>
      <pubDate>Fri, 19 Jan 2018 09:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/149/</guid>
      <description>GooseはGo製のDB Migrationツール。
コード
こんなリポジトリを作成し、各自ブランチを切ってGoose形式のup/downのSQLを書き、終わったらPullRequestを出す。
goose/ .keep .circleci/config.yml create_test_table.sql $ cat create_test_table.sql -- +goose Up -- SQL in this section is executed when the migration is applied. CREATE TABLE testtable ( id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT, n INT NOT NULL, c VARCHAR (20) NOT NULL UNIQUE ); -- +goose Down -- SQL in this section is executed when the migration is rolled back. DROP TABLE testtable; 無事Approveされ、mergeされるとCircleCIが走り、 SQLをgooseディレクトリの中にバージョンを付けて移し、 SlackにpostMessageするエンドポイントにリクエストを飛ばす。
ここでバージョンを作成することによって、並列で作業し、レビューなどの関係で適用順が前後しても修正する必要をなくしている。ただ、pushされる前に複数のブランチを連続でmergeする場合うまく動かないのでそれはなんとかする必要がある。</description>
    </item>
    
    <item>
      <title>SlackのInteractive messagesでボタンの入力を受け付ける</title>
      <link>https://www.sambaiz.net/article/148/</link>
      <pubDate>Tue, 16 Jan 2018 21:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/148/</guid>
      <description>Interactive messages
まずはサーバーを用意する。コードはここにあって、 Interactive messagesのハンドリングはSlack公式のnode-slack-interactive-messagesを使っている。
app.use(&#39;/slack&#39;, slackMessages.expressMiddleware()); slackMessages.action(&#39;question_button&#39;, (payload) =&amp;gt; { let replacement = payload.original_message; replacement.text =`${payload.user.name} likes ${payload.actions[0].value}`; delete replacement.attachments[0].actions; return replacement; }); ボタンの表示はattachmentsを使う。
web.chat.postMessage(channelId, &#39;Question&#39;, { attachments: [ { text: &amp;quot;Which buttons do you like?&amp;quot;, color: &amp;quot;#f9a41b&amp;quot;, callback_id: &amp;quot;question_button&amp;quot;, actions: [ { name: &amp;quot;primary_button&amp;quot;, type: &amp;quot;button&amp;quot;, style: &amp;quot;primary&amp;quot;, text: &amp;quot;Primary&amp;quot;, value: &amp;quot;Primary Button&amp;quot;, }, { name: &amp;quot;normal_button&amp;quot;, type: &amp;quot;button&amp;quot;, text: &amp;quot;Normal&amp;quot;, value: &amp;quot;Normal Button&amp;quot; }, { name: &amp;quot;danger_button&amp;quot;, type: &amp;quot;button&amp;quot;, style: &amp;quot;danger&amp;quot;, text: &amp;quot;Danger&amp;quot;, value: &amp;quot;Danger Button&amp;quot;, confirm: { title: &amp;quot;Really?</description>
    </item>
    
    <item>
      <title>TensorBoardでsummaryやグラフを見る</title>
      <link>https://www.sambaiz.net/article/147/</link>
      <pubDate>Sun, 07 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/147/</guid>
      <description>TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
で読んだコードをTensorboardでみてみる。
8888がJupyter、6006がTensorboard。
$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow コードをuploadするかJupyterからterminalを開いてcloneしてくる。
# apt-get update # apt-get install -y git wget # git clone https://github.com/tensorflow/models.git # cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz logdirを指定して実行し、Tensorboardを起動。
flags.DEFINE_string(&amp;quot;save_path&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;Model output directory.&amp;quot;) sv = tf.train.Supervisor(logdir=FLAGS.save_path)  追記(2018-11-14): Supervisorはdeprecatedなので以下の記事でやっているようにMonitoredTrainingSessionを使うとよい。
Deep LearningのBatch Normalizationの効果をTensorFlowで確認する - sambaiz-net
 # tensorboard --logdir=models/tutorials/rnn/ptb tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)による値がリアルタイムに表示される。
グラフのつながりや、各Operationの入出力やそのshapeを確認できる。 name_scopeで分けておくと見やすい。</description>
    </item>
    
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。
RNN/LSTMとは RNNは入力に対して出力のほかに情報を次のステップに渡すことで時系列データで学習できるようにするネットワーク。 展開すると同じネットワークに単語を一つずつ入れていくように表現できる。
これを単純にMLPで実装しようとすると逆誤差伝搬する際に過去の層にも伝搬させる(BPTT: Backpropagation through time)必要があり、 時間を遡るほど活性化関数の微分係数が再帰的に繰り返し掛けられるため勾配が消失や爆発しやすくなってしまう。 また、時系列データのうちに発火したいものと発火したくないものが混在している場合、同じ重みにつながっているため更新を打ち消しあってしまう入力/出力重み衝突という問題もある。
これらを解決するのがLSTM(Long Short Term Memory networks)で、 勾配消失は活性化関数がxで重みが単位行列のニューロンのCEC(Constant Error Carousel)によって常に誤差に掛けられる係数を1にすることで防ぎ、 入力/出力重み衝突は必要な入出力を通したり不必要な情報は忘れさせるために値域(0,1)の値を掛けるinput gate、forget gate、output gateによって回避する。gateは入力と前回の出力によって制御される。
TensorflowではいくつかLSTMの実装が用意されていて、CudnnLSTMやBasicLSTMCell、LSTMBlockCellなどがある。 cuDNNというのはNVIDIAのCUDAのDNNライブラリのこと。 LSTMBlockCellはもう少し複雑なLSTMでBasicLSTMCellよりも速い。
動かしてみる $ git clone https://github.com/tensorflow/models.git $ cd models/tutorials/rnn/ptb/ $ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz $ tar xvf simple-examples.tgz $ python3 -m venv env $ . ./env/bin/activate $ pip install numpy tensorflow $ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0 Epoch: 1 Learning rate: 1.000 0.004 perplexity: 5534.452 speed: 894 wps 0.</description>
    </item>
    
    <item>
      <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
      <link>https://www.sambaiz.net/article/145/</link>
      <pubDate>Sun, 24 Dec 2017 23:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/145/</guid>
      <description>https://github.com/sambaiz/athena-admin
AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。
料金はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。 データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだけど都度locationを指定してADD PARTITIONを実行するのは大変。さらにスキーマを変更するのにもALTER TABLE ADD COLUMNSなどはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。
ではどうしようもないかというとMSCK REPAIR TABLEというのがあって、 これはS3のObjectのdt=YYYY-MM-DDのようなkey=valueのprefixを認識してパーティションを作るもの。作り直す際もこれ1クエリで終わる。それなら最初からそういう風に置けばよいのではというところだけど、勝手にYYYY/MM/DD/HHのprefixを付けてしまうFirehoseのようなのもある。
今回作ったathena-adminは以下のような定義ファイルから、 パーティションのkey=valueのprefixが付くように置き換えたり、変更があったらmigrationする。 このファイルを書き換えるだけで基本的にどうにかなるし、バージョン管理すればテーブル定義の変更を追うことができる。
{ &amp;quot;general&amp;quot;: { &amp;quot;athenaRegion&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;, &amp;quot;databaseName&amp;quot;: &amp;quot;aaaa&amp;quot;, &amp;quot;saveDefinitionLocation&amp;quot;: &amp;quot;s3://saveDefinitionBucket/aaaa.json&amp;quot; }, &amp;quot;tables&amp;quot;: { &amp;quot;sample_data&amp;quot;: { &amp;quot;columns&amp;quot;: { &amp;quot;user_id&amp;quot;: &amp;quot;int&amp;quot;, &amp;quot;value&amp;quot;: { &amp;quot;score&amp;quot;: &amp;quot;int&amp;quot;, &amp;quot;category&amp;quot;: &amp;quot;string&amp;quot; } /* &amp;quot;struct&amp;lt;score:int,category:string&amp;gt;&amp;quot; のように書くこともできる */ }, &amp;quot;srcLocation&amp;quot;: &amp;quot;s3://src/location/&amp;quot;, &amp;quot;partition&amp;quot;: { &amp;quot;prePartitionLocation&amp;quot;: &amp;quot;s3://pre/partition/&amp;quot;, /* optional */ &amp;quot;regexp&amp;quot;: &amp;quot;(\\d{4})/(\\d{2})/(\\d{2})/&amp;quot;, /* optional */ &amp;quot;keys&amp;quot;: [ { &amp;quot;name&amp;quot;: &amp;quot;dt&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;{1}-{2}-{3}&amp;quot;, /* optional */ } ] } } } } 使い方はこんな感じ。使い方によってはmigrate()だけ呼ぶこともあると思う。 replaceObjects()にはmatchedHandlerというのを渡すこともできて、 UTCからJSTに変換するといったこともできる。</description>
    </item>
    
    <item>
      <title>ApexでデプロイしたLambdaのトリガーをTerraformで管理する</title>
      <link>https://www.sambaiz.net/article/144/</link>
      <pubDate>Sun, 12 Nov 2017 22:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/144/</guid>
      <description>Apexでfunctionをデプロイするとトリガーが登録されないのであとで追加することになる。 これを手作業で行うこともできるのだけど、せっかくなのでアプリケーションと一緒に管理したい。 そんなときのためにterraformコマンドをラップしたapex infraが用意されている。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
functionsと同列にinfrastructureディレクトリを作成してtfファイルを置く。 その下に環境ごとのディレクトリを作成することもできて、その場合は--envで指定した環境のものが使われる。
- functions - infrastructure main.tf variables.tf - modules - cloudwatch_schedule main.tf variables.tf project.json functionをデプロイするとそのARNが変数で取れるようになる。
$ apex list --tfvars apex_function_hello=&amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot; 今回設定するトリガーはCloudwatch Eventのスケジューリング。作成するリソースは以下の通り。
 aws_cloudwatch_event_ruleでイベントルール(今回はschedule)を作成 aws_cloudwatch_event_targetでルールにターゲット(今回はLambda)を設定 aws_lambda_permissionでルールに対象Lambdaをinvokeする権限を付ける  $ cat infrastructure/modules/cloudwatch_schefule/variables.tf variable &amp;quot;lambda_function_name&amp;quot; {} variable &amp;quot;lambda_function_arn&amp;quot; {} variable &amp;quot;schedule_expression&amp;quot; { description = &amp;quot;cloudwatch schedule expression e.g. \&amp;quot;cron(0/5 * * * ? *)\&amp;quot;&amp;quot; } $ cat infrastructure/modules/cloudwatch_schefule/main.tf resource &amp;quot;aws_cloudwatch_event_rule&amp;quot; &amp;quot;lambda&amp;quot; { name = &amp;quot;lambda_rule_${var.lambda_function_name}&amp;quot; description = &amp;quot;invoke lambda ${var.</description>
    </item>
    
    <item>
      <title>JavaScriptのrequire/importの歴史</title>
      <link>https://www.sambaiz.net/article/143/</link>
      <pubDate>Sat, 11 Nov 2017 20:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/143/</guid>
      <description>scriptタグを並べる &amp;lt;body&amp;gt; &amp;lt;script src=&amp;quot;a.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script src=&amp;quot;b.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; 先に書かれたa.jsで定義された内容はb.jsで読むことができる。
$ cat a.js const a = &#39;a is defined&#39;; const divA = document.createElement(&#39;div&#39;); divA.textContent = (typeof b !== &#39;undefined&#39;) ? b : &#39;b is undefined&#39;; document.body.appendChild(divA); $ cat b.js const b = &#39;b is defined&#39;; const divB = document.createElement(&#39;div&#39;); divB.textContent = (typeof a !== &#39;undefined&#39;) ? a : &#39;a is undefined&#39;; document.body.appendChild(divB); 依存が増えてくると順番を考えるのが大変。さらにグローバルな名前空間を汚染してしまう。
b is undefined a is defined AMDとCommonJS というのも、かつてのJSにはモジュールを読み込む仕組みがなかった。 そこで考えられたのがAMDやCommonJSというフォーマット。 AMD(Asynchronous module definition)はRequireJSによって提供されるrequire()で動的にscriptタグを埋める。CommonJSはNodeでもおなじみのrequire()で、これにWebpackを通して一つのファイルにまとめておく。同じ関数名が使われているが全くの別物。</description>
    </item>
    
    <item>
      <title>圧縮アルゴリズムZopfliとBrotli</title>
      <link>https://www.sambaiz.net/article/142/</link>
      <pubDate>Fri, 03 Nov 2017 15:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/142/</guid>
      <description>どちらもGoogleが開発した圧縮アルゴリズム。
puppetter-lambda-starter-kit のissueに 現在使っているgzipと、Zopfli、Brotliを比較したデータが上がっていたので調べてみた。
Zopfli 出力としてDeflateに対応している。
Deflate LZ77(実際は改良版のLZSS)とハフマン記号による可逆圧縮アルゴリズム。 zip、zlib、gzip、pngなどで使われていて、これらはヘッダーやフッターが異なる。 LZSSはバイト列を見ていって同じ部分を発見したらそこを参照するように置き換えていく。
a b c a b c a b c d d d =&amp;gt; a b c (距離3, 長さ6) d (距離１, 長さ2) このLZSSにあたる部分をZopfliはがんばってやるので圧縮時間が結構かかるがサイズは小さくなるらしい。 展開は通常のDeflate通り。上げてくれたデータを見ても大体そんな感じだ。
$ git clone https://github.com/google/zopfli $ cd zopfli $ make zopfli $ ./zopfli aaaa Brotli LZ77、ハフマン記号に加えて2nd order context modelingというのを使って圧縮する Deflateではない可逆圧縮アルゴリズム。 Safari以外のモダンなブラウザで既に対応しているか対応しているところ。 対応している場合、Accept-EncodingやContent-Encodingヘッダに含まれるのはbr。 圧縮率も展開時間もかなり良さそう。
Nodeにもblotliのライブラリがあって、 圧縮はEmscriptenで本家のC++コードから変換し、 展開は手で移植しているようだ。
$ npm install blotli const fs = require(&#39;fs&#39;); const brotli = require(&#39;brotli&#39;); const TARGET = process.</description>
    </item>
    
    <item>
      <title>Redashでデータを可視化する</title>
      <link>https://www.sambaiz.net/article/141/</link>
      <pubDate>Mon, 23 Oct 2017 23:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/141/</guid>
      <description>RedashはOSSのデータ可視化ツール。 BIツールのようにパラメータを変えながら指標を探っていくというよりは、分かっている指標を見るのに使うイメージ。 比較的機能が少ない分処理がわかりやすく、 クエリが自動生成されないため時間がかかるものを実行する前にある程度気づけるのが良いと思う。
docker-composeで立ち上げることもできるけど、 AWSの各リージョンにAMIが用意されているのでそれで立ち上げる。
sshで入って以下のようなのを必要に応じて設定する。 メールを送る場合はSESでメールアドレスをVerifyしてやるのが簡単。 GSuiteを使っている場合、OAuthのClientID、Secretを発行しドメインを登録するとそれで認証できる。
$ ssh ubuntu@***** $ sudo vi /opt/redash/.env export REDASH_MAIL_SERVER=&amp;quot;email-smtp.us-east-1.amazonaws.com&amp;quot; export REDASH_MAIL_USE_TLS=&amp;quot;true&amp;quot; export REDASH_MAIL_USERNAME=&amp;quot;*****&amp;quot; export REDASH_MAIL_PASSWORD=&amp;quot;*****&amp;quot; export REDASH_MAIL_DEFAULT_SENDER=&amp;quot;*****&amp;quot; # Email address to send from export REDASH_GOOGLE_CLIENT_ID=&amp;quot;&amp;quot; export REDASH_GOOGLE_CLIENT_SECRET=&amp;quot;&amp;quot; $ cd /opt/redash/current $ sudo -u redash bin/run ./manage.py org set_google_apps_domains {{domains}} $ sudo supervisorctl restart all HTTPS対応するのに/etc/nginx/sites-available/redashを編集する。crtとkeyの場所は変える。
upstream rd_servers { server 127.0.0.1:5000; } server { server_tokens off; listen 80 default; access_log /var/log/nginx/rd.access.log; gzip on; gzip_types *; gzip_proxied any; location /ping { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://rd_servers; } location / { return 301 https://$host$request_uri; } } server { listen 443 ssl; # Make sure to set paths to your certificate .</description>
    </item>
    
    <item>
      <title>ApexでLambdaをデプロイする</title>
      <link>https://www.sambaiz.net/article/140/</link>
      <pubDate>Sun, 22 Oct 2017 16:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/140/</guid>
      <description>ApexでLambdaをデプロイする。 とても簡単に使えるし、変なこともしないので良い感じ。
 Serverless Frameworkだとeventの設定までカバーできてより便利。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
 インストール。ダウンロードして実行できるようにしている。
$ curl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh  IAMFullAccess AWSLambdaFullAccess  を付けたIAMのプロファイルを登録しておく。
$ aws configure --profile apex $ aws configure list --profile apex Name Value Type Location ---- ----- ---- -------- profile apex manual --profile access_key ****************OVGQ shared-credentials-file secret_key ****************oi5t shared-credentials-file region ap-northeast-1 config-file ~/.aws/config apex initしてnameとdescriptionを入れるとIAMが登録され、 ディレクトリ構造が作られる。
$ apex init --profile apex Project name: try-apex Project description: test [+] creating IAM try-apex_lambda_function role [+] creating IAM try-apex_lambda_logs policy [+] attaching policy to lambda_function role.</description>
    </item>
    
    <item>
      <title>Node.jsのコードをPrettierでフォーマットしてESLintにかける</title>
      <link>https://www.sambaiz.net/article/139/</link>
      <pubDate>Thu, 19 Oct 2017 00:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/139/</guid>
      <description>PrettierはJSやTSのコードフォーマッタで、 ReactやBabel、Yarnなどの開発にも使われている。
今回はPrettierでフォーマットしたものを eslint --fixするprettier-eslint-cliを使う。役割が被っているけどPrettierはeslint --fixよりも強力にフォーマットしてくれるようだ。
$ git init $ yarn add --dev eslint eslint-config-google prettier-eslint-cli husky lint-staged $ cat .eslintrc.js module.exports = { &amp;quot;extends&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;parserOptions&amp;quot;: { &amp;quot;ecmaVersion&amp;quot;: 2017, } }; 対象のコードはこれ。
$ cat src/main.js /** * hoge function */ function hoge() { const f = (aaaaaaaaaaaaaaa, bbbbbbbbbb, ccccccccc, dddddddddddd, eeeeeeeeeeeeee) =&amp;gt; console.log(&#39;a&#39;); f(1, 2, 3, 4, 5); } hoge(); Prettierのドキュメントでも紹介されているようにlint-stagedを使うとCommit時にフォーマットし、Lintをかけることができる。
{ &amp;quot;scripts&amp;quot;: { &amp;quot;precommit&amp;quot;: &amp;quot;lint-staged&amp;quot;, &amp;quot;lint&amp;quot;: &amp;quot;eslint src&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;prettier-eslint --write \&amp;quot;src/**/*.</description>
    </item>
    
    <item>
      <title>確率分布(二項分布/ポアソン分布/正規分布/カイ二乗分布/t分布)</title>
      <link>https://www.sambaiz.net/article/138/</link>
      <pubDate>Sun, 15 Oct 2017 01:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/138/</guid>
      <description>二項分布 確率pで起きる事象がn回の試行でx回起きる確率関数の離散的確率分布。記号で書くとB[n,p]。 期待値はnpで、分散はnp(1-p)。
ポアソン分布 二項分布において、起きる確率pが少なく、試行回数nが多いときに代わりに適用できる確率分布。 具体的にはnが50ぐらいだったら、npが5以下のとき。 試行回数が多いとき、二項分布だとCの部分の計算が困難になってしまうのを解決できる。 期待値も分散もnp=μ。
正規分布 正規分布は平均値μを最大値とし、左右対称な釣鐘型をしている連続的確率分布。記号で書くとN[μ,σ^2]。 二項分布のnを大きくしていくと正規分布に近づいていく。 p=0.5であれば、n=10の二項分布B[10,0.5]でも良い近似が得られる(N[5,2.5])。 逆にnが大きな二項分布の近似として正規分布を使うこともできる。
N[0,1]の正規分布を標準正規分布と呼ぶ。 ある正規分布に従う確率変数xを、標準正規分布に従うzに変換することを標準化変換という。 標準正規分布にすると正規分布表の値を使って計算できる。
また、平均μ、分散σ^2の任意な分布からn個の標本をとったときの平均はN[μ, σ^2/n]に従う。 言い換えれば、標本の平均と真の平均の誤差はN[0, σ^2/n]。これを中心極限定理という。
t分布 自由度vのt分布は正規分布に従うv+1個の標本から計算される次の確率変数Tの分布。 nは標本数で、bar{X}は標本平均、μは母平均、s^2は標本分散ではなくn-1で割る不偏分散。
これを利用すれば標本数が少なく母分散が不明でも母平均の検定や区間を推定することができる。
統計的仮説検定 - sambaiz-net
Γはガンマ関数で階乗の概念を複素数全体に拡張したもの。nが自然数のとき Γ(n+1)=n! になる。
カイ二乗分布 自由度kのカイ二乗分布は標準正規分布に従うk個の標本の二乗の和、あるいは正規分布N[μ, σ^2]を標準化変換した次の確率変数Zの分布。
また、母平均μの代わりに標本平均bar{X}を用いた次のZは自由度k-1のカイ二乗分布に従う。s^2は標本分散。 これを利用すれば母平均が不明でも母分散σ^2の検定や区間を推定することができる。
参考 統計学入門
ガンマ関数 - Wikipedia
t分布 - Wikipedia</description>
    </item>
    
    <item>
      <title>Lpノルムと正則化</title>
      <link>https://www.sambaiz.net/article/137/</link>
      <pubDate>Thu, 12 Oct 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/137/</guid>
      <description>ノルムとは ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。
 p(av) = |a| p(v): スケーラブル p(u + v) ≦ p(u) + p(v): 三角不等式を満たす p(v) ≧ 0: 負の値を取らない p(v) = 0 &amp;lt;=&amp;gt; v=0: 距離が0 &amp;lt;=&amp;gt; 零ベクトル  以下の式で表されるノルムをLpノルムと呼ぶ。
L1ノルム(マンハッタン距離) 絶対値の和。座標軸方向にしか移動できない縛りでの距離。 StreetとAvenueが格子状になっているマンハッタンではタクシーが移動する距離はL1ノルムのようになる。
L2ノルム(ユークリッド距離) 2乗の和の平方根。普通の距離。
正則化(regularization) 機械学習で過学習を防ぐためのもの。 Lp正則化は重みのLpノルムをp乗してハイパーパラメータΛを掛けたものを正則化項として 素の損失関数に加える。これを最小化するのだから重みがペナルティとしてはたらく。 L1正則化ではΛが大きければいくつかの重みが0になって次元削減できるが、 L2正則化では重みに比例して小さくなるだけ。それぞれLasso回帰、Ridge回帰ともいう。 また、これらを割合で足して使うElasticNetというものもある。
参考 Norm (mathematics) - Wikipedia
RでL1 / L2正則化を実践する - 六本木で働くデータサイエンティストのブログ</description>
    </item>
    
    <item>
      <title>OpenID ConnectのIDトークンの内容と検証</title>
      <link>https://www.sambaiz.net/article/136/</link>
      <pubDate>Mon, 09 Oct 2017 20:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/136/</guid>
      <description>OpenID Connectは認可(AuthoriZation)のプロトコルであるOAuth 2.0を正しく認証(AutheNtication)に使うためのプロトコル。
OpenID Connect Core 1.0(日本語訳)
OAuth2.0のメモ - sambaiz-net
OpenID ConnectではOAuthのアクセストークンに加えて Issuer(IdP)によって署名されたJWT(JSON Web Token)形式のIDトークンも返す。 このIDトークンの署名を検証し、含まれるIssuerとクライアントの情報を参照することで OAuthのImplicit flowでのトークン置き換え攻撃を防ぐことができる。
JWT/IDトークン JWTはRFC7519で定義されている、 パーティ間で安全にClaim(エンドユーザーのようなエンティティの情報)を受け渡すための表現方法。 JSONにエンコードしたClaimは、JOSE(Javascript Object Signing and Encryption)のサブセットであるJWS(JSON Web Signature)のペイロードとして署名を付与されるか、JWE(JSON Web Encryption)で暗号化される。 以下のJWTはJWSのもの。
JWSには(ヘッダ).(ペイロード).(署名)の文字列で表現されるCompact SerializationとJSONで表現されるJSON Serializationがあるが、JWTではCompact Serializationを使う。
ヘッダには署名に使うアルゴリズムalgが含まれる。 JWTを受け取った際、不正なalgになっていないかチェックする必要がある。
{ &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;, &amp;quot;kid&amp;quot;: &amp;quot;5b0924f6f83c719514987954cf66683b370677d4&amp;quot; } ペイロードには以下のようなClaimが含まれる。これ以外のClaimを含めることもできる。
{ &amp;quot;iss&amp;quot;: &amp;quot;https://server.example.com&amp;quot;, # IssuerのIdentifier。httpsのURL &amp;quot;sub&amp;quot;: &amp;quot;24400320&amp;quot;, # Subject Identifier。Issuerでユニークなエンドユーザーの識別子。 &amp;quot;aud&amp;quot;: &amp;quot;s6BhdRkqt3&amp;quot;, # audience。OAuth2.0のclient_id &amp;quot;nonce&amp;quot;: &amp;quot;n-0S6_WzA2Mj&amp;quot;, # リクエストで送ったのがそのまま返ってくる。リプレイ攻撃を防ぐため &amp;quot;exp&amp;quot;: 1311281970, # IDトークンの有効期限。時間はすべてUNIXエポック秒 &amp;quot;iat&amp;quot;: 1311280970, # IDトークンの発行時刻 &amp;quot;auth_time&amp;quot;: 1311280969 # エンドユーザーの認証時刻 } IDトークンを取得する GoogleのOAuth 2.</description>
    </item>
    
    <item>
      <title>RSA暗号とPEM/DERの構造</title>
      <link>https://www.sambaiz.net/article/135/</link>
      <pubDate>Sun, 01 Oct 2017 21:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/135/</guid>
      <description>RSA暗号とは  暗号化: c ≡ m^e (mod n) 複合: m ≡ c^d (mod n)  公開鍵がe,nで秘密鍵がd。nはとても大きく近くない素数p,qの積で、 これを公開しても素因数分解できないのがこの暗号の前提になっている。 768bit(10進数で232桁)では既に解読されているので、少なくとも1024bit以上にする。
eはEuler totient function(1~nまでの整数でnと互いに素なものの個数。今回の場合はφ(n)=(p-1)(q-1))未満で互いに素な正の整数で、小さすぎても大きすぎてもだめ。2^16 + 1 = 65537がよく使われる。
dはed ≡ 1 (mod φ(n))を満たすd。
例 例として(p,q)=(193,709)とするとこんな感じ。
 n = p * q = 136837 φ(n) = (p-1)(q-1) = 135936 e = 65537 &amp;lt; φ(n)  秘密鍵dは65537*d ≡ 1 (mod 135936)の式を変形した 65537*d - 135936*x = gcd(65537,135936) = 1を、拡張されたユークリッドの互除法で解く。 以下のように135936と65537を残しながら展開していく。
135936 = 65537 * 2 + 4862 =&amp;gt; 4862 = 135936 * 1 + 65537 * -2 65537 = 4862 * 13 + 2331 =&amp;gt; 2331 = 65537 - (135936 * 1 + 65537 * -2) * 13 = 135936 * -13 + 65537 * 27 4862 = 2331 * 2 + 200 =&amp;gt; 200 = (135936 * 1 + 65537 * -2) - (135936 * -13 + 65537 * 27) * 2 = 135936 * 27 + 65537 * -56 2331 = 200 * 11 + 131 =&amp;gt; 131 = (135936 * -13 + 65537 * 27) - (135936 * 27 + 65537 * -56) * 11 = 135936 * -310 + 65537 * 643 .</description>
    </item>
    
    <item>
      <title>自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数</title>
      <link>https://www.sambaiz.net/article/134/</link>
      <pubDate>Mon, 25 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/134/</guid>
      <description>自己情報量 P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。
log(P)+log(Q)=log(P*Q)より加法性がある。 例えば、サイコロで1の目が2回連続で出る(P=1/36)情報量(5.16bits)はサイコロで1の目が出る(P=1/6)情報量(2.58bits)の2倍と等しい。 確率が高ければ高いほど自己情報量は小さくなり、P(ω)=1では0bitになる。
エントロピー 確率分布Pに従う確率変数Xのエントロピーは以下の式で定義される。情報量の平均。
これは情報を送る際に必要なビット数の平均の下限になっている。 例えば、Xが1~4の値を(0.8, 0.1, 0.06, 0.04)の確率でとるとする。 4通りなのだからそれぞれ2bits(00, 01, 10, 11)のコードで表すこともできるが、 ほとんど3や4は出ないのだからbit数を偏らせて(0, 10, 110, 111)のコードで表すと 0.8*1 + 0.1*2 + 0.06*3 + 0.04*3 = 1.3bitsまで減らすことができる。 この場合のエントロピーは1.01bitsで、これより小さくすることはできない。
カルバック・ライブラー情報量 離散確率分布PのQに対するカルバック・ライブラー情報量は以下の式で定義される。連続確率分布では積分する。 Qの自己情報量からPの自己情報量を引いて平均を取ったもので、分布間の距離のように考えることができる。非負の値を取る。
交差エントロピー 離散確率分布PとQの交差エントロピーは以下の式で定義される。連続確率分布では積分する。 PのエントロピーにPのQに対するKL情報量を足したもの。
これはQの分布に最適化されたコードでPの分布の確率変数の情報を送ってしまった際に必要なビット数の平均の下限になっている。KL情報量が余分な分。機械学習の損失関数に使われる。
ロジスティック回帰と尤度関数/交差エントロピー誤差と勾配降下法 - sambaiz-net
参考 Self-information - Wikipedia
Kullback–Leibler divergence - Wikipedia
情報理論を視覚的に理解する (3/4) | コンピュータサイエンス | POSTD</description>
    </item>
    
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>活性化関数というのは各層での重み掛けバイアス足しのあとに適用する非線形の関数。 これはカーネル法のように空間を変換して線形分離できないデータを線形分離できるようにするはたらきをする。 線形な関数を使うと層を重ねても結局線形のままで、空間もそのまま伸縮するだけなので目的を果たさない。
バックプロバゲーション(誤差逆伝播法)するために微分できる必要がある。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
Tensorflowでは以下の活性化関数が用意されている。
sigmoid 値域は(0,1)でシグマの語末系ςに似たS字を描く。 微分係数がそれほど大きくないので何層もこの関数を適用すると、バックプロバゲーションで微分係数を掛けていった結果、勾配が消失する問題がありあまり使われない。値域が(-1,1)で似たグラフを描くtanh(Hyperbolic tangent)もある。
softsign tanhと比べて漸近線に近づく速度が遅くなっている。 それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。
softplus ReLUに続く。
ReLU(Rectified Linear Unit) 単純だけど最有力。勾配消失も起きにくい。x=0で微分できないが0か1として扱われる。
def deriv_relu(x): return np.where(x &amp;gt; 0, 1, 0) softplusと比べてexpやlogを含まない分高速に計算できるので、 膨大で複雑なデータセットに対して多くの層を用いることができる。
0以下は等しく0になるため、学習中に落ちてしまうとニューロンが死んでしまう。 これを避けるため0以下のときy = exp(x) - 1にするELU(Exponential Linear Unit) というのもある。
比較的起きにくいとはいえ、層を深くすると勾配消失する可能性は高まる。 活性化関数ごとに異なる重みの初期値によってこれを緩和でき、ReLUでは入力次元数によるHe Initializationというのが提案されている。
rng = np.random.RandomState(1234) n_in = 10 # 入力次元数 rng.uniform( low=-np.sqrt(6/n_in), high=+np.sqrt(6/n_in), size=5 ) # He Initialization 参考 Activation functions and it’s types-Which is better?
最適化から見たディープラーニングの考え方
Understanding the difficulty of training deep feedforward neural networks</description>
    </item>
    
    <item>
      <title>Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った</title>
      <link>https://www.sambaiz.net/article/132/</link>
      <pubDate>Sun, 10 Sep 2017 23:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/132/</guid>
      <description>PuppeteerでHeadless Chromeを動かすコードを Lambda上で動かすStarter Kitを作った。
puppeteer-lambda-starter-kit
Chromeの準備 Puppeteerのインストール時に落としてくるChromeをLambda上で動かそうとしても Lambdaにないshared libraryに依存しているため失敗する。
error while loading shared libraries: libpangocairo-1.0.so.0: cannot open shared object file: No such file or directory Lambda上でHeadless Chromeを動かす例がないか調べたらserverless-chromeというのがあって、 Headless用の設定でChromeをビルドしていた。 ほかにはchromelessというのもあるけど これはserverless-chromeに 依存している。 最小構成でPuppeteerを使いたかったので、今回はこれらを使わず一から作ることにした。
serverless-chromeにもビルドしたものが置いてあるが、少しバージョンが古いようだったので最新版でビルドした。 基本的には書いてある 通りやればうまくいく。他のプロセスとのshared memoryとして/dev/shmを使っているのを、/tmpに置き換える ようにしないと、実行時のpage.goto()でFailed Provisional Load: ***, error_code: -12になる。
ビルドしたheadless_shellには問題になった依存は含まれていないようだ。
$ ldd headless_shell linux-vdso.so.1 =&amp;gt; (0x00007ffcb6fed000) libpthread.so.0 =&amp;gt; /lib64/libpthread.so.0 (0x00007f5f17dbe000) libdl.so.2 =&amp;gt; /lib64/libdl.so.2 (0x00007f5f17bba000) librt.so.1 =&amp;gt; /lib64/librt.so.1 (0x00007f5f179b1000) libnss3.so =&amp;gt; /usr/lib64/libnss3.so (0x00007f5f17692000) libnssutil3.so =&amp;gt; /usr/lib64/libnssutil3.so (0x00007f5f17466000) libsmime3.so =&amp;gt; /usr/lib64/libsmime3.</description>
    </item>
    
    <item>
      <title>Headless Chromeでファイルをダウンロードする</title>
      <link>https://www.sambaiz.net/article/131/</link>
      <pubDate>Sun, 03 Sep 2017 18:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/131/</guid>
      <description>Chrome DevTools Protocolに ExperimentalだけどPage.setDownloadBehavior というのがあったので、これを呼んでファイルをダウンロードしてみた。
今回は公式のDevToolsのNode API、Puppeteerを使うけど、 setDownloadBehaviorを送るAPIはまだなく、直接clientを取ってsendするので他のライブラリでもやることは変わらないと思う。 Puppeteerのインストールの際にChromiumも入る。setDownloadBehaviorは現行Chromeの60では対応していないようだけど、62が入ったのでなんとかなりそう。
$ yarn add puppeteer $ find . -name &amp;quot;*chrome*&amp;quot; ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_100_percent.pak ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_200_percent.pak ちなみに、このChromeをLambda上で実行しようとすると失敗する。
Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った
 ChromeでChromeをダウンロードしてみる。
const puppeteer = require(&#39;puppeteer&#39;), fs = require(&#39;fs&#39;); const headless = true, downloadPath = &#39;./Download&#39;; (async () =&amp;gt; { const browser = await puppeteer.launch({headless: headless}); const page = await browser.newPage(); await page._client.send( &#39;Page.setDownloadBehavior&#39;, {behavior : &#39;allow&#39;, downloadPath: downloadPath} ); await page.goto(&#39;https://www.google.co.jp/chrome/browser/desktop/index.html&#39;, {waitUntil: &#39;networkidle&#39;}); await page.</description>
    </item>
    
    <item>
      <title>floatとdoubleの表現と精度</title>
      <link>https://www.sambaiz.net/article/130/</link>
      <pubDate>Sat, 02 Sep 2017 12:47:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/130/</guid>
      <description>IEEE754の仕様。記憶が薄れていたのでまとめておく。
float(32bit)は
 1bit: 符号 8bit: 指数部(exponent) 23bit: 仮数部(fraction)  double(64bit)は
 1bit: 符号 11bit: 指数部 52bit: 仮数部  で表される。
例えば-5.25(2進で-101.01)を表す場合、 -1.0101 * 2^2のように±1.xxxx * 2^nの形にして、負なら符号を1に、指数部を正(1~254or2046)にするため nに127or1023のバイアスを足した数を入れ、仮数部にはxxxxの部分の後ろに0を詰めたのをそのまま入れる。 したがって、-5.25のfloatは1 10000001 01010000000000000000000になる。
ただし、指数部が0のときは仮数部xxxxに対して0.xxxx * 2^-126or1022のように解釈し、 0や指数部で表すことができる数(2^-126or1022)より絶対値が小さい非正規化数を表すことができるようになっている。 また、Infinityはそれぞれ(255or2047,0)、NaNは(255or2047,0以外)で表す。
精度は仮数部の大きさに依存し、floatが10進でMath.log10(2 ** 23) = 6.92桁で、doubleがMath.log10(2 ** 52) = 15.65桁。JavaScriptの数値はdoubleなので 1234567890.1234569が1234567890.123457になり16~17桁目で値がおかしくなることが確認できる。
参考 IEEE 754 - Wikipedia
Double-precision floating-point format - Wikipedia</description>
    </item>
    
    <item>
      <title>Pythonのインタラクティブな可視化ライブラリBokehでグラフを描く</title>
      <link>https://www.sambaiz.net/article/129/</link>
      <pubDate>Sat, 26 Aug 2017 18:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/129/</guid>
      <description>Pythonの可視化というとmatplotlibや、 そのラッパーのseaborn、 データ解析ライブラリのPandasにもそういう機能があるけど、 これらが表示するのが静止画なのに対して、BokehはD3.jsで描画し、 拡大したりスクロールしたり、動的に何か表示することができる。Bokehはカメラのボケ。 似たようなのにPlotlyというのもあるけど、 こちらはPandasと同じpydata.orgドメインで、スターが多い。
jupyter/datascience-notebookイメージにもBokehがインストールされている。
$ docker run -d -p 8888:8888 jupyter/datascience-notebook start-notebook.sh 簡単なグラフを描く output_notebookでJupytor Notebokに出力する。ファイルに出力する場合はouput_fileを呼ぶ。
from bokeh.plotting import figure from bokeh.io import output_notebook, show output_notebook() figure()でplotするFigureオブジェクトを作成する。
p = figure( title=&amp;quot;Hoge&amp;quot;, x_axis_label=&#39;x&#39;, y_axis_label=&#39;y&#39;, y_axis_type=&amp;quot;log&amp;quot; ) line()で線をつないでcircle()で円を描く。
x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0] y0 = [i**2 for i in x] y1 = [10**i for i in x] y2 = [10**(i**2) for i in x] p.line(x, x, legend=&amp;quot;y=x&amp;quot;) p.</description>
    </item>
    
    <item>
      <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
      <link>https://www.sambaiz.net/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/128/</guid>
      <description>Hiveとは Hadoop上で動くデータウェアハウスソフトウェア。 SQLを拡張したHiveQLを書くとデータを処理するMapReduceやSpark、Tezのジョブが生成される。 クエリの実行に時間がかかり、耐障害性があるのでDailyやHourlyのバッチで使われる。
ちなみにAthenaにも使われているPresto はタスクを並列に実行し、中間データをメモリ上に持つことで数分以内に結果が得られるので ダッシュボードなどの用途でアドホックに使える。中間データが大きいと時間がかかったり失敗する。
Impalaはさらに速いけどメモリの消費が激しいらしい。
Cloudera Docker Imageを起動する Cloudera Docker Imageには
 CDH: Clouderaのディストリビューション。Hadoop、Hive、SparkなどのOSSで構成されている。 Cloudera Manager: CDHクラスタを管理する。無料のExpressと有料のEnterpriseで使える機能に差がある。  が含まれていて、これを起動すると諸々立ち上がる。CDHクラスタを組むのはサポートされていないようなのでテスト用らしい。
$ docker pull cloudera/quickstart:latest $ docker run --hostname=quickstart.cloudera --privileged=true -itd -p 8888 -p 7180 -p 80 cloudera/quickstart /usr/bin/docker-quickstart 80がチュートリアルで、8888がHadoopのWeb UIのHue、7180がCloudera Manager。Dockerに割り当てるメモリが2GBだとFailed to contact an active Resource Managerになってしまったので4GBにした。
Hiveのテーブルを作成して実行する チュートリアルではSqoopを使ってDBから取り込んでいるんだけど、 今回はjsonのログのテーブルを作成する。
$ sqoop import-all-tables \ -m 1 \ --connect jdbc:mysql://localhost:3306/retail_db \ --username=retail_dba \ --password=cloudera \ --compression-codec=snappy \ --as-parquetfile \ --warehouse-dir=/user/hive/warehouse \ --hive-import JSONを扱うにはStringからLATERAL VIEW json_tuple(json_str, &amp;quot;field1&amp;quot;, &amp;quot;field2&amp;quot;) j AS field1, field2のように実行時にパースする方法と、JSON SerDeで最初から別カラムにいれる方法があるが、今回はSerDeでやる。</description>
    </item>
    
    <item>
      <title>CloudflareでカスタムドメインのGitHub PagesにHTTPSでアクセスできるようにする</title>
      <link>https://www.sambaiz.net/article/127/</link>
      <pubDate>Mon, 21 Aug 2017 23:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/127/</guid>
      <description>このサイトはGitHub Pagesでカスタムドメインsambaiz.netを設定して、 Apex Domain(sambaiz.net)にAレコードを登録して運用していたのだけれど、これだとカスタムドメインの証明書を置けないのでHTTPSでアクセスすると警告が出てしまう。 いい加減HTTPだと許されない風潮になってきたのでCloudflareを前に挟んでHTTPSでアクセスできるようにした。 ついでにCNAMEを登録できないApex Domain(sambaiz.net)をやめてwww.sambaiz.netに向ける。
DNSの設定をする Cloudflareでドメインを入れると既存のDNS Recordsを読み込むので必要に応じて修正する。 CloudflareではCNAME FlatteningによってApex Domainにも設定上ではCNAMEを与えることができ、内部でAレコードに解決してくれる。 そのためApex Domainをそのまま使っても実は問題ないのだけど、今後のために変えておく。 www.sambaiz.netにGitHub PagesのCNAMEを設定し、sambaiz.net(@)にはwww.sambaiz.netをCNAMEとして設定した。
あとGitHub Pagesの方のカスタムドメインもwww.sambaiz.netにした。 wwwを設定するとApex Domainでアクセスしたときにリダイレクトするようになっているので 既存のリンクが切れたり混在することはない。
指示された*.ns.cloudflare.comのようなCloudflareのネームサーバーをドメインに設定する。 さくらの場合、Apex Domainのネームサーバーはゾーン表示ではなくWHOIS情報のところから変更できる。 設定してしばらくするとCloudflareを通してアクセスが飛び警告なくHTTPSでアクセスできるようになる。 証明書は共有のものになっている。
正常にアクセスできることを確認できたら今HTTPになっている画像やリンクもHTTPSにする。
$ find . -name &#39;.git*&#39; -prune -o -name &#39;public&#39; -prune -o -name &#39;static&#39; -prune -o -type d -o -print | xargs sed -i &amp;quot;&amp;quot; &amp;quot;s/http:\/\/sambaiz.net/https:\/\/www.sambaiz.net/g&amp;quot; Cloudflareの機能 Cloudflareにはいくつかプランがあって、今回はFreeプランにした。
Analytics  キャッシュされている/ないリクエスト数や帯域、それによる節約量 ブロックした脅威の数 何人/どこの国からアクセスが来たか コンテンツ(HTML/CSS/PNG)ごとのリクエストの割合  などがわかる。FreeだとWeb TrafficやGeographyが直近24時間より短いスパンで取れない。
Crypto SSLまわりの設定。
 Flexible: クライアントとCloudflareはHTTPS、CloudflareとオリジンサーバーはHTTPで通信する。 Full: デフォルト。Cloudflareとオリジンサーバーの通信もHTTPSで行うが、証明書の検証は行われない。 Full(Strict) 証明書の検証も行う。  から選択する。Business以上のPlanだと共有の証明書ではなく独自のものを上げることもできる。</description>
    </item>
    
    <item>
      <title>HDFS(Hadoop Distributed File System)とは</title>
      <link>https://www.sambaiz.net/article/126/</link>
      <pubDate>Mon, 14 Aug 2017 22:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/126/</guid>
      <description>HDFSとは Hadoopの分散ファイルシステム。 Hadoopの抽象化されたファイルシステム実装の一つで、他の実装にはLocal fileやS3などがある。 データのサイズが大きい場合に特に問題になるディスクI/Oを分散させ、 読み書きする最小の単位であるブロックサイズを大きくしシークのコストを減らすことで スループットを高めている。 ディスクI/Oがどれくらい遅いかというと、 シークがデータセンター内での往復の通信の20倍(10ms)、 1MBの読み込みが40倍の時間(20ms)かかる。
一方、小さなデータに低レイテンシでアクセスするというのは得意でなく、 また、1ファイルあたり150バイトのメタデータがNameNodeのメモリ上に乗っかるため大量のファイルを扱うのは大変。 あとデータは追記しかできない。
NameNodeとDataNode クラスタの中にはおおよそ2種類のノードがあって、 ブロックがあるいくらかのDataNodeと、
 ファイルの階層とメタデータ どのDataNodeにそのファイルのブロックがあるか  の情報が含まれる
 fsimage(メタデータのスナップショット) edit log(fsimageに含まれていない変更ログ)  を保存する、名前空間に単一のNameNodeがある。 もう一つSecondary NameNodeというのがあって、これはedit logが大きくならないよう 定期的にedit logをfsimageにマージするもの。
NameNodeが機能停止すると読み書きできなくなってしまうので、 新しいNameNodeを立てる必要がある。 その際fsimageにedit logを適用して状態を復元するため これらのファイルを別のファイルシステムにバックアップなどして失われないようにする。
巨大なクラスタだとNameNodeを立ち上げるのに30分以上かかることもあるため、 Secondary NameNodeの代わりにStandby NameNodeを立ててHigh Availabilityにすることもできる。 Standby NameNodeはNameNodeと共有ストレージでedit logを共有し、最新の状態がメモリ上に乗っているので NameNodeが死んだと判断されてから数十秒ほどで切り替えることができる。
書き込みと読み込み 書き込み ファイルシステムがNameNodeとやりとりして、ファイルが存在しているか、パーミッションがあるかを確認し、問題なければFSDataOutputStreamをクライアントに返す。 書き込むデータはdata queueにまず入って、 どのDataNodeに書き込むかはDataStreamerというのがNameNodeとやりとりして決める。 レプリカの設定数分DataNodeが選ばれ、順に書き込まれるようDataNode間でパイプラインを作る。 正常に書き込まれたDetaNodeからはack packetが返ってくるのでこれはack queryに入れて 全て正しく書き込まれたことが確認できたら消す。 失敗したDataNodeがあったら、そこに中途半端に書き込まれた分を復活したら消すようにして、パイプラインから除き 新しいパイプラインを作る。
読み込み ファイルシステムがNameNodeにファイルのブロックがどこにあるかを聞く。 NameNodeは、ブロックがあるDataNodeをクライアントからネットワークトポロジ的に近い順にソートしてアドレスを返す。 ファイルシステムはそのアドレスが含まれたFSDataInputStreamをクライアントに返して、クライアントが順にreadしていく。
SingleNode Clusterで動かす $ yum --enablerepo=epel -y install pdsh $ echo $JAVA_HOME /usr/lib/jvm/jre $ wget http://ftp.</description>
    </item>
    
    <item>
      <title>PythonのLintとFormatter</title>
      <link>https://www.sambaiz.net/article/125/</link>
      <pubDate>Fri, 11 Aug 2017 14:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/125/</guid>
      <description>YAPF スタイルに沿って整形してくれる、Goでいうgo fmtみたいなもの。 デフォルトはPython公式のスタイルガイドPEP8でフォーマットされる。
$ pip install yapf VSCodeでPythonを書くときは、 Pythonプラグイン を入れてこんな設定をWorkspaceのconfigに入れておいて、 保存した時にフォーマットがかかるようにすると快適。
&amp;quot;editor.formatOnSave&amp;quot;: true, &amp;quot;python.formatting.provider&amp;quot;: &amp;quot;yapf&amp;quot; Lint YAPFでフォーマットされた以下のコードにLintをかける。
class FizzBuzz: def __init__(self, start=0): self.num = start def __iter__(self): return self def __next__(self): self.num += 1 if self.num % 15 == 0: return &amp;quot;FizzBuzz&amp;quot; if self.num % 3 == 0: return &amp;quot;Fizz&amp;quot; if self.num % 5 == 0: return &amp;quot;Buzz&amp;quot; return self.num if __name__ == &amp;quot;__main__&amp;quot;: fizzBuzz = FizzBuzz() for i in range(100): print(next(fizzBuzz)) Pylint PythonプラグインではデフォルトでPylintが使われる。</description>
    </item>
    
    <item>
      <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
      <link>https://www.sambaiz.net/article/124/</link>
      <pubDate>Sun, 06 Aug 2017 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/124/</guid>
      <description>AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリSonnetを使う。 当初はPython2しか対応していないようだったけど、今は3にも対応している。
準備 TensorFlowを使うライブラリはほかにもいくつかあるのだけど、 Kerasと比較してみると、 KerasがTensorFlowの部分を完全にラップしているのに対して、 Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。
SonnetとTensorFlowとPython3入りイメージをDockerHubに上げた。 Dockerfileはここ。
内容は基本的にREADME通りだけど、 configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。 あとは、TensorFlowのビルドに使われているGCCのバージョンが古いようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;を付けている。
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_ 起動。
$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet $ docker logs sonnet ... Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=***** Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。
import sonnet as snt import tensorflow as tf snt.resampler(tf.constant([0.]), tf.constant([0.])) # =&amp;gt; &amp;lt;tf.Tensor &#39;resampler/Resampler:0&#39; shape=(1,) dtype=float32&amp;gt; MNIST TensorFlowのチュートリアルのデータを使って、畳み込みを行わない簡単なMNISTをやってみる。 このデータはtrain、validation、test用に最初から分かれていて、 それぞれピクセル濃度配列の画像データと、その画像がどの数字なのかを表すone-hot vectorのラベルを含んでいる。</description>
    </item>
    
    <item>
      <title>Node.jsをTypeScriptで書く</title>
      <link>https://www.sambaiz.net/article/123/</link>
      <pubDate>Sat, 29 Jul 2017 19:34:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/123/</guid>
      <description>公式のTypeScript-Node-Starterから始めてもいいけど、依存が少し余分なので一から作ることにした。
コードはここ。
$ yarn add --dev typescript tslint tslint-microsoft-contrib jest ts-jest @types/jest package.json scriptsとテストフレームワークJestの設定を追加。
{ &amp;quot;devDependencies&amp;quot;: { ... &amp;quot;typescript&amp;quot;: &amp;quot;^2.4.2&amp;quot; }, &amp;quot;scripts&amp;quot;: { &amp;quot;start&amp;quot;: &amp;quot;npm run build &amp;amp;&amp;amp; node dist/app.js&amp;quot;, &amp;quot;build&amp;quot;: &amp;quot;npm run lint &amp;amp;&amp;amp; tsc&amp;quot;, &amp;quot;test&amp;quot;: &amp;quot;jest --forceExit&amp;quot;, &amp;quot;lint&amp;quot;: &amp;quot;tslint -c tslint.json -p tsconfig.json --type-check&amp;quot; }, &amp;quot;jest&amp;quot;: { &amp;quot;transform&amp;quot;: { &amp;quot;^.+\\.ts$&amp;quot;: &amp;quot;./node_modules/ts-jest/preprocessor.js&amp;quot; }, &amp;quot;testRegex&amp;quot;: &amp;quot;/test/.*\\.test\\.(ts|js)$&amp;quot;, &amp;quot;moduleFileExtensions&amp;quot;: [ &amp;quot;ts&amp;quot;, &amp;quot;js&amp;quot; ], &amp;quot;testEnvironment&amp;quot;: &amp;quot;node&amp;quot; } } tsconfig.json 公式のそのまま。
{ &amp;quot;compilerOptions&amp;quot;: { &amp;quot;module&amp;quot;: &amp;quot;commonjs&amp;quot;, &amp;quot;target&amp;quot;: &amp;quot;es6&amp;quot;, &amp;quot;noImplicitAny&amp;quot;: true, &amp;quot;moduleResolution&amp;quot;: &amp;quot;node&amp;quot;, &amp;quot;sourceMap&amp;quot;: true, &amp;quot;outDir&amp;quot;: &amp;quot;dist&amp;quot;, &amp;quot;baseUrl&amp;quot;: &amp;quot;.</description>
    </item>
    
    <item>
      <title>KubernetesのパッケージマネージャーHelmを使う</title>
      <link>https://www.sambaiz.net/article/122/</link>
      <pubDate>Wed, 26 Jul 2017 01:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/122/</guid>
      <description>Kubernatesが操舵手なのに対して、Helmは舵。 パッケージはChart(海図)と呼ばれている。
ChartにはデフォルトでGoのtemplateで書かれたManifestが含まれ、values.yamlの値を-f values.yamlや--set key=valueフラグで上書きして適用しインストールすることができる。
Helmコマンドをインストールする。 今回はminikubeに入れるので立ち上げる。
$ brew install kubernetes-helm $ helm version Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.5.0&amp;quot;, GitCommit:&amp;quot;012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} # brew cask install virtualbox minikube $ minikube version minikube version: v0.20.0 $ minikube start Kubectl is now configured to use the cluster. $ kubectl version Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.2&amp;quot;, GitCommit:&amp;quot;922a86cfcd65915a9b2f69f3f193b8907d741d9c&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2017-07-21T19:06:19Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;} Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;6&amp;quot;, GitVersion:&amp;quot;v1.6.4&amp;quot;, GitCommit:&amp;quot;d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-06-22T04:31:09Z&amp;quot;, GoVersion:&amp;quot;go1.7.5&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;} $ kubectl config current-context minikube まずk8sクラスタ上にHelmの管理サーバーTillerをインストールする必要がある。</description>
    </item>
    
    <item>
      <title>TerraformでVPCを管理するmoduleを作る</title>
      <link>https://www.sambaiz.net/article/121/</link>
      <pubDate>Sun, 23 Jul 2017 02:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/121/</guid>
      <description>Terraform
$ brew install terraform $ terraform -v Terraform v0.9.11 Terraformの設定要素 provider IaaS(e.g. AWS)、PaaS(e.g. Heroku)、SaaS(e.g. CloudFlare)など。
AWS Providerはこんな感じ。 ここに直接access_keyやsecret_keyを書くこともできるけど、誤って公開されてしまわないように環境変数か variableで渡す。
provider &amp;quot;aws&amp;quot; { # access_key = &amp;quot;${var.access_key}&amp;quot; # secret_key = &amp;quot;${var.secret_key}&amp;quot; region = &amp;quot;us-east-1&amp;quot; } $ export AWS_ACCESS_KEY_ID=&amp;quot;anaccesskey&amp;quot; $ export AWS_SECRET_ACCESS_KEY=&amp;quot;asecretkey&amp;quot; varibale CLIでオーバーライドできるパラメーター。typeにはstringのほかにmapやlistを渡すことができ、 何も渡さないとdefault値のものが、それもなければstringになる。
variable &amp;quot;key&amp;quot; { type = &amp;quot;string&amp;quot; default = &amp;quot;value&amp;quot; description = &amp;quot;description&amp;quot; } 値を渡す方法はTF_VAR_をprefixとする環境変数、-var、-var-fileがある。 また、moduleのinputとして渡されることもある。
$ export TF_VAR_somelist=&#39;[&amp;quot;ami-abc123&amp;quot;, &amp;quot;ami-bcd234&amp;quot;]&#39; $ terraform apply -var foo=bar -var foo=baz $ terraform apply -var-file=foo.</description>
    </item>
    
    <item>
      <title>HoloLensでのUnityアプリケーションのフレームレート</title>
      <link>https://www.sambaiz.net/article/120/</link>
      <pubDate>Sun, 16 Jul 2017 23:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/120/</guid>
      <description>HoloLensディスプレイのフレームレート HoloLensのディスプレイは60fpsでリフレッシュされるので、アプリケーションもこれに合わせて60fps、 つまり16msごとにOSにイメージを渡せるのがベスト。 ただし、安定して60fpsが実現できないような重いアプリケーションの場合、 変動してしまうよりは下げて安定させる方が良い。
フレームレートはDevice Portalから確認することができ、キャプチャする際は30fpsに制限される。
Unityアプリケーションのフレームレート Unityでのフレームレートは Application.targetFrameRate で設定できる。デフォルト値は-1で、その場合プラットフォームごとのデフォルト設定が使われる。 何も設定しない状態でHoloLensで動かしたところ60fpsになった。
Debugビルドでのフレームレートの低下 DebugビルドだとSpace Robot Kyle だけ描画するだけでもフレームレートが20まで下がってしまった。
HoloLensで剣振ってみた - sambaiz-net
DebugビルドだったのをRelasseビルドに変えたら60fpsになった。 Relaseビルドではコードの最適化にチェックが入っていたりするんだけど、 その辺りを外してみても特に変わらなかったのでそれではないらしい。</description>
    </item>
    
    <item>
      <title>HoloLensで剣振ってみた</title>
      <link>https://www.sambaiz.net/article/119/</link>
      <pubDate>Sun, 09 Jul 2017 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/119/</guid>
      <description>かつてCardboardでやったようにHoloLensでも剣を振ってみた。
剣を振るVRゲームを作った - sambaiz-net
剣を振ってロボットに当てると爆発する。
動画
剣の方は前回と同じくiOSアプリから傾きをBLEで送信している。今回は傘がなかったのでペットボトルにくくりつけた。
HoloLensのアプリの方はUWPのネイティブプラグインを作った。 Creater&amp;rsquo;s UpdateのAPIがまだ使えなかったので一つ前のAPIを使ってビルドしている。 なお、ペアリングはアプリ内ではなくOSの設定画面から行なっている。 エラーについては原因が分からずハンドリングできていないものもあるけど、つなぎ直すと大抵どうにかなった。 つなぎ直す際はHoloLens側だけではなくiOS側の方の設定も削除する。
Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net
ロボットを小さくしているのは近づいても視野角に収まるようにするため。 小さいとどこにいるか分からないので目印を出したほうが良い。 近接武器じゃなきゃ敵に近づかなくてよくなるのでましになるかも。
上の動画を見れば分かるように、全体的に動きが重くて素でframerateが20ぐらいしか出ていない。 これはReleaseビルドにすると改善された。
HoloLensでのUnityアプリケーションのフレームレート - sambaiz-net</description>
    </item>
    
    <item>
      <title>HoloLensのSpartial MappingでNavMeshを生成してランダムにAgentを出現・移動させる</title>
      <link>https://www.sambaiz.net/article/118/</link>
      <pubDate>Sun, 02 Jul 2017 23:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/118/</guid>
      <description>Unity 5.6.2f1 HoloToolkit v1.5.7.0 Unity 5.6から動的にNavMeshを生成できるようになったので HoloLensのSpartial MappingしたものをNavMeshにしてAgentを動かしてみる。
Unityで動的にNavMeshを生成する - sambaiz-net
Spartial MappingしたものをNavMeshにするのは以下の記事のスクリプトを使った。
HoloLens の空間マップで NavMesh を使ってみる - たるこすの日記
Unity-Technologies/NavMeshComponentsから LocalNavMeshBuilderとNavMeshSourceTagを持ってきてLocalNavMeshBuilderのObjectを置いておき、 Spartial MappingしたものにNavMeshSourceTagを付けられればExampleと同様にNavMeshにできる。 そこで、このスクリプトではSpatialMappingSourceを取得し、イベントハンドラでNavMeshSourceTagが追加されるようにしている。
using HoloToolkit.Unity.SpatialMapping; using UnityEngine; using HoloToolkit.Unity; public class SpatialMappingNavMesh : MonoBehaviour { public GameObject SpatialMapping; private void Awake() { var spatialMappingSources = SpatialMapping.GetComponents&amp;lt;SpatialMappingSource&amp;gt;(); foreach (var source in spatialMappingSources) { source.SurfaceAdded += SpatialMappingSource_SurfaceAdded; source.SurfaceUpdated += SpatialMappingSource_SurfaceUpdated; } } private void SpatialMappingSource_SurfaceAdded(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceObject&amp;gt; e) { e.Data.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;(); } private void SpatialMappingSource_SurfaceUpdated(object sender, DataEventArgs&amp;lt;SpatialMappingSource.</description>
    </item>
    
    <item>
      <title>Unityで動的にNavMeshを生成する</title>
      <link>https://www.sambaiz.net/article/117/</link>
      <pubDate>Sat, 01 Jul 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/117/</guid>
      <description>Unity5.6から動的にNavMeshを生成できるようになった。
Unity-Technologies/NavMeshComponentsの Exampleの2_drop_blankのsceneを開く。
分断されたCubeの床と、その上に黄色いCylindarと赤いCubeがあって、 クリックしたところに黄色いCylindarが動くんだけど、床がつながっていないのでそのままでは赤いCubeまではたどり着けない。 スペースを押すと目の前に板が出てくるのでこの上を渡って移動することができる。
板の上がNavMeshとして認識されている。
床のCubeと追加される板にはNavMeshSourceTag.csが付いていて、staticなm_Meshesとm_Terrainsにそれぞれ追加している。
public static List&amp;lt;MeshFilter&amp;gt; m_Meshes = new List&amp;lt;MeshFilter&amp;gt;(); public static List&amp;lt;Terrain&amp;gt; m_Terrains = new List&amp;lt;Terrain&amp;gt;(); void OnEnable() { var m = GetComponent&amp;lt;MeshFilter&amp;gt;(); if (m != null) { m_Meshes.Add(m); } var t = GetComponent&amp;lt;Terrain&amp;gt;(); if (t != null) { m_Terrains.Add(t); } } void OnDisable() { var m = GetComponent&amp;lt;MeshFilter&amp;gt;(); if (m != null) { m_Meshes.Remove(m); } var t = GetComponent&amp;lt;Terrain&amp;gt;(); if (t != null) { m_Terrains.</description>
    </item>
    
    <item>
      <title>Fluentdのout_copyのstoreのエラーは他のstoreに影響する</title>
      <link>https://www.sambaiz.net/article/116/</link>
      <pubDate>Sat, 01 Jul 2017 18:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/116/</guid>
      <description>Fluentdのout_copyプラグインは 一つのeventを複数のoutputに渡すために使われる。 ただ、複数設定した中のstoreでエラーが起きると他のstoreにも影響してしまう。
例えばこんなの。
&amp;lt;source&amp;gt; @type dummy dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;} tag dummy rate 1 &amp;lt;/source&amp;gt; &amp;lt;match dummy&amp;gt; @type copy &amp;lt;store&amp;gt; @type stdout &amp;lt;/store&amp;gt; &amp;lt;store&amp;gt; @type file path /var/log/td-agent/dummy buffer_queue_limit 0 buffer_chunk_limit 1k &amp;lt;/store&amp;gt; &amp;lt;/match&amp;gt; fileの方でqueue size exceeds limitになるとstdoutも出力されなくなってしまう。
ちなみに一旦relabelしてもだめ。
&amp;lt;source&amp;gt; @type dummy dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;} tag dummy rate 1 &amp;lt;/source&amp;gt; &amp;lt;match dummy&amp;gt; @type copy &amp;lt;store&amp;gt; @type stdout &amp;lt;/store&amp;gt; &amp;lt;store&amp;gt; @type relabel @label @file &amp;lt;/store&amp;gt; &amp;lt;/match&amp;gt; &amp;lt;label @file&amp;gt; &amp;lt;match dummy&amp;gt; @type file path /var/log/td-agent/dummy buffer_queue_limit 0 buffer_chunk_limit 1k &amp;lt;/match&amp;gt; &amp;lt;/label&amp;gt; ドキュメントでも紹介されている、sonots氏のout_copy_exでは storeにignore_errorを付けるとrescueするようになっているので他に巻き込まれなくなる。</description>
    </item>
    
    <item>
      <title>Unityの経路探索: NavMeshとAgentとObstacle</title>
      <link>https://www.sambaiz.net/article/115/</link>
      <pubDate>Thu, 29 Jun 2017 00:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/115/</guid>
      <description>NavMeshと経路探索 NavMeshというのはエージェントが移動できる面についてのデータ構造で、凸ポリゴンの面と位置関係を含んでいる。 経路探索は2点間を一番近いポリゴンにマッピングし、A*アルゴリズムを用いて行われる。あとからオブジェクトが追加されるなどして道を塞いでしまってもCarvingしてNavMeshに穴をあければ別の経路で移動することができるが、このようなグローバルの経路探索に影響を及ぼす操作は計算にコストがかかるので、各エージェントローカルの衝突回避で済むならそのほうがよい。
NavMeshをbakeする こんな感じで床に適当なオブジェクトを置いてみた。
Window -&amp;gt; NavigationでBakeするのを選択してNavigation Staticし(StaticになってBakeの対象になる)、 Bakeボタンを押すとこんな感じでBakeされる。
オブジェクトの上がNavMeshに含まれていないのはAgent sizeのStep Heightよりも高いため。 段差を移動するときに浮いてしまうのを避けるためにはAdvancedのHeight Meshをオンにする。 また、端が含まれていないのはこのAgentの中心が入れる位置を表しているためで、 Agent Radiusを変更すると広がったり狭まったりするのを確認できる。
NavMesh Agent Radius0.5, Height2のCylindarを作成し、Nav Mesh Agentを追加する。
で、ゴールにオブジェクトを置いてそこまで移動させてみる。
using UnityEngine.AI; public GameObject goal; void Start () { var agent = GetComponent&amp;lt;NavMeshAgent&amp;gt;(); agent.destination = goal.transform.position; } NavMesh Obstacle 障害物。上で通った経路上にNavMesh Obstacleを追加したCubeを置いたところうまく避けてゴールまでたどり着いた。
ただ、完全に道をふさいでしまうと立ち往生してしまうので Carveにチェックを入れるとCarvingされ、他の経路でゴールまで進むようになる。
Unityで動的にNavMeshを生成する - sambaiz-net</description>
    </item>
    
    <item>
      <title>Unityの物理エンジン・衝突: RigidbodyとCollidarとJoint</title>
      <link>https://www.sambaiz.net/article/114/</link>
      <pubDate>Sun, 25 Jun 2017 23:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/114/</guid>
      <description>Rigidbody GameObjectを物理特性によって制御し、力の影響を受けるようにする。 Mass(質量)やDrag(空気抵抗)、Use Gravityなどのプロパティがある。
移動させるのに自分でTransformは変更せず力をかけて物理演算に任せる。 Is Kinematicにチェックを入れると物理エンジンによって移動しないようになるので、 Transformを直接変更する場合は有効にする。 ただし、スクリプトで動的にIs Kinematicを切り替えるのはパフォーマンスが良くない。
Collidar RigidBodyの物理特性の境界を定義する。衝突させるには両方にCollidarが設定されている必要がある。 RigidBodyなしのCollidarを静的Collidarといって、無効にしたり移動しないことを前提に最適化される。 移動したりするものについてはRigidBodyを付けて、必要ならIs Kinematicを有効にする。
衝突時にはOnCollisionEnter() が呼ばれる。ほかに離れたときのOnCollisionExit()、 触れている間、毎フレーム呼ばれるOnCollisionStay()がある。
void OnCollisionEnter(Collision collision) { foreach (ContactPoint contact in collision.contacts) { if (contact.otherCollider.tag == &amp;quot;Player&amp;quot;) { Debug.Log(collision.relativeVelocity.magnitude); } } } Is Triggerにチェックを入れると物理エンジンには無視されてすり抜け、侵入に対してトリガーイベントが呼ばれる。 OnCollistionと同様に OnTriggerEnter()、 OnTriggerExit()、 OnTriggerStay() がある。
void OnTriggerEnter(Collider other) { Debug.Log(other.tag); } Joint Rigitbodyを他のRigitbodyとつなげるもの。 例えばSprint Jointだとオブジェクト間がばねのように伸縮する。</description>
    </item>
    
    <item>
      <title>fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする</title>
      <link>https://www.sambaiz.net/article/113/</link>
      <pubDate>Sun, 25 Jun 2017 00:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/113/</guid>
      <description>デプロイやスループットの調整を簡単にするため、BeanstalkでAggregatorを立ち上げた。
負荷分散 TCPの24224(設定による)が通るようにEC2,ELBのSGとリスナーの設定をする必要があって、 ELBのSGのアウトバウンドの設定が見落とされがち。ELBのクロスゾーン分散は有効になっている。
まず、ELBに3台、それぞれ別のAZ(1b, 1c, 1d)に配置されている状態でログを送り始めるとそれぞれ均等にログが届いた。 その状態から4台(1b * 2, 1c, 1d)にすると、2つのインスタンス(1b, 1c)のみに均等にログが届くようになった。 4台になると(1b, 1c)と(1b, 1d)に分けられてELBのノードがそれらの組に紐づいたということだと思う。 各ノードにはDNSラウンドロビンするようになっている。実際restartすると今度は別の組の方に送られた。
では、なぜ一度送り始めると同じ方にしか飛ばないかというと、forwardプラグインのexpire_dns_cacheがデフォルトでnilになっていて、 heartbeatが届いている間は無期限にDNSキャッシュするようになっているため。これに0(キャッシュしない)か秒数を指定すると、 その間隔で他の組のインスタンスにもログが届くようになった。 expire_dns_cacheしなくても複数のインスタンスからラウンドロビンされるため全体でいえば分散される。
heartbeat ELB配下のEC2を全て落としてもheartbeatに失敗しないため、standyに移行せずELBのバックエンド接続エラーになってログがロストしてしまうようだ。 ログにも出ず、以下のようにactive-standbyの設定をしてもstandbyに移行しない。 全てのインスタンスが同時に落ちるというのは滅多に起きないだろうけど、少なくとも検知できるようにはしておく。
&amp;lt;server&amp;gt; name td1 host autoscale-td1.us-east-1.elasticbeanstalk.com port 24224 &amp;lt;/server&amp;gt; &amp;lt;server&amp;gt; name td2 host autoscale-td2.us-east-1.elasticbeanstalk.com port 24224 standby &amp;lt;/server&amp;gt; Blue/Green Deployment Blue-Green Deploymentというのは、2つの系を用意し、activeでない方にデプロイし、 スワップして反映させるもの。ダウンタイムなしで問題が起きた際にもすぐに切り戻すことができる。 スワップして向き先を変えるにはexpire_dns_cacheを設定する必要がある。
Auto Scaling 増えるのはいいとして減るときに、 送り先で一時的に障害が起きていたりするとバッファをflushできずにログがロストする可能性がある。 それでいうとログの送り元でも同じことが起こりうるんだけど、通常Aggregatorにしか送らないので比較的問題になりにくい。
これを避けたい場合、Auto Scalingグループの設定で スケールインから保護を有効にして これから立ち上がるインスタンスはスケールインしなくすることができる。 それまでに立ち上がっていたインスタンスには適用されないので注意。
スケールインしないということは最大の台数で止まってしまうので、 ピークを過ぎたらスワップしてバッファが全て掃けたことを確認してからTerminateすることになる。 これを日常的にやるのは面倒なので、実際は予期しない流量の増加に備えて一応設定しておき、 普段はしきい値にひっかからないような最低台数で待ち構えておくことにするかな。
あとはヘルスチェックによって潰される可能性はなくもないけど、それはもうやむなし・・・。
参考 AWS ELBの社内向け構成ガイドを公開してみる 負荷分散編 – Cross-Zone Routingを踏まえて ｜ Developers.</description>
    </item>
    
    <item>
      <title>UnityのMecanimでヒューマノイドアニメーションさせる</title>
      <link>https://www.sambaiz.net/article/112/</link>
      <pubDate>Tue, 20 Jun 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/112/</guid>
      <description>Space Robot Kyleを動かす。
アバターの作成 AssetsのModel/Robot Kyleを選択し、RigのAnimation TypeをHumanoidにすると、 自動的にボーン構造を解析して人型にマッピングしたアバターが設定される。 Configure Avatarで確認すると正しく設定されているようだ。
モーションの設定 KyleのAnimatorのAnimationに設定するAnimation Controllerを作成する。 まずは2つCreate Stateし、それぞれMotionに適当なモーション(今回はFighter Pack Bundle FREEを使った)を設定し、 Make Transitionで相互に結ぶと、オレンジになっているデフォルトステートから交互にモーションする。 ステートにはStateMachineBehaviourのScriptを設定することもできる。
次にParametersでモーションを変化させる。
Animatorの左上、parametersタブからBoolのWalkを追加する。 そして片方のTransitionのConditionにWalkがfalse、もう片方にはWalkがtrueを追加すると、 状態によって違うモーションをするようになる。 ちなみに、AnyStateからConditionを設定したTransitionを設定すると、どこのStateからでもそれで遷移させることができる。
このParameterはこんな感じに値を設定できる。
void Update () { GetComponent&amp;lt;Animator&amp;gt; ().SetBool (&amp;quot;Walk&amp;quot;, Random.value &amp;lt; 0.5); } 一部だけモーションさせる 人体の一部だけをモーションさせるにはAvatar Maskを使う。
Animationで複数のレイヤーを作成すれば、異なるMaskでそれぞれステートを持たせることができる。
Animation Override Controller 作ったAnimationを違うモーションで再利用することができる。</description>
    </item>
    
    <item>
      <title>NorikraでログをJOINする</title>
      <link>https://www.sambaiz.net/article/111/</link>
      <pubDate>Thu, 15 Jun 2017 00:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/111/</guid>
      <description>NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net
適当なログを出すコードを書いた。
sambaiz/lottery-log
これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。 広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。
// lottery.log {&amp;quot;ts&amp;quot;:1497453504.6818597,&amp;quot;uid&amp;quot;:&amp;quot;b18c0d98-19b2-4e37-8fc4-6b00a4b728c3&amp;quot;,&amp;quot;prize&amp;quot;:855,&amp;quot;isWin&amp;quot;:true} // received.log {&amp;quot;ts&amp;quot;:1497453515.932101,&amp;quot;uid&amp;quot;:&amp;quot;bc4f578f-4a5f-47f1-a4e0-1ef0b43c316e&amp;quot;} クエリはこんな感じ。一つはlotteryログとreceivedログをuidでJOINするもので、 received_rateの計算にはサブクエリも使っている。 received_rateの計算で分母に小さな値を足しているのはNaNやInfinityにならないようにするため。 receivedログは最大30秒遅れて出力されるため、40秒前までのreceivedログをwin:timeで見ている。 これをtime_batchにしてしまうと期待通りの結果にならないので注意。
もう一つはJavaの関数でboolを0/1にして平均をとることでisWinがtrueである割合を出している。
$ docker exec norikra norikra-client query add lottery_agg &#39; SELECT COUNT(*) as received_count, (COUNT(*) / (SELECT COUNT(*) + 0.00001 FROM lottery.win:time_batch(1 sec, 0).std:unique(uid))) as received_rate, AVG(prize) as prize_avg, SUM(prize) as prize_sum FROM lottery.win:time(40 sec).std:unique(uid) as a, received.win:time_batch(1 sec, 0).std:unique(uid) as b WHERE a.uid = b.uid&#39; $ docker exec norikra norikra-client query add lottery_win_rate &#39;SELECT avg(Boolean.</description>
    </item>
    
    <item>
      <title>VSでのネイティブプラグインのビルドからUnityでのWSAのビルドまでをバッチでする</title>
      <link>https://www.sambaiz.net/article/110/</link>
      <pubDate>Tue, 13 Jun 2017 00:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/110/</guid>
      <description>VSでのネイティブプラグインのビルド VSが使っているビルドツール MSBuildを使う。 VSのプロジェクトファイルにはMSBuildのXMLが含まれている。 これ自体はVSに依存していないため、単体で動かすこともできる。
パスが通ってなかったらパスを通す。管理者権限が必要。
&amp;gt; MSBuild &#39;MSBuild&#39; は、内部コマンドまたは外部コマンド、 操作可能なプログラムまたはバッチ ファイルとして認識されていません。 &amp;gt;　SETX /M PATH &amp;quot;%PATH%;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\Bin&amp;quot; 成功: 指定した値は保存されました。 別プロセスから適用されるので立ち上げ直すとパスが通っていることを確認できる。
&amp;gt; MSBuild /version Microsoft (R) Build Engine バージョン 15.1.1012.6693 Copyright (C) Microsoft Corporation.All rights reserved. 15.1.1012.6693 ビルドしてAssets\Pluginsに配置する。これは前作ったBLEのネイティブプラグインのもの。
Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net
&amp;gt; git clone git@github.com:sambaiz/UnityBLE_UWP.git &amp;gt; cd UnityBLE_UWP &amp;gt; MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;quot;x86&amp;quot; &amp;gt; MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release &amp;gt; copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA &amp;gt; copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.dll .</description>
    </item>
    
    <item>
      <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
      <link>https://www.sambaiz.net/article/109/</link>
      <pubDate>Sat, 10 Jun 2017 12:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/109/</guid>
      <description>NorikraはTD社のtagomoris氏が作った、 スキーマレスのストリーミングデータを処理するOSS。
モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだけど、 流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。
Norikraを立ち上げてクエリを実行する 公式で紹介されているDockerイメージがあったのでこれで動かしてみる。
$ docker run -e &amp;quot;TZ=Asia/Tokyo&amp;quot; -p 26578:26578 -p 26571:26571 -v `pwd`:/var/tmp/norikra:rw -d myfinder/docker-norikra norikra start --stats /var/tmp/norikra/stats.json -l /var/tmp/norikra ほかのオプションとして-Xmsや-XmxでJVMのヒープメモリの量を設定したり、Experimentalではあるけど--shutoffでヒープメモリが一杯になる前に弾いて OutOfMemoryを防ぐことができる。 また、Norikraのコアエンジンで使われているOSSの CEP (Complex event processing)エンジン、 Esper のパフォーマンスチューニングとして--microや--smallなどを渡すこともできるけど試していない。
公式サイトの例に従ってクライアントからデータを入れてクエリを実行してみる。
まずはtargetをopenする。targetというのはスキーマレスのイベントストリームのこと。 ここで定義したフィールドは必須になる。
$ norikra-client target open www path:string status:integer referer:string agent:string userid:integer $ norikra-client target list TARGET	AUTO_FIELD www	true 次にクエリを追加する。一見普通のSQLのように見えるけど、EsperのクエリであるEPL(Event Processing Language)。 ただしSELECTしか使えないのも含めてクエリにいくらかの制限がある。
このクエリではwin:time_batchで10秒のWindowを定義し、eventをgroup byして、その数をeventとして出力する。
$ norikra-client query add www.toppageviews &#39;SELECT count(*) AS cnt FROM www.</description>
    </item>
    
    <item>
      <title>fluentdでKinesis streamsに送るときの性能確認</title>
      <link>https://www.sambaiz.net/article/108/</link>
      <pubDate>Mon, 05 Jun 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/108/</guid>
      <description>localでのstreamsとproducerのbenchmark aws-fluent-plugin-kinesisの make benchmarkはlocalにDummyServerを立ち上げて送っている。
空でもいいのでroleをつけておく必要がある。
$ git clone https://github.com/awslabs/aws-fluent-plugin-kinesis.git $ cd aws-fluent-plugin-kinesis $ yum install -y ruby-devel gcc $ echo &#39;gem &amp;quot;io-console&amp;quot;&#39; &amp;gt;&amp;gt; Gemfile $ make $ make benchmark RATEを指定しなければデフォルトで秒間1000レコードが送られる設定。 fluentdを起動してから10秒後にプロセスをkillし、そのレコード数などを出力している。
t2.microでデフォルト(RATE=1000)で実行した結果がこれ。 固める分producerの方はややパフォーマンスが落ちる。
bundle exec rake benchmark TYPE=streams Results: requets: 20, raw_records: 9400, records: 9400 bundle exec rake benchmark TYPE=producer Results: requets: 14, raw_records: 1005, records: 8900 RATE=3000のとき。producerではraw_recordsが1/100、リクエスト数は1/5。 streamsだとシャードを増やしていく必要があるけど、producerの方は当分大丈夫そうだ。
bundle exec rake benchmark TYPE=streams Results: requets: 57, raw_records: 27600, records: 27600 bundle exec rake benchmark TYPE=producer Results: requets: 12, raw_records: 241, records: 25200 RATE=10000のとき。raw_records, requestの圧縮率はさらに上がり、 パフォーマンスの差が大きくなってきている。</description>
    </item>
    
    <item>
      <title>td-agent2.3.5のfluentdが0.14系になってしまっているのでソースからビルドする</title>
      <link>https://www.sambaiz.net/article/107/</link>
      <pubDate>Sun, 04 Jun 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/107/</guid>
      <description>追記(2016-06-25): 現在は普通に入れても0.12系の2.3.5-1が入るようになっている。
 $ curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh $ td-agent --version td-agent 0.14.16 0.12系じゃない！？
$ yum list installed | grep td-agent td-agent.x86_64 2.3.5-0.el2017 @treasuredata どうやら2.3.5では0.14系になってしまっているよう。 そのあとにリリースされた2.3.5-1では直ってるみたいだけど、現時点ではrpmリポジトリに上がっていない。
しょうがないのでソースからビルドすることにした。 いずれにせよ各環境で同じバージョンのビルドに合わせるべきだとは思う。 Beanstalk環境の場合、AMIに固めていたとしても非Beanstalk AMIではyum updateされてしまうので注意が必要だ。
BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因 - sambaiz-net
前UbuntuでやったようにDockerでビルドする。今回はAmazon Linux向け。
td-agentをビルドしてfluentdのバージョンを上げる - sambaiz-net
https://hub.docker.com/r/sambaiz/docker-td-agent-build-amazon-linux/
FROM amazonlinux:2017.03 WORKDIR /tmp RUN yum -y update &amp;amp;&amp;amp; \ yum groupinstall -y &amp;quot;Development Tools&amp;quot; &amp;amp;&amp;amp; \ yum install -y ruby23 ruby23-devel &amp;amp;&amp;amp; \ gem install bundler io-console &amp;amp;&amp;amp; \ git clone https://github.</description>
    </item>
    
    <item>
      <title>BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因</title>
      <link>https://www.sambaiz.net/article/106/</link>
      <pubDate>Sun, 04 Jun 2017 23:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/106/</guid>
      <description>User-Dataとは EC2インスタンス起動時に、シェルスクリプトを走らせたりcloud-initディレクティブを適用できる機能。 コンソールではインスタンスの詳細の設定の、高度な詳細のところから設定できる。
BeanstalkでのUser-Data 実はBeanstalkでも使われていて、CloudFormationで設定されている。
&amp;quot; /bin/bash /tmp/ebbootstrap.sh &amp;quot;, ... &amp;quot;Fn::FindInMap&amp;quot;: [ &amp;quot;AWSEBOptions&amp;quot;, &amp;quot;options&amp;quot;, &amp;quot;UserDataScript&amp;quot; ] &amp;quot; &amp;gt; /tmp/ebbootstrap.sh &amp;quot;, ... &amp;quot;AWSEBOptions&amp;quot;: { &amp;quot;options&amp;quot;: { &amp;quot;UserDataScript&amp;quot;: &amp;quot;https://s3-ap-northeast-1.amazonaws.com/elasticbeanstalk-env-resources-ap-northeast-1/stalks/eb_node_js_4.0.1.90.2/lib/UserDataScript.sh&amp;quot;, &amp;quot;guid&amp;quot;: &amp;quot;f08557fc43ac&amp;quot;, } } このshellの中では、時計を同期させたり、awsebユーザーを作成したりするほかに、 非Beanstalk AMI(is_baked=false)ではyum updateが走るようになっている。 そのため、AMIでのバージョンとBeanstalkで立ち上がったときのバージョンが異なることがあるようだ。
GUID=$7 function update_yum_packages { if is_baked update_yum_packages_$GUID; then log yum update has already been done. else log Updating yum packages. yum --exclude=aws-cfn-bootstrap update -y || echo Warning: cannot update yum packages. Continue... mark_installed update_yum_packages_$GUID # Update system-release RPM package will reset the .</description>
    </item>
    
    <item>
      <title>Unity/UWPでBLEを扱うプラグインを作る</title>
      <link>https://www.sambaiz.net/article/105/</link>
      <pubDate>Sun, 04 Jun 2017 11:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/105/</guid>
      <description>コードはここ
この動画の 50:00あたりから説明があるように、 ビルドされたWSAが読むUWPのdllのほかに、 Unityエディタ上から読むための.NET Framework3.5のdllを用意する。 こうすることで実行環境ごとの違いをUnityコード上で気にしなくてもよくなる。
新しいプロジェクトで
  Visual C# から.NET Framework 3.5にしてクラスライブラリ(.NET Framework)
  Visual C# -&amp;gt;　Windows -&amp;gt; ユニバーサルからクラスライブラリ(ユニバーサルWindows)
  の2つのプロジェクトを同じソリューションに作成する。 VS2017で.NET Frameworkのクラスライブラリプロジェクトを作成するためには Visual Studio Installerで.NET Coreのワークロードをインストールする必要がある。 また、これとは別に動作確認用のUWPアプリケーションプロジェクトを作成した。
UWPの方のプロジェクトにあるClass1.csを削除し、追加 -&amp;gt; 既存の項目から、 もう片方のClass1.csをリンクとして追加して、この共通のcsにUWPのコードを書いていくんだけど、 そのまま書くと当然.NET Frameworkの方でビルドできないので 実装部分を#if WINDOWS_UWP ~ #endif で囲む。UWPの方のプロジェクトにはプロパティ -&amp;gt; ビルドの条件付きコンパイルにWINDOWS_UWPが含まれているので有効になる。
public void Start() { #if WINDOWS_UWP ... #endif } UWPでBLEを扱うのは前書いた通り。 ただし、なぜかXAMLに依存しているようでD3Dビルドすると失敗する。
UWPでBLEデバイスとペアリングして値を取得する - sambaiz-net
ビルドするとdllができるので.NET Frameworkの方をAssets/Pluginsに置いてInspectorからEditorにだけチェックを入れる。 UWPの方はAssets/Plugins/WSAに置くとWSA Playerにだけチェックが入る。
あとは普通にusingして使うだけ。Edit-&amp;gt;Project Settings-&amp;gt;PlayerからBluetoothのcapabilityを有効にするのを忘れずに。 Package.appxmanifestは上書きされないようなので前にビルドしたやつがあったら一旦消す。
using UnityBLE; public class BLE : MonoBehaviour { string value = &amp;quot;no connection&amp;quot;; public GameObject text; private string serviceUUID = &amp;quot;***&amp;quot;; private string characteristicUUID = &amp;quot;***&amp;quot;; void Start() { var ble = new UnityBLE.</description>
    </item>
    
    <item>
      <title>Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる</title>
      <link>https://www.sambaiz.net/article/104/</link>
      <pubDate>Sat, 27 May 2017 16:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/104/</guid>
      <description>https://github.com/uber-go/zap
$ go get -u go.uber.org/zap $ go get -u gopkg.in/natefinch/lumberjack.v2 速さの秘訣 Go言語のLogger「zap」は何故高速に構造化されたログを出力する事が出来るのか｜株式会社CAリワード
reflectionとallocationの回避。
一度allocateしたBufferやEncoderは sync.Poolで使い回している。 このPoolはまさにallocateされたアイテムを再利用するためのもので、GCの負担を緩和させることができる。 Poolのアイテムは勝手に削除されることがあり、もし参照しか持っていなかったらそのままdeallocateされる。
https://github.com/uber-go/zap/blob/v1.4.0/buffer/pool.go#L34
func NewPool() Pool { return Pool{p: &amp;amp;sync.Pool{ New: func() interface{} { return &amp;amp;Buffer{bs: make([]byte, 0, _size)} }, }} } 使い方 現状ドキュメントが乏しいのでコードから探っていく必要がある。 まずはQuick Startから。
zap.NewProduction()はNewProductionConfig().Build(options...)のショートカット。 ConfigをBuildしてLoggerを取得し、InfoやErrorで書く流れ。
logger, _ := zap.NewProduction() defer logger.Sync() logger.Info(&amp;quot;Hoge&amp;quot;, // Structured context as strongly-typed Field values. zap.Int(&amp;quot;attempt&amp;quot;, 3), zap.Duration(&amp;quot;backoff&amp;quot;, time.Second), ) {&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1495870212.3378785,&amp;quot;caller&amp;quot;:&amp;quot;zap-log/main.go:36&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;Hoge&amp;quot;,&amp;quot;attempt&amp;quot;:3,&amp;quot;backoff&amp;quot;:1} NewProductionConfig()の内容はこんな感じ。ここからOutputPathを書き換えるとファイルに出力されるようにできる。
config := zap.Config{ Level: zap.NewAtomicLevelAt(zap.ErrorLevel), Development: false, Sampling: &amp;amp;zap.</description>
    </item>
    
    <item>
      <title>夜のNY郊外を無一文で彷徨い、Google I/OとMaker Faire Bay Areaに行ってきた</title>
      <link>https://www.sambaiz.net/article/103/</link>
      <pubDate>Mon, 22 May 2017 23:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/103/</guid>
      <description>Googleが毎年やっているイベント、Google I/Oのチケットが当たったのでアメリカに行ってきた。 海外に行くのはこれが3回目でアメリカははじめて。一人での海外もはじめて。
準備 チケットが当たってからExpediaで航空券やホテルを取った。航空券の流れで保険にも加入した。 アメリカの医療費は相当高いそうなので何かしらの保険に入っておかないと不安だ。
会期中は会場近辺のサンフランシスコ/マウンテンビューのホテルがとんでもなく値上がりしている模様。 多分通常の倍ぐらいにはなっているので早めに取っておくとよいと思われる。
GoogleI/Oは週末にかけての3日間だったので、その前の週末から出発し、前半はニューヨークに行くことにして、 マンハッタンに宿を取った。
アメリカに入国するのにはESTAを申請する必要がある。 申請自体は72時間以内に通るのだけど、パスポート番号が必要がなので持っていなければ先に作っておく必要がある。 ESTAが通っていないと本当に入れないらしい。怖い。
現地での通信手段はT-mobileのTourist plan($30プリペイドでSIM+2GB LTE+国内通話+SMS) を購入することにした。 日本にはsimを送ってくれないので現地で調達する必要がある。モバイルルータはちょっと高いような気がして借りなかった。
あとは英語力をなんとかしようと付け焼刃でDMM英会話をはじめてみたが、準備期間が短すぎたかなと思う。
出国 チェックインの締め切りが出発の1時間前だったので、 余裕を持って2時間前ぐらいには着くはずだったんだけど、こんなときに限って財布を落とすわ成田エクスプレスは突然運休するわで大ピンチ。 日暮里から京急のスカイライナーに乗ってスーツケースをかついで走ってなんとか飛行機には間に合ったが、 両替などする時間はなく、財布に1000円しか入っていない状態で出発することになってしまった。
距離にして11000km、12時間のフライトの末、ニューヨークのジョン・F・ケネディ国際空港(JFK)に到着。 時差で-13時間になるため出発よりも早い時刻に到着することになって得した気分だ。 ついにアメリカに来た。
ニューヨーク 当初はニューヨーク観光しつつ、アムトラック(電車)でワシントンD.C.にも行っちゃおうかと考えてチケットまで買っていた。 しかし現実は厳しい。
 現地に到着し、通信手段を調達するためT-mobileのショップに向かおうとしたが、肝心のショップの場所がわからない。 もちろん日本のsimカードはすでに機能停止しているので空港のWifiで調べたところ、そこから一番近いところでも数km離れていることがわかった。 タイムズスクエアの近くにはあるようだったので、まずはなんとかしてホテルに向かうことにしたが、 JFKからマンハッタンまでは直線距離で20km以上離れている。ホテルの送迎サービスはなかった。 それでもGoogle mapに従って、途中free wifiを乗り継いでいけばこのときはなんとかなるかなと思っていた。
空港から電車で行こうと思っていたところ、うかつにも謎タクシーに誘導されて乗ってしまった。 47ドルでホテルまで行ってくれると思いきや、それはJamaica駅までの料金で、ホテルまでは100ドルという。調べていた相場の倍だ。 傷口を広げないようJamaicaで降ろしてもらうことにした。 乗る前に現金はないからクレジットカードで払う旨を伝えたのだけど、 支払いの段になってクレジットカードの機械が壊れたから現金でと言い出して困った。なにせ1ドルも持っていないのだから。 近くのATMで現金を下ろすよう言われたのでクレジットカードを入れたのだけれど 2枚ともアウト。そこからどうやって払うんだって問いつめられるもののどうしようもない。 結局解放してもらえたが、初っ端からほとんど心が折れてしまって国に帰りたかった。
それでもなんとかしてホテルにはたどり着かなくてはならないので、LIRRという電車でJamaicaからWoodside駅に向かった。 空港で調べたGoogle mapの経路に出たからそうしたのだけど、 マンハッタンにあるハブ駅、Pensilvania(Penn) stationまで行くほうが行き先表示に出ているので分かりやすかった。 改札はなくて切符は車内で確認される。
案内の人に聞いて電車に乗ったんだけど、切符の確認の際にこの電車ではないと言われる。 乗り間違えると、引き返すためにホームで割と長く待つことになる。5月も半ばなのに白い息が出るぐらい寒い。 Googleで調べようにも、駅にあるWifiはどうも契約していないと使えなさそうなものしかなかった。 地下鉄にはfree wifiが通っていたが、それも全ての駅で使えるというわけではなさそうだった。
Woodsideからは地下鉄に乗るのだけれど、この券売機がなぜかクレジットカードのPINをうけつけてくれずチケットを買えなかった。 カードが止まったかと思い、しょうがないので6kmほど歩いてマンハッタンまで向かうことにした。雨が降っていて、寒くて泣きたくなった。 空港でマップのデータを読んでいたのでGPSと合わせればオフラインでも自分の位置はわかるのが唯一の救いだ。 電話もなかったので、道中あったスタバなどのfree wifiを外から使わせてもらって、 家族に連絡をとって日本からクレジットカード会社に問い合わせてもらったが、 本人からの連絡じゃないとだめとのことでどうしようもなかった。
マンハッタンに行くためにはイースト川を越える必要があったので、 地図上で橋になっているところを順番に見てまわったが、車や電車でないとだめなところばかりで暗雲がただこめる。 あとから調べたら、マンハッタンの南側、ブルックリンとマンハッタン橋は歩いて渡れたらしい。 あの向こうがマンハッタンなのになと沿岸を眺めながら、この時点で夜中の0時を回っていて、野宿の可能性を考え始める。
途方に暮れて彷徨っていたところ、歩いていたおじさんとたまたま目が合って、 お金がなくて電車には乗れないんだけど、徒歩でマンハッタンに渡る方法はあるか聞いたら、 なんと地下鉄の駅まで案内してくれて運賃を出してくれた。 お礼するために連絡先を聞こうとしたのにすぐいなくなってしまわれた。命の恩人だ。</description>
    </item>
    
    <item>
      <title>io17で発表されたFirebaseのphone number authをwebで試してみた</title>
      <link>https://www.sambaiz.net/article/102/</link>
      <pubDate>Wed, 17 May 2017 23:34:00 -0700</pubDate>
      
      <guid>https://www.sambaiz.net/article/102/</guid>
      <description>今日のdeveloper keynoteで発表されたphone number authを試してみた。 Firebaseだと他にはPerformance Monitoringも発表されている。 あとSDKをオープンソースにするとか。
firebase-toolsを最新版にする。
# npm install -g firebase-tools $ firebase -V 3.9.0 FirebaseUIを使う場合、これも最新版にしないと出てこない。
&amp;lt;script src=&amp;quot;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;link type=&amp;quot;text/css&amp;quot; rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.css&amp;quot; /&amp;gt; firebase.auth.PhoneAuthProvider.PROVIDER_IDがphone number authの オプション。
const uiConfig = { signInOptions: [ firebase.auth.PhoneAuthProvider.PROVIDER_ID ], ... } const ui = new firebaseui.auth.AuthUI(firebase.auth()); ui.start(&#39;#firebaseui-auth-container&#39;, uiConfig); こんなボタンを押すと
電話番号とCAPTCHAが入り、
SMSに書かれた番号を入力すると認証される。
二段階認証のようなものだと思っていたけど、そうではないみたい。</description>
    </item>
    
    <item>
      <title>UWPでBLEデバイスとペアリングして値を取得する</title>
      <link>https://www.sambaiz.net/article/101/</link>
      <pubDate>Sat, 13 May 2017 10:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/101/</guid>
      <description>ManifestからBluetoothを許可しておく。
BLEデバイスを見つける CreateWatcherにBluetooth LEプロトコルのAEP(Association EndPoint)サービスクラスIDと requestPropaertiesで必要なデバイス情報を渡している。 最後のAssociationEndpointはSystem.Devices.Aep.ProtocolIdのAepと対応している。
using Windows.Devices.Enumeration; string[] requestedProperties = { &amp;quot;System.Devices.Aep.DeviceAddress&amp;quot;, &amp;quot;System.Devices.Aep.IsConnected&amp;quot; }; deviceWatcher = DeviceInformation.CreateWatcher( &amp;quot;(System.Devices.Aep.ProtocolId:=\&amp;quot;{bb7bb05e-5972-42b5-94fc-76eaa7084d49}\&amp;quot;)&amp;quot;, requestedProperties, DeviceInformationKind.AssociationEndpoint); deviceWatcher.Start(); deviceWatcher.Added += DeviceWatcher_Added; deviceWatcher.Removed += DeviceWatcher_Removed; deviceWatcher.Updated += DeviceWatcher_Updated; /* deviceWatcher.EnumerationCompleted += DeviceWatcher_EnumerationCompleted; deviceWatcher.Stopped += DeviceWatcher_Stopped; */ Dictionary&amp;lt;string, DeviceInformation&amp;gt; deviceInfos = new Dictionary&amp;lt;string, DeviceInformation&amp;gt;(); private void DeviceWatcher_Added(DeviceWatcher sender, DeviceInformation deviceInfo) { if (sender == deviceWatcher) { if (deviceInfo.Name != string.Empty) { deviceInfos.Add(deviceInfo.Id, deviceInfo); } } } private void DeviceWatcher_Updated(DeviceWatcher sender, DeviceInformationUpdate deviceInfoUpdate) { if (sender == deviceWatcher) { deviceInfos[deviceInfoUpdate.</description>
    </item>
    
    <item>
      <title>RxJSでObservableを結合する(merge, forkJoin, concat, combineLatest)</title>
      <link>https://www.sambaiz.net/article/100/</link>
      <pubDate>Tue, 09 May 2017 20:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/100/</guid>
      <description>RxJSでRxをはじめる - sambaiz.net
merge 2つのstreamの両方の値がemitされる。
Rx.Observable.merge( stream1, stream2 ).subscribe( data =&amp;gt; console.log(`merge ${data}`), err =&amp;gt; console.log(`merge ${err}`) ); forkJoin completeしたときの最後の値を配列としてemitする。 非同期で一つ値をemitするようなstreamで、Promise.allのようなことをしたいときはこれ。
Rx.Observable.forkJoin( stream1, stream2 ).subscribe( data =&amp;gt; console.log(` forkJoin: ${data}`), err =&amp;gt; console.log(` forkJoin: ${err}`) ) concat 前のstreamがcompleteしたら次のstreamの値がemitされる。
Rx.Observable.concat( stream1, stream2 ).subscribe( data =&amp;gt; console.log(` concat ${data}`), err =&amp;gt; console.log(` concat ${err}`) ); combineLatest stream自体を結合するのではなく値を結合する。 この例だと、stream1でemitされた値がa、stream2で最後にemitされた値がbのときa+bをemitする。 combineする値がない場合はemitされない。
stream1.combineLatest(stream2, (a, b) =&amp;gt; a + b).subscribe( data =&amp;gt; console.log(` combineLatest ${data}`), err =&amp;gt; console.</description>
    </item>
    
    <item>
      <title>angular/material2でフォームを作る</title>
      <link>https://www.sambaiz.net/article/99/</link>
      <pubDate>Sat, 06 May 2017 22:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/99/</guid>
      <description>コード
angular/material2の準備 現時点で DatePickerや Tableなど 開発中のコンポーネントが多いため足りないものを他のライブラリで補うなどする必要がある。 DatePickerはもう少しで出そう。
$ npm install --save @angular/material $ npm install --save hammerjs # gesture用 $ npm install --save @angular/animations Moduleでimport &#39;hammerjs&#39;;して、以下のModuleをimportに加える。
 BrowserAnimationsModule(from &#39;@angular/platform-browser/animations&#39;) MdButtonModuleなど使うもの(from &#39;@angular/material&#39;)  スタイルとアイコン(md-icon)を追加。
&amp;lt;link href=&amp;quot;../node_modules/@angular/material/prebuilt-themes/indigo-pink.css&amp;quot; rel=&amp;quot;stylesheet&amp;quot;&amp;gt; &amp;lt;link href=&amp;quot;https://fonts.googleapis.com/icon?family=Material+Icons&amp;quot; rel=&amp;quot;stylesheet&amp;quot;&amp;gt; フォームを作る とりあえずコンポーネントを作成。
$ ng g component TodoForm Formの値をバインドするためのクラスを作成する。
export class TodoForm { constructor( public id: number, public title: string, public active: boolean, public priority?: number, ) { } } まずはmaterial2のmdInput, mdSelect, mdButtonでフォームを作る。 #todoFormのように頭についている#は reference variableで、 titleはrequiredとしている。</description>
    </item>
    
    <item>
      <title>CSSのdisplayとposition</title>
      <link>https://www.sambaiz.net/article/98/</link>
      <pubDate>Sat, 06 May 2017 14:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/98/</guid>
      <description>display レンダリングに使うボックスを指定する。
outer display type pのようなブロックレベル要素やspanのようなインラインレベル要素に関わらず、指定したボックスにレンダリングする。
&amp;lt;style&amp;gt; .bg { background-color: #22ee22; width: 150px; height: 50px; } &amp;lt;/style&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:none&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;none&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;p style=&amp;quot;display:inline&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline&amp;lt;/p&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt; 中央寄せ 中央寄せはblockにwidthを設定してmargin autoするか、 親要素でtext-align: centerしてinline(-block)にする。
&amp;lt;style&amp;gt; .bg { background-color: #22ee22; height: 80px; } &amp;lt;/style&amp;gt; &amp;lt;div style=&amp;quot;margin: 5 auto&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block margin&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;quot;margin: 5 auto; width: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block margin width&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;quot;margin: 5 auto; display: inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block margin&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;quot;text-align: center&amp;quot;&amp;gt; &amp;lt;div style=&amp;quot;display: inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block align-center&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;quot;width: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block align-center width&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; flex displayでflexを指定するとflex containerになる。 flex-flowは 表示する方向のflex-directionと 折り返しのflex-wrapのショートハンドプロパティ。</description>
    </item>
    
    <item>
      <title>AngularのRouter</title>
      <link>https://www.sambaiz.net/article/97/</link>
      <pubDate>Sun, 30 Apr 2017 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/97/</guid>
      <description>@angular/core&amp;quot;: 4.1.0 Angular2とangular-cliでTODOを作る - sambaiz.net
angular-cliは@angular/cliに変更された。
routingを行うのでnewで--routingオプションを付けている。
$ npm install -g @angular/cli $ ng -v @angular/cli: 1.0.1 $ ng new angular4-routing --routing $ cd angular4-routing/ $ cat package.json | grep @angular/core &amp;quot;@angular/core&amp;quot;: &amp;quot;^4.0.0&amp;quot;, $ ng serve ** NG Live Development Server is running on http://localhost:4200 ** --routingを付けたのでapp-routing.module.tsが作成され、app.module.tsにAppRoutingModuleが追加される。 index.htmlのheadにはpushStateのroutingが働くように base要素が 追加されている。
import { NgModule } from &#39;@angular/core&#39;; import { Routes, RouterModule } from &#39;@angular/router&#39;; const routes: Routes = [ { path: &#39;&#39;, children: [] } ]; @NgModule({ imports: [RouterModule.</description>
    </item>
    
    <item>
      <title>Node.jsのStream API</title>
      <link>https://www.sambaiz.net/article/96/</link>
      <pubDate>Sat, 22 Apr 2017 19:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/96/</guid>
      <description>Stream APIとは NodeでStreamデータを扱うためのもの。 例えばサイズが大きいファイルの入出力をStreamとして扱うことでバッファを最小限にできる。
StreamはEventEmitterで、 Readable streamやWritable stream、ReadableとWritableを合わせたDuplex streamと Readしたものを加工してWriteするTransform streamの種類があり、 それぞれ特定の関数が実装されている必要がある。
Readable stream Readable streamにはflowingとpausedの 二つのモードがある。 最初はpausedモードで、readableになってからread()することで読むことができる。
const fs = require(&#39;fs&#39;); let readable = fs.createReadStream(&#39;sample.txt&#39;); var i = 0; readable.on(&#39;readable&#39;, () =&amp;gt; { let chunk; while (null !== (chunk = readable.read(10))) { console.log(`${i++}: ${chunk}`); } }); dable.on(&#39;end&#39;, () =&amp;gt; { console.log(&#39;end&#39;); }); $ cat sample.txt abcdefghijklmnopqrstuvwxyz 1234567890 あいうえお $ node main.js 0: abcdefghij 1: klmnopqrst 2: uvwxyz 123 3: 4567890 あい 4: うえお end dataのイベントハンドラーを追加するか、後で書くpipeを使うとflowingモードになる。</description>
    </item>
    
    <item>
      <title>tmuxのメモ</title>
      <link>https://www.sambaiz.net/article/95/</link>
      <pubDate>Fri, 21 Apr 2017 00:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/95/</guid>
      <description>https://tmux.github.io/
セッションを立ち上げてその中で複数のウィンドウやペインからコマンドを実行できるやつ。 サーバーでの作業中にネットワークが切断されてしまってもセッションをattachすることで再開することができる。 ローカル環境でもコマンドキーでのウィンドウ作成やペインの分割、 複数のサーバーにsshで入って調査するようなときにペインの同時入力は便利。 もちろんターミナルを閉じてしまっても再開できる。
$ brew install tmux $ tmux $ tmux ls $ tmux a # sessionをattachする bind key(デフォルトでCtrl + b)を入れてからコマンドキーを入れる。よく使うもの。
 c: 新しいウインドウをCreateする d: 今のクライアントをDetachする n: Nextウィンドウに移動する p: Previousウィンドウに戻る w: Windowを一覧表示して選択する x: ペインを削除する ,: ウィンドウの名前を変更する z: ウィンドウ一杯にペインをzoomする/解除 [: ペイン内をスクロールできるようになる。qで解除  ~/.tmux.confはこんな感じにしている。
# bind keyをC-tに変更してC-bを解除 set -g prefix C-t unbind C-b # Vimのキーバインドでペインを移動する bind h select-pane -L bind j select-pane -D bind k select-pane -U bind l select-pane -R # - でペインを横に分割する(縦に切る) bind - split-window -h # | でペインを縦に分割する(横に切る) bind | split-window -v # 同時入力 bind s set-window-option synchronize-panes on bind S set-window-option synchronize-panes off </description>
    </item>
    
    <item>
      <title>Firebaseをwebで使う(Hosting, Authentication, Realtime Database, Storage)</title>
      <link>https://www.sambaiz.net/article/94/</link>
      <pubDate>Sun, 16 Apr 2017 20:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/94/</guid>
      <description>Firebaseとは GoogleのmBaaS。Android/iOSアプリの開発に使う認証、データストア、クラッシュレポート、分析、通知、広告などなど全部入りサービス。 今年のGoogleI/Oでも毎時間のように Firebaseのセッションがあって大分推している印象。
基本的にはアプリで使うのだけれど、webで使える機能も結構ある。今回は
 Hosting Authentication Realtime Database Storage  を使ってみる。
料金 プランは無料のSPARKと25ドル/月のFLAME、従量課金のBLAZEがある。 試す分にはSPARKで十分だけど、Realtime Databaseの同時接続数が100なので注意。
セットアップ firebase-cliをインストール、ログインして初期化する。
$ npm install -g firebase-tools $ firebase login $ mkdir firebase-chat &amp;amp;&amp;amp; cd firebase-chat $ firebase init ... ? What Firebase CLI features do you want to setup for this folder? ❯◉ Database: Deploy Firebase Realtime Database Rules ◉ Functions: Configure and deploy Cloud Functions ◉ Hosting: Configure and deploy Firebase Hosting sites ?</description>
    </item>
    
    <item>
      <title>MySQLのALTER TABLEのメモ</title>
      <link>https://www.sambaiz.net/article/93/</link>
      <pubDate>Sat, 15 Apr 2017 19:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/93/</guid>
      <description>しばらく書かないとどういう構文だったか忘れてしまう。
MySQL :: MySQL 5.6 リファレンスマニュアル :: 13.1.7 ALTER TABLE 構文
CREATE TABLE t0 ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, c1 VARCHAR(30), c2 VARCHAR(30) ); CREATE TABLE t2 ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY ); ALTER TABLE t0 RENAME t1; ALTER TABLE t1 ADD COLUMN t2_id BIGINT UNSIGNED AFTER id, ADD COLUMN c3 INTEGER NOT NULL AFTER t2_id, MODIFY COLUMN c1 VARCHAR(30) NOT NULL, DROP COLUMN c2, ADD INDEX (c3), ADD FOREIGN KEY (t2_id) REFERENCES t2(id) ON UPDATE RESTRICT ON DELETE RESTRICT ; mysql&amp;gt; SHOW CREATE TABLE t1 \G; *************************** 1.</description>
    </item>
    
    <item>
      <title>Unityのパーティクル設定(Shuriken)</title>
      <link>https://www.sambaiz.net/article/92/</link>
      <pubDate>Thu, 13 Apr 2017 17:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/92/</guid>
      <description>UnityにはShurikenというパーティクルシステムがある。
Sphereを置いてParticle Systemを追加すると、Particleが出始める。
モジュール 設定項目が多いためモジュールに分かれている。ひとまずデフォルトで有効になっている
 (メインモジュール) Emission Shape Renderer  について見ていく。
メインモジュール  Duration: 5 Looping: true  デフォルトだとLoopingにチェックが入っているのでずっと出ているが、チェックを外すとDurationで止まる。
 Start Delay: 0 Play On Awake: true  PlayOnAwakeがtrueでStartDelayが0なので実行してからすぐにParticleが出始める。
 Start Lifetime: 5 Max Particles: 1000  StartLifetimeはParticleが消えるまでの時間。ただしMaxParticlesに達したら消される。
 Start Speed: 5 Simulation Speed: 1  StartSpeedはParticleの初速で、上げると勢い良く飛んでいく。 SimulationSpeedを上げるとParticleが出るのも含めて全体のスピードが上がる。
 Start Size: 1  Particleの初期サイズ。小さくすると塵みたいになる。
 Start Rotation: 0  Particleの初期角度。
 Gravity Modifier: 0  重力値。0だと無重力。
 Simulation Space: Local  Particleをlocal座標かworld座標で動かすか。 Localだとオブジェクトが移動したときに一緒に移動する。Worldだと置いてかれる。</description>
    </item>
    
    <item>
      <title>godocのメモ</title>
      <link>https://www.sambaiz.net/article/91/</link>
      <pubDate>Wed, 05 Apr 2017 22:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/91/</guid>
      <description>https://godoc.org/golang.org/x/tools/cmd/godoc
コメントからドキュメントを生成する。
$ godoc cmd/fmt Printf func Printf(format string, a ...interface{}) (n int, err error) Printf formats according to a format specifier and writes to standard output. It returns the number of bytes written and any write error encountered. $ godoc -src cmd/fmt Printf // Printf formats according to a format specifier and writes to standard output. // It returns the number of bytes written and any write error encountered. func Printf(format string, a .</description>
    </item>
    
    <item>
      <title>Nightmareでブラウザでの操作を自動化する</title>
      <link>https://www.sambaiz.net/article/90/</link>
      <pubDate>Wed, 29 Mar 2017 23:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/90/</guid>
      <description>最近、POSTWASHという洗濯代行サービスを使っている。 専用のカバンに詰めて集荷にきた人に渡すと、きれいに畳まれた洗濯ものが届く便利なサービスだ。 注文時にはWebのフォームから集荷、配達時間や支払い方法などを選ぶ必要があるんだけど、毎週のことなのでこれを自動化してみる。
ブラウザの操作を自動化するのにNightmareを使う。 Electronを使っていて、PahntomJSより2倍くらい速く、簡潔に書ける。
$ npm install nightmare Nightmare()の引数にshow: trueを渡すとウィンドウが開いて実行し始める。 これで確認画面までいくのであとは注文ボタンを押すだけ。 ウィンドウが閉じないように最後にnightmare.end()を呼んでいない。
const co = require(&#39;co&#39;); const moment = require(&#39;moment&#39;) const jst = +9 const Nightmare = require(&#39;nightmare&#39;);	const nightmare = Nightmare({ show: true, waitTimeout: 3000, gotoTimeout: 3000 }); const loginID = process.env.LOGIN_ID; const loginPassword = process.env.LOGIN_PASSWORD; moment.locale(&#39;ja&#39;); const now = moment().utcOffset(jst) const dayAfterTomorrow = now.add(2, &#39;days&#39;).format(&amp;quot;YYYY年M月D日(ddd)&amp;quot;); const nextWeek = now.add(7, &#39;days&#39;).format(&amp;quot;YYYY年M月D日(ddd)&amp;quot;) console.log(`${dayAfterTomorrow}~${nextWeek}`); // IDとパスワードを入れてログイン const login = () =&amp;gt; nightmare .</description>
    </item>
    
    <item>
      <title>Node.jsでの文字コードの変換</title>
      <link>https://www.sambaiz.net/article/89/</link>
      <pubDate>Tue, 28 Mar 2017 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/89/</guid>
      <description>node-iconvを使う。
$ npm install iconv SHIFT_JISからUTF-8への変換はこんな感じ。
const Iconv = require(&#39;iconv&#39;).Iconv; const before = new Buffer([ 0x8b, 0x8d, 0x8e, 0x4d, 0x26, 0x82, 0xb2, 0x94, 0xd1 ]); const iconv = new Iconv(&#39;SHIFT_JIS&#39;, &#39;UTF-8&#39;); console.log(`before: ${before.toString(&#39;hex&#39;)} ${before.toString()}`) const after = iconv.convert(before); console.log(`after: ${after.toString(&#39;hex&#39;)} ${after.toString()}`); before: 8b8d8e4d2682b294d1 ���M&amp;amp;���� after: e7899be79abf26e38194e9a3af 牛皿&amp;amp;ご飯 文字コードによっては変換後に表せないことがある。 例えば、UTF-8からSHIFT_JISへの変換でサロゲートペア🍚を渡すと変換できず、エラーになる。
throw errnoException(&#39;EILSEQ&#39;, &#39;Illegal character sequence.&#39;); //IGNOREを付けることで そのような文字があった場合でもエラーにしないようにできる。
const Iconv = require(&#39;iconv&#39;).Iconv; const before = &amp;quot;牛皿&amp;amp;🍚&amp;quot;; const iconv = new Iconv(&#39;UTF-8&#39;, &#39;SHIFT_JIS//IGNORE&#39;); console.</description>
    </item>
    
    <item>
      <title>HoloLensのSharing</title>
      <link>https://www.sambaiz.net/article/88/</link>
      <pubDate>Sat, 25 Mar 2017 22:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/88/</guid>
      <description>HoloToolkit-Unity v1.5.5.0  サーバー SharingService.exeを ここ からとってきて実行する。開発に使っているHoloToolkitと同じリリースバージョンのものを使う。
&amp;gt; SharingService.exe -local ... SharingService: Listening for session list connections on port 20602 of all network devices of the local machine. SharingService: Local IP addresses are: SharingService: xxx.xxx.xxx.xxx SharingService: Created Session &amp;quot;Default&amp;quot; with ID 0 on port 20601 今日のTokyo Hololens Meetup Vol.2の開発者セッションで、 ちょうどSharingの話があったのだけれど、残念ながら先着順で出遅れて聞けなかった。
Tweetを見る限りだとカスタマイズできず、スケーリングできないSharingService.exeは使わずに MagicOnionというのを自前で作ったらしい。
Tokyo Hololens MeetuUp Vol.2 Session5 #HoloLensJP #TMCN - Togetterまとめ
クライアント Assets/HoloToolkit/Sharing/TestsのSceneで試してみる。
以下のcapabilitiesを設定し、
 SpatialPerception InternetClient  SharingのServer Addressを設定してビルド。ほかにはこんな設定がある。</description>
    </item>
    
    <item>
      <title>Unixのパイプをmkfifo()で作ってdup2()で標準出力にコピーして書き込む</title>
      <link>https://www.sambaiz.net/article/87/</link>
      <pubDate>Fri, 24 Mar 2017 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/87/</guid>
      <description>パイプとは Unixでプロセス間通信するためのもの。シェルで使う|は無名パイプ。 mkfifo()システムコールで名前付きパイプを作成でき、これを読み書きすることで任意のプロセス間でやりとりできる。
$ mkfifo hoge $ ls -lh $ prw-r--r-- ... 0B ... hoge 通常のファイルと同様に読み書きすることができ、読み書きどちらかを行おうとすると待つことになる。
$ echo hoge &amp;amp; # 読まれるまで待つ $ cat hoge aaaaa [1]+ Done echo &amp;quot;aaaaa&amp;quot; &amp;gt; hoge $ cat hoge &amp;amp; # 書かれるまで待つ $ echo &amp;quot;bbbbb&amp;quot; &amp;gt; hoge bbbbb [1]+ Done cat hoge ファイルディスクリプタをコピーするシステムコールdup2()でopenしたパイプを標準出力(1)にコピーしてみる。
#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;fcntl.h&amp;gt; int main(){ int fd = open(&amp;quot;./hoge&amp;quot;, O_WRONLY); if(fd &amp;lt; 0){ printf(&amp;quot;fail to open\n&amp;quot;); return 1; } printf(&amp;quot;OPEN %d \n&amp;quot;, fd); if(dup2(fd, 1) &amp;lt; 0){ printf(&amp;quot;fail to dup2\n&amp;quot;); return 2; } printf(&amp;quot;WRITE\n&amp;quot;); // これがどこに書き込まれるか close(fd); } 最後のprintfの内容は標準出力ではなく、パイプに書き込まれていることがわかる。</description>
    </item>
    
    <item>
      <title>CuratorでElasticsearchの古いindexを削除する</title>
      <link>https://www.sambaiz.net/article/86/</link>
      <pubDate>Wed, 22 Mar 2017 00:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/86/</guid>
      <description>Curatorとは indexやsnapshotを管理するのに使えるツール。
インストール インストールする。
$ cat /etc/yum.repos.d/curator.repo [curator-4] name=CentOS/RHEL 7 repository for Elasticsearch Curator 4.x packages baseurl=http://packages.elastic.co/curator/4/centos/7 gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 $ yum install -y elasticsearch-curator $ curator --version curator, version 4.2.6 config configファイルを書く。
client: hosts: - 127.0.0.1 port: 9200 logging: loglevel: INFO logfile: logformat: default blacklist: [&#39;elasticsearch&#39;, &#39;urllib3&#39;] action 今回はindexを削除するのでdelete_indices。 対象はfilterで指定する。 logstash formatだとhogehoge-2017.01.01のようなindex名になるので%Y.%m.%d。okder than 3 daysのものを削除する。
actions: 1: action: delete_indices description: &amp;gt;- 3日前より古いhogehoge-* indexを消す filters: - filtertype: pattern kind: prefix value: hogehoge- - filtertype: age source: name direction: older timestring: &#39;%Y.</description>
    </item>
    
    <item>
      <title>RxJSでRxをはじめる</title>
      <link>https://www.sambaiz.net/article/85/</link>
      <pubDate>Sat, 18 Mar 2017 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/85/</guid>
      <description>https://github.com/ReactiveX/rxjs
Rx(ReactiveX)とは 非同期処理をうまく扱えるようにするライブラリ。いろんな言語で実装されている。 非同期処理の結果はObservableなStreamに流される。 ObservableはIteratableのように扱うことができる。
RxはObserver pattern を拡張したもの。 Observer patternというのは、Subjectが、Observeしている全てのObserverに対して通知を送るデザインパターン。 C#などのeventのそれ。
C#のdelegateとevent - sambaiz.net
試してみる inputのkeyupイベントのObservableを作成し、それをsubscribe()して出力している。
&amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;script src=&amp;quot;https://cdnjs.cloudflare.com/ajax/libs/rxjs/5.0.1/Rx.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;input&amp;quot; /&amp;gt; &amp;lt;script&amp;gt; const inputForm = document.querySelector(&#39;#input&#39;); const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;); keyups.subscribe( data =&amp;gt; console.log(data), err =&amp;gt; console.log(err) ); &amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 入力するとこんなのが出力される。
KeyboardEvent {isTrusted: true, key: &amp;quot;a&amp;quot;, code: &amp;quot;KeyA&amp;quot;, location: 0, ctrlKey: false…} KeyboardEvent {isTrusted: true, key: &amp;quot;b&amp;quot;, code: &amp;quot;KeyB&amp;quot;, location: 0, ctrlKey: false…} KeyboardEvent {isTrusted: true, key: &amp;quot;c&amp;quot;, code: &amp;quot;KeyC&amp;quot;, location: 0, ctrlKey: false…} Observable create next()でObservableに値をemitし、complete()で終了させる。 error()でエラーをemitするとそれ以後の値はemitされない。</description>
    </item>
    
    <item>
      <title>FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ</title>
      <link>https://www.sambaiz.net/article/84/</link>
      <pubDate>Wed, 15 Mar 2017 23:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/84/</guid>
      <description>KPL(Kinesis Producer Library)とは Developing Amazon Kinesis Streams Producers Using the Amazon Kinesis Producer Library - Amazon Kinesis Streams
Kinesisに送るとき、自動リトライしてくれたり、レコードをまとめてスループットを向上してくれたりするアプリケーション。Protobufを使っている。 普通に送るとどんなに小さくてもシャード*1000レコード/秒しか最大でPUTできないのを、KPLを使ってまとめることで増やすことができる。
fluentdで送る aws-fluent-plugin-kinesisでkinesis_producerを指定するとKPLを使って送信する。
&amp;lt;kinesis_producer&amp;gt;の中にKPLの設定を書くことができる。
&amp;lt;kinesis_producer&amp;gt; record_max_buffered_time 10 &amp;lt;/kinesis_producer&amp;gt; record_max_bufferd_time はバッファされたレコードが送られるまでの最大時間(ms)。デフォルトは100ms。この時間が経つか、他のリミットに当たったらレコードは送られる。
 AggregationMaxCount: 一つのレコードにまとめる最大レコード数 AggregationMaxSize: まとめたレコードの最大バイト数 CollectionMaxCount: PutRecordsで送る最大アイテム数 CollectionMaxSize: PutRecordsで送るデータ量  CloudWatchに送るmetrics_levelはデフォルトでdetailedになっていて、 コンソールのメトリクスからstream名で検索すると KinesisProducerLibraryにUserRecordsPerKinesisRecordや、UserRecordsDataPut、BufferingTime、RequestTimeなどいろいろ表示される。
とりあえず試しにこんな設定で送ってみる。
&amp;lt;match hoge.log&amp;gt; @type kinesis_producer region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt; Lambdaで読む まとめられたレコードをkinesis-aggregationで分解して読む。 今回はNode.jsでやる。
$ npm install --save aws-kinesis-agg 注意する必要があるのはドキュメントの情報が古くて、 関数の引数が足りないこと。第二引数のcomputeChecksumsが抜けているので気付かないと一つずつずれていくことになる。</description>
    </item>
    
    <item>
      <title>C#のdelegateとevent</title>
      <link>https://www.sambaiz.net/article/83/</link>
      <pubDate>Sun, 12 Mar 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/83/</guid>
      <description>delegate カプセル化するためのdelegate(移譲)メソッドに使う型。
public class Converter{ private static double defaultConvert(double num){ return num; } public delegate double Convert(double num); public Convert convert = defaultConvert; public double run(double num){ return convert (num); } } 匿名メソッドやラムダ式を渡すこともできる。
var conv = new Converter (); print (conv.run (2)); // 2 // 匿名メソッドの例 conv.convert = delegate(double input) { return input + 1; }; print (conv.run (2)); // 2 + 1 = 3 // ラムダ式の例 conv.convert = s =&amp;gt; s * s; print (conv.</description>
    </item>
    
    <item>
      <title>UnityのMaterial</title>
      <link>https://www.sambaiz.net/article/82/</link>
      <pubDate>Sat, 11 Mar 2017 20:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/82/</guid>
      <description>MaterialとShaderとTexture Materialは表面がどのようにレダリングされるかを定義するもの。 Shaderを指定し、Textureなどのパラメーターを設定する。
Shaderは光と、Materialの設定から、ピクセルの色を計算するスクリプト。 大体Standard Shader で事足りるらしい。
Textureはビットマップイメージ。色(Albedo)だけではなく、反射率や粗さなど、いろんな要素に使える。
Standard Shader Rendering Mode Albedoは(255, 255, 255, 255)で、テクスチャにはDefault Particleを指定している。 透明度はテクスチャのアルファチャンネルとAlbedoのアルファ値に基づく。
 Opaque: デフォルト。すべて不透明。   CutOut: 閾値を境に、完全に透明か、不透明になる。  Alpha Cutoffを0.1にした。
 Transparent: 透明度が適用される。現実世界の透明なマテリアルのように、反射のハイライトは完全に表示される。   Fade: ハイライトにも透明度を適用する。フェードイン/アウトしたいときに使う。  Metallic マテリアルチャートをもとにAlbedoとMetallicとSmoothnessを設定する。
これは
 Albedo: (255, 255, 255, 255) Metallic: 1 Smoothness: 0.68  を設定している。</description>
    </item>
    
    <item>
      <title>UnityのUI</title>
      <link>https://www.sambaiz.net/article/81/</link>
      <pubDate>Wed, 08 Mar 2017 16:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/81/</guid>
      <description>Canvas UI要素を配置するための領域。
renderMode   Overlay: スクリーンに対してオーバーレイするように表示
  Camera: Cameraから指定した距離(planeDistance)離れた前方に表示
  World Space 他のオブジェクトと同じように表示
  Canvas Scaler   UI Scale Mode (World Space以外)
  Constant Pixel Size: 画面サイズに関わらず同じピクセル数にする
  Scale With Screen Size: 画面サイズでスケールさせる
  Constant Physical Size 解像度や画面サイズによらず物理的に同じサイズにする
    Dynami Pixels Per Unit (World Spaceのみ): Textなどの動的に生成されたビットマップの解像度
  1と3でそれぞれこんな感じになる。
AutoLayout Vertical Layout Groupや Grid Layout Group など。これらのComponentを追加すると子要素のTransform(の一部)が自動で設定される。
Content Size Fitter Layout Component要素に合うように自動で調整される。</description>
    </item>
    
    <item>
      <title>UnityのTransform</title>
      <link>https://www.sambaiz.net/article/80/</link>
      <pubDate>Tue, 07 Mar 2017 02:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/80/</guid>
      <description>https://docs.unity3d.com/jp/current/ScriptReference/Transform.html
オブジェクトの位置、スケール、回転を保持する。親子関係を持つ。
Position positionがワールド空間の、 localPosition が親から見た相対的なローカル空間の位置。localPositionの1unitはscaleに依存する。
transform.position = new Vector3(0, 0, 0); transform.localPosition = new Vector3(0, 0, 0); 徐々に移動するにはTranslate()を使う。 最後の引数はデフォルトでSpace.Selfになっていて、Space.Worldを指定するとワールド座標を基準にする。
Time.deltaTimeは最後のフレームを完了するのにかかった秒数。 なのでフレームレートにかかわらず同じ速度で移動させることができる。
transform.Translate(0, Time.deltaTime, 0, Space.World); transform.Translate(Vector3.up * Time.deltaTime, Space.World); // 軸に沿って移動 transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform); // 最後の引数のローカル座標を基準にする transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform); Scale localScale はローカル空間のスケール。ワールド空間のScaleはない。
transform.localScale = new Vector3(0.1f, 1f, 1f); Rotation ワールド空間の rotationと ローカル空間の localRoation。
UnityはQuarternion(四元数)で回転を持っている。 実際はQuarternionそのものを自分で計算することはなく、 Quaternion.LookRotation()や Quaternion.Euler()などを使う。
Vector3 relativePos; transform.rotation = Quaternion.LookRotation(relativePos); // そのPointを向くように回転 transform.localRotation = Quaternion.Euler(0, 30, 0); Transformを向くように回転する場合は LookAt()を使う。</description>
    </item>
    
    <item>
      <title>Moment.jsでNode.jsのDateを任意のフォーマットの文字列にする</title>
      <link>https://www.sambaiz.net/article/79/</link>
      <pubDate>Mon, 06 Mar 2017 20:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/79/</guid>
      <description>Moment.js
相対時間(5 years ago)を出したり、日付の計算(add(3, &#39;days&#39;))もできる便利なライブラリ。 ブラウザでも使える。
$ npm install moment const moment = require(&#39;moment&#39;) const jst = +9 let now = moment().utcOffset(jst).format(&amp;quot;YYYY-MM-DD HH:mm:ss.SSSZ&amp;quot;); console.log(now); $ TZ=Africa/Ouagadougou node main.js mutableなのでadd()などの操作で元の値が変わってしまうのに注意。 変わると困る場合clone()する必要がある。
let now2 = moment(); let now3 = now2.clone(); console.log(now2); console.log(now2.add(1, &#39;days&#39;)); console.log(now2); console.log(now3); </description>
    </item>
    
    <item>
      <title>Unityと.NETとMono</title>
      <link>https://www.sambaiz.net/article/78/</link>
      <pubDate>Sun, 05 Mar 2017 18:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/78/</guid>
      <description>.NETとかよくわからなかったのでまとめてみた。
.NET Framework .NET Framework - Wikipedia
Microsoftが開発したアプリケーション開発、実行環境。
各言語のコンパイラによって言語、環境によらない共通の中間言語(CIL, Common Intermediate Language)バイナリ(exeやdll)に変換し、 実行時に共通言語基盤(CLI, Common Language Infrastructure)の仮想実行システム(VES)が環境依存の機械語を動的に生成(JIT, Just in time)する。 CLIの仕様はECMAで標準化されていて、Microsoftが実装したCLIが共通言語ランタイム(CLR)。Windowsでしか動かない。
.NET Core .NET Core - .NET Core による .NET のクロスプラットフォームへの移行
Microsoft/dotnet
オープンソースで、クロスプラットフォームに対応した.NET。CoreCLRはWindowsだけではなくMacやLinuxでも動く。 .NET Frameworkと共通のAPIもあるが、GUIまわりでどちらかにしかないAPIが存在する。
Mono オープンソースで、クロスプラットフォームな.NET Framework互換ソフトウェア。C#のコンパイラとCLIが実装されている。 Unityはこれを使っているが、バージョンが古くて使えないライブラリがある。
.NET CoreでHello World インストール手順に沿って dotnetコマンドを使えるようにする。
Hello Worldまで。
$ dotnet console -o hwapp $ cd hwapp $ ls Program.cs	hwapp.csproj $ dotnet restore $ ls Program.cs	hwapp.csproj	obj $ ls obj hwapp.csproj.nuget.g.props	project.assets.json hwapp.</description>
    </item>
    
    <item>
      <title>Elasticsearchで期間ごとの集計値を出す</title>
      <link>https://www.sambaiz.net/article/77/</link>
      <pubDate>Sun, 05 Mar 2017 01:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/77/</guid>
      <description>Bucket(SQLでいうGROUP BY)にまとめて(Bucket Aggreagtion)、集計(Metric Aggregation)する。
使うデータは作ったツールで生成したこんなの。
{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82} Bucket Aggregations Date Range Aggregation date_rangeで期間のBucketを作る。この例だと今から10分前の00秒~今の分の00秒まで。
$ curl localhost:9200/hoge/_search -d&#39; { &amp;quot;aggs&amp;quot;: { &amp;quot;range_10minutes&amp;quot;: { &amp;quot;date_range&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;HH-mm-ssZ&amp;quot;, &amp;quot;ranges&amp;quot;: [ { &amp;quot;to&amp;quot;: &amp;quot;now/m&amp;quot;, &amp;quot;from&amp;quot;: &amp;quot;now-10m/m&amp;quot; } ] } } } }&#39; | jq .aggregations { &amp;quot;range_10minutes&amp;quot;: { &amp;quot;buckets&amp;quot;: [ { &amp;quot;key&amp;quot;: &amp;quot;15-17+0000-15-27+0000&amp;quot;, &amp;quot;from&amp;quot;: 1488640620000, &amp;quot;from_as_string&amp;quot;: &amp;quot;15-17+0000&amp;quot;, &amp;quot;to&amp;quot;: 1488641220000, &amp;quot;to_as_string&amp;quot;: &amp;quot;15-27+0000&amp;quot;, &amp;quot;doc_count&amp;quot;: 600 } ] } } Date Histogram Aggregation date_histogramで日付の間隔でBucketを作る。この例だと1分ごとにBucketが作られる。
$ curl localhost:9200/hoge/_search -d&#39; { &amp;quot;aggs&amp;quot;: { &amp;quot;histogram_1minute&amp;quot;: { &amp;quot;date_histogram&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;, &amp;quot;interval&amp;quot;: &amp;quot;1m&amp;quot; } } } }&#39; | jq .</description>
    </item>
    
    <item>
      <title>一定間隔でjsonデータを作って送り続けるCLIツールを作った</title>
      <link>https://www.sambaiz.net/article/76/</link>
      <pubDate>Sat, 04 Mar 2017 23:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/76/</guid>
      <description>Elasticsearchにリアルタイムなテストデータを投入するために、一定間隔でjsonを作って送り続けるCLIツールを作った。Go製。 urfave/cliを使った。
sambaiz/sendjson
こんなindexにデータを入れてみる。
$ curl -XPUT &#39;http://localhost:9200/hoge&#39; -d&#39; { &amp;quot;mappings&amp;quot;: { &amp;quot;test_type&amp;quot;: { &amp;quot;_all&amp;quot;: { &amp;quot;enabled&amp;quot;: false }, &amp;quot;properties&amp;quot;: { &amp;quot;os_name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; }, &amp;quot;score&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;byte&amp;quot; }, &amp;quot;@timestamp&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;epoch_second&amp;quot; } } } } } &#39; こんな感じでキーに対してtypeと入る値を定義するとそれっぽいデータができて送られていく。
$ go install github.com/sambaiz/sendjson $ sendjson --interval 0.5s --duration 10s --url http://localhost:9200/hoge/test_type &#39; { &amp;quot;os_name&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;or&amp;quot;: [&amp;quot;windows&amp;quot;, &amp;quot;mac&amp;quot;, &amp;quot;linux&amp;quot;, &amp;quot;ios&amp;quot;, &amp;quot;android&amp;quot;]}, &amp;quot;score&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;, &amp;quot;min&amp;quot;: 0, &amp;quot;max&amp;quot;: 100}, &amp;quot;@timestamp&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;time&amp;quot;, &amp;quot;time_format&amp;quot;: &amp;quot;unix_epoch&amp;quot;} }&#39; {&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82} {&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:9} {&amp;quot;@timestamp&amp;quot;:1488635131,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:73} {&amp;quot;@timestamp&amp;quot;:1488635131,&amp;quot;os_name&amp;quot;:&amp;quot;ios&amp;quot;,&amp;quot;score&amp;quot;:50} {&amp;quot;@timestamp&amp;quot;:1488635132,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:69} .</description>
    </item>
    
    <item>
      <title>H2OでHTTPS-&gt;HTTPのリバースプロキシを立てる</title>
      <link>https://www.sambaiz.net/article/75/</link>
      <pubDate>Thu, 02 Mar 2017 20:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/75/</guid>
      <description>良くチューニングされたNginxと同じくらい速いと 評判のHTTP/2サーバーH2Oでリバースプロキシを立ててみる。 HTTP/2だけではなく1.xにも対応しているので古い環境などでも大丈夫。
設定は Reverse Proxyと HTTP to HTTPSの サンプルをもとにして書いた。
hosts: &amp;quot;*&amp;quot;: listen: port: 443 ssl: certificate-file: /etc/h2o/oreore.crt key-file: /etc/h2o/server.key paths: &amp;quot;/&amp;quot;: proxy.reverse.url: http://127.0.0.1:3000/ access-log: /dev/stdout error-log: /dev/stderr とりあえずオレオレ証明書で試してみる。
$ openssl genrsa 2048 &amp;gt; server.key # private key $ openssl req -new -key server.key &amp;gt; server.csr # certificate signing request $ openssl x509 -days 365000 -req -signkey server.key &amp;lt; server.csr &amp;gt; oreore.crt # oreore certificate Dockerで動かす。lkwg82/h2o.docker
$ vi h2o.conf $ docker run -v $(pwd):/etc/h2o --net=host --name h2o --restart=always -itd lkwg82/h2o-http2-server $ curl --insecure https://127.</description>
    </item>
    
    <item>
      <title>Goroutineの数をworkerで抑制する</title>
      <link>https://www.sambaiz.net/article/74/</link>
      <pubDate>Mon, 27 Feb 2017 23:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/74/</guid>
      <description>Goのnet/httpとKeep-Alive - sambaiz.netでやったように、 あるエンドポイントに連続してGoroutineでリクエストを投げると、リクエスト数を増やしたときにタイムアウトが頻発するようになった。
まず、2000リクエストを投げてみた結果。
[RESULT] request: 2000, ok: 2000, ng: 0, time(ms) 138 一応全部捌けてはいるけど、おおよそ同時にリクエストを送っているのにタイムアウト(100ms)時間を超えてしまっている。これをさらに3000に増やしてみる。
[RESULT] request: 3000, ok: 13, ng: 2987, time(ms) 372 ほぼ全滅してしまった・・・。時間もおかしいのでGoroutineでの処理に遅延が発生しているようだ。 そこで、都度Goroutineを生成してリクエストを投げるのではなく、 一定数のWorkerに処理させることで、同時に作られるGoroutineの数を抑制する。
type Req struct { Okch chan int Ngch chan int } func startWorker(ctx context.Context, num int) (requestch chan *Req) { requestch = make(chan *Req) for i := 0; i &amp;lt; num; i++ { go func() { for { select { case req := &amp;lt;-requestch: request(req.</description>
    </item>
    
    <item>
      <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
      <link>https://www.sambaiz.net/article/73/</link>
      <pubDate>Sun, 26 Feb 2017 18:56:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/73/</guid>
      <description>aws-fluent-plugin-kinesisでKinesis Streamsに送り、Lambdaで読んでS3に保存する。 要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。
fluentdで送る $ td-agent-gem install fluent-plugin-kinesis try_flush_intervalとqueued_chunk_flush_intervalはドキュメントには載っていないが、 以下のページによるとそれぞれqueueに次のchunkがないときとあるときのflushする間隔。 いずれもデフォルトは1だが、これを減らすことでもっと頻繁に吐き出されるようになるらしい。
Fluentd の out_forward と BufferedOutput
あとシャードに振り分けるためのpartition_key を指定できる。デフォルトはランダム。
&amp;lt;source&amp;gt; @type tail path /var/log/td-agent/hoge.log pos_file /etc/td-agent/log.pos tag hoge.log format json time_key timestamp # 2017-01-01T01:01:01+0900 time_format %Y-%m-%dT%H:%M:%S%z &amp;lt;/source&amp;gt; &amp;lt;match hoge.log&amp;gt; @type kinesis_streams region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt; いくつか送ってみる。
for i in `seq 1 1000` do echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;, &amp;quot;timestamp&amp;quot;: &amp;quot;2017-01-01T01:01:01+0900&amp;quot;}&#39; &amp;gt;&amp;gt; /var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>AWSのAssumeRole</title>
      <link>https://www.sambaiz.net/article/72/</link>
      <pubDate>Sat, 25 Feb 2017 20:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/72/</guid>
      <description>AWS Security Token Serviceによる、 RoleArn(arn:aws:iam::&amp;lt;account id&amp;gt;:role/&amp;lt;role name&amp;gt;)から一時的なCredentialを取得する仕組み。 前もって発行したAPIキーとは違い、有効期限が存在するため続けて呼ぶ場合は失効する前に再発行する必要がある。
ではRoleArnを知っていたら誰でも取得できるかというと、もちろんそうではなく、 ロールの信頼関係、&amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;のPrincipalのところで信頼する対象を設定する。 例えば、Serviceでec2.amazonaws.comを指定してEC2がAssumeRoleするのを許可したり、 AWSで(他の)アカウントやユーザーを指定してそのAPIキーでこのRoleのCredentialを取得できるようにしたりといった感じ。
{ &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;, &amp;quot;Statement&amp;quot;: [ { &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Principal&amp;quot;: { &amp;quot;Service&amp;quot;: &amp;quot;ec2.amazonaws.com&amp;quot; }, &amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot; } ] } EC2にロールを設定すると、実はそのロールについてAssumeRoleして自動でCredentialを取得している。 EC2にロールを設定するにはロールとは別に インスタンスプロファイルを作成 する必要があるが、コンソールでEC2のサービスロールを作ると同名のインスタンスプロファイルが自動で作成される。 さらに、AssumeRoleのServiceとしてec2.amazonaws.comが追加されている。
$ curl http://169.254.169.254/latest/meta-data/iam/info { &amp;quot;Code&amp;quot; : &amp;quot;Success&amp;quot;, &amp;quot;LastUpdated&amp;quot; : &amp;quot;2017-02-25T10:56:33Z&amp;quot;, &amp;quot;InstanceProfileArn&amp;quot; : &amp;quot;arn:aws:iam::*****:instance-profile/assume_role_test&amp;quot;, &amp;quot;InstanceProfileId&amp;quot; : &amp;quot;*****&amp;quot; } $ curl http://169.254.169.254/latest/meta-data/iam/security-credentials/assume_role_test { &amp;quot;Code&amp;quot; : &amp;quot;Success&amp;quot;, &amp;quot;LastUpdated&amp;quot; : &amp;quot;2017-02-25T10:56:23Z&amp;quot;, &amp;quot;Type&amp;quot; : &amp;quot;AWS-HMAC&amp;quot;, &amp;quot;AccessKeyId&amp;quot; : &amp;quot;*****&amp;quot;, &amp;quot;SecretAccessKey&amp;quot; : &amp;quot;*****&amp;quot;, &amp;quot;Token&amp;quot; : &amp;quot;*****&amp;quot;, &amp;quot;Expiration&amp;quot; : &amp;quot;2017-02-25T17:26:07Z&amp;quot; } 参考 IAMロール徹底理解 〜 AssumeRoleの正体 ｜ Developers.</description>
    </item>
    
    <item>
      <title>ElasticsearchのCircuit Breaker</title>
      <link>https://www.sambaiz.net/article/71/</link>
      <pubDate>Fri, 24 Feb 2017 21:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/71/</guid>
      <description>ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net
ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。 表示されたエラーはこういうの。
&amp;quot;root_cause&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;circuit_breaking_exception&amp;quot;, &amp;quot;reason&amp;quot;: &amp;quot;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;quot;, &amp;quot;bytes_wanted&amp;quot;: 10464007168, &amp;quot;bytes_limit&amp;quot;: 8998512230 } ], これは1リクエストの集計などで使うメモリ量がしきい値をこえて Circuit Breakerが発動したということ。 メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。
情報はstatsのapiでも取得できる。
$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request { &amp;quot;limit_size_in_bytes&amp;quot;: 8998512230, &amp;quot;limit_size&amp;quot;: &amp;quot;8.3gb&amp;quot;, &amp;quot;estimated_size_in_bytes&amp;quot;: 10348347504, &amp;quot;estimated_size&amp;quot;: &amp;quot;9.6gb&amp;quot;, &amp;quot;overhead&amp;quot;: 1, &amp;quot;tripped&amp;quot;: 470 } 今回ひっかかったのはindices.breaker.request.limit。デフォルトではJVMのヒープメモリの60%になっているが、 これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。
$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{ &amp;quot;persistent&amp;quot; : { &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;, &amp;quot;indices.breaker.total.limit&amp;quot;: &amp;quot;80%&amp;quot; } }&#39; $ curl -XPUT localhost:9200/_cluster/settings -d &#39;{ &amp;quot;persistent&amp;quot; : { &amp;quot;indices.</description>
    </item>
    
    <item>
      <title>crontabのメモ</title>
      <link>https://www.sambaiz.net/article/70/</link>
      <pubDate>Fri, 24 Feb 2017 21:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/70/</guid>
      <description>各ユーザーごとのcron設定。crontab -eでも編集できるけど、間違えて-rにすると全部消えてしまうのでこういう風に一旦取り出してから編集すると安全。
$ crontab -l &amp;gt; ~/crontab $ echo &amp;quot;*/1 * * * * /hoge/fuga.sh&amp;quot; &amp;gt;&amp;gt; ~/crontab $ crontab &amp;lt; ~/crontab $ crontab -l */1 * * * * /hoge/fuga.sh 参考 cron 設定ファイル (crontab ファイル) の置き場所と書式について - ひだまりソケットは壊れない</description>
    </item>
    
    <item>
      <title>Cookieのメモ</title>
      <link>https://www.sambaiz.net/article/69/</link>
      <pubDate>Wed, 22 Feb 2017 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/69/</guid>
      <description>https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies
レスポンスにSet-Cookieヘッダーが含まれていればブラウザはcookieに保存する。
HTTP/1.0 200 OK Content-type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry リクエスト時にはCookieヘッダーにcookieを入れて送る。
GET /sample_page.html HTTP/1.1 Host: www.example.org Cookie: yummy_cookie=choco; tasty_cookie=strawberry CookieにExpire(ある期間まで有効)またはMax-Age(特定の期間の間有効)を設定するとPermanent cookieとなる。 いずれも設定しなかった場合Session cookieとなり、ブラウザを閉じると削除されることになっているが、 ブラウザのセッション復元機能が有効になっていれば永続化される。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secureを付けるとHTTPSでのみ送られる。 また、HttpOnlyはjsからdocument.cookieなどでアクセスすることができなくなる。 サイトにXSSの脆弱性があるとき、cookieが盗まれてしまうのを防ぐことができるので問題なければ設定するべき。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly Domainを指定するとそのドメインとサブドメインへのリクエストのときに送られる。しないとそのドメインだけ。Pathも指定できる。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Domain=example.com; Path=/ リクエストが飛び、Set-Cookieヘッダーを受け取ればCookieに書かれるので、アクセスしたサイトのドメイン以外のCookieが書かれることがある。 このようなCookieを3rd party cookieといって、広告のトラッキングによく使われるが、 Safariなどのデフォルト設定では書き込めなくなっている。</description>
    </item>
    
    <item>
      <title>ELBのスケーリングとsurge queue</title>
      <link>https://www.sambaiz.net/article/68/</link>
      <pubDate>Tue, 21 Feb 2017 19:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/68/</guid>
      <description>バックエンドだけではなくELB自体もスケーリングし、内部node数はdigで調べることができる。 このnode数は自分ではコントロールできず、基本的に意識することはない。
$ dig ****.ap-northeast-1.elb.amazonaws.com ;; ANSWER SECTION: *****.elb.amazonaws.com. 60 IN A xxx.xxx.xxx.xxx *****.elb.amazonaws.com. 60 IN A yyy.yyy.yyy.yyy nodeが増えるのにはある程度時間がかかるので、 アクセスが急増(5分間で50%以上のトラフィック増加が目安) したら捌ききれず、503を返すことがある。 前もって多量のアクセスが来ることが分かっていて、 AWSサポートがBusiness以上なら pre-warming申請することでnodeが増えた状態で待ち構えられる。
バックエンドのアプリケーションがリクエストを処理できない場合、ELBのsurge queueに溜まっていく。 この数はCloudWatchのSurgeQueueLength(キュー長の急増)メトリクスで確認できる。 また、SurgeQueueLengthの最大値1024を超えるとリクエストは拒否され、その数はSpoiloverCount(過剰数)メトリクスに出る。
参考 ELBの挙動とCloudWatchメトリクスの読み方を徹底的に理解する ｜ Developers.IO
Elastic Load Balancing でのレイテンシーのトラブルシューティング</description>
    </item>
    
    <item>
      <title>Kinesis Streams/Firehose/Analyticsを試す</title>
      <link>https://www.sambaiz.net/article/67/</link>
      <pubDate>Mon, 20 Feb 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/67/</guid>
      <description>https://aws.amazon.com/jp/kinesis/
リアルタイムのストリーミングデータを扱うサービス群。 いまのところTokyoリージョンではKinesis Streamsしか使えない。
Kinesis Firehose AWSのデータストアに送るストリーム。自分でデータを読む処理を書かなくてよく、スケーリングも勝手にやってくれるので簡単に使える。
https://aws.amazon.com/jp/kinesis/firehose/faqs/
Q: 送信先とは何ですか? 送信先はデータが配信されるデータストアです。Amazon Kinesis Firehose では、 現在送信先として Amazon S3、Amazon Redshift、Amazon Elasticsearch Service がサポートされています。 料金は取り込まれたデータ量による。 一見そんなに高くならないように見えるが、5KB単位で切り上げられるのでレコードのサイズが小さくて数が多い場合に注意が必要。
今回はS3に送ってみる。
圧縮方法を設定したり、Lambdaを噛ませたりすることができる。
StatusがActiveになったらKinesis Agentで送ってみる。 CloudWatchとFirehoseにPutする権限が必要。Firehoseはkinesis:ではなくfirehose:なので注意。
$ sudo yum install –y aws-kinesis-agent /etc/aws-kinesis/agent.jsonを編集する。リージョンごとのエンドポイントは ここ にある。
{ &amp;quot;awsAccessKeyId&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;awsSecretAccessKey&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;firehose.endpoint&amp;quot;: &amp;quot;https://firehose.us-east-1.amazonaws.com&amp;quot;, &amp;quot;flows&amp;quot;: [ { &amp;quot;filePattern&amp;quot;: &amp;quot;/tmp/hoge.log&amp;quot;, &amp;quot;deliveryStream&amp;quot;: &amp;quot;hogefugastream&amp;quot; } ] } $ sudo service aws-kinesis-agent start $ sudo chkconfig aws-kinesis-agent on $ echo &amp;quot;aaa&amp;quot; &amp;gt;&amp;gt; /tmp/hoge.log $ tail /var/log/aws-kinesis-agent/aws-kinesis-agent.</description>
    </item>
    
    <item>
      <title>fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する</title>
      <link>https://www.sambaiz.net/article/66/</link>
      <pubDate>Sun, 19 Feb 2017 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/66/</guid>
      <description>fluentdのmonitor_agent メトリクスをjsonで返すAPIを提供する。
&amp;lt;source&amp;gt; @type monitor_agent bind 0.0.0.0 port 24220 &amp;lt;/source&amp;gt; $ curl localhost:24220/api/plugins.json | jq { &amp;quot;plugins&amp;quot;: [ { &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d8c250&amp;quot;, &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;forward&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;@type&amp;quot;: &amp;quot;forward&amp;quot;, &amp;quot;port&amp;quot;: &amp;quot;24222&amp;quot;, &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot; }, &amp;quot;output_plugin&amp;quot;: false, &amp;quot;retry_count&amp;quot;: null }, { &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d894c4&amp;quot;, &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;monitor_agent&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;@type&amp;quot;: &amp;quot;monitor_agent&amp;quot;, &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot;, &amp;quot;port&amp;quot;: &amp;quot;24220&amp;quot; }, &amp;quot;output_plugin&amp;quot;: false, &amp;quot;retry_count&amp;quot;: null }, { &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590dc1f2c&amp;quot;, &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;@type&amp;quot;: &amp;quot;file&amp;quot;, &amp;quot;path&amp;quot;: &amp;quot;/var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>Goのselectの中断処理(close, context)</title>
      <link>https://www.sambaiz.net/article/65/</link>
      <pubDate>Thu, 16 Feb 2017 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/65/</guid>
      <description>close(chan) closeしたチャネルを読むとゼロ値になるので、selectで待っているやつにまとめて送れる。
func main() { done := make(chan bool) wg := new(sync.WaitGroup) waitTillDone(wg, done) waitTillDone(wg, done) // こんなことしなくていい // done &amp;lt;- true // done &amp;lt;- true close(done) wg.Wait() } func waitTillDone(wg *sync.WaitGroup, done &amp;lt;-chan bool) { wg.Add(1) go func() { select { case v := &amp;lt;-done: fmt.Println(v) // false (ゼロ値) wg.Done() } }() } context key-valueの値を渡せるほかにキャンセルやタイムアウトの仕組みをもつ。
ctx := context.Background() // empty context ctx, cancel = context.WithCancel(ctx) ctx, cancel = context.WithDeadline(ctx, time.</description>
    </item>
    
    <item>
      <title>fluentd自身のログを拾う</title>
      <link>https://www.sambaiz.net/article/64/</link>
      <pubDate>Tue, 14 Feb 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/64/</guid>
      <description>fluentdは自身のログもfluent.errorのようなタグでイベントとして流す。
バッファを0にして意図的にエラーを発生させてみる。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; # throw away &amp;lt;match fluent.info&amp;gt; @type null &amp;lt;/match&amp;gt; &amp;lt;match fluent.**&amp;gt; @type stdout &amp;lt;/match&amp;gt; # error! &amp;lt;match **&amp;gt; @type file path /var/log/td-agent/hoge.log buffer_chunk_limit 0 buffer_queue_limit 0 &amp;lt;/match&amp;gt; すると、こんなのがtd-agent.logに出力される。
fluent.error: {&amp;quot;error&amp;quot;:&amp;quot;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;quot;,&amp;quot;error_class&amp;quot;:&amp;quot;Fluent::BufferQueueLimitError&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;quot;} ただ、これだとaggregatorに集めたときにどのサーバーのfluentdに問題が発生してるのか分からない。 そこでホスト名を追加する。
fluentdのrecord_transformerでログを加工する - sambaiz.net
&amp;lt;filter fluent.**&amp;gt; @type record_transformer enable_ruby &amp;lt;record&amp;gt; hostname &amp;quot;#{Socket.gethostname}&amp;quot; tag ${tag} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; fluent.error: {&amp;quot;error&amp;quot;:&amp;quot;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;quot;,&amp;quot;error_class&amp;quot;:&amp;quot;Fluent::BufferQueueLimitError&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;quot;, &amp;quot;hostname&amp;quot;:&amp;quot;*****&amp;quot;,&amp;quot;tag&amp;quot;:&amp;quot;fluent.</description>
    </item>
    
    <item>
      <title>GoでDynamoDBを使う</title>
      <link>https://www.sambaiz.net/article/63/</link>
      <pubDate>Sun, 12 Feb 2017 23:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/63/</guid>
      <description>テーブルを作成する プライマリキー テーブルの操作のガイドライン - Amazon DynamoDB
プライマリキーとしてパーティションキー(ハッシュキー)とオプションのソートキー(レンジキー)を設定する。 DynamoDBはこのパーティションキーに基づいて、複数のパーティションに分散して保存する。 テーブルにプロビジョニングされたスループット性能はパーティション間で均等に使われるので、 ソートキーを設定する場合にこれを最大限に活用するためには、 あるパーティションにリクエストが集中しないよう、パーティションキーに特定の値ばかり集中しないようなフィールドを 選ぶ必要がある。
セカンダリインデックス パーティションキーのグローバルセカンダリインデックス(GSI)と ソートキーのローカルセカンダリインデックス(LSI)がある。 射影されるフィールドを選択でき、ここに含まれないフィールドは返さない。 ただし、すべてをインデックスに書き込むのはコストが高いのでなるべく絞る。
キャパシティユニット  1読み込みキャパシティユニット: 4kbを超えないデータを1秒に1~2回(整合性による)読み込める 1書き込みキャパシティユニット: 1kbを超えないデータを1秒に1回書き込める  ユニットに応じて1時間あたりで課金される。
未使用のキャパシティがある場合、最大5分保持してバーストに備えてくれる。
読み書きする aws-sdk-goを直接使ってもいいけど、簡単に扱えるラッパー guregu/dynamo を使うことにした。
type Data struct { ID int64 `dynamo:&amp;quot;id&amp;quot;` Name string Age int } db := dynamo.New(session.New(), &amp;amp;aws.Config{Region: aws.String(&amp;quot;ap-northeast-1&amp;quot;)}) table := db.Table(&amp;quot;testtable&amp;quot;) Create &amp;amp; Update d := Data{ID: 1, Name: &amp;quot;hogefuga&amp;quot;, Age: 123} if err := table.Put(d).Run(); err != nil { return err } if err := table.</description>
    </item>
    
    <item>
      <title>Elasticsearchのmapping</title>
      <link>https://www.sambaiz.net/article/62/</link>
      <pubDate>Thu, 09 Feb 2017 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/62/</guid>
      <description>Dynamic mappingがあるので、自分で設定しなくてもデータは入るけど、 自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。 バージョンは5.2。
$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39; { &amp;quot;name&amp;quot;: 0 } &#39; $ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39; { &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot; } &#39; { &amp;quot;error&amp;quot; : { &amp;quot;root_cause&amp;quot; : [ { &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot; } ], &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;, &amp;quot;caused_by&amp;quot; : { &amp;quot;type&amp;quot; : &amp;quot;number_format_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;For input string: \&amp;quot;sambaiz\&amp;quot;&amp;quot; } }, &amp;quot;status&amp;quot; : 400 } Mapping parameters index falseにするとindexしない。クエリで必要ないものはfalseにする。</description>
    </item>
    
    <item>
      <title>Goのnet/httpとKeep-Alive</title>
      <link>https://www.sambaiz.net/article/61/</link>
      <pubDate>Tue, 07 Feb 2017 22:42:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/61/</guid>
      <description>Keep-AliveするとTCPコネクションを使い回し、名前解決やコネクション(3 way handshake)を毎回行わなくてよくなる。 Goのnet/httpではデフォルトでKeep-Aliveが 有効になっているが、 全体と同一ホストでそれぞれKeep-Aliveするコネクション数が制限される。 これらの値はClientのTransportが持っていて、 これがnullだとDefaultTransportが参照されるので、意識しなければこの値が使われる。
 MaxIdleConns: DefaultTransportでは100になっている。0にすると無制限。 MaxIdleConnsPerHost: デフォルト値は2。0にするとデフォルト値が使われる。  同一のホストに同時にたくさんリクエストする場合、2だとほとんど意味を持たない。これを増やして比較してみた。
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;io/ioutil&amp;quot; &amp;quot;net/http&amp;quot; &amp;quot;time&amp;quot; ) var client = http.Client{ Timeout: time.Millisecond * 100, } const TOTAL_REQUEST_NUM = 3000 const TARGET_URL = &amp;quot;*****&amp;quot; func main() { http.DefaultTransport.(*http.Transport).MaxIdleConns = 0 http.DefaultTransport.(*http.Transport).MaxIdleConnsPerHost = 3000 okChan := make(chan int, TOTAL_REQUEST_NUM) ngChan := make(chan int, TOTAL_REQUEST_NUM) var okCount = 0 var ngCount = 0 // connect and keep-alive for i := 0; i &amp;lt; TOTAL_REQUEST_NUM; i++ { go request(okChan, ngChan) } for { select { case &amp;lt;-okChan: okCount++ case &amp;lt;-ngChan: ngCount++ } if okCount+ngCount == TOTAL_REQUEST_NUM { break } } okCount = 0 ngCount = 0 startNs := time.</description>
    </item>
    
    <item>
      <title>iftopでネットワークの帯域を見る</title>
      <link>https://www.sambaiz.net/article/60/</link>
      <pubDate>Tue, 07 Feb 2017 20:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/60/</guid>
      <description>$ yum install --enablerepo=epel iftop $ iftop -f &amp;quot;not dst net 10.0.0.0/8&amp;quot; -i eth0のようにしてインタフェースを指定し、-fでフィルタをかけられる。フィルタの詳細はman pcap-filterで。
 12.5Kb 25.0Kb 37.5Kb 50.0Kb	62.5Kb └─────────────────────────┴──────────────────────────┴──────────────────────────┴──────────────────────────┴────────────────────────── ip-172-31-9-9.ap-northeast-1.compute.internal =&amp;gt; 61-121-217-66.dh-connect.net 1.72Kb 6.57Kb 2.40Kb &amp;lt;= 416b 2.13Kb 702b ... ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── TX: cum: 22.6KB peak: 13.2Kb rates: 1.22Kb 1.27Kb 2.46Kb RX: 6.63KB 5.03Kb 208b 330b 748b TOTAL: 29.2KB 18.2Kb 1.42Kb 1.59Kb 3.19Kb 左から2, 10, 40秒間の平均kbps。TXが送信量、RXが受信量で、cumが総量、peakが最大。
実行中にSでソースのポートをDでディスティネーションのポートが表示される。</description>
    </item>
    
    <item>
      <title>vmstatのメモ</title>
      <link>https://www.sambaiz.net/article/59/</link>
      <pubDate>Mon, 06 Feb 2017 22:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/59/</guid>
      <description>$ vmstat 間隔(秒) procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 118588 80388 2516284 0 0 2 77 141 85 1 0 98 0 0 procs   r: 実行待ちプロセス数。CPUの処理が追いついていない。
  b: 割り込み不可能なスリープ中のプロセス数。I/O待ちらしい。
  memory   swpd: バーチャルメモリの使用量。
  free: 空きメモリ量。
  buff: バッファに使われてるメモリ量。
  cache: キャッシュに使われているメモリ量。</description>
    </item>
    
    <item>
      <title>EC2のインスタンスストア</title>
      <link>https://www.sambaiz.net/article/58/</link>
      <pubDate>Mon, 06 Feb 2017 21:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/58/</guid>
      <description>http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/InstanceStorage.html
EC2ではインスタンスタイプによってはEBSに加えてインスタンスストアが使える。しかも追加料金なし。 対象はストレージが&amp;quot;EBSのみ&amp;quot;でないもの。
https://aws.amazon.com/jp/ec2/instance-types/
インスタンスストアはインスタンスが停止したり、障害が起きると消える一時ストレージ。再起動では消えない。 ホストに物理的にアタッチされているので、バッファやキャッシュなどの頻繁に読み書きされ、消えてもいいデータに最適。 他のインスタンスにアタッチすることはできない。容量や性能もインスタンスタイプに依存する。
インスタンスストアボリュームの追加は インスタンスの起動時に、新しいボリュームを追加し、ボリュームタイプをインスタンスストアにすることで行うことができる。
今回はSSDストレージ1 x 4のm3.mediumで試す。これは4gbのボリュームが一つ追加できるという意味。
まずはインスタンスストアを追加してないインスタンス。 lsblkというのはlist block devicesの略。
$ df -h ファイルシス サイズ 使用 残り 使用% マウント位置 /dev/xvda1 7.8G 1.2G 6.6G 15% / ... $ dd if=/dev/zero of=hoge bs=1M count=1000 $ ls -sh 合計 1001M 1001M hoge $ df -h ファイルシス サイズ 使用 残り 使用% マウント位置 /dev/xvda1 7.8G 2.2G 5.6G 28% / ... $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 8G 0 disk └─xvda1 202:1 0 8G 0 part / それに対してインスタンスストア(/dev/xvdb)を追加したインスタンス。</description>
    </item>
    
    <item>
      <title>HoloLensでGaze, Click, Hold, Voiceイベントを拾う</title>
      <link>https://www.sambaiz.net/article/57/</link>
      <pubDate>Sun, 05 Feb 2017 20:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/57/</guid>
      <description>こんなの。SparitalMappingを有効にしているので球が床で止まっている。
動画
HoloToolKit のインタフェースを実装することでイベントを拾えるようになっている。
IFocusable Gazeしたとき。
public void OnFocusEnter（） { gazing = true; } public void OnFocusExit() { gazing = false; } IInputClickHandler クリックしたとき。
public void OnInputClicked(InputEventData eventData) { if (!clicked) { clicked = true; clickedRotationFrame = 0; } countUp(); } IHoldHandler Hold(指を下げたまま維持する)したとき。 指を上げたときがCompletedで、Objectを外れたときCanceledになる。
public void OnHoldStarted(HoldEventData eventData) { holding = true; clicked = true; } public void OnHoldCompleted(HoldEventData eventData) { holding = false; } public void OnHoldCanceled(HoldEventData eventData) { holding = false; } ISpeechHandler 声の入力。 InspectorからSpeech Input Source(Script)を追加して反応するキーワードを設定して使う。 MicrophoneのCapabilitiesが必要。</description>
    </item>
    
    <item>
      <title>HoloLensの開発を始める</title>
      <link>https://www.sambaiz.net/article/56/</link>
      <pubDate>Sat, 04 Feb 2017 21:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/56/</guid>
      <description>HoloLensでのアプリケーション https://developer.microsoft.com/en-us/windows/holographic/app_model
ある点を見るGazeと指で選択するGesture、声で入力するVoiceで操作する。
HoloLens shell では壁などにタイルを配置することでアプリケーションが起動する。
一度に動くアプリケーションは一つ。 他にアクティブなアプリケーションがあれば中断され、タイルは最後の状態のスクリーンショットになる。 タイルを削除するとプロセスが終了する。
Viewには空間全体を使うHolographic Viewと、通常のウィンドウのような2D Viewがある。
開発を始める Unityを使ってHolographic Viewのアプリケーションを開発する。
必要なツールをインストールする。エミュレーターは空きメモリが2GB以上ないと立ち上がらない。
https://developer.microsoft.com/en-us/windows/holographic/install_the_tools
チュートリアル https://developer.microsoft.com/en-us/windows/holographic/holograms_100
QualityのところでWindows Storeのマークがなかったら、 UnityのFile-&amp;gt;Build SettingsからWindows Storeモジュールをダウンロードする。
https://developer.microsoft.com/en-us/windows/holographic/holograms_101e
エミュレーターはWASDキーで移動してカーソルキーで向きを変え、エンターキーで選択できる。
エミュレーターで動かしてみる UnityProjectを作成してHolograms 100のように設定していく。
まずはCamera。
 Position: (0,0,0) Clear Flags: Solid Color Background: (0,0,0,0) Clipping Planes Near: 0.85  とりあえず動くことを確認するため適当なオブジェクトを置いてビルドしてみる。
Edit-&amp;gt;Project Settings-&amp;gt;QualityでWindows StoreをFastestにする。
Build Settings-&amp;gt;Windows Storeで
 SDK: Universal: 10 Target device: HoloLens UWP Build Type: D3D Unity C# Projectにチェック  にする。
BuildSettingsにあるPlayer Settingsボタンを押して Other SettingsのVirtual Reality Supportedにチェックを入れ、 SDKsにWindows Holographicが出るのを確認する。</description>
    </item>
    
    <item>
      <title>fluentdのrecord_transformerでログを加工する</title>
      <link>https://www.sambaiz.net/article/55/</link>
      <pubDate>Fri, 03 Feb 2017 21:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/55/</guid>
      <description>http://docs.fluentd.org/v0.12/articles/filter_record_transformer
追加したり、編集したり、削除したりできるフィルタ。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;filter hoge.log&amp;gt; @type record_transformer enable_ruby auto_typecast true remove_keys b,d &amp;lt;record&amp;gt; what_is_tag ${tag} what_is_a ${record[&amp;quot;a&amp;quot;]} what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; &amp;lt;match hoge.log&amp;gt; @type stdout &amp;lt;/match&amp;gt; この例だとタグを値に持つ&amp;quot;what_is_tag&amp;rdquo;、aを値に持つ&amp;quot;what_is_a&amp;rdquo;、b.cの値に1を足す&amp;quot;what_is_c_of_b_add_1&amp;quot;が追加され、 bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。
auto_typecastをtrueにしないと&amp;quot;what_is_c_of_b_add_1&amp;quot;の値がstringになる。
$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: 1}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.log hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2} エラーが起きるとnullになるが、それ以外の処理はされる。
$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: &amp;quot;error!&amp;quot;}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.</description>
    </item>
    
    <item>
      <title>fluentdでElasticsearchに送る</title>
      <link>https://www.sambaiz.net/article/54/</link>
      <pubDate>Wed, 01 Feb 2017 21:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/54/</guid>
      <description>uken/fluent-plugin-elasticsearch
必要なものをいれていく。Amazon LinuxのAMIから。
 Failed to build gem native extension.  $ yum install -y ruby-devel  serverengine requires Ruby version &amp;gt;= 2.1.0.  rbenvでバージョンを上げる。
$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv $ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src $ echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile $ ~/.rbenv/bin/rbenv init $ echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile $ source ~/.bash_profile $ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build $ rbenv -v rbenv 1.1.0-2-g4f8925a  Ruby install aborted due to missing extensions  $ yum install -y openssl-devel readline-devel zlib-devel $ rbenv install -l 1.</description>
    </item>
    
    <item>
      <title>Goのnet/http.Client.Doの内部実装をたどったメモ</title>
      <link>https://www.sambaiz.net/article/53/</link>
      <pubDate>Mon, 30 Jan 2017 20:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/53/</guid>
      <description>package main import ( &amp;quot;fmt&amp;quot; &amp;quot;net/http&amp;quot; &amp;quot;io/ioutil&amp;quot; ) var client = http.Client{} func main() { req, err := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;http://example.com&amp;quot;, nil) if err != nil{ panic(err) } resp, err := client.Do(req) if err != nil{ panic(err) } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil{ panic(err) } fmt.Println(string(body)) } Client TransportがTCPコネクションをキャッシュするのでClientは使い回すべき。複数のgoroutineでコンカレントに使っても大丈夫。
https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36
type Client struct { // nilならDefaultTransportが使われる Transport RoundTripper // nilなら10回で止まる CheckRedirect func(req *Request, via []*Request) error // nilならcookieは無視される Jar CookieJar Timeout time.</description>
    </item>
    
    <item>
      <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
      <link>https://www.sambaiz.net/article/52/</link>
      <pubDate>Sun, 29 Jan 2017 17:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/52/</guid>
      <description>https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
vm.max_map_count (バーチャルメモリにマッピングできる最大ページ数) を262144以上にする。
$ sysctl vm.max_map_count $ grep vm.max_map_count /etc/sysctl.conf vm.max_map_count=262144 # sysctl -w vm.max_map_count=262144 30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。
-cap-add=IPC_LOCKでLock memory(スワップアウトしないようにする)を 許可する。
https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html
ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。 ただし、物理RAMの50%以下で、32GB近辺の境界を超えないようにする。
$ mkdir -p ~/do/elasticsearch/data $ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \ --name elasticsearch \ -p 9200:9200 \ -e xpack.security.enabled=false \ -e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;quot;-Xms28g -Xmx28g&amp;quot; \ --cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \ --restart=always \ docker.elastic.co/elasticsearch/elasticsearch:5.1.2 $ docker volume ls local elasticsearch 問題なく起動しているか確認する。
$ curl localhost:9200 | jq { &amp;quot;name&amp;quot;: &amp;quot;eqIkJ48&amp;quot;, &amp;quot;cluster_name&amp;quot;: &amp;quot;docker-cluster&amp;quot;, &amp;quot;cluster_uuid&amp;quot;: &amp;quot;Lsu_C7wORS6G-0m9PJ9sFQ&amp;quot;, &amp;quot;version&amp;quot;: { &amp;quot;number&amp;quot;: &amp;quot;5.</description>
    </item>
    
    <item>
      <title>fluentdのforward</title>
      <link>https://www.sambaiz.net/article/51/</link>
      <pubDate>Wed, 25 Jan 2017 22:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/51/</guid>
      <description>td-agent間でログをやりとりするとき に使われるforwardについて。内部ではMessagePackを使っている。
forward input http://docs.fluentd.org/articles/in_forward
受け取る側。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;match **&amp;gt; @type stdout &amp;lt;/match&amp;gt; /etc/init.d/td-agent restartしてfluent-catで送ってみる。
$ echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat -h xx.xx.xx.xx test.tag /var/log/td-agent/td-agent.logに出力される。
test.tag: {&amp;quot;hoge&amp;quot;:&amp;quot;fuga&amp;quot;} forward output http://docs.fluentd.org/articles/out_forward
http://docs.fluentd.org/articles/buffer-plugin-overview
送る側。
ポートはデフォルトで24224で、イベントの送信にTCPを、heartbeatにUDP(heartbeat_typeで変えられる)を使う。
flush_intervalははデフォルトで60秒。 確認のときは短くしておくと分かりやすい。 buffer_queueの一番上のチャンクがこの時間経過するか、サイズがbuffer_chunk_limitを超えると、一番下のチャンクが書き込まれ、新しいチャンクがpushされる。 chunkの数がbuffer_queue_limitに到達してしまうと新しいイベントは破棄されてしまうので リソースを圧迫(buffer_chunk_limit * buffer_queue_limit)しない程度に十分大きな数にしておき、 スパイクや障害時に備えておく。 buffer_typeはデフォルトがmemory。fileだとflush_at_shutdownのデフォルトがfalseなので注意。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;match **&amp;gt; @type forward flush_interval 1s buffer_type file buffer_path /var/log/td-agent/forward-buf flush_at_shutdown true buffer_chunk_limit 256m &amp;lt;server&amp;gt; name log_server host xx.</description>
    </item>
    
    <item>
      <title>Goのinterface/structの埋め込み</title>
      <link>https://www.sambaiz.net/article/50/</link>
      <pubDate>Wed, 18 Jan 2017 01:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/50/</guid>
      <description>Goには継承が存在しない。その代わりstructを埋め込み、委譲することができる。
https://golang.org/doc/effective_go.html#embedding
挙動 interfaceにinterfaceを埋め込む type I interface { Hoge() } type J interface { Fuga() } type K interface { I J } インタフェースKはIとJを合わせたものになる。IとJに重複する関数がある場合はエラーになる。
type L struct { } func (l L) Hoge() { fmt.Println(&amp;quot;hoge&amp;quot;) } func (l L) Fuga() { fmt.Println(&amp;quot;fuga&amp;quot;) } var k K k = L{} k.Hoge() k.Fuga() structにinterfaceを埋め込む type K interface { Hoge() Fuga() } type M struct { K } 埋め込むとm.Hoge()のように透過的にKを扱うことができるようになる。
m := M{L{}} m.Hoge() // m.</description>
    </item>
    
    <item>
      <title>Goのpanicとrecover</title>
      <link>https://www.sambaiz.net/article/49/</link>
      <pubDate>Tue, 17 Jan 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/49/</guid>
      <description>panic https://golang.org/pkg/builtin/#panic
panicは現在のgoroutineの通常の実行を停止する組み込み関数。 index out of rangeや invalid memory address or nil pointer dereference のときなどでも呼ばれる。
deferを実行して呼び出し元に戻り、panicの実行-&amp;gt;deferの実行-&amp;gt;呼び出し元に戻る、を繰り返して 最後まで戻ったらプログラムを終了し、panicに渡した引数と共にエラーをレポートする。
func main() { a() } func a() { defer fmt.Println(&amp;quot;a&amp;quot;) b() fmt.Println(&amp;quot;a2&amp;quot;) } func b() { defer fmt.Println(&amp;quot;b1&amp;quot;) panic(&amp;quot;b2&amp;quot;) defer fmt.Println(&amp;quot;b3&amp;quot;) } b1 a panic: b2 goroutine 1 [running]: panic(0x89840, 0xc42000a2c0) /*****/libexec/src/runtime/panic.go:500 +0x1a1 main.b() /*****/main.go:19 +0x107 main.a() /*****/main.go:13 +0xce main.main() /*****/main.go:8 +0x14 exit status 2 recover https://golang.org/pkg/builtin/#recover
deferで呼ぶことによってpanicを停止させることができる組み込み関数。 panicの引数に渡した値を取得できる。
func main() { fmt.Println(a()) fmt.</description>
    </item>
    
    <item>
      <title>OAuth2.0のメモ</title>
      <link>https://www.sambaiz.net/article/48/</link>
      <pubDate>Sun, 08 Jan 2017 02:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/48/</guid>
      <description>認可(Authorization)と認証(Authentication) それぞれAuthZ、AuthNとも書かれる。
 認可: リソースへのアクセスを許可する 認証: ユーザーが何者かを検証する  OAuth 2.0 認可のプロトコル。 それによってアクセスできるようになったリソースの情報をもとに認証を行ったりすることもあるが、 以下に示すImplicit Flowでそれをやると他のサービスのトークンで他人に成りすませてしまう問題があるため、 認証する場合はOAuth 2.0ベースの認証プロトコルのOpenID Connectを使うべき。 その場合もトークンを取得するまでの流れはほとんどOAuth 2.0通りなのでフローを理解しておいて無駄はない。
OpenID ConnectのIDトークンの内容と検証 - sambaiz-net
Authorization Code Flow OAuthクライアントがアプリケーションサーバーのときのフロー。
まずユーザーがOAuth認可ページで認可する。 このリクエストには
 client_id redirect_uri scope: アクセスできるリソースの種類 response_type=code: 認可コードが返される state: CSRFを防ぐためのランダムで一意な文字列。アプリケーションサーバーが保持して、前後で一致するかチェックする  が含まれる。
認可されると認可コードとstateを付けてredirect_uri(事前に登録しておく)にリダイレクトするので、 アプリケーションサーバーは認可コードをアクセストークンに交換する。 この際、client_idとclient_secretも送る。
オプションでリフレッシュトークンを含み、これを使うと期限が切れたとき新しいアクセストークンを取得できる。
アクセストークンは通常Bearer Token(Authorization: Bearer ***)としてリクエストに含まれる。
Implicit Flow OAuthクライアントがアプリなどでclient_secretの機密性を保てない場合のフロー。
認可コードは不要なのでresponse_type=tokenでリクエストし、アクセストークンをブラウザで取得する。 リフレッシュトークンは含まない。 他のサービスで発行された他人のトークンを使うことでなりすませてしまうので、 そのトークンがどのサービスに対して発行されたかを確認する術が特に用意されているのでなければ 認証に使ってはいけない。OpenID Connectでは署名されたIDトークンに発行されたサービスの情報が含まれている。
参考 O&amp;rsquo;Reilly Japan - OAuth 2.0をはじめよう
Implicit Flow では Covert Redirect で Token 漏れるね - OAuth.</description>
    </item>
    
    <item>
      <title>go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる</title>
      <link>https://www.sambaiz.net/article/47/</link>
      <pubDate>Wed, 04 Jan 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/47/</guid>
      <description>この関数のベンチマークを取る。
package cal import ( &amp;quot;math/big&amp;quot; ) var cache = map[int]*big.Int{} func resetCache() { cache = map[int]*big.Int{} } func Fibonacci(n int) *big.Int { if c := cache[n]; c != nil { return c } ret := new(big.Int) before := big.NewInt(1) for i := 1; i &amp;lt; n; i++ { tmp := new(big.Int).Add(ret, before) before = ret ret = tmp cache[i] = ret } cache[n] = ret return ret } 引数にtesting.Bを取る、Benchmarkから始まる関数を書いて、b.N回ループさせる。</description>
    </item>
    
    <item>
      <title>汎用シリアライズ方法(MessagePack/Protocol Buffers/FlatBuffers)</title>
      <link>https://www.sambaiz.net/article/46/</link>
      <pubDate>Fri, 30 Dec 2016 18:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/46/</guid>
      <description>MessagePackとは JSONのように使うことができ、速くてサイズが小さい。
{&amp;quot;compact&amp;quot;:true,&amp;quot;スキーマ&amp;quot;:{&amp;quot;number&amp;quot;: 999, &amp;quot;string&amp;quot;: &amp;quot;aaa&amp;quot;}} のjson(61bytes)をMessagePack(45bytes)に変換したのがこれ。見やすいように改行している。
82 a7 63 6f 6d 70 61 63 74 c3 ac e3 82 b9 e3 82 ad e3 83 bc e3 83 9e 82 a6 6e 75 6d 62 65 72 cd 03 e7 a6 73 74 72 69 6e 67 a3 61 61 61 一行目の82は要素数2のfixmap(要素数15まで)を表す。
二行目のa7が7バイトのfixstr(31bytesまで)で、 63 6f 6d 70 61 63 74が&amp;quot;compact&amp;rdquo;。c3はtrue。
三行目のacは12バイトのfixstrで、e3 82 b9 e3 82 ad e3 83 bc e3 83 9eが&amp;quot;スキーマ&amp;rdquo;。</description>
    </item>
    
    <item>
      <title>GoogleのkvsライブラリLevelDBを使う</title>
      <link>https://www.sambaiz.net/article/45/</link>
      <pubDate>Sat, 24 Dec 2016 21:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/45/</guid>
      <description>LevelDBとは https://github.com/google/leveldb
Googleが作った高速なkey-valueストレージライブラリ。
ChromeのIndexedDBやprometheusなどで使われている。
特徴  Keyと任意のバイト配列のValue データはKeyでソートされる。ソートのための比較関数はオーバーライドできる。 基本的な操作はPut, Get, Delete。 複数の変更を一つのatomicなバッチで行える 一環したデータのビューを取得するために、一時的なスナップショットを作成できる データを前にも後ろにもイテレーションできる データはSnappy compression libraryで自動で圧縮される。 ファイルシステムの操作など外部のアクティビティを仮想的なインタフェースを通して行うので、OSとのやりとりをカスタマイズできる。  制限  SQLデータベースではない。リレーショナルなデータモデルは持てないし、SQLやインデックスにも対応していない。 一度に一つのプロセスしかDBにアクセスできない。  キャッシュ  DBはファイルシステムのディレクトリに対応する名前を持ち、内容はそのディレクトリに保存される。 各ファイルには圧縮したブロックが保存され、良く使うものについては非圧縮のブロックがキャッシュされる。 ソートして隣接するキーは通常、同じブロックに配置される。ディスク転送とキャッシュはブロック単位。  フィルタ  Getの際、不要なデータを読まなくていいようにフィルタ(Bloom Filter)を用いることができる。 独自の比較関数(末尾のスペースを無視するなど)を使う場合、Bloom Filterを使うことができないことがあるので、その場合は独自のフィルタが必要。  レベル  最近の更新はログファイルに保存される。これが決められたサイズ(デフォルトでは約4MB)に達すると、sorted table(sst)に変換され、新しいログファイルが生成される。 現在のログファイルのコピーがメモリ(memtable)にも乗って読み取りで参照される。 sstはキーによってソートされたエントリーを保存する。エントリーはキーの値か、削除マーカー。 sstはレベルによってまとめられる。ログファイルから変換されると、特別なyoungレベル(level-0とも呼ばれる)に配置される。 youngファイルの数があるしきい値(現在4つ)を超えると全てのyoungファイルを全てのlevel-1ファイルとマージし、新しいlevel-1ファイルを生成する(2MBごとに1ファイル)。 youngレベルのファイルにはキーが重複していることがある。しかし、他のレベルでは重複しないキーの範囲がある。 level-L(L&amp;gt;=1)のファイルの合計サイズが10^L MBを超えたとき、level-Lのファイルと、level-(L+1)の全てのファイルをマージし、新しいlevel-(L+1)ファイルを生成する。 これによって、バルク読み込み/書き込みのみを使い、コストが高いシークを最小限にして、youngレベルから大きいレベルに更新を徐々にマイグレーションすることができる。  動かしてみる LevelDBのgo実装。
syndtr/goleveldb
$ go get github.com/syndtr/goleveldb/leveldb まずDBを開く。
// open db, err := leveldb.OpenFile(&amp;quot;/Users/sambaiz/leveldb&amp;quot;, nil) defer db.Close() if err != nil { panic(err) } 普通に5個(key0~4)、バッチで5個(key5~9)のデータを入れて、そのうち一つを消す。</description>
    </item>
    
    <item>
      <title>gvmでGoのバージョン管理</title>
      <link>https://www.sambaiz.net/article/44/</link>
      <pubDate>Tue, 20 Dec 2016 20:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/44/</guid>
      <description>moovweb/gvm
必要なものはREADMEを見て入れる。
$ bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) $ source ${HOME}/.gvm/scripts/gvm $ gvm install go1.7 -B $ gvm use go1.7 $ go version go version go1.7 linux/amd64 $GOPATHと$GOROOTが書き変わる(${HOME}/.gvm/pkgsets/go1.7/global/)ので注意。</description>
    </item>
    
    <item>
      <title>複数EC2インスタンスを立ち上げてvegetaで負荷試験する</title>
      <link>https://www.sambaiz.net/article/43/</link>
      <pubDate>Sun, 18 Dec 2016 20:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/43/</guid>
      <description>vegetaで負荷をかける。
インスタンスを立ち上げるスクリプト コードはここ。 sambaiz/loadtest
まずキーペアを作成し、EC2インスタンスを立ち上げて、全てのインスタンスが使えるようになるまで待つ。
aws ec2 create-key-pair --key-name LoadTestKeyPare --query &#39;KeyMaterial&#39; --output text &amp;gt; LoadTestKeyPare.pem chmod 400 LoadTestKeyPare.pem aws ec2 run-instances --image-id $AMI_ID --count $INSTANCE_NUM --instance-type t2.micro --key-name LoadTestKeyPare --security-group-ids $SECURITY_GROUP_IDS --subnet-id $SUBNET_ID ... aws ec2 wait instance-status-ok --instance-ids $INSTANCE_IDS このAMIは事前にPackerでつくったもの。vegetaをインストールしてファイルディスクリプタの上限を増やしている。
{ &amp;quot;variables&amp;quot;: { &amp;quot;aws_access_key&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;aws_secret_key&amp;quot;: &amp;quot;&amp;quot; }, &amp;quot;builders&amp;quot;: [{ &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;, &amp;quot;access_key&amp;quot;: &amp;quot;{{user `aws_access_key`}}&amp;quot;, &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `aws_secret_key`}}&amp;quot;, &amp;quot;region&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;, &amp;quot;source_ami&amp;quot;: &amp;quot;ami-0c11b26d&amp;quot;, &amp;quot;instance_type&amp;quot;: &amp;quot;t2.micro&amp;quot;, &amp;quot;ssh_username&amp;quot;: &amp;quot;ec2-user&amp;quot;, &amp;quot;ami_name&amp;quot;: &amp;quot;loadtest {{timestamp}}&amp;quot; }], &amp;quot;provisioners&amp;quot;: [{ &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;, &amp;quot;inline&amp;quot;: [ &amp;quot;wget https://github.</description>
    </item>
    
    <item>
      <title>SSHポートフォワーディングとnetstatのメモ</title>
      <link>https://www.sambaiz.net/article/42/</link>
      <pubDate>Sat, 17 Dec 2016 12:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/42/</guid>
      <description>SSHポートフォワーディング ローカルの8080ポートを、example.comを通したexample2.comの80ポートに向ける。
$ ssh hoge@example.com -Nf -L 8080:example2.com:80 $ curl localhost:8080 # =&amp;gt; example2.com:80  -N: リモートでコマンドを実行しない -f: バックグラウンドで実行  netstat ネットワークの状態を確認する。
$ netstat -ant Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN ...  -a: non-listening(TCPではESTABLISHED状態)しているソケットだけではなく、listeningしている情報も出す -n: 数値のアドレスで表示する -t: TCPで制限  </description>
    </item>
    
    <item>
      <title>ファイルディスクリプタの上限を増やす</title>
      <link>https://www.sambaiz.net/article/41/</link>
      <pubDate>Thu, 08 Dec 2016 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/41/</guid>
      <description>ファイルディスクリプタとは プロセスの外部とやりとりするための識別子。POSIXではint型で、0がstdin、1がstdout、2がstderrといったもの。 ファイルやデバイスに対するopen()や、 ネットワーク(INETドメインソケット)やホスト内(UNIXドメインソケット)で 通信するためのソケットを生成するsocket()などのシステムコールで生成される。
ファイルディスクリプタの上限 一つのプロセスがリソースを食いつぶさないように 使えるファイルディスクリプタの上限が決まっていて、ulimit -nで確認できる。デフォルトは大体1024。
$ ulimit -n 1024 各プロセスの上限と使っているファイルディスクリプタはこれで確認できる。
$ cat /proc/&amp;lt;プロセスID&amp;gt;/limits ... Max open files 1024 4096 files ... $ ls -l /proc/&amp;lt;プロセスID&amp;gt;/fd webサーバーのように同時にたくさん通信したりすると上限に達してしまい、Too many open filesになってしまうので増やす必要がある。
/etc/security/limits.confで変更する PAM認証時(ログインするときなど)に適用されるので、サーバーの起動時に立ち上がったデーモンには使えない。
$ cat /etc/pam.d/sshd ... session required pam_limits.so ... 全てのユーザー(*)のプロセスが使える ファイルディスクリプタ(nofile)のsoft(ユーザーが設定できる)とhard(rootが設定できる)上限を共に64000にする。
$ echo &amp;quot;* hard nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf $ echo &amp;quot;* soft nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf $ ulimit -n 64000 ulimit -nで変更する シェルと、起動したプロセスで有効。
$ ulimit -n 64000 dockerコンテナでは run時にulimitオプションで --ulimit nofile=11111のように指定することもできる。</description>
    </item>
    
    <item>
      <title>Angular2とangular-cliでTODOを作る</title>
      <link>https://www.sambaiz.net/article/40/</link>
      <pubDate>Mon, 05 Dec 2016 00:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/40/</guid>
      <description>コード: https://github.com/sambaiz/angular2-todo
アプリケーションの作成と立ち上げ angular-cliをインストールしてサーバーを立ち上げるまで。
$ npm install angular-cli -g $ ng -v angular-cli: 1.0.0-beta.21 node: 5.12.0 os: darwin x64 $ ng new mytodo $ cd mytodo $ ng server http://localhost:4200/
新しいコンポーネントを作る 新しいコンポーネントを作る。
$ ng g component todo-list これでtodo-listディレクトリにコンポーネントクラスとテンプレートとCSS、テストとindexが出力される。
また、app.module.ts(BootstrapするRoot Module)にも追加されている。 NgModuleのdeclartionsなどに入っているものは、各Componentで指定しなくても使えるようになる。
import { BrowserModule } from &#39;@angular/platform-browser&#39;; import { NgModule } from &#39;@angular/core&#39;; import { FormsModule } from &#39;@angular/forms&#39;; import { HttpModule } from &#39;@angular/http&#39;; import { AppComponent } from &#39;.</description>
    </item>
    
    <item>
      <title>OpenVPNサーバーPritunlをDockerで動かす</title>
      <link>https://www.sambaiz.net/article/39/</link>
      <pubDate>Fri, 02 Dec 2016 21:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/39/</guid>
      <description>PritunlでVPNサーバーを立てる。
Dockerfileはこんな感じ。
https://hub.docker.com/r/sambaiz/pritunl/
FROM mongo:3.4 # https://docs.pritunl.com/docs/installation RUN echo &#39;deb http://repo.pritunl.com/stable/apt jessie main&#39; &amp;gt; /etc/apt/sources.list.d/pritunl.list &amp;amp;&amp;amp; \ apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 7568D9BB55FF9E5287D586017AE645C0CF8E292A &amp;amp;&amp;amp; \ apt-get --assume-yes update &amp;amp;&amp;amp; \ apt-get --assume-yes upgrade &amp;amp;&amp;amp; \ apt-get --assume-yes install pritunl iptables EXPOSE 80 443 12345/udp CMD mongod --fork --logpath /data/db/mongod.log &amp;amp;&amp;amp; echo &#39;Setup Key:&#39; `pritunl setup-key` &amp;amp;&amp;amp; pritunl start $ docker run -itd -p 80:80 -p 443:443 -p 12345:12345/udp --privileged sambaiz/pritunl $ docker logs &amp;lt;id&amp;gt; .</description>
    </item>
    
    <item>
      <title>aws-sdk-goでs3にput/get</title>
      <link>https://www.sambaiz.net/article/38/</link>
      <pubDate>Wed, 30 Nov 2016 20:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/38/</guid>
      <description>aws-sdk-goでS3にputしてgetする。
package main import ( &amp;quot;bytes&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws/session&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/service/s3&amp;quot; ) const REGION = &amp;quot;ap-northeast-1&amp;quot; const BUCKET_NAME = &amp;quot;faweijojio4f3e4&amp;quot; func main() { sess, err := session.NewSession(aws.NewConfig().WithRegion(REGION)) if err != nil { fmt.Println(err.Error()) return } svc := s3.New(sess) // put data := []byte(&amp;quot;BBBBBB&amp;quot;) key := &amp;quot;AAA.txt&amp;quot; params := &amp;amp;s3.PutObjectInput{ Bucket: aws.String(BUCKET_NAME), Key: aws.String(key), Body: bytes.NewReader(data), ContentLength: aws.Int64(int64(len(data))), ContentType: aws.String(&amp;quot;text/plain&amp;quot;), } if _, err = svc.PutObject(params); err != nil { fmt.Println(err.Error()) return } // bucket list keys := []string{} err = svc.</description>
    </item>
    
    <item>
      <title>Goでstructをリフレクションしてcsvを出力する</title>
      <link>https://www.sambaiz.net/article/37/</link>
      <pubDate>Mon, 28 Nov 2016 21:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/37/</guid>
      <description>こんなstructとデータがあったら、
type Result struct{ Name string `col:&amp;quot;who&amp;quot;` Point int } x := Result{&amp;quot;sam&amp;quot;, 100} フィールド名と、値、タグはrefrectで取れる。
x := Result{&amp;quot;sam&amp;quot;, 100} v := reflect.ValueOf(x) fmt.Println(v.Type().Field(0).Name) // -&amp;gt; Name fmt.Println(v.Type().Field(1).Name) // -&amp;gt; Point fmt.Println(v.Field(0).Interface()) // -&amp;gt; sam fmt.Println(v.Field(1).Interface()) // -&amp;gt; 100 fmt.Println(v.Type().Field(0).Tag.Get(&amp;quot;col&amp;quot;)) // -&amp;gt; who fmt.Println(v.Type().Field(1).Tag.Get(&amp;quot;col&amp;quot;)) // -&amp;gt; これらをencoding/csvで書く。
ただ、引数を[]interface{}にするとinterface{}のスライスしか渡せないので、 一旦interface{}で受け取ってスライスにする。このときにもrefrectを使っている。
package main import ( &amp;quot;encoding/csv&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;os&amp;quot; &amp;quot;reflect&amp;quot; &amp;quot;strings&amp;quot; ) type Result struct { Name string `col:&amp;quot;who&amp;quot;` Point int Age int `col:&amp;quot;-&amp;quot;` // ignore } const COLTAG = &amp;quot;col&amp;quot; func main() { x := []Result{Result{&amp;quot;sam&amp;quot;, 100, 24}, Result{&amp;quot;tom&amp;quot;, 0, 100025}} file, err := os.</description>
    </item>
    
    <item>
      <title>WebVRを動かす</title>
      <link>https://www.sambaiz.net/article/36/</link>
      <pubDate>Wed, 16 Nov 2016 00:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/36/</guid>
      <description>WebVRとは Webブラウザ上でVRアプリケーションを動かすためのAPI。 ヘッドマウントディスプレイの動きを3D空間上の動きに変換してくれる。
WebVR API - Web API インターフェイス | MDN
ただし、まだほとんどのブラウザがVR APIをサポートしていないので、 実際はPolyfillで動かすことになる。
動かしてみる まず、webvr-boilerplateを動かしてみる。
$ npm init $ npm install node-static $ git clone https://github.com/borismus/webvr-boilerplate.git $ cd webvr-boilerplate/ &amp;amp;&amp;amp; npm install &amp;amp; cd .. var static = require(&#39;node-static&#39;); var fileServer = new static.Server(&#39;./webvr-boilerplate&#39;); require(&#39;http&#39;).createServer(function (request, response) { request.addListener(&#39;end&#39;, function () { fileServer.serve(request, response); }).resume(); }).listen(8080); http://localhost:8080
を見ると箱が回っているのが映る。
ただ、start_modeに3を指定してVRモードにしようとしたところ、
http://localhost:8080/index.html?start_mode=3
PCのChromeから見ると
base.js:191 Uncaught (in promise) Error: VRDisplay is not capable of presenting というエラーが出てしまった。</description>
    </item>
    
    <item>
      <title>JVMのヒープ領域とFull GC</title>
      <link>https://www.sambaiz.net/article/35/</link>
      <pubDate>Mon, 14 Nov 2016 23:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/35/</guid>
      <description>ヒープ領域 ヒープ領域というのはメモリ上の動的に確保する領域のこと。 JVMでは、ヒープ領域のNew領域とOld領域、非ヒープ領域のPermanent領域が存在する(した)。
Permanent領域 ロードしたクラスやメソッドが入る。 Java8版のHotspotVM(OracleのJVM)ではMetaspace領域となり、ネイティブメモリに乗るようになったらしい。
New領域 New領域の中はさらに分かれている。
 Eden領域: オブジェクトが作られて最初に配置される。 To領域(Survivor領域1): Edenが一杯になると、EdenとFromから送られる。 From領域(Survivor領域0): Edenが一杯になると、Toから送られる。  Edenが一杯になったときに不要なオブジェクトは破棄、必要なものは領域を移動させるのがScavenge GC。 つまり、Edenが一杯になるたびにToに飛んだオブジェクトはFromと往復し続ける。 ただし、MaxTenuringThresholdの回数を超えるとOld領域に送られることになる。
Old領域 Old領域も一杯になったらどうしようもないのでFull GCが走る。 Full GCでは全ての領域のオブジェクトをチェックして不要なものを探す。 これに集中するので他のことはできなくなり、時間もかかる。 Full GCばかり起きていたらまともに動かないので、 Old領域にまで行かないようにオブジェクトの寿命を短くするか、 ヒープ領域の大きさ(-Xms, -Xmx)を変えたりしてなるべく起きないようにしたい。
どれくらいFull GCしているかどうか -XloggcでGCのログが出せる。-XX:+UseGCLogFileRotationでローテーションしたりもできる。 あと手軽にjpsからのjstat -gc &amp;lt;pid&amp;gt;、あるいはグラフで可視化できるようなやつでヒープ領域の状態を確認する。 jstatの結果の意味はここに書いてある。 例えばFGCがフルGCイベントの数。
参考 JVMとGCのしくみ
Java8のHotSpotVMからPermanent領域が消えた理由とその影響 | ギークを目指して
Java開発の性能改善！ その２ GCログの解析とHeepの設定</description>
    </item>
    
    <item>
      <title>API BlueprintでAPI仕様を書く</title>
      <link>https://www.sambaiz.net/article/34/</link>
      <pubDate>Thu, 10 Nov 2016 00:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/34/</guid>
      <description>API BlueprintというのはAPIの仕様を書くための言語で、 これを元にHTMLのドキュメントにしたり、モックサーバーを立てたりするツールがある。
最初にMetadataとして、API Blueprintのバージョンを書く。
FORMAT: 1A 基本的にはMarkdownのように書ける。
# テストAPI テスト 頭にGroupと書くとグループができる。
# Group echo やまびこ 終わりに[]で囲んでリソースを書く。
## echo [/echo] やっほー アクション。
### echo [POST] 叫ぶ + say (string) - 発声 リクエスト例とレスポンス例はこんな感じ。JSON Schemaを書くこともできる。
+ Request (application/json) { &amp;quot;say&amp;quot;: &amp;quot;yahho&amp;quot; } + Response 200 (application/json) + Headers Hoge: Fuga + Body { &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot; } 全体
FORMAT: 1A # テストAPI テスト # Group echo やまびこ ## echo [/echo] やっほー ### echo [POST] 叫ぶ + say (string) - 発声 + Request (application/json) { &amp;quot;say&amp;quot;: &amp;quot;yahho&amp;quot; } + Response 200 (application/json) + Headers Hoge: Fuga + Body { &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot; } これを使って、aglioでHTMLにしたり、</description>
    </item>
    
    <item>
      <title>logrotateでログをローテーションする</title>
      <link>https://www.sambaiz.net/article/33/</link>
      <pubDate>Wed, 09 Nov 2016 22:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/33/</guid>
      <description>logrusがローテーションする仕組みを持っていなかったので、 READMEに書いてあったlogrotateを使う。/etc/logrotate.dの中に設定ファイルを入れて、cronで回して使う。
FROM ubuntu:14.04 ADD logrotate /etc/logrotate.d/app RUN echo &amp;quot;/usr/sbin/logrotate /etc/logrotate.conf&amp;quot; &amp;gt; /etc/cron.daily/logrotate 設定ファイル(logrotate)はこんな感じ。
/var/log/app.log { daily rotate 4 missingok delaycompress dateext } dailyで1日に1回、rotate 4で過去4日分残し、 missingokでファイルがなくてもエラーにせず、delaycompressで圧縮するのをローテーションした次の回にして、 dateextでローテーションしたファイルの末尾を数字ではなく日付にする。
実際に動かして確かめる。
logrotateを実行すると、/var/lib/logrotate/statusに過去に見た時間が入る。
$ echo &amp;quot;aaaaa&amp;quot; &amp;gt; /var/log/app.log $ logrotate /etc/logrotate.conf $ cat /var/lib/logrotate/status logrotate state -- version 2 ... &amp;quot;/var/log/app.log&amp;quot; 2016-11-9-11:0:0 ... 強制的にローテーションさせてみる。
$ echo &amp;quot;aaaa&amp;quot; &amp;gt; /var/log/app.log $ logrotate -f /etc/logrotate.conf $ ls /var/log | grep app app.log app.log-20161109 $ cat /var/log/app.log-20161109 aaaaa </description>
    </item>
    
    <item>
      <title>td-agentをビルドしてfluentdのバージョンを上げる</title>
      <link>https://www.sambaiz.net/article/32/</link>
      <pubDate>Sun, 06 Nov 2016 11:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/32/</guid>
      <description>$td-agent --version td-agent 0.12.26 td-agentって書いてあるけど、これがfluentdのバージョンらしい。
fluentdはv0.14からナノ秒で時間を持つようになった。 ただ、現行のtd-agent(v2.3.2)は上の通り古いバージョンを使っている。 0.14になるtd-agent-3はまだリリースされていないので、 自分でfluentdをv0.14.8に上げてビルドすることにした。
FROM ubuntu:14.04 WORKDIR /tmp RUN apt-get update &amp;amp;&amp;amp; \ apt-get install -y git software-properties-common build-essential curl &amp;amp;&amp;amp; \ add-apt-repository -y ppa:brightbox/ruby-ng &amp;amp;&amp;amp; \ apt-get update &amp;amp;&amp;amp; \ apt-get install -y ruby2.3 ruby2.3-dev &amp;amp;&amp;amp; \ gem install bundler &amp;amp;&amp;amp; \ git clone https://github.com/treasure-data/omnibus-td-agent WORKDIR /tmp/omnibus-td-agent RUN sed -ie &amp;quot;s/^default_version.*$/default_version &#39;3d1dd53f31d1fe49508f230a71a2b4c2ceb20f47&#39;/&amp;quot; config/software/fluentd.rb &amp;amp;&amp;amp; \ sed -ie &amp;quot;s/^license_file.*$/license_file &#39;LICENSE&#39;/&amp;quot; config/projects/td-agent2.rb &amp;amp;&amp;amp; \ bundle install --binstubs &amp;amp;&amp;amp; \ bin/gem_downloader core_gems.</description>
    </item>
    
    <item>
      <title>d3.jsで折れ線グラフを書くコードを読む</title>
      <link>https://www.sambaiz.net/article/31/</link>
      <pubDate>Thu, 03 Nov 2016 00:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/31/</guid>
      <description>http://bl.ocks.org/mbostock/3883245
CSSと
&amp;lt;style&amp;gt; .axis--x path { display: none; } .line { fill: none; stroke: steelblue; stroke-width: 1.5px; } &amp;lt;/style&amp;gt; グラフを書くsvgとd3.js。
&amp;lt;svg width=&amp;quot;960&amp;quot; height=&amp;quot;500&amp;quot;&amp;gt;&amp;lt;/svg&amp;gt; &amp;lt;script src=&amp;quot;https://d3js.org/d3.v4.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; var svg = d3.select(&amp;quot;svg&amp;quot;), margin = {top: 20, right: 20, bottom: 30, left: 50}, width = +svg.attr(&amp;quot;width&amp;quot;) - margin.left - margin.right, height = +svg.attr(&amp;quot;height&amp;quot;) - margin.top - margin.bottom, g = svg.append(&amp;quot;g&amp;quot;).attr(&amp;quot;transform&amp;quot;, &amp;quot;translate(&amp;quot; + margin.left + &amp;quot;,&amp;quot; + margin.top + &amp;quot;)&amp;quot;); d3.selectでsvg要素を選択。widthとheightを取得したり、中にg(グループ)を入れてtransformでmarginを作っている。
&amp;lt;svg width=&amp;quot;960&amp;quot; height=&amp;quot;500&amp;quot;&amp;gt;&amp;lt;g transform=&amp;quot;translate(50,20)&amp;quot;&amp;gt;&amp;lt;/g&amp;gt;&amp;lt;/svg&amp;gt; svg.</description>
    </item>
    
    <item>
      <title>mp4をエンコードしてMPEG-DASHにして再生する</title>
      <link>https://www.sambaiz.net/article/30/</link>
      <pubDate>Sun, 30 Oct 2016 23:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/30/</guid>
      <description>MPEG-DASHとは HTTPで動画をストリーミングするための規格。似たようなのにAppleの独自規格であるHLSなどがある。
サーバーはMPD(Media Presentation Description)ファイルと、セグメントに分けられた動画や音声ファイルを持っていて、 クライアントはMPDファイルをリクエストし、この内容をもとにセグメントをリクエストしていく。
準備 ffmpegと MP4Boxを使うので、これらを実行できるようにする。 Docker上で実行することもできて、その場合は以下のようにエイリアスを付けると便利。
$ alias ffmpeg=&#39;docker run --rm -v `pwd`:/tmp/workdir jrottenberg/ffmpeg&#39; $ alias MP4Box=&#39;docker run --rm -v `pwd`:/work sambaiz/mp4box&#39; エンコード $ffmpeg -i input.mp4 -vcodec libx264 -vb 448k -r 30 -x264opts no-scenecut -g 15 -acodec libfaac -ac 2 -ab 128k -frag_duration 5000000 -movflags empty_moov output.mp4 オプションの意味は多分こんな感じ。
 -vcodec libx264: 動画をH.264にエンコードする -vb 448k: 動画のビットレート(bps) -r 30: 動画のフレームレート(fps) -x264opts no-scenecut: キーフレームの間隔を動画の内容によらず固定にする -g 15: キープレームの間隔。フレームレート(-r) * フラグメントの時間(-frag_duration) / キーフレームの間隔(-g)が整数になるようにする。 -acodec libfaac: 音声をAACにエンコードする -ac 2: 音声チャンネル数2(ステレオ) -ab 128k: 音声のビットレート(bps) -frag_duration 5000000: フラグメント(セグメント)の時間(μs)。 -movflags empty_moov: 頭にmdat atom(データが含まれる)なしで、moov atom(メタ情報が含まれている)を書き始めるらしい。これにしないとMP4Boxに入れるときに失敗した。  $ MP4Box -info -v input.</description>
    </item>
    
    <item>
      <title>剣を振るVRゲームを作った</title>
      <link>https://www.sambaiz.net/article/29/</link>
      <pubDate>Sun, 30 Oct 2016 19:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/29/</guid>
      <description>プレイ動画
CardboardにAndroidを入れて、
iPhoneをくくりつけた傘を動かすと、画面の剣も動くのでこれで敵を倒すゲーム。
実装 剣(iOS) 剣にくくりつけたiPhoneの傾きの値をUnity(Android)に送信している。 iOSはClassic Bluetoothを自由に使えないので、Androidと通信する場合はBLEを使う。 BLEは通常だと20byteしか一度に送れないので、これを超えないよう注意する必要がある。
BLEで通信するところは
iOS端末をBLEのPeripheralにする
で作ったので、端末の傾きを取得して送るだけ。
import UIKit import CoreMotion class Motion{ let peripheral: BLEPeripheral let accelHandler:CMDeviceMotionHandler let manager = CMMotionManager() public init(peripheral :BLEPeripheral, label :UILabel){ self.peripheral = peripheral accelHandler = { (data: CMDeviceMotion?, error: Error?) -&amp;gt; Void in let str = String(format: &amp;quot;%.1f %.1f %.1f&amp;quot;, arguments: [data!.attitude.pitch * 180 / M_PI, data!.attitude.roll * 180 / M_PI, data!.attitude.yaw * 180 / M_PI] ) let res = peripheral.</description>
    </item>
    
    <item>
      <title>gcloudのアカウント切り替えとkubectlのcontext変更</title>
      <link>https://www.sambaiz.net/article/28/</link>
      <pubDate>Tue, 25 Oct 2016 20:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/28/</guid>
      <description>いつも迷うのでまとめた。
gcloudのアカウント一覧と切り替え $ gcloud auth list $ gcloud config set account `ACCOUNT` configにprojectなども設定している場合はconfig自体を作成して切り替えた方が楽。
$ gcloud config configurations create &amp;lt;name&amp;gt; $ gcloud config configurations activate &amp;lt;name&amp;gt; $ gcloud config list ... Your active configuration is: [&amp;lt;name&amp;gt;] $ gcloud config set account &amp;lt;accout&amp;gt; $ gcloud config set project &amp;lt;project&amp;gt; kubectlのcontext変更 $ kubectl config current-context $ kubectl config view # contexts $ kubectl config use-context minikube </description>
    </item>
    
    <item>
      <title>UnityでAndroidのBLEを使うネイティブプラグインを作る</title>
      <link>https://www.sambaiz.net/article/27/</link>
      <pubDate>Sun, 23 Oct 2016 20:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/27/</guid>
      <description>UnityからBLEを使うためのネイティブプラグインを作る。
Android側 まず、Activityなしのプロジェクトを作って、New ModuleからAndroid Libraryを選択。 これらのパッケージ名がUnityで使うものと被らないようにする。
/Applications/Unity/PlaybackEngines/AndroidPlayer/Variations/mono/Release/Classes/classes.jar をModuleの方のlibsに置く。
import com.unity3d.player.UnityPlayer; このjarは元々のやつとかぶってしまうので除外(build.gradleに追加)
android.libraryVariants.all { variant -&amp;gt; variant.outputs.each { output -&amp;gt; output.packageLibrary.exclude(&#39;libs/classes.jar&#39;) } } ActiviyはUnityPlayer.currentActivityで取得でき、 Unity側のメソッドを呼ぶのも UnityPlayer.UnitySendMessage(mGameObjName, mCallBackName, new String(characteristic.getValue())); のようにできる。
public class BLE { private final static String TAG = BLE.class.getSimpleName(); private static final int REQUEST_ENABLE_BT = 1; private static final int MY_PERMISSION_RESPONSE = 2; private static final String PERIPHERAL_LOCAL_NAME = &amp;quot;my-ble&amp;quot;; private static final UUID PERIPHERAL_SERIVCE_UUID = UUID.fromString(&amp;quot;BF9CB85F-620C-4A67-BDD2-1A64213F74CA&amp;quot;); private static final UUID PERIPHERAL_CHARACTERISTIC_UUID = UUID.</description>
    </item>
    
    <item>
      <title>iOS端末をBLEのPeripheralにする</title>
      <link>https://www.sambaiz.net/article/26/</link>
      <pubDate>Sun, 23 Oct 2016 01:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/26/</guid>
      <description>CoreBluetoothプログラミングガイド
流れ まず、CoreBluetooth.frameworkを追加する。
import CoreBluetooth CBPeripheralManagerを生成。
peripheralManager = CBPeripheralManager(delegate: self, queue: nil) stateが変化したらdelegateメソッドが呼ばれるので.poweredOnであることを確認できれば Managerの準備は完了。
public func peripheralManagerDidUpdateState(_ peripheral: CBPeripheralManager){ switch (peripheral.state){ case .poweredOn: print(&amp;quot;PeripheralManager state is ok&amp;quot;) ready = true default: print(&amp;quot;PeripheralManager state is ng:&amp;quot;, peripheral.state) ready = false } } Characteristicを作成。CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify)で、 Centralが読みにくることも、通知を受け取ることもできるようにし、CBAttributePermissions.readableでreadのみ許可する。 このvalueをnilにしておかないと、キャッシュされあとで変更できなくなる。
characteristic = CBMutableCharacteristic( type: CHARACTERISTIC_UUID, properties: CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify), value:nil, permissions:CBAttributePermissions.readable) このCharacteristicのServiceを作成し、Managerに登録する。
let service = CBMutableService(type: SERVICE_UUID, primary: true) service.characteristics = [characteristic] peripheralManager!.add(service) ready = true public func peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?</description>
    </item>
    
    <item>
      <title>android-BluetoothLeGattを読む</title>
      <link>https://www.sambaiz.net/article/25/</link>
      <pubDate>Fri, 21 Oct 2016 14:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/25/</guid>
      <description>BLEのサンプルコード。
https://github.com/googlesamples/android-BluetoothLeGatt
DeviceScanActivity BLEをサポートしているかチェックする。 BluetoothChatではBluetoothAdapterを取得するのに BluetoothAdapter.getDefaultAdapter()のようにしていたが、 BLEをサポートしているような新しいバージョンでは、BluetoothManagerのgetAdapter()を使うらしい。
@Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); getActionBar().setTitle(R.string.title_devices); mHandler = new Handler(); // Use this check to determine whether BLE is supported on the device. Then you can // selectively disable BLE-related features. if (!getPackageManager().hasSystemFeature(PackageManager.FEATURE_BLUETOOTH_LE)) { Toast.makeText(this, R.string.ble_not_supported, Toast.LENGTH_SHORT).show(); finish(); } // Initializes a Bluetooth adapter. For API level 18 and above, get a reference to // BluetoothAdapter through BluetoothManager. final BluetoothManager bluetoothManager = (BluetoothManager) getSystemService(Context.</description>
    </item>
    
    <item>
      <title>PackerでAMIを作る</title>
      <link>https://www.sambaiz.net/article/24/</link>
      <pubDate>Tue, 18 Oct 2016 22:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/24/</guid>
      <description>https://www.packer.io/
いろんなプラットフォームのイメージを作ることができるツール。 これでfluentdのログサーバーのAMIを作る。
$ brew install packer # mac $ packer -v 0.10.1 設定ファイルはこんな感じ。variablesの値は{{user ... }}のところで使われる。 buildersに作るイメージの情報を書いて、provisionersで環境を作る。
provisionersにはchefやansibleなども指定できるが、 継ぎ足し継ぎ足しで秘伝のタレ化したAMIも最初は、コマンドいくつか実行するだけなのでとりあえず手作業で作った、後でなんとかするなんてものもあったりして、 そういうものは無理にchefなどで始めず、手軽にshellでpacker buildするといいと思う。 手作業よりも楽だしソースが別にあるので使われていないAMIを消すのも簡単。
fileではpermissionがないところに置くことができないので、一旦置いてshellで移動する。
{ &amp;quot;variables&amp;quot;: { &amp;quot;aws_access_key&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;aws_secret_key&amp;quot;: &amp;quot;&amp;quot; }, &amp;quot;builders&amp;quot;: [{ &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;, &amp;quot;access_key&amp;quot;: &amp;quot;{{user `aws_access_key`}}&amp;quot;, &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `aws_secret_key`}}&amp;quot;, &amp;quot;region&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;, &amp;quot;source_ami&amp;quot;: &amp;quot;ami-1a15c77b&amp;quot;, &amp;quot;instance_type&amp;quot;: &amp;quot;t2.small&amp;quot;, &amp;quot;ssh_username&amp;quot;: &amp;quot;ec2-user&amp;quot;, &amp;quot;ami_name&amp;quot;: &amp;quot;fluentd-logserver {{timestamp}}&amp;quot; }], &amp;quot;provisioners&amp;quot;: [{ &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;, &amp;quot;source&amp;quot;: &amp;quot;td-agent.conf&amp;quot;, &amp;quot;destination&amp;quot;: &amp;quot;/home/ec2-user/td-agent.conf&amp;quot; }, { &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;, &amp;quot;inline&amp;quot;: [ &amp;quot;curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh&amp;quot;, &amp;quot;sudo mv /home/ec2-user/td-agent.</description>
    </item>
    
    <item>
      <title>android-bluetoothChatを読む</title>
      <link>https://www.sambaiz.net/article/23/</link>
      <pubDate>Sat, 15 Oct 2016 14:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/23/</guid>
      <description>Classic Bluetoothのサンプルコード。
https://github.com/googlesamples/android-BluetoothChat
MainActivity まず、MainActivity。
Fragmentのcommitや、
@Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); if (savedInstanceState == null) { FragmentTransaction transaction = getSupportFragmentManager().beginTransaction(); BluetoothChatFragment fragment = new BluetoothChatFragment(); transaction.replace(R.id.sample_content_fragment, fragment); transaction.commit(); } } オプションメニューの設定をしている。
// 最初だけ呼ばれる @Override public boolean onCreateOptionsMenu(Menu menu) { getMenuInflater().inflate(R.menu.main, menu); return true; } // 表示される度に呼ばれる @Override public boolean onPrepareOptionsMenu(Menu menu) { MenuItem logToggle = menu.findItem(R.id.menu_toggle_log); logToggle.setVisible(findViewById(R.id.sample_output) instanceof ViewAnimator); logToggle.setTitle(mLogShown ? R.string.sample_hide_log : R.string.sample_show_log); return super.onPrepareOptionsMenu(menu); } @Override public boolean onOptionsItemSelected(MenuItem item) { switch(item.</description>
    </item>
    
    <item>
      <title>静的ウェブサイトエンジンHugoに乗り換えた</title>
      <link>https://www.sambaiz.net/article/22/</link>
      <pubDate>Tue, 04 Oct 2016 22:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/22/</guid>
      <description>https://gohugo.io/
今までこのサイトはフロントのReactからLambda &amp;amp; API Gatewayで作った記事APIを呼ぶ構成になっていた。
ホームページ作った
当初はページの描画をフロントに任せることで、 サーバーレス (記事の情報をjsonで渡すAPI Gatewayと、S3の組み合わせ) で作れると思っていたが、結果そんなに甘くはなく、サーバーサイドレンダリングするはめになる。 最初からレンダリングしたものを置いておけばいいと思った。
webpack環境でredux&amp;amp;react-routerのページをサーバーサイドレンダリングする
そんなこんなでHugoに乗り換えることにした。 記事はmarkdownで管理していたので、これにメタ情報を加えるだけで移行できた。 タグで絞り込むこともできるようになったので良いと思う。 また、静的なページになったのでgithub pagesに置けるようにもなった。</description>
    </item>
    
    <item>
      <title>DeepDreaming with TensorFlowをやる(2)</title>
      <link>https://www.sambaiz.net/article/21/</link>
      <pubDate>Sat, 10 Sep 2016 14:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/21/</guid>
      <description>前回の続き。
Multiscale image generation 様々なスケールで勾配上昇させる。小さなスケールで上昇させたものをより大きなスケールでさらに上昇させていく。 ただ、壁紙のようなサイズを生成するような場合にそれを行うと、GPUのメモリを食いつぶしてしまう。 これを避けるために、画像を小さなタイルに分割し、それぞれ独立に勾配を計算する。 また、毎回画像をランダムにシフトしていくことで、タイルに見えることを避け、画像全体の品質を向上させる。
def tffunc(*argtypes): &#39;&#39;&#39;Helper that transforms TF-graph generating function into a regular one. See &amp;quot;resize&amp;quot; function below. &#39;&#39;&#39; placeholders = list(map(tf.placeholder, argtypes)) def wrap(f): out = f(*placeholders) def wrapper(*args, **kw): return out.eval(dict(zip(placeholders, args)), session=kw.get(&#39;session&#39;)) return wrapper return wrap # Helper function that uses TF to resize an image def resize(img, size): img = tf.expand_dims(img, 0) return tf.image.resize_bilinear(img, size)[0,:,:,:] resize = tffunc(np.float32, np.int32)(resize) def calc_grad_tiled(img, t_grad, tile_size=512): &#39;&#39;&#39;Compute the value of tensor t_grad over the image in a tiled way.</description>
    </item>
    
    <item>
      <title>DeepDreaming with Tensorflowをやる(1)</title>
      <link>https://www.sambaiz.net/article/20/</link>
      <pubDate>Wed, 07 Sep 2016 01:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/20/</guid>
      <description>https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb
例の通りまとめながら進めていく。
 このノートブックは、畳み込みニューラルネットワークによる画像生成の手法を説明するものだ。 ネットワークは入力画像へ変換させる配列のレイヤーの集合から成り立っている。 変換のパラメータは勾配降下法で変形しながら学習していく。 内部的な画像の表現は意味不明なように見えるが、可視化し、解釈することができる。
Loading and displaying the model graph 学習済みネットワークのprotobufファイルが用意されていて、これをダウンロードして使う。 ただgcr.io/tensorflow/tensorflowにwgetもunzipも入っていなかったので、中に入ってapt-getした。
model_fn = &#39;tensorflow_inception_graph.pb&#39; # creating TensorFlow session and loading the model graph = tf.Graph() sess = tf.InteractiveSession(graph=graph) with tf.gfile.FastGFile(model_fn, &#39;rb&#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) t_input = tf.placeholder(np.float32, name=&#39;input&#39;) # define the input tensor imagenet_mean = 117.0 t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0) tf.import_graph_def(graph_def, {&#39;input&#39;:t_preprocessed}) tf.gfile.FastGFileのドキュメントが見つからないので ソース を探したところFile I/Oのラッパーのようだ。これでprotobufファイルを読み、ParseFromStringでGraphDefにする。
さらにこれと入力データをtf.import_graph_defに 渡すことでGraphに取り込む。
tf.expand_dimsは値が1の次元を指定の場所に挿入する もの。なんでそんなことをしたり、imagenet_meanを引いているのかは説明がなかった。
layers = [op.name for op in graph.</description>
    </item>
    
    <item>
      <title>Grafana/InfluxDB/Fluentdでログを可視化する</title>
      <link>https://www.sambaiz.net/article/19/</link>
      <pubDate>Wed, 31 Aug 2016 20:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/19/</guid>
      <description>コードはここ。
InfluxDB Golangで書かれた時系列データベース。今回使うのはv0.13。前のバージョンと結構違うので注意。
デフォルトでは無効になっている認証を有効にするために設定ファイルを編集して設置する。
$ brew install influxdb # OSX $ influxd config &amp;gt; influxdb.conf [http] ... auth-enabled = true ... FROM influxdb:0.13 VOLUME /var/lib/influxdb ADD influxdb.conf / ENV INFLUXDB_CONFIG_PATH /influxdb.conf $ docker run -p 8083:8083 -p 8086:8086 myinfluxdb influxdコマンドや :8083のWebインタフェースの他に :8086にHTTP APIが用意されている。
$ curl -i -XPOST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE USER root WITH PASSWORD &#39;root&#39; WITH ALL PRIVILEGES&amp;quot; $ curl -i -XPOST http://localhost:8086/query -u root:root --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot; {&amp;quot;results&amp;quot;:[{}]} # Line Protocol(https://docs.</description>
    </item>
    
    <item>
      <title>GKEで複数コンテナのアプリケーションを動かす</title>
      <link>https://www.sambaiz.net/article/18/</link>
      <pubDate>Fri, 26 Aug 2016 21:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/18/</guid>
      <description>前回は単一コンテナのアプリケーションを動かしたが、今回はコンテナ間でやり取りが発生するものを動かす。 流れとしては、クライアントからのリクエストをGATEWAYサーバーで受け取り、SERVICEサーバーにリクエストし、その結果を返すまで。
プログラムは以下の通り、環境変数TYPEの値によって挙動を変えていて、同じイメージを使い回す。コードはここ。
var http = require(&#39;http&#39;); var handleRequest = function(request, response) { if(process.env.TYPE == &amp;quot;GATEWAY&amp;quot;){ console.log(&#39;Passed.&#39;); var options = { host: &#39;service&#39;, port: 8080, method: &#39;GET&#39; }; var req = http.request(options, function(res) { data = &amp;quot;&amp;quot; res.on(&#39;data&#39;, function (chunk) { data+=chunk; }); res.on(&#39;end&#39;, () =&amp;gt; { response.writeHead(200); response.end(data); }); }); req.on(&#39;error&#39;, function(e) { response.writeHead(500) response.end(e.message); }); req.end(); }else{ console.log(&#39;Received.&#39;); response.writeHead(200); response.end(&#39;ok&#39;); } }; var www = http.createServer(handleRequest); www.listen(8080); これをContainer RegistryにPushする。</description>
    </item>
    
    <item>
      <title>Google Container Engine(GKE)で単一コンテナのアプリケーションを動かす</title>
      <link>https://www.sambaiz.net/article/17/</link>
      <pubDate>Sun, 21 Aug 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/17/</guid>
      <description>Kubernetes - Hello World Walkthrough
CloudSDKとkubectlのインストール Cloud SDKをインストールしてgloudコマンドを使えるようにする。
$ gcloud --version Google Cloud SDK 122.0.0 $ gcloud components install kubectl Google Container RegistryにPush $ export PROJECT_ID=&amp;quot;******&amp;quot; $ docker build -t gcr.io/$PROJECT_ID/test:v1 . $ gcloud docker push gcr.io/$PROJECT_ID/test:v1 プロジェクトの課金を有効にしていないとこんなエラーメッセージが出る。
denied: Unable to create the repository, please check that you have access to do so. Clusterの作成 $ gcloud config set core/project $PROJECT_ID $ gcloud config set compute/zone asia-east1-b $ gcloud container clusters create test-cluster $ gcloud config set container/cluster test-cluster Container Engine APIが有効になっていない場合はこうなる。 一度コンソールからContainer Engineを選ぶと、サービスの準備が始まって有効になる。</description>
    </item>
    
    <item>
      <title>JenkinsのMultiple SCMs PluginからPipeline Pluginへの移行</title>
      <link>https://www.sambaiz.net/article/16/</link>
      <pubDate>Sat, 20 Aug 2016 16:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/16/</guid>
      <description>Jenkins環境を作り直すことになり、 長らく使ってきたMultiple SCMs PluginがDeprecatedなので、 Pipeline Pluginに移行することにした。
プラグインをインストールすると、ジョブ作成時にPipelineを選択できるようになる。 Pipeline scriptの複数リポジトリを指定するところはこんな感じ。
node { stage &#39;Checkout rep1&#39; git([url: &#39;git@rep1.git&#39;, branch: REP1_BRANCH]) stage &#39;Checkout rep2&#39; dir(&#39;rep2&#39;) { git([url: &#39;git@rep2.git&#39;, branch: REP2_BRANCH]) } stage &#39;Checkout rep3&#39; dir(&#39;subdir3/rep3&#39;) { git([url: &#39;git@rep3.git&#39;, branch: REP3_BRANCH]) } stage &#39;Build&#39; ... } まとめて入ったPipeline Stage View Pluginによって、 経過や変更などいろいろ見やすくなった。</description>
    </item>
    
    <item>
      <title>GolangでAPIとテストを書く(echo/dbr/glide/goose/mock)</title>
      <link>https://www.sambaiz.net/article/15/</link>
      <pubDate>Mon, 15 Aug 2016 04:07:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/15/</guid>
      <description>以下の記事を参考にして簡単なAPIとそのテストを書いてみた。コードはここ。
Go言語でTestableなWebアプリケーションを目指して｜サイバーエージェント 公式エンジニアブログ
使った主なライブラリ・ツール echo webフレームワーク。速いらしい。
$ go get -u github.com/labstack/echo func main() { conn, err := dbr.Open(&amp;quot;mysql&amp;quot;, &amp;quot;root:@tcp(localhost:3306)/mboard&amp;quot;, nil) if err != nil { panic(err) } conn.SetMaxIdleConns(200) conn.SetMaxOpenConns(200) e := echo.New() // middlewares e.Use(middleware.Logger()) e.Use(middleware.Recover()) e.Use(middleware.CORSWithConfig(middleware.CORSConfig{ AllowOrigins: []string{&amp;quot;*&amp;quot;}, AllowMethods: []string{echo.GET, echo.PUT, echo.POST, echo.DELETE}, })) // endpoints e.GET(&amp;quot;/&amp;quot;, func(c echo.Context) error { return c.String(http.StatusOK, &amp;quot;Hello, World!&amp;quot;) }) e.GET(&amp;quot;/messages&amp;quot;, func(c echo.Context) error { return handler.NewMessageWithSession(conn.NewSession(nil)).GetMessages(c) }) e.POST(&amp;quot;/messages&amp;quot;, func(c echo.Context) error { return handler.</description>
    </item>
    
    <item>
      <title>O&#39;Reillyの「マイクロサービスアーキテクチャ」を読んだ</title>
      <link>https://www.sambaiz.net/article/14/</link>
      <pubDate>Sat, 06 Aug 2016 18:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/14/</guid>
      <description>O&amp;rsquo;Reilly Japan - マイクロサービスアーキテクチャ
設計、開発、テストや監視など一通りまとまっているマイクロサービスアーキテクチャの本。
マイクロサービスアーキテクチャというのは、協調して動作する小規模で自律的なサービスでシステムを構成するもので、 一般的なモノリシック(一枚岩)システムのモジュールのように独立したサービスを作っていく。 自律的というのは、他には何も変更せずに、単独でサービスの変更やデプロイを行えるということ。
メリットとしては
 サービスごとに異なる技術を使うことができる 一部のサービスで障害が発生しても、機能低下させて稼働し続けるシステムを構築できる 性能を高める必要があるサービスだけをスケールでき、効率的にリソースを使うことができる デプロイのリスクを最小限に抑えることができるため、迅速に行うことができる レガシーなコードを捨て去る障壁が低い  などが挙げられていた。
正しくサービスを切り分けるにはドメインの理解が必要で、「境界づけられたコンテキスト」が1つのサービスとなるようにする。 そのため、最初はモノシリックに進めることも推奨されていた。
 特に初めてのドメインでは、システムをマイクロサービスに分解するのが時期尚早だとコストがかかってしまう場合があります。いろいろな意味で、マイクロサービスに分解したい既存のコードベースがある方が、最初からマイクロサービスに取り組むよりもはるかに簡単です (3.3.3)
 実現する上で、DBの扱いが難しいと思った。 サービス間のDBの共有はスキーマの変更に弱く、技術の縛りが発生してしまうので避けなければならない。 一方で、DBを分割すると1つのトランザクションで完結しなくなり、どのように整合性を保っていくか。 そんな話が5章に書いてあって、いくつか方法は挙げられているが、いずれにせよ何かしらの制御をしなくてはいけないし、 データの取得の上でも一つのデータベースにあったほうが便利だったりする。 サービスの単位がデータに引きずられてしまうと、マイクロサービスとはいえないものが出来上がりそうだ。 きれいに分けられればいいけど実際どうなんだろう。
すぐにマイクロサービスを採用するかは別としても、考え方として活かせそうなことが多かった。 実際にやってみて、また読み返して自分のものにしていこうと思う。</description>
    </item>
    
    <item>
      <title>Tensorflowの学習データを使ったAPIを作る</title>
      <link>https://www.sambaiz.net/article/13/</link>
      <pubDate>Fri, 05 Aug 2016 22:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/13/</guid>
      <description>チュートリアルのMNISTの学習データを使って、手書き数字画像のデータを受け取り、数字を返すAPIを作る。 コードはここにある。
学習して結果を保存する 前回の学習結果のcheckpointファイルを出力する。 tf.train.Saver().saveでnameで対応するVariableの値が保存できる。 また、その際デフォルトでMetaGraphもexportされ、これをimportすればGraphも復元することができる。
import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data class Mnist: def __init__(self): g = tf.Graph() with g.as_default(): W_conv1 = self._weight_variable([5, 5, 1, 32], &amp;quot;W_conv1&amp;quot;) b_conv1 = self._bias_variable([32], &amp;quot;b_conv1&amp;quot;) self._x = tf.placeholder(tf.float32, [None, 784]) x_image = tf.reshape(self._x, [-1,28,28,1]) h_conv1 = tf.nn.relu(self._conv2d(x_image, W_conv1) + b_conv1) h_pool1 = self._max_pool_2x2(h_conv1) W_conv2 = self._weight_variable([5, 5, 32, 64], &amp;quot;W_conv2&amp;quot;) b_conv2 = self._bias_variable([64], &amp;quot;b_conv2&amp;quot;) h_conv2 = tf.nn.relu(self._conv2d(h_pool1, W_conv2) + b_conv2) h_pool2 = self.</description>
    </item>
    
    <item>
      <title>Googleが作ったRPCフレームワークgRPCを使ってみた</title>
      <link>https://www.sambaiz.net/article/12/</link>
      <pubDate>Fri, 29 Jul 2016 22:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/12/</guid>
      <description>A high performance, open source, general RPC framework that puts mobile and HTTP/2 first.
 What is gRPC? gRPCを使うと、クライアントアプリケーションは直接ローカルのオブジェクトのように、他のマシンのサーバーアプリケーションのメソッドを呼ぶことができ、 分散したアプリケーションやサービスを簡単に作ることができる。 多くのRPCシステムと同様にgRPCはサービスを定義し、リモートから呼べるメソッドとそのパラメーターおよび返り値の型を記述するようになっている。 サーバーサイドではインタフェースを実装し、クライアントからの呼び出しをハンドリングするgRPCサーバーを実行する。 クライアントサイドではサーバーと同じメソッドを提供するスタブを持っている。
gRPCクライアントとサーバーは様々な環境同士でやり取りすることができ、いくつもの言語でサポートされている。 そのため例えば、gRPCサーバーをJavaでクライアントをGoやPython、Rubyで作るのも可能だ。 加えて、最新のGoodle APIにはgRPCのインタフェースが存在するので、これらをアプリケーションに組み込むのも容易にできる。
Protobuf デフォルトではgRPCはprotobuf(protocol buffers)でやり取りする。 protobufというのは、 Googleによるオープンソースのシリアライズフォーマット。
今回作るのは、同じ文字列を返すだけのEchoサーバーで、コードはここにある。 以下のprotoファイルでは、EchoというサービスはRetEchoというメソッドを含み、 これは文字列sayを含むEchoRequestに対して、文字列retを含むEchoReplyを返すということを表している。
syntax = &amp;quot;proto3&amp;quot;; option java_package = &amp;quot;net.sambaiz.trygrpc.protos&amp;quot;; package protos; service Echo { rpc RetEcho (EchoRequest) returns (EchoReply) {} } message EchoRequest { string say = 1; } message EchoReply { string ret = 1; } これをprotocでコンパイルするとecho.</description>
    </item>
    
    <item>
      <title>MySQLで大文字小文字を区別しないのを直す</title>
      <link>https://www.sambaiz.net/article/11/</link>
      <pubDate>Sun, 24 Jul 2016 22:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/11/</guid>
      <description>Collationの話。
MySQL 5.6 CREATE TABLE sample ( id SERIAL, name VARCHAR(30) ) ENGINE=InnoDB CHARACTER SET utf8mb4; INSERT INTO sample (name) VALUES (&#39;tom&#39;),(&#39;Tom&#39;),(&#39;TOM&#39;); このテーブルを&amp;quot;tom&amp;quot;で絞り込むとこうなる。大文字小文字を区別していない。
mysql&amp;gt; SELECT * FROM sample2 WHERE name = &#39;tom&#39;; +----+------+ | id | name | +----+------+ | 1 | tom | | 2 | Tom | | 3 | TOM | +----+------+ 3 rows in set (0.01 sec) MySQL :: MySQL 5.6 リファレンスマニュアル :: B.5.5.1 文字列検索での大文字/小文字の区別
 単純な比較操作 (&amp;gt;=、&amp;gt;、=、&amp;lt;、&amp;lt;=、ソート、およびグループ化) は、各文字の「ソート値」に基づきます。 同じソート値を持つ文字は同じ文字として扱われます。たとえば、「e」 と 「é」 が対象の照合順序で同じソート値を持つ場合は、等しいと判断されます。</description>
    </item>
    
    <item>
      <title>グラフデータベースNeo4jを触ってみた</title>
      <link>https://www.sambaiz.net/article/10/</link>
      <pubDate>Thu, 21 Jul 2016 09:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/10/</guid>
      <description>社内勉強会でオープンソースの グラフデータベースNeo4jが紹介されていたので触ってみた。
What is a Graph Database? つながりも含めたグラフとしてデータを扱うデータベース。 データセットのサイズによらず、複雑なつながりや、クエリをうまく扱える。 無数のデータの中から、関係ないデータを見ることなく多数のノードとつながりからなる必要なデータだけを取れる。
インストール ここからCommunity Editionを選んで OSごとに用意されている実行ファイルをダウンロードしてくる。 ファイルを実行し、Startを押すとブラウザで開けるようになる。
グラフ グラフは以下の要素から構成される。
 Node: データそのもので、まとめるためのラベルを複数付けられる Relationships: typeを持つ、Nodeのつながり Properties: NodeやRelationshipsが持てるkey-valueの値  Cypher Neo4jで使うクエリ言語。
まずはCREATE文でNodeを作る。Personはラベルだ。
CREATE (ee:Person { name: &amp;quot;Emil&amp;quot;, from: &amp;quot;Sweden&amp;quot;, klout: 99 }) CREATE文では使われていなかった謎のeeだが、MATCH文を見るとデータが格納される変数だということがわかる。 このeeは次のCREATE文でも参照できて、(ee)-[:KNOWS {since: 2001}]-&amp;gt;(js)で 作ったNodeとのRelationshipsを張るのに使っている。
MATCH (ee:Person) WHERE ee.name = &amp;quot;Emil&amp;quot; RETURN ee; CREATE (js:Person { name: &amp;quot;Johan&amp;quot;, from: &amp;quot;Sweden&amp;quot;, learn: &amp;quot;surfing&amp;quot; }), (ir:Person { name: &amp;quot;Ian&amp;quot;, from: &amp;quot;England&amp;quot;, title: &amp;quot;author&amp;quot; }), (rvb:Person { name: &amp;quot;Rik&amp;quot;, from: &amp;quot;Belgium&amp;quot;, pet: &amp;quot;Orval&amp;quot; }), (ally:Person { name: &amp;quot;Allison&amp;quot;, from: &amp;quot;California&amp;quot;, hobby: &amp;quot;surfing&amp;quot; }), (ee)-[:KNOWS {since: 2001}]-&amp;gt;(js),(ee)-[:KNOWS {rating: 5}]-&amp;gt;(ir), (js)-[:KNOWS]-&amp;gt;(ir),(js)-[:KNOWS]-&amp;gt;(rvb), (ir)-[:KNOWS]-&amp;gt;(js),(ir)-[:KNOWS]-&amp;gt;(ally), (rvb)-[:KNOWS]-&amp;gt;(ally) 以下のようにパターンマッチもできる。この例だとEmilの友達が取得できる。</description>
    </item>
    
    <item>
      <title>Kubernetesのチュートリアルをたどる</title>
      <link>https://www.sambaiz.net/article/9/</link>
      <pubDate>Mon, 18 Jul 2016 22:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/9/</guid>
      <description>Kubernetesとは Kubernetes(発音はkoo-ber-nay&amp;rsquo;-tace。 ギリシャ語で操舵手。)はGoogleによって開発が始められた、アプリケーションコンテナにおける自動デプロイ、スケーリング、操作を 自動化するOSS。K8sと略される。
Minikube K8sをローカルで試すために、MinikubeというVMの中で単一ノードのK8sクラスターを動かすツールを入れる。
v0.6.0
curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.6.0/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/ $ minikube start Starting local Kubernetes cluster... ... $ kubectl version Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;2&amp;quot;, GitVersion:&amp;quot;v1.2.4&amp;quot;, GitCommit:&amp;quot;3eed1e3be6848b877ff80a93da3785d9034d0a4f&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;3&amp;quot;, GitVersion:&amp;quot;v1.3.0&amp;quot;, GitCommit:&amp;quot;283137936a498aed572ee22af6774b6fb6e9fd94&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} Pods K8sではコンテナのグループをpodと呼ぶ。pod中のコンテナは共にデプロイされ、起動し、停止する。 また、グループとして複製される。
Podの定義は次のようにyamlで書かれる。
apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 Podの定義に望ましい状態を記述すると、Kubernatesはそれを見て現在の状態が一致しているかどうか確認する。 例えば、Podが作られたときに、コンテナがその中で動いている状態が望ましい状態だとすると、 コンテナが動かなくなったときに、Kubernatesは新しいものを再作成することで望ましい状態にする。</description>
    </item>
    
    <item>
      <title>Node.jsのバージョン管理</title>
      <link>https://www.sambaiz.net/article/8/</link>
      <pubDate>Fri, 15 Jul 2016 19:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/8/</guid>
      <description>n nodeが必要だけど手軽。
n latest, n stable, n ltsでバージョンが切り替わる。 バージョンを指定する場合、n &amp;lt;version&amp;gt;でインストールし、nでインストールされているバージョンの一覧から選択できる。 バージョンの削除はn - &amp;lt;version&amp;gt;。
$ npm install -g n $ n stable $ node -v v6.2.2 nvm nodeが必要ない。
$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.1/install.sh | bash $ nvm install node $ node -v v7.7.2 $ nvm install 6 $ node -v v6.10.0 $ nvm ls v6.10.0 -&amp;gt; v7.7.2 default -&amp;gt; node (-&amp;gt; v7.7.2) node -&amp;gt; stable (-&amp;gt; v7.7.2) (default) stable -&amp;gt; 7.7 (-&amp;gt; v7.</description>
    </item>
    
    <item>
      <title>Docker公式ドキュメント&#34;network コマンドを使う&#34;を読む</title>
      <link>https://www.sambaiz.net/article/7/</link>
      <pubDate>Fri, 15 Jul 2016 00:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/7/</guid>
      <description>Docker version 1.12.0-rc2 公式ドキュメントnetwork コマンドを使う の内容をまとめてみた。
dockerには3つのデフォルトネットワークが存在する。docker run時に--netオプションでネットワークを指定しない限り、 docker0として表示されるbridgeネットワークにコンテナを接続する。
$ docker network ls NETWORK ID NAME DRIVER SCOPE a3b712537566 bridge bridge local f6d86cb54edd host host local 33cb30b024d9 none null local ただし、後方互換性を維持するため、デフォルトのbridgeネットワークでは自動的に名前解決が行われない。
これらのネットワークとは別にユーザー定義のネットワークを作成することもできる。 単一ホストのbridgeネットワークと、複数ホストにまたがるoverlayネットワークから選択でき、 何も指定しなかったらbridgeになる。subnetを指定しなければ、 dockerデーモンがネットワークに対してサブネットを自動的に割り当てるが、 dockerが管理していないサブネットと重複するのを避けるために指定することが推奨されている。
$ docker network create -d bridge --subnet 172.25.0.0/16 isolated_nw $ docker network inspect isolated_nw $ docker network rm isolated_nw # 削除 docker network inspectで以下のようなネットワークの情報が得られる。
[ { &amp;quot;Name&amp;quot;: &amp;quot;isolated_nw&amp;quot;, &amp;quot;Id&amp;quot;: &amp;quot;c81547cf7ed897054ea645192c6c47dcf7a248e77bc8067609becab5330e417d&amp;quot;, &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;, &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;, &amp;quot;EnableIPv6&amp;quot;: false, &amp;quot;IPAM&amp;quot;: { &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;Options&amp;quot;: {}, &amp;quot;Config&amp;quot;: [ { &amp;quot;Subnet&amp;quot;: &amp;quot;172.</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアル2(Deep MNIST for Experts)</title>
      <link>https://www.sambaiz.net/article/6/</link>
      <pubDate>Tue, 12 Jul 2016 21:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/6/</guid>
      <description>前回に引き続き、まとめながら進めていく。
Deep MNIST for Experts
Start TensorFlow InteractiveSession 今回は、前回のようにグラフを作成してからSessionを開始する代わりに InteractiveSessionを使う。 グラフを作成し実行するのをインタラクティブに行うことができ、IPythonのような環境で便利だ。
import tensorflow as tf sess = tf.InteractiveSession() Build a Multilayer Convolutional Network 前回のシンプルなモデルではあまり良い結果が出なかった。 そこで、今回はもう少し良いモデルの畳み込みニューラルネットワークを作成する。
Weight Initialization 勾配が0になるのを避けるために重みの初期化時にノイズを付ける。 tf.truncated_normalは正規分布で、μ±2σ範囲内のランダムな値を返す。 以下の例だと、meanのデフォルトが0.0なので、正規分布 N(0, 0.01)の、-0.2&amp;lt;=x&amp;lt;=0.2な値がランダムに返ることになる。
また、ReLU(Rectified Linear Unit, 正規化線形関数)ニューロンを使うので、&amp;ldquo;死んだニューロン&amp;quot;を避けるために、バイアスは小さな正の値で初期化する。
ニューラルネットワークと活性化関数 - sambaiz-net
def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) Convolution and Pooling TensorFlowに畳み込みとプーリングの関数が用意されている。
畳み込みというのは、画像に対してフィルターを少しずつ動かしながら掛けていく処理のこと。このページが分かりやすい。 例えば、ソーベルフィルタで輪郭になっているところを抽出するように、 フィルターの値によって、その区域における、ある特徴を際立たせたりすることができる。 今回はこのフィルターが重みとなり、際立たせたいのはその数字を識別するための特徴ということになる。 前回は画像を一次元の配列として扱い重みを学習していたので、縦の情報が失われていたが、この方法ではそれがない。
プーリングというのは画像から区域ごとにサンプリングする処理のこと。最大プーリングや、平均プーリングなどの手法がある。 畳み込みのように順番に区域を見ていって、最大プーリングならそのうちの最大のものを採用し、他のものは無視する。 サイズが小さくなるだけではなく、ちょっとした位置のずれを吸収することができる。
def conv2d(x, W): return tf.</description>
    </item>
    
    <item>
      <title>webpack環境でredux&amp;react-routerのページをサーバーサイドレンダリングする</title>
      <link>https://www.sambaiz.net/article/5/</link>
      <pubDate>Sun, 10 Jul 2016 03:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/5/</guid>
      <description>このページをGoogleのSearch Consoleからクローラーがちゃんと見ているか確認してみたら、 なぜか真っ白のページが表示されていた・・・。とりあえずサーバーサイドレンダリングしてみることにした。 コードはgithubに上げてある。
サーバーサイドとはいえ、css-loaderでcss moduleを使っているのでwebpackを使う必要があった。 まず、そのままのwebpackの設定で作ったものをserver.jsから呼ぶとエラーが出た。
***/sambaiz-net/web/public/bundle.js:20933 module.exports = self.fetch.bind(self); ReferenceError: self is not defined そこで、targetをnodeにしたサーバーサイド用にwebpackの設定を作成し、実行してみたところ
module.exports = { entry: &#39;./js/server.js&#39;, target: &#39;node&#39;, output: { path: path.join(__dirname, &#39;dist&#39;), filename: &#39;server.js&#39;, publicPath: &#39;/&#39; }, 今度はこんなエラーが出たので
ERROR in ./~/iconv-lite/encodings/tables/gb18030-ranges.json Module parse failed: ***/sambaiz-net/web/node_modules/iconv-lite/encodings/tables/gb18030-ranges.json Unexpected token (1:9) You may need an appropriate loader to handle this file type. loadersに下の設定を追加した。
{ test: /\.json$/, loader: &amp;quot;json-loader&amp;quot;} webpackには成功したが、serverを起動すると今度は以下のようなエラーが出た。
return /msie [6-9]\b/.test(window.navigator.userAgent.toLowerCase()); ReferenceError: window is not defined style-loaderのコードだったので、 まず、フロント側のwebpackで extract-text-webpack-pluginを使ってcssを別に出力することにした。</description>
    </item>
    
    <item>
      <title>MySQLのUNIX_TIMESTAMPにある程度未来の日付を渡すと0になる</title>
      <link>https://www.sambaiz.net/article/4/</link>
      <pubDate>Mon, 04 Jul 2016 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/4/</guid>
      <description>以下、MySQL5.6で遭遇した。
MySQLのUNIX_TIMESTAMPは DATETIME文字列などを引数にとり、UNIXタイムスタンプ(1970-01-01 00:00:00 UTCを起点とした経過秒数)を返す関数だ。
mysql&amp;gt; SET SESSION time_zone = &#39;UTC&#39;; mysql&amp;gt; select UNIX_TIMESTAMP(&#39;1970-01-01 00:00:00&#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&#39;1970-01-01 00:00:00&#39;) | +---------------------------------------+ | 0 | +---------------------------------------+ 1 row in set (0.00 sec) ただし、2038年1月19日3時14分7秒(UTC)以降を渡すと0になってしまう。 これはドキュメントにも書いてある通り範囲外だから。
mysql&amp;gt; select UNIX_TIMESTAMP(&#39;2038-01-19-03-14-07&#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&#39;2038-01-19-03-14-07&#39;) | +---------------------------------------+ | 2147483647 | +---------------------------------------+ 1 row in set (0.04 sec) mysql&amp;gt; select UNIX_TIMESTAMP(&#39;2038-01-19-03-14-08&#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&#39;2038-01-19-03-14-08&#39;) | +---------------------------------------+ | 0 | +---------------------------------------+ 1 row in set (0.00 sec) では、この境目は何かというと、32ビットで表せる符号付数値の最大値だ。</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアルまで</title>
      <link>https://www.sambaiz.net/article/3/</link>
      <pubDate>Sun, 03 Jul 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/3/</guid>
      <description>Googleが公開した人工知能ライブラリTensorFlowを使ってみる。 セットアップ方法はいくつか提供されているが、Dockerで動かすことにした。 Jupyter Notebookが立ち上がるのですぐに試せて良い。
$ docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow http://localhost:8888/tree
公式のチュートリアルをまとめながら進めてみる。
MNIST For ML Beginners
The MNIST Data MNISTというのは0~9の書き数字の画像のデータセットのことで、これらを正しく分類するのが目的。
それぞれの画像は一律28*28=784ピクセルで、それぞれのピクセルは0と1の間の数値(強さ)で表されている。 今回はこれの縦横を取っ払って784次元のベクトルとして扱っている。
したがって、学習用の画像データは[55000, 784]のtensor(n次元の配列)で表される。 55000というのが画像の数で、784というのがそれぞれの画像の次元を意味している。
それぞれの画像に対応した数字のラベルは[55000, 10]で表される。 10というのは、0~9それぞれに対応した次元のうち、一つだけ1で、それ以外が0という風に使われる。これをone-hot vectorという。
Softmax Regressions Softmaxはいくつかの異なるもの(今回でいうと数字)に確率を割り当てる。
画像が特定のクラス(0~9)に属するかどうか計算するために、ピクセルの強さに重みを付けた合計を計算する。 もし、そのピクセルがそのクラスに属さない根拠になるなら負の重みがかかり、属する根拠になるなら、正の重みがかかるようにする。 また合計にさらに入力と無関係なクラスごとに異なるバイアスを足す。
全てのクラスで計算した値をsoftmax関数に入れ、それぞれ確率に変換する。この確率の和は1になるようになっている。
Implementing the Regression Pythonでは行列の積のような重い処理をするとき、NumPyのようなライブラリを使ってPythonの外で行うが、 外からPythonに戻るときにオーバーヘッドが発生してしまう。 TensorFlowでも重い処理を外で行うが、オーバーヘッドを避けるために、 単体の重い処理をPythonから独立して実行するのではなく、Pythonの外側で実行される関連した処理のグラフを記述させる。
import tensorflow as tf x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b) tf.placeholderは実行時に与えられる値で、今回が画像データ。 W(重み)とb(バイアス)は学習する変数。 tf.matmul(x, W) + bの部分が重みを付けた合計にバイアスを足したものに対応している。 matmulはmatrix multiple、つまり行列の積。</description>
    </item>
    
    <item>
      <title>Reactで作ったページにTwitterCardsとOGPのメタデータを埋める</title>
      <link>https://www.sambaiz.net/article/2/</link>
      <pubDate>Sat, 02 Jul 2016 13:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/2/</guid>
      <description>せっかくページを作ったので、SNSにシェアするときに見栄えをよくしようと思った。
Twitter CardsやOGPのmetaタグを埋めるとTwitterやFacebookにURLを貼ったときに上のように表示されるようになる(上はFacebookの例)。そこで、react-helmetでこんな感じで動的に埋め込んだんだけど読んでくれない。
&amp;lt;Helmet title={&#39;sambaiz.net&#39;} meta={[ {&amp;quot;name&amp;quot;: &amp;quot;twitter:card&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;summary&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;twitter:site&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;@sambaiz&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;twitter:title&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;sambaiz.net&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;twitter:description&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;僕のホームページ&amp;quot;}, {&amp;quot;property&amp;quot;: &amp;quot;og:title&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;sambaiz.net&amp;quot;}, {&amp;quot;property&amp;quot;: &amp;quot;og:type&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;blog&amp;quot;}, {&amp;quot;property&amp;quot;: &amp;quot;og:image&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;http://d2wgaf7ubdj1mv.cloudfront.net/my.jpg&amp;quot;}, {&amp;quot;property&amp;quot;: &amp;quot;og:url&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;https://www.sambaiz.net&amp;quot;} ]} /&amp;gt; GoogleのクローラーのようにJavascriptを解釈してくれる と思ってた。残念。
しょうがないのでここだけサーバーサイドレンダリングすることにした。
&#39;use strict&#39; import express from &#39;express&#39; import path from &#39;path&#39; import compression from &#39;compression&#39; require(&#39;isomorphic-fetch&#39;); var app = express() app.use(compression()) // serve our static stuff app.use(express.static(path.join(__dirname, &#39;..&#39;, &#39;.</description>
    </item>
    
    <item>
      <title>ブログを作った</title>
      <link>https://www.sambaiz.net/article/1/</link>
      <pubDate>Wed, 29 Jun 2016 23:43:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/1/</guid>
      <description>最近表に出るものを作っていなかったので、このサイトを作ってみた。
表はReact/Reduxで、裏側はAWSのLambdaでサーバーレスに作ってある。 コードはgithubに公開してみた。
これを期になるべくアウトプットしていこうと思う。大抵三日坊主なのだけれど。
&amp;ndash;
追記: 今はHugoに置き換わっている
静的ウェブサイトエンジンHugoに乗り換えた</description>
    </item>
    
  </channel>
</rss>