<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Articles on sambaiz-net</title>
    <link>https://www.sambaiz.net/article/</link>
    <description>Recent content in Articles on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Tue, 29 May 2018 22:33:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/article/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>IstioでSidecar Envoyを付けるまで</title>
      <link>https://www.sambaiz.net/article/167/</link>
      <pubDate>Tue, 29 May 2018 22:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/167/</guid>
      <description>Istioとは サービスが増えるにしたがって複雑になるサービスメッシュ(マイクロサービス間のネットワーク)の、ロードバランシングや認証、モニタリングなどを一手に担うOSS。 概念は抽象化されていて、Kubernetes以外のサポートも考えられている。
Envoy Sidecarとしてデプロイされる、サービスメッシュでの全ての通信を通すプロキシ。したがってコードに手を入れる必要がない。 CNCFのプロジェクトの一つで、 Istio用にオリジナルから拡張されている。 ロードバランシングやヘルスチェックなどを行い、メトリクスを取る。
Mixer AWSやGCPといったインフラの差異を吸収する。
Pilot サービスディスカバリしてEnvoyのトラフィックを制御する。A/Bテストやカナリアリリースをする場合や、障害に対応して適切にルーティングを行うことができる。
Istio-Auth サービスやエンドユーザーの認証を行い、ポリシーに従ってアクセス制御する。
[Istioのインストール]()https://istio.io/docs/setup/kubernetes/quick-start.html ローカルのminikubeに環境を作る。 apiserver.Admission.PluginNamesでは立ち上がらなかったので代わりに apiserver.admission-controlを指定している。
$ minikube version minikube version: v0.27.0 $ minikube start \ --extra-config=apiserver.admission-control=&amp;quot;NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota&amp;quot; \ --kubernetes-version=v1.9.0 $ kubectl config current-context minikube  最新のistioを持ってきてapplyする。
$ curl -L https://git.io/getLatestIstio | sh - $ cd istio-0.7.1/ $ kubectl apply -f install/kubernetes/istio-auth.yaml  作成されたserviceとpodはこんな感じ。
$ kubectl get svc -o name -n istio-system NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE istio-ingress LoadBalancer 10.</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
      <link>https://www.sambaiz.net/article/166/</link>
      <pubDate>Tue, 29 May 2018 09:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/166/</guid>
      <description>ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成しアンサンブル学習する手法。 決定木なので特徴量の影響が分かりやすく、単一の決定木と比べて過学習を防ぐことができる。
train.csvとtest.csvをKaggleからダウンロードする。 csvにはタイタニックの乗客者リストが含まれ、test.csvには生還したかを表すSurvivedが抜けている。 これを予測するのがこのコンペティションの目的だ。
データのうちFareやAge、Embarkedは入っていないものがあって、これらの欠損値をどう扱うという問題がある。
df = pd.read_csv(&#39;./train.csv&#39;) print(len(df)) print(df.isnull().sum())  891 PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64  連続値をとるFareとAgeは平均を取り、Embarkedは欠損値用の値にしてみた。数値化できないものについては除いている。
def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).</description>
    </item>
    
    <item>
      <title>TerraformでGKEクラスタとBigQueryを立てる</title>
      <link>https://www.sambaiz.net/article/165/</link>
      <pubDate>Tue, 29 May 2018 02:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/165/</guid>
      <description>GKEクラスタからBigQueryを読み書きすることを想定している。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net
GKE  google_container_cluster  oauth_scopeにbigqueryを付けている。
resource &amp;quot;google_container_cluster&amp;quot; &amp;quot;sample&amp;quot; { name = &amp;quot;${var.cluster_name}&amp;quot; description = &amp;quot;sample k8s cluster&amp;quot; zone = &amp;quot;${var.gcp_zone}&amp;quot; initial_node_count = &amp;quot;${var.initial_node_count}&amp;quot; master_auth { username = &amp;quot;${var.master_username}&amp;quot; password = &amp;quot;${var.master_password}&amp;quot; } node_config { machine_type = &amp;quot;${var.node_machine_type}&amp;quot; disk_size_gb = &amp;quot;${var.node_disk_size}&amp;quot; oauth_scopes = [ &amp;quot;https://www.googleapis.com/auth/compute&amp;quot;, &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;, &amp;quot;https://www.googleapis.com/auth/logging.write&amp;quot;, &amp;quot;https://www.googleapis.com/auth/monitoring&amp;quot;, &amp;quot;https://www.googleapis.com/auth/bigquery&amp;quot;, ] } }  variable &amp;quot;env&amp;quot; { description = &amp;quot;system env&amp;quot; } variable &amp;quot;gcp_zone&amp;quot; { description = &amp;quot;GCP zone, e.</description>
    </item>
    
    <item>
      <title>カナダのバンクーバーから南へ5都市周ってGoogleI/Oに行ってきた</title>
      <link>https://www.sambaiz.net/article/164/</link>
      <pubDate>Mon, 28 May 2018 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/164/</guid>
      <description>去年と連続でチケットが当たって2回目の参加。 前回はニューヨークで大変な目にあったが、 今回はI/OがGWの次の週だったので日程に余裕があり、カナダのバンクーバーから、ビクトリア、アメリカに入ってポートエンジェルス、シアトル、ポートランドと南下していって会場のマウンテンビューを目指すことにした。
準備 前回と同じ基本的にExpediaで航空券やホテルは取って、各業者のサイトで都市間の移動に使うフェリーやバスや電車を予約して、 あとアメリカのeSTAのようにカナダにもeTAというのがあって申請した。
前回は空港からマンハッタンのT-mobileのショップにたどり着くまでネット回線がなく、地図すら空港のwifi頼みで大変な思いをした。 今回はカナダも行くので事前にAmazonでカナダも対応しているプランのSIMを購入して業者にアクティベートしてもらうことにした。
今回は夜出発だったので時間に余裕があったが、念のため前日から万札を何枚か財布に入れておいた。つまるところ、現金とネットさえあればなんとでもなるのだ。
バンクーバー 空港から出ても怪しい人を見かけないし、駅の人も愛想良く案内してくれる。 アナウンスもはっきりしているので聞き取りやすく券売機のUIもわかりやすい。 駅の券売機で交通ICカードCompassを手に入れれば、電車・バス共に乗ることができる。 Uberは走っていないがバスが発達していて大体事足りる。バス停の標識も比較的低い位置にあって気付きやすい。
バスから降りるとき皆Thank youと言ってるのは良い感じだ。財布を落としたり傘を忘れたりしても皆で教えてくれるし、人が親切で治安が良くて安心感がある。
アジア系の飲食店が多い。漢字が併記されているのもよく見る。
朝食はJethro&amp;rsquo;s Fine Grubという店で取った。ダウンタウンからは少し離れてるのに待ちが発生していた。
これを食べてからGranville Islandという店が並んでいるところに行ってきた。 Public Marketにはソーセージやお菓子などが売ってたりするんだけど、腹が一向に空かないし、中には座れず外はとても寒かったので何も買わずに帰ってきた。
ビクトリア BC Ferries ConnectorというバスがバンクーバーのPublic Central Stationから出ていて、これに乗るとそのままフェリーに乗り込んでビクトリアまで行くことができる。船内のカフェテリアにカナダらしい食べ物プーティンがあったので頼んでみたら思ったより量が多く、15分前ぐらいのアナウンスでバスに戻らないと普通に置いてかれるので、なんとかコーラで流し込んだ。
ビクトリアのダウンタウンに到着後、バスで1時間くらいかけて北へButchers Gardenという庭園に向かった。 ビクトリアには交通ICカードがないので、車内で5ドル払って1日乗車券をもらって乗る。 この時期は色とりどりのチューリップが咲いていて、歩いているだけで良い香りがする。
そのほかに鹿おどしのある日本庭園や、イタリア庭園もあったりする。
このためにビクトリアを訪れてもよいぐらい満足度が高かった。
朝食はBlueFox Caffeという店でEggs Pacificoというサーモンとアボカドのエッグベネディクトを頼んだ。 付け合わせの芋が多いが、とても美味しい。1日1食の日々がしばらく続く。
ポートエンジェルス(オリンピック半島) ビクトリアの州議事堂の近くから出ているBlack Ball Ferry Lineに乗ってポートエンジェルスに移動する。 予約しても受付でチケットを受け取る必要がある。乗る前に入国審査を受けて、I-94Aという紙をパスポートに貼ってもらった。 料金が6ドルかかる。カードでも払えるがカナダドルでは払えなかった。
町の自転車屋で電動自転車を借りて、まずはオリンピック国立公園のビジターセンターを目指した。ここで10ドル払うと入園券みたいなののとマップがもらえる。 どこに行くつもりか、と聞かれたので何も考えてないと答えると、比較的近くにあるHurricane Ridgeという所を教えてもらったのでそこを目指すことにした。
オフシーズンだからか道を工事していて所々コンディションが悪い。しかもずっと上り坂だ。 それでも電動アシストの力を借りて登っていったのだが、途中でまさかの電池切れ。しょうがないので町に引き返してその日は終わり。返すとき顛末を説明したら割り引いてくれた。
次の日はバスでMarymere fallsという小さな滝のトレッキングコースに行った。散歩みたいなコースですぐ終わってしまったので、 途中の分岐にあったStormKingというコースにも入ってみたら、傾斜が延々と続く山登りコースだった。終盤END OF MAINTAINED TRAILの標識よりあとはいろいろ厳しくなり、勇気と気合いでロープをつかみながら登っていくことになる。
頂上からはCrescent Lakeがその名の通り三日月に見える。景色はよいのだけど足場が狭くて立っているだけで怖い。
シアトル ポートエンジェルスからバスでシアトルへ。Olympic Bus Linesのバスで、クッキーが配られた。
シアトルのホテルは高かったのでAirBnbを使ってみた。ナンバーロック式の部屋だったので、ホストとはメッセージのやりとりだけで済んだし、親切にも日本語のガイドブックまで用意しておいてくれた。
まず、交通ICカードOrcaを手に入れようと、駅の自販機にクレジットカードを入れたところ出てこなくなってしまった。駅員はいないので、なんとか引き抜こうと頑張っていたところ、親切な人がペンチを借りてきてくれてなんとか引き抜くことができた。よかった。 ただ、こんな苦労して手に入れたOrcaも2回ぐらいしか使わなかった。というのもバス停が他の標識と混在して分かりづらく、Uberに迎えに来てもらった方が楽だったからだ。相乗りのUber Poolならバスの倍くらいで乗ることができる。
気を取り直して、Amazonの本部、Day 1に行ってきた。前から予約すれば社内ツアーもあるみたいだけど、今回の目的はこの1階にある、今年オープンしたレジ無しコンビニのAmazon Goだ。</description>
    </item>
    
    <item>
      <title>Macでの開発環境構築メモ</title>
      <link>https://www.sambaiz.net/article/163/</link>
      <pubDate>Sat, 14 Apr 2018 14:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/163/</guid>
      <description>新しいMBPを買ったので開発環境の構築でやったことを残しておく
設定  アクセシビリティから3本指スクロールを有効にする ホットコーナーの左上にLaunchPad、右上にデスクトップを割り当てている 画面をなるべく広く使うためにDockは左に置いて自動的に隠す  bash_profile パッケージマネージャ以外で持ってきたバイナリは${HOME}/binに置くことにする。
touch ~/.bash_profile mkdir ${HOME}/bin echo &amp;quot;export PATH=\$PATH:${HOME}/bin&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile  HomeBrew &amp;amp; Cask /usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot; brew tap caskroom/cask  一般的なアプリケーション/コマンドのインストール XcodeとUnityとLINEは手動で入れる。
brew cask install google-chrome kap visual-studio-code slack kindle brew install jq gibo mysql wget  Git git config --global user.name sambaiz git config --global user.email godgourd@gmail.com  Docker &amp;amp; K8s brew cask install docker virtualbox minikube brew install docker  fish bash前提で書かれたスクリプトも多いので、デフォルトシェルにはしない。</description>
    </item>
    
    <item>
      <title>Pythonのasyncioで非同期にリクエストを飛ばす</title>
      <link>https://www.sambaiz.net/article/162/</link>
      <pubDate>Sat, 14 Apr 2018 13:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/162/</guid>
      <description>Pythonのasyncioはイベントループを回してシングルスレッドで並行に非同期処理を行う。 マルチスレッドで並列に実行するのがthreadingで、 マルチプロセスで並列に実行するのがmultiprocessing。
import asyncio async def sleep(s): await asyncio.sleep(s) print(s) return s loop = asyncio.get_event_loop() loop.run_until_complete(sleep(5)) coros = [sleep(3), sleep(2)] futures = asyncio.gather(*coros) loop.run_until_complete(futures) print(futures.result()) loop.close()  $ python main.py 5 2 3 [3, 2]  get_event_loop() でイベントループを取得し、 gather()で処理をまとめたりして、 run_until_complete()で Futureの完了を待ち、 結果を取得してイベントループをclose()している。
async defを付けた関数はCoroutineとなり、 ensure_future()でFutureのサブクラスの、イベントループで実行させるTaskにすることができる。 run_until_complete()はそのままCoroutineを投げてもensure_future()でwrapしてくれる。
httpクライアントrequestsはBlockingするようなので、asyncioに対応しているaiohttpを使ってリクエストしてみる。
import aiohttp import asyncio import async_timeout async def fetch(session, url): print(&amp;quot;{} start&amp;quot;.format(url)) async with async_timeout.timeout(10): async with session.get(url) as response: text = await response.</description>
    </item>
    
    <item>
      <title>Kubernetes,Helmで負荷試験ツールLocustを立てる</title>
      <link>https://www.sambaiz.net/article/161/</link>
      <pubDate>Sun, 18 Mar 2018 22:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/161/</guid>
      <description>OSSの負荷試験ツールLocustをK8sクラスタに立てる。 K8sならworkerの増減も簡単だし、HelmのChartもあるので立てるのも楽。
LocustはPython製で、以下のようなコードで処理を書くことができる。
@task(10)のように括弧の中に数字を書いて実行される割合を偏らせることもできる。 異なるTaskSetに対応するユーザーを複数作ることもできて、こちらもweightで重みを付けられる。 ユーザー数はあとでWeb上から入力する。
$ mkdir tasks $ cat tasks/tasks.py from locust import HttpLocust, TaskSet, task class ElbTasks(TaskSet): @task def task1(self): with client.get(&amp;quot;/&amp;quot;, catch_response=True) as response: if response.content != &amp;quot;Success&amp;quot;: response.failure(&amp;quot;Got wrong response&amp;quot;) class ElbWarmer(HttpLocust): task_set = ElbTasks min_wait = 1000 max_wait = 3000  stableにChartはあるが、今のところtasksの中を書き換えなくてはいけないようなので、forkしてきてtasksの中を書き換え、helm repo addするためにpackageして、これを参照するindex.yamlを生成した。
$ helm package . $ helm repo index . $ ls locust-0.1.2.tgz index.yaml index.yaml	locust-0.1.2.tgz $ cat index.yaml apiVersion: v1 entries: locust: .</description>
    </item>
    
    <item>
      <title>RBACが有効なGKEでHelmを使う</title>
      <link>https://www.sambaiz.net/article/160/</link>
      <pubDate>Sun, 18 Mar 2018 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/160/</guid>
      <description>k8sのパッケージマネージャーHelmを使う - sambaiz-net
$ helm version Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.8.2&amp;quot;, GitCommit:&amp;quot;a80231648a1473929271764b920a8e346f6de844&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} Server: &amp;amp;version.Version{SemVer:&amp;quot;v2.8.2&amp;quot;, GitCommit:&amp;quot;a80231648a1473929271764b920a8e346f6de844&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}  GKEでhelm initしてhelm installしたところ以下のエラーが返ってきた。
Error: release my-locust failed: namespaces &amp;quot;default&amp;quot; is forbidden: User &amp;quot;system:serviceaccount:kube-system:default&amp;quot; cannot get namespaces in the namespace &amp;quot;default&amp;quot;: Unknown user &amp;quot;system:serviceaccount:kube-system:default&amp;quot;  GKEではデフォルトでK8sのRBAC(Role-Based Access Control)が有効になっているため、Tillerインスタンスに権限を与える必要がある。
ということでTiller用にnamespaceを切って、その中では好きにできるRoleと、Tillerが使うServiceAccountを作成し、RoleBindingで紐づける。
kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: tiller-manager namespace: tiller-world rules: - apiGroups: [&amp;quot;&amp;quot;, &amp;quot;extensions&amp;quot;, &amp;quot;apps&amp;quot;] resources: [&amp;quot;*&amp;quot;] verbs: [&amp;quot;*&amp;quot;] --- apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: tiller-world --- kind: RoleBinding apiVersion: rbac.</description>
    </item>
    
    <item>
      <title>Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る</title>
      <link>https://www.sambaiz.net/article/159/</link>
      <pubDate>Tue, 13 Mar 2018 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/159/</guid>
      <description>Logging AgentをNodeレベルのDaemonSetとして動かすのではなく、Podの中にSidecar Containerとして動かす。その分リソースは食うけど、独自の設定で動かせる。
アプリケーション https://github.com/sambaiz/go-logging-sample
Goで定期的にログを出すサンプルコードを書いたのでこれを使う。 viperで設定を持ち、 zapでログを出力する。 あとSIGINTを拾ってSync()してGraceful Shutdownするようにしている。
Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net
multistage-buildでビルドして、GKEで動かすのでContainer Registryに上げる。
$ docker build -t go-logging-sample . $ docker tag go-logging-sample gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1 $ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample  Fluentdの設定 fluent-plugin-bigqueryプラグインを使う。
projectとdataset、パーティションの日付分割テーブルに入れる場合は、auto_create_tableできないのでtableも作成しておく。
fluentdの設定はConfigMapで持つ。
apiVersion: v1 kind: ConfigMap metadata: name: fluentd-config data: fluent.conf: | &amp;lt;source&amp;gt; @type tail format json path /var/log/app.log pos_file /var/log/app.log.pos tag bigquery &amp;lt;/source&amp;gt; &amp;lt;match bigquery&amp;gt; @type bigquery method load &amp;lt;buffer time&amp;gt; @type file path /var/log/bigquery.</description>
    </item>
    
    <item>
      <title>MySQL InnoDBのロックの挙動</title>
      <link>https://www.sambaiz.net/article/158/</link>
      <pubDate>Sat, 03 Mar 2018 19:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/158/</guid>
      <description>https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html
トランザクション分離レベルはデフォルトのREPEATABLE-READ。
&amp;gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@GLOBAL.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+  準備 DBを立ち上げてテーブルとレコードを入れる。
$ cat schema_and_data.sql CREATE TABLE a ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, name VARCHAR(128) NOT NULL ); CREATE TABLE b ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, a_id BIGINT UNSIGNED NOT NULL, FOREIGN KEY (a_id) REFERENCES a (id) ); INSERT INTO a (id, name) VALUES (1, &#39;1&#39;); INSERT INTO a (id, name) VALUES (2, &#39;2&#39;); INSERT INTO a (id, name) VALUES (3, &#39;3&#39;); INSERT INTO a (id, name) VALUES (8, &#39;8&#39;); INSERT INTO a (id, name) VALUES (9, &#39;9&#39;); INSERT INTO a (id, name) VALUES (10, &#39;10&#39;); $ cat start.</description>
    </item>
    
    <item>
      <title>Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる</title>
      <link>https://www.sambaiz.net/article/157/</link>
      <pubDate>Sun, 25 Feb 2018 23:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/157/</guid>
      <description>UserPoolを作成。デフォルト設定はこんな感じ。 必須項目や、確認メールの文面などを自由にカスタマイズでき、 登録時などのタイミングでLambdaを発火させることもできる。
作成したUserPoolにアプリクライアントを追加する。 ブラウザで使うのでクライアントシークレットはなし。
クライアント側 amazon-cognito-identity-jsを使う。
依存するjsを持ってくる。
$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/amazon-cognito-identity.min.js $ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/aws-cognito-sdk.min.js  Sign UpからAPIを呼ぶところまでのボタンを並べた。 SignInすると以下のデータをそのページのドメインのLocal Storageに保持する。
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.idToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.accessToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.refreshToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.clockDrift CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.LastAuthUser  APIを呼ぶときはidToken(JWT)をAuthorization Headerに乗せる。
&amp;lt;button id=&amp;quot;signUp&amp;quot;&amp;gt;Sign Up&amp;lt;/button&amp;gt; &amp;lt;p&amp;gt;&amp;lt;label&amp;gt;Code:&amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;code&amp;quot;&amp;gt;&amp;lt;/label&amp;gt;&amp;lt;/p&amp;gt; &amp;lt;button id=&amp;quot;confirm&amp;quot;&amp;gt;Confirm&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;signIn&amp;quot;&amp;gt;Sign In&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;whoAmI&amp;quot;&amp;gt;Who am I?&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;requestAPI&amp;quot;&amp;gt;Request API with token&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;signOut&amp;quot;&amp;gt;Sign Out&amp;lt;/button&amp;gt; &amp;lt;script src=&amp;quot;aws-cognito-sdk.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script src=&amp;quot;amazon-cognito-identity.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script&amp;gt; const USER_NAME = &amp;quot;*****&amp;quot;; const USER_PASSWORD = &amp;quot;*****&amp;quot;; const USER_EMAIL = &amp;quot;*****&amp;quot;; class CognitoUserPoolAuth { constructor(UserPoolId, clientId, apiEndpoint) { const poolData = { UserPoolId : UserPoolId, ClientId : clientId }; this.</description>
    </item>
    
    <item>
      <title>ブラウザのwindow間の値渡し</title>
      <link>https://www.sambaiz.net/article/156/</link>
      <pubDate>Fri, 23 Feb 2018 02:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/156/</guid>
      <description>直接Windowを参照する プロトコル、ポート、ドメインが全て同じ場合は、親はopen()した返り値で、子はwindow.openerで相手のwindowが取れて、直接参照したりDOMを操作したりすることもできる。
$ cat index.html &amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Open window&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;btn2&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt; &amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; let win2; const button = document.getElementById(&amp;quot;btn&amp;quot;); button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; { window.foo = &amp;quot;bar from window1&amp;quot;; win2 = window.open(&amp;quot;index2.html&amp;quot;); }, false); const button2 = document.getElementById(&amp;quot;btn2&amp;quot;); button2.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; { if (win2) { win2.close(); } }, false); &amp;lt;/script&amp;gt;  $ cat index2.html &amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt; &amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; console.log(window.aaa); const parentWindow = window.opener; const view = document.getElementById(&amp;quot;view&amp;quot;); view.</description>
    </item>
    
    <item>
      <title>Serverless FrameworkでLambdaをデプロイする</title>
      <link>https://www.sambaiz.net/article/155/</link>
      <pubDate>Sun, 11 Feb 2018 23:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/155/</guid>
      <description>Serverless FrameworkでLambda Functionをデプロイする。 Apexが基本的にFunction自体のデプロイしかしないのに対して、こちらはeventの設定なども諸々やってくれて強い。
ApexでLambdaをデプロイする - sambaiz-net
$ npm install -g serverless $ serverless version 1.26.0  ApexではFunctionごとにディレクトリが作られたが、ServerlessではServiceごとに作られ、 一つのService内で複数のFunctionを定義できる。handlerは同じでも異なっていてもよい。
Apexの形式の場合、共通の処理をWebpackなどで各Functionに持って来たり、 同じような処理の複数のFunctionを立てる際はコピーする必要があったが、 こちらは必要最小限の変更でそれらを行うことができる。
templateからServiceをcreateする。
$ serverless create --template aws-nodejs --path testservice $ ls testservice/ handler.js	serverless.yml  設定ファイルserverless.yml にはLambdaの基本的なもののほかに、VPCやevent、IAM Roleなども書けて、これらはdeploy時に作られるCloudFormationのstackによって管理される。必要なら生のCloudFormationの設定も書ける。
ApexでもTerraformによって管理することができるが、書くのはこちらの方がはるかに楽。
ApexでデプロイしたLambdaのトリガーをTerraformで管理する - sambaiz-net
$ cat sesrverless.yml service: testservice provider: name: aws profile: foobar region: ap-northeast-1 runtime: nodejs6.10 memorySize: 512 timeout: 10 functions: hello: handler: handler.hello events: - http: path: hello/world method: get cors: true  deployすると{service}-{stage}-{function}のFunctionが作られる。 今回の場合はtestservice-prd-test。stageをymlでも指定しなかった場合はデフォルト値のdevになる。</description>
    </item>
    
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。 全体のコードはここ。
入力 以下の関数によって生成した1次元のデータ列。 これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。
def make_time_series_data(size): data = [] for i in range(size): data.append(sin(random.normalvariate(i,0.1)*0.1)) return np.reshape(np.array(data, dtype=np.float32), (size,1)) def make_batch(data, batch_size, num_steps, num_dimensions, name=None): epoch_size = data.size // (batch_size*num_steps*num_dimensions) data = np.lib.stride_tricks.as_strided( data, shape= (epoch_size, batch_size, num_steps+1, num_dimensions), strides=( 4*batch_size*num_steps*num_dimensions, 4*num_steps*num_dimensions, 4*num_dimensions, 4 # bytes ), writeable=False )  モデル input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。 lossはMSE(Mean squared error)。OptimizerはGradientDecentOptimizerを使っている。
チュートリアルでは自力で各time_stepの値を入れていたけど、 今回はdynamic_rnn()に任せている。
class Model(object):dc def __init__(self, config, is_training=False): # config self.</description>
    </item>
    
    <item>
      <title>xorm reverseでDBスキーマからGoのstructを生成する</title>
      <link>https://www.sambaiz.net/article/153/</link>
      <pubDate>Sat, 10 Feb 2018 15:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/153/</guid>
      <description>GoのORMのxormにはxorm reverseというDBのスキーマから以下のようなテンプレートに沿ったGoのstructなどを生成するツールがある。
package {{.Model}} import ( {{range .Imports}}&amp;quot;{{.}}&amp;quot;{{end}} ) {{range .Tables}} type {{Mapper .Name}} struct { {{$table := .}} {{range .Columns}}	{{Mapper .Name}}	{{Type .}} {{end}} } {{end}}  リポジトリにあるテンプレートにxorm用テンプレートとgo用のテンプレートが用意されているように、単体で使うこともできる。 また、テンプレートを書く言語としてもGo以外にC++もサポートしている。
xormのcmdとドライバをインストール。
$ go get github.com/go-xorm/cmd/xorm $ go get github.com/go-sql-driver/mysql $ xorm Version: 0.2.0524  様々な型のカラムを含むテーブルで試す。
$ cat schema.sql CREATE TABLE table1 ( n_tinyint TINYINT, n_int INT, n_int_unsigned INT UNSIGNED NOT NULL DEFAULT 1, n_bigint BIGINT, n_float FLOAT, n_double DOUBLE, d_date DATE, d_datetime DATETIME, s_char CHAR(64), s_varchar VARCHAR(64), s_text TEXT, s_json JSON, b_binary BLOB, e_enum ENUM(&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;) ) $ cat setup.</description>
    </item>
    
    <item>
      <title>DatadogのLambda Integrationで気象データを送ってアラートを飛ばす</title>
      <link>https://www.sambaiz.net/article/152/</link>
      <pubDate>Mon, 05 Feb 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/152/</guid>
      <description>最近朝が寒くて布団から出るのがつらい。雨や雪が降っていたら尚更のこと、それならそれで現状を把握する必要がある。 そこで、無料から使える気象API OpenWeatherMapのデータをdatadogに送って、特に寒い日や雨雪が降るような朝にはアラートを飛ばすことにした。
インスタンスが立っていたらDataDog AgentのDogStatsD経由で送ることができ、 そうでなければ通常はAPIを呼ぶことになるんだけど、Lambdaでは、AWS Integrationを設定すると有効になるLambda Integrationによって MONITORING|unix_epoch_timestamp|value|metric_type|my.metric.name|#tag1:value,tag2のフォーマットでconsole.logするだけでメトリクスが送られるようになっている。
const axios = require(&#39;axios&#39;); const CITY = &#39;Shibuya&#39;; const API_KEY = &#39;*****&#39;; const WEATHER_API = `http://api.openweathermap.org/data/2.5/weather?q=${CITY}&amp;amp;units=metric&amp;amp;appid=${API_KEY}`; const METRIC_COUNTER = &#39;counter&#39;; const METRIC_GAUGE = &#39;gauge&#39;; const monitor = (metricName, metricType, value, tags) =&amp;gt; { const unixEpochTimestamp = Math.floor(new Date().getTime()); console.log(`MONITORING|${unixEpochTimestamp}|${value}|${metricType}|${metricName}|#${tags.join(&#39;,&#39;)}`); }; exports.handler = async (event, context, callback) =&amp;gt; { const data = (await axios.get(WEATHER_API)).data const namePrefix = &#39;livinginfo.weather&#39; monitor(`${namePrefix}.temperature`, METRIC_GAUGE, data.main.temp, []) monitor(`${namePrefix}.</description>
    </item>
    
    <item>
      <title>ローカルでビルドしたimageをminikubeで使う</title>
      <link>https://www.sambaiz.net/article/151/</link>
      <pubDate>Thu, 01 Feb 2018 22:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/151/</guid>
      <description>$ minikube version minikube version: v0.25.0 $ kubectl version Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;9&amp;quot;, GitVersion:&amp;quot;v1.9.2&amp;quot;, GitCommit:&amp;quot;5fa2db2bd46ac79e5e00a4e6ed24191080aa463b&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2018-01-18T21:11:08Z&amp;quot;, GoVersion:&amp;quot;go1.9.2&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;} $ kubectl config current-context minikube $ minikube status minikube: Running cluster: Running kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100  dockerコマンドがminikube VM内で動いているdocker daemonを参照するようにする。
$ minikube docker-env export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot; export DOCKER_HOST=&amp;quot;tcp://192.168.99.100:2376&amp;quot; export DOCKER_CERT_PATH=&amp;quot;/Users/sambaiz/.minikube/certs&amp;quot; $ eval $(minikube docker-env) $ docker info --format &#39;{{json .Name}}&#39; &amp;quot;minikube&amp;quot;  ビルドするDockerfile。nginxが立ち上がるだけ。
FROM nginx  何もタグを付けない(:latest)とcreate時にDockerレジストリからpullしにいって失敗してしまうため、タグ付きでビルドする。</description>
    </item>
    
    <item>
      <title>Chromeで任意のscriptを読み込まれる前に差し替える</title>
      <link>https://www.sambaiz.net/article/150/</link>
      <pubDate>Thu, 01 Feb 2018 21:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/150/</guid>
      <description>ChromeのDevToolsではSourcesからscriptを書き換えられるようになっているが、 一行目にbreakpointを挟んで更新するとそこで止まるので読み込まれる前に差し替えることができる。 ページの読み込み時に呼ばれるSDKやライブラリの影響範囲を調べたりデバッグしたりするのに便利。
確認用jsとhtml
console.log(&amp;quot;original&amp;quot;)  &amp;lt;script src=&amp;quot;index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;  読み込み時に実行されるconsole.logの文章を変えた。</description>
    </item>
    
    <item>
      <title>Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す</title>
      <link>https://www.sambaiz.net/article/149/</link>
      <pubDate>Fri, 19 Jan 2018 09:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/149/</guid>
      <description>GooseはGo製のDB Migrationツール。
コード
こんなリポジトリを作成し、各自ブランチを切ってGoose形式のup/downのSQLを書き、終わったらPullRequestを出す。
goose/ .keep .circleci/config.yml create_test_table.sql  $ cat create_test_table.sql -- +goose Up -- SQL in this section is executed when the migration is applied. CREATE TABLE testtable ( id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT, n INT NOT NULL, c VARCHAR (20) NOT NULL UNIQUE ); -- +goose Down -- SQL in this section is executed when the migration is rolled back. DROP TABLE testtable;  無事Approveされ、mergeされるとCircleCIが走り、 SQLをgooseディレクトリの中にバージョンを付けて移し、 SlackにpostMessageするエンドポイントにリクエストを飛ばす。</description>
    </item>
    
    <item>
      <title>SlackのInteractive messagesでボタンの入力を受け付ける</title>
      <link>https://www.sambaiz.net/article/148/</link>
      <pubDate>Tue, 16 Jan 2018 21:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/148/</guid>
      <description>Interactive messages
まずはサーバーを用意する。コードはここにあって、 Interactive messagesのハンドリングはSlack公式のnode-slack-interactive-messagesを使っている。
app.use(&#39;/slack&#39;, slackMessages.expressMiddleware()); slackMessages.action(&#39;question_button&#39;, (payload) =&amp;gt; { let replacement = payload.original_message; replacement.text =`${payload.user.name} likes ${payload.actions[0].value}`; delete replacement.attachments[0].actions; return replacement; });  ボタンの表示はattachmentsを使う。
web.chat.postMessage(channelId, &#39;Question&#39;, { attachments: [ { text: &amp;quot;Which buttons do you like?&amp;quot;, color: &amp;quot;#f9a41b&amp;quot;, callback_id: &amp;quot;question_button&amp;quot;, actions: [ { name: &amp;quot;primary_button&amp;quot;, type: &amp;quot;button&amp;quot;, style: &amp;quot;primary&amp;quot;, text: &amp;quot;Primary&amp;quot;, value: &amp;quot;Primary Button&amp;quot;, }, { name: &amp;quot;normal_button&amp;quot;, type: &amp;quot;button&amp;quot;, text: &amp;quot;Normal&amp;quot;, value: &amp;quot;Normal Button&amp;quot; }, { name: &amp;quot;danger_button&amp;quot;, type: &amp;quot;button&amp;quot;, style: &amp;quot;danger&amp;quot;, text: &amp;quot;Danger&amp;quot;, value: &amp;quot;Danger Button&amp;quot;, confirm: { title: &amp;quot;Really?</description>
    </item>
    
    <item>
      <title>TensorBoardでsummaryやグラフを見る</title>
      <link>https://www.sambaiz.net/article/147/</link>
      <pubDate>Sun, 07 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/147/</guid>
      <description>TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
で読んだコードをTensorboardでみてみる。
8888がJupyter、6006がTensorboard。
$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow  コードをuploadするかJupyterからterminalを開いてcloneしてくる。
# apt-get update # apt-get install -y git wget # git clone https://github.com/tensorflow/models.git # cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz  logdirを指定して実行し、Tensorboardを起動。
flags.DEFINE_string(&amp;quot;save_path&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;Model output directory.&amp;quot;) sv = tf.train.Supervisor(logdir=FLAGS.save_path)  # tensorboard --logdir=models/tutorials/rnn/ptb  tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)による値がリアルタイムに表示される。
グラフのつながりや、各Operationの入出力やそのshapeを確認できる。</description>
    </item>
    
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。
RNN/LSTMとは RNNは入力に対して出力のほかに情報を次のステップに渡すネットワーク。 展開すると同じネットワークに単語を一つずつ入れていくように表現できる。
TensorflowではいくつかRNNの実装が用意されていて、このコードではそのうちのCudnnLSTMやBasicLSTMCell、LSTMBlockCellを選べるようになっている。cuDNNというのはNVIDIAのCUDAのDNNライブラリのこと。LSTMBlockCellはBasicLSTMCellより速い。
LSTM(Long Short Term Memory networks)はRNNの一種で、入力にtanhを通す通常のRNNの処理に加え、それぞれ重みを持ち、どの値を更新するか決定するinput gateや、どの値を忘れるかを決定するforget gate、何を出力するか決定するoutput gateを通す。 こちらはtanhではなく値域(0,1)のシグモイドを通したものを掛けていくので、0であれば情報は失われ、1であれば完全に残る。
動かしてみる $ git clone https://github.com/tensorflow/models.git $ cd models/tutorials/rnn/ptb/ $ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz $ tar xvf simple-examples.tgz $ python3 -m venv env $ . ./env/bin/activate $ pip install numpy tensorflow  $ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0 Epoch: 1 Learning rate: 1.000 0.004 perplexity: 5534.452 speed: 894 wps 0.104 perplexity: 845.383 speed: 1277 wps ... 0.803 perplexity: 316.</description>
    </item>
    
    <item>
      <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
      <link>https://www.sambaiz.net/article/145/</link>
      <pubDate>Sun, 24 Dec 2017 23:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/145/</guid>
      <description>https://github.com/sambaiz/athena-admin
AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。
料金はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。 データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだけど都度locationを指定してADD PARTITIONを実行するのは大変。さらにスキーマを変更するのにもALTER TABLE ADD COLUMNSなどはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。
ではどうしようもないかというとMSCK REPAIR TABLEというのがあって、 これはS3のObjectのdt=YYYY-MM-DDのようなkey=valueのprefixを認識してパーティションを作るもの。作り直す際もこれ1クエリで終わる。それなら最初からそういう風に置けばよいのではというところだけど、勝手にYYYY/MM/DD/HHのprefixを付けてしまうFirehoseのようなのもある。
今回作ったathena-adminは以下のような定義ファイルから、 パーティションのkey=valueのprefixが付くように置き換えたり、変更があったらmigrationする。 このファイルを書き換えるだけで基本的にどうにかなるし、バージョン管理すればテーブル定義の変更を追うことができる。
{ &amp;quot;general&amp;quot;: { &amp;quot;athenaRegion&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;, &amp;quot;databaseName&amp;quot;: &amp;quot;aaaa&amp;quot;, &amp;quot;saveDefinitionLocation&amp;quot;: &amp;quot;s3://saveDefinitionBucket/aaaa.json&amp;quot; }, &amp;quot;tables&amp;quot;: { &amp;quot;sample_data&amp;quot;: { &amp;quot;columns&amp;quot;: { &amp;quot;user_id&amp;quot;: &amp;quot;int&amp;quot;, &amp;quot;value&amp;quot;: { &amp;quot;score&amp;quot;: &amp;quot;int&amp;quot;, &amp;quot;category&amp;quot;: &amp;quot;string&amp;quot; } /* &amp;quot;struct&amp;lt;score:int,category:string&amp;gt;&amp;quot; のように書くこともできる */ }, &amp;quot;srcLocation&amp;quot;: &amp;quot;s3://src/location/&amp;quot;, &amp;quot;partition&amp;quot;: { &amp;quot;prePartitionLocation&amp;quot;: &amp;quot;s3://pre/partition/&amp;quot;, /* optional */ &amp;quot;regexp&amp;quot;: &amp;quot;(\\d{4})/(\\d{2})/(\\d{2})/&amp;quot;, /* optional */ &amp;quot;keys&amp;quot;: [ { &amp;quot;name&amp;quot;: &amp;quot;dt&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;{1}-{2}-{3}&amp;quot;, /* optional */ } ] } } } }  使い方はこんな感じ。使い方によってはmigrate()だけ呼ぶこともあると思う。 replaceObjects()にはmatchedHandlerというのを渡すこともできて、 UTCからJSTに変換するといったこともできる。</description>
    </item>
    
    <item>
      <title>ApexでデプロイしたLambdaのトリガーをTerraformで管理する</title>
      <link>https://www.sambaiz.net/article/144/</link>
      <pubDate>Sun, 12 Nov 2017 22:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/144/</guid>
      <description>Apexでfunctionをデプロイするとトリガーが登録されないのであとで追加することになる。 これを手作業で行うこともできるのだけど、せっかくなのでアプリケーションと一緒に管理したい。 そんなときのためにterraformコマンドをラップしたapex infraが用意されている。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
functionsと同列にinfrastructureディレクトリを作成してtfファイルを置く。 その下に環境ごとのディレクトリを作成することもできて、その場合は--envで指定した環境のものが使われる。
- functions - infrastructure main.tf variables.tf - modules - cloudwatch_schedule main.tf variables.tf project.json  functionをデプロイするとそのARNが変数で取れるようになる。
$ apex list --tfvars apex_function_hello=&amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;  今回設定するトリガーはCloudwatch Eventのスケジューリング。作成するリソースは以下の通り。
 aws_cloudwatch_event_ruleでイベントルール(今回はschedule)を作成 aws_cloudwatch_event_targetでルールにターゲット(今回はLambda)を設定 aws_lambda_permissionでルールに対象Lambdaをinvokeする権限を付ける  $ cat infrastructure/modules/cloudwatch_schefule/variables.tf variable &amp;quot;lambda_function_name&amp;quot; {} variable &amp;quot;lambda_function_arn&amp;quot; {} variable &amp;quot;schedule_expression&amp;quot; { description = &amp;quot;cloudwatch schedule expression e.g. \&amp;quot;cron(0/5 * * * ? *)\&amp;quot;&amp;quot; } $ cat infrastructure/modules/cloudwatch_schefule/main.tf resource &amp;quot;aws_cloudwatch_event_rule&amp;quot; &amp;quot;lambda&amp;quot; { name = &amp;quot;lambda_rule_${var.</description>
    </item>
    
    <item>
      <title>JavaScriptのrequire/import</title>
      <link>https://www.sambaiz.net/article/143/</link>
      <pubDate>Sat, 11 Nov 2017 20:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/143/</guid>
      <description>scriptタグを並べる &amp;lt;body&amp;gt; &amp;lt;script src=&amp;quot;a.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script src=&amp;quot;b.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt;  先に書かれたa.jsで定義された内容はb.jsで読むことができる。
$ cat a.js const a = &#39;a is defined&#39;; const divA = document.createElement(&#39;div&#39;); divA.textContent = (typeof b !== &#39;undefined&#39;) ? b : &#39;b is undefined&#39;; document.body.appendChild(divA); $ cat b.js const b = &#39;b is defined&#39;; const divB = document.createElement(&#39;div&#39;); divB.textContent = (typeof a !== &#39;undefined&#39;) ? a : &#39;a is undefined&#39;; document.body.appendChild(divB);  依存が増えてくると順番を考えるのが大変。さらにグローバルな名前空間を汚染してしまう。
b is undefined a is defined  AMDとCommonJS というのも、かつてのJSにはモジュールを読み込む仕組みがなかった。 そこで考えられたのがAMDやCommonJSというフォーマット。 AMD(Asynchronous module definition)はRequireJSによって提供されるrequire()で動的にscriptタグを埋める。CommonJSはNodeでもおなじみのrequire()で、これにWebpackを通して一つのファイルにまとめておく。同じ関数名が使われているが全くの別物。</description>
    </item>
    
    <item>
      <title>圧縮アルゴリズムZopfliとBrotli</title>
      <link>https://www.sambaiz.net/article/142/</link>
      <pubDate>Fri, 03 Nov 2017 15:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/142/</guid>
      <description>どちらもGoogleが開発した圧縮アルゴリズム。
puppetter-lambda-starter-kit のissueに 現在使っているgzipと、Zopfli、Brotliを比較したデータが上がっていたので調べてみた。
Zopfli 出力としてDeflateに対応している。
Deflate LZ77(実際は改良版のLZSS)とハフマン記号による可逆圧縮アルゴリズム。 zip、zlib、gzip、pngなどで使われていて、これらはヘッダーやフッターが異なる。 LZSSはバイト列を見ていって同じ部分を発見したらそこを参照するように置き換えていく。
a b c a b c a b c d d d =&amp;gt; a b c (距離3, 長さ6) d (距離１, 長さ2)  このLZSSにあたる部分をZopfliはがんばってやるので圧縮時間が結構かかるがサイズは小さくなるらしい。 展開は通常のDeflate通り。上げてくれたデータを見ても大体そんな感じだ。
$ git clone https://github.com/google/zopfli $ cd zopfli $ make zopfli $ ./zopfli aaaa  Brotli LZ77、ハフマン記号に加えて2nd order context modelingというのを使って圧縮する Deflateではない可逆圧縮アルゴリズム。 Safari以外のモダンなブラウザで既に対応しているか対応しているところ。 対応している場合、Accept-EncodingやContent-Encodingヘッダに含まれるのはbr。 圧縮率も展開時間もかなり良さそう。
Nodeにもblotliのライブラリがあって、 圧縮はEmscriptenで本家のC++コードから変換し、 展開は手で移植しているようだ。
$ npm install blotli  const fs = require(&#39;fs&#39;); const brotli = require(&#39;brotli&#39;); const TARGET = process.</description>
    </item>
    
    <item>
      <title>Redashでデータを可視化する</title>
      <link>https://www.sambaiz.net/article/141/</link>
      <pubDate>Mon, 23 Oct 2017 23:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/141/</guid>
      <description>RedashはOSSのデータ可視化ツール。 BIツールのようにパラメータを変えながら指標を探っていくというよりは、分かっている指標を見るのに使うイメージ。 比較的機能が少ない分処理がわかりやすく、 クエリが自動生成されないため時間がかかるものを実行する前にある程度気づけるのが良いと思う。
docker-composeで立ち上げることもできるけど、 AWSの各リージョンにAMIが用意されているのでそれで立ち上げる。
sshで入って以下のようなのを必要に応じて設定する。 メールを送る場合はSESでメールアドレスをVerifyしてやるのが簡単。 GSuiteを使っている場合、OAuthのClientID、Secretを発行しドメインを登録するとそれで認証できる。
$ ssh ubuntu@***** $ sudo vi /opt/redash/.env export REDASH_MAIL_SERVER=&amp;quot;email-smtp.us-east-1.amazonaws.com&amp;quot; export REDASH_MAIL_USE_TLS=&amp;quot;true&amp;quot; export REDASH_MAIL_USERNAME=&amp;quot;*****&amp;quot; export REDASH_MAIL_PASSWORD=&amp;quot;*****&amp;quot; export REDASH_MAIL_DEFAULT_SENDER=&amp;quot;*****&amp;quot; # Email address to send from export REDASH_GOOGLE_CLIENT_ID=&amp;quot;&amp;quot; export REDASH_GOOGLE_CLIENT_SECRET=&amp;quot;&amp;quot; $ cd /opt/redash/current $ sudo -u redash bin/run ./manage.py org set_google_apps_domains {{domains}} $ sudo supervisorctl restart all  HTTPS対応するのに/etc/nginx/sites-available/redashを編集する。crtとkeyの場所は変える。
upstream rd_servers { server 127.0.0.1:5000; } server { server_tokens off; listen 80 default; access_log /var/log/nginx/rd.access.log; gzip on; gzip_types *; gzip_proxied any; location /ping { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://rd_servers; } location / { return 301 https://$host$request_uri; } } server { listen 443 ssl; # Make sure to set paths to your certificate .</description>
    </item>
    
    <item>
      <title>ApexでLambdaをデプロイする</title>
      <link>https://www.sambaiz.net/article/140/</link>
      <pubDate>Sun, 22 Oct 2017 16:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/140/</guid>
      <description>ApexでLambdaをデプロイする。 とても簡単に使えるし、変なこともしないので良い感じ。
Serverless Frameworkだとeventの設定までカバーできてより便利。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
インストール。ダウンロードして実行できるようにしている。
$ curl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh   IAMFullAccess AWSLambdaFullAccess  を付けたIAMのプロファイルを登録しておく。
$ aws configure --profile apex $ aws configure list --profile apex Name Value Type Location ---- ----- ---- -------- profile apex manual --profile access_key ****************OVGQ shared-credentials-file secret_key ****************oi5t shared-credentials-file region ap-northeast-1 config-file ~/.aws/config  apex initしてnameとdescriptionを入れるとIAMが登録され、 ディレクトリ構造が作られる。
$ apex init --profile apex Project name: try-apex Project description: test [+] creating IAM try-apex_lambda_function role [+] creating IAM try-apex_lambda_logs policy [+] attaching policy to lambda_function role.</description>
    </item>
    
    <item>
      <title>Node.jsのコードをPrettierでフォーマットしてESLintにかける</title>
      <link>https://www.sambaiz.net/article/139/</link>
      <pubDate>Thu, 19 Oct 2017 00:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/139/</guid>
      <description>PrettierはJSやTSのコードフォーマッタで、 ReactやBabel、Yarnなどの開発にも使われている。
今回はPrettierでフォーマットしたものを eslint --fixするprettier-eslint-cliを使う。役割が被っているけどPrettierはeslint --fixよりも強力にフォーマットしてくれるようだ。
$ git init $ yarn add --dev eslint eslint-config-google prettier-eslint-cli husky lint-staged $ cat .eslintrc.js module.exports = { &amp;quot;extends&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;parserOptions&amp;quot;: { &amp;quot;ecmaVersion&amp;quot;: 2017, } };  対象のコードはこれ。
$ cat src/main.js /** * hoge function */ function hoge() { const f = (aaaaaaaaaaaaaaa, bbbbbbbbbb, ccccccccc, dddddddddddd, eeeeeeeeeeeeee) =&amp;gt; console.log(&#39;a&#39;); f(1, 2, 3, 4, 5); } hoge();  Prettierのドキュメントでも紹介されているようにlint-stagedを使うとCommit時にフォーマットし、Lintをかけることができる。
{ &amp;quot;scripts&amp;quot;: { &amp;quot;precommit&amp;quot;: &amp;quot;lint-staged&amp;quot;, &amp;quot;lint&amp;quot;: &amp;quot;eslint src&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;prettier-eslint --write \&amp;quot;src/**/*.</description>
    </item>
    
    <item>
      <title>確率分布(二項分布/ポアソン分布/正規分布)</title>
      <link>https://www.sambaiz.net/article/138/</link>
      <pubDate>Sun, 15 Oct 2017 01:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/138/</guid>
      <description>二項分布 確率pで起きる事象がn回の試行でx回起きる確率関数の離散的確率分布。記号で書くとB[n,p]。 期待値はnpで、分散はnp(1-p)。
ポアソン分布 二項分布において、起きる確率pが少なく、試行回数nが多いときに代わりに適用できる確率分布。 具体的にはnが50ぐらいだったら、npが5以下のとき。 試行回数が多いとき、二項分布だとCの部分の計算が困難になってしまうのを解決できる。 期待値も分散もnp=μ。
正規分布 正規分布は平均値μを最大値とし、左右対称な釣鐘型をしている連続的確率分布。記号で書くとN[μ,σ^2]。 二項分布のnを大きくしていくと正規分布に近づいていく。 p=0.5であれば、n=10の二項分布B[10,0.5]でも良い近似が得られる(N[5,2.5])。 逆にnが大きな二項分布の近似として正規分布を使うこともできる。
N[0,1]の正規分布を標準正規分布と呼ぶ。 ある正規分布に従う確率変数xを、標準正規分布に従うzに変換することを標準化変換という。 標準正規分布にすると正規分布表の値を使って計算できる。
また、平均μ、分散σ^2の任意な分布からn個の標本をとったときの平均はN[μ, σ^2/n]に従う。 言い換えれば、標本の平均と真の平均の誤差はN[0, σ^2/n]。これを中心極限定理という。
参考 統計学入門</description>
    </item>
    
    <item>
      <title>Lpノルムと正則化</title>
      <link>https://www.sambaiz.net/article/137/</link>
      <pubDate>Thu, 12 Oct 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/137/</guid>
      <description>ノルムとは ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。
 p(av) = |a| p(v): スケーラブル p(u + v) ≦ p(u) + p(v): 三角不等式を満たす p(v) ≧ 0: 負の値を取らない p(v) = 0 &amp;lt;=&amp;gt; v=0: 距離が0 &amp;lt;=&amp;gt; 零ベクトル  以下の式で表されるノルムをLpノルムと呼ぶ。
L1ノルム(マンハッタン距離) 絶対値の和。座標軸方向にしか移動できない縛りでの距離。 StreetとAvenueが格子状になっているマンハッタンではタクシーが移動する距離はL1ノルムのようになる。
L2ノルム(ユークリッド距離) 2乗の和の平方根。普通の距離。
正則化(regularization) 機械学習で過学習を防ぐためのもの。 Lp正則化は重みのLpノルムをp乗してハイパーパラメータΛを掛けたものを正則化項として 素の損失関数に加える。これを最小化するのだから重みがペナルティとしてはたらく。 L1正則化ではΛが大きければいくつかの重みが0になって次元削減できるが、 L2正則化では重みに比例して小さくなるだけ。それぞれLasso回帰、Ridge回帰ともいう。 また、これらを割合で足して使うElasticNetというものもある。
参考 Norm (mathematics) - Wikipedia
RでL1 / L2正則化を実践する - 六本木で働くデータサイエンティストのブログ</description>
    </item>
    
    <item>
      <title>OpenID ConnectのIDトークンの内容と検証</title>
      <link>https://www.sambaiz.net/article/136/</link>
      <pubDate>Mon, 09 Oct 2017 20:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/136/</guid>
      <description>OpenID Connectは認可(AuthoriZation)のプロトコルであるOAuth 2.0を正しく認証(AutheNtication)に使うためのプロトコル。
OpenID Connect Core 1.0(日本語訳)
OAuth2.0のメモ - sambaiz-net
OpenID ConnectではOAuthのアクセストークンに加えて Issuer(IdP)によって署名されたJWT(JSON Web Token)形式のIDトークンも返す。 このIDトークンの署名を検証し、含まれるIssuerとクライアントの情報を参照することで OAuthのImplicit flowでのトークン置き換え攻撃を防ぐことができる。
JWT/IDトークン JWTはRFC7519で定義されている、 パーティ間で安全にClaim(エンドユーザーのようなエンティティの情報)を受け渡すための表現方法。 JSONにエンコードしたClaimは、JOSE(Javascript Object Signing and Encryption)のサブセットであるJWS(JSON Web Signature)のペイロードとして署名を付与されるか、JWE(JSON Web Encryption)で暗号化される。 以下のJWTはJWSのもの。
JWSには(ヘッダ).(ペイロード).(署名)の文字列で表現されるCompact SerializationとJSONで表現されるJSON Serializationがあるが、JWTではCompact Serializationを使う。
ヘッダには署名に使うアルゴリズムalgが含まれる。 JWTを受け取った際、不正なalgになっていないかチェックする必要がある。
{ &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;, &amp;quot;kid&amp;quot;: &amp;quot;5b0924f6f83c719514987954cf66683b370677d4&amp;quot; }  ペイロードには以下のようなClaimが含まれる。これ以外のClaimを含めることもできる。
{ &amp;quot;iss&amp;quot;: &amp;quot;https://server.example.com&amp;quot;, # IssuerのIdentifier。httpsのURL &amp;quot;sub&amp;quot;: &amp;quot;24400320&amp;quot;, # Subject Identifier。Issuerでユニークなエンドユーザーの識別子。 &amp;quot;aud&amp;quot;: &amp;quot;s6BhdRkqt3&amp;quot;, # audience。OAuth2.0のclient_id &amp;quot;nonce&amp;quot;: &amp;quot;n-0S6_WzA2Mj&amp;quot;, # リクエストで送ったのがそのまま返ってくる。リプレイ攻撃を防ぐため &amp;quot;exp&amp;quot;: 1311281970, # IDトークンの有効期限。時間はすべてUNIXエポック秒 &amp;quot;iat&amp;quot;: 1311280970, # IDトークンの発行時刻 &amp;quot;auth_time&amp;quot;: 1311280969 # エンドユーザーの認証時刻 }  IDトークンを取得する GoogleのOAuth 2.</description>
    </item>
    
    <item>
      <title>RSA暗号とPEM/DERの構造</title>
      <link>https://www.sambaiz.net/article/135/</link>
      <pubDate>Sun, 01 Oct 2017 21:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/135/</guid>
      <description>RSA暗号とは  暗号化: c ≡ m^e (mod n) 複合: m ≡ c^d (mod n)  公開鍵がe,nで秘密鍵がd。nはとても大きく近くない素数p,qの積で、 これを公開しても素因数分解できないのがこの暗号の前提になっている。 768bit(10進数で232桁)では既に解読されているので、少なくとも1024bit以上にする。
eはEuler totient function(1~nまでの整数でnと互いに素なものの個数。今回の場合はφ(n)=(p-1)(q-1))未満で互いに素な正の整数で、小さすぎても大きすぎてもだめ。2^16 + 1 = 65537がよく使われる。
dはed ≡ 1 (mod φ(n))を満たすd。
例 例として(p,q)=(193,709)とするとこんな感じ。
 n = p * q = 136837 φ(n) = (p-1)(q-1) = 135936 e = 65537 &amp;lt; φ(n)  秘密鍵dは65537*d ≡ 1 (mod 135936)の式を変形した 65537*d - 135936*x = gcd(65537,135936) = 1を、拡張されたユークリッドの互除法で解く。 以下のように135936と65537を残しながら展開していく。
135936 = 65537 * 2 + 4862 =&amp;gt; 4862 = 135936 * 1 + 65537 * -2 65537 = 4862 * 13 + 2331 =&amp;gt; 2331 = 65537 - (135936 * 1 + 65537 * -2) * 13 = 135936 * -13 + 65537 * 27 4862 = 2331 * 2 + 200 =&amp;gt; 200 = (135936 * 1 + 65537 * -2) - (135936 * -13 + 65537 * 27) * 2 = 135936 * 27 + 65537 * -56 2331 = 200 * 11 + 131 =&amp;gt; 131 = (135936 * -13 + 65537 * 27) - (135936 * 27 + 65537 * -56) * 11 = 135936 * -310 + 65537 * 643 .</description>
    </item>
    
    <item>
      <title>自己情報量、エントロピー、KL情報量、交差エントロピー</title>
      <link>https://www.sambaiz.net/article/134/</link>
      <pubDate>Mon, 25 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/134/</guid>
      <description>自己情報量 P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。
log(P)+log(Q)=log(P*Q)より加法性がある。 例えば、サイコロで1の目が2回連続で出る(P=1&amp;frasl;36)情報量(5.16bits)はサイコロで1の目が出る(P=1&amp;frasl;6)情報量(2.58bits)の2倍と等しい。 確率が高ければ高いほど自己情報量は小さくなり、P(ω)=1では0bitになる。
エントロピー 確率分布Pに従う確率変数Xのエントロピーは以下の式で定義される。情報量の平均。
これは情報を送る際に必要なビット数の平均の下限になっている。 例えば、Xが1~4の値を(0.8, 0.1, 0.06, 0.04)の確率でとるとする。 4通りなのだからそれぞれ2bits(00, 01, 10, 11)のコードで表すこともできるが、 ほとんど3や4は出ないのだからbit数を偏らせて(0, 10, 110, 111)のコードで表すと 0.8*1 + 0.1*2 + 0.06*3 + 0.04*3 = 1.3bitsまで減らすことができる。 この場合のエントロピーは1.01bitsで、これより小さくすることはできない。
カルバック・ライブラー情報量 離散確率分布PのQに対するカルバック・ライブラー情報量は以下の式で定義される。連続確率分布では積分する。 Qの自己情報量からPの自己情報量を引いて平均を取ったもの。ギブスの不等式より非負の値を取る。
交差エントロピー 離散確率分布PとQの交差エントロピーは以下の式で定義される。連続確率分布では積分する。 PのエントロピーにPのQに対するKL情報量を足したもの。
これはQの分布に最適化されたコードでPの分布の確率変数の情報を送ってしまった際に必要なビット数の平均の下限になっている。KL情報量が余分な分。
参考 Self-information - Wikipedia
Kullback–Leibler divergence - Wikipedia
情報理論を視覚的に理解する (3&amp;frasl;4) | コンピュータサイエンス | POSTD</description>
    </item>
    
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>ニューラルネットワークの活性化関数は各層での重み掛けバイアス足しのあとに適用する非線形の関数。 というのも、線形な計算を繰り返したところで
f(x) = ax + b g(x) = f(f(x)) = (a^2)x + (ab + b)  のように単一の線形関数で表現できてしまい、多層にする意味がないため。 また、バックプロバゲーション(誤差逆伝播法)のために微分できる必要もある。
Tensorflowでも以下の活性化関数が用意されている。
sigmoid y = 1 / (1 + exp(-x))。値域は(0,1)でシグマの語末系ςに似たS字を描く。 xが大きいときに微分係数が小さくなるため、何層もこの関数を適用するとき、バックプロバゲーションで微分係数を掛けた結果、勾配が消滅(Gradient vanishing)する問題があり、あまり使われないようだ。値域が(-1,1)で似たグラフを描くtanh(Hyperbolic tangent)もある。
softsign x/(1 + abs(x))。tanhと比べて漸近線に近づく速度が遅くなっている。 それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。
softplus log(1 + exp(x))。ReLUに続く。
ReLU(Rectified Linear Unit) max(0, x)。単純だけど最有力。Gradient vanishingも起きない。 softplusと比べてexpやlogを含まない分高速に計算できるので、 膨大で複雑なデータセットに対して多くの層を用いることができる。
0以下は等しく0になるため、トレーニング中に落ちてしまうとニューロンが死んでしまうことがある。 そのような場合は0以下のときy = exp(x) - 1にするELU(Exponential Linear Unit) などを使う。
参考 Activation functions and it’s types-Which is better?
最適化から見たディープラーニングの考え方
Understanding the difficulty of training deep feedforward neural networks</description>
    </item>
    
    <item>
      <title>Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った</title>
      <link>https://www.sambaiz.net/article/132/</link>
      <pubDate>Sun, 10 Sep 2017 23:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/132/</guid>
      <description>PuppeteerでHeadless Chromeを動かすコードを Lambda上で動かすStarter Kitを作った。
puppeteer-lambda-starter-kit
Chromeの準備 Puppeteerのインストール時に落としてくるChromeをLambda上で動かそうとしても Lambdaにないshared libraryに依存しているため失敗する。
error while loading shared libraries: libpangocairo-1.0.so.0: cannot open shared object file: No such file or directory  Lambda上でHeadless Chromeを動かす例がないか調べたらserverless-chromeというのがあって、 Headless用の設定でChromeをビルドしていた。 ほかにはchromelessというのもあるけど これはserverless-chromeに 依存している。 最小構成でPuppeteerを使いたかったので、今回はこれらを使わず一から作ることにした。
serverless-chromeにもビルドしたものが置いてあるが、少しバージョンが古いようだったので最新版でビルドした。 基本的には書いてある 通りやればうまくいく。他のプロセスとのshared memoryとして/dev/shmを使っているのを、/tmpに置き換える ようにしないと、実行時のpage.goto()でFailed Provisional Load: ***, error_code: -12になる。
ビルドしたheadless_shellには問題になった依存は含まれていないようだ。
$ ldd headless_shell linux-vdso.so.1 =&amp;gt; (0x00007ffcb6fed000) libpthread.so.0 =&amp;gt; /lib64/libpthread.so.0 (0x00007f5f17dbe000) libdl.so.2 =&amp;gt; /lib64/libdl.so.2 (0x00007f5f17bba000) librt.so.1 =&amp;gt; /lib64/librt.so.1 (0x00007f5f179b1000) libnss3.so =&amp;gt; /usr/lib64/libnss3.so (0x00007f5f17692000) libnssutil3.so =&amp;gt; /usr/lib64/libnssutil3.so (0x00007f5f17466000) libsmime3.</description>
    </item>
    
    <item>
      <title>Headless Chromeでファイルをダウンロードする</title>
      <link>https://www.sambaiz.net/article/131/</link>
      <pubDate>Sun, 03 Sep 2017 18:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/131/</guid>
      <description>Chrome DevTools Protocolに ExperimentalだけどPage.setDownloadBehavior というのがあったので、これを呼んでファイルをダウンロードしてみた。
今回は公式のDevToolsのNode API、Puppeteerを使うけど、 setDownloadBehaviorを送るAPIはまだなく、直接clientを取ってsendするので他のライブラリでもやることは変わらないと思う。 Puppeteerのインストールの際にChromiumも入る。setDownloadBehaviorは現行Chromeの60では対応していないようだけど、62が入ったのでなんとかなりそう。
$ yarn add puppeteer $ find . -name &amp;quot;*chrome*&amp;quot; ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_100_percent.pak ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_200_percent.pak  ちなみに、このChromeをLambda上で実行しようとすると失敗する。
Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った
ChromeでChromeをダウンロードしてみる。
const puppeteer = require(&#39;puppeteer&#39;), fs = require(&#39;fs&#39;); const headless = true, downloadPath = &#39;./Download&#39;; (async () =&amp;gt; { const browser = await puppeteer.launch({headless: headless}); const page = await browser.newPage(); await page._client.send( &#39;Page.setDownloadBehavior&#39;, {behavior : &#39;allow&#39;, downloadPath: downloadPath} ); await page.goto(&#39;https://www.google.co.jp/chrome/browser/desktop/index.html&#39;, {waitUntil: &#39;networkidle&#39;}); await page.</description>
    </item>
    
    <item>
      <title>floatとdoubleの表現と精度</title>
      <link>https://www.sambaiz.net/article/130/</link>
      <pubDate>Sat, 02 Sep 2017 12:47:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/130/</guid>
      <description>IEEE754の仕様。記憶が薄れていたのでまとめておく。
float(32bit)は
 1bit: 符号 8bit: 指数部(exponent) 23bit: 仮数部(fraction)  double(64bit)は
 1bit: 符号 11bit: 指数部 52bit: 仮数部  で表される。
例えば-5.25(2進で-101.01)を表す場合、 -1.0101 * 2^2のように±1.xxxx * 2^nの形にして、負なら符号を1に、指数部を正(1~254or2046)にするため nに127or1023のバイアスを足した数を入れ、仮数部にはxxxxの部分の後ろに0を詰めたのをそのまま入れる。 したがって、-5.25のfloatは1 10000001 01010000000000000000000になる。
ただし、指数部が0のときは仮数部xxxxに対して0.xxxx * 2^-126or1022のように解釈し、 0や指数部で表すことができる数(2^-126or1022)より絶対値が小さい非正規化数を表すことができるようになっている。 また、Infinityはそれぞれ(255or2047,0)、NaNは(255or2047,0以外)で表す。
精度は仮数部の大きさに依存し、floatが10進でMath.log10(2 ** 23) = 6.92桁で、doubleがMath.log10(2 ** 52) = 15.65桁。JavaScriptの数値はdoubleなので 1234567890.1234569が1234567890.123457になり16~17桁目で値がおかしくなることが確認できる。
参考 IEEE 754 - Wikipedia
Double-precision floating-point format - Wikipedia</description>
    </item>
    
    <item>
      <title>Pythonのインタラクティブな可視化ライブラリBokehでグラフを描く</title>
      <link>https://www.sambaiz.net/article/129/</link>
      <pubDate>Sat, 26 Aug 2017 18:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/129/</guid>
      <description>Pythonの可視化というとmatplotlibや、 そのラッパーのseaborn、 データ解析ライブラリのPandasにもそういう機能があるけど、 これらが表示するのが静止画なのに対して、BokehはD3.jsで描画し、 拡大したりスクロールしたり、動的に何か表示することができる。Bokehはカメラのボケ。 似たようなのにPlotlyというのもあるけど、 こちらはPandasと同じpydata.orgドメインで、スターが多い。
jupyter/datascience-notebookイメージにもBokehがインストールされている。
$ docker run -d -p 8888:8888 jupyter/datascience-notebook start-notebook.sh  簡単なグラフを描く output_notebookでJupytor Notebokに出力する。ファイルに出力する場合はouput_fileを呼ぶ。
from bokeh.plotting import figure from bokeh.io import output_notebook, show output_notebook()  figure()でplotするFigureオブジェクトを作成する。
p = figure( title=&amp;quot;Hoge&amp;quot;, x_axis_label=&#39;x&#39;, y_axis_label=&#39;y&#39;, y_axis_type=&amp;quot;log&amp;quot; )  line()で線をつないでcircle()で円を描く。
x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0] y0 = [i**2 for i in x] y1 = [10**i for i in x] y2 = [10**(i**2) for i in x] p.</description>
    </item>
    
    <item>
      <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
      <link>https://www.sambaiz.net/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/128/</guid>
      <description>Hiveとは Hadoop上で動くデータウェアハウスソフトウェア。 SQLを拡張したHiveQLを書くとデータを処理するMapReduceやSpark、Tezのジョブが生成される。 クエリの実行に時間がかかり、耐障害性があるのでDailyやHourlyのバッチで使われる。
ちなみにAthenaにも使われているPresto はタスクを並列に実行し、中間データをメモリ上に持つことで数分以内に結果が得られるので ダッシュボードなどの用途でアドホックに使える。中間データが大きいと時間がかかったり失敗する。
Impalaはさらに速いけどメモリの消費が激しいらしい。
Cloudera Docker Imageを起動する Cloudera Docker Imageには
 CDH: Clouderaのディストリビューション。Hadoop、Hive、SparkなどのOSSで構成されている。 Cloudera Manager: CDHクラスタを管理する。無料のExpressと有料のEnterpriseで使える機能に差がある。  が含まれていて、これを起動すると諸々立ち上がる。CDHクラスタを組むのはサポートされていないようなのでテスト用らしい。
$ docker pull cloudera/quickstart:latest $ docker run --hostname=quickstart.cloudera --privileged=true -itd -p 8888 -p 7180 -p 80 cloudera/quickstart /usr/bin/docker-quickstart  80がチュートリアルで、8888がHadoopのWeb UIのHue、7180がCloudera Manager。Dockerに割り当てるメモリが2GBだとFailed to contact an active Resource Managerになってしまったので4GBにした。
Hiveのテーブルを作成して実行する チュートリアルではSqoopを使ってDBから取り込んでいるんだけど、 今回はjsonのログのテーブルを作成する。
$ sqoop import-all-tables \ -m 1 \ --connect jdbc:mysql://localhost:3306/retail_db \ --username=retail_dba \ --password=cloudera \ --compression-codec=snappy \ --as-parquetfile \ --warehouse-dir=/user/hive/warehouse \ --hive-import  JSONを扱うにはStringからLATERAL VIEW json_tuple(json_str, &amp;quot;field1&amp;quot;, &amp;quot;field2&amp;quot;) j AS field1, field2のように実行時にパースする方法と、JSON SerDeで最初から別カラムにいれる方法があるが、今回はSerDeでやる。</description>
    </item>
    
    <item>
      <title>CloudflareでカスタムドメインのGitHub PagesにHTTPSでアクセスできるようにする</title>
      <link>https://www.sambaiz.net/article/127/</link>
      <pubDate>Mon, 21 Aug 2017 23:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/127/</guid>
      <description>このサイトはGitHub Pagesでカスタムドメインsambaiz.netを設定して、 Apex Domain(sambaiz.net)にAレコードを登録して運用していたのだけれど、これだとカスタムドメインの証明書を置けないのでHTTPSでアクセスすると警告が出てしまう。 いい加減HTTPだと許されない風潮になってきたのでCloudflareを前に挟んでHTTPSでアクセスできるようにした。 ついでにCNAMEを登録できないApex Domain(sambaiz.net)をやめてwww.sambaiz.netに向ける。
DNSの設定をする Cloudflareでドメインを入れると既存のDNS Recordsを読み込むので必要に応じて修正する。 CloudflareではCNAME FlatteningによってApex Domainにも設定上ではCNAMEを与えることができ、内部でAレコードに解決してくれる。 そのためApex Domainをそのまま使っても実は問題ないのだけど、今後のために変えておく。 www.sambaiz.netにGitHub PagesのCNAMEを設定し、sambaiz.net(@)にはwww.sambaiz.netをCNAMEとして設定した。
あとGitHub Pagesの方のカスタムドメインもwww.sambaiz.netにした。 wwwを設定するとApex Domainでアクセスしたときにリダイレクトするようになっているので 既存のリンクが切れたり混在することはない。
指示された*.ns.cloudflare.comのようなCloudflareのネームサーバーをドメインに設定する。 さくらの場合、Apex Domainのネームサーバーはゾーン表示ではなくWHOIS情報のところから変更できる。 設定してしばらくするとCloudflareを通してアクセスが飛び警告なくHTTPSでアクセスできるようになる。 証明書は共有のものになっている。
正常にアクセスできることを確認できたら今HTTPになっている画像やリンクもHTTPSにする。
$ find . -name &#39;.git*&#39; -prune -o -name &#39;public&#39; -prune -o -name &#39;static&#39; -prune -o -type d -o -print | xargs sed -i &amp;quot;&amp;quot; &amp;quot;s/http:\/\/sambaiz.net/https:\/\/www.sambaiz.net/g&amp;quot;  Cloudflareの機能 Cloudflareにはいくつかプランがあって、今回はFreeプランにした。
Analytics  キャッシュされている/ないリクエスト数や帯域、それによる節約量 ブロックした脅威の数 何人/どこの国からアクセスが来たか コンテンツ(HTML/CSS/PNG)ごとのリクエストの割合  などがわかる。FreeだとWeb TrafficやGeographyが直近24時間より短いスパンで取れない。
Crypto SSLまわりの設定。
 Flexible: クライアントとCloudflareはHTTPS、CloudflareとオリジンサーバーはHTTPで通信する。 Full: デフォルト。Cloudflareとオリジンサーバーの通信もHTTPSで行うが、証明書の検証は行われない。 Full(Strict) 証明書の検証も行う。  から選択する。Business以上のPlanだと共有の証明書ではなく独自のものを上げることもできる。</description>
    </item>
    
    <item>
      <title>HDFS(Hadoop Distributed File System)とは</title>
      <link>https://www.sambaiz.net/article/126/</link>
      <pubDate>Mon, 14 Aug 2017 22:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/126/</guid>
      <description>HDFSとは Hadoopの分散ファイルシステム。 Hadoopの抽象化されたファイルシステム実装の一つで、他の実装にはLocal fileやS3などがある。 データのサイズが大きい場合に特に問題になるディスクI/Oを分散させ、 読み書きする最小の単位であるブロックサイズを大きくしシークのコストを減らすことで スループットを高めている。 ディスクI/Oがどれくらい遅いかというと、 シークがデータセンター内での往復の通信の20倍(10ms)、 1MBの読み込みが40倍の時間(20ms)かかる。
一方、小さなデータに低レイテンシでアクセスするというのは得意でなく、 また、1ファイルあたり150バイトのメタデータがNameNodeのメモリ上に乗っかるため大量のファイルを扱うのは大変。 あとデータは追記しかできない。
NameNodeとDataNode クラスタの中にはおおよそ2種類のノードがあって、 ブロックがあるいくらかのDataNodeと、
 ファイルの階層とメタデータ どのDataNodeにそのファイルのブロックがあるか  の情報が含まれる
 fsimage(メタデータのスナップショット) edit log(fsimageに含まれていない変更ログ)  を保存する、名前空間に単一のNameNodeがある。 もう一つSecondary NameNodeというのがあって、これはedit logが大きくならないよう 定期的にedit logをfsimageにマージするもの。
NameNodeが機能停止すると読み書きできなくなってしまうので、 新しいNameNodeを立てる必要がある。 その際fsimageにedit logを適用して状態を復元するため これらのファイルを別のファイルシステムにバックアップなどして失われないようにする。
巨大なクラスタだとNameNodeを立ち上げるのに30分以上かかることもあるため、 Secondary NameNodeの代わりにStandby NameNodeを立ててHigh Availabilityにすることもできる。 Standby NameNodeはNameNodeと共有ストレージでedit logを共有し、最新の状態がメモリ上に乗っているので NameNodeが死んだと判断されてから数十秒ほどで切り替えることができる。
書き込みと読み込み 書き込み ファイルシステムがNameNodeとやりとりして、ファイルが存在しているか、パーミッションがあるかを確認し、問題なければFSDataOutputStreamをクライアントに返す。 書き込むデータはdata queueにまず入って、 どのDataNodeに書き込むかはDataStreamerというのがNameNodeとやりとりして決める。 レプリカの設定数分DataNodeが選ばれ、順に書き込まれるようDataNode間でパイプラインを作る。 正常に書き込まれたDetaNodeからはack packetが返ってくるのでこれはack queryに入れて 全て正しく書き込まれたことが確認できたら消す。 失敗したDataNodeがあったら、そこに中途半端に書き込まれた分を復活したら消すようにして、パイプラインから除き 新しいパイプラインを作る。
読み込み ファイルシステムがNameNodeにファイルのブロックがどこにあるかを聞く。 NameNodeは、ブロックがあるDataNodeをクライアントからネットワークトポロジ的に近い順にソートしてアドレスを返す。 ファイルシステムはそのアドレスが含まれたFSDataInputStreamをクライアントに返して、クライアントが順にreadしていく。
SingleNode Clusterで動かす $ yum --enablerepo=epel -y install pdsh $ echo $JAVA_HOME /usr/lib/jvm/jre $ wget http://ftp.</description>
    </item>
    
    <item>
      <title>PythonのLintとFormatter</title>
      <link>https://www.sambaiz.net/article/125/</link>
      <pubDate>Fri, 11 Aug 2017 14:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/125/</guid>
      <description>YAPF スタイルに沿って整形してくれる、Goでいうgo fmtみたいなもの。 デフォルトはPython公式のスタイルガイドPEP8でフォーマットされる。
$ pip install yapf  VSCodeでPythonを書くときは、 Pythonプラグイン を入れてこんな設定をWorkspaceのconfigに入れておいて、 保存した時にフォーマットがかかるようにすると快適。
&amp;quot;editor.formatOnSave&amp;quot;: true, &amp;quot;python.formatting.provider&amp;quot;: &amp;quot;yapf&amp;quot;  Lint YAPFでフォーマットされた以下のコードにLintをかける。
class FizzBuzz: def __init__(self, start=0): self.num = start def __iter__(self): return self def __next__(self): self.num += 1 if self.num % 15 == 0: return &amp;quot;FizzBuzz&amp;quot; if self.num % 3 == 0: return &amp;quot;Fizz&amp;quot; if self.num % 5 == 0: return &amp;quot;Buzz&amp;quot; return self.num if __name__ == &amp;quot;__main__&amp;quot;: fizzBuzz = FizzBuzz() for i in range(100): print(next(fizzBuzz))  Pylint PythonプラグインではデフォルトでPylintが使われる。</description>
    </item>
    
    <item>
      <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
      <link>https://www.sambaiz.net/article/124/</link>
      <pubDate>Sun, 06 Aug 2017 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/124/</guid>
      <description>AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリSonnetを使う。 当初はPython2しか対応していないようだったけど、今は3にも対応している。
準備 TensorFlowを使うライブラリはほかにもいくつかあるのだけど、 Kerasと比較してみると、 KerasがTensorFlowの部分を完全にラップしているのに対して、 Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。
SonnetとTensorFlowとPython3入りイメージをDockerHubに上げた。 Dockerfileはここ。
内容は基本的にREADME通りだけど、 configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。 あとは、TensorFlowのビルドに使われているGCCのバージョンが古いようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;を付けている。
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_  起動。
$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet $ docker logs sonnet ... Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=*****  Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。
import sonnet as snt import tensorflow as tf snt.resampler(tf.constant([0.]), tf.constant([0.])) # =&amp;gt; &amp;lt;tf.</description>
    </item>
    
    <item>
      <title>Node.jsをTypeScriptで書く</title>
      <link>https://www.sambaiz.net/article/123/</link>
      <pubDate>Sat, 29 Jul 2017 19:34:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/123/</guid>
      <description>公式のTypeScript-Node-Starterから始めてもいいけど、依存が少し余分なので一から作ることにした。
コードはここ。
$ yarn add --dev typescript tslint tslint-microsoft-contrib jest ts-jest @types/jest  package.json scriptsとテストフレームワークJestの設定を追加。
{ &amp;quot;devDependencies&amp;quot;: { ... &amp;quot;typescript&amp;quot;: &amp;quot;^2.4.2&amp;quot; }, &amp;quot;scripts&amp;quot;: { &amp;quot;start&amp;quot;: &amp;quot;npm run build &amp;amp;&amp;amp; node dist/app.js&amp;quot;, &amp;quot;build&amp;quot;: &amp;quot;npm run lint &amp;amp;&amp;amp; tsc&amp;quot;, &amp;quot;test&amp;quot;: &amp;quot;jest --forceExit&amp;quot;, &amp;quot;lint&amp;quot;: &amp;quot;tslint -c tslint.json -p tsconfig.json --type-check&amp;quot; }, &amp;quot;jest&amp;quot;: { &amp;quot;transform&amp;quot;: { &amp;quot;^.+\\.ts$&amp;quot;: &amp;quot;./node_modules/ts-jest/preprocessor.js&amp;quot; }, &amp;quot;testRegex&amp;quot;: &amp;quot;/test/.*\\.test\\.(ts|js)$&amp;quot;, &amp;quot;moduleFileExtensions&amp;quot;: [ &amp;quot;ts&amp;quot;, &amp;quot;js&amp;quot; ], &amp;quot;testEnvironment&amp;quot;: &amp;quot;node&amp;quot; } }  tsconfig.json 公式のそのまま。</description>
    </item>
    
    <item>
      <title>k8sのパッケージマネージャーHelmを使う</title>
      <link>https://www.sambaiz.net/article/122/</link>
      <pubDate>Wed, 26 Jul 2017 01:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/122/</guid>
      <description>Kubernatesが操舵手なのに対して、Helmは舵。 パッケージはChart(海図)と呼ばれている。
Helmをインストールし、minikubeを立ち上げる。
$ brew install kubernetes-helm $ helm version Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.5.0&amp;quot;, GitCommit:&amp;quot;012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} # brew cask install virtualbox minikube $ minikube version minikube version: v0.20.0 $ minikube start Kubectl is now configured to use the cluster. $ kubectl version Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.2&amp;quot;, GitCommit:&amp;quot;922a86cfcd65915a9b2f69f3f193b8907d741d9c&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2017-07-21T19:06:19Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;} Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;6&amp;quot;, GitVersion:&amp;quot;v1.6.4&amp;quot;, GitCommit:&amp;quot;d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-06-22T04:31:09Z&amp;quot;, GoVersion:&amp;quot;go1.7.5&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;} $ kubectl config current-context minikube  k8sクラスタ上にHelmの管理サーバーTillerをインストールする必要がある。 ついでにリポジトリもupdateする。</description>
    </item>
    
    <item>
      <title>TerraformでVPCを管理するmoduleを作る</title>
      <link>https://www.sambaiz.net/article/121/</link>
      <pubDate>Sun, 23 Jul 2017 02:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/121/</guid>
      <description>Terraform
$ brew install terraform $ terraform -v Terraform v0.9.11  Terraformの設定要素 provider IaaS(e.g. AWS)、PaaS(e.g. Heroku)、SaaS(e.g. CloudFlare)など。
AWS Providerはこんな感じ。 ここに直接access_keyやsecret_keyを書くこともできるけど、誤って公開されてしまわないように環境変数か variableで渡す。
provider &amp;quot;aws&amp;quot; { # access_key = &amp;quot;${var.access_key}&amp;quot; # secret_key = &amp;quot;${var.secret_key}&amp;quot; region = &amp;quot;us-east-1&amp;quot; }  $ export AWS_ACCESS_KEY_ID=&amp;quot;anaccesskey&amp;quot; $ export AWS_SECRET_ACCESS_KEY=&amp;quot;asecretkey&amp;quot;  varibale CLIでオーバーライドできるパラメーター。typeにはstringのほかにmapやlistを渡すことができ、 何も渡さないとdefault値のものが、それもなければstringになる。
variable &amp;quot;key&amp;quot; { type = &amp;quot;string&amp;quot; default = &amp;quot;value&amp;quot; description = &amp;quot;description&amp;quot; }  値を渡す方法はTF_VAR_をprefixとする環境変数、-var、-var-fileがある。 また、moduleのinputとして渡されることもある。
$ export TF_VAR_somelist=&#39;[&amp;quot;ami-abc123&amp;quot;, &amp;quot;ami-bcd234&amp;quot;]&#39; $ terraform apply -var foo=bar -var foo=baz $ terraform apply -var-file=foo.</description>
    </item>
    
    <item>
      <title>HoloLensでのUnityアプリケーションのフレームレート</title>
      <link>https://www.sambaiz.net/article/120/</link>
      <pubDate>Sun, 16 Jul 2017 23:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/120/</guid>
      <description>HoloLensディスプレイのフレームレート HoloLensのディスプレイは60fpsでリフレッシュされるので、アプリケーションもこれに合わせて60fps、 つまり16msごとにOSにイメージを渡せるのがベスト。 ただし、安定して60fpsが実現できないような重いアプリケーションの場合、 変動してしまうよりは下げて安定させる方が良い。
フレームレートはDevice Portalから確認することができ、キャプチャする際は30fpsに制限される。
Unityアプリケーションのフレームレート Unityでのフレームレートは Application.targetFrameRate で設定できる。デフォルト値は-1で、その場合プラットフォームごとのデフォルト設定が使われる。 何も設定しない状態でHoloLensで動かしたところ60fpsになった。
Debugビルドでのフレームレートの低下 DebugビルドだとSpace Robot Kyle だけ描画するだけでもフレームレートが20まで下がってしまった。
HoloLensで剣振ってみた - sambaiz-net
DebugビルドだったのをRelasseビルドに変えたら60fpsになった。 Relaseビルドではコードの最適化にチェックが入っていたりするんだけど、 その辺りを外してみても特に変わらなかったのでそれではないらしい。</description>
    </item>
    
    <item>
      <title>HoloLensで剣振ってみた</title>
      <link>https://www.sambaiz.net/article/119/</link>
      <pubDate>Sun, 09 Jul 2017 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/119/</guid>
      <description>かつてCardboardでやったようにHoloLensでも剣を振ってみた。
剣を振るVRゲームを作った - sambaiz-net
剣を振ってロボットに当てると爆発する。
動画
剣の方は前回と同じくiOSアプリから傾きをBLEで送信している。今回は傘がなかったのでペットボトルにくくりつけた。
HoloLensのアプリの方はUWPのネイティブプラグインを作った。 Creater&amp;rsquo;s UpdateのAPIがまだ使えなかったので一つ前のAPIを使ってビルドしている。 なお、ペアリングはアプリ内ではなくOSの設定画面から行なっている。 エラーについては原因が分からずハンドリングできていないものもあるけど、つなぎ直すと大抵どうにかなった。 つなぎ直す際はHoloLens側だけではなくiOS側の方の設定も削除する。
Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net
ロボットを小さくしているのは近づいても視野角に収まるようにするため。 小さいとどこにいるか分からないので目印を出したほうが良い。 近接武器じゃなきゃ敵に近づかなくてよくなるのでましになるかも。
上の動画を見れば分かるように、全体的に動きが重くて素でframerateが20ぐらいしか出ていない。 これはReleaseビルドにすると改善された。
HoloLensでのUnityアプリケーションのフレームレート - sambaiz-net</description>
    </item>
    
    <item>
      <title>HoloLensのSpartial MappingでNavMeshを生成してランダムにAgentを出現・移動させる</title>
      <link>https://www.sambaiz.net/article/118/</link>
      <pubDate>Sun, 02 Jul 2017 23:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/118/</guid>
      <description>Unity 5.6.2f1 HoloToolkit v1.5.7.0  Unity 5.6から動的にNavMeshを生成できるようになったので HoloLensのSpartial MappingしたものをNavMeshにしてAgentを動かしてみる。
Unityで動的にNavMeshを生成する - sambaiz-net
Spartial MappingしたものをNavMeshにするのは以下の記事のスクリプトを使った。
HoloLens の空間マップで NavMesh を使ってみる - たるこすの日記
Unity-Technologies/NavMeshComponentsから LocalNavMeshBuilderとNavMeshSourceTagを持ってきてLocalNavMeshBuilderのObjectを置いておき、 Spartial MappingしたものにNavMeshSourceTagを付けられればExampleと同様にNavMeshにできる。 そこで、このスクリプトではSpatialMappingSourceを取得し、イベントハンドラでNavMeshSourceTagが追加されるようにしている。
using HoloToolkit.Unity.SpatialMapping; using UnityEngine; using HoloToolkit.Unity; public class SpatialMappingNavMesh : MonoBehaviour { public GameObject SpatialMapping; private void Awake() { var spatialMappingSources = SpatialMapping.GetComponents&amp;lt;SpatialMappingSource&amp;gt;(); foreach (var source in spatialMappingSources) { source.SurfaceAdded += SpatialMappingSource_SurfaceAdded; source.SurfaceUpdated += SpatialMappingSource_SurfaceUpdated; } } private void SpatialMappingSource_SurfaceAdded(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceObject&amp;gt; e) { e.Data.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;(); } private void SpatialMappingSource_SurfaceUpdated(object sender, DataEventArgs&amp;lt;SpatialMappingSource.</description>
    </item>
    
    <item>
      <title>Unityで動的にNavMeshを生成する</title>
      <link>https://www.sambaiz.net/article/117/</link>
      <pubDate>Sat, 01 Jul 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/117/</guid>
      <description>Unity5.6から動的にNavMeshを生成できるようになった。
Unity-Technologies/NavMeshComponentsの Exampleの2_drop_blankのsceneを開く。
分断されたCubeの床と、その上に黄色いCylindarと赤いCubeがあって、 クリックしたところに黄色いCylindarが動くんだけど、床がつながっていないのでそのままでは赤いCubeまではたどり着けない。 スペースを押すと目の前に板が出てくるのでこの上を渡って移動することができる。
板の上がNavMeshとして認識されている。
床のCubeと追加される板にはNavMeshSourceTag.csが付いていて、staticなm_Meshesとm_Terrainsにそれぞれ追加している。
public static List&amp;lt;MeshFilter&amp;gt; m_Meshes = new List&amp;lt;MeshFilter&amp;gt;(); public static List&amp;lt;Terrain&amp;gt; m_Terrains = new List&amp;lt;Terrain&amp;gt;(); void OnEnable() { var m = GetComponent&amp;lt;MeshFilter&amp;gt;(); if (m != null) { m_Meshes.Add(m); } var t = GetComponent&amp;lt;Terrain&amp;gt;(); if (t != null) { m_Terrains.Add(t); } } void OnDisable() { var m = GetComponent&amp;lt;MeshFilter&amp;gt;(); if (m != null) { m_Meshes.Remove(m); } var t = GetComponent&amp;lt;Terrain&amp;gt;(); if (t != null) { m_Terrains.</description>
    </item>
    
    <item>
      <title>Fluentdのout_copyのstoreのエラーは他のstoreに影響する</title>
      <link>https://www.sambaiz.net/article/116/</link>
      <pubDate>Sat, 01 Jul 2017 18:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/116/</guid>
      <description>Fluentdのout_copyプラグインは 一つのeventを複数のoutputに渡すために使われる。 ただ、複数設定した中のstoreでエラーが起きると他のstoreにも影響してしまう。
例えばこんなの。
&amp;lt;source&amp;gt; @type dummy dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;} tag dummy rate 1 &amp;lt;/source&amp;gt; &amp;lt;match dummy&amp;gt; @type copy &amp;lt;store&amp;gt; @type stdout &amp;lt;/store&amp;gt; &amp;lt;store&amp;gt; @type file path /var/log/td-agent/dummy buffer_queue_limit 0 buffer_chunk_limit 1k &amp;lt;/store&amp;gt; &amp;lt;/match&amp;gt;  fileの方でqueue size exceeds limitになるとstdoutも出力されなくなってしまう。
ちなみに一旦relabelしてもだめ。
&amp;lt;source&amp;gt; @type dummy dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;} tag dummy rate 1 &amp;lt;/source&amp;gt; &amp;lt;match dummy&amp;gt; @type copy &amp;lt;store&amp;gt; @type stdout &amp;lt;/store&amp;gt; &amp;lt;store&amp;gt; @type relabel @label @file &amp;lt;/store&amp;gt; &amp;lt;/match&amp;gt; &amp;lt;label @file&amp;gt; &amp;lt;match dummy&amp;gt; @type file path /var/log/td-agent/dummy buffer_queue_limit 0 buffer_chunk_limit 1k &amp;lt;/match&amp;gt; &amp;lt;/label&amp;gt;  ドキュメントでも紹介されている、sonots氏のout_copy_exでは storeにignore_errorを付けるとrescueするようになっているので他に巻き込まれなくなる。</description>
    </item>
    
    <item>
      <title>Unityの経路探索: NavMeshとAgentとObstacle</title>
      <link>https://www.sambaiz.net/article/115/</link>
      <pubDate>Thu, 29 Jun 2017 00:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/115/</guid>
      <description>NavMeshと経路探索 NavMeshというのはエージェントが移動できる面についてのデータ構造で、凸ポリゴンの面と位置関係を含んでいる。 経路探索は2点間を一番近いポリゴンにマッピングし、A*アルゴリズムを用いて行われる。あとからオブジェクトが追加されるなどして道を塞いでしまってもCarvingしてNavMeshに穴をあければ別の経路で移動することができるが、このようなグローバルの経路探索に影響を及ぼす操作は計算にコストがかかるので、各エージェントローカルの衝突回避で済むならそのほうがよい。
NavMeshをbakeする こんな感じで床に適当なオブジェクトを置いてみた。
Window -&amp;gt; NavigationでBakeするのを選択してNavigation Staticし(StaticになってBakeの対象になる)、 Bakeボタンを押すとこんな感じでBakeされる。
オブジェクトの上がNavMeshに含まれていないのはAgent sizeのStep Heightよりも高いため。 段差を移動するときに浮いてしまうのを避けるためにはAdvancedのHeight Meshをオンにする。 また、端が含まれていないのはこのAgentの中心が入れる位置を表しているためで、 Agent Radiusを変更すると広がったり狭まったりするのを確認できる。
NavMesh Agent Radius0.5, Height2のCylindarを作成し、Nav Mesh Agentを追加する。
で、ゴールにオブジェクトを置いてそこまで移動させてみる。
using UnityEngine.AI; public GameObject goal; void Start () { var agent = GetComponent&amp;lt;NavMeshAgent&amp;gt;(); agent.destination = goal.transform.position; }  NavMesh Obstacle 障害物。上で通った経路上にNavMesh Obstacleを追加したCubeを置いたところうまく避けてゴールまでたどり着いた。
ただ、完全に道をふさいでしまうと立ち往生してしまうので Carveにチェックを入れるとCarvingされ、他の経路でゴールまで進むようになる。
Unityで動的にNavMeshを生成する - sambaiz-net</description>
    </item>
    
    <item>
      <title>Unityの物理エンジン・衝突: RigidbodyとCollidarとJoint</title>
      <link>https://www.sambaiz.net/article/114/</link>
      <pubDate>Sun, 25 Jun 2017 23:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/114/</guid>
      <description>Rigidbody GameObjectを物理特性によって制御し、力の影響を受けるようにする。 Mass(質量)やDrag(空気抵抗)、Use Gravityなどのプロパティがある。
移動させるのに自分でTransformは変更せず力をかけて物理演算に任せる。 Is Kinematicにチェックを入れると物理エンジンによって移動しないようになるので、 Transformを直接変更する場合は有効にする。 ただし、スクリプトで動的にIs Kinematicを切り替えるのはパフォーマンスが良くない。
Collidar RigidBodyの物理特性の境界を定義する。衝突させるには両方にCollidarが設定されている必要がある。 RigidBodyなしのCollidarを静的Collidarといって、無効にしたり移動しないことを前提に最適化される。 移動したりするものについてはRigidBodyを付けて、必要ならIs Kinematicを有効にする。
衝突時にはOnCollisionEnter() が呼ばれる。ほかに離れたときのOnCollisionExit()、 触れている間、毎フレーム呼ばれるOnCollisionStay()がある。
void OnCollisionEnter(Collision collision) { foreach (ContactPoint contact in collision.contacts) { if (contact.otherCollider.tag == &amp;quot;Player&amp;quot;) { Debug.Log(collision.relativeVelocity.magnitude); } } }  Is Triggerにチェックを入れると物理エンジンには無視されてすり抜け、侵入に対してトリガーイベントが呼ばれる。 OnCollistionと同様に OnTriggerEnter()、 OnTriggerExit()、 OnTriggerStay() がある。
void OnTriggerEnter(Collider other) { Debug.Log(other.tag); }  Joint Rigitbodyを他のRigitbodyとつなげるもの。 例えばSprint Jointだとオブジェクト間がばねのように伸縮する。</description>
    </item>
    
    <item>
      <title>fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする</title>
      <link>https://www.sambaiz.net/article/113/</link>
      <pubDate>Sun, 25 Jun 2017 00:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/113/</guid>
      <description>デプロイやスループットの調整を簡単にするため、BeanstalkでAggregatorを立ち上げた。
負荷分散 TCPの24224(設定による)が通るようにEC2,ELBのSGとリスナーの設定をする必要があって、 ELBのSGのアウトバウンドの設定が見落とされがち。ELBのクロスゾーン分散は有効になっている。
まず、ELBに3台、それぞれ別のAZ(1b, 1c, 1d)に配置されている状態でログを送り始めるとそれぞれ均等にログが届いた。 その状態から4台(1b * 2, 1c, 1d)にすると、2つのインスタンス(1b, 1c)のみに均等にログが届くようになった。 4台になると(1b, 1c)と(1b, 1d)に分けられてELBのノードがそれらの組に紐づいたということだと思う。 各ノードにはDNSラウンドロビンするようになっている。実際restartすると今度は別の組の方に送られた。
では、なぜ一度送り始めると同じ方にしか飛ばないかというと、forwardプラグインのexpire_dns_cacheがデフォルトでnilになっていて、 heartbeatが届いている間は無期限にDNSキャッシュするようになっているため。これに0(キャッシュしない)か秒数を指定すると、 その間隔で他の組のインスタンスにもログが届くようになった。 expire_dns_cacheしなくても複数のインスタンスからラウンドロビンされるため全体でいえば分散される。
heartbeat ELB配下のEC2を全て落としてもheartbeatに失敗しないため、standyに移行せずELBのバックエンド接続エラーになってログがロストしてしまうようだ。 ログにも出ず、以下のようにactive-standbyの設定をしてもstandbyに移行しない。 全てのインスタンスが同時に落ちるというのは滅多に起きないだろうけど、少なくとも検知できるようにはしておく。
&amp;lt;server&amp;gt; name td1 host autoscale-td1.us-east-1.elasticbeanstalk.com port 24224 &amp;lt;/server&amp;gt; &amp;lt;server&amp;gt; name td2 host autoscale-td2.us-east-1.elasticbeanstalk.com port 24224 standby &amp;lt;/server&amp;gt;  Blue/Green Deployment Blue-Green Deploymentというのは、2つの系を用意し、activeでない方にデプロイし、 スワップして反映させるもの。ダウンタイムなしで問題が起きた際にもすぐに切り戻すことができる。 スワップして向き先を変えるにはexpire_dns_cacheを設定する必要がある。
Auto Scaling 増えるのはいいとして減るときに、 送り先で一時的に障害が起きていたりするとバッファをflushできずにログがロストする可能性がある。 それでいうとログの送り元でも同じことが起こりうるんだけど、通常Aggregatorにしか送らないので比較的問題になりにくい。
これを避けたい場合、Auto Scalingグループの設定で スケールインから保護を有効にして これから立ち上がるインスタンスはスケールインしなくすることができる。 それまでに立ち上がっていたインスタンスには適用されないので注意。
スケールインしないということは最大の台数で止まってしまうので、 ピークを過ぎたらスワップしてバッファが全て掃けたことを確認してからTerminateすることになる。 これを日常的にやるのは面倒なので、実際は予期しない流量の増加に備えて一応設定しておき、 普段はしきい値にひっかからないような最低台数で待ち構えておくことにするかな。
あとはヘルスチェックによって潰される可能性はなくもないけど、それはもうやむなし・・・。
参考 AWS ELBの社内向け構成ガイドを公開してみる 負荷分散編 – Cross-Zone Routingを踏まえて ｜ Developers.</description>
    </item>
    
    <item>
      <title>UnityのMecanimでヒューマノイドアニメーションさせる</title>
      <link>https://www.sambaiz.net/article/112/</link>
      <pubDate>Tue, 20 Jun 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/112/</guid>
      <description>Space Robot Kyleを動かす。
アバターの作成 AssetsのModel/Robot Kyleを選択し、RigのAnimation TypeをHumanoidにすると、 自動的にボーン構造を解析して人型にマッピングしたアバターが設定される。 Configure Avatarで確認すると正しく設定されているようだ。
モーションの設定 KyleのAnimatorのAnimationに設定するAnimation Controllerを作成する。 まずは2つCreate Stateし、それぞれMotionに適当なモーション(今回はFighter Pack Bundle FREEを使った)を設定し、 Make Transitionで相互に結ぶと、オレンジになっているデフォルトステートから交互にモーションする。 ステートにはStateMachineBehaviourのScriptを設定することもできる。
次にParametersでモーションを変化させる。
Animatorの左上、parametersタブからBoolのWalkを追加する。 そして片方のTransitionのConditionにWalkがfalse、もう片方にはWalkがtrueを追加すると、 状態によって違うモーションをするようになる。 ちなみに、AnyStateからConditionを設定したTransitionを設定すると、どこのStateからでもそれで遷移させることができる。
このParameterはこんな感じに値を設定できる。
void Update () { GetComponent&amp;lt;Animator&amp;gt; ().SetBool (&amp;quot;Walk&amp;quot;, Random.value &amp;lt; 0.5); }  一部だけモーションさせる 人体の一部だけをモーションさせるにはAvatar Maskを使う。
Animationで複数のレイヤーを作成すれば、異なるMaskでそれぞれステートを持たせることができる。
Animation Override Controller 作ったAnimationを違うモーションで再利用することができる。</description>
    </item>
    
    <item>
      <title>NorikraでログをJOINする</title>
      <link>https://www.sambaiz.net/article/111/</link>
      <pubDate>Thu, 15 Jun 2017 00:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/111/</guid>
      <description>NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net
適当なログを出すコードを書いた。
sambaiz/lottery-log
これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。 広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。
// lottery.log {&amp;quot;ts&amp;quot;:1497453504.6818597,&amp;quot;uid&amp;quot;:&amp;quot;b18c0d98-19b2-4e37-8fc4-6b00a4b728c3&amp;quot;,&amp;quot;prize&amp;quot;:855,&amp;quot;isWin&amp;quot;:true} // received.log {&amp;quot;ts&amp;quot;:1497453515.932101,&amp;quot;uid&amp;quot;:&amp;quot;bc4f578f-4a5f-47f1-a4e0-1ef0b43c316e&amp;quot;}  クエリはこんな感じ。一つはlotteryログとreceivedログをuidでJOINするもので、 received_rateの計算にはサブクエリも使っている。 received_rateの計算で分母に小さな値を足しているのはNaNやInfinityにならないようにするため。 receivedログは最大30秒遅れて出力されるため、40秒前までのreceivedログをwin:timeで見ている。 これをtime_batchにしてしまうと期待通りの結果にならないので注意。
もう一つはJavaの関数でboolを0/1にして平均をとることでisWinがtrueである割合を出している。
$ docker exec norikra norikra-client query add lottery_agg &#39; SELECT COUNT(*) as received_count, (COUNT(*) / (SELECT COUNT(*) + 0.00001 FROM lottery.win:time_batch(1 sec, 0).std:unique(uid))) as received_rate, AVG(prize) as prize_avg, SUM(prize) as prize_sum FROM lottery.win:time(40 sec).std:unique(uid) as a, received.win:time_batch(1 sec, 0).std:unique(uid) as b WHERE a.uid = b.uid&#39; $ docker exec norikra norikra-client query add lottery_win_rate &#39;SELECT avg(Boolean.</description>
    </item>
    
    <item>
      <title>VSでのネイティブプラグインのビルドからUnityでのWSAのビルドまでをバッチでする</title>
      <link>https://www.sambaiz.net/article/110/</link>
      <pubDate>Tue, 13 Jun 2017 00:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/110/</guid>
      <description>VSでのネイティブプラグインのビルド VSが使っているビルドツール MSBuildを使う。 VSのプロジェクトファイルにはMSBuildのXMLが含まれている。 これ自体はVSに依存していないため、単体で動かすこともできる。
パスが通ってなかったらパスを通す。管理者権限が必要。
&amp;gt; MSBuild &#39;MSBuild&#39; は、内部コマンドまたは外部コマンド、 操作可能なプログラムまたはバッチ ファイルとして認識されていません。 &amp;gt;　SETX /M PATH &amp;quot;%PATH%;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\Bin&amp;quot; 成功: 指定した値は保存されました。  別プロセスから適用されるので立ち上げ直すとパスが通っていることを確認できる。
&amp;gt; MSBuild /version Microsoft (R) Build Engine バージョン 15.1.1012.6693 Copyright (C) Microsoft Corporation.All rights reserved. 15.1.1012.6693  ビルドしてAssets\Pluginsに配置する。これは前作ったBLEのネイティブプラグインのもの。
Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net
&amp;gt; git clone git@github.com:sambaiz/UnityBLE_UWP.git &amp;gt; cd UnityBLE_UWP &amp;gt; MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;quot;x86&amp;quot; &amp;gt; MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release &amp;gt; copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA &amp;gt; copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.</description>
    </item>
    
    <item>
      <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
      <link>https://www.sambaiz.net/article/109/</link>
      <pubDate>Sat, 10 Jun 2017 12:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/109/</guid>
      <description>NorikraはTD社のtagomoris氏が作った、 スキーマレスのストリーミングデータを処理するOSS。
モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだけど、 流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。
Norikraを立ち上げてクエリを実行する 公式で紹介されているDockerイメージがあったのでこれで動かしてみる。
$ docker run -e &amp;quot;TZ=Asia/Tokyo&amp;quot; -p 26578:26578 -p 26571:26571 -v `pwd`:/var/tmp/norikra:rw -d myfinder/docker-norikra norikra start --stats /var/tmp/norikra/stats.json -l /var/tmp/norikra  ほかのオプションとして-Xmsや-XmxでJVMのヒープメモリの量を設定したり、Experimentalではあるけど--shutoffでヒープメモリが一杯になる前に弾いて OutOfMemoryを防ぐことができる。 また、Norikraのコアエンジンで使われているOSSの CEP (Complex event processing)エンジン、 Esper のパフォーマンスチューニングとして--microや--smallなどを渡すこともできるけど試していない。
公式サイトの例に従ってクライアントからデータを入れてクエリを実行してみる。
まずはtargetをopenする。targetというのはスキーマレスのイベントストリームのこと。 ここで定義したフィールドは必須になる。
$ norikra-client target open www path:string status:integer referer:string agent:string userid:integer $ norikra-client target list TARGET	AUTO_FIELD www	true  次にクエリを追加する。一見普通のSQLのように見えるけど、EsperのクエリであるEPL(Event Processing Language)。 ただしSELECTしか使えないのも含めてクエリにいくらかの制限がある。
このクエリではwin:time_batchで10秒のWindowを定義し、eventをgroup byして、その数をeventとして出力する。
$ norikra-client query add www.toppageviews &#39;SELECT count(*) AS cnt FROM www.</description>
    </item>
    
    <item>
      <title>fluentdでKinesis streamsに送るときの性能確認</title>
      <link>https://www.sambaiz.net/article/108/</link>
      <pubDate>Mon, 05 Jun 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/108/</guid>
      <description>localでのstreamsとproducerのbenchmark aws-fluent-plugin-kinesisの make benchmarkはlocalにDummyServerを立ち上げて送っている。
空でもいいのでroleをつけておく必要がある。
$ git clone https://github.com/awslabs/aws-fluent-plugin-kinesis.git $ cd aws-fluent-plugin-kinesis $ yum install -y ruby-devel gcc $ echo &#39;gem &amp;quot;io-console&amp;quot;&#39; &amp;gt;&amp;gt; Gemfile $ make $ make benchmark  RATEを指定しなければデフォルトで秒間1000レコードが送られる設定。 fluentdを起動してから10秒後にプロセスをkillし、そのレコード数などを出力している。
t2.microでデフォルト(RATE=1000)で実行した結果がこれ。 固める分producerの方はややパフォーマンスが落ちる。
bundle exec rake benchmark TYPE=streams Results: requets: 20, raw_records: 9400, records: 9400 bundle exec rake benchmark TYPE=producer Results: requets: 14, raw_records: 1005, records: 8900  RATE=3000のとき。producerではraw_recordsが1/100、リクエスト数は1/5。 streamsだとシャードを増やしていく必要があるけど、producerの方は当分大丈夫そうだ。
bundle exec rake benchmark TYPE=streams Results: requets: 57, raw_records: 27600, records: 27600 bundle exec rake benchmark TYPE=producer Results: requets: 12, raw_records: 241, records: 25200  RATE=10000のとき。raw_records, requestの圧縮率はさらに上がり、 パフォーマンスの差が大きくなってきている。</description>
    </item>
    
    <item>
      <title>td-agent2.3.5のfluentdが0.14系になってしまっているのでソースからビルドする</title>
      <link>https://www.sambaiz.net/article/107/</link>
      <pubDate>Sun, 04 Jun 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/107/</guid>
      <description>追記(2016-06-25): 現在は普通に入れても0.12系の2.3.5-1が入るようになっている。
 $ curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh $ td-agent --version td-agent 0.14.16  0.12系じゃない！？
$ yum list installed | grep td-agent td-agent.x86_64 2.3.5-0.el2017 @treasuredata  どうやら2.3.5では0.14系になってしまっているよう。 そのあとにリリースされた2.3.5-1では直ってるみたいだけど、現時点ではrpmリポジトリに上がっていない。
しょうがないのでソースからビルドすることにした。 いずれにせよ各環境で同じバージョンのビルドに合わせるべきだとは思う。 Beanstalk環境の場合、AMIに固めていたとしても非Beanstalk AMIではyum updateされてしまうので注意が必要だ。
BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因 - sambaiz-net
前UbuntuでやったようにDockerでビルドする。今回はAmazon Linux向け。
td-agentをビルドしてfluentdのバージョンを上げる - sambaiz-net
https://hub.docker.com/r/sambaiz/docker-td-agent-build-amazon-linux/
FROM amazonlinux:2017.03 WORKDIR /tmp RUN yum -y update &amp;amp;&amp;amp; \ yum groupinstall -y &amp;quot;Development Tools&amp;quot; &amp;amp;&amp;amp; \ yum install -y ruby23 ruby23-devel &amp;amp;&amp;amp; \ gem install bundler io-console &amp;amp;&amp;amp; \ git clone https://github.</description>
    </item>
    
    <item>
      <title>BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因</title>
      <link>https://www.sambaiz.net/article/106/</link>
      <pubDate>Sun, 04 Jun 2017 23:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/106/</guid>
      <description>User-Dataとは EC2インスタンス起動時に、シェルスクリプトを走らせたりcloud-initディレクティブを適用できる機能。 コンソールではインスタンスの詳細の設定の、高度な詳細のところから設定できる。
BeanstalkでのUser-Data 実はBeanstalkでも使われていて、CloudFormationで設定されている。
&amp;quot; /bin/bash /tmp/ebbootstrap.sh &amp;quot;, ... &amp;quot;Fn::FindInMap&amp;quot;: [ &amp;quot;AWSEBOptions&amp;quot;, &amp;quot;options&amp;quot;, &amp;quot;UserDataScript&amp;quot; ] &amp;quot; &amp;gt; /tmp/ebbootstrap.sh &amp;quot;, ... &amp;quot;AWSEBOptions&amp;quot;: { &amp;quot;options&amp;quot;: { &amp;quot;UserDataScript&amp;quot;: &amp;quot;https://s3-ap-northeast-1.amazonaws.com/elasticbeanstalk-env-resources-ap-northeast-1/stalks/eb_node_js_4.0.1.90.2/lib/UserDataScript.sh&amp;quot;, &amp;quot;guid&amp;quot;: &amp;quot;f08557fc43ac&amp;quot;, } }  このshellの中では、時計を同期させたり、awsebユーザーを作成したりするほかに、 非Beanstalk AMI(is_baked=false)ではyum updateが走るようになっている。 そのため、AMIでのバージョンとBeanstalkで立ち上がったときのバージョンが異なることがあるようだ。
GUID=$7 function update_yum_packages { if is_baked update_yum_packages_$GUID; then log yum update has already been done. else log Updating yum packages. yum --exclude=aws-cfn-bootstrap update -y || echo Warning: cannot update yum packages. Continue... mark_installed update_yum_packages_$GUID # Update system-release RPM package will reset the .</description>
    </item>
    
    <item>
      <title>Unity/UWPでBLEを扱うプラグインを作る</title>
      <link>https://www.sambaiz.net/article/105/</link>
      <pubDate>Sun, 04 Jun 2017 11:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/105/</guid>
      <description>コードはここ
この動画の 50:00あたりから説明があるように、 ビルドされたWSAが読むUWPのdllのほかに、 Unityエディタ上から読むための.NET Framework3.5のdllを用意する。 こうすることで実行環境ごとの違いをUnityコード上で気にしなくてもよくなる。
新しいプロジェクトで
 Visual C# から.NET Framework 3.5にしてクラスライブラリ(.NET Framework)
 Visual C# -&amp;gt;　Windows -&amp;gt; ユニバーサルからクラスライブラリ(ユニバーサルWindows)
  の2つのプロジェクトを同じソリューションに作成する。 VS2017で.NET Frameworkのクラスライブラリプロジェクトを作成するためには Visual Studio Installerで.NET Coreのワークロードをインストールする必要がある。 また、これとは別に動作確認用のUWPアプリケーションプロジェクトを作成した。
UWPの方のプロジェクトにあるClass1.csを削除し、追加 -&amp;gt; 既存の項目から、 もう片方のClass1.csをリンクとして追加して、この共通のcsにUWPのコードを書いていくんだけど、 そのまま書くと当然.NET Frameworkの方でビルドできないので 実装部分を#if WINDOWS_UWP ~ #endif で囲む。UWPの方のプロジェクトにはプロパティ -&amp;gt; ビルドの条件付きコンパイルにWINDOWS_UWPが含まれているので有効になる。
public void Start() { #if WINDOWS_UWP ... #endif }  UWPでBLEを扱うのは前書いた通り。 ただし、なぜかXAMLに依存しているようでD3Dビルドすると失敗する。
UWPでBLEデバイスとペアリングして値を取得する - sambaiz-net
ビルドするとdllができるので.NET Frameworkの方をAssets/Pluginsに置いてInspectorからEditorにだけチェックを入れる。 UWPの方はAssets/Plugins/WSAに置くとWSA Playerにだけチェックが入る。
あとは普通にusingして使うだけ。Edit-&amp;gt;Project Settings-&amp;gt;PlayerからBluetoothのcapabilityを有効にするのを忘れずに。 Package.appxmanifestは上書きされないようなので前にビルドしたやつがあったら一旦消す。
using UnityBLE; public class BLE : MonoBehaviour { string value = &amp;quot;no connection&amp;quot;; public GameObject text; private string serviceUUID = &amp;quot;***&amp;quot;; private string characteristicUUID = &amp;quot;***&amp;quot;; void Start() { var ble = new UnityBLE.</description>
    </item>
    
    <item>
      <title>Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる</title>
      <link>https://www.sambaiz.net/article/104/</link>
      <pubDate>Sat, 27 May 2017 16:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/104/</guid>
      <description>https://github.com/uber-go/zap
$ go get -u go.uber.org/zap $ go get -u gopkg.in/natefinch/lumberjack.v2  速さの秘訣 Go言語のLogger「zap」は何故高速に構造化されたログを出力する事が出来るのか｜株式会社CAリワード
reflectionとallocationの回避。
一度allocateしたBufferやEncoderは sync.Poolで使い回している。 このPoolはまさにallocateされたアイテムを再利用するためのもので、GCの負担を緩和させることができる。 Poolのアイテムは勝手に削除されることがあり、もし参照しか持っていなかったらそのままdeallocateされる。
https://github.com/uber-go/zap/blob/v1.4.0/buffer/pool.go#L34
func NewPool() Pool { return Pool{p: &amp;amp;sync.Pool{ New: func() interface{} { return &amp;amp;Buffer{bs: make([]byte, 0, _size)} }, }} }  使い方 現状ドキュメントが乏しいのでコードから探っていく必要がある。 まずはQuick Startから。
zap.NewProduction()はNewProductionConfig().Build(options...)のショートカット。 ConfigをBuildしてLoggerを取得し、InfoやErrorで書く流れ。
logger, _ := zap.NewProduction() defer logger.Sync() logger.Info(&amp;quot;Hoge&amp;quot;, // Structured context as strongly-typed Field values. zap.Int(&amp;quot;attempt&amp;quot;, 3), zap.Duration(&amp;quot;backoff&amp;quot;, time.Second), )  {&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1495870212.3378785,&amp;quot;caller&amp;quot;:&amp;quot;zap-log/main.go:36&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;Hoge&amp;quot;,&amp;quot;attempt&amp;quot;:3,&amp;quot;backoff&amp;quot;:1}  NewProductionConfig()の内容はこんな感じ。ここからOutputPathを書き換えるとファイルに出力されるようにできる。</description>
    </item>
    
    <item>
      <title>夜のNY郊外を無一文で彷徨い、Google I/OとMaker Faire Bay Areaに行ってきた</title>
      <link>https://www.sambaiz.net/article/103/</link>
      <pubDate>Mon, 22 May 2017 23:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/103/</guid>
      <description>Googleが毎年やっているイベント、Google I/Oのチケットが当たったのでアメリカに行ってきた。 海外に行くのはこれが3回目でアメリカははじめて。一人での海外もはじめて。
準備 チケットが当たってからExpediaで航空券やホテルを取った。航空券の流れで保険にも加入した。 アメリカの医療費は相当高いそうなので何かしらの保険に入っておかないと不安だ。
会期中は会場近辺のサンフランシスコ/マウンテンビューのホテルがとんでもなく値上がりしている模様。 多分通常の倍ぐらいにはなっているので早めに取っておくとよいと思われる。
GoogleI/Oは週末にかけての3日間だったので、その前の週末から出発し、前半はニューヨークに行くことにして、 マンハッタンに宿を取った。
アメリカに入国するのにはESTAを申請する必要がある。 申請自体は72時間以内に通るのだけど、パスポート番号が必要がなので持っていなければ先に作っておく必要がある。 ESTAが通っていないと本当に入れないらしい。怖い。
現地での通信手段はT-mobileのTourist plan($30プリペイドでSIM+2GB LTE+国内通話+SMS) を購入することにした。 日本にはsimを送ってくれないので現地で調達する必要がある。モバイルルータはちょっと高いような気がして借りなかった。
あとは英語力をなんとかしようと付け焼刃でDMM英会話をはじめてみたが、準備期間が短すぎたかなと思う。
出国 チェックインの締め切りが出発の1時間前だったので、 余裕を持って2時間前ぐらいには着くはずだったんだけど、こんなときに限って財布を落とすわ成田エクスプレスは突然運休するわで大ピンチ。 日暮里から京急のスカイライナーに乗ってスーツケースをかついで走ってなんとか飛行機には間に合ったが、 両替などする時間はなく、財布に1000円しか入っていない状態で出発することになってしまった。
距離にして11000km、12時間のフライトの末、ニューヨークのジョン・F・ケネディ国際空港(JFK)に到着。 時差で-13時間になるため出発よりも早い時刻に到着することになって得した気分だ。 ついにアメリカに来た。
ニューヨーク 当初はニューヨーク観光しつつ、アムトラック(電車)でワシントンD.C.にも行っちゃおうかと考えてチケットまで買っていた。 しかし現実は厳しい。
現地に到着し、通信手段を調達するためT-mobileのショップに向かおうとしたが、肝心のショップの場所がわからない。 もちろん日本のsimカードはすでに機能停止しているので空港のWifiで調べたところ、そこから一番近いところでも数km離れていることがわかった。 タイムズスクエアの近くにはあるようだったので、まずはなんとかしてホテルに向かうことにしたが、 JFKからマンハッタンまでは直線距離で20km以上離れている。ホテルの送迎サービスはなかった。 それでもGoogle mapに従って、途中free wifiを乗り継いでいけばこのときはなんとかなるかなと思っていた。
空港から電車で行こうと思っていたところ、うかつにも謎タクシーに誘導されて乗ってしまった。 47ドルでホテルまで行ってくれると思いきや、それはJamaica駅までの料金で、ホテルまでは100ドルという。調べていた相場の倍だ。 傷口を広げないようJamaicaで降ろしてもらうことにした。 乗る前に現金はないからクレジットカードで払う旨を伝えたのだけど、 支払いの段になってクレジットカードの機械が壊れたから現金でと言い出して困った。なにせ1ドルも持っていないのだから。 近くのATMで現金を下ろすよう言われたのでクレジットカードを入れたのだけれど 2枚ともアウト。そこからどうやって払うんだって問いつめられるもののどうしようもない。 結局解放してもらえたが、初っ端からほとんど心が折れてしまって国に帰りたかった。
それでもなんとかしてホテルにはたどり着かなくてはならないので、LIRRという電車でJamaicaからWoodside駅に向かった。 空港で調べたGoogle mapの経路に出たからそうしたのだけど、 マンハッタンにあるハブ駅、Pensilvania(Penn) stationまで行くほうが行き先表示に出ているので分かりやすかった。 改札はなくて切符は車内で確認される。
案内の人に聞いて電車に乗ったんだけど、切符の確認の際にこの電車ではないと言われる。 乗り間違えると、引き返すためにホームで割と長く待つことになる。5月も半ばなのに白い息が出るぐらい寒い。 Googleで調べようにも、駅にあるWifiはどうも契約していないと使えなさそうなものしかなかった。 地下鉄にはfree wifiが通っていたが、それも全ての駅で使えるというわけではなさそうだった。
Woodsideからは地下鉄に乗るのだけれど、この券売機がなぜかクレジットカードのPINをうけつけてくれずチケットを買えなかった。 カードが止まったかと思い、しょうがないので6kmほど歩いてマンハッタンまで向かうことにした。雨が降っていて、寒くて泣きたくなった。 空港でマップのデータを読んでいたのでGPSと合わせればオフラインでも自分の位置はわかるのが唯一の救いだ。 電話もなかったので、道中あったスタバなどのfree wifiを外から使わせてもらって、 家族に連絡をとって日本からクレジットカード会社に問い合わせてもらったが、 本人からの連絡じゃないとだめとのことでどうしようもなかった。
マンハッタンに行くためにはイースト川を越える必要があったので、 地図上で橋になっているところを順番に見てまわったが、車や電車でないとだめなところばかりで暗雲がただこめる。 あとから調べたら、マンハッタンの南側、ブルックリンとマンハッタン橋は歩いて渡れたらしい。 あの向こうがマンハッタンなのになと沿岸を眺めながら、この時点で夜中の0時を回っていて、野宿の可能性を考え始める。
途方に暮れて彷徨っていたところ、歩いていたおじさんとたまたま目が合って、 お金がなくて電車には乗れないんだけど、徒歩でマンハッタンに渡る方法はあるか聞いたら、 なんと地下鉄の駅まで案内してくれて運賃を出してくれた。 お礼するために連絡先を聞こうとしたのにすぐいなくなってしまわれた。命の恩人だ。</description>
    </item>
    
    <item>
      <title>io17で発表されたFirebaseのphone number authをwebで試してみた</title>
      <link>https://www.sambaiz.net/article/102/</link>
      <pubDate>Wed, 17 May 2017 23:34:00 -0700</pubDate>
      
      <guid>https://www.sambaiz.net/article/102/</guid>
      <description>今日のdeveloper keynoteで発表されたphone number authを試してみた。 Firebaseだと他にはPerformance Monitoringも発表されている。 あとSDKをオープンソースにするとか。
firebase-toolsを最新版にする。
# npm install -g firebase-tools $ firebase -V 3.9.0  FirebaseUIを使う場合、これも最新版にしないと出てこない。
&amp;lt;script src=&amp;quot;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;link type=&amp;quot;text/css&amp;quot; rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.css&amp;quot; /&amp;gt;  firebase.auth.PhoneAuthProvider.PROVIDER_IDがphone number authの オプション。
const uiConfig = { signInOptions: [ firebase.auth.PhoneAuthProvider.PROVIDER_ID ], ... } const ui = new firebaseui.auth.AuthUI(firebase.auth()); ui.start(&#39;#firebaseui-auth-container&#39;, uiConfig);  こんなボタンを押すと
電話番号とCAPTCHAが入り、
SMSに書かれた番号を入力すると認証される。
二段階認証のようなものだと思っていたけど、そうではないみたい。</description>
    </item>
    
    <item>
      <title>UWPでBLEデバイスとペアリングして値を取得する</title>
      <link>https://www.sambaiz.net/article/101/</link>
      <pubDate>Sat, 13 May 2017 10:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/101/</guid>
      <description>ManifestからBluetoothを許可しておく。
BLEデバイスを見つける CreateWatcherにBluetooth LEプロトコルのAEP(Association EndPoint)サービスクラスIDと requestPropaertiesで必要なデバイス情報を渡している。 最後のAssociationEndpointはSystem.Devices.Aep.ProtocolIdのAepと対応している。
using Windows.Devices.Enumeration; string[] requestedProperties = { &amp;quot;System.Devices.Aep.DeviceAddress&amp;quot;, &amp;quot;System.Devices.Aep.IsConnected&amp;quot; }; deviceWatcher = DeviceInformation.CreateWatcher( &amp;quot;(System.Devices.Aep.ProtocolId:=\&amp;quot;{bb7bb05e-5972-42b5-94fc-76eaa7084d49}\&amp;quot;)&amp;quot;, requestedProperties, DeviceInformationKind.AssociationEndpoint); deviceWatcher.Start();  deviceWatcher.Added += DeviceWatcher_Added; deviceWatcher.Removed += DeviceWatcher_Removed; deviceWatcher.Updated += DeviceWatcher_Updated; /* deviceWatcher.EnumerationCompleted += DeviceWatcher_EnumerationCompleted; deviceWatcher.Stopped += DeviceWatcher_Stopped; */ Dictionary&amp;lt;string, DeviceInformation&amp;gt; deviceInfos = new Dictionary&amp;lt;string, DeviceInformation&amp;gt;(); private void DeviceWatcher_Added(DeviceWatcher sender, DeviceInformation deviceInfo) { if (sender == deviceWatcher) { if (deviceInfo.Name != string.Empty) { deviceInfos.Add(deviceInfo.Id, deviceInfo); } } } private void DeviceWatcher_Updated(DeviceWatcher sender, DeviceInformationUpdate deviceInfoUpdate) { if (sender == deviceWatcher) { deviceInfos[deviceInfoUpdate.</description>
    </item>
    
    <item>
      <title>RxJSでObservableを結合する(merge, forkJoin, concat, combineLatest)</title>
      <link>https://www.sambaiz.net/article/100/</link>
      <pubDate>Tue, 09 May 2017 20:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/100/</guid>
      <description>RxJSでRxをはじめる - sambaiz.net
merge 2つのstreamの両方の値がemitされる。
Rx.Observable.merge( stream1, stream2 ).subscribe( data =&amp;gt; console.log(`merge ${data}`), err =&amp;gt; console.log(`merge ${err}`) );  forkJoin completeしたときの最後の値を配列としてemitする。 非同期で一つ値をemitするようなstreamで、Promise.allのようなことをしたいときはこれ。
Rx.Observable.forkJoin( stream1, stream2 ).subscribe( data =&amp;gt; console.log(` forkJoin: ${data}`), err =&amp;gt; console.log(` forkJoin: ${err}`) )  concat 前のstreamがcompleteしたら次のstreamの値がemitされる。
Rx.Observable.concat( stream1, stream2 ).subscribe( data =&amp;gt; console.log(` concat ${data}`), err =&amp;gt; console.log(` concat ${err}`) );  combineLatest stream自体を結合するのではなく値を結合する。 この例だと、streamでemitされた値がa、stream2で最後のemitされた値がbになる。 combineする値がない場合はemitされない。
stream1.combineLatest(stream2, (a, b) =&amp;gt; a + b).subscribe( data =&amp;gt; console.</description>
    </item>
    
    <item>
      <title>angular/material2でフォームを作る</title>
      <link>https://www.sambaiz.net/article/99/</link>
      <pubDate>Sat, 06 May 2017 22:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/99/</guid>
      <description>コード
angular/material2の準備 現時点で DatePickerや Tableなど 開発中のコンポーネントが多いため足りないものを他のライブラリで補うなどする必要がある。 DatePickerはもう少しで出そう。
$ npm install --save @angular/material $ npm install --save hammerjs # gesture用 $ npm install --save @angular/animations  Moduleでimport &#39;hammerjs&#39;;して、以下のModuleをimportに加える。
 BrowserAnimationsModule(from &#39;@angular/platform-browser/animations&#39;) MdButtonModuleなど使うもの(from &#39;@angular/material&#39;)  スタイルとアイコン(md-icon)を追加。
&amp;lt;link href=&amp;quot;../node_modules/@angular/material/prebuilt-themes/indigo-pink.css&amp;quot; rel=&amp;quot;stylesheet&amp;quot;&amp;gt; &amp;lt;link href=&amp;quot;https://fonts.googleapis.com/icon?family=Material+Icons&amp;quot; rel=&amp;quot;stylesheet&amp;quot;&amp;gt;  フォームを作る とりあえずコンポーネントを作成。
$ ng g component TodoForm  Formの値をバインドするためのクラスを作成する。
export class TodoForm { constructor( public id: number, public title: string, public active: boolean, public priority?: number, ) { } }  まずはmaterial2のmdInput, mdSelect, mdButtonでフォームを作る。 #todoFormのように頭についている#は reference variableで、 titleはrequiredとしている。</description>
    </item>
    
    <item>
      <title>CSSのdisplayとposition</title>
      <link>https://www.sambaiz.net/article/98/</link>
      <pubDate>Sat, 06 May 2017 14:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/98/</guid>
      <description>display レンダリングに使うボックスを指定する。
outer display type pのようなブロックレベル要素やspanのようなインラインレベル要素に関わらず、指定したボックスにレンダリングする。
&amp;lt;style&amp;gt; .bg { background-color: #22ee22; width: 150px; height: 50px; } &amp;lt;/style&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:none&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;none&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;p style=&amp;quot;display:inline&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline&amp;lt;/p&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt;  中央寄せ 中央寄せはblockにwidthを設定してmargin autoするか、 親要素でtext-align: centerしてinline(-block)にする。
&amp;lt;style&amp;gt; .bg { background-color: #22ee22; height: 80px; } &amp;lt;/style&amp;gt; &amp;lt;div style=&amp;quot;margin: 5 auto&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block margin&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;quot;margin: 5 auto; width: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block margin width&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;quot;margin: 5 auto; display: inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block margin&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;quot;text-align: center&amp;quot;&amp;gt; &amp;lt;div style=&amp;quot;display: inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block align-center&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;quot;width: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block align-center width&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;  flex displayでflexを指定するとflex containerになる。 flex-flowは 表示する方向のflex-directionと 折り返しのflex-wrapのショートハンドプロパティ。</description>
    </item>
    
    <item>
      <title>AngularのRouter</title>
      <link>https://www.sambaiz.net/article/97/</link>
      <pubDate>Sun, 30 Apr 2017 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/97/</guid>
      <description>@angular/core&amp;quot;: 4.1.0  Angular2とangular-cliでTODOを作る - sambaiz.net
angular-cliは@angular/cliに変更された。
routingを行うのでnewで--routingオプションを付けている。
$ npm install -g @angular/cli $ ng -v @angular/cli: 1.0.1 $ ng new angular4-routing --routing $ cd angular4-routing/ $ cat package.json | grep @angular/core &amp;quot;@angular/core&amp;quot;: &amp;quot;^4.0.0&amp;quot;, $ ng serve ** NG Live Development Server is running on http://localhost:4200 **  --routingを付けたのでapp-routing.module.tsが作成され、app.module.tsにAppRoutingModuleが追加される。 index.htmlのheadにはpushStateのroutingが働くように base要素が 追加されている。
import { NgModule } from &#39;@angular/core&#39;; import { Routes, RouterModule } from &#39;@angular/router&#39;; const routes: Routes = [ { path: &#39;&#39;, children: [] } ]; @NgModule({ imports: [RouterModule.</description>
    </item>
    
    <item>
      <title>Node.jsのStream API</title>
      <link>https://www.sambaiz.net/article/96/</link>
      <pubDate>Sat, 22 Apr 2017 19:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/96/</guid>
      <description>Stream APIとは NodeでStreamデータを扱うためのもの。 例えばサイズが大きいファイルの入出力をStreamとして扱うことでバッファを最小限にできる。
StreamはEventEmitterで、 Readable streamやWritable stream、ReadableとWritableを合わせたDuplex streamと Readしたものを加工してWriteするTransform streamの種類があり、 それぞれ特定の関数が実装されている必要がある。
Readable stream Readable streamにはflowingとpausedの 二つのモードがある。 最初はpausedモードで、readableになってからread()することで読むことができる。
const fs = require(&#39;fs&#39;); let readable = fs.createReadStream(&#39;sample.txt&#39;); var i = 0; readable.on(&#39;readable&#39;, () =&amp;gt; { let chunk; while (null !== (chunk = readable.read(10))) { console.log(`${i++}: ${chunk}`); } }); dable.on(&#39;end&#39;, () =&amp;gt; { console.log(&#39;end&#39;); });  $ cat sample.txt abcdefghijklmnopqrstuvwxyz 1234567890 あいうえお $ node main.js 0: abcdefghij 1: klmnopqrst 2: uvwxyz 123 3: 4567890 あい 4: うえお end  dataのイベントハンドラーを追加するか、後で書くpipeを使うとflowingモードになる。</description>
    </item>
    
    <item>
      <title>tmuxのメモ</title>
      <link>https://www.sambaiz.net/article/95/</link>
      <pubDate>Fri, 21 Apr 2017 00:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/95/</guid>
      <description>https://tmux.github.io/
セッションを立ち上げてその中で複数のウィンドウやペインからコマンドを実行できるやつ。 サーバーでの作業中にネットワークが切断されてしまってもセッションをattachすることで再開することができる。 ローカル環境でもコマンドキーでのウィンドウ作成やペインの分割、 複数のサーバーにsshで入って調査するようなときにペインの同時入力は便利。 もちろんターミナルを閉じてしまっても再開できる。
$ brew install tmux $ tmux $ tmux ls $ tmux a # sessionをattachする  bind key(デフォルトでCtrl + b)を入れてからコマンドキーを入れる。よく使うもの。
 c: 新しいウインドウをCreateする d: 今のクライアントをDetachする n: Nextウィンドウに移動する p: Previousウィンドウに戻る w: Windowを一覧表示して選択する x: ペインを削除する ,: ウィンドウの名前を変更する z: ウィンドウ一杯にペインをzoomする/解除 [: ペイン内をスクロールできるようになる。qで解除  ~/.tmux.confはこんな感じにしている。
# bind keyをC-tに変更してC-bを解除 set -g prefix C-t unbind C-b # Vimのキーバインドでペインを移動する bind h select-pane -L bind j select-pane -D bind k select-pane -U bind l select-pane -R # - でペインを横に分割する(縦に切る) bind - split-window -h # | でペインを縦に分割する(横に切る) bind | split-window -v # 同時入力 bind s set-window-option synchronize-panes on bind S set-window-option synchronize-panes off  </description>
    </item>
    
    <item>
      <title>Firebaseをwebで使う(Hosting, Authentication, Realtime Database, Storage)</title>
      <link>https://www.sambaiz.net/article/94/</link>
      <pubDate>Sun, 16 Apr 2017 20:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/94/</guid>
      <description>Firebaseとは GoogleのmBaaS。Android/iOSアプリの開発に使う認証、データストア、クラッシュレポート、分析、通知、広告などなど全部入りサービス。 今年のGoogleI/Oでも毎時間のように Firebaseのセッションがあって大分推している印象。
基本的にはアプリで使うのだけれど、webで使える機能も結構ある。今回は
 Hosting Authentication Realtime Database Storage  を使ってみる。
料金 プランは無料のSPARKと25ドル/月のFLAME、従量課金のBLAZEがある。 試す分にはSPARKで十分だけど、Realtime Databaseの同時接続数が100なので注意。
セットアップ firebase-cliをインストール、ログインして初期化する。
$ npm install -g firebase-tools $ firebase login $ mkdir firebase-chat &amp;amp;&amp;amp; cd firebase-chat $ firebase init ... ? What Firebase CLI features do you want to setup for this folder? ❯◉ Database: Deploy Firebase Realtime Database Rules ◉ Functions: Configure and deploy Cloud Functions ◉ Hosting: Configure and deploy Firebase Hosting sites ?</description>
    </item>
    
    <item>
      <title>MySQLのALTER TABLEのメモ</title>
      <link>https://www.sambaiz.net/article/93/</link>
      <pubDate>Sat, 15 Apr 2017 19:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/93/</guid>
      <description>MySQL :: MySQL 5.6 リファレンスマニュアル :: 13.1.7 ALTER TABLE 構文
CREATE TABLE t0 ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, c1 VARCHAR(30), c2 VARCHAR(30) ); CREATE TABLE t2 ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY );  ALTER TABLE t0 RENAME t1; ALTER TABLE t1 ADD COLUMN t2_id BIGINT UNSIGNED AFTER id, ADD COLUMN c3 INTEGER NOT NULL AFTER t2_id, MODIFY COLUMN c1 VARCHAR(30) NOT NULL, DROP COLUMN c2, ADD INDEX (c3), ADD FOREIGN KEY (t2_id) REFERENCES t2(id) ON UPDATE CASCADE ON DELETE CASCADE ;  mysql&amp;gt; SHOW CREATE TABLE t1 \G; *************************** 1.</description>
    </item>
    
    <item>
      <title>Unityのパーティクル設定(Shuriken)</title>
      <link>https://www.sambaiz.net/article/92/</link>
      <pubDate>Thu, 13 Apr 2017 17:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/92/</guid>
      <description>UnityにはShurikenというパーティクルシステムがある。
Sphereを置いてParticle Systemを追加すると、Particleが出始める。
モジュール 設定項目が多いためモジュールに分かれている。ひとまずデフォルトで有効になっている
 (メインモジュール) Emission Shape Renderer  について見ていく。
メインモジュール  Duration: 5 Looping: true  デフォルトだとLoopingにチェックが入っているのでずっと出ているが、チェックを外すとDurationで止まる。
 Start Delay: 0 Play On Awake: true  PlayOnAwakeがtrueでStartDelayが0なので実行してからすぐにParticleが出始める。
 Start Lifetime: 5 Max Particles: 1000  StartLifetimeはParticleが消えるまでの時間。ただしMaxParticlesに達したら消される。
 Start Speed: 5 Simulation Speed: 1  StartSpeedはParticleの初速で、上げると勢い良く飛んでいく。 SimulationSpeedを上げるとParticleが出るのも含めて全体のスピードが上がる。
 Start Size: 1  Particleの初期サイズ。小さくすると塵みたいになる。
 Start Rotation: 0  Particleの初期角度。
 Gravity Modifier: 0  重力値。0だと無重力。
 Simulation Space: Local  Particleをlocal座標かworld座標で動かすか。 Localだとオブジェクトが移動したときに一緒に移動する。Worldだと置いてかれる。</description>
    </item>
    
    <item>
      <title>godocのメモ</title>
      <link>https://www.sambaiz.net/article/91/</link>
      <pubDate>Wed, 05 Apr 2017 22:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/91/</guid>
      <description>https://godoc.org/golang.org/x/tools/cmd/godoc
コメントからドキュメントを生成する。
$ godoc cmd/fmt Printf func Printf(format string, a ...interface{}) (n int, err error) Printf formats according to a format specifier and writes to standard output. It returns the number of bytes written and any write error encountered. $ godoc -src cmd/fmt Printf // Printf formats according to a format specifier and writes to standard output. // It returns the number of bytes written and any write error encountered. func Printf(format string, a .</description>
    </item>
    
    <item>
      <title>Nightmareでブラウザでの操作を自動化する</title>
      <link>https://www.sambaiz.net/article/90/</link>
      <pubDate>Wed, 29 Mar 2017 23:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/90/</guid>
      <description>最近、POSTWASHという洗濯代行サービスを使っている。 専用のカバンに詰めて集荷にきた人に渡すと、きれいに畳まれた洗濯ものが届く便利なサービスだ。 注文時にはWebのフォームから集荷、配達時間や支払い方法などを選ぶ必要があるんだけど、毎週のことなのでこれを自動化してみる。
ブラウザの操作を自動化するのにNightmareを使う。 Electronを使っていて、PahntomJSより2倍くらい速く、簡潔に書ける。
$ npm install nightmare  Nightmare()の引数にshow: trueを渡すとウィンドウが開いて実行し始める。 これで確認画面までいくのであとは注文ボタンを押すだけ。 ウィンドウが閉じないように最後にnightmare.end()を呼んでいない。
const co = require(&#39;co&#39;); const moment = require(&#39;moment&#39;) const jst = +9 const Nightmare = require(&#39;nightmare&#39;);	const nightmare = Nightmare({ show: true, waitTimeout: 3000, gotoTimeout: 3000 }); const loginID = process.env.LOGIN_ID; const loginPassword = process.env.LOGIN_PASSWORD; moment.locale(&#39;ja&#39;); const now = moment().utcOffset(jst) const dayAfterTomorrow = now.add(2, &#39;days&#39;).format(&amp;quot;YYYY年M月D日(ddd)&amp;quot;); const nextWeek = now.add(7, &#39;days&#39;).format(&amp;quot;YYYY年M月D日(ddd)&amp;quot;) console.log(`${dayAfterTomorrow}~${nextWeek}`); // IDとパスワードを入れてログイン const login = () =&amp;gt; nightmare .</description>
    </item>
    
    <item>
      <title>Node.jsでの文字コードの変換</title>
      <link>https://www.sambaiz.net/article/89/</link>
      <pubDate>Tue, 28 Mar 2017 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/89/</guid>
      <description>node-iconvを使う。
$ npm install iconv  SHIFT_JISからUTF-8への変換はこんな感じ。
const Iconv = require(&#39;iconv&#39;).Iconv; const before = new Buffer([ 0x8b, 0x8d, 0x8e, 0x4d, 0x26, 0x82, 0xb2, 0x94, 0xd1 ]); const iconv = new Iconv(&#39;SHIFT_JIS&#39;, &#39;UTF-8&#39;); console.log(`before: ${before.toString(&#39;hex&#39;)} ${before.toString()}`) const after = iconv.convert(before); console.log(`after: ${after.toString(&#39;hex&#39;)} ${after.toString()}`);  before: 8b8d8e4d2682b294d1 ���M&amp;amp;���� after: e7899be79abf26e38194e9a3af 牛皿&amp;amp;ご飯  文字コードによっては変換後に表せないことがある。 例えば、UTF-8からSHIFT_JISへの変換でサロゲートペア🍚を渡すと変換できず、エラーになる。
throw errnoException(&#39;EILSEQ&#39;, &#39;Illegal character sequence.&#39;);  //IGNOREを付けることで そのような文字があった場合でもエラーにしないようにできる。
const Iconv = require(&#39;iconv&#39;).Iconv; const before = &amp;quot;牛皿&amp;amp;🍚&amp;quot;; const iconv = new Iconv(&#39;UTF-8&#39;, &#39;SHIFT_JIS//IGNORE&#39;); console.</description>
    </item>
    
    <item>
      <title>HoloLensのSharing</title>
      <link>https://www.sambaiz.net/article/88/</link>
      <pubDate>Sat, 25 Mar 2017 22:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/88/</guid>
      <description>HoloToolkit-Unity v1.5.5.0  サーバー SharingService.exeを ここ からとってきて実行する。開発に使っているHoloToolkitと同じリリースバージョンのものを使う。
&amp;gt; SharingService.exe -local ... SharingService: Listening for session list connections on port 20602 of all network devices of the local machine. SharingService: Local IP addresses are: SharingService: xxx.xxx.xxx.xxx SharingService: Created Session &amp;quot;Default&amp;quot; with ID 0 on port 20601  今日のTokyo Hololens Meetup Vol.2の開発者セッションで、 ちょうどSharingの話があったのだけれど、残念ながら先着順で出遅れて聞けなかった。
Tweetを見る限りだとカスタマイズできず、スケーリングできないSharingService.exeは使わずに MagicOnionというのを自前で作ったらしい。
Tokyo Hololens MeetuUp Vol.2 Session5 #HoloLensJP #TMCN - Togetterまとめ
クライアント Assets/HoloToolkit/Sharing/TestsのSceneで試してみる。
以下のcapabilitiesを設定し、
 SpatialPerception InternetClient  SharingのServer Addressを設定してビルド。ほかにはこんな設定がある。</description>
    </item>
    
    <item>
      <title>Unixのパイプをmkfifo()で作ってdup2()で標準出力にコピーして書き込む</title>
      <link>https://www.sambaiz.net/article/87/</link>
      <pubDate>Fri, 24 Mar 2017 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/87/</guid>
      <description>パイプとは Unixでプロセス間通信するためのもの。シェルで使う|は無名パイプ。 mkfifo()システムコールで名前付きパイプを作成でき、これを読み書きすることで任意のプロセス間でやりとりできる。
$ mkfifo hoge $ ls -lh $ prw-r--r-- ... 0B ... hoge  通常のファイルと同様に読み書きすることができ、読み書きどちらかを行おうとすると待つことになる。
$ echo hoge &amp;amp; # 読まれるまで待つ $ cat hoge aaaaa [1]+ Done echo &amp;quot;aaaaa&amp;quot; &amp;gt; hoge $ cat hoge &amp;amp; # 書かれるまで待つ $ echo &amp;quot;bbbbb&amp;quot; &amp;gt; hoge bbbbb [1]+ Done cat hoge  ファイルディスクリプタをコピーするシステムコールdup2()でopenしたパイプを標準出力(1)にコピーしてみる。
#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;fcntl.h&amp;gt; int main(){ int fd = open(&amp;quot;./hoge&amp;quot;, O_WRONLY); if(fd &amp;lt; 0){ printf(&amp;quot;fail to open\n&amp;quot;); return 1; } printf(&amp;quot;OPEN %d \n&amp;quot;, fd); if(dup2(fd, 1) &amp;lt; 0){ printf(&amp;quot;fail to dup2\n&amp;quot;); return 2; } printf(&amp;quot;WRITE\n&amp;quot;); // これがどこに書き込まれるか close(fd); }  最後のprintfの内容は標準出力ではなく、パイプに書き込まれていることがわかる。</description>
    </item>
    
    <item>
      <title>CuratorでElasticsearchの古いindexを削除する</title>
      <link>https://www.sambaiz.net/article/86/</link>
      <pubDate>Wed, 22 Mar 2017 00:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/86/</guid>
      <description>Curatorとは indexやsnapshotを管理するのに使えるツール。
インストール インストールする。
$ cat /etc/yum.repos.d/curator.repo [curator-4] name=CentOS/RHEL 7 repository for Elasticsearch Curator 4.x packages baseurl=http://packages.elastic.co/curator/4/centos/7 gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 $ yum install -y elasticsearch-curator $ curator --version curator, version 4.2.6  config configファイルを書く。
client: hosts: - 127.0.0.1 port: 9200 logging: loglevel: INFO logfile: logformat: default blacklist: [&#39;elasticsearch&#39;, &#39;urllib3&#39;]  action 今回はindexを削除するのでdelete_indices。 対象はfilterで指定する。 logstash formatだとhogehoge-2017.01.01のようなindex名になるので%Y.%m.%d。okder than 3 daysのものを削除する。
actions: 1: action: delete_indices description: &amp;gt;- 3日前より古いhogehoge-* indexを消す filters: - filtertype: pattern kind: prefix value: hogehoge- - filtertype: age source: name direction: older timestring: &#39;%Y.</description>
    </item>
    
    <item>
      <title>RxJSでRxをはじめる</title>
      <link>https://www.sambaiz.net/article/85/</link>
      <pubDate>Sat, 18 Mar 2017 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/85/</guid>
      <description>https://github.com/ReactiveX/rxjs
Rx(ReactiveX)とは 非同期処理をうまく扱えるようにするライブラリ。いろんな言語で実装されている。 非同期処理の結果はObservableなStreamに流される。 ObservableはIteratableのように扱うことができる。
RxはObserver pattern を拡張したもの。 Observer patternというのは、Subjectが、Observeしている全てのObserverに対して通知を送るデザインパターン。 C#などのeventのそれ。
C#のdelegateとevent - sambaiz.net
試してみる inputのkeyupイベントのObservableを作成し、それをsubscribe()して出力している。
&amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;script src=&amp;quot;https://cdnjs.cloudflare.com/ajax/libs/rxjs/5.0.1/Rx.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;input&amp;quot; /&amp;gt; &amp;lt;script&amp;gt; const inputForm = document.querySelector(&#39;#input&#39;); const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;); keyups.subscribe( data =&amp;gt; console.log(data), err =&amp;gt; console.log(err) ); &amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt;  入力するとこんなのが出力される。
KeyboardEvent {isTrusted: true, key: &amp;quot;a&amp;quot;, code: &amp;quot;KeyA&amp;quot;, location: 0, ctrlKey: false…} KeyboardEvent {isTrusted: true, key: &amp;quot;b&amp;quot;, code: &amp;quot;KeyB&amp;quot;, location: 0, ctrlKey: false…} KeyboardEvent {isTrusted: true, key: &amp;quot;c&amp;quot;, code: &amp;quot;KeyC&amp;quot;, location: 0, ctrlKey: false…}  Observable create next()でObservableに値をemitし、complete()で終了させる。 error()でエラーをemitするとそれ以後の値はemitされない。</description>
    </item>
    
    <item>
      <title>FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ</title>
      <link>https://www.sambaiz.net/article/84/</link>
      <pubDate>Wed, 15 Mar 2017 23:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/84/</guid>
      <description>KPL(Kinesis Producer Library)とは Developing Amazon Kinesis Streams Producers Using the Amazon Kinesis Producer Library - Amazon Kinesis Streams
Kinesisに送るとき、自動リトライしてくれたり、レコードをまとめてスループットを向上してくれたりするアプリケーション。Protobufを使っている。 普通に送るとどんなに小さくてもシャード*1000レコード/秒しか最大でPUTできないのを、KPLを使ってまとめることで増やすことができる。
fluentdで送る aws-fluent-plugin-kinesisでkinesis_producerを指定するとKPLを使って送信する。
&amp;lt;kinesis_producer&amp;gt;の中にKPLの設定を書くことができる。
&amp;lt;kinesis_producer&amp;gt; record_max_buffered_time 10 &amp;lt;/kinesis_producer&amp;gt;  record_max_bufferd_time はバッファされたレコードが送られるまでの最大時間(ms)。デフォルトは100ms。この時間が経つか、他のリミットに当たったらレコードは送られる。
 AggregationMaxCount: 一つのレコードにまとめる最大レコード数 AggregationMaxSize: まとめたレコードの最大バイト数 CollectionMaxCount: PutRecordsで送る最大アイテム数 CollectionMaxSize: PutRecordsで送るデータ量  CloudWatchに送るmetrics_levelはデフォルトでdetailedになっていて、 コンソールのメトリクスからstream名で検索すると KinesisProducerLibraryにUserRecordsPerKinesisRecordや、UserRecordsDataPut、BufferingTime、RequestTimeなどいろいろ表示される。
とりあえず試しにこんな設定で送ってみる。
&amp;lt;match hoge.log&amp;gt; @type kinesis_producer region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt;  Lambdaで読む まとめられたレコードをkinesis-aggregationで分解して読む。 今回はNode.jsでやる。</description>
    </item>
    
    <item>
      <title>C#のdelegateとevent</title>
      <link>https://www.sambaiz.net/article/83/</link>
      <pubDate>Sun, 12 Mar 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/83/</guid>
      <description>delegate カプセル化するためのdelegate(移譲)メソッドに使う型。
public class Converter{ private static double defaultConvert(double num){ return num; } public delegate double Convert(double num); public Convert convert = defaultConvert; public double run(double num){ return convert (num); } }  匿名メソッドやラムダ式を渡すこともできる。
var conv = new Converter (); print (conv.run (2)); // 2 // 匿名メソッドの例 conv.convert = delegate(double input) { return input + 1; }; print (conv.run (2)); // 2 + 1 = 3 // ラムダ式の例 conv.convert = s =&amp;gt; s * s; print (conv.</description>
    </item>
    
    <item>
      <title>UnityのMaterial</title>
      <link>https://www.sambaiz.net/article/82/</link>
      <pubDate>Sat, 11 Mar 2017 20:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/82/</guid>
      <description>MaterialとShaderとTexture Materialは表面がどのようにレダリングされるかを定義するもの。 Shaderを指定し、Textureなどのパラメーターを設定する。
Shaderは光と、Materialの設定から、ピクセルの色を計算するスクリプト。 大体Standard Shader で事足りるらしい。
Textureはビットマップイメージ。色(Albedo)だけではなく、反射率や粗さなど、いろんな要素に使える。
Standard Shader Rendering Mode Albedoは(255, 255, 255, 255)で、テクスチャにはDefault Particleを指定している。 透明度はテクスチャのアルファチャンネルとAlbedoのアルファ値に基づく。
 Opaque: デフォルト。すべて不透明。   CutOut: 閾値を境に、完全に透明か、不透明になる。  Alpha Cutoffを0.1にした。
 Transparent: 透明度が適用される。現実世界の透明なマテリアルのように、反射のハイライトは完全に表示される。   Fade: ハイライトにも透明度を適用する。フェードイン/アウトしたいときに使う。  Metallic マテリアルチャートをもとにAlbedoとMetallicとSmoothnessを設定する。
これは
 Albedo: (255, 255, 255, 255) Metallic: 1 Smoothness: 0.68  を設定している。</description>
    </item>
    
    <item>
      <title>UnityのUI</title>
      <link>https://www.sambaiz.net/article/81/</link>
      <pubDate>Wed, 08 Mar 2017 16:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/81/</guid>
      <description>Canvas UI要素を配置するための領域。
renderMode  Overlay: スクリーンに対してオーバーレイするように表示
 Camera: Cameraから指定した距離(planeDistance)離れた前方に表示
 World Space 他のオブジェクトと同じように表示
  Canvas Scaler  UI Scale Mode (World Space以外)
 Constant Pixel Size: 画面サイズに関わらず同じピクセル数にする
 Scale With Screen Size: 画面サイズでスケールさせる
 Constant Physical Size 解像度や画面サイズによらず物理的に同じサイズにする
  Dynami Pixels Per Unit (World Spaceのみ): Textなどの動的に生成されたビットマップの解像度
  1と3でそれぞれこんな感じになる。
AutoLayout Vertical Layout Groupや Grid Layout Group など。これらのComponentを追加すると子要素のTransform(の一部)が自動で設定される。
Content Size Fitter Layout Component要素に合うように自動で調整される。
レイアウトを作る RectTool(ツールバーボタンの一番右の四角いやつ)を選択して、Pivot, Localにするとよい。 Canvasにいろいろ置いていって、Anchorを選んでRect Transformを設定していく。 あとはPrefabにしてInstantiateするなりして表示する。</description>
    </item>
    
    <item>
      <title>UnityのTransform</title>
      <link>https://www.sambaiz.net/article/80/</link>
      <pubDate>Tue, 07 Mar 2017 02:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/80/</guid>
      <description>https://docs.unity3d.com/jp/current/ScriptReference/Transform.html
オブジェクトの位置、スケール、回転を保持する。親子関係を持つ。
Position positionがワールド空間の、 localPosition が親から見た相対的なローカル空間の位置。localPositionの1unitはscaleに依存する。
transform.position = new Vector3(0, 0, 0); transform.localPosition = new Vector3(0, 0, 0);  徐々に移動するにはTranslate()を使う。 最後の引数はデフォルトでSpace.Selfになっていて、Space.Worldを指定するとワールド座標を基準にする。
Time.deltaTimeは最後のフレームを完了するのにかかった秒数。 なのでフレームレートにかかわらず同じ速度で移動させることができる。
transform.Translate(0, Time.deltaTime, 0, Space.World); transform.Translate(Vector3.up * Time.deltaTime, Space.World); // 軸に沿って移動 transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform); // 最後の引数のローカル座標を基準にする transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform);  Scale localScale はローカル空間のスケール。ワールド空間のScaleはない。
transform.localScale = new Vector3(0.1f, 1f, 1f);  Rotation ワールド空間の rotationと ローカル空間の localRoation。
UnityはQuarternion(四元数)で回転を持っている。 実際はQuarternionそのものを自分で計算することはなく、 Quaternion.LookRotation()や Quaternion.Euler()などを使う。
Vector3 relativePos; transform.rotation = Quaternion.LookRotation(relativePos); // そのPointを向くように回転 transform.</description>
    </item>
    
    <item>
      <title>Node.jsでDateを任意のフォーマットの文字列にする</title>
      <link>https://www.sambaiz.net/article/79/</link>
      <pubDate>Mon, 06 Mar 2017 20:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/79/</guid>
      <description>Moment.jsを使う。 相対時間(5 years ago)を出したり、日付の計算(add(3, &#39;days&#39;))もできる便利なライブラリ。 ブラウザでも使える。
$ npm install moment  const moment = require(&#39;moment&#39;) const jst = +9 let now = moment().utcOffset(jst).format(&amp;quot;YYYY-MM-DD HH:mm:ss.SSSZ&amp;quot;); console.log(now);  </description>
    </item>
    
    <item>
      <title>Unityと.NETとMono</title>
      <link>https://www.sambaiz.net/article/78/</link>
      <pubDate>Sun, 05 Mar 2017 18:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/78/</guid>
      <description>.NETとかよくわからなかったのでまとめてみた。
.NET Framework .NET Framework - Wikipedia
Microsoftが開発したアプリケーション開発、実行環境。
各言語のコンパイラによって言語、環境によらない共通の中間言語(CIL, Common Intermediate Language)バイナリ(exeやdll)に変換し、 実行時に共通言語基盤(CLI, Common Language Infrastructure)の仮想実行システム(VES)が環境依存の機械語を動的に生成(JIT, Just in time)する。 CLIの仕様はECMAで標準化されていて、Microsoftが実装したCLIが共通言語ランタイム(CLR)。Windowsでしか動かない。
.NET Core .NET Core - .NET Core による .NET のクロスプラットフォームへの移行
Microsoft/dotnet
オープンソースで、クロスプラットフォームに対応した.NET。CoreCLRはWindowsだけではなくMacやLinuxでも動く。 .NET Frameworkと共通のAPIもあるが、GUIまわりでどちらかにしかないAPIが存在する。
Mono オープンソースで、クロスプラットフォームな.NET Framework互換ソフトウェア。C#のコンパイラとCLIが実装されている。 Unityはこれを使っているが、バージョンが古くて使えないライブラリがある。
.NET CoreでHello World インストール手順に沿って dotnetコマンドを使えるようにする。
Hello Worldまで。
$ dotnet console -o hwapp $ cd hwapp $ ls Program.cs	hwapp.csproj $ dotnet restore $ ls Program.cs	hwapp.csproj	obj $ ls obj hwapp.csproj.nuget.g.props	project.</description>
    </item>
    
    <item>
      <title>Elasticsearchで期間ごとの集計値を出す</title>
      <link>https://www.sambaiz.net/article/77/</link>
      <pubDate>Sun, 05 Mar 2017 01:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/77/</guid>
      <description>Bucket(SQLでいうGROUP BY)にまとめて(Bucket Aggreagtion)、集計(Metric Aggregation)する。
使うデータは作ったツールで生成したこんなの。
{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82}  Bucket Aggregations Date Range Aggregation date_rangeで期間のBucketを作る。この例だと今から10分前の00秒~今の分の00秒まで。
$ curl localhost:9200/hoge/_search -d&#39; { &amp;quot;aggs&amp;quot;: { &amp;quot;range_10minutes&amp;quot;: { &amp;quot;date_range&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;HH-mm-ssZ&amp;quot;, &amp;quot;ranges&amp;quot;: [ { &amp;quot;to&amp;quot;: &amp;quot;now/m&amp;quot;, &amp;quot;from&amp;quot;: &amp;quot;now-10m/m&amp;quot; } ] } } } }&#39; | jq .aggregations  { &amp;quot;range_10minutes&amp;quot;: { &amp;quot;buckets&amp;quot;: [ { &amp;quot;key&amp;quot;: &amp;quot;15-17+0000-15-27+0000&amp;quot;, &amp;quot;from&amp;quot;: 1488640620000, &amp;quot;from_as_string&amp;quot;: &amp;quot;15-17+0000&amp;quot;, &amp;quot;to&amp;quot;: 1488641220000, &amp;quot;to_as_string&amp;quot;: &amp;quot;15-27+0000&amp;quot;, &amp;quot;doc_count&amp;quot;: 600 } ] } }  Date Histogram Aggregation date_histogramで日付の間隔でBucketを作る。この例だと1分ごとにBucketが作られる。</description>
    </item>
    
    <item>
      <title>一定間隔でjsonデータを作って送り続けるCLIツールを作った</title>
      <link>https://www.sambaiz.net/article/76/</link>
      <pubDate>Sat, 04 Mar 2017 23:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/76/</guid>
      <description>Elasticsearchにリアルタイムなテストデータを投入するために、一定間隔でjsonを作って送り続けるCLIツールを作った。Go製。 urfave/cliを使った。
sambaiz/sendjson
こんなindexにデータを入れてみる。
$ curl -XPUT &#39;http://localhost:9200/hoge&#39; -d&#39; { &amp;quot;mappings&amp;quot;: { &amp;quot;test_type&amp;quot;: { &amp;quot;_all&amp;quot;: { &amp;quot;enabled&amp;quot;: false }, &amp;quot;properties&amp;quot;: { &amp;quot;os_name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; }, &amp;quot;score&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;byte&amp;quot; }, &amp;quot;@timestamp&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;epoch_second&amp;quot; } } } } } &#39;  こんな感じでキーに対してtypeと入る値を定義するとそれっぽいデータができて送られていく。
$ go install github.com/sambaiz/sendjson $ sendjson --interval 0.5s --duration 10s --url http://localhost:9200/hoge/test_type &#39; { &amp;quot;os_name&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;or&amp;quot;: [&amp;quot;windows&amp;quot;, &amp;quot;mac&amp;quot;, &amp;quot;linux&amp;quot;, &amp;quot;ios&amp;quot;, &amp;quot;android&amp;quot;]}, &amp;quot;score&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;, &amp;quot;min&amp;quot;: 0, &amp;quot;max&amp;quot;: 100}, &amp;quot;@timestamp&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;time&amp;quot;, &amp;quot;time_format&amp;quot;: &amp;quot;unix_epoch&amp;quot;} }&#39; {&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82} {&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:9} {&amp;quot;@timestamp&amp;quot;:1488635131,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:73} {&amp;quot;@timestamp&amp;quot;:1488635131,&amp;quot;os_name&amp;quot;:&amp;quot;ios&amp;quot;,&amp;quot;score&amp;quot;:50} {&amp;quot;@timestamp&amp;quot;:1488635132,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:69} .</description>
    </item>
    
    <item>
      <title>H2OでHTTPS-&gt;HTTPのリバースプロキシを立てる</title>
      <link>https://www.sambaiz.net/article/75/</link>
      <pubDate>Thu, 02 Mar 2017 20:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/75/</guid>
      <description>良くチューニングされたNginxと同じくらい速いと 評判のHTTP/2サーバーH2Oでリバースプロキシを立ててみる。 HTTP/2だけではなく1.xにも対応しているので古い環境などでも大丈夫。
設定は Reverse Proxyと HTTP to HTTPSの サンプルをもとにして書いた。
hosts: &amp;quot;*&amp;quot;: listen: port: 443 ssl: certificate-file: /etc/h2o/oreore.crt key-file: /etc/h2o/server.key paths: &amp;quot;/&amp;quot;: proxy.reverse.url: http://127.0.0.1:3000/ access-log: /dev/stdout error-log: /dev/stderr  とりあえずオレオレ証明書で試してみる。
$ openssl genrsa 2048 &amp;gt; server.key # private key $ openssl req -new -key server.key &amp;gt; server.csr # certificate signing request $ openssl x509 -days 365000 -req -signkey server.key &amp;lt; server.csr &amp;gt; oreore.crt # oreore certificate  Dockerで動かす。lkwg82/h2o.docker
$ vi h2o.</description>
    </item>
    
    <item>
      <title>Goroutineの数をworkerで抑制する</title>
      <link>https://www.sambaiz.net/article/74/</link>
      <pubDate>Mon, 27 Feb 2017 23:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/74/</guid>
      <description>Goのnet/httpとKeep-Alive - sambaiz.netでやったように、 あるエンドポイントに連続してGoroutineでリクエストを投げると、リクエスト数を増やしたときにタイムアウトが頻発するようになった。
まず、2000リクエストを投げてみた結果。
[RESULT] request: 2000, ok: 2000, ng: 0, time(ms) 138  一応全部捌けてはいるけど、おおよそ同時にリクエストを送っているのにタイムアウト(100ms)時間を超えてしまっている。これをさらに3000に増やしてみる。
[RESULT] request: 3000, ok: 13, ng: 2987, time(ms) 372  ほぼ全滅してしまった・・・。時間もおかしいのでGoroutineでの処理に遅延が発生しているようだ。 そこで、都度Goroutineを生成してリクエストを投げるのではなく、 一定数のWorkerに処理させることで、同時に作られるGoroutineの数を抑制する。
type Req struct { Okch chan int Ngch chan int } func startWorker(ctx context.Context, num int) (requestch chan *Req) { requestch = make(chan *Req) for i := 0; i &amp;lt; num; i++ { go func() { for { select { case req := &amp;lt;-requestch: request(req.</description>
    </item>
    
    <item>
      <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
      <link>https://www.sambaiz.net/article/73/</link>
      <pubDate>Sun, 26 Feb 2017 18:56:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/73/</guid>
      <description>aws-fluent-plugin-kinesisでKinesis Streamsに送り、Lambdaで読んでS3に保存する。 要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。
fluentdで送る $ td-agent-gem install fluent-plugin-kinesis  try_flush_intervalとqueued_chunk_flush_intervalはドキュメントには載っていないが、 以下のページによるとそれぞれqueueに次のchunkがないときとあるときのflushする間隔。 いずれもデフォルトは1だが、これを減らすことでもっと頻繁に吐き出されるようになるらしい。
Fluentd の out_forward と BufferedOutput
あとシャードに振り分けるためのpartition_key を指定できる。デフォルトはランダム。
&amp;lt;source&amp;gt; @type tail path /var/log/td-agent/hoge.log pos_file /etc/td-agent/log.pos tag hoge.log format json time_key timestamp # 2017-01-01T01:01:01+0900 time_format %Y-%m-%dT%H:%M:%S%z &amp;lt;/source&amp;gt; &amp;lt;match hoge.log&amp;gt; @type kinesis_streams region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt;  いくつか送ってみる。
for i in `seq 1 1000` do echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;, &amp;quot;timestamp&amp;quot;: &amp;quot;2017-01-01T01:01:01+0900&amp;quot;}&#39; &amp;gt;&amp;gt; /var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>AWSのAssumeRole</title>
      <link>https://www.sambaiz.net/article/72/</link>
      <pubDate>Sat, 25 Feb 2017 20:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/72/</guid>
      <description>AWS Security Token Serviceによる、 RoleArn(arn:aws:iam::&amp;lt;account id&amp;gt;:role/&amp;lt;role name&amp;gt;)から一時的なCredentialを取得する仕組み。 前もって発行したAPIキーとは違い、有効期限が存在するため続けて呼ぶ場合は失効する前に再発行する必要がある。
ではRoleArnを知っていたら誰でも取得できるかというと、もちろんそうではなく、 ロールの信頼関係、&amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;のPrincipalのところで信頼する対象を設定する。 例えば、Serviceでec2.amazonaws.comを指定してEC2がAssumeRoleするのを許可したり、 AWSで(他の)アカウントやユーザーを指定してそのAPIキーでこのRoleのCredentialを取得できるようにしたりといった感じ。
{ &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;, &amp;quot;Statement&amp;quot;: [ { &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Principal&amp;quot;: { &amp;quot;Service&amp;quot;: &amp;quot;ec2.amazonaws.com&amp;quot; }, &amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot; } ] }  EC2にロールを設定すると、実はそのロールについてAssumeRoleして自動でCredentialを取得している。 EC2にロールを設定するにはロールとは別に インスタンスプロファイルを作成 する必要があるが、コンソールでEC2のサービスロールを作ると同名のインスタンスプロファイルが自動で作成される。 さらに、AssumeRoleのServiceとしてec2.amazonaws.comが追加されている。
$ curl http://169.254.169.254/latest/meta-data/iam/info { &amp;quot;Code&amp;quot; : &amp;quot;Success&amp;quot;, &amp;quot;LastUpdated&amp;quot; : &amp;quot;2017-02-25T10:56:33Z&amp;quot;, &amp;quot;InstanceProfileArn&amp;quot; : &amp;quot;arn:aws:iam::*****:instance-profile/assume_role_test&amp;quot;, &amp;quot;InstanceProfileId&amp;quot; : &amp;quot;*****&amp;quot; } $ curl http://169.254.169.254/latest/meta-data/iam/security-credentials/assume_role_test { &amp;quot;Code&amp;quot; : &amp;quot;Success&amp;quot;, &amp;quot;LastUpdated&amp;quot; : &amp;quot;2017-02-25T10:56:23Z&amp;quot;, &amp;quot;Type&amp;quot; : &amp;quot;AWS-HMAC&amp;quot;, &amp;quot;AccessKeyId&amp;quot; : &amp;quot;*****&amp;quot;, &amp;quot;SecretAccessKey&amp;quot; : &amp;quot;*****&amp;quot;, &amp;quot;Token&amp;quot; : &amp;quot;*****&amp;quot;, &amp;quot;Expiration&amp;quot; : &amp;quot;2017-02-25T17:26:07Z&amp;quot; }  参考 IAMロール徹底理解 〜 AssumeRoleの正体 ｜ Developers.</description>
    </item>
    
    <item>
      <title>ElasticsearchのCircuit Breaker</title>
      <link>https://www.sambaiz.net/article/71/</link>
      <pubDate>Fri, 24 Feb 2017 21:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/71/</guid>
      <description>ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net
ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。 表示されたエラーはこういうの。
&amp;quot;root_cause&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;circuit_breaking_exception&amp;quot;, &amp;quot;reason&amp;quot;: &amp;quot;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;quot;, &amp;quot;bytes_wanted&amp;quot;: 10464007168, &amp;quot;bytes_limit&amp;quot;: 8998512230 } ],  これは1リクエストの集計などで使うメモリ量がしきい値をこえて Circuit Breakerが発動したということ。 メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。
情報はstatsのapiでも取得できる。
$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request { &amp;quot;limit_size_in_bytes&amp;quot;: 8998512230, &amp;quot;limit_size&amp;quot;: &amp;quot;8.3gb&amp;quot;, &amp;quot;estimated_size_in_bytes&amp;quot;: 10348347504, &amp;quot;estimated_size&amp;quot;: &amp;quot;9.6gb&amp;quot;, &amp;quot;overhead&amp;quot;: 1, &amp;quot;tripped&amp;quot;: 470 }  今回ひっかかったのはindices.breaker.request.limit。デフォルトではJVMのヒープメモリの60%になっているが、 これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。
$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{ &amp;quot;persistent&amp;quot; : { &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;, &amp;quot;indices.</description>
    </item>
    
    <item>
      <title>crontabのメモ</title>
      <link>https://www.sambaiz.net/article/70/</link>
      <pubDate>Fri, 24 Feb 2017 21:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/70/</guid>
      <description>各ユーザーごとのcron設定。crontab -eでも編集できるけど、間違えて-rにすると全部消えてしまうのでこういう風に一旦取り出してから編集すると安全。
$ crontab -l &amp;gt; ~/crontab $ echo &amp;quot;*/1 * * * * /hoge/fuga.sh&amp;quot; &amp;gt;&amp;gt; ~/crontab $ crontab &amp;lt; ~/crontab $ crontab -l */1 * * * * /hoge/fuga.sh  参考 cron 設定ファイル (crontab ファイル) の置き場所と書式について - ひだまりソケットは壊れない</description>
    </item>
    
    <item>
      <title>Cookieのメモ</title>
      <link>https://www.sambaiz.net/article/69/</link>
      <pubDate>Wed, 22 Feb 2017 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/69/</guid>
      <description>https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies
レスポンスにSet-Cookieヘッダーが含まれていればブラウザはcookieに保存する。
HTTP/1.0 200 OK Content-type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry  リクエスト時にはCookieヘッダーにcookieを入れて送る。
GET /sample_page.html HTTP/1.1 Host: www.example.org Cookie: yummy_cookie=choco; tasty_cookie=strawberry  CookieにExpire(ある期間まで有効)またはMax-Age(特定の期間の間有効)を設定するとPermanent cookieとなる。 いずれも設定しなかった場合Session cookieとなり、ブラウザを閉じると削除されることになっているが、 ブラウザのセッション復元機能が有効になっていれば永続化される。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;  Secureを付けるとHTTPSでのみ送られる。 また、HttpOnlyはjsからdocument.cookieなどでアクセスすることができなくなる。 サイトにXSSの脆弱性があるとき、cookieが盗まれてしまうのを防ぐことができるので問題なければ設定するべき。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly  Domainを指定するとそのドメインとサブドメインへのリクエストのときに送られる。しないとそのドメインだけ。Pathも指定できる。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Domain=example.com; Path=/  リクエストが飛び、Set-Cookieヘッダーを受け取ればCookieに書かれるので、アクセスしたサイトのドメイン以外のCookieが書かれることがある。 このようなCookieを3rd party cookieといって、広告のトラッキングによく使われるが、 Safariなどのデフォルト設定では書き込めなくなっている。</description>
    </item>
    
    <item>
      <title>ELBのスケーリングとsurge queue</title>
      <link>https://www.sambaiz.net/article/68/</link>
      <pubDate>Tue, 21 Feb 2017 19:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/68/</guid>
      <description>バックエンドだけではなくELB自体もスケーリングし、内部node数はdigで調べることができる。 このnode数は自分ではコントロールできず、基本的に意識することはない。
$ dig ****.ap-northeast-1.elb.amazonaws.com ;; ANSWER SECTION: *****.elb.amazonaws.com. 60 IN A xxx.xxx.xxx.xxx *****.elb.amazonaws.com. 60 IN A yyy.yyy.yyy.yyy  nodeが増えるのにはある程度時間がかかるので、 アクセスが急増(5分間で50%以上のトラフィック増加が目安) したら捌ききれず、503を返すことがある。 前もって多量のアクセスが来ることが分かっていて、 AWSサポートがBusiness以上なら pre-warming申請することでnodeが増えた状態で待ち構えられる。
バックエンドのアプリケーションがリクエストを処理できない場合、ELBのsurge queueに溜まっていく。 この数はCloudWatchのSurgeQueueLength(キュー長の急増)メトリクスで確認できる。 また、SurgeQueueLengthの最大値1024を超えるとリクエストは拒否され、その数はSpoiloverCount(過剰数)メトリクスに出る。
参考 ELBの挙動とCloudWatchメトリクスの読み方を徹底的に理解する ｜ Developers.IO
Elastic Load Balancing でのレイテンシーのトラブルシューティング</description>
    </item>
    
    <item>
      <title>Kinesis Streams/Firehose/Analyticsを試す</title>
      <link>https://www.sambaiz.net/article/67/</link>
      <pubDate>Mon, 20 Feb 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/67/</guid>
      <description>https://aws.amazon.com/jp/kinesis/
リアルタイムのストリーミングデータを扱うサービス群。 いまのところTokyoリージョンではKinesis Streamsしか使えない。
Kinesis Firehose AWSのデータストアに送るストリーム。自分でデータを読む処理を書かなくてよく、スケーリングも勝手にやってくれるので簡単に使える。
https://aws.amazon.com/jp/kinesis/firehose/faqs/
Q: 送信先とは何ですか? 送信先はデータが配信されるデータストアです。Amazon Kinesis Firehose では、 現在送信先として Amazon S3、Amazon Redshift、Amazon Elasticsearch Service がサポートされています。  料金は取り込まれたデータ量による。
今回はS3に送ってみる。
圧縮方法を設定したり、Lambdaを噛ませたりすることができる。
StatusがActiveになったらKinesis Agentで送ってみる。 CloudWatchとFirehoseにPutする権限が必要。Firehoseはkinesis:ではなくfirehose:なので注意。
$ sudo yum install –y aws-kinesis-agent  /etc/aws-kinesis/agent.jsonを編集する。リージョンごとのエンドポイントは ここ にある。
{ &amp;quot;awsAccessKeyId&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;awsSecretAccessKey&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;firehose.endpoint&amp;quot;: &amp;quot;https://firehose.us-east-1.amazonaws.com&amp;quot;, &amp;quot;flows&amp;quot;: [ { &amp;quot;filePattern&amp;quot;: &amp;quot;/tmp/hoge.log&amp;quot;, &amp;quot;deliveryStream&amp;quot;: &amp;quot;hogefugastream&amp;quot; } ] }  $ sudo service aws-kinesis-agent start $ sudo chkconfig aws-kinesis-agent on $ echo &amp;quot;aaa&amp;quot; &amp;gt;&amp;gt; /tmp/hoge.</description>
    </item>
    
    <item>
      <title>fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する</title>
      <link>https://www.sambaiz.net/article/66/</link>
      <pubDate>Sun, 19 Feb 2017 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/66/</guid>
      <description>fluentdのmonitor_agent メトリクスをjsonで返すAPIを提供する。
&amp;lt;source&amp;gt; @type monitor_agent bind 0.0.0.0 port 24220 &amp;lt;/source&amp;gt;  $ curl localhost:24220/api/plugins.json | jq { &amp;quot;plugins&amp;quot;: [ { &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d8c250&amp;quot;, &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;forward&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;@type&amp;quot;: &amp;quot;forward&amp;quot;, &amp;quot;port&amp;quot;: &amp;quot;24222&amp;quot;, &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot; }, &amp;quot;output_plugin&amp;quot;: false, &amp;quot;retry_count&amp;quot;: null }, { &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d894c4&amp;quot;, &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;monitor_agent&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;@type&amp;quot;: &amp;quot;monitor_agent&amp;quot;, &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot;, &amp;quot;port&amp;quot;: &amp;quot;24220&amp;quot; }, &amp;quot;output_plugin&amp;quot;: false, &amp;quot;retry_count&amp;quot;: null }, { &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590dc1f2c&amp;quot;, &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;@type&amp;quot;: &amp;quot;file&amp;quot;, &amp;quot;path&amp;quot;: &amp;quot;/var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>Goのselectの中断処理(close, context)</title>
      <link>https://www.sambaiz.net/article/65/</link>
      <pubDate>Thu, 16 Feb 2017 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/65/</guid>
      <description>close(chan) closeしたチャネルを読むとゼロ値になるので、selectで待っているやつにまとめて送れる。
func main() { done := make(chan bool) wg := new(sync.WaitGroup) waitTillDone(wg, done) waitTillDone(wg, done) // こんなことしなくていい // done &amp;lt;- true // done &amp;lt;- true close(done) wg.Wait() } func waitTillDone(wg *sync.WaitGroup, done &amp;lt;-chan bool) { wg.Add(1) go func() { select { case v := &amp;lt;-done: fmt.Println(v) // false (ゼロ値) wg.Done() } }() }  context key-valueの値を渡せるほかにキャンセルやタイムアウトの仕組みをもつ。
ctx := context.Background() // empty context ctx, cancel = context.WithCancel(ctx) ctx, cancel = context.</description>
    </item>
    
    <item>
      <title>fluentd自身のログを拾う</title>
      <link>https://www.sambaiz.net/article/64/</link>
      <pubDate>Tue, 14 Feb 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/64/</guid>
      <description>fluentdは自身のログもfluent.errorのようなタグでイベントとして流す。
バッファを0にして意図的にエラーを発生させてみる。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; # throw away &amp;lt;match fluent.info&amp;gt; @type null &amp;lt;/match&amp;gt; &amp;lt;match fluent.**&amp;gt; @type stdout &amp;lt;/match&amp;gt; # error! &amp;lt;match **&amp;gt; @type file path /var/log/td-agent/hoge.log buffer_chunk_limit 0 buffer_queue_limit 0 &amp;lt;/match&amp;gt;  すると、こんなのがtd-agent.logに出力される。
fluent.error: {&amp;quot;error&amp;quot;:&amp;quot;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;quot;,&amp;quot;error_class&amp;quot;:&amp;quot;Fluent::BufferQueueLimitError&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;quot;}  ただ、これだとaggregatorに集めたときにどのサーバーのfluentdに問題が発生してるのか分からない。 そこでホスト名を追加する。
fluentdのrecord_transformerでログを加工する - sambaiz.net
&amp;lt;filter fluent.**&amp;gt; @type record_transformer enable_ruby &amp;lt;record&amp;gt; hostname &amp;quot;#{Socket.gethostname}&amp;quot; tag ${tag} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt;  fluent.</description>
    </item>
    
    <item>
      <title>GoでDynamoDBを使う</title>
      <link>https://www.sambaiz.net/article/63/</link>
      <pubDate>Sun, 12 Feb 2017 23:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/63/</guid>
      <description>テーブルを作成する プライマリキー テーブルの操作のガイドライン - Amazon DynamoDB
プライマリキーとしてパーティションキー(ハッシュキー)とオプションのソートキー(レンジキー)を設定する。 DynamoDBはこのパーティションキーに基づいて、複数のパーティションに分散して保存する。 テーブルにプロビジョニングされたスループット性能はパーティション間で均等に使われるので、 ソートキーを設定する場合にこれを最大限に活用するためには、 あるパーティションにリクエストが集中しないよう、パーティションキーに特定の値ばかり集中しないようなフィールドを 選ぶ必要がある。
セカンダリインデックス パーティションキーのグローバルセカンダリインデックス(GSI)と ソートキーのローカルセカンダリインデックス(LSI)がある。 射影されるフィールドを選択でき、ここに含まれないフィールドは返さない。 ただし、すべてをインデックスに書き込むのはコストが高いのでなるべく絞る。
キャパシティユニット  1読み込みキャパシティユニット: 4kbを超えないデータを1秒に1~2回(整合性による)読み込める 1書き込みキャパシティユニット: 1kbを超えないデータを1秒に1回書き込める  ユニットに応じて1時間あたりで課金される。
未使用のキャパシティがある場合、最大5分保持してバーストに備えてくれる。
読み書きする aws-sdk-goを直接使ってもいいけど、簡単に扱えるラッパー guregu/dynamo を使うことにした。
type Data struct { ID int64 `dynamo:&amp;quot;id&amp;quot;` Name string Age int } db := dynamo.New(session.New(), &amp;amp;aws.Config{Region: aws.String(&amp;quot;ap-northeast-1&amp;quot;)}) table := db.Table(&amp;quot;testtable&amp;quot;)  Create &amp;amp; Update d := Data{ID: 1, Name: &amp;quot;hogefuga&amp;quot;, Age: 123} if err := table.Put(d).Run(); err != nil { return err } if err := table.</description>
    </item>
    
    <item>
      <title>Elasticsearchのmapping</title>
      <link>https://www.sambaiz.net/article/62/</link>
      <pubDate>Thu, 09 Feb 2017 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/62/</guid>
      <description>Dynamic mappingがあるので、自分で設定しなくてもデータは入るけど、 自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。 バージョンは5.2。
$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39; { &amp;quot;name&amp;quot;: 0 } &#39; $ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39; { &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot; } &#39; { &amp;quot;error&amp;quot; : { &amp;quot;root_cause&amp;quot; : [ { &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot; } ], &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;, &amp;quot;caused_by&amp;quot; : { &amp;quot;type&amp;quot; : &amp;quot;number_format_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;For input string: \&amp;quot;sambaiz\&amp;quot;&amp;quot; } }, &amp;quot;status&amp;quot; : 400 }  Mapping parameters index falseにするとindexしない。クエリで必要ないものはfalseにする。</description>
    </item>
    
    <item>
      <title>Goのnet/httpとKeep-Alive</title>
      <link>https://www.sambaiz.net/article/61/</link>
      <pubDate>Tue, 07 Feb 2017 22:42:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/61/</guid>
      <description>Keep-AliveするとTCPコネクションを使い回し、名前解決やコネクション(3 way handshake)を毎回行わなくてよくなる。 Goのnet/httpではデフォルトでKeep-Aliveが 有効になっているが、 全体と同一ホストでそれぞれKeep-Aliveするコネクション数が制限される。 これらの値はClientのTransportが持っていて、 これがnullだとDefaultTransportが参照されるので、意識しなければこの値が使われる。
 MaxIdleConns: DefaultTransportでは100になっている。0にすると無制限。 MaxIdleConnsPerHost: デフォルト値は2。0にするとデフォルト値が使われる。  同一のホストに同時にたくさんリクエストする場合、2だとほとんど意味を持たない。これを増やして比較してみた。
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;io/ioutil&amp;quot; &amp;quot;net/http&amp;quot; &amp;quot;time&amp;quot; ) var client = http.Client{ Timeout: time.Millisecond * 100, } const TOTAL_REQUEST_NUM = 3000 const TARGET_URL = &amp;quot;*****&amp;quot; func main() { http.DefaultTransport.(*http.Transport).MaxIdleConns = 0 http.DefaultTransport.(*http.Transport).MaxIdleConnsPerHost = 3000 okChan := make(chan int, TOTAL_REQUEST_NUM) ngChan := make(chan int, TOTAL_REQUEST_NUM) var okCount = 0 var ngCount = 0 // connect and keep-alive for i := 0; i &amp;lt; TOTAL_REQUEST_NUM; i++ { go request(okChan, ngChan) } for { select { case &amp;lt;-okChan: okCount++ case &amp;lt;-ngChan: ngCount++ } if okCount+ngCount == TOTAL_REQUEST_NUM { break } } okCount = 0 ngCount = 0 startNs := time.</description>
    </item>
    
    <item>
      <title>iftopでネットワークの帯域を見る</title>
      <link>https://www.sambaiz.net/article/60/</link>
      <pubDate>Tue, 07 Feb 2017 20:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/60/</guid>
      <description>$ yum install --enablerepo=epel iftop $ iftop -f &amp;quot;not dst net 10.0.0.0/8&amp;quot;  -i eth0のようにしてインタフェースを指定し、-fでフィルタをかけられる。フィルタの詳細はman pcap-filterで。
 12.5Kb 25.0Kb 37.5Kb 50.0Kb	62.5Kb └─────────────────────────┴──────────────────────────┴──────────────────────────┴──────────────────────────┴────────────────────────── ip-172-31-9-9.ap-northeast-1.compute.internal =&amp;gt; 61-121-217-66.dh-connect.net 1.72Kb 6.57Kb 2.40Kb &amp;lt;= 416b 2.13Kb 702b ... ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── TX: cum: 22.6KB peak: 13.2Kb rates: 1.22Kb 1.27Kb 2.46Kb RX: 6.63KB 5.03Kb 208b 330b 748b TOTAL: 29.2KB 18.2Kb 1.42Kb 1.59Kb 3.19Kb  左から2, 10, 40秒間の平均kbps。TXが送信量、RXが受信量で、cumが総量、peakが最大。
実行中にSでソースのポートをDでディスティネーションのポートが表示される。</description>
    </item>
    
    <item>
      <title>vmstatのメモ</title>
      <link>https://www.sambaiz.net/article/59/</link>
      <pubDate>Mon, 06 Feb 2017 22:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/59/</guid>
      <description>$ vmstat 間隔(秒) procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 118588 80388 2516284 0 0 2 77 141 85 1 0 98 0 0  procs  r: 実行待ちプロセス数。CPUの処理が追いついていない。
 b: 割り込み不可能なスリープ中のプロセス数。I/O待ちらしい。
  memory  swpd: バーチャルメモリの使用量。
 free: 空きメモリ量。
 buff: バッファに使われてるメモリ量。
 cache: キャッシュに使われているメモリ量。
  swap  si: 秒あたりのスワップイン量。メモリが足りていない。</description>
    </item>
    
    <item>
      <title>EC2のインスタンスストア</title>
      <link>https://www.sambaiz.net/article/58/</link>
      <pubDate>Mon, 06 Feb 2017 21:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/58/</guid>
      <description>http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/InstanceStorage.html
EC2ではインスタンスタイプによってはEBSに加えてインスタンスストアが使える。しかも追加料金なし。 対象はストレージが&amp;rdquo;EBSのみ&amp;rdquo;でないもの。
https://aws.amazon.com/jp/ec2/instance-types/
インスタンスストアはインスタンスが停止したり、障害が起きると消える一時ストレージ。再起動では消えない。 ホストに物理的にアタッチされているので、バッファやキャッシュなどの頻繁に読み書きされ、消えてもいいデータに最適。 他のインスタンスにアタッチすることはできない。容量や性能もインスタンスタイプに依存する。
インスタンスストアボリュームの追加は インスタンスの起動時に、新しいボリュームを追加し、ボリュームタイプをインスタンスストアにすることで行うことができる。
今回はSSDストレージ1 x 4のm3.mediumで試す。これは4gbのボリュームが一つ追加できるという意味。
まずはインスタンスストアを追加してないインスタンス。 lsblkというのはlist block devicesの略。
$ df -h ファイルシス サイズ 使用 残り 使用% マウント位置 /dev/xvda1 7.8G 1.2G 6.6G 15% / ... $ dd if=/dev/zero of=hoge bs=1M count=1000 $ ls -sh 合計 1001M 1001M hoge $ df -h ファイルシス サイズ 使用 残り 使用% マウント位置 /dev/xvda1 7.8G 2.2G 5.6G 28% / ... $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 8G 0 disk └─xvda1 202:1 0 8G 0 part /  それに対してインスタンスストア(/dev/xvdb)を追加したインスタンス。</description>
    </item>
    
    <item>
      <title>HoloLensでGaze, Click, Hold, Voiceイベントを拾う</title>
      <link>https://www.sambaiz.net/article/57/</link>
      <pubDate>Sun, 05 Feb 2017 20:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/57/</guid>
      <description>こんなの。SparitalMappingを有効にしているので球が床で止まっている。
動画
HoloToolKit のインタフェースを実装することでイベントを拾えるようになっている。
IFocusable Gazeしたとき。
public void OnFocusEnter（） { gazing = true; } public void OnFocusExit() { gazing = false; }  IInputClickHandler クリックしたとき。
public void OnInputClicked(InputEventData eventData) { if (!clicked) { clicked = true; clickedRotationFrame = 0; } countUp(); }  IHoldHandler Hold(指を下げたまま維持する)したとき。 指を上げたときがCompletedで、Objectを外れたときCanceledになる。
public void OnHoldStarted(HoldEventData eventData) { holding = true; clicked = true; } public void OnHoldCompleted(HoldEventData eventData) { holding = false; } public void OnHoldCanceled(HoldEventData eventData) { holding = false; }  ISpeechHandler 声の入力。 InspectorからSpeech Input Source(Script)を追加して反応するキーワードを設定して使う。 MicrophoneのCapabilitiesが必要。</description>
    </item>
    
    <item>
      <title>HoloLensの開発を始める</title>
      <link>https://www.sambaiz.net/article/56/</link>
      <pubDate>Sat, 04 Feb 2017 21:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/56/</guid>
      <description>HoloLensでのアプリケーション https://developer.microsoft.com/en-us/windows/holographic/app_model
ある点を見るGazeと指で選択するGesture、声で入力するVoiceで操作する。
HoloLens shell では壁などにタイルを配置することでアプリケーションが起動する。
一度に動くアプリケーションは一つ。 他にアクティブなアプリケーションがあれば中断され、タイルは最後の状態のスクリーンショットになる。 タイルを削除するとプロセスが終了する。
Viewには空間全体を使うHolographic Viewと、通常のウィンドウのような2D Viewがある。
開発を始める Unityを使ってHolographic Viewのアプリケーションを開発する。
必要なツールをインストールする。エミュレーターは空きメモリが2GB以上ないと立ち上がらない。
https://developer.microsoft.com/en-us/windows/holographic/install_the_tools
チュートリアル https://developer.microsoft.com/en-us/windows/holographic/holograms_100
QualityのところでWindows Storeのマークがなかったら、 UnityのFile-&amp;gt;Build SettingsからWindows Storeモジュールをダウンロードする。
https://developer.microsoft.com/en-us/windows/holographic/holograms_101e
エミュレーターはWASDキーで移動してカーソルキーで向きを変え、エンターキーで選択できる。
エミュレーターで動かしてみる UnityProjectを作成してHolograms 100のように設定していく。
まずはCamera。
 Position: (0,0,0) Clear Flags: Solid Color Background: (0,0,0,0) Clipping Planes Near: 0.85  とりあえず動くことを確認するため適当なオブジェクトを置いてビルドしてみる。
Edit-&amp;gt;Project Settings-&amp;gt;QualityでWindows StoreをFastestにする。
Build Settings-&amp;gt;Windows Storeで
 SDK: Universal: 10 Target device: HoloLens UWP Build Type: D3D Unity C# Projectにチェック  にする。
BuildSettingsにあるPlayer Settingsボタンを押して Other SettingsのVirtual Reality Supportedにチェックを入れ、 SDKsにWindows Holographicが出るのを確認する。</description>
    </item>
    
    <item>
      <title>fluentdのrecord_transformerでログを加工する</title>
      <link>https://www.sambaiz.net/article/55/</link>
      <pubDate>Fri, 03 Feb 2017 21:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/55/</guid>
      <description>http://docs.fluentd.org/v0.12/articles/filter_record_transformer
追加したり、編集したり、削除したりできるフィルタ。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;filter hoge.log&amp;gt; @type record_transformer enable_ruby auto_typecast true remove_keys b,d &amp;lt;record&amp;gt; what_is_tag ${tag} what_is_a ${record[&amp;quot;a&amp;quot;]} what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; &amp;lt;match hoge.log&amp;gt; @type stdout &amp;lt;/match&amp;gt;  この例だとタグを値に持つ&amp;rdquo;what_is_tag&amp;rdquo;、aを値に持つ&amp;rdquo;what_is_a&amp;rdquo;、b.cの値に1を足す&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;が追加され、 bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。
auto_typecastをtrueにしないと&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;の値がstringになる。
$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: 1}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.log hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2}  エラーが起きるとnullになるが、それ以外の処理はされる。
$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: &amp;quot;error!&amp;quot;}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.</description>
    </item>
    
    <item>
      <title>fluentdでElasticsearchに送る</title>
      <link>https://www.sambaiz.net/article/54/</link>
      <pubDate>Wed, 01 Feb 2017 21:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/54/</guid>
      <description>uken/fluent-plugin-elasticsearch
必要なものをいれていく。Amazon LinuxのAMIから。
 Failed to build gem native extension.  $ yum install -y ruby-devel   serverengine requires Ruby version &amp;gt;= 2.1.0.  rbenvでバージョンを上げる。
$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv $ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src $ echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile $ ~/.rbenv/bin/rbenv init $ echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile $ source ~/.bash_profile $ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build  $ rbenv -v rbenv 1.</description>
    </item>
    
    <item>
      <title>Goのnet/http.Client.Doの内部実装をたどったメモ</title>
      <link>https://www.sambaiz.net/article/53/</link>
      <pubDate>Mon, 30 Jan 2017 20:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/53/</guid>
      <description>package main import ( &amp;quot;fmt&amp;quot; &amp;quot;net/http&amp;quot; &amp;quot;io/ioutil&amp;quot; ) var client = http.Client{} func main() { req, err := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;http://example.com&amp;quot;, nil) if err != nil{ panic(err) } resp, err := client.Do(req) if err != nil{ panic(err) } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil{ panic(err) } fmt.Println(string(body)) }  Client TransportがTCPコネクションをキャッシュするのでClientは使い回すべき。複数のgoroutineでコンカレントに使っても大丈夫。
https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36
type Client struct { // nilならDefaultTransportが使われる Transport RoundTripper // nilなら10回で止まる CheckRedirect func(req *Request, via []*Request) error // nilならcookieは無視される Jar CookieJar Timeout time.</description>
    </item>
    
    <item>
      <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
      <link>https://www.sambaiz.net/article/52/</link>
      <pubDate>Sun, 29 Jan 2017 17:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/52/</guid>
      <description>https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
vm.max_map_count (バーチャルメモリにマッピングできる最大ページ数) を262144以上にする。
$ sysctl vm.max_map_count $ grep vm.max_map_count /etc/sysctl.conf vm.max_map_count=262144 # sysctl -w vm.max_map_count=262144  30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。
-cap-add=IPC_LOCKでLock memory(スワップアウトしないようにする)を 許可する。
https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html
ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。 ただし、物理RAMの50%以下で、32GB近辺の境界を超えないようにする。
$ mkdir -p ~/do/elasticsearch/data $ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \ --name elasticsearch \ -p 9200:9200 \ -e xpack.security.enabled=false \ -e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;quot;-Xms28g -Xmx28g&amp;quot; \ --cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \ --restart=always \ docker.elastic.co/elasticsearch/elasticsearch:5.1.2 $ docker volume ls local elasticsearch  問題なく起動しているか確認する。</description>
    </item>
    
    <item>
      <title>fluentdのforward</title>
      <link>https://www.sambaiz.net/article/51/</link>
      <pubDate>Wed, 25 Jan 2017 22:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/51/</guid>
      <description>td-agent間でログをやりとりするとき に使われるforwardについて。内部ではMessagePackを使っている。
forward input http://docs.fluentd.org/articles/in_forward
受け取る側。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;match **&amp;gt; @type stdout &amp;lt;/match&amp;gt;  /etc/init.d/td-agent restartしてfluent-catで送ってみる。
$ echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat -h xx.xx.xx.xx test.tag  /var/log/td-agent/td-agent.logに出力される。
test.tag: {&amp;quot;hoge&amp;quot;:&amp;quot;fuga&amp;quot;}  forward output http://docs.fluentd.org/articles/out_forward
http://docs.fluentd.org/articles/buffer-plugin-overview
送る側。
ポートはデフォルトで24224で、イベントの送信にTCPを、heartbeatにUDP(heartbeat_typeで変えられる)を使う。
flush_intervalははデフォルトで60秒。 確認のときは短くしておくと分かりやすい。 buffer_queueの一番上のチャンクがこの時間経過するか、サイズがbuffer_chunk_limitを超えると、一番下のチャンクが書き込まれ、新しいチャンクがpushされる。 chunkの数がbuffer_queue_limitに到達してしまうと新しいイベントは破棄されてしまうので リソースを圧迫(buffer_chunk_limit * buffer_queue_limit)しない程度に十分大きな数にしておき、 スパイクや障害時に備えておく。 buffer_typeはデフォルトがmemory。fileだとflush_at_shutdownのデフォルトがfalseなので注意。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;match **&amp;gt; @type forward flush_interval 1s buffer_type file buffer_path /var/log/td-agent/forward-buf flush_at_shutdown true buffer_chunk_limit 256m &amp;lt;server&amp;gt; name log_server host xx.</description>
    </item>
    
    <item>
      <title>Goのinterface/structの埋め込み</title>
      <link>https://www.sambaiz.net/article/50/</link>
      <pubDate>Wed, 18 Jan 2017 01:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/50/</guid>
      <description>Goには継承が存在しない。その代わりstructを埋め込み、委譲することができる。
https://golang.org/doc/effective_go.html#embedding
挙動 interfaceにinterfaceを埋め込む type I interface { Hoge() } type J interface { Fuga() } type K interface { I J }  インタフェースKはIとJを合わせたものになる。IとJに重複する関数がある場合はエラーになる。
type L struct { } func (l L) Hoge() { fmt.Println(&amp;quot;hoge&amp;quot;) } func (l L) Fuga() { fmt.Println(&amp;quot;fuga&amp;quot;) }  var k K k = L{} k.Hoge() k.Fuga()  structにinterfaceを埋め込む type K interface { Hoge() Fuga() } type M struct { K }  埋め込むとm.</description>
    </item>
    
    <item>
      <title>Goのpanicとrecover</title>
      <link>https://www.sambaiz.net/article/49/</link>
      <pubDate>Tue, 17 Jan 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/49/</guid>
      <description>panic https://golang.org/pkg/builtin/#panic
panicは現在のgoroutineの通常の実行を停止する組み込み関数。 index out of rangeや invalid memory address or nil pointer dereference のときなどでも呼ばれる。
deferを実行して呼び出し元に戻り、panicの実行-&amp;gt;deferの実行-&amp;gt;呼び出し元に戻る、を繰り返して 最後まで戻ったらプログラムを終了し、panicに渡した引数と共にエラーをレポートする。
func main() { a() } func a() { defer fmt.Println(&amp;quot;a&amp;quot;) b() fmt.Println(&amp;quot;a2&amp;quot;) } func b() { defer fmt.Println(&amp;quot;b1&amp;quot;) panic(&amp;quot;b2&amp;quot;) defer fmt.Println(&amp;quot;b3&amp;quot;) }  b1 a panic: b2 goroutine 1 [running]: panic(0x89840, 0xc42000a2c0) /*****/libexec/src/runtime/panic.go:500 +0x1a1 main.b() /*****/main.go:19 +0x107 main.a() /*****/main.go:13 +0xce main.main() /*****/main.go:8 +0x14 exit status 2  recover https://golang.org/pkg/builtin/#recover
deferで呼ぶことによってpanicを停止させることができる組み込み関数。 panicの引数に渡した値を取得できる。
func main() { fmt.</description>
    </item>
    
    <item>
      <title>OAuth2.0のメモ</title>
      <link>https://www.sambaiz.net/article/48/</link>
      <pubDate>Sun, 08 Jan 2017 02:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/48/</guid>
      <description>認可(Authorization)と認証(Authentication) それぞれAuthZ、AuthNとも書かれる。
 認可: リソースへのアクセスを許可する 認証: ユーザーが何者かを検証する  OAuth 2.0 認可のプロトコル。 それによってアクセスできるようになったリソースの情報をもとに認証を行ったりすることもあるが、 以下に示すImplicit Flowでそれをやると他のサービスのトークンで他人に成りすませてしまう問題があるため、 認証する場合はOAuth 2.0ベースの認証プロトコルのOpenID Connectを使うべき。 その場合もトークンを取得するまでの流れはほとんどOAuth 2.0通りなのでフローを理解しておいて無駄はない。
OpenID ConnectのIDトークンの内容と検証 - sambaiz-net
Authorization Code Flow OAuthクライアントがアプリケーションサーバーのときのフロー。
まずユーザーがOAuth認可ページで認可する。 このリクエストには
 client_id redirect_uri scope: アクセスできるリソースの種類 response_type=code: 認可コードが返される state: CSRFを防ぐためのランダムで一意な文字列。アプリケーションサーバーが保持して、前後で一致するかチェックする  が含まれる。
認可されると認可コードとstateを付けてredirect_uri(事前に登録しておく)にリダイレクトするので、 アプリケーションサーバーは認可コードをアクセストークンに交換する。 この際、client_idとclient_secretも送る。
オプションでリフレッシュトークンを含み、これを使うと期限が切れたとき新しいアクセストークンを取得できる。
アクセストークンは通常Bearer Token(Authorization: Bearer ***)としてリクエストに含まれる。
Implicit Flow OAuthクライアントがアプリなどでclient_secretの機密性を保てない場合のフロー。
認可コードは不要なのでresponse_type=tokenでリクエストし、アクセストークンをブラウザで取得する。 リフレッシュトークンは含まない。 他のサービスで発行された他人のトークンを使うことでなりすませてしまうので、 そのトークンがどのサービスに対して発行されたかを確認する術が特に用意されているのでなければ 認証に使ってはいけない。OpenID Connectでは署名されたIDトークンに発行されたサービスの情報が含まれている。
参考 O&amp;rsquo;Reilly Japan - OAuth 2.0をはじめよう
Implicit Flow では Covert Redirect で Token 漏れるね - OAuth.</description>
    </item>
    
    <item>
      <title>go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる</title>
      <link>https://www.sambaiz.net/article/47/</link>
      <pubDate>Wed, 04 Jan 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/47/</guid>
      <description>この関数のベンチマークを取る。
package cal import ( &amp;quot;math/big&amp;quot; ) var cache = map[int]*big.Int{} func resetCache() { cache = map[int]*big.Int{} } func Fibonacci(n int) *big.Int { if c := cache[n]; c != nil { return c } ret := new(big.Int) before := big.NewInt(1) for i := 1; i &amp;lt; n; i++ { tmp := new(big.Int).Add(ret, before) before = ret ret = tmp cache[i] = ret } cache[n] = ret return ret }  引数にtesting.</description>
    </item>
    
    <item>
      <title>汎用シリアライズ方法(MessagePack/Protocol Buffers/FlatBuffers)</title>
      <link>https://www.sambaiz.net/article/46/</link>
      <pubDate>Fri, 30 Dec 2016 18:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/46/</guid>
      <description>MessagePackとは JSONのように使うことができ、速くてサイズが小さい。
{&amp;quot;compact&amp;quot;:true,&amp;quot;スキーマ&amp;quot;:{&amp;quot;number&amp;quot;: 999, &amp;quot;string&amp;quot;: &amp;quot;aaa&amp;quot;}}  のjson(61bytes)をMessagePack(45bytes)に変換したのがこれ。見やすいように改行している。
82 a7 63 6f 6d 70 61 63 74 c3 ac e3 82 b9 e3 82 ad e3 83 bc e3 83 9e 82 a6 6e 75 6d 62 65 72 cd 03 e7 a6 73 74 72 69 6e 67 a3 61 61 61  一行目の82は要素数2のfixmap(要素数15まで)を表す。
二行目のa7が7バイトのfixstr(31bytesまで)で、 63 6f 6d 70 61 63 74が&amp;rdquo;compact&amp;rdquo;。c3はtrue。
三行目のacは12バイトのfixstrで、e3 82 b9 e3 82 ad e3 83 bc e3 83 9eが&amp;rdquo;スキーマ&amp;rdquo;。</description>
    </item>
    
    <item>
      <title>GoogleのkvsライブラリLevelDBを使う</title>
      <link>https://www.sambaiz.net/article/45/</link>
      <pubDate>Sat, 24 Dec 2016 21:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/45/</guid>
      <description>LevelDBとは https://github.com/google/leveldb
Googleが作った高速なkey-valueストレージライブラリ。
ChromeのIndexedDBやprometheusなどで使われている。
特徴  Keyと任意のバイト配列のValue データはKeyでソートされる。ソートのための比較関数はオーバーライドできる。 基本的な操作はPut, Get, Delete。 複数の変更を一つのatomicなバッチで行える 一環したデータのビューを取得するために、一時的なスナップショットを作成できる データを前にも後ろにもイテレーションできる データはSnappy compression libraryで自動で圧縮される。 ファイルシステムの操作など外部のアクティビティを仮想的なインタフェースを通して行うので、OSとのやりとりをカスタマイズできる。  制限  SQLデータベースではない。リレーショナルなデータモデルは持てないし、SQLやインデックスにも対応していない。 一度に一つのプロセスしかDBにアクセスできない。  キャッシュ  DBはファイルシステムのディレクトリに対応する名前を持ち、内容はそのディレクトリに保存される。 各ファイルには圧縮したブロックが保存され、良く使うものについては非圧縮のブロックがキャッシュされる。 ソートして隣接するキーは通常、同じブロックに配置される。ディスク転送とキャッシュはブロック単位。  フィルタ  Getの際、不要なデータを読まなくていいようにフィルタ(Bloom Filter)を用いることができる。 独自の比較関数(末尾のスペースを無視するなど)を使う場合、Bloom Filterを使うことができないことがあるので、その場合は独自のフィルタが必要。  レベル  最近の更新はログファイルに保存される。これが決められたサイズ(デフォルトでは約4MB)に達すると、sorted table(sst)に変換され、新しいログファイルが生成される。 現在のログファイルのコピーがメモリ(memtable)にも乗って読み取りで参照される。 sstはキーによってソートされたエントリーを保存する。エントリーはキーの値か、削除マーカー。 sstはレベルによってまとめられる。ログファイルから変換されると、特別なyoungレベル(level-0とも呼ばれる)に配置される。 youngファイルの数があるしきい値(現在4つ)を超えると全てのyoungファイルを全てのlevel-1ファイルとマージし、新しいlevel-1ファイルを生成する(2MBごとに1ファイル)。 youngレベルのファイルにはキーが重複していることがある。しかし、他のレベルでは重複しないキーの範囲がある。 level-L(L&amp;gt;=1)のファイルの合計サイズが10^L MBを超えたとき、level-Lのファイルと、level-(L+1)の全てのファイルをマージし、新しいlevel-(L+1)ファイルを生成する。 これによって、バルク読み込み/書き込みのみを使い、コストが高いシークを最小限にして、youngレベルから大きいレベルに更新を徐々にマイグレーションすることができる。  動かしてみる LevelDBのgo実装。
syndtr/goleveldb
$ go get github.com/syndtr/goleveldb/leveldb  まずDBを開く。
// open db, err := leveldb.OpenFile(&amp;quot;/Users/sambaiz/leveldb&amp;quot;, nil) defer db.Close() if err !</description>
    </item>
    
    <item>
      <title>gvmでGoのバージョン管理</title>
      <link>https://www.sambaiz.net/article/44/</link>
      <pubDate>Tue, 20 Dec 2016 20:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/44/</guid>
      <description>moovweb/gvm
必要なものはREADMEを見て入れる。
$ bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) $ source ${HOME}/.gvm/scripts/gvm $ gvm install go1.7 -B $ gvm use go1.7 $ go version go version go1.7 linux/amd64  $GOPATHと$GOROOTが書き変わる(${HOME}/.gvm/pkgsets/go1.7/global/)ので注意。</description>
    </item>
    
    <item>
      <title>複数EC2インスタンスを立ち上げてvegetaで負荷試験する</title>
      <link>https://www.sambaiz.net/article/43/</link>
      <pubDate>Sun, 18 Dec 2016 20:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/43/</guid>
      <description>vegetaで負荷をかける。
インスタンスを立ち上げるスクリプト コードはここ。 sambaiz/loadtest
まずキーペアを作成し、EC2インスタンスを立ち上げて、全てのインスタンスが使えるようになるまで待つ。
aws ec2 create-key-pair --key-name LoadTestKeyPare --query &#39;KeyMaterial&#39; --output text &amp;gt; LoadTestKeyPare.pem chmod 400 LoadTestKeyPare.pem aws ec2 run-instances --image-id $AMI_ID --count $INSTANCE_NUM --instance-type t2.micro --key-name LoadTestKeyPare --security-group-ids $SECURITY_GROUP_IDS --subnet-id $SUBNET_ID ... aws ec2 wait instance-status-ok --instance-ids $INSTANCE_IDS  このAMIは事前にPackerでつくったもの。vegetaをインストールしてファイルディスクリプタの上限を増やしている。
{ &amp;quot;variables&amp;quot;: { &amp;quot;aws_access_key&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;aws_secret_key&amp;quot;: &amp;quot;&amp;quot; }, &amp;quot;builders&amp;quot;: [{ &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;, &amp;quot;access_key&amp;quot;: &amp;quot;{{user `aws_access_key`}}&amp;quot;, &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `aws_secret_key`}}&amp;quot;, &amp;quot;region&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;, &amp;quot;source_ami&amp;quot;: &amp;quot;ami-0c11b26d&amp;quot;, &amp;quot;instance_type&amp;quot;: &amp;quot;t2.micro&amp;quot;, &amp;quot;ssh_username&amp;quot;: &amp;quot;ec2-user&amp;quot;, &amp;quot;ami_name&amp;quot;: &amp;quot;loadtest {{timestamp}}&amp;quot; }], &amp;quot;provisioners&amp;quot;: [{ &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;, &amp;quot;inline&amp;quot;: [ &amp;quot;wget https://github.</description>
    </item>
    
    <item>
      <title>SSHポートフォワーディングとnetstatのメモ</title>
      <link>https://www.sambaiz.net/article/42/</link>
      <pubDate>Sat, 17 Dec 2016 12:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/42/</guid>
      <description> SSHポートフォワーディング ローカルの8080ポートを、example.comを通したexample2.comの80ポートに向ける。
$ ssh hoge@example.com -Nf -L 8080:example2.com:80 $ curl localhost:8080 # =&amp;gt; example2.com:80   -N: リモートでコマンドを実行しない -f: バックグラウンドで実行  netstat ネットワークの状態を確認する。
$ netstat -ant Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN ...   -a: non-listening(TCPではESTABLISHED状態)しているソケットだけではなく、listeningしている情報も出す -n: 数値のアドレスで表示する -t: TCPで制限  </description>
    </item>
    
    <item>
      <title>ファイルディスクリプタの上限を増やす</title>
      <link>https://www.sambaiz.net/article/41/</link>
      <pubDate>Thu, 08 Dec 2016 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/41/</guid>
      <description>ファイルディスクリプタとは プロセスの外部とやりとりするための識別子。POSIXではint型で、0がstdin、1がstdout、2がstderrといったもの。 ファイルやデバイスに対するopen()や、 ネットワーク(INETドメインソケット)やホスト内(UNIXドメインソケット)で 通信するためのソケットを生成するsocket()などのシステムコールで生成される。
ファイルディスクリプタの上限 一つのプロセスがリソースを食いつぶさないように 使えるファイルディスクリプタの上限が決まっていて、ulimit -nで確認できる。デフォルトは大体1024。
$ ulimit -n 1024  各プロセスの上限と使っているファイルディスクリプタはこれで確認できる。
$ cat /proc/&amp;lt;プロセスID&amp;gt;/limits ... Max open files 1024 4096 files ... $ ls -l /proc/&amp;lt;プロセスID&amp;gt;/fd  webサーバーのように同時にたくさん通信したりすると上限に達してしまい、Too many open filesになってしまうので増やす必要がある。
/etc/security/limits.confで変更する PAM認証時(ログインするときなど)に適用されるので、サーバーの起動時に立ち上がったデーモンには使えない。
$ cat /etc/pam.d/sshd ... session required pam_limits.so ...  全てのユーザー(*)のプロセスが使える ファイルディスクリプタ(nofile)のsoft(ユーザーが設定できる)とhard(rootが設定できる)上限を共に64000にする。
$ echo &amp;quot;* hard nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf $ echo &amp;quot;* soft nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf $ ulimit -n 64000  ulimit -nで変更する シェルと、起動したプロセスで有効。</description>
    </item>
    
    <item>
      <title>Angular2とangular-cliでTODOを作る</title>
      <link>https://www.sambaiz.net/article/40/</link>
      <pubDate>Mon, 05 Dec 2016 00:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/40/</guid>
      <description>コード: https://github.com/sambaiz/angular2-todo
アプリケーションの作成と立ち上げ angular-cliをインストールしてサーバーを立ち上げるまで。
$ npm install angular-cli -g $ ng -v angular-cli: 1.0.0-beta.21 node: 5.12.0 os: darwin x64 $ ng new mytodo $ cd mytodo $ ng server  http://localhost:4200/
新しいコンポーネントを作る 新しいコンポーネントを作る。
$ ng g component todo-list  これでtodo-listディレクトリにコンポーネントクラスとテンプレートとCSS、テストとindexが出力される。
また、app.module.ts(BootstrapするRoot Module)にも追加されている。 NgModuleのdeclartionsなどに入っているものは、各Componentで指定しなくても使えるようになる。
import { BrowserModule } from &#39;@angular/platform-browser&#39;; import { NgModule } from &#39;@angular/core&#39;; import { FormsModule } from &#39;@angular/forms&#39;; import { HttpModule } from &#39;@angular/http&#39;; import { AppComponent } from &#39;.</description>
    </item>
    
    <item>
      <title>OpenVPNサーバーPritunlをDockerで動かす</title>
      <link>https://www.sambaiz.net/article/39/</link>
      <pubDate>Fri, 02 Dec 2016 21:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/39/</guid>
      <description>PritunlでVPNサーバーを立てる。
Dockerfileはこんな感じ。
https://hub.docker.com/r/sambaiz/pritunl/
FROM mongo:3.4 # https://docs.pritunl.com/docs/installation RUN echo &#39;deb http://repo.pritunl.com/stable/apt jessie main&#39; &amp;gt; /etc/apt/sources.list.d/pritunl.list &amp;amp;&amp;amp; \ apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 7568D9BB55FF9E5287D586017AE645C0CF8E292A &amp;amp;&amp;amp; \ apt-get --assume-yes update &amp;amp;&amp;amp; \ apt-get --assume-yes upgrade &amp;amp;&amp;amp; \ apt-get --assume-yes install pritunl iptables EXPOSE 80 443 12345/udp CMD mongod --fork --logpath /data/db/mongod.log &amp;amp;&amp;amp; echo &#39;Setup Key:&#39; `pritunl setup-key` &amp;amp;&amp;amp; pritunl start  $ docker run -itd -p 80:80 -p 443:443 -p 12345:12345/udp --privileged sambaiz/pritunl $ docker logs &amp;lt;id&amp;gt; .</description>
    </item>
    
    <item>
      <title>aws-sdk-goでs3にput/get</title>
      <link>https://www.sambaiz.net/article/38/</link>
      <pubDate>Wed, 30 Nov 2016 20:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/38/</guid>
      <description>aws-sdk-goでS3にputしてgetする。
package main import ( &amp;quot;bytes&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws/session&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/service/s3&amp;quot; ) const REGION = &amp;quot;ap-northeast-1&amp;quot; const BUCKET_NAME = &amp;quot;faweijojio4f3e4&amp;quot; func main() { sess, err := session.NewSession(aws.NewConfig().WithRegion(REGION)) if err != nil { fmt.Println(err.Error()) return } svc := s3.New(sess) // put data := []byte(&amp;quot;BBBBBB&amp;quot;) key := &amp;quot;AAA.txt&amp;quot; params := &amp;amp;s3.PutObjectInput{ Bucket: aws.String(BUCKET_NAME), Key: aws.String(key), Body: bytes.NewReader(data), ContentLength: aws.Int64(int64(len(data))), ContentType: aws.String(&amp;quot;text/plain&amp;quot;), } if _, err = svc.PutObject(params); err != nil { fmt.Println(err.Error()) return } // bucket list keys := []string{} err = svc.</description>
    </item>
    
    <item>
      <title>Goでstructをリフレクションしてcsvを出力する</title>
      <link>https://www.sambaiz.net/article/37/</link>
      <pubDate>Mon, 28 Nov 2016 21:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/37/</guid>
      <description>こんなstructとデータがあったら、
type Result struct{ Name string `col:&amp;quot;who&amp;quot;` Point int } x := Result{&amp;quot;sam&amp;quot;, 100}  フィールド名と、値、タグはrefrectで取れる。
x := Result{&amp;quot;sam&amp;quot;, 100} v := reflect.ValueOf(x) fmt.Println(v.Type().Field(0).Name) // -&amp;gt; Name fmt.Println(v.Type().Field(1).Name) // -&amp;gt; Point fmt.Println(v.Field(0).Interface()) // -&amp;gt; sam fmt.Println(v.Field(1).Interface()) // -&amp;gt; 100 fmt.Println(v.Type().Field(0).Tag.Get(&amp;quot;col&amp;quot;)) // -&amp;gt; who fmt.Println(v.Type().Field(1).Tag.Get(&amp;quot;col&amp;quot;)) // -&amp;gt;  これらをencoding/csvで書く。
ただ、引数を[]interface{}にするとinterface{}のスライスしか渡せないので、 一旦interface{}で受け取ってスライスにする。このときにもrefrectを使っている。
package main import ( &amp;quot;encoding/csv&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;os&amp;quot; &amp;quot;reflect&amp;quot; &amp;quot;strings&amp;quot; ) type Result struct { Name string `col:&amp;quot;who&amp;quot;` Point int Age int `col:&amp;quot;-&amp;quot;` // ignore } const COLTAG = &amp;quot;col&amp;quot; func main() { x := []Result{Result{&amp;quot;sam&amp;quot;, 100, 24}, Result{&amp;quot;tom&amp;quot;, 0, 100025}} file, err := os.</description>
    </item>
    
    <item>
      <title>WebVRを動かす</title>
      <link>https://www.sambaiz.net/article/36/</link>
      <pubDate>Wed, 16 Nov 2016 00:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/36/</guid>
      <description>WebVRとは Webブラウザ上でVRアプリケーションを動かすためのAPI。 ヘッドマウントディスプレイの動きを3D空間上の動きに変換してくれる。
WebVR API - Web API インターフェイス | MDN
ただし、まだほとんどのブラウザがVR APIをサポートしていないので、 実際はPolyfillで動かすことになる。
動かしてみる まず、webvr-boilerplateを動かしてみる。
$ npm init $ npm install node-static $ git clone https://github.com/borismus/webvr-boilerplate.git $ cd webvr-boilerplate/ &amp;amp;&amp;amp; npm install &amp;amp; cd ..  var static = require(&#39;node-static&#39;); var fileServer = new static.Server(&#39;./webvr-boilerplate&#39;); require(&#39;http&#39;).createServer(function (request, response) { request.addListener(&#39;end&#39;, function () { fileServer.serve(request, response); }).resume(); }).listen(8080);  http://localhost:8080
を見ると箱が回っているのが映る。
ただ、start_modeに3を指定してVRモードにしようとしたところ、
http://localhost:8080/index.html?start_mode=3
PCのChromeから見ると
base.js:191 Uncaught (in promise) Error: VRDisplay is not capable of presenting  というエラーが出てしまった。</description>
    </item>
    
    <item>
      <title>JVMのヒープ領域とFull GC</title>
      <link>https://www.sambaiz.net/article/35/</link>
      <pubDate>Mon, 14 Nov 2016 23:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/35/</guid>
      <description>ヒープ領域 ヒープ領域というのはメモリ上の動的に確保する領域のこと。 JVMでは、ヒープ領域のNew領域とOld領域、非ヒープ領域のPermanent領域が存在する(した)。
Permanent領域 ロードしたクラスやメソッドが入る。 Java8版のHotspotVM(OracleのJVM)ではMetaspace領域となり、ネイティブメモリに乗るようになったらしい。
New領域 New領域の中はさらに分かれている。
 Eden領域: オブジェクトが作られて最初に配置される。 To領域(Survivor領域1): Edenが一杯になると、EdenとFromから送られる。 From領域(Survivor領域0): Edenが一杯になると、Toから送られる。  Edenが一杯になったときに不要なオブジェクトは破棄、必要なものは領域を移動させるのがScavenge GC。 つまり、Edenが一杯になるたびにToに飛んだオブジェクトはFromと往復し続ける。 ただし、MaxTenuringThresholdの回数を超えるとOld領域に送られることになる。
Old領域 Old領域も一杯になったらどうしようもないのでFull GCが走る。 Full GCでは全ての領域のオブジェクトをチェックして不要なものを探す。 これに集中するので他のことはできなくなり、時間もかかる。 Full GCばかり起きていたらまともに動かないので、 Old領域にまで行かないようにオブジェクトの寿命を短くするか、 ヒープ領域の大きさ(-Xms, -Xmx)を変えたりしてなるべく起きないようにしたい。
どれくらいFull GCしているかどうか -XloggcでGCのログが出せる。-XX:+UseGCLogFileRotationでローテーションしたりもできる。 あと手軽にjpsからのjstat -gc &amp;lt;pid&amp;gt;、あるいはグラフで可視化できるようなやつでヒープ領域の状態を確認する。 jstatの結果の意味はここに書いてある。 例えばFGCがフルGCイベントの数。
参考 JVMとGCのしくみ
Java8のHotSpotVMからPermanent領域が消えた理由とその影響 | ギークを目指して
Java開発の性能改善！ その２ GCログの解析とHeepの設定</description>
    </item>
    
    <item>
      <title>API BlueprintでAPI仕様を書く</title>
      <link>https://www.sambaiz.net/article/34/</link>
      <pubDate>Thu, 10 Nov 2016 00:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/34/</guid>
      <description>API BlueprintというのはAPIの仕様を書くための言語で、 これを元にHTMLのドキュメントにしたり、モックサーバーを立てたりするツールがある。
最初にMetadataとして、API Blueprintのバージョンを書く。
FORMAT: 1A  基本的にはMarkdownのように書ける。
# テストAPI テスト  頭にGroupと書くとグループができる。
# Group echo やまびこ  終わりに[]で囲んでリソースを書く。
## echo [/echo] やっほー  アクション。
### echo [POST] 叫ぶ + say (string) - 発声  リクエスト例とレスポンス例はこんな感じ。JSON Schemaを書くこともできる。
+ Request (application/json) { &amp;quot;say&amp;quot;: &amp;quot;yahho&amp;quot; } + Response 200 (application/json) + Headers Hoge: Fuga + Body { &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot; }  全体
FORMAT: 1A # テストAPI テスト # Group echo やまびこ ## echo [/echo] やっほー ### echo [POST] 叫ぶ + say (string) - 発声 + Request (application/json) { &amp;quot;say&amp;quot;: &amp;quot;yahho&amp;quot; } + Response 200 (application/json) + Headers Hoge: Fuga + Body { &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot; }  これを使って、aglioでHTMLにしたり、</description>
    </item>
    
    <item>
      <title>logrotateでログをローテーションする</title>
      <link>https://www.sambaiz.net/article/33/</link>
      <pubDate>Wed, 09 Nov 2016 22:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/33/</guid>
      <description>logrusがローテーションする仕組みを持っていなかったので、 READMEに書いてあったlogrotateを使う。/etc/logrotate.dの中に設定ファイルを入れて、cronで回して使う。
FROM ubuntu:14.04 ADD logrotate /etc/logrotate.d/app RUN echo &amp;quot;/usr/sbin/logrotate /etc/logrotate.conf&amp;quot; &amp;gt; /etc/cron.daily/logrotate  設定ファイル(logrotate)はこんな感じ。
/var/log/app.log { daily rotate 4 missingok delaycompress dateext }  dailyで1日に1回、rotate 4で過去4日分残し、 missingokでファイルがなくてもエラーにせず、delaycompressで圧縮するのをローテーションした次の回にして、 dateextでローテーションしたファイルの末尾を数字ではなく日付にする。
実際に動かして確かめる。
logrotateを実行すると、/var/lib/logrotate/statusに過去に見た時間が入る。
$ echo &amp;quot;aaaaa&amp;quot; &amp;gt; /var/log/app.log $ logrotate /etc/logrotate.conf $ cat /var/lib/logrotate/status logrotate state -- version 2 ... &amp;quot;/var/log/app.log&amp;quot; 2016-11-9-11:0:0 ...  強制的にローテーションさせてみる。
$ echo &amp;quot;aaaa&amp;quot; &amp;gt; /var/log/app.log $ logrotate -f /etc/logrotate.conf $ ls /var/log | grep app app.log app.log-20161109 $ cat /var/log/app.</description>
    </item>
    
    <item>
      <title>td-agentをビルドしてfluentdのバージョンを上げる</title>
      <link>https://www.sambaiz.net/article/32/</link>
      <pubDate>Sun, 06 Nov 2016 11:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/32/</guid>
      <description>$td-agent --version td-agent 0.12.26  td-agentって書いてあるけど、これがfluentdのバージョンらしい。
fluentdはv0.14からナノ秒で時間を持つようになった。 ただ、現行のtd-agent(v2.3.2)は上の通り古いバージョンを使っている。 0.14になるtd-agent-3はまだリリースされていないので、 自分でfluentdをv0.14.8に上げてビルドすることにした。
FROM ubuntu:14.04 WORKDIR /tmp RUN apt-get update &amp;amp;&amp;amp; \ apt-get install -y git software-properties-common build-essential curl &amp;amp;&amp;amp; \ add-apt-repository -y ppa:brightbox/ruby-ng &amp;amp;&amp;amp; \ apt-get update &amp;amp;&amp;amp; \ apt-get install -y ruby2.3 ruby2.3-dev &amp;amp;&amp;amp; \ gem install bundler &amp;amp;&amp;amp; \ git clone https://github.com/treasure-data/omnibus-td-agent WORKDIR /tmp/omnibus-td-agent RUN sed -ie &amp;quot;s/^default_version.*$/default_version &#39;3d1dd53f31d1fe49508f230a71a2b4c2ceb20f47&#39;/&amp;quot; config/software/fluentd.rb &amp;amp;&amp;amp; \ sed -ie &amp;quot;s/^license_file.*$/license_file &#39;LICENSE&#39;/&amp;quot; config/projects/td-agent2.rb &amp;amp;&amp;amp; \ bundle install --binstubs &amp;amp;&amp;amp; \ bin/gem_downloader core_gems.</description>
    </item>
    
    <item>
      <title>d3.jsで折れ線グラフを書くコードを読む</title>
      <link>https://www.sambaiz.net/article/31/</link>
      <pubDate>Thu, 03 Nov 2016 00:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/31/</guid>
      <description>http://bl.ocks.org/mbostock/3883245
CSSと
&amp;lt;style&amp;gt; .axis--x path { display: none; } .line { fill: none; stroke: steelblue; stroke-width: 1.5px; } &amp;lt;/style&amp;gt;  グラフを書くsvgとd3.js。
&amp;lt;svg width=&amp;quot;960&amp;quot; height=&amp;quot;500&amp;quot;&amp;gt;&amp;lt;/svg&amp;gt; &amp;lt;script src=&amp;quot;https://d3js.org/d3.v4.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;  var svg = d3.select(&amp;quot;svg&amp;quot;), margin = {top: 20, right: 20, bottom: 30, left: 50}, width = +svg.attr(&amp;quot;width&amp;quot;) - margin.left - margin.right, height = +svg.attr(&amp;quot;height&amp;quot;) - margin.top - margin.bottom, g = svg.append(&amp;quot;g&amp;quot;).attr(&amp;quot;transform&amp;quot;, &amp;quot;translate(&amp;quot; + margin.left + &amp;quot;,&amp;quot; + margin.top + &amp;quot;)&amp;quot;);  d3.selectでsvg要素を選択。widthとheightを取得したり、中にg(グループ)を入れてtransformでmarginを作っている。
&amp;lt;svg width=&amp;quot;960&amp;quot; height=&amp;quot;500&amp;quot;&amp;gt;&amp;lt;g transform=&amp;quot;translate(50,20)&amp;quot;&amp;gt;&amp;lt;/g&amp;gt;&amp;lt;/svg&amp;gt;  svg.</description>
    </item>
    
    <item>
      <title>mp4をエンコードしてMPEG-DASHにして再生する</title>
      <link>https://www.sambaiz.net/article/30/</link>
      <pubDate>Sun, 30 Oct 2016 23:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/30/</guid>
      <description>MPEG-DASHとは HTTPで動画をストリーミングするための規格。似たようなのにAppleの独自規格であるHLSなどがある。
サーバーはMPD(Media Presentation Description)ファイルと、セグメントに分けられた動画や音声ファイルを持っていて、 クライアントはMPDファイルをリクエストし、この内容をもとにセグメントをリクエストしていく。
準備 ffmpegと MP4Boxを使うので、これらを実行できるようにする。 Docker上で実行することもできて、その場合は以下のようにエイリアスを付けると便利。
$ alias ffmpeg=&#39;docker run --rm -v `pwd`:/tmp/workdir jrottenberg/ffmpeg&#39; $ alias MP4Box=&#39;docker run --rm -v `pwd`:/work sambaiz/mp4box&#39;  エンコード $ffmpeg -i input.mp4 -vcodec libx264 -vb 448k -r 30 -x264opts no-scenecut -g 15 -acodec libfaac -ac 2 -ab 128k -frag_duration 5000000 -movflags empty_moov output.mp4  オプションの意味は多分こんな感じ。
 -vcodec libx264: 動画をH.264にエンコードする -vb 448k: 動画のビットレート(bps) -r 30: 動画のフレームレート(fps) -x264opts no-scenecut: キーフレームの間隔を動画の内容によらず固定にする -g 15: キープレームの間隔。フレームレート(-r) * フラグメントの時間(-frag_duration) / キーフレームの間隔(-g)が整数になるようにする。 -acodec libfaac: 音声をAACにエンコードする -ac 2: 音声チャンネル数2(ステレオ) -ab 128k: 音声のビットレート(bps) -frag_duration 5000000: フラグメント(セグメント)の時間(μs)。 -movflags empty_moov: 頭にmdat atom(データが含まれる)なしで、moov atom(メタ情報が含まれている)を書き始めるらしい。これにしないとMP4Boxに入れるときに失敗した。  $ MP4Box -info -v input.</description>
    </item>
    
    <item>
      <title>剣を振るVRゲームを作った</title>
      <link>https://www.sambaiz.net/article/29/</link>
      <pubDate>Sun, 30 Oct 2016 19:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/29/</guid>
      <description>プレイ動画
CardboardにAndroidを入れて、
iPhoneをくくりつけた傘を動かすと、画面の剣も動くのでこれで敵を倒すゲーム。
実装 剣(iOS) 剣にくくりつけたiPhoneの傾きの値をUnity(Android)に送信している。 iOSはClassic Bluetoothを自由に使えないので、Androidと通信する場合はBLEを使う。 BLEは通常だと20byteしか一度に送れないので、これを超えないよう注意する必要がある。
BLEで通信するところは
iOS端末をBLEのPeripheralにする
で作ったので、端末の傾きを取得して送るだけ。
import UIKit import CoreMotion class Motion{ let peripheral: BLEPeripheral let accelHandler:CMDeviceMotionHandler let manager = CMMotionManager() public init(peripheral :BLEPeripheral, label :UILabel){ self.peripheral = peripheral accelHandler = { (data: CMDeviceMotion?, error: Error?) -&amp;gt; Void in let str = String(format: &amp;quot;%.1f %.1f %.1f&amp;quot;, arguments: [data!.attitude.pitch * 180 / M_PI, data!.attitude.roll * 180 / M_PI, data!.attitude.yaw * 180 / M_PI] ) let res = peripheral.</description>
    </item>
    
    <item>
      <title>gcloudのアカウント切り替えとkubectlのcontext変更</title>
      <link>https://www.sambaiz.net/article/28/</link>
      <pubDate>Tue, 25 Oct 2016 20:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/28/</guid>
      <description> いつも迷うのでまとめた。
gcloudのアカウント一覧と切り替え $ gcloud auth list $ gcloud config set account `ACCOUNT`  kubectlのcontext変更 $ kubectl config current-context $ kubectl config view # contexts $ kubectl config use-context minikube  </description>
    </item>
    
    <item>
      <title>UnityでAndroidのBLEを使うネイティブプラグインを作る</title>
      <link>https://www.sambaiz.net/article/27/</link>
      <pubDate>Sun, 23 Oct 2016 20:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/27/</guid>
      <description>UnityからBLEを使うためのネイティブプラグインを作る。
Android側 まず、Activityなしのプロジェクトを作って、New ModuleからAndroid Libraryを選択。 これらのパッケージ名がUnityで使うものと被らないようにする。
/Applications/Unity/PlaybackEngines/AndroidPlayer/Variations/mono/Release/Classes/classes.jar をModuleの方のlibsに置く。
import com.unity3d.player.UnityPlayer;  このjarは元々のやつとかぶってしまうので除外(build.gradleに追加)
android.libraryVariants.all { variant -&amp;gt; variant.outputs.each { output -&amp;gt; output.packageLibrary.exclude(&#39;libs/classes.jar&#39;) } }  ActiviyはUnityPlayer.currentActivityで取得でき、 Unity側のメソッドを呼ぶのも UnityPlayer.UnitySendMessage(mGameObjName, mCallBackName, new String(characteristic.getValue())); のようにできる。
public class BLE { private final static String TAG = BLE.class.getSimpleName(); private static final int REQUEST_ENABLE_BT = 1; private static final int MY_PERMISSION_RESPONSE = 2; private static final String PERIPHERAL_LOCAL_NAME = &amp;quot;my-ble&amp;quot;; private static final UUID PERIPHERAL_SERIVCE_UUID = UUID.</description>
    </item>
    
    <item>
      <title>iOS端末をBLEのPeripheralにする</title>
      <link>https://www.sambaiz.net/article/26/</link>
      <pubDate>Sun, 23 Oct 2016 01:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/26/</guid>
      <description>CoreBluetoothプログラミングガイド
流れ まず、CoreBluetooth.frameworkを追加する。
import CoreBluetooth  CBPeripheralManagerを生成。
peripheralManager = CBPeripheralManager(delegate: self, queue: nil)  stateが変化したらdelegateメソッドが呼ばれるので.poweredOnであることを確認できれば Managerの準備は完了。
public func peripheralManagerDidUpdateState(_ peripheral: CBPeripheralManager){ switch (peripheral.state){ case .poweredOn: print(&amp;quot;PeripheralManager state is ok&amp;quot;) ready = true default: print(&amp;quot;PeripheralManager state is ng:&amp;quot;, peripheral.state) ready = false } }  Characteristicを作成。CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify)で、 Centralが読みにくることも、通知を受け取ることもできるようにし、CBAttributePermissions.readableでreadのみ許可する。 このvalueをnilにしておかないと、キャッシュされあとで変更できなくなる。
characteristic = CBMutableCharacteristic( type: CHARACTERISTIC_UUID, properties: CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify), value:nil, permissions:CBAttributePermissions.readable)  このCharacteristicのServiceを作成し、Managerに登録する。
let service = CBMutableService(type: SERVICE_UUID, primary: true) service.characteristics = [characteristic] peripheralManager!.add(service) ready = true  public func peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?</description>
    </item>
    
    <item>
      <title>android-BluetoothLeGattを読む</title>
      <link>https://www.sambaiz.net/article/25/</link>
      <pubDate>Fri, 21 Oct 2016 14:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/25/</guid>
      <description>BLEのサンプルコード。
https://github.com/googlesamples/android-BluetoothLeGatt
DeviceScanActivity BLEをサポートしているかチェックする。 BluetoothChatではBluetoothAdapterを取得するのに BluetoothAdapter.getDefaultAdapter()のようにしていたが、 BLEをサポートしているような新しいバージョンでは、BluetoothManagerのgetAdapter()を使うらしい。
@Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); getActionBar().setTitle(R.string.title_devices); mHandler = new Handler(); // Use this check to determine whether BLE is supported on the device. Then you can // selectively disable BLE-related features. if (!getPackageManager().hasSystemFeature(PackageManager.FEATURE_BLUETOOTH_LE)) { Toast.makeText(this, R.string.ble_not_supported, Toast.LENGTH_SHORT).show(); finish(); } // Initializes a Bluetooth adapter. For API level 18 and above, get a reference to // BluetoothAdapter through BluetoothManager. final BluetoothManager bluetoothManager = (BluetoothManager) getSystemService(Context.</description>
    </item>
    
    <item>
      <title>PackerでAMIを作る</title>
      <link>https://www.sambaiz.net/article/24/</link>
      <pubDate>Tue, 18 Oct 2016 22:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/24/</guid>
      <description>https://www.packer.io/
いろんなプラットフォームのイメージを作ることができるツール。 これでfluentdのログサーバーのAMIを作る。
$ brew install packer # mac $ packer -v 0.10.1  設定ファイルはこんな感じ。variablesの値は{{user ... }}のところで使われる。 buildersに作るイメージの情報を書いて、provisionersで環境を作る。
provisionersにはchefやansibleなども指定できるが、 継ぎ足し継ぎ足しで秘伝のタレ化したAMIも最初は、
「コマンドいくつか実行するだけなのでとりあえず手作業で作った、後でなんとかする」
なんてものもあったりして、 そういうものは無理にchefなどで始めず、手軽にshellでpacker buildするといいと思う。 手作業よりも楽だし、ソースが別にあるので使われていないAMIを消すのも簡単だ。
fileではpermissionがないところに置くことができないので、一旦置いてshellで移動する。
{ &amp;quot;variables&amp;quot;: { &amp;quot;aws_access_key&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;aws_secret_key&amp;quot;: &amp;quot;&amp;quot; }, &amp;quot;builders&amp;quot;: [{ &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;, &amp;quot;access_key&amp;quot;: &amp;quot;{{user `aws_access_key`}}&amp;quot;, &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `aws_secret_key`}}&amp;quot;, &amp;quot;region&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;, &amp;quot;source_ami&amp;quot;: &amp;quot;ami-1a15c77b&amp;quot;, &amp;quot;instance_type&amp;quot;: &amp;quot;t2.small&amp;quot;, &amp;quot;ssh_username&amp;quot;: &amp;quot;ec2-user&amp;quot;, &amp;quot;ami_name&amp;quot;: &amp;quot;fluentd-logserver {{timestamp}}&amp;quot; }], &amp;quot;provisioners&amp;quot;: [{ &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;, &amp;quot;source&amp;quot;: &amp;quot;td-agent.conf&amp;quot;, &amp;quot;destination&amp;quot;: &amp;quot;/home/ec2-user/td-agent.conf&amp;quot; }, { &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;, &amp;quot;inline&amp;quot;: [ &amp;quot;curl -L https://toolbelt.</description>
    </item>
    
    <item>
      <title>android-bluetoothChatを読む</title>
      <link>https://www.sambaiz.net/article/23/</link>
      <pubDate>Sat, 15 Oct 2016 14:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/23/</guid>
      <description>Classic Bluetoothのサンプルコード。
https://github.com/googlesamples/android-BluetoothChat
MainActivity まず、MainActivity。
Fragmentのcommitや、
@Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); if (savedInstanceState == null) { FragmentTransaction transaction = getSupportFragmentManager().beginTransaction(); BluetoothChatFragment fragment = new BluetoothChatFragment(); transaction.replace(R.id.sample_content_fragment, fragment); transaction.commit(); } }  オプションメニューの設定をしている。
// 最初だけ呼ばれる @Override public boolean onCreateOptionsMenu(Menu menu) { getMenuInflater().inflate(R.menu.main, menu); return true; } // 表示される度に呼ばれる @Override public boolean onPrepareOptionsMenu(Menu menu) { MenuItem logToggle = menu.findItem(R.id.menu_toggle_log); logToggle.setVisible(findViewById(R.id.sample_output) instanceof ViewAnimator); logToggle.setTitle(mLogShown ? R.string.sample_hide_log : R.string.sample_show_log); return super.</description>
    </item>
    
    <item>
      <title>静的ウェブサイトエンジンHugoに乗り換えた</title>
      <link>https://www.sambaiz.net/article/22/</link>
      <pubDate>Tue, 04 Oct 2016 22:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/22/</guid>
      <description>https://gohugo.io/
今までこのサイトはフロントのReactからLambda &amp;amp; API Gatewayで作った記事APIを呼ぶ構成になっていた。
ホームページ作った
当初はページの描画をフロントに任せることで、 サーバーレス (記事の情報をjsonで渡すAPI Gatewayと、S3の組み合わせ) で作れると思っていたが、結果そんなに甘くはなく、サーバーサイドレンダリングするはめになる。 最初からレンダリングしたものを置いておけばいいと思った。
webpack環境でredux&amp;amp;react-routerのページをサーバーサイドレンダリングする
そんなこんなでHugoに乗り換えることにした。 記事はmarkdownで管理していたので、これにメタ情報を加えるだけで移行できた。 タグで絞り込むこともできるようになったので良いと思う。 また、静的なページになったのでgithub pagesに置けるようにもなった。</description>
    </item>
    
    <item>
      <title>DeepDreaming with TensorFlowをやる(2)</title>
      <link>https://www.sambaiz.net/article/21/</link>
      <pubDate>Sat, 10 Sep 2016 14:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/21/</guid>
      <description>前回の続き。
Multiscale image generation 様々なスケールで勾配上昇させる。小さなスケールで上昇させたものをより大きなスケールでさらに上昇させていく。 ただ、壁紙のようなサイズを生成するような場合にそれを行うと、GPUのメモリを食いつぶしてしまう。 これを避けるために、画像を小さなタイルに分割し、それぞれ独立に勾配を計算する。 また、毎回画像をランダムにシフトしていくことで、タイルに見えることを避け、画像全体の品質を向上させる。
def tffunc(*argtypes): &#39;&#39;&#39;Helper that transforms TF-graph generating function into a regular one. See &amp;quot;resize&amp;quot; function below. &#39;&#39;&#39; placeholders = list(map(tf.placeholder, argtypes)) def wrap(f): out = f(*placeholders) def wrapper(*args, **kw): return out.eval(dict(zip(placeholders, args)), session=kw.get(&#39;session&#39;)) return wrapper return wrap # Helper function that uses TF to resize an image def resize(img, size): img = tf.expand_dims(img, 0) return tf.image.resize_bilinear(img, size)[0,:,:,:] resize = tffunc(np.float32, np.int32)(resize) def calc_grad_tiled(img, t_grad, tile_size=512): &#39;&#39;&#39;Compute the value of tensor t_grad over the image in a tiled way.</description>
    </item>
    
    <item>
      <title>DeepDreaming with Tensorflowをやる(1)</title>
      <link>https://www.sambaiz.net/article/20/</link>
      <pubDate>Wed, 07 Sep 2016 01:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/20/</guid>
      <description>https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb
例の通りまとめながら進めていく。
このノートブックは、畳み込みニューラルネットワークによる画像生成の手法を説明するものだ。 ネットワークは入力画像へ変換させる配列のレイヤーの集合から成り立っている。 変換のパラメータは勾配降下法で変形しながら学習していく。 内部的な画像の表現は意味不明なように見えるが、可視化し、解釈することができる。
Loading and displaying the model graph 学習済みネットワークのprotobufファイルが用意されていて、これをダウンロードして使う。 ただgcr.io/tensorflow/tensorflowにwgetもunzipも入っていなかったので、中に入ってapt-getした。
model_fn = &#39;tensorflow_inception_graph.pb&#39; # creating TensorFlow session and loading the model graph = tf.Graph() sess = tf.InteractiveSession(graph=graph) with tf.gfile.FastGFile(model_fn, &#39;rb&#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) t_input = tf.placeholder(np.float32, name=&#39;input&#39;) # define the input tensor imagenet_mean = 117.0 t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0) tf.import_graph_def(graph_def, {&#39;input&#39;:t_preprocessed})  tf.gfile.FastGFileのドキュメントが見つからないので ソース を探したところFile I/Oのラッパーのようだ。これでprotobufファイルを読み、ParseFromStringでGraphDefにする。
さらにこれと入力データをtf.import_graph_defに 渡すことでGraphに取り込む。
tf.expand_dimsは値が1の次元を指定の場所に挿入する もの。なんでそんなことをしたり、imagenet_meanを引いているのかは説明がなかった。
layers = [op.</description>
    </item>
    
    <item>
      <title>Grafana/InfluxDB/Fluentdでログを可視化する</title>
      <link>https://www.sambaiz.net/article/19/</link>
      <pubDate>Wed, 31 Aug 2016 20:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/19/</guid>
      <description>コードはここ。
InfluxDB Golangで書かれた時系列データベース。今回使うのはv0.13。前のバージョンと結構違うので注意。
デフォルトでは無効になっている認証を有効にするために設定ファイルを編集して設置する。
$ brew install influxdb # OSX $ influxd config &amp;gt; influxdb.conf  [http] ... auth-enabled = true ...  FROM influxdb:0.13 VOLUME /var/lib/influxdb ADD influxdb.conf / ENV INFLUXDB_CONFIG_PATH /influxdb.conf  $ docker run -p 8083:8083 -p 8086:8086 myinfluxdb  influxdコマンドや :8083のWebインタフェースの他に :8086にHTTP APIが用意されている。
$ curl -i -XPOST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE USER root WITH PASSWORD &#39;root&#39; WITH ALL PRIVILEGES&amp;quot; $ curl -i -XPOST http://localhost:8086/query -u root:root --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot; {&amp;quot;results&amp;quot;:[{}]} # Line Protocol(https://docs.</description>
    </item>
    
    <item>
      <title>GKEで複数コンテナのアプリケーションを動かす</title>
      <link>https://www.sambaiz.net/article/18/</link>
      <pubDate>Fri, 26 Aug 2016 21:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/18/</guid>
      <description>前回は単一コンテナのアプリケーションを動かしたが、今回はコンテナ間でやり取りが発生するものを動かす。 流れとしては、クライアントからのリクエストをGATEWAYサーバーで受け取り、SERVICEサーバーにリクエストし、その結果を返すまで。
プログラムは以下の通り、環境変数TYPEの値によって挙動を変えていて、同じイメージを使い回す。コードはここ。
var http = require(&#39;http&#39;); var handleRequest = function(request, response) { if(process.env.TYPE == &amp;quot;GATEWAY&amp;quot;){ console.log(&#39;Passed.&#39;); var options = { host: &#39;service&#39;, port: 8080, method: &#39;GET&#39; }; var req = http.request(options, function(res) { data = &amp;quot;&amp;quot; res.on(&#39;data&#39;, function (chunk) { data+=chunk; }); res.on(&#39;end&#39;, () =&amp;gt; { response.writeHead(200); response.end(data); }); }); req.on(&#39;error&#39;, function(e) { response.writeHead(500) response.end(e.message); }); req.end(); }else{ console.log(&#39;Received.&#39;); response.writeHead(200); response.end(&#39;ok&#39;); } }; var www = http.createServer(handleRequest); www.listen(8080);  これをContainer RegistryにPushする。</description>
    </item>
    
    <item>
      <title>Google Container Engine(GKE)で単一コンテナのアプリケーションを動かす</title>
      <link>https://www.sambaiz.net/article/17/</link>
      <pubDate>Sun, 21 Aug 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/17/</guid>
      <description>Kubernetes - Hello World Walkthrough
CloudSDKとkubectlのインストール Cloud SDKをインストールしてgloudコマンドを使えるようにする。
$ gcloud --version Google Cloud SDK 122.0.0 $ gcloud components install kubectl  Google Container RegistryにPush $ export PROJECT_ID=&amp;quot;******&amp;quot; $ docker build -t gcr.io/$PROJECT_ID/test:v1 . $ gcloud docker push gcr.io/$PROJECT_ID/test:v1  プロジェクトの課金を有効にしていないとこんなエラーメッセージが出る。
denied: Unable to create the repository, please check that you have access to do so.  Clusterの作成 $ gcloud config set core/project $PROJECT_ID $ gcloud config set compute/zone asia-east1-b $ gcloud container clusters create test-cluster $ gcloud config set container/cluster test-cluster  Container Engine APIが有効になっていない場合はこうなる。 一度コンソールからContainer Engineを選ぶと、サービスの準備が始まって有効になる。</description>
    </item>
    
    <item>
      <title>JenkinsのMultiple SCMs PluginからPipeline Pluginへの移行</title>
      <link>https://www.sambaiz.net/article/16/</link>
      <pubDate>Sat, 20 Aug 2016 16:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/16/</guid>
      <description>Jenkins環境を作り直すことになり、 長らく使ってきたMultiple SCMs PluginがDeprecatedなので、 Pipeline Pluginに移行することにした。
プラグインをインストールすると、ジョブ作成時にPipelineを選択できるようになる。 Pipeline scriptの複数リポジトリを指定するところはこんな感じ。
node { stage &#39;Checkout rep1&#39; git([url: &#39;git@rep1.git&#39;, branch: REP1_BRANCH]) stage &#39;Checkout rep2&#39; dir(&#39;rep2&#39;) { git([url: &#39;git@rep2.git&#39;, branch: REP2_BRANCH]) } stage &#39;Checkout rep3&#39; dir(&#39;subdir3/rep3&#39;) { git([url: &#39;git@rep3.git&#39;, branch: REP3_BRANCH]) } stage &#39;Build&#39; ... }  まとめて入ったPipeline Stage View Pluginによって、 経過や変更などいろいろ見やすくなった。</description>
    </item>
    
    <item>
      <title>GolangでAPIとテストを書く(echo/dbr/glide/goose/mock)</title>
      <link>https://www.sambaiz.net/article/15/</link>
      <pubDate>Mon, 15 Aug 2016 04:07:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/15/</guid>
      <description>久々にGolangを書くことになったので、以下の記事を参考にして簡単なAPIとそのテストを書いてみた。 コードはここ。
Go言語でTestableなWebアプリケーションを目指して｜サイバーエージェント 公式エンジニアブログ
使った主なライブラリ・ツール echo webフレームワーク。速いらしい。
$ go get -u github.com/labstack/echo  func main() { conn, err := dbr.Open(&amp;quot;mysql&amp;quot;, &amp;quot;root:@tcp(localhost:3306)/mboard&amp;quot;, nil) if err != nil { panic(err) } conn.SetMaxIdleConns(200) conn.SetMaxOpenConns(200) e := echo.New() // middlewares e.Use(middleware.Logger()) e.Use(middleware.Recover()) e.Use(middleware.CORSWithConfig(middleware.CORSConfig{ AllowOrigins: []string{&amp;quot;*&amp;quot;}, AllowMethods: []string{echo.GET, echo.PUT, echo.POST, echo.DELETE}, })) // endpoints e.GET(&amp;quot;/&amp;quot;, func(c echo.Context) error { return c.String(http.StatusOK, &amp;quot;Hello, World!&amp;quot;) }) e.GET(&amp;quot;/messages&amp;quot;, func(c echo.Context) error { return handler.NewMessageWithSession(conn.NewSession(nil)).GetMessages(c) }) e.POST(&amp;quot;/messages&amp;quot;, func(c echo.</description>
    </item>
    
    <item>
      <title>O&#39;Reillyの「マイクロサービスアーキテクチャ」を読んだ</title>
      <link>https://www.sambaiz.net/article/14/</link>
      <pubDate>Sat, 06 Aug 2016 18:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/14/</guid>
      <description>O&amp;rsquo;Reilly Japan - マイクロサービスアーキテクチャ
設計、開発、テストや監視など一通りまとまっているマイクロサービスアーキテクチャの本。
マイクロサービスアーキテクチャというのは、協調して動作する小規模で自律的なサービスでシステムを構成するもので、 一般的なモノリシック(一枚岩)システムのモジュールのように独立したサービスを作っていく。 自律的というのは、他には何も変更せずに、単独でサービスの変更やデプロイを行えるということ。
メリットとしては
 サービスごとに異なる技術を使うことができる 一部のサービスで障害が発生しても、機能低下させて稼働し続けるシステムを構築できる 性能を高める必要があるサービスだけをスケールでき、効率的にリソースを使うことができる デプロイのリスクを最小限に抑えることができるため、迅速に行うことができる レガシーなコードを捨て去る障壁が低い  などが挙げられていた。
正しくサービスを切り分けるにはドメインの理解が必要で、「境界づけられたコンテキスト」が1つのサービスとなるようにする。 そのため、最初はモノシリックに進めることも推奨されていた。
 特に初めてのドメインでは、システムをマイクロサービスに分解するのが時期尚早だとコストがかかってしまう場合があります。いろいろな意味で、マイクロサービスに分解したい既存のコードベースがある方が、最初からマイクロサービスに取り組むよりもはるかに簡単です (3.3.3)
 実現する上で、DBの扱いが難しいと思った。 サービス間のDBの共有はスキーマの変更に弱く、技術の縛りが発生してしまうので避けなければならない。 一方で、DBを分割すると1つのトランザクションで完結しなくなり、どのように整合性を保っていくか。 そんな話が5章に書いてあって、いくつか方法は挙げられているが、いずれにせよ何かしらの制御をしなくてはいけないし、 データの取得の上でも一つのデータベースにあったほうが便利だったりする。 サービスの単位がデータに引きずられてしまうと、マイクロサービスとはいえないものが出来上がりそうだ。 きれいに分けられればいいけど実際どうなんだろう。
すぐにマイクロサービスを採用するかは別としても、考え方として活かせそうなことが多かった。 実際にやってみて、また読み返して自分のものにしていこうと思う。</description>
    </item>
    
    <item>
      <title>Tensorflowの学習データを使ったAPIを作る</title>
      <link>https://www.sambaiz.net/article/13/</link>
      <pubDate>Fri, 05 Aug 2016 22:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/13/</guid>
      <description>チュートリアルのMNISTの学習データを使って、手書き数字画像のデータを受け取り、数字を返すAPIを作る。 コードはここにある。
学習して結果を保存する 前回の学習結果のチェックポイントファイルを出力する。 tf.train.Saver().saveでnameで対応するVariableの値が保存できる。
今回は、学習側、アプリケーション側共にPythonを使うので、以下のようなクラスを作った。
import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data class Mnist: def __init__(self): g = tf.Graph() with g.as_default(): W_conv1 = self._weight_variable([5, 5, 1, 32], &amp;quot;W_conv1&amp;quot;) b_conv1 = self._bias_variable([32], &amp;quot;b_conv1&amp;quot;) self._x = tf.placeholder(tf.float32, [None, 784]) x_image = tf.reshape(self._x, [-1,28,28,1]) h_conv1 = tf.nn.relu(self._conv2d(x_image, W_conv1) + b_conv1) h_pool1 = self._max_pool_2x2(h_conv1) W_conv2 = self._weight_variable([5, 5, 32, 64], &amp;quot;W_conv2&amp;quot;) b_conv2 = self._bias_variable([64], &amp;quot;b_conv2&amp;quot;) h_conv2 = tf.nn.relu(self._conv2d(h_pool1, W_conv2) + b_conv2) h_pool2 = self.</description>
    </item>
    
    <item>
      <title>Googleが作ったRPCフレームワークgRPCを使ってみた</title>
      <link>https://www.sambaiz.net/article/12/</link>
      <pubDate>Fri, 29 Jul 2016 22:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/12/</guid>
      <description>A high performance, open source, general RPC framework that puts mobile and HTTP/2 first.
 What is gRPC? gRPCを使うと、クライアントアプリケーションは直接、ローカルのオブジェクトのように、他のマシンのサーバーアプリケーションのメソッドを呼ぶことができ、 分散したアプリケーションやサービスを簡単に作ることができる。 多くのRPCシステムと同様に、gRPCはサービスを定義し、リモートから呼べるメソッドと、そのパラメーターおよび返り値の型を記述するようになっている。 サーバーサイドではインタフェースを実装し、クライアントからの呼び出しをハンドリングするgRPCサーバーを実行する。 クライアントサイドでは、サーバーと同じメソッドを提供するスタブを持っている。
gRPCクライアントとサーバーは様々な環境同士でやり取りすることができ、いくつもの言語でサポートされている。 そのため、例えば、gRPCサーバーをJavaで、クライアントをGoやPython、Rubyで作るのも簡単だ。 加えて、最新のGoodle APIにはgRPCのインタフェースが存在するので、これらをアプリケーションに組み込むのも容易にできる。
Protobuf デフォルトではgRPCはprotobuf(protocol buffers)を使う。 protobufというのは、 Googleによるオープンソースの、構造化されたデータをシリアライズするメカニズムだ。
今回作るのは、同じ文字列を返すだけのEchoサーバーで、コードはここにある。 以下のprotoファイルでは、EchoというサービスはRetEchoというメソッドを含み、 これは文字列sayを含むEchoRequestに対して、文字列retを含むEchoReplyを返すということを表している。
syntax = &amp;quot;proto3&amp;quot;; option java_package = &amp;quot;net.sambaiz.trygrpc.protos&amp;quot;; package protos; service Echo { rpc RetEcho (EchoRequest) returns (EchoReply) {} } message EchoRequest { string say = 1; } message EchoReply { string ret = 1; }  これをprotocでコンパイルするとecho.</description>
    </item>
    
    <item>
      <title>MySQLで大文字小文字を区別しないのを直す</title>
      <link>https://www.sambaiz.net/article/11/</link>
      <pubDate>Sun, 24 Jul 2016 22:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/11/</guid>
      <description>Collationの話。
MySQL 5.6  CREATE TABLE sample ( id SERIAL, name VARCHAR(30) ) ENGINE=InnoDB CHARACTER SET utf8mb4; INSERT INTO sample (name) VALUES (&#39;tom&#39;),(&#39;Tom&#39;),(&#39;TOM&#39;);  このテーブルを&amp;rdquo;tom&amp;rdquo;で絞り込むとこうなる。大文字小文字を区別していない。
mysql&amp;gt; SELECT * FROM sample2 WHERE name = &#39;tom&#39;; +----+------+ | id | name | +----+------+ | 1 | tom | | 2 | Tom | | 3 | TOM | +----+------+ 3 rows in set (0.01 sec)  MySQL :: MySQL 5.6 リファレンスマニュアル :: B.</description>
    </item>
    
    <item>
      <title>グラフデータベースNeo4jを触ってみた</title>
      <link>https://www.sambaiz.net/article/10/</link>
      <pubDate>Thu, 21 Jul 2016 09:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/10/</guid>
      <description>社内勉強会でオープンソースの グラフデータベースNeo4jが紹介されていたので触ってみた。
What is a Graph Database? つながりも含めたグラフとしてデータを扱うデータベース。 データセットのサイズによらず、複雑なつながりや、クエリをうまく扱える。 無数のデータの中から、関係ないデータを見ることなく多数のノードとつながりからなる必要なデータだけを取れる。
インストール ここからCommunity Editionを選んで OSごとに用意されている実行ファイルをダウンロードしてくる。 ファイルを実行し、Startを押すとブラウザで開けるようになる。
グラフ グラフは以下の要素から構成される。
 Node: データそのもので、まとめるためのラベルを複数付けられる Relationships: typeを持つ、Nodeのつながり Properties: NodeやRelationshipsが持てるkey-valueの値  Cypher Neo4jで使うクエリ言語。
まずはCREATE文でNodeを作る。Personはラベルだ。
CREATE (ee:Person { name: &amp;quot;Emil&amp;quot;, from: &amp;quot;Sweden&amp;quot;, klout: 99 })  CREATE文では使われていなかった謎のeeだが、MATCH文を見るとデータが格納される変数だということがわかる。 このeeは次のCREATE文でも参照できて、(ee)-[:KNOWS {since: 2001}]-&amp;gt;(js)で 作ったNodeとのRelationshipsを張るのに使っている。
MATCH (ee:Person) WHERE ee.name = &amp;quot;Emil&amp;quot; RETURN ee; CREATE (js:Person { name: &amp;quot;Johan&amp;quot;, from: &amp;quot;Sweden&amp;quot;, learn: &amp;quot;surfing&amp;quot; }), (ir:Person { name: &amp;quot;Ian&amp;quot;, from: &amp;quot;England&amp;quot;, title: &amp;quot;author&amp;quot; }), (rvb:Person { name: &amp;quot;Rik&amp;quot;, from: &amp;quot;Belgium&amp;quot;, pet: &amp;quot;Orval&amp;quot; }), (ally:Person { name: &amp;quot;Allison&amp;quot;, from: &amp;quot;California&amp;quot;, hobby: &amp;quot;surfing&amp;quot; }), (ee)-[:KNOWS {since: 2001}]-&amp;gt;(js),(ee)-[:KNOWS {rating: 5}]-&amp;gt;(ir), (js)-[:KNOWS]-&amp;gt;(ir),(js)-[:KNOWS]-&amp;gt;(rvb), (ir)-[:KNOWS]-&amp;gt;(js),(ir)-[:KNOWS]-&amp;gt;(ally), (rvb)-[:KNOWS]-&amp;gt;(ally)  以下のようにパターンマッチもできる。この例だとEmilの友達が取得できる。</description>
    </item>
    
    <item>
      <title>Kubernetesのチュートリアルをたどる</title>
      <link>https://www.sambaiz.net/article/9/</link>
      <pubDate>Mon, 18 Jul 2016 22:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/9/</guid>
      <description>Kubernetesとは Kubernetes(発音はkoo-ber-nay&amp;rsquo;-tace。 ギリシャ語で操舵手。)はアプリケーションコンテナにおける、自動デプロイ、スケーリング、操作を 自動化するオープンソースプラットフォームだ。K8sと略される。Googleによって開発が始められた。
Minikube K8sをローカルで試すためのに、MinikubeというVMの中で単一ノードのK8sクラスターを動かすツールを入れる。
v0.6.0
curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.6.0/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/  $ minikube start Starting local Kubernetes cluster... ... $ kubectl version Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;2&amp;quot;, GitVersion:&amp;quot;v1.2.4&amp;quot;, GitCommit:&amp;quot;3eed1e3be6848b877ff80a93da3785d9034d0a4f&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;3&amp;quot;, GitVersion:&amp;quot;v1.3.0&amp;quot;, GitCommit:&amp;quot;283137936a498aed572ee22af6774b6fb6e9fd94&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}  Pods K8sではコンテナのグループをpodと呼ぶ。pod中のコンテナは共にデプロイされ、起動し、停止する。 また、グループとして複製される。
Podの定義は以下のようにyamlで書かれる。
apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80  Podの定義に望ましい状態を記述すると、Kubernatesはそれを見て現在の状態が一致しているかどうか確認する。 例えば、Podが作られたときに、コンテナがその中で動いている状態が望ましい状態だとすると、 コンテナが動かなくなったときに、Kubernatesは新しいものを再作成することで望ましい状態にする。</description>
    </item>
    
    <item>
      <title>Node.jsのバージョン管理</title>
      <link>https://www.sambaiz.net/article/8/</link>
      <pubDate>Fri, 15 Jul 2016 19:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/8/</guid>
      <description>n nodeが必要だけど手軽。
n latest, n stable, n ltsでバージョンが切り替わる。 バージョンを指定する場合、n &amp;lt;version&amp;gt;でインストールし、nでインストールされているバージョンの一覧から選択できる。 バージョンの削除はn - &amp;lt;version&amp;gt;。
$ npm install -g n $ n stable $ node -v v6.2.2  nvm nodeが必要ない。
$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.1/install.sh | bash $ nvm install node $ node -v v7.7.2 $ nvm install 6 $ node -v v6.10.0 $ nvm ls v6.10.0 -&amp;gt; v7.7.2 default -&amp;gt; node (-&amp;gt; v7.7.2) node -&amp;gt; stable (-&amp;gt; v7.7.2) (default) stable -&amp;gt; 7.</description>
    </item>
    
    <item>
      <title>Docker公式ドキュメント&#34;network コマンドを使う&#34;を読む</title>
      <link>https://www.sambaiz.net/article/7/</link>
      <pubDate>Fri, 15 Jul 2016 00:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/7/</guid>
      <description>Docker version 1.12.0-rc2  公式ドキュメントnetwork コマンドを使う の内容をまとめてみた。
dockerには3つのデフォルトネットワークが存在する。docker run時に--netオプションでネットワークを指定しない限り、 docker0として表示されるbridgeネットワークにコンテナを接続する。
$ docker network ls NETWORK ID NAME DRIVER SCOPE a3b712537566 bridge bridge local f6d86cb54edd host host local 33cb30b024d9 none null local  ただし、後方互換性を維持するため、デフォルトのbridgeネットワークでは自動的に名前解決が行われない。
これらのネットワークとは別にユーザー定義のネットワークを作成することもできる。 単一ホストのbridgeネットワークと、複数ホストにまたがるoverlayネットワークから選択でき、 何も指定しなかったらbridgeになる。subnetを指定しなければ、 dockerデーモンがネットワークに対してサブネットを自動的に割り当てるが、 dockerが管理していないサブネットと重複するのを避けるために指定することが推奨されている。
$ docker network create -d bridge --subnet 172.25.0.0/16 isolated_nw $ docker network inspect isolated_nw $ docker network rm isolated_nw # 削除  docker network inspectで以下のようなネットワークの情報が得られる。
[ { &amp;quot;Name&amp;quot;: &amp;quot;isolated_nw&amp;quot;, &amp;quot;Id&amp;quot;: &amp;quot;c81547cf7ed897054ea645192c6c47dcf7a248e77bc8067609becab5330e417d&amp;quot;, &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;, &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;, &amp;quot;EnableIPv6&amp;quot;: false, &amp;quot;IPAM&amp;quot;: { &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;Options&amp;quot;: {}, &amp;quot;Config&amp;quot;: [ { &amp;quot;Subnet&amp;quot;: &amp;quot;172.</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアル2(Deep MNIST for Experts)</title>
      <link>https://www.sambaiz.net/article/6/</link>
      <pubDate>Tue, 12 Jul 2016 21:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/6/</guid>
      <description>前回に引き続き、まとめながら進めていく。
Deep MNIST for Experts
Start TensorFlow InteractiveSession 今回は、前回のようにグラフを作成してからSessionを開始する代わりに InteractiveSessionを使う。 グラフを作成し実行するのをインタラクティブに行うことができ、IPythonのような環境で便利だ。
import tensorflow as tf sess = tf.InteractiveSession()  Build a Multilayer Convolutional Network 前回のシンプルなモデルでは、あまり良い結果が出なかった。 そこで、今回はもう少し洗練されたモデル、小さな畳み込みニューラルネットワークを作成する。
Weight Initialization このモデルを作成するためには、たくさんの重みとバイアスを作成する必要がある。
重みは、対称性を破り、勾配0を避けるために、少しのノイズで初期化すべきだ。
また、ReLU(Rectified Linear Unit, 正規化線形関数)ニューロンを使うので、&amp;rdquo;死んだニューロン&amp;rdquo;を避けるためにわずかな正の値のバイアスで初期化すると良い。
tf.truncated_normalは正規分布で、μ±2σ範囲内のランダムな値を返す。 以下の例だと、meanのデフォルトが0.0なので、正規分布 N(0, 0.01)の、-0.2&amp;lt;=x&amp;lt;=0.2な値がランダムに返ることになる。
def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)  Convolution and Pooling TensorFlowは柔軟な畳み込みとプーリングの手続きを提供している。
畳み込みというのは、画像に対してフィルターを少しずつ動かしながら掛けていく処理のことだ。このページが分かりやすい。 例えば、ソーベルフィルタで輪郭になっているところを抽出するように、 フィルターの値によって、その区域における、ある特徴を際立たせたりすることができる。 今回はこのフィルターが重みとなり、際立たせたいのはその数字を識別するための特徴ということになる。 前回は画像を一次元の配列として扱い重みを学習していたので、縦の情報が失われていたが、この方法ではそれがない。
プーリングというのは画像から区域ごとにサンプリングする処理だ。最大プーリングや、平均プーリングなどの手法がある。 畳み込みのように順番に区域を見ていって、最大プーリングならそのうちの最大のものを採用し、他のものは無視する。 サイズが小さくなるだけではなく、ちょっとした位置のずれを吸収することができる。
def conv2d(x, W): return tf.</description>
    </item>
    
    <item>
      <title>webpack環境でredux&amp;react-routerのページをサーバーサイドレンダリングする</title>
      <link>https://www.sambaiz.net/article/5/</link>
      <pubDate>Sun, 10 Jul 2016 03:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/5/</guid>
      <description>このページをGoogleのSearch Consoleからクローラーがちゃんと見ているか確認してみたら、 なぜか真っ白のページが表示されていた・・・。とりあえずサーバーサイドレンダリングしてみることにした。 コードはgithubに上げてある。
サーバーサイドとはいえ、css-loaderでcss moduleを使っているのでwebpackを使う必要があった。 まず、そのままのwebpackの設定で作ったものをserver.jsから呼ぶとエラーが出た。
***/sambaiz-net/web/public/bundle.js:20933 module.exports = self.fetch.bind(self); ReferenceError: self is not defined  そこで、targetをnodeにしたサーバーサイド用にwebpackの設定を作成し、実行してみたところ
module.exports = { entry: &#39;./js/server.js&#39;, target: &#39;node&#39;, output: { path: path.join(__dirname, &#39;dist&#39;), filename: &#39;server.js&#39;, publicPath: &#39;/&#39; },  今度はこんなエラーが出たので
ERROR in ./~/iconv-lite/encodings/tables/gb18030-ranges.json Module parse failed: ***/sambaiz-net/web/node_modules/iconv-lite/encodings/tables/gb18030-ranges.json Unexpected token (1:9) You may need an appropriate loader to handle this file type.  loadersに下の設定を追加した。
{ test: /\.json$/, loader: &amp;quot;json-loader&amp;quot;}  webpackには成功したが、serverを起動すると今度は以下のようなエラーが出た。
return /msie [6-9]\b/.test(window.navigator.userAgent.toLowerCase()); ReferenceError: window is not defined  style-loaderのコードだったので、 まず、フロント側のwebpackで extract-text-webpack-pluginを使ってcssを別に出力することにした。</description>
    </item>
    
    <item>
      <title>MySQLのUNIX_TIMESTAMPにある程度未来の日付を渡すと0になる</title>
      <link>https://www.sambaiz.net/article/4/</link>
      <pubDate>Mon, 04 Jul 2016 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/4/</guid>
      <description>以下、MySQL5.6で遭遇した。
MySQLのUNIX_TIMESTAMPは DATETIME文字列などを引数にとり、UNIXタイムスタンプ(1970-01-01 00:00:00 UTCを起点とした経過秒数)を返す関数だ。
mysql&amp;gt; SET SESSION time_zone = &#39;UTC&#39;; mysql&amp;gt; select UNIX_TIMESTAMP(&#39;1970-01-01 00:00:00&#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&#39;1970-01-01 00:00:00&#39;) | +---------------------------------------+ | 0 | +---------------------------------------+ 1 row in set (0.00 sec)  ただし、2038年1月19日3時14分7秒(UTC)以降を渡すと0になってしまう。 これはドキュメントにも書いてある通り範囲外だから。
mysql&amp;gt; select UNIX_TIMESTAMP(&#39;2038-01-19-03-14-07&#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&#39;2038-01-19-03-14-07&#39;) | +---------------------------------------+ | 2147483647 | +---------------------------------------+ 1 row in set (0.04 sec) mysql&amp;gt; select UNIX_TIMESTAMP(&#39;2038-01-19-03-14-08&#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&#39;2038-01-19-03-14-08&#39;) | +---------------------------------------+ | 0 | +---------------------------------------+ 1 row in set (0.00 sec)  では、この境目は何かというと、32ビットで表せる符号付数値の最大値だ。</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアルまで</title>
      <link>https://www.sambaiz.net/article/3/</link>
      <pubDate>Sun, 03 Jul 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/3/</guid>
      <description>Googleが公開した人工知能ライブラリTensorFlowを使ってみる。 セットアップ方法はいくつか提供されているが、Dockerで動かすことにした。 Jupyter Notebookが立ち上がるのですぐに試せて良い。
$ docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow  http://localhost:8888/tree
公式のチュートリアルをまとめながら進めてみる。
MNIST For ML Beginners
The MNIST Data MNISTというのは0~9の書き数字の画像のデータセットのことで、これらを正しく分類するのが目的。
それぞれの画像は一律28*28=784ピクセルで、それぞれのピクセルは0と1の間の数値(強さ)で表されている。 今回はこれの縦横を取っ払って784次元のベクトルとして扱っている。
したがって、学習用の画像データは[55000, 784]のtensor(n次元の配列)で表される。 55000というのが画像の数で、784というのがそれぞれの画像の次元を意味している。
それぞれの画像に対応した数字のラベルは[55000, 10]で表される。 10というのは、0~9それぞれに対応した次元のうち、一つだけ1で、それ以外が0という風に使われる。これをone-hot vectorという。
Softmax Regressions Softmaxはいくつかの異なるもの(今回でいうと数字)に確率を割り当てる。
画像が特定のクラス(0~9)に属するかどうか計算するために、ピクセルの強さに重みを付けた合計を計算する。 もし、そのピクセルがそのクラスに属さない根拠になるなら負の重みがかかり、属する根拠になるなら、正の重みがかかるようにする。 また合計にさらに入力と無関係なクラスごとに異なるバイアスを足す。
全てのクラスで計算した値をsoftmax関数に入れ、それぞれ確率に変換する。この確率の和は1になるようになっている。
Implementing the Regression Pythonでは行列の積のような重い処理をするとき、NumPyのようなライブラリを使ってPythonの外で行うが、 外からPythonに戻るときにオーバーヘッドが発生してしまう。 TensorFlowでも重い処理を外で行うが、オーバーヘッドを避けるために、 単体の重い処理をPythonから独立して実行する代わりに、Pythonの外側で実行される関連した処理のグラフを記述させる。
import tensorflow as tf x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b)  tf.placeholderは実行時に与えられる値で、今回が画像データ。 W(重み)とb(バイアス)は学習する変数。 tf.</description>
    </item>
    
    <item>
      <title>Reactで作ったページにTwitterCardsとOGPのメタデータを埋める</title>
      <link>https://www.sambaiz.net/article/2/</link>
      <pubDate>Sat, 02 Jul 2016 13:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/2/</guid>
      <description>せっかくページを作ったので、SNSにシェアするときに見栄えをよくしようと思った。
Twitter CardsやOGPのmetaタグを埋めるとTwitterやFacebookにURLを貼ったときに上のように表示されるようになる(上はFacebookの例)。そこで、react-helmetでこんな感じで動的に埋め込んだんだけど読んでくれない。
&amp;lt;Helmet title={&#39;sambaiz.net&#39;} meta={[ {&amp;quot;name&amp;quot;: &amp;quot;twitter:card&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;summary&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;twitter:site&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;@sambaiz&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;twitter:title&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;sambaiz.net&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;twitter:description&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;僕のホームページ&amp;quot;}, {&amp;quot;property&amp;quot;: &amp;quot;og:title&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;sambaiz.net&amp;quot;}, {&amp;quot;property&amp;quot;: &amp;quot;og:type&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;blog&amp;quot;}, {&amp;quot;property&amp;quot;: &amp;quot;og:image&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;http://d2wgaf7ubdj1mv.cloudfront.net/my.jpg&amp;quot;}, {&amp;quot;property&amp;quot;: &amp;quot;og:url&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;https://www.sambaiz.net&amp;quot;} ]} /&amp;gt;  GoogleのクローラーのようにJavascriptを解釈してくれる と思ってた。残念。
しょうがないのでここだけサーバーサイドレンダリングすることにした。
&#39;use strict&#39; import express from &#39;express&#39; import path from &#39;path&#39; import compression from &#39;compression&#39; require(&#39;isomorphic-fetch&#39;); var app = express() app.use(compression()) // serve our static stuff app.use(express.static(path.join(__dirname, &#39;.</description>
    </item>
    
    <item>
      <title>ブログを作った</title>
      <link>https://www.sambaiz.net/article/1/</link>
      <pubDate>Wed, 29 Jun 2016 23:43:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/1/</guid>
      <description>最近表に出るものを作っていなかったので、このサイトを作ってみた。
表はReact/Reduxで、裏側はAWSのLambdaでサーバーレスに作ってある。 コードはgithubに公開してみた。
これを期になるべくアウトプットしていこうと思う。大抵三日坊主なのだけれど。
&amp;ndash;
追記: 今はHugoに置き換わっている
静的ウェブサイトエンジンHugoに乗り換えた</description>
    </item>
    
  </channel>
</rss>