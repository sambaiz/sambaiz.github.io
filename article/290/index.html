<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Hugo 0.75.1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="/css/destyle.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">
  <link rel="icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">

  <meta name="theme-color" content="#41a248">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@sambaiz">
  
  <title>SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする - sambaiz-net</title>
  <meta name="twitter:title" content="SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする - sambaiz-net">
  <meta property='og:title' content="SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする - sambaiz-net">
  <meta property="og:type" content="article">
  
  <meta name="description" content="Elastic InferenceでGPUリソースをCPUインスタンスにアタッチする">
  <meta name="twitter:description" content="Elastic InferenceでGPUリソースをCPUインスタンスにアタッチする">
  
  

  <meta property="og:url" content="https://www.sambaiz.net/article/290/">
  <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
  <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />
  <meta name="google-site-verification" content="CEqNYjzc4Y7hb3FY7uUkmllGzeDc40brBwQJixeH61Q" />
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id":"https:\/\/www.sambaiz.net\/"
    },
    "headline": "SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする - sambaiz-net",
    "datePublished": "2020-07-26T02:43:00JST",
    "dateModified": "2020-07-26T02:43:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "image": "https:\/\/www.sambaiz.net\/images/my.jpg"
    },
    "publisher": {
      "@type": "Person",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https:\/\/www.sambaiz.net\/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https:\/\/www.sambaiz.net\/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "Elastic InferenceでGPUリソースをCPUインスタンスにアタッチする"
  }
</script>
</head>

<body>
  <div>
    <header>
      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" />
        <a class="nl" href="https://www.sambaiz.net/">sambaiz-net</a>
      </div>

      <div>
        <a class="nl" href="https://twitter.com/sambaiz"><i class="fa fa-2x fa-twitter"></i></a>
        <a class="nl" href="https://github.com/sambaiz"><i class="fa fa-2x fa-github"></i></a>
        <style>
          .filmarks-base {
            display: inline-block;
            width: 29px;
            height: 29px;
          }

          .filmarks {
            display: inline-block;
            width: 25px;
            height: 25px;
            background: url(/image/filmarks.svg) no-repeat;
            background-size: 450%;
            position: relative;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
          }
        </style>
        <div class="filmarks-base">
          <a href="https://filmarks.com/users/sambaiz" class="filmarks"></a>
        </div>
      </div>
    </header>

<div class="container">
  <article class="single">
    <div class="single body">
      <h1>SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする</h1>
      <p>(2020-07-26)</p>
      <p>学習させたモデルをSageMakerのホスティングサービスにデプロイする。</p>
<p><a href="https://www.sambaiz.net/article/287/">SageMakerでPyTorchのモデルを学習させる - sambaiz-net</a></p>
<h2 id="推論時に呼ばれる関数">推論時に呼ばれる関数</h2>
<p>推論時には次の関数が<a href="https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#serve-a-pytorch-model">呼ばれる</a>。</p>
<ul>
<li>model_fn(model_dir): モデルをロードする</li>
<li>input_fn(request_body, request_content_type): リクエストボディのデシリアライズ</li>
<li>predict_fn(input_data, model): モデルで推論する</li>
<li>output_fn(prediction, content_type): Content-Typeに応じたシリアライズ</li>
</ul>
<p><code>input_fn()</code> と <code>output_fn()</code> はJSON, CSV, NPYに対応した実装が、<code>predict_fn()</code> はモデルを呼び出す実装がデフォルトとして用意されていて、
<code>model_fn()</code> も後述するElastic Inferenceを使う場合<code>model.pt</code>というファイルをロードするデフォルト実装が使われる。
ただしその場合モデルが<code>torch.jit.save()</code>で<a href="https://pytorch.org/docs/stable/jit.html">TorchScript</a>として保存してある<a href="https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#save-the-model">必要がある</a>。</p>
<p>今回は <code>predict_fn()</code> のみ実装した。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python">$ cat inference<span style="color:#ff79c6">.</span>py
<span style="color:#ff79c6">import</span> torch

<span style="color:#ff79c6">def</span> <span style="color:#50fa7b">predict_fn</span>(input_data, model):
    device <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>device(<span style="color:#f1fa8c">&#39;cuda&#39;</span> <span style="color:#ff79c6">if</span> torch<span style="color:#ff79c6">.</span>cuda<span style="color:#ff79c6">.</span>is_available() <span style="color:#ff79c6">else</span> <span style="color:#f1fa8c">&#39;cpu&#39;</span>)
    model <span style="color:#ff79c6">=</span> model<span style="color:#ff79c6">.</span>to(device)
    input_data <span style="color:#ff79c6">=</span> input_data<span style="color:#ff79c6">.</span>to(device)
    model<span style="color:#ff79c6">.</span>eval()
    <span style="color:#ff79c6">with</span> torch<span style="color:#ff79c6">.</span>jit<span style="color:#ff79c6">.</span>optimized_execution(True, {<span style="color:#f1fa8c">&#34;target_device&#34;</span>: <span style="color:#f1fa8c">&#34;eia:0&#34;</span>}):
        output <span style="color:#ff79c6">=</span> model(input_data)
        <span style="color:#ff79c6">return</span> output<span style="color:#ff79c6">.</span>max(<span style="color:#bd93f9">1</span>)[<span style="color:#bd93f9">1</span>]
</code></pre></div><h2 id="デプロイ">デプロイ</h2>
<p>Training jobがモデルを保存したS3のパスを取ってきて<a href="https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html#pytorch-model">PyTorchModel</a>を作る。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#ff79c6">from</span> sagemaker.pytorch.model <span style="color:#ff79c6">import</span> PyTorchModel

training_job_name <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#39;pytorch-training-2020-07-25-08-41-45-674&#39;</span>
training_job <span style="color:#ff79c6">=</span> sess<span style="color:#ff79c6">.</span>client(<span style="color:#f1fa8c">&#39;sagemaker&#39;</span>)<span style="color:#ff79c6">.</span>describe_training_job(TrainingJobName<span style="color:#ff79c6">=</span>training_job_name)
model <span style="color:#ff79c6">=</span> PyTorchModel(model_data<span style="color:#ff79c6">=</span>training_job[<span style="color:#f1fa8c">&#39;ModelArtifacts&#39;</span>][<span style="color:#f1fa8c">&#39;S3ModelArtifacts&#39;</span>], 
                     role<span style="color:#ff79c6">=</span>sagemaker<span style="color:#ff79c6">.</span>get_execution_role(),
                     framework_version<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;1.3.1&#39;</span>,
                     py_version<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;py3&#39;</span>,
                     source_dir<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;/root/sagemaker-pytorch-mnist&#39;</span>,
                     entry_point<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;inference.py&#39;</span>)
</code></pre></div><p><code>deploy()</code>するとModelsとEndpoint configurations、Endpointsが作成される。結構時間がかかる。</p>
<p><img src="https://www.sambaiz.net/images/290.png" alt="Endpoints"></p>
<p><code>accelerator_type</code>に指定している<a href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/ei.html">Elastic Inference</a>というのは、適した量のGPUリソースを各CPUインスタンスにアタッチしてくれるもので、GPUインスタンスのリソースを十分使えていない場合コストを下げることができる。ただEI用のイメージのPyTorchのバージョンが古くバージョンを下げる必要があった。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python">model<span style="color:#ff79c6">.</span>deploy(instance_type<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;ml.c4.xlarge&#39;</span>, initial_instance_count<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>, endpoint_name<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;pytorch-mnist-test&#39;</span>, accelerator_type<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;ml.eia2.medium&#39;</span>)
</code></pre></div><p>呼び出してみる。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#ff79c6">from</span> torchvision <span style="color:#ff79c6">import</span> datasets, transforms

dataset <span style="color:#ff79c6">=</span> datasets<span style="color:#ff79c6">.</span>MNIST(<span style="color:#f1fa8c">&#39;mnist&#39;</span>, train<span style="color:#ff79c6">=</span>False, transform<span style="color:#ff79c6">=</span>transforms<span style="color:#ff79c6">.</span>ToTensor(), download<span style="color:#ff79c6">=</span>False)
result <span style="color:#ff79c6">=</span> predictor<span style="color:#ff79c6">.</span>predict(dataset[<span style="color:#bd93f9">0</span>][<span style="color:#bd93f9">0</span>]<span style="color:#ff79c6">.</span>view(<span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>, <span style="color:#bd93f9">1</span>, <span style="color:#bd93f9">28</span>, <span style="color:#bd93f9">28</span>))
<span style="color:#ff79c6">print</span>(result) <span style="color:#6272a4"># [7]</span>
<span style="color:#ff79c6">print</span>(dataset[<span style="color:#bd93f9">0</span>][<span style="color:#bd93f9">1</span>]) <span style="color:#6272a4"># 7</span>
</code></pre></div><p>shapeの不一致などでエラーを起こすとタイムアウトし、ログにも <code>EI Error Description: Internal error</code> と表示されるだけでトラブルシューティングが難しかった。
例外をcatchしてログを出したり入力のバリデーションを行うと良いと思う。</p>
<h2 id="後片付け">後片付け</h2>
<p>デプロイしたリソースを削除する。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python">predictor<span style="color:#ff79c6">.</span>delete_endpoint()
predictor<span style="color:#ff79c6">.</span>delete_model()
</code></pre></div>
    </div>
  </article>
</div>

</div>

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date(); a = s.createElement(o),
      m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-39190067-3', 'auto');
  ga('send', 'pageview');
</script>


</body>

</html>