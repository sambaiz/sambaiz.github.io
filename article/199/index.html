<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Hugo 0.38.2" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7"
    crossorigin="anonymous">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/magula.min.css">
  <link rel="stylesheet" href="/css/slidebars.min.css">
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">
  <link rel="icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">

  <meta name="theme-color" content="#41a248">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@sambaiz">
  
  <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する - sambaiz-net</title>
  <meta name="twitter:title" content="TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する - sambaiz-net">
  <meta property='og:title' content="TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する - sambaiz-net">
  <meta property="og:type" content="article">
  
  <meta name="description" content="CPU/GPU/TPUでCNNを学習させて実行時間を比較する">
  <meta name="twitter:description" content="CPU/GPU/TPUでCNNを学習させて実行時間を比較する">
  
  

  <meta property="og:url" content="https://www.sambaiz.net/article/199/">
  <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
  <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />
  <meta name="google-site-verification" content="CEqNYjzc4Y7hb3FY7uUkmllGzeDc40brBwQJixeH61Q" />
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id":"https://www.sambaiz.net/"
    },
    "headline": "TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する | sambaiz-net ",
    "datePublished": "2018-11-27T09:57:00JST",
    "dateModified": "2018-11-27T09:57:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "image": "https://www.sambaiz.net/images/my.jpg"
    },
    "publisher": {
      "@type": "Organization",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.sambaiz.net/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https://www.sambaiz.net/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "CPU/GPU/TPUでCNNを学習させて実行時間を比較する"
  }
</script>
</head>

<body>
  <div off-canvas="id-1 left reveal">
  
  <ul class="tag-list">
    
  </ul>
  
  <ul class="tag-list">
    <li><a href="https://www.sambaiz.net/tags/aws">aws</a></li><li><a href="https://www.sambaiz.net/tags/golang">golang</a></li><li><a href="https://www.sambaiz.net/tags/machinelearning">machinelearning</a></li><li><a href="https://www.sambaiz.net/tags/log">log</a></li><li><a href="https://www.sambaiz.net/tags/kubernetes">kubernetes</a></li><li><a href="https://www.sambaiz.net/tags/python">python</a></li><li><a href="https://www.sambaiz.net/tags/tensorflow">tensorflow</a></li><li><a href="https://www.sambaiz.net/tags/unity">unity</a></li><li><a href="https://www.sambaiz.net/tags/fluentd">fluentd</a></li><li><a href="https://www.sambaiz.net/tags/gcp">gcp</a></li><li><a href="https://www.sambaiz.net/tags/infra">infra</a></li><li><a href="https://www.sambaiz.net/tags/node.js">node.js</a></li><li><a href="https://www.sambaiz.net/tags/web">web</a></li><li><a href="https://www.sambaiz.net/tags/docker">docker</a></li><li><a href="https://www.sambaiz.net/tags/lambda">lambda</a></li><li><a href="https://www.sambaiz.net/tags/javascript">javascript</a></li><li><a href="https://www.sambaiz.net/tags/mysql">mysql</a></li><li><a href="https://www.sambaiz.net/tags/elasticsearch">elasticsearch</a></li><li><a href="https://www.sambaiz.net/tags/hololens">hololens</a></li><li><a href="https://www.sambaiz.net/tags/linux">linux</a></li><li><a href="https://www.sambaiz.net/tags/ble">ble</a></li><li><a href="https://www.sambaiz.net/tags/circleci">circleci</a></li><li><a href="https://www.sambaiz.net/tags/product">product</a></li><li><a href="https://www.sambaiz.net/tags/react">react</a></li><li><a href="https://www.sambaiz.net/tags/typescript">typescript</a></li><li><a href="https://www.sambaiz.net/tags/android">android</a></li><li><a href="https://www.sambaiz.net/tags/angular">angular</a></li><li><a href="https://www.sambaiz.net/tags/auth">auth</a></li><li><a href="https://www.sambaiz.net/tags/cron">cron</a></li><li><a href="https://www.sambaiz.net/tags/istio">istio</a></li><li><a href="https://www.sambaiz.net/tags/terraform">terraform</a></li><li><a href="https://www.sambaiz.net/tags/uwp">uwp</a></li><li><a href="https://www.sambaiz.net/tags/.net">.net</a></li><li><a href="https://www.sambaiz.net/tags/css">css</a></li><li><a href="https://www.sambaiz.net/tags/datadog">datadog</a></li><li><a href="https://www.sambaiz.net/tags/event">event</a></li><li><a href="https://www.sambaiz.net/tags/firebase">firebase</a></li><li><a href="https://www.sambaiz.net/tags/grpc">grpc</a></li><li><a href="https://www.sambaiz.net/tags/hadoop">hadoop</a></li><li><a href="https://www.sambaiz.net/tags/norikra">norikra</a></li><li><a href="https://www.sambaiz.net/tags/rx">rx</a></li><li><a href="https://www.sambaiz.net/tags/vr">vr</a></li><li><a href="https://www.sambaiz.net/tags/api">api</a></li><li><a href="https://www.sambaiz.net/tags/cdn">cdn</a></li><li><a href="https://www.sambaiz.net/tags/compress">compress</a></li><li><a href="https://www.sambaiz.net/tags/crypto">crypto</a></li><li><a href="https://www.sambaiz.net/tags/csharp">csharp</a></li><li><a href="https://www.sambaiz.net/tags/d3.js">d3.js</a></li><li><a href="https://www.sambaiz.net/tags/github">github</a></li><li><a href="https://www.sambaiz.net/tags/hugo">hugo</a></li><li><a href="https://www.sambaiz.net/tags/ios">ios</a></li><li><a href="https://www.sambaiz.net/tags/jenkins">jenkins</a></li><li><a href="https://www.sambaiz.net/tags/jvm">jvm</a></li><li><a href="https://www.sambaiz.net/tags/leveldb">leveldb</a></li><li><a href="https://www.sambaiz.net/tags/math">math</a></li><li><a href="https://www.sambaiz.net/tags/neo4j">neo4j</a></li><li><a href="https://www.sambaiz.net/tags/pytorch">pytorch</a></li><li><a href="https://www.sambaiz.net/tags/read_paper">read_paper</a></li><li><a href="https://www.sambaiz.net/tags/scikit-learn">scikit-learn</a></li><li><a href="https://www.sambaiz.net/tags/serialize">serialize</a></li><li><a href="https://www.sambaiz.net/tags/server">server</a></li><li><a href="https://www.sambaiz.net/tags/sonnet">sonnet</a></li><li><a href="https://www.sambaiz.net/tags/spark">spark</a></li><li><a href="https://www.sambaiz.net/tags/spec">spec</a></li><li><a href="https://www.sambaiz.net/tags/statistics">statistics</a></li><li><a href="https://www.sambaiz.net/tags/video">video</a></li>
  </ul>
  
</div>

  <div canvas="container" id="container">
    <header>
      <button type="button" class="btn toggle-side">TAG</button>

      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" />
        <a class="nl" href="https://www.sambaiz.net/">sambaiz-net</a>
      </div>

      <div class="sns">
        <a class="nl" href="https://twitter.com/sambaiz"><i class="fa fa-2x fa-twitter"></i></a>
        <a class="nl" href="https://github.com/sambaiz"><i class="fa fa-2x fa-github"></i></a>
        <style>
          .strava-badge-base {
            display: inline-block;
            height: 29px;
            width: 29px;
          }

          .strava-badge {
            display: inline-block;
            height: 24px;
            width: 24px;
            background: url(/image/strava.png) no-repeat;
            position: relative;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
          }

          .filmarks-base {
            display: inline-block;
            width: 29px;
            height: 29px;
          }

          .filmarks {
            display: inline-block;
            width: 25px;
            height: 25px;
            background: url(/image/filmarks.svg) no-repeat;
            background-size: 450%;
            position: relative;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
          }

          .studyplus-base {
            display: inline-block;
            width: 29px;
            height: 29px;
          }

          .studyplus {
            display: inline-block;
            height: 24px;
            width: 24px;
            background: url(/image/studyplus.png) no-repeat;
            position: relative;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
          }
        </style>
        <div class="strava-badge-base">
          <a href="https://strava.com/athletes/36758958/badge" class="strava-badge"></a>
        </div>
        <div class="filmarks-base">
          <a href="https://filmarks.com/users/sambaiz" class="filmarks"></a>
        </div>
        <div class="studyplus-base">
          <a href="https://www.studyplus.jp/users/0842722cd7a6483baa7979f9d3f7c2e6/studylog/logs" class="studyplus"></a>
        </div>
      </div>
    </header>

<div class="container">

  <div class="row">
    <div class="col-md-12">

      <article class="single">
        <div class="single body">
          <h1>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</h1>
          <p>(2018-11-27)</p>
          

<p>TPU(Tensor Processing Unit)は
Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。
<a href="https://cloudplatform-jp.googleblog.com/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu.html">一般的なGPUと比べて15~30倍もの性能が出る</a>
らしく検索や翻訳などGoogleのサービスでも使われている。</p>

<p>TPUを使える環境として、無料で使えるJupyter Notebooksの<a href="https://colab.research.google.com/">Google Colab</a>と
GCPの<a href="https://cloud.google.com/tpu/">Cloud TPU</a>がある。ColabのTPUも裏側ではCloud TPUが動いている。
Cloud TPUを直に使うとVMから接続して使うことになるので、TPUの<a href="https://cloud.google.com/tpu/docs/pricing">料金</a>に加えてVMの料金もかかる。</p>

<h2 id="モデルのtpu対応">モデルのTPU対応</h2>

<p>CNNのモデルを<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimator">TPUEstimator</a>でTPUに対応させる。</p>

<p><a href="https://www.tensorflow.org/guide/estimators">Estimator</a>はTensorFlowの高レベルAPIで、
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#train">train()</a>、
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate">evaluate()</a>、
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#predict">predict()</a>、
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#export_saved_model">export_saved_model()</a>
といったモデルの学習から保存まで必要な機能を一通り提供する。</p>

<p>初めは比較的低レベルのAPIを使おうとしていたが、XLA(Accelerated Linear Algebra)によるコンパイルがうまくいかないなど様々な問題にあたって大変だったので使っておくと良いと思う。
それでもトライアンドエラーの繰り返しで、典型的なものは<a href="https://cloud.google.com/tpu/docs/troubleshooting">Troubleshooting</a>にあるが、ないものは調べるなりしてなんとかやっていくしかない。</p>

<p>定数などの定義。BATCH_SIZEはCloud TPUのシャード数の8で割り切れる値にする必要がある。</p>

<pre><code>import pandas as pd
from sklearn.model_selection import train_test_split
import tensorflow as tf
import numpy as np
flags = tf.app.flags
flags.DEFINE_boolean('use_tpu', True, 'use tpu or not')
tf.app.flags.DEFINE_string('f', '', 'kernel')
FLAGS = flags.FLAGS

EPOCH_NUM = 100
BATCH_SIZE = 800 # must be divisible by number of replicas 8
EVAL_BATCH_SIZE = 800
SHARD_NUM = 8 # A single Cloud TPU has 8 shards.
ITERATION_NUM = 100 # Number of training steps to run on the Cloud TPU before returning control.
</code></pre>

<h3 id="入力データの準備">入力データの準備</h3>

<p>入力は関数で渡し、tf.data APIのdatasetを返せばイテレートしてくれる。</p>

<p><a href="https://www.sambaiz.net/article/195/">TensorFlowのtf.data API - sambaiz-net</a></p>

<p>batch()でdrop_remainderをTrueにして端数を切り捨てないと、shapeが確定せずコンパイルできない。</p>

<pre><code>from google.colab import auth
from googleapiclient.discovery import build
from io import BytesIO

auth.authenticate_user()
bucket = &quot;&lt;bucket_name&gt;&quot;
gcs_service = build('storage', 'v1')
train_data = gcs_service.objects().get_media(bucket=bucket, object='train.csv').execute()
train = pd.read_csv(BytesIO(train_data))

MODEL_DIR = 'gs://{}/model/tpu'.format(bucket)

(x_train, x_valid, y_train, y_valid) = train_test_split(
    train.drop('label', axis=1).values.reshape((-1, 28, 28, 1)).astype(np.float32), 
    np.identity(10)[train['label']].astype(np.float32), 
    test_size = 0.1, random_state = 100)

def train_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({'x': x_train}, y_train)) # (features, labels)
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(params['batch_size'], drop_remainder=True)
    return dataset

def valid_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({'x': x_valid}, y_valid))
    dataset = dataset.batch(params['batch_size'], drop_remainder=True)
    return dataset
</code></pre>

<p>入出力するファイルはローカルではなくGCSなどに置く必要があるのでCloud TPUからも読み書きできるようにする。</p>

<pre><code>{
    &quot;domain&quot;: &quot;global&quot;,
    &quot;reason&quot;: &quot;forbidden&quot;,
    &quot;message&quot;: &quot;service-******@cloud-tpu.iam.gserviceaccount.com does not have storage.objects.create access to &lt;bucket_name&gt;.&quot;
}
</code></pre>

<pre><code>!gsutil acl ch -u service-*****@cloud-tpu.iam.gserviceaccount.com:WRITER gs://&lt;bucket_name&gt;
</code></pre>

<h3 id="モデルの作成">モデルの作成</h3>

<p>Estimatorには次のシグネチャのmodel_fnを渡す。
引数のfeaturesとlabelsはinput_fnの返り値で、
modeは<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys">tf.estimator.ModeKeys</a>の<code>TRAIN</code>、<code>EVAL</code>、<code>PREDICT</code>で、
paramsはEstimator生成時に渡せるパラメータ。
optimizerは<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/CrossShardOptimizer">CrossShardOptimizer</a>で<a href="https://www.tensorflow.org/guide/using_tpu#optimizer">wrapする</a>。</p>

<p>TPUに対応している<a href="https://cloud.google.com/tpu/docs/tensorflow-ops">op</a>で作る必要がある。</p>

<pre><code>def model_fn(features, labels, mode, params):
    def metric_fn(labels, logits):
        return {
            'accuracy': tf.metrics.accuracy(
                labels=tf.argmax(labels, axis=1), predictions=tf.argmax(logits, axis=1))
         }
    is_training = tf.equal(mode, tf.estimator.ModeKeys.TRAIN)
    conv1 = tf.layers.conv2d(
        inputs=features['x'],
        filters=32, 
        kernel_size=[5, 5], 
        padding=&quot;same&quot;, 
        activation=tf.nn.relu)
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)
    conv2 = tf.layers.conv2d(
        inputs=pool1, 
        filters=64, 
        kernel_size=[5, 5],
        padding=&quot;same&quot;, 
        activation=tf.nn.relu)
    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
    pool2_flat = tf.layers.flatten(pool2)
    dense = tf.layers.dense(inputs=pool2_flat, units=128, activation=tf.nn.relu)
    dropout = tf.layers.dropout(
        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)
    logits = tf.layers.dense(inputs=dropout, units=10)

    loss = tf.losses.softmax_cross_entropy(
        onehot_labels=labels, logits=logits)
    
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.contrib.tpu.TPUEstimatorSpec(mode, loss=loss, 
                                               eval_metrics=(metric_fn, [labels, logits]))

    optimizer = tf.train.AdamOptimizer(0.01)
    if FLAGS.use_tpu:
        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)

    return tf.contrib.tpu.TPUEstimatorSpec(
        mode=mode,
        loss=loss,
        predictions={
            'pred': tf.argmax(logits, axis=1)
        },
        train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))
</code></pre>

<h3 id="tpuestimatorの生成">TPUEstimatorの生成</h3>

<p>TPUのアドレスが環境変数COLAB_TPU_ADDRに入るのでこれをmasterとする。</p>

<pre><code>if FLAGS.use_tpu:
    master = 'grpc://' + os.environ['COLAB_TPU_ADDR']
    run_config = tf.contrib.tpu.RunConfig(
        master=master,
        session_config=tf.ConfigProto(
            allow_soft_placement=True, log_device_placement=True),
        tpu_config=tf.contrib.tpu.TPUConfig(ITERATION_NUM, SHARD_NUM))
else:
    run_config = tf.contrib.tpu.RunConfig()

classifier = tf.contrib.tpu.TPUEstimator(
    model_fn=model_fn,
    model_dir=MODEL_DIR,
    config=run_config,
    params={},
    train_batch_size=BATCH_SIZE,
    eval_batch_size=EVAL_BATCH_SIZE,
    predict_batch_size=BATCH_SIZE,
    use_tpu=FLAGS.use_tpu)
</code></pre>

<h3 id="学習">学習</h3>

<pre><code>for epoch in range(EPOCH_NUM):
  max_steps = len(x_train)*(epoch+1)//BATCH_SIZE
  valid_steps = len(x_valid)//EVAL_BATCH_SIZE
  if FLAGS.use_tpu: 
    max_steps //= SHARD_NUM
  train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_steps)
  eval_spec = tf.estimator.EvalSpec(input_fn=valid_input_fn, steps=valid_steps)
  result = tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
  if result[0] is not None:
    print('epoch: {}, loss: {} accuracy: {}'.format(epoch+1, result[0]['loss'], result[0]['accuracy']))
  else:
    print('epoch: {} is already trained'.format(epoch+1))
</code></pre>

<h3 id="colabでtensorboardを開く">ColabでTensorBoardを開く</h3>

<p>このスクリプトを実行するとTensorBoardを立ち上げてngrokで外に開いてくれる。</p>

<p><a href="https://github.com/mixuala/colab_utils">mixuala/colab_utils</a></p>

<pre><code>!git clone https://github.com/mixuala/colab_utils
import os
import colab_utils.tboard

# set paths
ROOT = %pwd
colab_utils.tboard.launch_tensorboard(bin_dir=ROOT, log_dir=MODEL_DIR)
</code></pre>

<h2 id="結果">結果</h2>

<p>学習させて実行時間を計測する。計測はセルの頭に<code>%%time</code>を付けるとできる。</p>

<h3 id="cpu">CPU</h3>

<p>ベースライン。</p>

<pre><code>CPU times: user 18min 28s, sys: 32.8 s, total: 19min 1s
Wall time: 14min 33s
</code></pre>

<h3 id="gpu">GPU</h3>

<p>ランタイムからアクセラレータをGPUに設定。使われるGPUはNVIDIAの<a href="https://www.nvidia.co.jp/object/tesla-k80-jp.html">Tesla K80</a>。</p>

<pre><code>from tensorflow.python.client import device_lib
device_lib.list_local_devices()
# ...
# physical_device_desc: &quot;device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7&quot;]
</code></pre>

<p>結果。</p>

<pre><code>CPU times: user 3min 2s, sys: 24.2 s, total: 3min 26s
Wall time: 8min 6s
</code></pre>

<h3 id="tpu">TPU</h3>

<p>アクセラレータをTPUに変更。
GPUより速くなることを期待したが、むしろCPUよりも遅くなってしまった。その上精度の伸びも遅くて良いところがない。</p>

<pre><code>CPU times: user 3min, sys: 23.8 s, total: 3min 24s
Wall time: 15min
</code></pre>

<h2 id="再チャレンジ">再チャレンジ</h2>

<p>エポックの立ち上がりが遅いので学習を切らずに続けて行わせてみる。</p>

<pre><code>def train_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({'x': x_train}, y_train)) # (features, labels)
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(params['batch_size'], drop_remainder=True)
    dataset = dataset.repeat(EPOCH_NUM)
    return dataset

epoch = EPOCH_NUM-1
max_steps = len(x_train)*(epoch+1)/BATCH_SIZE
valid_steps = len(x_valid)//EVAL_BATCH_SIZE
if FLAGS.use_tpu: 
  max_steps //= SHARD_NUM
train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_steps)
eval_spec = tf.estimator.EvalSpec(input_fn=valid_input_fn, steps=valid_steps)
result = tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
if result[0] is not None:
  print('epoch: {}, loss: {} accuracy: {}'.format(epoch+1, result[0]['loss'],  result[0]['accuracy']))
else:
  print('epoch: {} is already trained'.format(epoch+1))
</code></pre>

<p>これを実行したところGPUと同程度には速くなった。</p>

<pre><code># GPU
CPU times: user 40.9 s, sys: 7.8 s, total: 48.7 s
Wall time: 1min 43s

# TPU
CPU times: user 35.2 s, sys: 4.46 s, total: 39.7 s
Wall time: 1min 34s
</code></pre>

<p>さらにEPOCH_NUMを5から100にして再計測する。</p>

<h2 id="結果-1">結果</h2>

<h3 id="gpu-1">GPU</h3>

<pre><code>CPU times: user 3min 27s, sys: 2min, total: 5min 28s
Wall time: 6min 5s
</code></pre>

<h3 id="tpu-1">TPU</h3>

<p>エポック数を大幅に増やしたのにも関わらずほとんど実行時間が変わらずとても速い。
CPU時間も変わっていないので演算がTPUで完結していてCPU-TPU間のデータの受け渡しが最小限で済んでいるのかもしれない。</p>

<pre><code>CPU times: user 34.5 s, sys: 7.32 s, total: 41.8 s
Wall time: 1min 38s
</code></pre>

<h2 id="参考">参考</h2>

<p><a href="https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d">Google Colab Free GPU Tutorial – Deep Learning Turkey – Medium</a></p>

<p><a href="https://qiita.com/koshian2/items/fb989cebe0266d1b32fc">Google ColabのTPUで対GPUの最速に挑戦する - Qiita</a></p>

        </div>
      </article>
    </div>
  </div>
</div>

</div> 
<script src="//code.jquery.com/jquery-2.1.3.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script src="/js/slidebars.min.js"></script>
<script>
    ( function ( $ ) {
      
      var controller = new slidebars();
      controller.init();

      $( '.toggle-side' ).on( 'click', function ( event ) {
          event.stopPropagation();
          event.preventDefault();

          controller.toggle( 'id-1' );
        } );

        $( '#container' ).on( 'click', function ( event ) {
            controller.close( 'id-1' );
          });
    } ) ( jQuery );
</script>

<script>hljs.initHighlightingOnLoad();</script>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-39190067-3', 'auto');
ga('send', 'pageview');
</script>


  </body>
</html>

