<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">

  
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NCML2RV');</script>
  

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;700&display=swap" rel="stylesheet">

  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
  <link rel="stylesheet" href="/css/destyle.css">
  <style>
    body {
        background-color: #f1f1f1;
        line-height: 1.3;
        font-family: 'Noto Sans JP', sans-serif;
    }

    .languages {
        position: absolute;
        top: 10px;
        right: 15px;
        font-size: 1.2rem;
        color: #3a9240;
    }

    header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
    }

    header>.title {
        font-size: 1.875rem;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns {
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns-item {
        display: inline-block;
        margin: 3px;
    }

    .filmarks {
        display: inline-block;
        width: 30px;
        height: 30px;
        margin-top: 3px;
        background: url(/image/filmarks.svg) no-repeat;
        background-size: 450%;
    }

    header>.tags {
        display: flex;
        justify-content: center;
        align-items: center;
        font-size: 1.2rem;
        max-width: 1000px;
        margin: auto;
        padding: 0 20px;
    }

    header>.tags .others {
        font-weight: bold;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
    }

    .nl {
        display: inline-block;
    }

    .cell {
        background-color: #fff;
        border-radius: 5px;
        padding: 10px;
        box-shadow: 0 1px 1px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
    }

    time {
        color: #333;
    }

    .tag {
        color: #3a9240;
        margin: 0 5px;
    }

    .tag:hover {
        text-decoration: underline;
    }

     
    .paging {
        display: inline-block;
        font-size: 1.25rem;
        margin: 10px 10px;
    }

    .paging.next {
        float: right;
    }


     
    .list>.title {
        font-size: 1.75rem;
        margin: 0 0 10px 10px;
    }

     
    .grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(262px, 1fr));
        gap: 20px;
        margin: 0 10px;
    }

    .grid-nl {
        width: 100%;
    }

    .grid-cell {
        height: 11.25rem;
        overflow: hidden;
        box-sizing: content-box;
    }

    .grid-cell>.title {
        font-size: 1.5rem;
        word-wrap: break-word;
    }

     
    .single {
        margin: 0 10px 10px 10px;
        line-height: 1.5;
    }

    @media screen and (min-width: 768px) {
        .single .cell {
            padding: 10px 20px;
        }
    }

    .single-header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
        line-height: 1.3;
    }

    .single-header h1 {
        font-size: 2rem;
        font-weight: bold;
    }

    .single h2 {
        font-size: 1.8rem;
        border-bottom: 1px solid #ddd;
        margin-block-start: 1.875rem;
    }

    .single h3 {
        font-size: 1.5rem;
        margin-block-start: 1.5rem;
    }

    .single h4 {
        font-size: 1.2rem;
        margin-block-start: 1rem;
    }

    .single a {
        color: #3a9240;
    }

    .single a:hover {
        text-decoration: underline;
    }

    .single p {
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single p>code {
        background-color: #eee;
        color: #333;
        padding: 0 0.2rem;
        display: inline-block;
        overflow: auto;
        max-width: 100%;
        vertical-align: bottom;
    }

    .single .highlight {
        box-shadow: 0 1px 5px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single .highlight>pre {
        padding: 10px;
        overflow-x: auto;
        background-color: ;
    }

    .single img {
        max-width: 100%;
    }

    .single blockquote {
        border-left: 5px solid #ddd;
        color: #777;
        padding: 1rem 0 1rem 1rem;
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single hr {
        color: #bbb;
        margin-block-start: 1.5rem;
        margin-block-end: 1.5rem;
    }

    .single ul {
        list-style-type: disc;
        padding-left: 1.5em;
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .share {
        position: relative;
        text-align: right;
        margin-top: 5px;
    }

    .share .cell {
        display: inline-block;
        text-align: center;
        margin-bottom: 5px;
    }

    .share-button {
        display: inline-block;
        margin: 0 5px;
    }

    @media screen and (min-width: 1400px) {
        .share .cell {
            position: absolute;
            bottom: 0;
            margin-left: 5px;
        }

        .share-button {
            display: inline-block;
            margin: 5px 0;
        }
    }
</style>
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">
  <link rel="icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">

  <meta name="theme-color" content="#41a248">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@sambaiz">
  
  <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する - sambaiz-net</title>
  <meta name="twitter:title" content="TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する - sambaiz-net">
  <meta property='og:title' content="TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する - sambaiz-net">
  <meta property="og:type" content="article">
  
  <meta name="description" content="CPU/GPU/TPUでCNNを学習させて実行時間を比較する">
  <meta name="twitter:description" content="CPU/GPU/TPUでCNNを学習させて実行時間を比較する">
  
  

  <meta property="og:url" content="https://www.sambaiz.net/article/199/">
  <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
  <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />

  

<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id": "https://www.sambaiz.net/"
    },
    "headline": "TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する",
    "datePublished": "2018-11-27T09:57:00JST",
    "dateModified": "2018-11-27T09:57:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "url": "https://www.sambaiz.net/",
      "image": "https://www.sambaiz.net/images/my.jpg"
    },
    "publisher": {
      "@type": "Person",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.sambaiz.net/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https://www.sambaiz.net/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "CPU/GPU/TPUでCNNを学習させて実行時間を比較する"
  }
</script>
</head>

<body>
  
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NCML2RV"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  
  <div>
    <div class="languages">
      
    </div>

    <header>
      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" alt="icon" />
        <a class="nl" href='/'>
          <h1>sambaiz-net</h1>
        </a>
      </div>

      <div class="sns">
        <div class="sns-item">
          <a class="nl" href="https://twitter.com/sambaiz">
            <img src="/image/twitter.png" width="30px" height="30px" alt="twitter">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://github.com/sambaiz">
            <img src="/image/github.png" width="30px" height="30px" alt="github">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://bookmeter.com/users/1060169/books/read">
            <img src="/image/bookmeter.png" width="30px" height="30px" alt="bookmeter">
          </a>
        </div>
        <div class="sns-item">
          <a href="https://filmarks.com/users/sambaiz" class="filmarks" aria-label="filmarks"></a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://www.alltrails.com/members/taiki-sakamoto/recordings">
            <img src="/image/alltrails.png" width="30px" height="30px" alt="alltrails">
          </a>
        </div>
      </div>
      <div class="tags">
        <div>
          
          <a class="tag" href="/tags/aws/">
            aws</a>
          
          <a class="tag" href="/tags/golang/">
            golang</a>
          
          <a class="tag" href="/tags/machinelearning/">
            machinelearning</a>
          
          <a class="tag" href="/tags/python/">
            python</a>
          
          <a class="tag" href="/tags/kubernetes/">
            kubernetes</a>
          
          <a class="tag" href="/tags/log/">
            log</a>
          
          <a class="tag" href="/tags/docker/">
            docker</a>
          
          <a class="tag" href="/tags/gcp/">
            gcp</a>
          
          <a class="tag" href="/tags/fluentd/">
            fluentd</a>
          
          <a class="tag" href="/tags/infra/">
            infra</a>
          
          <a class="tag others" href="/tags/">...</a>
        </div>
      </div>
    </header>

<div class="container">
  <article class="single">
    <div class="cell">
      <div class="single-header">
        <h1>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</h1>
        <time>2018-11-27</time>
        <a class="tag" href='/tags/machinelearning/'>machinelearning</a><a class="tag" href='/tags/tensorflow/'>tensorflow</a>
      </div>
      <p>TPU(Tensor Processing Unit)は
Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。
<a href="https://cloudplatform-jp.googleblog.com/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu.html">一般的なGPUと比べて15~30倍もの性能が出る</a>
らしく検索や翻訳などGoogleのサービスでも使われている。</p>
<p>TPUを使える環境として、無料で使えるJupyter Notebooksの<a href="https://colab.research.google.com/">Google Colab</a>と
GCPの<a href="https://cloud.google.com/tpu/">Cloud TPU</a>がある。ColabのTPUも裏側ではCloud TPUが動いている。
Cloud TPUを直に使うとVMから接続して使うことになるので、TPUの<a href="https://cloud.google.com/tpu/docs/pricing">料金</a>に加えてVMの料金もかかる。</p>
<h2 id="モデルのtpu対応">モデルのTPU対応</h2>
<p>CNNのモデルを<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimator">TPUEstimator</a>でTPUに対応させる。</p>
<p><a href="https://www.tensorflow.org/guide/estimators">Estimator</a>はTensorFlowの高レベルAPIで、
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#train">train()</a>、
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate">evaluate()</a>、
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#predict">predict()</a>、
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#export_saved_model">export_saved_model()</a>
といったモデルの学習から保存まで必要な機能を一通り提供する。</p>
<p>初めは比較的低レベルのAPIを使おうとしていたが、XLA(Accelerated Linear Algebra)によるコンパイルがうまくいかないなど様々な問題にあたって大変だったので使っておくと良いと思う。
それでもトライアンドエラーの繰り返しで、典型的なものは<a href="https://cloud.google.com/tpu/docs/troubleshooting">Troubleshooting</a>にあるが、ないものは調べるなりしてなんとかやっていくしかない。</p>
<p>定数などの定義。BATCH_SIZEはCloud TPUのシャード数の8で割り切れる値にする必要がある。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">import</span> pandas <span style="color:#00f">as</span> pd
<span style="color:#00f">from</span> sklearn.model_selection <span style="color:#00f">import</span> train_test_split
<span style="color:#00f">import</span> tensorflow <span style="color:#00f">as</span> tf
<span style="color:#00f">import</span> numpy <span style="color:#00f">as</span> np
flags = tf.app.flags
flags.DEFINE_boolean(<span style="color:#a31515">&#39;use_tpu&#39;</span>, True, <span style="color:#a31515">&#39;use tpu or not&#39;</span>)
tf.app.flags.DEFINE_string(<span style="color:#a31515">&#39;f&#39;</span>, <span style="color:#a31515">&#39;&#39;</span>, <span style="color:#a31515">&#39;kernel&#39;</span>)
FLAGS = flags.FLAGS

EPOCH_NUM = 100
BATCH_SIZE = 800 <span style="color:#008000"># must be divisible by number of replicas 8</span>
EVAL_BATCH_SIZE = 800
SHARD_NUM = 8 <span style="color:#008000"># A single Cloud TPU has 8 shards.</span>
ITERATION_NUM = 100 <span style="color:#008000"># Number of training steps to run on the Cloud TPU before returning control.</span>
</code></pre></div><h3 id="入力データの準備">入力データの準備</h3>
<p>入力は関数で渡し、tf.data APIのdatasetを返せばイテレートしてくれる。</p>
<p><a href="https://www.sambaiz.net/article/195/">TensorFlowのtf.data API - sambaiz-net</a></p>
<p>batch()でdrop_remainderをTrueにして端数を切り捨てないと、shapeが確定せずコンパイルできない。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">from</span> google.colab <span style="color:#00f">import</span> auth
<span style="color:#00f">from</span> googleapiclient.discovery <span style="color:#00f">import</span> build
<span style="color:#00f">from</span> io <span style="color:#00f">import</span> BytesIO

auth.authenticate_user()
bucket = <span style="color:#a31515">&#34;&lt;bucket_name&gt;&#34;</span>
gcs_service = build(<span style="color:#a31515">&#39;storage&#39;</span>, <span style="color:#a31515">&#39;v1&#39;</span>)
train_data = gcs_service.objects().get_media(bucket=bucket, object=<span style="color:#a31515">&#39;train.csv&#39;</span>).execute()
train = pd.read_csv(BytesIO(train_data))

MODEL_DIR = <span style="color:#a31515">&#39;gs://{}/model/tpu&#39;</span>.format(bucket)

(x_train, x_valid, y_train, y_valid) = train_test_split(
    train.drop(<span style="color:#a31515">&#39;label&#39;</span>, axis=1).values.reshape((-1, 28, 28, 1)).astype(np.float32), 
    np.identity(10)[train[<span style="color:#a31515">&#39;label&#39;</span>]].astype(np.float32), 
    test_size = 0.1, random_state = 100)

<span style="color:#00f">def</span> train_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({<span style="color:#a31515">&#39;x&#39;</span>: x_train}, y_train)) <span style="color:#008000"># (features, labels)</span>
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(params[<span style="color:#a31515">&#39;batch_size&#39;</span>], drop_remainder=True)
    <span style="color:#00f">return</span> dataset

<span style="color:#00f">def</span> valid_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({<span style="color:#a31515">&#39;x&#39;</span>: x_valid}, y_valid))
    dataset = dataset.batch(params[<span style="color:#a31515">&#39;batch_size&#39;</span>], drop_remainder=True)
    <span style="color:#00f">return</span> dataset
</code></pre></div><p>入出力するファイルはローカルではなくGCSなどに置く必要があるのでCloud TPUからも読み書きできるようにする。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-json" data-lang="json">{
    &#34;domain&#34;: <span style="color:#a31515">&#34;global&#34;</span>,
    &#34;reason&#34;: <span style="color:#a31515">&#34;forbidden&#34;</span>,
    &#34;message&#34;: <span style="color:#a31515">&#34;service-******@cloud-tpu.iam.gserviceaccount.com does not have storage.objects.create access to &lt;bucket_name&gt;.&#34;</span>
}
</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">!gsutil acl ch -u service-*****@cloud-tpu.iam.gserviceaccount.com:WRITER gs://&lt;bucket_name&gt;
</code></pre></div><h3 id="モデルの作成">モデルの作成</h3>
<p>Estimatorには次のシグネチャのmodel_fnを渡す。
引数のfeaturesとlabelsはinput_fnの返り値で、
modeは<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys">tf.estimator.ModeKeys</a>の<code>TRAIN</code>、<code>EVAL</code>、<code>PREDICT</code>で、
paramsはEstimator生成時に渡せるパラメータ。
optimizerは<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/CrossShardOptimizer">CrossShardOptimizer</a>で<a href="https://www.tensorflow.org/guide/using_tpu#optimizer">wrapする</a>。</p>
<p>TPUに対応している<a href="https://cloud.google.com/tpu/docs/tensorflow-ops">op</a>で作る必要がある。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">def</span> model_fn(features, labels, mode, params):
    <span style="color:#00f">def</span> metric_fn(labels, logits):
        <span style="color:#00f">return</span> {
            <span style="color:#a31515">&#39;accuracy&#39;</span>: tf.metrics.accuracy(
                labels=tf.argmax(labels, axis=1), predictions=tf.argmax(logits, axis=1))
         }
    is_training = tf.equal(mode, tf.estimator.ModeKeys.TRAIN)
    conv1 = tf.layers.conv2d(
        inputs=features[<span style="color:#a31515">&#39;x&#39;</span>],
        filters=32, 
        kernel_size=[5, 5], 
        padding=<span style="color:#a31515">&#34;same&#34;</span>, 
        activation=tf.nn.relu)
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)
    conv2 = tf.layers.conv2d(
        inputs=pool1, 
        filters=64, 
        kernel_size=[5, 5],
        padding=<span style="color:#a31515">&#34;same&#34;</span>, 
        activation=tf.nn.relu)
    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
    pool2_flat = tf.layers.flatten(pool2)
    dense = tf.layers.dense(inputs=pool2_flat, units=128, activation=tf.nn.relu)
    dropout = tf.layers.dropout(
        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)
    logits = tf.layers.dense(inputs=dropout, units=10)

    loss = tf.losses.softmax_cross_entropy(
        onehot_labels=labels, logits=logits)
    
    <span style="color:#00f">if</span> mode == tf.estimator.ModeKeys.EVAL:
        <span style="color:#00f">return</span> tf.contrib.tpu.TPUEstimatorSpec(mode, loss=loss, 
                                               eval_metrics=(metric_fn, [labels, logits]))

    optimizer = tf.train.AdamOptimizer(0.01)
    <span style="color:#00f">if</span> FLAGS.use_tpu:
        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)

    <span style="color:#00f">return</span> tf.contrib.tpu.TPUEstimatorSpec(
        mode=mode,
        loss=loss,
        predictions={
            <span style="color:#a31515">&#39;pred&#39;</span>: tf.argmax(logits, axis=1)
        },
        train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))
</code></pre></div><h3 id="tpuestimatorの生成">TPUEstimatorの生成</h3>
<p>TPUのアドレスが環境変数COLAB_TPU_ADDRに入るのでこれをmasterとする。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">if</span> FLAGS.use_tpu:
    master = <span style="color:#a31515">&#39;grpc://&#39;</span> + os.environ[<span style="color:#a31515">&#39;COLAB_TPU_ADDR&#39;</span>]
    run_config = tf.contrib.tpu.RunConfig(
        master=master,
        session_config=tf.ConfigProto(
            allow_soft_placement=True, log_device_placement=True),
        tpu_config=tf.contrib.tpu.TPUConfig(ITERATION_NUM, SHARD_NUM))
<span style="color:#00f">else</span>:
    run_config = tf.contrib.tpu.RunConfig()

classifier = tf.contrib.tpu.TPUEstimator(
    model_fn=model_fn,
    model_dir=MODEL_DIR,
    config=run_config,
    params={},
    train_batch_size=BATCH_SIZE,
    eval_batch_size=EVAL_BATCH_SIZE,
    predict_batch_size=BATCH_SIZE,
    use_tpu=FLAGS.use_tpu)
</code></pre></div><h3 id="学習">学習</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">for</span> epoch <span style="color:#00f">in</span> range(EPOCH_NUM):
  max_steps = len(x_train)*(epoch+1)//BATCH_SIZE
  valid_steps = len(x_valid)//EVAL_BATCH_SIZE
  <span style="color:#00f">if</span> FLAGS.use_tpu: 
    max_steps //= SHARD_NUM
  train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_steps)
  eval_spec = tf.estimator.EvalSpec(input_fn=valid_input_fn, steps=valid_steps)
  result = tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
  <span style="color:#00f">if</span> result[0] <span style="color:#00f">is</span> <span style="color:#00f">not</span> None:
    <span style="color:#00f">print</span>(<span style="color:#a31515">&#39;epoch: {}, loss: {} accuracy: {}&#39;</span>.format(epoch+1, result[0][<span style="color:#a31515">&#39;loss&#39;</span>], result[0][<span style="color:#a31515">&#39;accuracy&#39;</span>]))
  <span style="color:#00f">else</span>:
    <span style="color:#00f">print</span>(<span style="color:#a31515">&#39;epoch: {} is already trained&#39;</span>.format(epoch+1))
</code></pre></div><h3 id="colabでtensorboardを開く">ColabでTensorBoardを開く</h3>
<p>このスクリプトを実行するとTensorBoardを立ち上げてngrokで外に開いてくれる。</p>
<p><a href="https://github.com/mixuala/colab_utils">mixuala/colab_utils</a></p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="">!</span>git clone https://github.com/mixuala/colab_utils
<span style="color:#00f">import</span> os
<span style="color:#00f">import</span> colab_utils.tboard

<span style="color:#008000"># set paths</span>
ROOT = %pwd
colab_utils.tboard.launch_tensorboard(bin_dir=ROOT, log_dir=MODEL_DIR)
</code></pre></div><h2 id="結果">結果</h2>
<p>学習させて実行時間を計測する。計測はセルの頭に<code>%%time</code>を付けるとできる。</p>
<h3 id="cpu">CPU</h3>
<p>ベースライン。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">CPU times: user 18min 28s, sys: 32.8 s, total: 19min 1s
Wall time: 14min 33s
</code></pre></div><h3 id="gpu">GPU</h3>
<p>ランタイムからアクセラレータをGPUに設定。使われるGPUはNVIDIAの<a href="https://www.nvidia.co.jp/object/tesla-k80-jp.html">Tesla K80</a>。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">from</span> tensorflow.python.client <span style="color:#00f">import</span> device_lib
device_lib.list_local_devices()
<span style="color:#008000"># ...</span>
<span style="color:#008000"># physical_device_desc: &#34;device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7&#34;]</span>
</code></pre></div><p>結果。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">CPU times: user 3min 2s, sys: 24.2 s, total: 3min 26s
Wall time: 8min 6s
</code></pre></div><h3 id="tpu">TPU</h3>
<p>アクセラレータをTPUに変更。
GPUより速くなることを期待したが、むしろCPUよりも遅くなってしまった。その上精度の伸びも遅くて良いところがない。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">CPU times: user 3min, sys: 23.8 s, total: 3min 24s
Wall time: 15min
</code></pre></div><h2 id="再チャレンジ">再チャレンジ</h2>
<p>エポックの立ち上がりが遅いので学習を切らずに続けて行わせてみる。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">def</span> train_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({<span style="color:#a31515">&#39;x&#39;</span>: x_train}, y_train)) <span style="color:#008000"># (features, labels)</span>
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(params[<span style="color:#a31515">&#39;batch_size&#39;</span>], drop_remainder=True)
    dataset = dataset.repeat(EPOCH_NUM)
    <span style="color:#00f">return</span> dataset

epoch = EPOCH_NUM-1
max_steps = len(x_train)*(epoch+1)/BATCH_SIZE
valid_steps = len(x_valid)//EVAL_BATCH_SIZE
<span style="color:#00f">if</span> FLAGS.use_tpu: 
  max_steps //= SHARD_NUM
train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_steps)
eval_spec = tf.estimator.EvalSpec(input_fn=valid_input_fn, steps=valid_steps)
result = tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
<span style="color:#00f">if</span> result[0] <span style="color:#00f">is</span> <span style="color:#00f">not</span> None:
  <span style="color:#00f">print</span>(<span style="color:#a31515">&#39;epoch: {}, loss: {} accuracy: {}&#39;</span>.format(epoch+1, result[0][<span style="color:#a31515">&#39;loss&#39;</span>],  result[0][<span style="color:#a31515">&#39;accuracy&#39;</span>]))
<span style="color:#00f">else</span>:
  <span style="color:#00f">print</span>(<span style="color:#a31515">&#39;epoch: {} is already trained&#39;</span>.format(epoch+1))
</code></pre></div><p>これを実行したところGPUと同程度には速くなった。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback"># GPU
CPU times: user 40.9 s, sys: 7.8 s, total: 48.7 s
Wall time: 1min 43s

# TPU
CPU times: user 35.2 s, sys: 4.46 s, total: 39.7 s
Wall time: 1min 34s
</code></pre></div><p>さらにEPOCH_NUMを5から100にして再計測する。</p>
<h2 id="結果-1">結果</h2>
<h3 id="gpu-1">GPU</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">CPU times: user 3min 27s, sys: 2min, total: 5min 28s
Wall time: 6min 5s
</code></pre></div><h3 id="tpu-1">TPU</h3>
<p>エポック数を大幅に増やしたのにも関わらずほとんど実行時間が変わらずとても速い。
CPU時間も変わっていないので演算がTPUで完結していてCPU-TPU間のデータの受け渡しが最小限で済んでいるのかもしれない。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">CPU times: user 34.5 s, sys: 7.32 s, total: 41.8 s
Wall time: 1min 38s
</code></pre></div><h2 id="参考">参考</h2>
<p><a href="https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d">Google Colab Free GPU Tutorial – Deep Learning Turkey – Medium</a></p>
<p><a href="https://qiita.com/koshian2/items/fb989cebe0266d1b32fc">Google ColabのTPUで対GPUの最速に挑戦する - Qiita</a></p>

    </div>
    <div class="share">
      <div class="cell">
        <div>share</div>
        <div>
          <a class="share-button" href='https://twitter.com/intent/tweet?url=https://www.sambaiz.net/article/199/&text=TensorFlow%e3%81%ae%e3%83%a2%e3%83%87%e3%83%ab%e3%82%92TPU%e3%81%ab%e5%af%be%e5%bf%9c%e3%81%95%e3%81%9b%e3%81%a6Colab%e3%81%a7%e5%ad%a6%e7%bf%92%e3%81%97%e5%ae%9f%e8%a1%8c%e6%99%82%e9%96%93%e3%82%92%e8%a8%88%e6%b8%ac%e3%81%99%e3%82%8b%20-%20sambaiz-net'>
            <img src="/image/twitter.png" width="40px" height="40px" alt="twitter">
          </a>
          <a href="https://b.hatena.ne.jp/entry/" class="share-button hatena-bookmark-button" data-hatena-bookmark-layout="touch" data-hatena-bookmark-width="40" data-hatena-bookmark-height="40" title="このエントリーをはてなブックマークに追加">
            <img src="https://b.st-hatena.com/images/v4/public/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="40" height="40" style="border: none;" />
          </a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
        </div>
      </div>
    </div>
  </article>
</div>

</div>
</body>

</html>