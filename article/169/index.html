<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Hugo 0.75.1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="/css/destyle.css">
  <style>
    body {
        background-color: #f1f1f1;
        line-height: 1.3;
    }

    header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
    }

    header>.title {
        font-size: 1.875rem;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns {
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns-item {
        display: inline-block;
        margin: 3px;
    }

    .filmarks {
        display: inline-block;
        width: 30px;
        height: 30px;
        margin-top: 3px;
        background: url(/image/filmarks.svg) no-repeat;
        background-size: 450%;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
    }

    .nl {
        display: inline-block;
    }

    .cell {
        background-color: #fff;
        border-radius: 5px;
        padding: 10px;
        box-shadow: 0 1px 1px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
    }

    time {
        color: #333;
    }

     
    .paging {
        display: inline-block;
        font-size: 1.25rem;
        margin: 10px 10px;
    }

    .paging.next {
        float: right;
    }


     
    .list>.title {
        font-size: 1.75rem;
        margin: 0 0 10px 10px;
    }

     
    .grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(262px, 1fr));
        gap: 20px;
        margin: 0 10px;
    }

    .grid-nl {
        width: 100%;
    }

    .grid-cell {
        height: 11.25rem;
        overflow: hidden;
        box-sizing: content-box;
    }

    .grid-cell>.title {
        font-size: 1.5rem;
        word-wrap: break-word;
    }

     
    .single {
        margin: 0 10px 20px 10px;
        line-height: 1.5;
    }

    @media screen and (min-width: 768px) {
        .single .cell {
            padding: 10px 20px;
        }
    }

    .single-header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
        line-height: 1.3;
    }

    .single-header h1 {
        font-size: 2rem;
        font-weight: bold;
    }

    .single h2 {
        font-size: 1.8rem;
        border-bottom: 1px solid #ddd;
        margin-block-start: 1.875rem;
    }

    .single a {
        color: #3a9240;
    }

    .single a:hover {
        text-decoration: underline;
    }

    .single p {
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single p>code {
        background-color: #eee;
        color: #333;
        padding: 0 0.2rem;
        display: inline-block;
        overflow: auto;
        max-width: 100%;
        vertical-align: bottom;
    }

    .single .highlight {
        box-shadow: 0 1px 1px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
    }

    .single .highlight>pre {
        padding: 10px;
        overflow-x: auto;
    }

    .single img {
        max-width: 100%;
    }

    .single blockquote {}

    .single hr {}
</style>
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">
  <link rel="icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">

  <meta name="theme-color" content="#41a248">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@sambaiz">
  
  <title>ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す - sambaiz-net</title>
  <meta name="twitter:title" content="ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す - sambaiz-net">
  <meta property='og:title' content="ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す - sambaiz-net">
  <meta property="og:type" content="article">
  
  <meta name="description" content="ベイズ最適化">
  <meta name="twitter:description" content="ベイズ最適化">
  
  

  <meta property="og:url" content="https://www.sambaiz.net/article/169/">
  <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
  <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />
  <meta name="google-site-verification" content="CEqNYjzc4Y7hb3FY7uUkmllGzeDc40brBwQJixeH61Q" />
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id":"https:\/\/www.sambaiz.net\/"
    },
    "headline": "ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す - sambaiz-net",
    "datePublished": "2018-06-10T17:50:00JST",
    "dateModified": "2018-06-10T17:50:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "image": "https:\/\/www.sambaiz.net\/images/my.jpg"
    },
    "publisher": {
      "@type": "Person",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https:\/\/www.sambaiz.net\/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https:\/\/www.sambaiz.net\/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "ベイズ最適化"
  }
</script>
</head>

<body>
  <div>
    <header>
      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" alt="アイコン" />
        <a class="nl" href="https://www.sambaiz.net/">
          <h1>sambaiz-net</h1>
        </a>
      </div>

      <div class="sns">
        <div class="sns-item">
          <a class="nl" href="https://twitter.com/sambaiz">
            <img src="//www.sambaiz.net/image/twitter.png" width="30px" height="30px" alt="twitter">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://github.com/sambaiz">
            <img src="//www.sambaiz.net/image/github.png" width="30px" height="30px" alt="github">
          </a>
        </div>
        <div class="sns-item">
          <a href="https://filmarks.com/users/sambaiz" class="filmarks" aria-label="filmarks"></a>
        </div>
      </div>
    </header>

<div class="container">
  <article class="single">
    <div class="cell">
      <div class="single-header">
        <h1>ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す</h1>
        <time>2018-06-10</time>
      </div>
      <p>ベイズ最適化で良いハイパーパラメータを総当りのグリッドサーチより効率的に探す。</p>
<p>まず現在の最大値を超える確率や期待値を出力とする獲得関数を決めて、ガウス過程(GP)に従うと仮定する。
ガウス過程は回帰関数の確率モデルで、任意の入力(x1, x2, &hellip; , xn)に対応する出力(y1, y2, &hellip;, yn)がガウス分布(=正規分布)に従うというもの。
これによって予測されるまだ試していない入力での期待値や分散から次に試す値を決める。</p>
<p>今回はKaggleのTitanicのチュートリアルを、チューニングなしのランダムフォレストとXGBoostで解いたときの結果と比較して、ベイズ最適化によるハイパーパラメータで精度が向上するか確認する。</p>
<p><a href="https://www.sambaiz.net/article/166/">KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net</a></p>
<p><a href="https://www.sambaiz.net/article/168/">KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net</a></p>
<h2 id="ランダムフォレスト">ランダムフォレスト</h2>
<p>Pythonのベイズ最適化のライブラリ、<a href="https://github.com/fmfn/BayesianOptimization">BayesianOptimization</a>を使う。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">$ pip install bayesian-optimization
</code></pre></div><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">RandomForestClassifier</a>のハイパーパラメータ</p>
<ul>
<li>n_estimators: 木の数</li>
<li>min_samples_split: ノードを分割するのに必要な最小サンプル数</li>
<li>max_features: 分割するときに考慮する特徴量の割合</li>
</ul>
<p>の値を探すため、<code>BayesianOptimization</code>に最大化したい値(精度)とパラメータの範囲を渡す。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#ff79c6">from</span> sklearn.model_selection <span style="color:#ff79c6">import</span> cross_val_score
<span style="color:#ff79c6">from</span> sklearn.ensemble <span style="color:#ff79c6">import</span> RandomForestClassifier
<span style="color:#ff79c6">from</span> bayes_opt <span style="color:#ff79c6">import</span> BayesianOptimization

<span style="color:#ff79c6">import</span> pandas <span style="color:#ff79c6">as</span> pd

<span style="color:#ff79c6">def</span> <span style="color:#50fa7b">preprocess</span>(df):
    df[<span style="color:#f1fa8c">&#39;Fare&#39;</span>] <span style="color:#ff79c6">=</span> df[<span style="color:#f1fa8c">&#39;Fare&#39;</span>]<span style="color:#ff79c6">.</span>fillna(df[<span style="color:#f1fa8c">&#39;Fare&#39;</span>]<span style="color:#ff79c6">.</span>mean())
    df[<span style="color:#f1fa8c">&#39;Age&#39;</span>] <span style="color:#ff79c6">=</span> df[<span style="color:#f1fa8c">&#39;Age&#39;</span>]<span style="color:#ff79c6">.</span>fillna(df[<span style="color:#f1fa8c">&#39;Age&#39;</span>]<span style="color:#ff79c6">.</span>mean())
    df[<span style="color:#f1fa8c">&#39;Embarked&#39;</span>] <span style="color:#ff79c6">=</span> df[<span style="color:#f1fa8c">&#39;Embarked&#39;</span>]<span style="color:#ff79c6">.</span>fillna(<span style="color:#f1fa8c">&#39;Unknown&#39;</span>)
    df[<span style="color:#f1fa8c">&#39;Sex&#39;</span>] <span style="color:#ff79c6">=</span> df[<span style="color:#f1fa8c">&#39;Sex&#39;</span>]<span style="color:#ff79c6">.</span>apply(<span style="color:#ff79c6">lambda</span> x: <span style="color:#bd93f9">1</span> <span style="color:#ff79c6">if</span> x <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#39;male&#39;</span> <span style="color:#ff79c6">else</span> <span style="color:#bd93f9">0</span>)
    df[<span style="color:#f1fa8c">&#39;Embarked&#39;</span>] <span style="color:#ff79c6">=</span> df[<span style="color:#f1fa8c">&#39;Embarked&#39;</span>]<span style="color:#ff79c6">.</span>map( {<span style="color:#f1fa8c">&#39;S&#39;</span>: <span style="color:#bd93f9">0</span>, <span style="color:#f1fa8c">&#39;C&#39;</span>: <span style="color:#bd93f9">1</span>, <span style="color:#f1fa8c">&#39;Q&#39;</span>: <span style="color:#bd93f9">2</span>, <span style="color:#f1fa8c">&#39;Unknown&#39;</span>: <span style="color:#bd93f9">3</span>} )<span style="color:#ff79c6">.</span>astype(<span style="color:#8be9fd;font-style:italic">int</span>)
    df <span style="color:#ff79c6">=</span> df<span style="color:#ff79c6">.</span>drop([<span style="color:#f1fa8c">&#39;Cabin&#39;</span>,<span style="color:#f1fa8c">&#39;Name&#39;</span>,<span style="color:#f1fa8c">&#39;PassengerId&#39;</span>,<span style="color:#f1fa8c">&#39;Ticket&#39;</span>],axis<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>)
    <span style="color:#ff79c6">return</span> df

df <span style="color:#ff79c6">=</span> preprocess(pd<span style="color:#ff79c6">.</span>read_csv(<span style="color:#f1fa8c">&#39;./train.csv&#39;</span>))
train_x <span style="color:#ff79c6">=</span> df<span style="color:#ff79c6">.</span>drop(<span style="color:#f1fa8c">&#39;Survived&#39;</span>, axis<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>)
train_y <span style="color:#ff79c6">=</span> df<span style="color:#ff79c6">.</span>Survived

<span style="color:#ff79c6">def</span> <span style="color:#50fa7b">randomforest_cv</span>(n_estimators, min_samples_split, max_features):
    val <span style="color:#ff79c6">=</span> cross_val_score(
        RandomForestClassifier(
            n_estimators<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">int</span>(n_estimators),
            min_samples_split<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">int</span>(min_samples_split),
            max_features<span style="color:#ff79c6">=</span>max_features,
            random_state<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0</span>
        ),
        train_x, train_y,
        scoring <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#39;accuracy&#39;</span>,
        cv <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">3</span>, <span style="color:#6272a4"># 3-fold</span>
        n_jobs <span style="color:#ff79c6">=</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span> <span style="color:#6272a4"># use all CPUs</span>
    )<span style="color:#ff79c6">.</span>mean()
    <span style="color:#ff79c6">return</span> val

randomforest_cv_bo <span style="color:#ff79c6">=</span> BayesianOptimization(
    randomforest_cv,
    {<span style="color:#f1fa8c">&#39;n_estimators&#39;</span>: (<span style="color:#bd93f9">10</span>, <span style="color:#bd93f9">250</span>),
    <span style="color:#f1fa8c">&#39;min_samples_split&#39;</span>: (<span style="color:#bd93f9">2</span>, <span style="color:#bd93f9">25</span>),
    <span style="color:#f1fa8c">&#39;max_features&#39;</span>: (<span style="color:#bd93f9">0.1</span>, <span style="color:#bd93f9">0.999</span>)}
)

gp_params <span style="color:#ff79c6">=</span> {<span style="color:#f1fa8c">&#34;alpha&#34;</span>: <span style="color:#bd93f9">1e-5</span>}
randomforest_cv_bo<span style="color:#ff79c6">.</span>maximize(n_iter<span style="color:#ff79c6">=</span><span style="color:#bd93f9">50</span>, <span style="color:#ff79c6">**</span>gp_params)
<span style="color:#ff79c6">print</span>(randomforest_cv_bo<span style="color:#ff79c6">.</span>res[<span style="color:#f1fa8c">&#39;max&#39;</span>][<span style="color:#f1fa8c">&#39;max_val&#39;</span>])
<span style="color:#ff79c6">print</span>(randomforest_cv_bo<span style="color:#ff79c6">.</span>res[<span style="color:#f1fa8c">&#39;max&#39;</span>][<span style="color:#f1fa8c">&#39;max_params&#39;</span>])
</code></pre></div><p>まずinit_points回<a href="https://github.com/fmfn/BayesianOptimization/blob/0.6.0/bayes_opt/bayesian_optimization.py#L84">ランダムな値で試して</a>、
それらの結果を起点にベイズ最適化で探していく。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-json" data-lang="json">Initialization
-------------------------------------------------------------------------------------
 Step |   Time |      Value |   max_features |   min_samples_split |   n_estimators | 
    <span style="color:#bd93f9">1</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.82267</span> |         <span style="color:#bd93f9">0.7470</span> |             <span style="color:#bd93f9">23.8836</span> |       <span style="color:#bd93f9">103.9041</span> | 
    <span style="color:#bd93f9">2</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.81818</span> |         <span style="color:#bd93f9">0.2784</span> |             <span style="color:#bd93f9">12.4106</span> |       <span style="color:#bd93f9">188.5984</span> | 
    <span style="color:#bd93f9">3</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.82267</span> |         <span style="color:#bd93f9">0.4745</span> |              <span style="color:#bd93f9">9.1743</span> |        <span style="color:#bd93f9">16.8421</span> | 
    <span style="color:#bd93f9">4</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.82267</span> |         <span style="color:#bd93f9">0.6617</span> |              <span style="color:#bd93f9">4.7600</span> |       <span style="color:#bd93f9">222.8920</span> | 
    <span style="color:#bd93f9">5</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.81033</span> |         <span style="color:#bd93f9">0.3057</span> |              <span style="color:#bd93f9">9.2044</span> |        <span style="color:#bd93f9">42.1871</span> | 
Bayesian Optimization
-------------------------------------------------------------------------------------
 Step |   Time |      Value |   max_features |   min_samples_split |   n_estimators | 
    <span style="color:#bd93f9">6</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">08</span>s |    <span style="color:#bd93f9">0.82043</span> |         <span style="color:#bd93f9">0.5444</span> |             <span style="color:#bd93f9">24.5978</span> |       <span style="color:#bd93f9">249.8593</span> | 
    <span style="color:#bd93f9">7</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">08</span>s |    <span style="color:#bd93f9">0.81033</span> |         <span style="color:#bd93f9">0.3853</span> |             <span style="color:#bd93f9">24.8421</span> |       <span style="color:#bd93f9">249.9177</span> | 
    <span style="color:#bd93f9">8</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">07</span>s |    <span style="color:#bd93f9">0.79012</span> |         <span style="color:#bd93f9">0.8454</span> |              <span style="color:#bd93f9">2.2098</span> |        <span style="color:#bd93f9">10.0838</span> | 
    <span style="color:#bd93f9">9</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">05</span>s |    <span style="color:#bd93f9">0.81257</span> |         <span style="color:#bd93f9">0.6389</span> |             <span style="color:#bd93f9">24.9582</span> |        <span style="color:#bd93f9">10.1302</span> | 
...
   <span style="color:#bd93f9">54</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">13</span>s |    <span style="color:#bd93f9">0.82379</span> |         <span style="color:#bd93f9">0.9751</span> |             <span style="color:#bd93f9">24.9576</span> |        <span style="color:#bd93f9">73.5207</span> | 
   <span style="color:#bd93f9">55</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">13</span>s |    <span style="color:#bd93f9">0.82043</span> |         <span style="color:#bd93f9">0.9698</span> |             <span style="color:#bd93f9">24.9442</span> |        <span style="color:#bd93f9">65.3054</span> | 
<span style="color:#bd93f9">0.82379349046</span>
{&#39;n_estimators&#39;: 73.520665913948847, &#39;min_samples_split&#39;: 24.957568460557685, &#39;max_features&#39;: 0.97511242524537167}
</code></pre></div><p>少し精度がよくなり、性別の影響がかなり強くなった。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">0.810169491525
Sex             0.445553
Fare            0.180365
Pclass          0.162260
Age             0.147300
Embarked        0.037309
SibSp           0.014159
Parch           0.013054
</code></pre></div><h2 id="xgboost">XGBoost</h2>
<p>XGBoostでは</p>
<ul>
<li>learning_rate</li>
<li>max_depth</li>
<li>subsample</li>
<li>colsample_bytree</li>
<li>min_child_weight</li>
<li>gamma</li>
<li>alpha</li>
</ul>
<p>を探す。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#ff79c6">import</span> pandas <span style="color:#ff79c6">as</span> pd
<span style="color:#ff79c6">import</span> xgboost <span style="color:#ff79c6">as</span> xgb
<span style="color:#ff79c6">from</span> bayes_opt <span style="color:#ff79c6">import</span> BayesianOptimization

df <span style="color:#ff79c6">=</span> preprocess(pd<span style="color:#ff79c6">.</span>read_csv(<span style="color:#f1fa8c">&#39;./train.csv&#39;</span>))
train_x <span style="color:#ff79c6">=</span> df<span style="color:#ff79c6">.</span>drop(<span style="color:#f1fa8c">&#39;Survived&#39;</span>, axis<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>)
train_y <span style="color:#ff79c6">=</span> df<span style="color:#ff79c6">.</span>Survived
xgtrain <span style="color:#ff79c6">=</span> xgb<span style="color:#ff79c6">.</span>DMatrix(train_x, label<span style="color:#ff79c6">=</span>train_y)

<span style="color:#ff79c6">def</span> <span style="color:#50fa7b">xgboost_cv</span>(
    learning_rate,
    max_depth,
    subsample,
    colsample_bytree,
    min_child_weight,
    gamma,
    alpha):
    
    params <span style="color:#ff79c6">=</span> {}
    params[<span style="color:#f1fa8c">&#39;learning_rate&#39;</span>] <span style="color:#ff79c6">=</span> learning_rate
    <span style="color:#6272a4"># maximum depth of a tree, increase this value will make the model more complex / likely to be overfitting.</span>
    params[<span style="color:#f1fa8c">&#39;max_depth&#39;</span>] <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">int</span>(max_depth) 
    <span style="color:#6272a4">#  subsample ratio of the training instance. Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees and this will prevent overfitting.</span>
    params[<span style="color:#f1fa8c">&#39;subsample&#39;</span>] <span style="color:#ff79c6">=</span> subsample
    <span style="color:#6272a4"># subsample ratio of columns when constructing each tree.</span>
    params[<span style="color:#f1fa8c">&#39;colsample_bytree&#39;</span>] <span style="color:#ff79c6">=</span> colsample_bytree 
    <span style="color:#6272a4"># minimum sum of instance weight (hessian) needed in a child. The larger, the more conservative the algorithm will be.</span>
    params[<span style="color:#f1fa8c">&#39;min_child_weight&#39;</span>] <span style="color:#ff79c6">=</span> min_child_weight
    <span style="color:#6272a4"># minimum loss reduction required to make a further partition on a leaf node of the tree. The larger, the more conservative the algorithm will be.</span>
    params[<span style="color:#f1fa8c">&#39;gamma&#39;</span>] <span style="color:#ff79c6">=</span> gamma 
    <span style="color:#6272a4"># L1 regularization term on weights, increase this value will make model more conservative. </span>
    params[<span style="color:#f1fa8c">&#39;alpha&#39;</span>] <span style="color:#ff79c6">=</span> alpha 
    params[<span style="color:#f1fa8c">&#39;objective&#39;</span>] <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#39;binary:logistic&#39;</span>

    cv_result <span style="color:#ff79c6">=</span> xgb<span style="color:#ff79c6">.</span>cv(
        params,
        xgtrain,
        num_boost_round<span style="color:#ff79c6">=</span><span style="color:#bd93f9">10</span>, 
        nfold<span style="color:#ff79c6">=</span><span style="color:#bd93f9">3</span>,
        seed<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0</span>,
        <span style="color:#6272a4"># Validation error needs to decrease at least every &lt;stopping_rounds&gt; round(s) to continue training.</span>
        <span style="color:#6272a4"># callbacks=[xgb.callback.early_stop(20)]</span>
    )

    <span style="color:#ff79c6">return</span> <span style="color:#bd93f9">1.0</span> <span style="color:#ff79c6">-</span> cv_result[<span style="color:#f1fa8c">&#39;test-error-mean&#39;</span>]<span style="color:#ff79c6">.</span>values[<span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>]


xgboost_cv_bo <span style="color:#ff79c6">=</span> BayesianOptimization(xgboost_cv, 
                             {
                                 <span style="color:#f1fa8c">&#39;learning_rate&#39;</span>: (<span style="color:#bd93f9">0.1</span>, <span style="color:#bd93f9">0.9</span>),
                                 <span style="color:#f1fa8c">&#39;max_depth&#39;</span>: (<span style="color:#bd93f9">5</span>, <span style="color:#bd93f9">15</span>),
                                 <span style="color:#f1fa8c">&#39;subsample&#39;</span>: (<span style="color:#bd93f9">0.5</span>, <span style="color:#bd93f9">1</span>),
                                 <span style="color:#f1fa8c">&#39;colsample_bytree&#39;</span>: (<span style="color:#bd93f9">0.1</span>, <span style="color:#bd93f9">1</span>),
                                 <span style="color:#f1fa8c">&#39;min_child_weight&#39;</span>: (<span style="color:#bd93f9">1</span>, <span style="color:#bd93f9">20</span>),
                                 <span style="color:#f1fa8c">&#39;gamma&#39;</span>: (<span style="color:#bd93f9">0</span>, <span style="color:#bd93f9">10</span>),
                                 <span style="color:#f1fa8c">&#39;alpha&#39;</span>: (<span style="color:#bd93f9">0</span>, <span style="color:#bd93f9">10</span>),
                             })

xgboost_cv_bo<span style="color:#ff79c6">.</span>maximize(n_iter<span style="color:#ff79c6">=</span><span style="color:#bd93f9">50</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-json" data-lang="json">Initialization
---------------------------------------------------------------------------------------------------------------------------------------------
 Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   learning_rate |   max_depth |   min_child_weight |   subsample | 
    <span style="color:#bd93f9">1</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.77441</span> |    <span style="color:#bd93f9">5.3061</span> |             <span style="color:#bd93f9">0.4302</span> |    <span style="color:#bd93f9">1.1512</span> |          <span style="color:#bd93f9">0.4484</span> |      <span style="color:#bd93f9">8.4632</span> |            <span style="color:#bd93f9">16.3455</span> |      <span style="color:#bd93f9">0.5688</span> | 
    <span style="color:#bd93f9">2</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.79349</span> |    <span style="color:#bd93f9">6.5298</span> |             <span style="color:#bd93f9">0.2519</span> |    <span style="color:#bd93f9">8.8275</span> |          <span style="color:#bd93f9">0.8277</span> |      <span style="color:#bd93f9">9.6443</span> |             <span style="color:#bd93f9">8.1207</span> |      <span style="color:#bd93f9">0.5426</span> | 
    <span style="color:#bd93f9">3</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.79349</span> |    <span style="color:#bd93f9">0.4152</span> |             <span style="color:#bd93f9">0.7973</span> |    <span style="color:#bd93f9">7.5153</span> |          <span style="color:#bd93f9">0.7173</span> |      <span style="color:#bd93f9">8.2608</span> |            <span style="color:#bd93f9">12.5433</span> |      <span style="color:#bd93f9">0.7952</span> | 
    <span style="color:#bd93f9">4</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.76768</span> |    <span style="color:#bd93f9">3.9047</span> |             <span style="color:#bd93f9">0.9619</span> |    <span style="color:#bd93f9">2.0264</span> |          <span style="color:#bd93f9">0.8893</span> |      <span style="color:#bd93f9">9.8001</span> |            <span style="color:#bd93f9">18.0125</span> |      <span style="color:#bd93f9">0.8254</span> | 
    <span style="color:#bd93f9">5</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">00</span>s |    <span style="color:#bd93f9">0.77217</span> |    <span style="color:#bd93f9">3.0779</span> |             <span style="color:#bd93f9">0.2957</span> |    <span style="color:#bd93f9">3.1872</span> |          <span style="color:#bd93f9">0.4871</span> |      <span style="color:#bd93f9">8.8120</span> |            <span style="color:#bd93f9">10.6444</span> |      <span style="color:#bd93f9">0.6602</span> | 
Bayesian Optimization
---------------------------------------------------------------------------------------------------------------------------------------------
 Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   learning_rate |   max_depth |   min_child_weight |   subsample | 
    <span style="color:#bd93f9">6</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">27</span>s |    <span style="color:#bd93f9">0.78676</span> |    <span style="color:#bd93f9">8.5373</span> |             <span style="color:#bd93f9">1.0000</span> |   <span style="color:#bd93f9">10.0000</span> |          <span style="color:#bd93f9">0.9000</span> |      <span style="color:#bd93f9">5.0000</span> |            <span style="color:#bd93f9">20.0000</span> |      <span style="color:#bd93f9">0.5000</span> | 
    <span style="color:#bd93f9">7</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">38</span>s |    <span style="color:#bd93f9">0.76768</span> |   <span style="color:#bd93f9">10.0000</span> |             <span style="color:#bd93f9">1.0000</span> |   <span style="color:#bd93f9">10.0000</span> |          <span style="color:#bd93f9">0.1000</span> |      <span style="color:#bd93f9">5.0000</span> |             <span style="color:#bd93f9">1.0000</span> |      <span style="color:#bd93f9">1.0000</span> | 
    <span style="color:#bd93f9">8</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">16</span>s |    <span style="color:#bd93f9">0.67901</span> |    <span style="color:#bd93f9">0.2277</span> |             <span style="color:#bd93f9">0.1000</span> |   <span style="color:#bd93f9">10.0000</span> |          <span style="color:#bd93f9">0.1000</span> |     <span style="color:#bd93f9">15.0000</span> |            <span style="color:#bd93f9">19.9844</span> |      <span style="color:#bd93f9">0.5000</span> | 
    <span style="color:#bd93f9">9</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">36</span>s |    <span style="color:#bd93f9">0.77666</span> |    <span style="color:#bd93f9">0.0000</span> |             <span style="color:#bd93f9">0.1000</span> |   <span style="color:#bd93f9">10.0000</span> |          <span style="color:#bd93f9">0.9000</span> |      <span style="color:#bd93f9">5.0000</span> |             <span style="color:#bd93f9">1.0000</span> |      <span style="color:#bd93f9">0.5000</span> | 
...

   <span style="color:#bd93f9">55</span> | <span style="color:#bd93f9">00</span>m<span style="color:#bd93f9">20</span>s |    <span style="color:#bd93f9">0.81818</span> |    <span style="color:#bd93f9">0.3008</span> |             <span style="color:#bd93f9">1.0000</span> |    <span style="color:#bd93f9">2.5199</span> |          <span style="color:#bd93f9">0.9000</span> |     <span style="color:#bd93f9">13.8205</span> |             <span style="color:#bd93f9">3.3037</span> |      <span style="color:#bd93f9">1.0000</span> | 
<span style="color:#bd93f9">0.833894666667</span>
{&#39;learning_rate&#39;: 0.46665290052625796, &#39;max_depth&#39;: 14.985905144970891, &#39;subsample&#39;: 0.96857695798880505, &#39;colsample_bytree&#39;: 0.74722905651892868, &#39;min_child_weight&#39;: 1.1211600650692968, &#39;gamma&#39;: 0.44876616653489076, &#39;alpha&#39;: 0.13669004333540569}
</code></pre></div><p>精度は微増した。元々のパラメータもそう悪くはなかったのかもしれない。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">0.803389830508
</code></pre></div><h2 id="参考">参考</h2>
<p><a href="https://www.slideshare.net/hoxo_m/ss-77421091">機械学習のためのベイズ最適化入門</a></p>
<p><a href="http://www.ism.ac.jp/~daichi/lectures/H26-GaussianProcess/gp-lecture2-daichi.pdf">ガウス過程の基礎と教師なし学習</a></p>

    </div>
  </article>
</div>

</div>

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date(); a = s.createElement(o),
      m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-39190067-3', 'auto');
  ga('send', 'pageview');
</script>


</body>

</html>