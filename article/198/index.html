<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">

  
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NCML2RV');</script>
  

  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
  <link rel="stylesheet" href="/css/destyle.css">
  <style>
    body {
        background-color: #f1f1f1;
        line-height: 1.3;
        
        font-family: "Helvetica Neue", 
            Arial, 
            "Hiragino Kaku Gothic ProN",
            "Hiragino Sans",
            "BIZ UDPGothic",
            Meiryo,
            sans-serif;
    }

    table {
        margin-block-start: 1.5rem;
        margin-block-end: 1.5rem;
    }

    table th,table td{
        padding: 0.2rem 1.0rem;
    }

    table tr{
        border-bottom: solid 1px #eee;
    }

    .languages {
        position: absolute;
        top: 10px;
        right: 15px;
        font-size: 1.2rem;
        color: #3a9240;
    }

    header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
    }

    header>.title {
        font-size: 1.875rem;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns {
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns-item {
        display: inline-block;
        margin: 3px;
    }

    .filmarks {
        display: inline-block;
        width: 32px;
        height: 32px;
        margin-top: 3px;
        background: url(/image/filmarks.svg) no-repeat;
        background-size: 450%;
    }

    header>.tags {
        display: flex;
        justify-content: center;
        align-items: center;
        font-size: 1.2rem;
        max-width: 1000px;
        margin: auto;
        padding: 0 20px;
    }

    header>.tags .others {
        font-weight: bold;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
    }

    .nl {
        display: inline-block;
    }

    .cell {
        background-color: #fff;
        border-radius: 5px;
        padding: 10px;
        box-shadow: 0 1px 1px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
    }

    time {
        color: #333;
    }

    .tag {
        color: #3a9240;
        margin: 0 5px;
    }

    .tag:hover {
        text-decoration: underline;
    }

     
    .paging {
        display: inline-block;
        font-size: 1.25rem;
        margin: 10px 10px;
    }

    .paging.next {
        float: right;
    }


     
    .list>.title {
        font-size: 1.75rem;
        margin: 0 0 10px 10px;
    }

     
    .grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(262px, 1fr));
        gap: 20px;
        margin: 0 10px;
    }

    .grid-nl {
        width: 100%;
    }

    .grid-cell {
        height: 11.25rem;
        overflow: hidden;
        box-sizing: content-box;
    }

    .grid-cell>.title {
        font-size: 1.4rem;
        word-wrap: break-word;
    }

     
    .single {
        margin: 0 10px 10px 10px;
        line-height: 1.5;
    }

    @media screen and (min-width: 768px) {
        .single .cell {
            padding: 10px 20px;
        }
    }

    .single-header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
        line-height: 1.3;
    }

    .single-header h1 {
        font-size: 2rem;
        font-weight: bold;
    }

    .single h2 {
        font-size: 1.8rem;
        border-bottom: 1px solid #ddd;
        margin-block-start: 1.875rem;
    }

    .single h3 {
        font-size: 1.5rem;
        margin-block-start: 1.5rem;
    }

    .single h4 {
        font-size: 1.2rem;
        margin-block-start: 1rem;
    }

    .single a {
        color: #3a9240;
    }

    .single a:hover {
        text-decoration: underline;
    }

    .single p {
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    code {
        
        font-family: ui-monospace, SFMono-Regular, SF Mono, Menlo, Consolas, Liberation Mono, monospace;
    }

    .single p>code, .single li>code {
        padding: 0 0.2rem;
        display: inline-block;
        overflow: auto;
        max-width: 100%;
        vertical-align: bottom;
    }

    .single strong {
        color: #d2691e;
        font-weight: normal;
    }

    .single .highlight {
        box-shadow: 0 1px 1px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
        margin-block-start: 1rem;
        margin-block-end: 1rem;
        font-size: 0.875rem;
    }

    .single .img_container {
        margin-block-start: 0.1rem;
        margin-block-end: 0.1rem;
        text-align: center;
    }

    .single img {
        border: 1px solid #ddd;
    }

    .single .highlight>pre {
        padding: 10px;
        overflow-x: auto;
    }

    .single img {
        max-width: 100%;
    }

    .single blockquote {
        border-left: 5px solid #ddd;
        color: #777;
        padding: 1rem 0 1rem 1rem;
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single blockquote > p {
        margin-block-start: 0;
        margin-block-end: 0;
    }

    .single hr {
        color: #bbb;
        margin-block-start: 1.5rem;
        margin-block-end: 1.5rem;
    }

    .single ul {
        list-style-type: disc;
        padding-left: 1.5em;
        margin-block-end: 0.4rem;
    }
</style>
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">
  <link rel="icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">

  <meta name="theme-color" content="#41a248">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@sambaiz">
  
  <title>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する - sambaiz-net</title>
  <meta name="twitter:title" content="Deep LearningのBatch Normalizationの効果をTensorFlowで確認する - sambaiz-net">
  <meta property='og:title' content="Deep LearningのBatch Normalizationの効果をTensorFlowで確認する - sambaiz-net">
  <meta property="og:type" content="article">
  
  <meta name="description" content="各層の入力を正規化する">
  <meta name="twitter:description" content="各層の入力を正規化する">
  
  

  <meta property="og:url" content="https://www.sambaiz.net/article/198/">
  <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
  <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />

  

  
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id": "https://www.sambaiz.net/"
    },
    "headline": "Deep LearningのBatch Normalizationの効果をTensorFlowで確認する",
    "datePublished": "2018-11-14T02:52:00JST",
    "dateModified": "2018-11-14T02:52:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "url": "https://www.sambaiz.net/",
      "image": "https://www.sambaiz.net/images/my.jpg"
    },
    "publisher": {
      "@type": "Person",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.sambaiz.net/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https://www.sambaiz.net/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "各層の入力を正規化する"
  }
</script>
</head>

<body>
  
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NCML2RV"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  
  <div>
    <div class="languages">
      
    </div>

    <header>
      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" alt="icon" />
        <a class="nl" href='/'>
          <h1>sambaiz-net</h1>
        </a>
      </div>

      <div class="sns">
        <div class="sns-item">
          <a class="nl" href="https://github.com/sambaiz">
            <img src="/image/github.png" width="30px" height="30px" alt="github">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://www.google.com/maps/contrib/102687103399829824749/photos">
            <img src="/image/googlemaps.svg" width="30px" height="30px" alt="google maps">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://boardgamearena.com/player?id=83835726">
            <img src="/image/boardgamearena.webp" width="30px" height="30px" alt="board game arena">
          </a>
        </div>
      </div>
      <div class="tags">
        <div>
          
          <a class="tag" href="/tags/aws/">
            aws</a>
          
          <a class="tag" href="/tags/golang/">
            golang</a>
          
          <a class="tag" href="/tags/machinelearning/">
            machinelearning</a>
          
          <a class="tag" href="/tags/kubernetes/">
            kubernetes</a>
          
          <a class="tag" href="/tags/python/">
            python</a>
          
          <a class="tag" href="/tags/etl/">
            etl</a>
          
          <a class="tag" href="/tags/gcp/">
            gcp</a>
          
          <a class="tag" href="/tags/spark/">
            spark</a>
          
          <a class="tag" href="/tags/web/">
            web</a>
          
          <a class="tag" href="/tags/fluentd/">
            fluentd</a>
          
          <a class="tag others" href="/tags/">...</a>
        </div>
      </div>
    </header>

<div class="container">
  <article class="single">
    <div class="cell">
      <div class="single-header">
        <h1>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する</h1>
        <time>2018-11-14</time>
        <a class="tag" href='/tags/machinelearning/'>machinelearning</a><a class="tag" href='/tags/tensorflow/'>tensorflow</a>
      </div>
      <h2 id="batch-normalizationとは">Batch Normalizationとは</h2>
<p>Deep Learningでは各層の学習を同時に行うため、前の層の変更によって各層の入力の分布が変わってしまうinternal covariate shiftという現象が起こり、そのためにパラメータの初期化をうまくやる必要があったり、学習率を大きくできず多くのステップを要する。
以下の論文で発表されたBatch Normalization(BN)は各層の入力を正規化して分布を固定することでこれを解決するというもの。
画像認識のコンテスト<a href="http://image-net.org/challenges/LSVRC/2015/results">ILSVRC 2015</a>で1位を取った<a href="https://arxiv.org/abs/1512.03385">ResNet(Residual Network)</a>でも使われている。</p>
<p><a href="https://arxiv.org/abs/1502.03167">Sergey Ioffe, Christian Szegedy (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p>
<p>具体的にはWx+bと活性化関数の間にBNの層を入れる。μ、σ^2は入力xの平均と分散。
単に正規化するだけでは表現力が下がってしまうのでγとβでスケールやシフトできるようにする。これらの変数は他のパラメータと同様に学習させる。</p>




<div class="img_container"><a href="/article/198/images/198.png">
    <img style="max-width: 100%; width: auto; height: auto;" src="/article/198/images/198_hu_a0d4a73c2543b5b5.png" width="343" height="84" alt="BN層の演算">
</a></div>


<h2 id="tensorflowでの確認">TensorFlowでの確認</h2>
<p>TensorFlowでは<a href="https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization">batch_normalization()</a>がすでに実装されているのでこれを使う。</p>
<p>以下のCNNで学習率を高めに設定しBNありなしの結果を比較する。学習データはmnist。MonitoredSessionでcostをsummaryとして出力しTensorBoardで見られるようにしている。</p>
<p><a href="https://www.sambaiz.net/article/147/">TensorBoardでsummaryやグラフを見る - sambaiz-net</a></p>
<p><a href="https://www.sambaiz.net/article/175/">TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> pandas <span style="color:#ff79c6">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> numpy <span style="color:#ff79c6">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> tensorflow <span style="color:#ff79c6">as</span> tf
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> sklearn.model_selection <span style="color:#ff79c6">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> sklearn.utils <span style="color:#ff79c6">import</span> shuffle
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> sklearn.metrics <span style="color:#ff79c6">import</span> accuracy_score
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train <span style="color:#ff79c6">=</span> pd<span style="color:#ff79c6">.</span>read_csv(<span style="color:#f1fa8c">&#39;./train.csv&#39;</span>)
</span></span><span style="display:flex;"><span>(x_train, x_valid ,y_train, y_valid) <span style="color:#ff79c6">=</span> train_test_split(
</span></span><span style="display:flex;"><span>    train<span style="color:#ff79c6">.</span>drop(<span style="color:#f1fa8c">&#39;label&#39;</span>, axis<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>)<span style="color:#ff79c6">.</span>values<span style="color:#ff79c6">.</span>reshape((<span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>, <span style="color:#bd93f9">28</span>, <span style="color:#bd93f9">28</span>, <span style="color:#bd93f9">1</span>)), 
</span></span><span style="display:flex;"><span>    np<span style="color:#ff79c6">.</span>identity(<span style="color:#bd93f9">10</span>)[train[<span style="color:#f1fa8c">&#39;label&#39;</span>]], 
</span></span><span style="display:flex;"><span>    test_size <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0.1</span>, random_state <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">100</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">&#34;data shape: </span><span style="color:#f1fa8c">{}</span><span style="color:#f1fa8c">, label shape </span><span style="color:#f1fa8c">{}</span><span style="color:#f1fa8c">&#34;</span><span style="color:#ff79c6">.</span>format(x_train<span style="color:#ff79c6">.</span>shape, y_train<span style="color:#ff79c6">.</span>shape))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tf<span style="color:#ff79c6">.</span>reset_default_graph()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">class</span> <span style="color:#50fa7b">ConvBnRelu</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> <span style="color:#50fa7b">__init__</span>(<span style="font-style:italic">self</span>, filters, kernel_size):
</span></span><span style="display:flex;"><span>        <span style="font-style:italic">self</span><span style="color:#ff79c6">.</span>filters <span style="color:#ff79c6">=</span> filters
</span></span><span style="display:flex;"><span>        <span style="font-style:italic">self</span><span style="color:#ff79c6">.</span>kernel_size<span style="color:#ff79c6">=</span> kernel_size
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> <span style="color:#50fa7b">__call__</span>(<span style="font-style:italic">self</span>, x, use_bn, is_training):
</span></span><span style="display:flex;"><span>        h <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>layers<span style="color:#ff79c6">.</span>Conv2D(filters<span style="color:#ff79c6">=</span><span style="font-style:italic">self</span><span style="color:#ff79c6">.</span>filters, kernel_size<span style="color:#ff79c6">=</span><span style="font-style:italic">self</span><span style="color:#ff79c6">.</span>kernel_size)(x)
</span></span><span style="display:flex;"><span>        h <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>cond(
</span></span><span style="display:flex;"><span>            use_bn,
</span></span><span style="display:flex;"><span>            true_fn<span style="color:#ff79c6">=</span><span style="color:#ff79c6">lambda</span>: tf<span style="color:#ff79c6">.</span>layers<span style="color:#ff79c6">.</span>batch_normalization(h, training<span style="color:#ff79c6">=</span>is_training),
</span></span><span style="display:flex;"><span>            false_fn<span style="color:#ff79c6">=</span><span style="color:#ff79c6">lambda</span>: h
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> tf<span style="color:#ff79c6">.</span>nn<span style="color:#ff79c6">.</span>relu(h)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>is_training <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>placeholder(tf<span style="color:#ff79c6">.</span>bool, shape<span style="color:#ff79c6">=</span>())
</span></span><span style="display:flex;"><span>use_bn <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>placeholder(tf<span style="color:#ff79c6">.</span>bool, shape<span style="color:#ff79c6">=</span>())
</span></span><span style="display:flex;"><span>x <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>placeholder(shape<span style="color:#ff79c6">=</span>[<span style="color:#ff79c6">None</span>, <span style="color:#bd93f9">28</span>, <span style="color:#bd93f9">28</span>, <span style="color:#bd93f9">1</span>], dtype<span style="color:#ff79c6">=</span>tf<span style="color:#ff79c6">.</span>float32)
</span></span><span style="display:flex;"><span>t <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>placeholder(tf<span style="color:#ff79c6">.</span>float32, [<span style="color:#ff79c6">None</span>, <span style="color:#bd93f9">10</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">with</span> tf<span style="color:#ff79c6">.</span>name_scope(<span style="color:#f1fa8c">&#34;Conv1&#34;</span>):
</span></span><span style="display:flex;"><span>    h <span style="color:#ff79c6">=</span> ConvBnRelu(filters<span style="color:#ff79c6">=</span><span style="color:#bd93f9">32</span>, kernel_size<span style="color:#ff79c6">=</span> [<span style="color:#bd93f9">3</span>, <span style="color:#bd93f9">3</span>])(x, use_bn, is_training)
</span></span><span style="display:flex;"><span>    h <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>layers<span style="color:#ff79c6">.</span>MaxPooling2D(pool_size<span style="color:#ff79c6">=</span>[<span style="color:#bd93f9">2</span>, <span style="color:#bd93f9">2</span>], strides<span style="color:#ff79c6">=</span><span style="color:#bd93f9">2</span>)(h)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">with</span> tf<span style="color:#ff79c6">.</span>name_scope(<span style="color:#f1fa8c">&#34;Conv2&#34;</span>):
</span></span><span style="display:flex;"><span>    h <span style="color:#ff79c6">=</span> ConvBnRelu(filters<span style="color:#ff79c6">=</span> <span style="color:#bd93f9">64</span>, kernel_size<span style="color:#ff79c6">=</span> [<span style="color:#bd93f9">3</span>, <span style="color:#bd93f9">3</span>])(h, use_bn, is_training)
</span></span><span style="display:flex;"><span>    h <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>layers<span style="color:#ff79c6">.</span>MaxPooling2D(pool_size<span style="color:#ff79c6">=</span>[<span style="color:#bd93f9">2</span>, <span style="color:#bd93f9">2</span>], strides<span style="color:#ff79c6">=</span><span style="color:#bd93f9">2</span>)(h)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>h <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>layers<span style="color:#ff79c6">.</span>Flatten()(h)
</span></span><span style="display:flex;"><span>y <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>layers<span style="color:#ff79c6">.</span>Dense(units<span style="color:#ff79c6">=</span><span style="color:#bd93f9">10</span>, activation<span style="color:#ff79c6">=</span>tf<span style="color:#ff79c6">.</span>nn<span style="color:#ff79c6">.</span>softmax)(h)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>global_step<span style="color:#ff79c6">=</span>tf<span style="color:#ff79c6">.</span>train<span style="color:#ff79c6">.</span>get_or_create_global_step()
</span></span><span style="display:flex;"><span>cost <span style="color:#ff79c6">=</span> <span style="color:#ff79c6">-</span> tf<span style="color:#ff79c6">.</span>reduce_mean(tf<span style="color:#ff79c6">.</span>reduce_sum(t <span style="color:#ff79c6">*</span> tf<span style="color:#ff79c6">.</span>log(tf<span style="color:#ff79c6">.</span>clip_by_value(y, <span style="color:#bd93f9">1e-10</span>, y)), axis<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>))
</span></span><span style="display:flex;"><span>summary_cost <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>summary<span style="color:#ff79c6">.</span>scalar(<span style="color:#f1fa8c">&#39;cost&#39;</span>, cost)
</span></span><span style="display:flex;"><span>optimizer <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>train<span style="color:#ff79c6">.</span>AdamOptimizer(<span style="color:#bd93f9">0.01</span>)<span style="color:#ff79c6">.</span>minimize(cost, global_step<span style="color:#ff79c6">=</span>global_step)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>EPOCH_NUM <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">5</span>
</span></span><span style="display:flex;"><span>BATCH_SIZE <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">100</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>hooks <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>    tf<span style="color:#ff79c6">.</span>train<span style="color:#ff79c6">.</span>StopAtStepHook(last_step<span style="color:#ff79c6">=</span>EPOCH_NUM<span style="color:#ff79c6">*</span>(<span style="color:#8be9fd;font-style:italic">len</span>(x_train) <span style="color:#ff79c6">//</span> BATCH_SIZE))
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>init <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>global_variables_initializer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">for</span> bn <span style="color:#ff79c6">in</span> [<span style="color:#ff79c6">False</span>, <span style="color:#ff79c6">True</span>]:
</span></span><span style="display:flex;"><span>    epoch <span style="color:#ff79c6">=</span> <span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">&#34;--- use binary norm: </span><span style="color:#f1fa8c">{}</span><span style="color:#f1fa8c"> ---&#34;</span><span style="color:#ff79c6">.</span>format(bn))
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">with</span> tf<span style="color:#ff79c6">.</span>train<span style="color:#ff79c6">.</span>MonitoredTrainingSession(
</span></span><span style="display:flex;"><span>        hooks<span style="color:#ff79c6">=</span>hooks, 
</span></span><span style="display:flex;"><span>        summary_dir<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;/home/jovyan/summary&#34;</span>,
</span></span><span style="display:flex;"><span>        save_summaries_steps<span style="color:#ff79c6">=</span><span style="color:#bd93f9">100</span>) <span style="color:#ff79c6">as</span> sess:    
</span></span><span style="display:flex;"><span>        sess<span style="color:#ff79c6">.</span>run(init, feed_dict<span style="color:#ff79c6">=</span>{x: x_valid, t: y_valid, is_training: <span style="color:#ff79c6">False</span>, use_bn: bn})
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">while</span> <span style="color:#ff79c6">not</span> sess<span style="color:#ff79c6">.</span>should_stop():
</span></span><span style="display:flex;"><span>            epoch <span style="color:#ff79c6">+=</span> <span style="color:#bd93f9">1</span>
</span></span><span style="display:flex;"><span>            y_pred, cost_valid, _ <span style="color:#ff79c6">=</span> sess<span style="color:#ff79c6">.</span>run([y, cost, summary_cost], feed_dict<span style="color:#ff79c6">=</span>{x: x_valid, t: y_valid, is_training: <span style="color:#ff79c6">False</span>, use_bn: bn})
</span></span><span style="display:flex;"><span>            <span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">&#34;epoch: </span><span style="color:#f1fa8c">{:2d}</span><span style="color:#f1fa8c">, cost: </span><span style="color:#f1fa8c">{:.4f}</span><span style="color:#f1fa8c">, accuracy: </span><span style="color:#f1fa8c">{:.4f}</span><span style="color:#f1fa8c">&#34;</span><span style="color:#ff79c6">.</span>format(
</span></span><span style="display:flex;"><span>                epoch, cost_valid, accuracy_score(y_pred<span style="color:#ff79c6">.</span>argmax(axis<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>), y_valid<span style="color:#ff79c6">.</span>argmax(axis<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>))))
</span></span><span style="display:flex;"><span>            x_train, y_train <span style="color:#ff79c6">=</span> shuffle(x_train, y_train, random_state<span style="color:#ff79c6">=</span><span style="color:#bd93f9">100</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#ff79c6">for</span> batch <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(<span style="color:#8be9fd;font-style:italic">len</span>(x_train) <span style="color:#ff79c6">//</span> BATCH_SIZE):
</span></span><span style="display:flex;"><span>                start <span style="color:#ff79c6">=</span> batch <span style="color:#ff79c6">*</span> BATCH_SIZE
</span></span><span style="display:flex;"><span>                end <span style="color:#ff79c6">=</span> start <span style="color:#ff79c6">+</span> BATCH_SIZE
</span></span><span style="display:flex;"><span>                sess<span style="color:#ff79c6">.</span>run(optimizer, feed_dict<span style="color:#ff79c6">=</span>{x: x_train[start:end], t: y_train[start:end], is_training: <span style="color:#ff79c6">True</span>, use_bn: bn})
</span></span></code></pre></div><p>BNを行わなかったときの結果。コストを下げられていない。ちなみに学習率を0.01から0.001にしたら下げられるようになった。</p>




<div class="img_container"><a href="/article/198/images/198-2.png">
    <img style="max-width: 100%; width: auto; height: auto;" src="/article/198/images/198-2_hu_ef6ace3f26fa7204.png" width="400" height="270" alt="BNしない場合のコスト">
</a></div>


<p>一方、BNを行ったときの結果がこれ。学習率はそのままで順調にコストを下げることができている。</p>




<div class="img_container"><a href="/article/198/images/198-3.png">
    <img style="max-width: 100%; width: auto; height: auto;" src="/article/198/images/198-3_hu_c6bcbd995392108.png" width="400" height="265" alt="BNした場合のコスト">
</a></div>



    </div>
  </article>
</div>

</div>
</body>

</html>