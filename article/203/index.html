<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Hugo 0.38.2" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7"
    crossorigin="anonymous">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/magula.min.css">
  <link rel="stylesheet" href="/css/slidebars.min.css">
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">
  <link rel="icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">

  <meta name="theme-color" content="#41a248">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@sambaiz">
  
  <title>AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net</title>
  <meta name="twitter:title" content="AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net">
  <meta property='og:title' content="AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net">
  <meta property="og:type" content="article">
  
  <meta name="description" content="PySpark">
  <meta name="twitter:description" content="PySpark">
  
  

  <meta property="og:url" content="https://www.sambaiz.net/article/203/">
  <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
  <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />
  <meta name="google-site-verification" content="CEqNYjzc4Y7hb3FY7uUkmllGzeDc40brBwQJixeH61Q" />
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id":"https://www.sambaiz.net/"
    },
    "headline": "AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する | sambaiz-net ",
    "datePublished": "2019-01-01T17:50:00JST",
    "dateModified": "2019-01-01T17:50:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "image": "https://www.sambaiz.net/images/my.jpg"
    },
    "publisher": {
      "@type": "Organization",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.sambaiz.net/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https://www.sambaiz.net/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "PySpark"
  }
</script>
</head>

<body>
  <div off-canvas="id-1 left reveal">
  
  <ul class="tag-list">
    
  </ul>
  
  <ul class="tag-list">
    <li><a href="https://www.sambaiz.net/tags/aws">aws</a></li><li><a href="https://www.sambaiz.net/tags/golang">golang</a></li><li><a href="https://www.sambaiz.net/tags/machinelearning">machinelearning</a></li><li><a href="https://www.sambaiz.net/tags/log">log</a></li><li><a href="https://www.sambaiz.net/tags/kubernetes">kubernetes</a></li><li><a href="https://www.sambaiz.net/tags/infra">infra</a></li><li><a href="https://www.sambaiz.net/tags/python">python</a></li><li><a href="https://www.sambaiz.net/tags/lambda">lambda</a></li><li><a href="https://www.sambaiz.net/tags/tensorflow">tensorflow</a></li><li><a href="https://www.sambaiz.net/tags/unity">unity</a></li><li><a href="https://www.sambaiz.net/tags/fluentd">fluentd</a></li><li><a href="https://www.sambaiz.net/tags/gcp">gcp</a></li><li><a href="https://www.sambaiz.net/tags/node.js">node.js</a></li><li><a href="https://www.sambaiz.net/tags/web">web</a></li><li><a href="https://www.sambaiz.net/tags/docker">docker</a></li><li><a href="https://www.sambaiz.net/tags/linux">linux</a></li><li><a href="https://www.sambaiz.net/tags/mysql">mysql</a></li><li><a href="https://www.sambaiz.net/tags/elasticsearch">elasticsearch</a></li><li><a href="https://www.sambaiz.net/tags/ios">ios</a></li><li><a href="https://www.sambaiz.net/tags/javascript">javascript</a></li><li><a href="https://www.sambaiz.net/tags/hololens">hololens</a></li><li><a href="https://www.sambaiz.net/tags/auth">auth</a></li><li><a href="https://www.sambaiz.net/tags/product">product</a></li><li><a href="https://www.sambaiz.net/tags/c&#43;&#43;">c&#43;&#43;</a></li><li><a href="https://www.sambaiz.net/tags/circleci">circleci</a></li><li><a href="https://www.sambaiz.net/tags/react">react</a></li><li><a href="https://www.sambaiz.net/tags/typescript">typescript</a></li><li><a href="https://www.sambaiz.net/tags/algorithm">algorithm</a></li><li><a href="https://www.sambaiz.net/tags/android">android</a></li><li><a href="https://www.sambaiz.net/tags/ble">ble</a></li><li><a href="https://www.sambaiz.net/tags/event">event</a></li><li><a href="https://www.sambaiz.net/tags/swift">swift</a></li><li><a href="https://www.sambaiz.net/tags/angular">angular</a></li><li><a href="https://www.sambaiz.net/tags/cron">cron</a></li><li><a href="https://www.sambaiz.net/tags/istio">istio</a></li><li><a href="https://www.sambaiz.net/tags/terraform">terraform</a></li><li><a href="https://www.sambaiz.net/tags/uwp">uwp</a></li><li><a href="https://www.sambaiz.net/tags/.net">.net</a></li><li><a href="https://www.sambaiz.net/tags/crypto">crypto</a></li><li><a href="https://www.sambaiz.net/tags/css">css</a></li><li><a href="https://www.sambaiz.net/tags/datadog">datadog</a></li><li><a href="https://www.sambaiz.net/tags/firebase">firebase</a></li><li><a href="https://www.sambaiz.net/tags/github">github</a></li><li><a href="https://www.sambaiz.net/tags/grpc">grpc</a></li><li><a href="https://www.sambaiz.net/tags/hadoop">hadoop</a></li><li><a href="https://www.sambaiz.net/tags/norikra">norikra</a></li><li><a href="https://www.sambaiz.net/tags/rx">rx</a></li><li><a href="https://www.sambaiz.net/tags/server">server</a></li><li><a href="https://www.sambaiz.net/tags/vr">vr</a></li><li><a href="https://www.sambaiz.net/tags/ansible">ansible</a></li><li><a href="https://www.sambaiz.net/tags/api">api</a></li><li><a href="https://www.sambaiz.net/tags/cdn">cdn</a></li><li><a href="https://www.sambaiz.net/tags/compress">compress</a></li><li><a href="https://www.sambaiz.net/tags/csharp">csharp</a></li><li><a href="https://www.sambaiz.net/tags/d3.js">d3.js</a></li><li><a href="https://www.sambaiz.net/tags/digdag">digdag</a></li><li><a href="https://www.sambaiz.net/tags/hugo">hugo</a></li><li><a href="https://www.sambaiz.net/tags/jenkins">jenkins</a></li><li><a href="https://www.sambaiz.net/tags/jvm">jvm</a></li><li><a href="https://www.sambaiz.net/tags/kotlin">kotlin</a></li><li><a href="https://www.sambaiz.net/tags/language">language</a></li><li><a href="https://www.sambaiz.net/tags/leveldb">leveldb</a></li><li><a href="https://www.sambaiz.net/tags/lisp">lisp</a></li><li><a href="https://www.sambaiz.net/tags/math">math</a></li><li><a href="https://www.sambaiz.net/tags/neo4j">neo4j</a></li><li><a href="https://www.sambaiz.net/tags/objective-c">objective-c</a></li><li><a href="https://www.sambaiz.net/tags/pytorch">pytorch</a></li><li><a href="https://www.sambaiz.net/tags/read_paper">read_paper</a></li><li><a href="https://www.sambaiz.net/tags/scikit-learn">scikit-learn</a></li><li><a href="https://www.sambaiz.net/tags/serialize">serialize</a></li><li><a href="https://www.sambaiz.net/tags/sonnet">sonnet</a></li><li><a href="https://www.sambaiz.net/tags/spark">spark</a></li><li><a href="https://www.sambaiz.net/tags/spec">spec</a></li><li><a href="https://www.sambaiz.net/tags/statistics">statistics</a></li><li><a href="https://www.sambaiz.net/tags/video">video</a></li><li><a href="https://www.sambaiz.net/tags/vscode">vscode</a></li>
  </ul>
  
</div>

  <div canvas="container" id="container">
    <header>
      <button type="button" class="btn toggle-side">TAG</button>

      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" />
        <a class="nl" href="https://www.sambaiz.net/">sambaiz-net</a>
      </div>

      <div class="sns">
        <a class="nl" href="https://twitter.com/sambaiz"><i class="fa fa-2x fa-twitter"></i></a>
        <a class="nl" href="https://github.com/sambaiz"><i class="fa fa-2x fa-github"></i></a>
        <style>
          .filmarks-base {
            display: inline-block;
            width: 29px;
            height: 29px;
          }

          .filmarks {
            display: inline-block;
            width: 25px;
            height: 25px;
            background: url(/image/filmarks.svg) no-repeat;
            background-size: 450%;
            position: relative;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
          }

          .vocabularycom-base {
            display: inline-block;
            width: 29px;
            height: 29px;
          }

          .vocabularycom {
            display: inline-block;
            height: 25px;
            width: 25px;
            background: url(/image/vocabularycom.png) no-repeat;
            background-size: contain;
            position: relative;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
          }

          .leetcode-base {
            display: inline-block;
            width: 29px;
            height: 29px;
          }

          .leetcode {
            display: inline-block;
            height: 25px;
            width: 25px;
            background: url(/image/leetcode.png) no-repeat;
            background-size: contain;
            position: relative;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
          }
        </style>
        <div class="filmarks-base">
          <a href="https://filmarks.com/users/sambaiz" class="filmarks"></a>
        </div>
        <div class="vocabularycom-base">
          <a href="https://www.vocabulary.com/profiles/B0JI0K19KKMVKH" class="vocabularycom"></a>
        </div>
        <div class="leetcode-base">
          <a href="https://leetcode.com/sambaiz/" class="leetcode"></a>
        </div>
      </div>
    </header>

<div class="container">

  <div class="row">
    <div class="col-md-12">

      <article class="single">
        <div class="single body">
          <h1>AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する</h1>
          <p>(2019-01-01)</p>
          

<p><a href="https://aws.amazon.com/jp/glue/">AWS Glue</a>はマネージドなETL(Extract/Transform/Load)サービスで、<a href="https://spark.apache.org/">Spark</a>を使ってS3などにあるデータを読み込み加工して変換出力したり、AthenaやRedshift Spectrumで参照できるデータカタログを提供する。
今回はS3のCSVを読み込んで加工し、列指向フォーマットParquetに変換しパーティションを切って出力、その後クローラを回してデータカタログにテーブルを作成してAthenaで参照できることを確認する。</p>

<p><a href="https://aws.amazon.com/jp/glue/pricing/">料金</a>はジョブがDPU(4vCPU/16GBメモリ)時間あたり$0.44(最低2DPU/10分)かかる。
また、クローラも同様にDPUで課金される。結構高い。</p>

<p>なお、Athenaの<a href="https://docs.aws.amazon.com/ja_jp/athena/latest/ug/ctas.html">CTAS</a>でもParquetを出力することができる。
出力先にファイルがないようにする必要があったり重いクエリは失敗することがあるが手軽で良い。</p>

<pre><code>import * as athena from 'athena-client'
const clientConfig: athena.AthenaClientConfig = {
	bucketUri: 's3://*****/*****'
  skipFetchResult: true,
};
const awsConfig: athena.AwsConfig = {
	region: 'us-east-1',
};

const client = athena.createClient(clientConfig, awsConfig);

(async () =&gt; {
	await client.execute(`
		CREATE TABLE *****
    WITH (
      format = 'PARQUET',
      external_location = 's3://*****'
    ) AS (
      SELECT ~~
    )
})();
</code></pre>

<h2 id="開発用エンドポイント">開発用エンドポイント</h2>

<p>ジョブの立ち上がりにやや時間がかかるため開発用エンドポイントを立ち上げておくとDPUが確保されて効率よく開発できる。
立ち上げている間のDPUの料金がかかる。つまりずっとジョブを実行し続けているようなもので結構高くつくので終わったら閉じるようにしたい。</p>

<p>ローカルやEC2から自分で開発用エンドポイントにsshして<a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/dev-endpoint-tutorial-local-notebook.html">Notebookを立てる</a>こともできるが、
コンソールから立ち上げたNotebookは最初からつながっていて鍵の登録も必要なくて楽。</p>

<pre><code>ssh -i private-key-file-path -NTL 9007:169.254.76.1:9007 glue@dev-endpoint-public-dns
</code></pre>

<p>NotebookのインスタンスのIAMロールを作成するとCloudwatch Logsまわりに加えてGlueのDevEndpointとAssetの取得権限が付与されている。</p>

<pre><code>{
  &quot;Action&quot;: [
    &quot;s3:ListBucket&quot;
  ],
  &quot;Effect&quot;: &quot;Allow&quot;,
  &quot;Resource&quot;: [
    &quot;arn:aws:s3:::aws-glue-jes-prod-us-east-1-assets&quot;
  ]
}
{
  &quot;Action&quot;: [
    &quot;s3:GetObject&quot;
  ],
  &quot;Effect&quot;: &quot;Allow&quot;,
  &quot;Resource&quot;: [
    &quot;arn:aws:s3:::aws-glue-jes-prod-us-east-1-assets*&quot;
  ]
}
{
  &quot;Action&quot;: [
    &quot;glue:UpdateDevEndpoint&quot;,
    &quot;glue:GetDevEndpoint&quot;,
    &quot;glue:GetDevEndpoints&quot;
  ],
  &quot;Effect&quot;: &quot;Allow&quot;,
  &quot;Resource&quot;: [
    &quot;arn:aws:glue:us-east-1:*****:devEndpoint/test*&quot;
  ]
}
</code></pre>

<p>たまに立ち上げに失敗したり次のようなエラーで実行できないことがあったが、立ち上げ直したらうまくいった。</p>

<pre><code>The code failed because of a fatal error:
	Error sending http request and maximum retry encountered..

Some things to try:
a) Make sure Spark has enough available resources for Jupyter to create a Spark context.
b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.
c) Restart the kernel.
</code></pre>

<p>printデバッグが捗る。</p>

<pre><code>...
print(output_df.toDF().collect()[0].asDict())
</code></pre>

<h2 id="ジョブのスクリプト">ジョブのスクリプト</h2>

<p>GlueはSpark標準のDataFrameを扱うこともできるが、独自にスキーマを柔軟に扱える<a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html">DynamicFrame</a>というのをサポートしている。DataFrameとは相互に変換できるので、SQL文の実行などDataFrameにしかないAPIを使いたい場合は変換する。
ただ、Sparkの設定を<a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html">変えられない</a>分、DynamicFrameがうまくやっているところもある。</p>

<p><a href="https://www.sambaiz.net/article/208/">Apache SparkのRDD, DataFrame, DataSetとAction, Transformation - sambaiz-net</a></p>

<pre><code>from pyspark.sql.utils import ParseException
data_frame = dynamc_frame.toDF()
data_frame.toDF().createOrReplaceTempView('t1')
try:
  data_frame2 = spark.sql('SELECT * FROM t1')
except ParseException as e:
    print(str(e).replace(&quot;\\n&quot;, &quot;\n&quot;))
</code></pre>

<p>入力は為替データのCSV。</p>

<pre><code>$ less kawase1.csv
Date,USD,GBP,EUR,CAD,CHF,SEK,DKK,NOK,AUD,NZD
2002/4/1,133.15,189.79,116.12,83.48,79.28,12.87,15.63,15.08,71.14,58.8
...

$ less kawase2.csv
Date,ZAR,BHD,HKD,INR,PHP,SGD,THB,KWD,SAR,AED,MXN,TWD
2002/4/1,11.76,353.65,17.07,2.73,2.61,72.21,3.07,434.14,35.52,36.26,14.81,3.82
...
</code></pre>

<p>やることは次の通り。</p>

<ul>
<li><a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame-reader.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-reader-from_options">create_dynamic_frame.from_options()</a>でS3のCSVを読んでDynamicFrameを生成</li>
<li>Dateで<a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-join">join()</a></li>
<li><a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-apply_mapping">apply_mapping()</a>でフィールド名と型をマッピングする</li>
<li><a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-map">map()</a>でDateをyear, month, dateの3フィールドに分割、各値をUSDとの比にする</li>
<li><a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame-writer.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-writer-from_options">create_dynamic_frame.from_options()</a>でパーティションをyearで<a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-programming-etl-partitions.html#aws-glue-programming-etl-partitions-writing">切って</a>フォーマットはParquetで書き込む</li>
<li>クローラの実行を開始する</li>
</ul>

<p>transformation_ctxは後述するジョブのブックマークで使われる一意な識別子。</p>

<pre><code>import sys
import datetime
import boto3
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

args = getResolvedOptions(sys.argv, [&quot;JOB_NAME&quot;])

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args[&quot;JOB_NAME&quot;], args)


def split_date(rec):
    date = datetime.datetime.strptime(rec[&quot;Date&quot;], &quot;%Y/%m/%d&quot;)
    rec[&quot;year&quot;] = date.year
    rec[&quot;month&quot;] = date.month
    rec[&quot;day&quot;] = date.day
    return rec


def convert_ratio_usd(rec):
    ret = {}
    for field in rec:
        ret[field] = rec[field]
        if field not in [&quot;year&quot;, &quot;month&quot;, &quot;day&quot;]:
            ret[field] /= rec[&quot;usd&quot;]
    return ret


input_df = glueContext.create_dynamic_frame.from_options(
    transformation_ctx=&quot;source&quot;,
    connection_type=&quot;s3&quot;,
    connection_options={&quot;paths&quot;: [&quot;s3://*****/kawase1.csv&quot;]},
    format=&quot;csv&quot;,
    format_options={&quot;withHeader&quot;: True})
input_df2 = glueContext.create_dynamic_frame.from_options(
    transformation_ctx=&quot;source&quot;,
    connection_type=&quot;s3&quot;,
    connection_options={&quot;paths&quot;: [&quot;s3://*****/kawase2.csv&quot;]},
    format=&quot;csv&quot;,
    format_options={&quot;withHeader&quot;: True})

output_df = input_df.join(
    [&quot;Date&quot;], [&quot;Date&quot;], input_df2, transformation_ctx=&quot;info&quot;).map(
        split_date, transformation_ctx=&quot;split_date&quot;).apply_mapping(
            [(&quot;year&quot;, &quot;smallint&quot;, &quot;year&quot;, &quot;smallint&quot;),
             (&quot;month&quot;, &quot;smallint&quot;, &quot;month&quot;, &quot;smallint&quot;),
             (&quot;day&quot;, &quot;smallint&quot;, &quot;day&quot;, &quot;smallint&quot;),
             (&quot;USD&quot;, &quot;string&quot;, &quot;usd&quot;, &quot;double&quot;),
             (&quot;EUR&quot;, &quot;string&quot;, &quot;eur&quot;, &quot;double&quot;),
             (&quot;AUD&quot;, &quot;string&quot;, &quot;aud&quot;, &quot;double&quot;),
             (&quot;ZAR&quot;, &quot;string&quot;, &quot;zar&quot;, &quot;double&quot;)],
            transformation_ctx=&quot;apply_mapping&quot;).map(
                convert_ratio_usd, transformation_ctx=&quot;convert_ratio_usd&quot;)

glueContext.write_dynamic_frame.from_options(
    frame=output_df,
    connection_type=&quot;s3&quot;,
    connection_options={
        &quot;path&quot;: &quot;s3://*****/target&quot;,
        &quot;partitionKeys&quot;: [&quot;year&quot;],
        &quot;compression&quot;: &quot;gzip&quot;
    },
    format=&quot;parquet&quot;,
    transformation_ctx=&quot;sink&quot;)
job.commit()

glue_client = boto3.client('glue', region_name='us-east-1')
glue_client.start_crawler(Name='kawase')
</code></pre>

<p>Glueのロールで読める場所にアップロードする。</p>

<pre><code>$ aws s3 cp main.py s3://aws-glue-scripts-*****/root/main.py
</code></pre>

<h2 id="ジョブとクローラの作成">ジョブとクローラの作成</h2>

<p>ジョブを作成する。デフォルトで10DPU使うようになっているので調整する。1DPUで2つのExecutorが<a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-debug-capacity.html#monitor-debug-capacity-visualize">動く</a>。
<a href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-continuations.html">ブックマーク</a>を有効にすると以前処理したデータは処理しないようにできるが、残念ながらParquetは対応していないため2回実行すると重複して出力されてしまう。</p>

<p><img src="https://www.sambaiz.net/images/203-1.png" alt="ジョブの作成" /></p>

<p>クローラはデータをクローリングしてデータカタログの指定のデータベースにスキーマやパーティションといったメタデータテーブルを作成する。
以前、LambdaでAthenaのスキーマを管理したりパーティションを切ったりするバッチを作ったが、Glueのデータカタログ上で同じことをやってくれる。
楽だけど現状DPUの設定項目がないのでデータが多くて時間がかかる場合はどうしようもなさそう。</p>

<p><a href="https://www.sambaiz.net/article/145/">Athenaのmigrationやpartitionするathena-adminを作った - sambaiz-net</a></p>

<h2 id="ジョブの実行">ジョブの実行</h2>

<p>トリガーを設定して定期的に実行することもできるが、今回は手動で実行する。</p>

<pre><code>$ aws glue start-job-run --job-name kawase
</code></pre>

<p>パーティションごとにParquetが出力されている。</p>

<p><img src="https://www.sambaiz.net/images/203-3.png" alt="パーティションごとのディレクトリ" /></p>

<p>また、クローラの実行が終わるとデータカタログにテーブルが追加される。</p>

<h2 id="athenaで参照">Athenaで参照</h2>

<p>AthenaをGlueリリース以前から使っていた場合はデータカタログをGlueのものに<a href="https://docs.aws.amazon.com/ja_jp/athena/latest/ug/glue-upgrade.html">アップグレード</a>する必要がある。
Athenaのところにリンクが出るので押しとけばIAMロールの更新など大体やってくれる。
これによってDatabaseにGlueのものが出るようになりクエリも実行できるようになる。</p>

<p><img src="https://www.sambaiz.net/images/203-4.png" alt="Athenaからの参照" /></p>

        </div>
      </article>
    </div>
  </div>
</div>

</div> 
<script src="//code.jquery.com/jquery-2.1.3.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script src="/js/slidebars.min.js"></script>
<script>
    ( function ( $ ) {
      
      var controller = new slidebars();
      controller.init();

      $( '.toggle-side' ).on( 'click', function ( event ) {
          event.stopPropagation();
          event.preventDefault();

          controller.toggle( 'id-1' );
        } );

        $( '#container' ).on( 'click', function ( event ) {
            controller.close( 'id-1' );
          });
    } ) ( jQuery );
</script>

<script>hljs.initHighlightingOnLoad();</script>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-39190067-3', 'auto');
ga('send', 'pageview');
</script>


  </body>
</html>

