<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">

  
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NCML2RV');</script>
  

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;700&display=swap" rel="stylesheet">

  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
  <link rel="stylesheet" href="/css/destyle.css">
  <style>
    body {
        background-color: #f1f1f1;
        line-height: 1.3;
        font-family: 'Noto Sans JP', sans-serif;
    }

    .languages {
        position: absolute;
        top: 10px;
        right: 15px;
        font-size: 1.2rem;
        color: #3a9240;
    }

    header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
    }

    header>.title {
        font-size: 1.875rem;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns {
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .sns-item {
        display: inline-block;
        margin: 3px;
    }

    .filmarks {
        display: inline-block;
        width: 30px;
        height: 30px;
        margin-top: 3px;
        background: url(/image/filmarks.svg) no-repeat;
        background-size: 450%;
    }

    header>.tags {
        display: flex;
        justify-content: center;
        align-items: center;
        font-size: 1.2rem;
        max-width: 1000px;
        margin: auto;
        padding: 0 20px;
    }

    header>.tags .others {
        font-weight: bold;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
    }

    .nl {
        display: inline-block;
    }

    .cell {
        background-color: #fff;
        border-radius: 5px;
        padding: 10px;
        box-shadow: 0 1px 1px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
    }

    time {
        color: #333;
    }

    .tag {
        color: #3a9240;
        margin: 0 5px;
    }

    .tag:hover {
        text-decoration: underline;
    }

     
    .paging {
        display: inline-block;
        font-size: 1.25rem;
        margin: 10px 10px;
    }

    .paging.next {
        float: right;
    }


     
    .list>.title {
        font-size: 1.75rem;
        margin: 0 0 10px 10px;
    }

     
    .grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(262px, 1fr));
        gap: 20px;
        margin: 0 10px;
    }

    .grid-nl {
        width: 100%;
    }

    .grid-cell {
        height: 11.25rem;
        overflow: hidden;
        box-sizing: content-box;
    }

    .grid-cell>.title {
        font-size: 1.5rem;
        word-wrap: break-word;
    }

     
    .single {
        margin: 0 10px 10px 10px;
        line-height: 1.5;
    }

    @media screen and (min-width: 768px) {
        .single .cell {
            padding: 10px 20px;
        }
    }

    .single-header {
        margin-block-start: 1.875rem;
        margin-block-end: 1.875rem;
        line-height: 1.3;
    }

    .single-header h1 {
        font-size: 2rem;
        font-weight: bold;
    }

    .single h2 {
        font-size: 1.8rem;
        border-bottom: 1px solid #ddd;
        margin-block-start: 1.875rem;
    }

    .single h3 {
        font-size: 1.5rem;
        margin-block-start: 1.5rem;
    }

    .single h4 {
        font-size: 1.2rem;
        margin-block-start: 1rem;
    }

    .single a {
        color: #3a9240;
    }

    .single a:hover {
        text-decoration: underline;
    }

    .single p {
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single p>code {
        background-color: #eee;
        color: #333;
        padding: 0 0.2rem;
        display: inline-block;
        overflow: auto;
        max-width: 100%;
        vertical-align: bottom;
    }

    .single .highlight {
        box-shadow: 0 1px 5px rgba(0, 0, 0, 0.3), 0 0 1px rgba(0, 0, 0, 0.1) inset;
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single .highlight>pre {
        padding: 10px;
        overflow-x: auto;
        background-color: ;
    }

    .single img {
        max-width: 100%;
    }

    .single blockquote {
        border-left: 5px solid #ddd;
        color: #777;
        padding: 1rem 0 1rem 1rem;
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .single hr {
        color: #bbb;
        margin-block-start: 1.5rem;
        margin-block-end: 1.5rem;
    }

    .single ul {
        list-style-type: disc;
        padding-left: 1.5em;
        margin-block-start: 0.83rem;
        margin-block-end: 0.83rem;
    }

    .share {
        position: relative;
        text-align: right;
        margin-top: 5px;
    }

    .share .cell {
        display: inline-block;
        text-align: center;
        margin-bottom: 5px;
    }

    .share-button {
        display: inline-block;
        margin: 0 5px;
    }

    @media screen and (min-width: 1400px) {
        .share .cell {
            position: absolute;
            bottom: 0;
            margin-left: 5px;
        }

        .share-button {
            display: inline-block;
            margin: 5px 0;
        }
    }
</style>
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">
  <link rel="icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">

  <meta name="theme-color" content="#41a248">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@sambaiz">
  
  <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net</title>
  <meta name="twitter:title" content="TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net">
  <meta property='og:title' content="TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net">
  <meta property="og:type" content="article">
  
  <meta name="description" content="RNN">
  <meta name="twitter:description" content="RNN">
  
  

  <meta property="og:url" content="https://www.sambaiz.net/article/146/">
  <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
  <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />

  

<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id": "https://www.sambaiz.net/"
    },
    "headline": "TensorFlowのRNN(LSTM)のチュートリアルのコードを読む",
    "datePublished": "2018-01-03T21:12:00JST",
    "dateModified": "2018-01-03T21:12:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "url": "https://www.sambaiz.net/",
      "image": "https://www.sambaiz.net/images/my.jpg"
    },
    "publisher": {
      "@type": "Person",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.sambaiz.net/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https://www.sambaiz.net/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "RNN"
  }
</script>
</head>

<body>
  
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NCML2RV"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  
  <div>
    <div class="languages">
      
    </div>

    <header>
      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" alt="icon" />
        <a class="nl" href='/'>
          <h1>sambaiz-net</h1>
        </a>
      </div>

      <div class="sns">
        <div class="sns-item">
          <a class="nl" href="https://twitter.com/sambaiz">
            <img src="/image/twitter.png" width="30px" height="30px" alt="twitter">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://github.com/sambaiz">
            <img src="/image/github.png" width="30px" height="30px" alt="github">
          </a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://bookmeter.com/users/1060169/books/read">
            <img src="/image/bookmeter.png" width="30px" height="30px" alt="bookmeter">
          </a>
        </div>
        <div class="sns-item">
          <a href="https://filmarks.com/users/sambaiz" class="filmarks" aria-label="filmarks"></a>
        </div>
        <div class="sns-item">
          <a class="nl" href="https://www.alltrails.com/members/taiki-sakamoto/recordings">
            <img src="/image/alltrails.png" width="30px" height="30px" alt="alltrails">
          </a>
        </div>
      </div>
      <div class="tags">
        <div>
          
          <a class="tag" href="/tags/aws/">
            aws</a>
          
          <a class="tag" href="/tags/golang/">
            golang</a>
          
          <a class="tag" href="/tags/machinelearning/">
            machinelearning</a>
          
          <a class="tag" href="/tags/python/">
            python</a>
          
          <a class="tag" href="/tags/kubernetes/">
            kubernetes</a>
          
          <a class="tag" href="/tags/log/">
            log</a>
          
          <a class="tag" href="/tags/docker/">
            docker</a>
          
          <a class="tag" href="/tags/gcp/">
            gcp</a>
          
          <a class="tag" href="/tags/fluentd/">
            fluentd</a>
          
          <a class="tag" href="/tags/infra/">
            infra</a>
          
          <a class="tag others" href="/tags/">...</a>
        </div>
      </div>
    </header>

<div class="container">
  <article class="single">
    <div class="cell">
      <div class="single-header">
        <h1>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</h1>
        <time>2018-01-03</time>
        <a class="tag" href='/tags/tensorflow/'>tensorflow</a><a class="tag" href='/tags/machinelearning/'>machinelearning</a>
      </div>
      <p>TensorflowのRNN(Recurrent Neural Networks)の<a href="https://www.tensorflow.org/tutorials/recurrent">チュートリアル</a>の<a href="https://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/rnn/ptb/ptb_word_lm.py">コード</a>を読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。</p>
<h2 id="rnnlstmとは">RNN/LSTMとは</h2>
<p>RNNは入力に対して出力のほかに情報を次のステップに渡すことで時系列データで学習できるようにするネットワーク。
展開すると同じネットワークに単語を一つずつ入れていくように表現できる。</p>
<p><img src="https://www.sambaiz.net/images/146-rnn.png" alt="RNN"></p>
<p>これを単純にMLPで実装しようとすると逆誤差伝搬する際に過去の層にも伝搬させる(BPTT: Backpropagation through time)必要があり、
時間を遡るほど活性化関数の微分係数が再帰的に繰り返し掛けられるため勾配が消失や爆発しやすくなってしまう。
また、時系列データのうちに発火したいものと発火したくないものが混在している場合、同じ重みにつながっているため更新を打ち消しあってしまう入力/出力重み衝突という問題もある。</p>
<p>これらを解決するのがLSTM(Long Short Term Memory networks)で、
勾配消失は活性化関数がxで重みが単位行列のニューロンのCEC(Constant Error Carousel)によって常に誤差に掛けられる係数を1にすることで防ぎ、
入力/出力重み衝突は必要な入出力を通したり不必要な情報は忘れさせるために値域(0,1)の値を掛けるinput gate、forget gate、output gateによって回避する。gateは入力と前回の出力によって制御される。</p>
<p><img src="https://www.sambaiz.net/images/146-lstm.png" alt="RNN"></p>
<p>TensorflowではいくつかLSTMの実装が用意されていて、<code>CudnnLSTM</code>や<code>BasicLSTMCell</code>、<code>LSTMBlockCell</code>などがある。
<a href="https://developer.nvidia.com/cudnn">cuDNN</a>というのはNVIDIAのCUDAのDNNライブラリのこと。
<code>LSTMBlockCell</code>はもう少し複雑なLSTMで<code>BasicLSTMCell</code>よりも速い。</p>
<h2 id="動かしてみる">動かしてみる</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">$ git clone https://github.com/tensorflow/models.git
$ cd models/tutorials/rnn/ptb/
$ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz
$ tar xvf simple-examples.tgz 
$ python3 -m venv env
$ . ./env/bin/activate
$ pip install numpy tensorflow
</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-fallback" data-lang="fallback">$ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 5534.452 speed: 894 wps
0.104 perplexity: 845.383 speed: 1277 wps
...
0.803 perplexity: 316.808 speed: 1195 wps
0.903 perplexity: 298.087 speed: 1205 wps
Epoch: 1 Train Perplexity: 283.825
Epoch: 1 Valid Perplexity: 182.132
Epoch: 2 Learning rate: 1.000
...
Epoch: 4 Learning rate: 1.000
...
Epoch: 5 Learning rate: 0.500
...
Epoch: 6 Learning rate: 0.250
...
Epoch: 7 Learning rate: 0.125
...
Epoch: 13 Learning rate: 0.002
...
Test Perplexity: 121.759
</code></pre></div><h2 id="reader">reader</h2>
<p>readerにはテストがあったので、これを使って実際にどんな出力をしているか見てみる。</p>
<h3 id="ptb_raw_data">ptb_raw_data</h3>
<p>単語をIDに変換したものと語彙数が返る。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">def</span> setUp(self):
  self._string_data = <span style="color:#a31515">&#34;</span><span style="color:#a31515">\n</span><span style="color:#a31515">&#34;</span>.join(
    [<span style="color:#a31515">&#34; hello there i am&#34;</span>,
     <span style="color:#a31515">&#34; rain as day&#34;</span>,
     <span style="color:#a31515">&#34; want some cheesy puffs ?&#34;</span>])

<span style="color:#00f">def</span> testPtbRawData(self):
  tmpdir = tf.test.get_temp_dir()
  <span style="color:#00f">for</span> suffix <span style="color:#00f">in</span> <span style="color:#a31515">&#34;train&#34;</span>, <span style="color:#a31515">&#34;valid&#34;</span>, <span style="color:#a31515">&#34;test&#34;</span>:
    filename = os.path.join(tmpdir, <span style="color:#a31515">&#34;ptb.</span><span style="color:#a31515">%s</span><span style="color:#a31515">.txt&#34;</span> % suffix)
    <span style="color:#00f">with</span> tf.gfile.GFile(filename, <span style="color:#a31515">&#34;w&#34;</span>) <span style="color:#00f">as</span> fh:
    fh.write(self._string_data)
  <span style="color:#008000"># Smoke test</span>
  output = reader.ptb_raw_data(tmpdir)
  <span style="color:#00f">print</span>(<span style="color:#a31515">&#39;output: {0}&#39;</span>.format(output))
  <span style="color:#008000"># output: (</span>
  <span style="color:#008000">#   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # train</span>
  <span style="color:#008000">#   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # valid</span>
  <span style="color:#008000">#   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # test</span>
  <span style="color:#008000">#   12 # vocabulary</span>
  <span style="color:#008000"># )</span>
  self.assertEqual(len(output), 4)
</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">print</span>(word_to_id)
=&gt; {<span style="color:#a31515">&#39;?&#39;</span>: 0, <span style="color:#a31515">&#39;am&lt;eos&gt;&#39;</span>: 1, <span style="color:#a31515">&#39;as&#39;</span>: 2, <span style="color:#a31515">&#39;cheesy&#39;</span>: 3, <span style="color:#a31515">&#39;day&lt;eos&gt;&#39;</span>: 4, <span style="color:#a31515">&#39;hello&#39;</span>: 5, <span style="color:#a31515">&#39;i&#39;</span>: 6, <span style="color:#a31515">&#39;puffs&#39;</span>: 7, <span style="color:#a31515">&#39;rain&#39;</span>: 8, <span style="color:#a31515">&#39;some&#39;</span>: 9, <span style="color:#a31515">&#39;there&#39;</span>: 10, <span style="color:#a31515">&#39;want&#39;</span>: 11}
</code></pre></div><h3 id="ptb_producer">ptb_producer</h3>
<p>session.runする度に時系列順に[batch_size, num_steps]のTensorを出力する。
二つ目の返り値は一つ右にずらしたもの。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">def</span> testPtbProducer(self):
  raw_data = [
  <span style="color:#008000"># t=0↓  t=1↓</span>
    4, 3, 2, 1, 0, 
    5, 6, 1, 1, 1, 
    1, 0, 3, 4, 1
  ]
  batch_size = 3
  num_steps = 2
  x, y = reader.ptb_producer(raw_data, batch_size, num_steps)
  <span style="color:#00f">with</span> self.test_session() <span style="color:#00f">as</span> session:
    coord = tf.train.Coordinator()
    tf.train.start_queue_runners(session, coord=coord)
    <span style="color:#00f">try</span>:
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[4, 3], [5, 6], [1, 0]])
      self.assertAllEqual(yval, [[3, 2], [6, 1], [0, 3]])
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[2, 1], [1, 1], [3, 4]])
      self.assertAllEqual(yval, [[1, 0], [1, 1], [4, 1]])
    <span style="color:#00f">finally</span>:
      coord.request_stop()
      coord.join()
</code></pre></div><p>実装はこんな感じ。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python">i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()
x = tf.strided_slice(data, [0, i * num_steps],
                        [batch_size, (i + 1) * num_steps])
x.set_shape([batch_size, num_steps])
y = tf.strided_slice(data, [0, i * num_steps + 1],
                        [batch_size, (i + 1) * num_steps + 1])
y.set_shape([batch_size, num_steps])
</code></pre></div><p>range_input_producerはその名の通りrangeのように0から値を生成するが、
Threadを調整する<a href="https://www.tensorflow.org/api_docs/python/tf/train/Coordinator">Coordinator</a>を生成し、
<a href="https://www.tensorflow.org/api_docs/python/tf/train/start_queue_runners">start_queue_runners</a>に渡す必要がある。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#008000"># example of range_input_producer</span>
<span style="color:#00f">with</span> self.test_session() <span style="color:#00f">as</span> session:
  i = tf.train.range_input_producer(100, shuffle=False).dequeue()
  coord = tf.train.Coordinator()
  tf.train.start_queue_runners(session, coord=coord)
  <span style="color:#00f">try</span>:
    <span style="color:#00f">print</span>(session.run(i)) <span style="color:#008000"># =&gt; 0</span>
    <span style="color:#00f">print</span>(session.run(i)) <span style="color:#008000"># =&gt; 1</span>
    <span style="color:#00f">print</span>(session.run(i)) <span style="color:#008000"># =&gt; 2</span>
  <span style="color:#00f">finally</span>:
    coord.request_stop()
    coord.join() <span style="color:#008000"># Wait for all the threads to terminate.</span>
</code></pre></div><h2 id="model">Model</h2>
<h3 id="入力の準備">入力の準備</h3>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup">embedding_lookup</a>で
embeddingから各stepの単語のものを抽出する。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">with</span> tf.device(<span style="color:#a31515">&#34;/cpu:0&#34;</span>):
  embedding = tf.get_variable(
    <span style="color:#a31515">&#34;embedding&#34;</span>, [vocab_size, size], dtype=data_type())
  <span style="color:#008000"># shape=(batch_size, num_steps, size), dtype=float32</span>
  inputs = tf.nn.embedding_lookup(embedding, input_.input_data)
</code></pre></div><p>embedding_lookupの挙動はこんな感じ。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#008000"># example of embedding_lookup</span>
<span style="color:#00f">with</span> tf.Session() <span style="color:#00f">as</span> session:
  <span style="color:#00f">print</span>(session.run(tf.nn.embedding_lookup(
    [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]],
    [[0,1,2], [3,4,5], [6,7,8]]
  ))) 
  <span style="color:#008000"># =&gt; [[ 0  2  4]</span>
  <span style="color:#008000">#     [ 6  8 10]</span>
  <span style="color:#008000">#     [ 1  3  5]]</span>
</code></pre></div><p>学習中の場合、過学習を防ぐためkeep_prob残してDropoutし、RNNのグラフを作り始める。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">if</span> is_training <span style="color:#00f">and</span> config.keep_prob &lt; 1:
  inputs = tf.nn.dropout(inputs, config.keep_prob)

output, state = self._build_rnn_graph(inputs, config, is_training)
</code></pre></div><h3 id="rnnのグラフ">RNNのグラフ</h3>
<p><code>rnn_mode</code>で実装を選べるようになっている。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">def</span> _build_rnn_graph(self, inputs, config, is_training):
  <span style="color:#00f">if</span> config.rnn_mode == CUDNN:
    <span style="color:#00f">return</span> self._build_rnn_graph_cudnn(inputs, config, is_training)
  <span style="color:#00f">else</span>:
    <span style="color:#00f">return</span> self._build_rnn_graph_lstm(inputs, config, is_training)
</code></pre></div><p>Cellは<code>LSTMBlockCell</code>をDroopoutWrapperでラップしたもの。
さらにこれをCellの出力が次のCellの入力になる<code>MultiRNNCell</code>で<code>num_layers</code>重ねている。</p>
<p>最初に<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell#zero_state">zero_state</a>の
初期状態から<code>num_steps</code>まわして各stepでのoutputと最後のstateを返す。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">def</span> _get_lstm_cell(self, config, is_training):
  <span style="color:#00f">if</span> config.rnn_mode == BASIC:
    <span style="color:#00f">return</span> tf.contrib.rnn.BasicLSTMCell(
      config.hidden_size, forget_bias=0.0, state_is_tuple=True,
      reuse=<span style="color:#00f">not</span> is_training)
  <span style="color:#00f">if</span> config.rnn_mode == BLOCK:
    <span style="color:#00f">return</span> tf.contrib.rnn.LSTMBlockCell(
      config.hidden_size, forget_bias=0.0)
  <span style="color:#00f">raise</span> ValueError(<span style="color:#a31515">&#34;rnn_mode </span><span style="color:#a31515">%s</span><span style="color:#a31515"> not supported&#34;</span> % config.rnn_mode)

<span style="color:#00f">def</span> _build_rnn_graph_lstm(self, inputs, config, is_training):
  <span style="color:#00f">def</span> make_cell():
    cell = self._get_lstm_cell(config, is_training)
    <span style="color:#00f">if</span> is_training <span style="color:#00f">and</span> config.keep_prob &lt; 1:
      cell = tf.contrib.rnn.DropoutWrapper(
        cell, output_keep_prob=config.keep_prob)
    <span style="color:#00f">return</span> cell

  cell = tf.contrib.rnn.MultiRNNCell(
    [make_cell() <span style="color:#00f">for</span> _ <span style="color:#00f">in</span> range(config.num_layers)], state_is_tuple=True)

  self._initial_state = cell.zero_state(config.batch_size, data_type())
  state = self._initial_state

  <span style="color:#008000"># [shape=(batch_size, hidden_size) dtype=float32, ...]</span>
  outputs = []
  <span style="color:#00f">with</span> tf.variable_scope(<span style="color:#a31515">&#34;RNN&#34;</span>):
    <span style="color:#00f">for</span> time_step <span style="color:#00f">in</span> range(self.num_steps):
      <span style="color:#00f">if</span> time_step &gt; 0: tf.get_variable_scope().reuse_variables()
      (cell_output, state) = cell(inputs[:, time_step, :], state)
      outputs.append(cell_output)

  <span style="color:#008000"># shape=(batch_size * num_steps, hidden_size), dtype=float32</span>
  output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])
  <span style="color:#00f">return</span> output, state
</code></pre></div><h3 id="コスト">コスト</h3>
<p>出力層を通したのをlogits(<code>log(p/(1-p)) (0≦p≦1)</code>)のシーケンスとして扱い、
<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss">sequence_loss</a>で
それぞれ交差エントロピーを求め、その和をコストとする。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python">output, state = self._build_rnn_graph(inputs, config, is_training)

softmax_w = tf.get_variable(
    <span style="color:#a31515">&#34;softmax_w&#34;</span>, [size, vocab_size], dtype=data_type())
softmax_b = tf.get_variable(<span style="color:#a31515">&#34;softmax_b&#34;</span>, [vocab_size], dtype=data_type())
logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)
<span style="color:#008000"># shape=(batch_size, num_steps, vocab_size), dtype=float32</span>
logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])

loss = tf.contrib.seq2seq.sequence_loss(
    <span style="color:#008000"># logits: [batch_size, sequence_length=num_steps, num_decoder_symbols=vocab_size] and dtype float</span>
    <span style="color:#008000"># The logits correspond to the prediction across all classes at each timestep.</span>
    logits,

    <span style="color:#008000"># targets: [batch_size, sequence_length=num_steps] and dtype int</span>
    <span style="color:#008000"># The target represents the true class at each timestep.</span>
    input_.targets,

    <span style="color:#008000"># weights: [batch_size, sequence_length] and dtype float</span>
    <span style="color:#008000"># When using weights as masking, set all valid timesteps to 1 and all padded timesteps to 0</span>
    tf.ones([self.batch_size, self.num_steps], dtype=data_type()),

    average_across_timesteps=False,
    average_across_batch=True)

<span style="color:#008000"># Update the cost</span>
self._cost = tf.reduce_sum(loss)
self._final_state = state
</code></pre></div><h3 id="勾配">勾配</h3>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/trainable_variables">trainable_variables</a>で
<code>trainable=True</code>(つまり_lr以外)のvariableを取得し、
<a href="https://www.tensorflow.org/api_docs/python/tf/gradients">gradients</a>で各variableに対しての勾配を求め、
<a href="https://www.tensorflow.org/api_docs/python/tf/clip_by_global_norm">clip_by_global_norm</a>で大きさを抑える。
これはgradient clippingと呼ばれる勾配爆発を防ぐための手法。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">if</span> <span style="color:#00f">not</span> is_training:
    <span style="color:#00f">return</span>

self._lr = tf.Variable(0.0, trainable=False)
tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(self._cost, tvars),
                                    config.max_grad_norm)
</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#008000"># example of trainable_variables</span>
<span style="color:#00f">with</span> tf.Session() <span style="color:#00f">as</span> session:
  a = tf.Variable(10.0, trainable=False)
  b = tf.Variable(20.0)
  c = tf.get_variable(<span style="color:#a31515">&#34;c&#34;</span>, [2, 2])
  d = tf.get_variable(<span style="color:#a31515">&#34;d&#34;</span>, [3, 3], trainable=False)
  session.run(tf.global_variables_initializer())
  <span style="color:#00f">print</span>(session.run(tf.trainable_variables()))
  <span style="color:#008000"># [20.0, array([[ 1.10110056,  0.6373167 ],</span>
  <span style="color:#008000"># [ 0.44673324, -0.11995673]], dtype=float32)]</span>
</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#008000"># example of gradients &amp; clip_by_global_norm</span>
<span style="color:#00f">with</span> tf.Session() <span style="color:#00f">as</span> session:
  xs = tf.Variable([10., 20., 30.])
  ys = [xs ** 2 + 123, xs * 5]
  grad = tf.gradients(ys,xs)
  session.run(tf.global_variables_initializer())
  <span style="color:#00f">print</span>(session.run(grad)) <span style="color:#008000"># [20 + 5, 40 + 5, 60 + 5]</span>

  list_clipped, global_norm = session.run(tf.clip_by_global_norm(grad,2))
  <span style="color:#008000"># global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))</span>
  <span style="color:#008000"># = sqrt(25 ** 2 + 45 ** 2 + 65 ** 2)</span>
  <span style="color:#00f">print</span>(global_norm) <span style="color:#008000"># 82.9156</span>

  <span style="color:#008000"># t_list[i] * clip_norm / max(global_norm, clip_norm)</span>
  <span style="color:#008000"># = [25, 45, 65] * 2 / global_norm</span>
  <span style="color:#00f">print</span>(list_clipped) <span style="color:#008000"># [0.60302269, 1.08544087, 1.56785905]</span>
</code></pre></div><h3 id="optimize">Optimize</h3>
<p>学習率_lrの<code>GradientDescenetOptimizer</code>でoptimizeする。
<a href="https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer#apply_gradients">apply_gradients</a>するたびに
global_stepがインクリメントされる。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python">optimizer = tf.train.GradientDescentOptimizer(self._lr)
self._train_op = optimizer.apply_gradients(
  zip(grads, tvars),
  global_step=tf.train.get_or_create_global_step())

self._new_lr = tf.placeholder(
  tf.float32, shape=[], name=<span style="color:#a31515">&#34;new_learning_rate&#34;</span>)
self._lr_update = tf.assign(self._lr, self._new_lr)
</code></pre></div><h3 id="run_epoch">run_epoch</h3>
<p><code>session.run</code>する。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python">fetches = {
  <span style="color:#a31515">&#34;cost&#34;</span>: model.cost,
  <span style="color:#a31515">&#34;final_state&#34;</span>: model.final_state,
}
<span style="color:#00f">if</span> eval_op <span style="color:#00f">is</span> <span style="color:#00f">not</span> None:
  fetches[<span style="color:#a31515">&#34;eval_op&#34;</span>] = eval_op

<span style="color:#00f">for</span> step <span style="color:#00f">in</span> range(model.input.epoch_size):
  feed_dict = {}
  <span style="color:#00f">for</span> i, (c, h) <span style="color:#00f">in</span> enumerate(model.initial_state):
    feed_dict[c] = state[i].c
    feed_dict[h] = state[i].h

  vals = session.run(fetches, feed_dict)
  cost = vals[<span style="color:#a31515">&#34;cost&#34;</span>]
  state = vals[<span style="color:#a31515">&#34;final_state&#34;</span>]

  costs += cost
  iters += model.input.num_steps

  <span style="color:#00f">if</span> verbose <span style="color:#00f">and</span> step % (model.input.epoch_size // 10) == 10:
    <span style="color:#00f">print</span>(<span style="color:#a31515">&#34;</span><span style="color:#a31515">%.3f</span><span style="color:#a31515"> perplexity: </span><span style="color:#a31515">%.3f</span><span style="color:#a31515"> speed: </span><span style="color:#a31515">%.0f</span><span style="color:#a31515"> wps&#34;</span> %
      (step * 1.0 / model.input.epoch_size, np.exp(costs / iters),
       iters * model.input.batch_size * max(1, FLAGS.num_gpus) /
       (time.time() - start_time)))
</code></pre></div><h3 id="main">main</h3>
<p>起点。学習率はmax_epochまで初期値で、それ以後のepochでは指数的に減少させていく。</p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/train/Supervisor">Supervisor</a>は</p>
<ul>
<li>Threadを調整する<a href="https://www.tensorflow.org/api_docs/python/tf/train/Coordinator">Corrdinator</a></li>
<li>variableを保存する<a href="https://www.tensorflow.org/api_docs/python/tf/train/Saver">Saver</a></li>
<li>チェックポイントからセッションを再開する<a href="https://www.tensorflow.org/api_docs/python/tf/train/SessionManager">SessionManager</a></li>
</ul>
<p>のラッパー。</p>
<blockquote>
<p>追記(2018-07-01): Supervisorはdeprecatedになったので代わりにMonitoredSessionを使うべき。</p>
<p><a href="https://www.sambaiz.net/article/175/">TensorFlowのMonitoredSession - sambaiz-net</a></p>
</blockquote>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2"><code class="language-python" data-lang="python"><span style="color:#00f">with</span> tf.Graph().as_default():
  tf.train.import_meta_graph(metagraph)
  <span style="color:#00f">for</span> model <span style="color:#00f">in</span> models.values():
    model.import_ops()
  sv = tf.train.Supervisor(logdir=FLAGS.save_path)
  config_proto = tf.ConfigProto(allow_soft_placement=soft_placement)
  <span style="color:#00f">with</span> sv.managed_session(config=config_proto) <span style="color:#00f">as</span> session:
    <span style="color:#00f">for</span> i <span style="color:#00f">in</span> range(config.max_max_epoch):
      lr_decay = config.lr_decay ** max(i + 1 - config.max_epoch, 0.0)
      m.assign_lr(session, config.learning_rate * lr_decay)

      <span style="color:#00f">print</span>(<span style="color:#a31515">&#34;Epoch: </span><span style="color:#a31515">%d</span><span style="color:#a31515"> Learning rate: </span><span style="color:#a31515">%.3f</span><span style="color:#a31515">&#34;</span> % (i + 1, session.run(m.lr)))
      train_perplexity = run_epoch(session, m, eval_op=m.train_op,
                                    verbose=True)
      <span style="color:#00f">print</span>(<span style="color:#a31515">&#34;Epoch: </span><span style="color:#a31515">%d</span><span style="color:#a31515"> Train Perplexity: </span><span style="color:#a31515">%.3f</span><span style="color:#a31515">&#34;</span> % (i + 1, train_perplexity))
      valid_perplexity = run_epoch(session, mvalid)
      <span style="color:#00f">print</span>(<span style="color:#a31515">&#34;Epoch: </span><span style="color:#a31515">%d</span><span style="color:#a31515"> Valid Perplexity: </span><span style="color:#a31515">%.3f</span><span style="color:#a31515">&#34;</span> % (i + 1, valid_perplexity))

    test_perplexity = run_epoch(session, mtest)
    <span style="color:#00f">print</span>(<span style="color:#a31515">&#34;Test Perplexity: </span><span style="color:#a31515">%.3f</span><span style="color:#a31515">&#34;</span> % test_perplexity)

    <span style="color:#00f">if</span> FLAGS.save_path:
      <span style="color:#00f">print</span>(<span style="color:#a31515">&#34;Saving model to </span><span style="color:#a31515">%s</span><span style="color:#a31515">.&#34;</span> % FLAGS.save_path)
      sv.saver.save(session, FLAGS.save_path, global_step=sv.global_step)
</code></pre></div><p><a href="https://www.sambaiz.net/article/154/">TensorFlow/RNNで連続的な値を取る時系列データを予測する - sambaiz-net</a></p>
<h2 id="参考">参考</h2>
<p><a href="https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3-%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0-TensorFlow%E3%83%BBKeras%E3%81%AB%E3%82%88%E3%82%8B%E6%99%82%E7%B3%BB%E5%88%97%E3%83%87%E3%83%BC%E3%82%BF%E5%87%A6%E7%90%86-%E5%B7%A3%E7%B1%A0-%E6%82%A0%E8%BC%94/dp/4839962510">詳解 ディープラーニング ~TensorFlow・Kerasによる時系列データ処理~</a></p>
<p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks &ndash; colah&rsquo;s blog</a></p>
<p><a href="https://qiita.com/t_Signull/items/21b82be280b46f467d1b">わかるLSTM ～ 最近の動向と共に - Qiita</a></p>
<p><a href="http://returnn.readthedocs.io/en/latest/tf_lstm_benchmark.html">TensorFlow LSTM benchmark — RETURNN 1.0-dev documentation</a></p>

    </div>
    <div class="share">
      <div class="cell">
        <div>share</div>
        <div>
          <a class="share-button" href='https://twitter.com/intent/tweet?url=https://www.sambaiz.net/article/146/&text=TensorFlow%e3%81%aeRNN%28LSTM%29%e3%81%ae%e3%83%81%e3%83%a5%e3%83%bc%e3%83%88%e3%83%aa%e3%82%a2%e3%83%ab%e3%81%ae%e3%82%b3%e3%83%bc%e3%83%89%e3%82%92%e8%aa%ad%e3%82%80%20-%20sambaiz-net'>
            <img src="/image/twitter.png" width="40px" height="40px" alt="twitter">
          </a>
          <a href="https://b.hatena.ne.jp/entry/" class="share-button hatena-bookmark-button" data-hatena-bookmark-layout="touch" data-hatena-bookmark-width="40" data-hatena-bookmark-height="40" title="このエントリーをはてなブックマークに追加">
            <img src="https://b.st-hatena.com/images/v4/public/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="40" height="40" style="border: none;" />
          </a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
        </div>
      </div>
    </div>
  </article>
</div>

</div>
</body>

</html>