<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.38.2" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/magula.min.css">
    <link rel="stylesheet" href="/css/slidebars.min.css">
    <link rel="stylesheet" href="/css/styles.css">
    <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.sambaiz.net/index.xml">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@sambaiz">
    
    <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net</title>
    <meta name="twitter:title" content="TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net">
    <meta property='og:title' content="TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net">
    <meta property="og:type" content="article">
    
      <meta name="description" content="RNN">
      <meta name="twitter:description" content="RNN">
    
    

    <meta property="og:url" content="https://www.sambaiz.net/article/146/">
    <meta property="og:image" content="https://www.sambaiz.net/images/my_l.jpg">
    <meta name="twitter:image" content="https://www.sambaiz.net/images/my.jpg" />
    <meta name="google-site-verification" content="CEqNYjzc4Y7hb3FY7uUkmllGzeDc40brBwQJixeH61Q" />

<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id":"https://www.sambaiz.net/"
    },
    "headline": "TensorFlowのRNN(LSTM)のチュートリアルのコードを読む | sambaiz-net ",
    "datePublished": "2018-01-03T21:12:00JST",
    "dateModified": "2018-01-03T21:12:00JST",
    "author": {
      "@type": "Person",
      "name": "sambaiz",
      "image": "https://www.sambaiz.net/images/my.jpg"
    },
    "publisher": {
      "@type": "Organization",
      "name": "sambaiz-net",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.sambaiz.net/images/my.jpg",
        "height": 60,
        "width": 60
      }
    },
    "image": {
      "@type": "ImageObject",
      "url": "https://www.sambaiz.net/images/my.jpg",
      "height": 138,
      "width": 138
    },
    "description": "RNN"
  }
</script>
</head>

<body>
  <div off-canvas="id-1 left reveal">
  
  <ul class="tag-list">
    
  </ul>
  
  <ul class="tag-list">
    <li><a href="https://www.sambaiz.net/tags/aws">aws</a></li><li><a href="https://www.sambaiz.net/tags/golang">golang</a></li><li><a href="https://www.sambaiz.net/tags/log">log</a></li><li><a href="https://www.sambaiz.net/tags/unity">unity</a></li><li><a href="https://www.sambaiz.net/tags/fluentd">fluentd</a></li><li><a href="https://www.sambaiz.net/tags/node.js">node.js</a></li><li><a href="https://www.sambaiz.net/tags/infra">infra</a></li><li><a href="https://www.sambaiz.net/tags/tensorflow">tensorflow</a></li><li><a href="https://www.sambaiz.net/tags/kubernetes">kubernetes</a></li><li><a href="https://www.sambaiz.net/tags/web">web</a></li><li><a href="https://www.sambaiz.net/tags/docker">docker</a></li><li><a href="https://www.sambaiz.net/tags/gcp">gcp</a></li><li><a href="https://www.sambaiz.net/tags/elasticsearch">elasticsearch</a></li><li><a href="https://www.sambaiz.net/tags/hololens">hololens</a></li><li><a href="https://www.sambaiz.net/tags/lambda">lambda</a></li><li><a href="https://www.sambaiz.net/tags/linux">linux</a></li><li><a href="https://www.sambaiz.net/tags/mysql">mysql</a></li><li><a href="https://www.sambaiz.net/tags/javascript">javascript</a></li><li><a href="https://www.sambaiz.net/tags/machinelearning">machinelearning</a></li><li><a href="https://www.sambaiz.net/tags/ble">ble</a></li><li><a href="https://www.sambaiz.net/tags/product">product</a></li><li><a href="https://www.sambaiz.net/tags/python">python</a></li><li><a href="https://www.sambaiz.net/tags/android">android</a></li><li><a href="https://www.sambaiz.net/tags/angular">angular</a></li><li><a href="https://www.sambaiz.net/tags/auth">auth</a></li><li><a href="https://www.sambaiz.net/tags/cron">cron</a></li><li><a href="https://www.sambaiz.net/tags/react">react</a></li><li><a href="https://www.sambaiz.net/tags/uwp">uwp</a></li><li><a href="https://www.sambaiz.net/tags/.net">.net</a></li><li><a href="https://www.sambaiz.net/tags/css">css</a></li><li><a href="https://www.sambaiz.net/tags/firebase">firebase</a></li><li><a href="https://www.sambaiz.net/tags/hadoop">hadoop</a></li><li><a href="https://www.sambaiz.net/tags/norikra">norikra</a></li><li><a href="https://www.sambaiz.net/tags/rx">rx</a></li><li><a href="https://www.sambaiz.net/tags/terraform">terraform</a></li><li><a href="https://www.sambaiz.net/tags/vr">vr</a></li><li><a href="https://www.sambaiz.net/tags/api">api</a></li><li><a href="https://www.sambaiz.net/tags/cdn">cdn</a></li><li><a href="https://www.sambaiz.net/tags/circleci">circleci</a></li><li><a href="https://www.sambaiz.net/tags/compress">compress</a></li><li><a href="https://www.sambaiz.net/tags/crypto">crypto</a></li><li><a href="https://www.sambaiz.net/tags/csharp">csharp</a></li><li><a href="https://www.sambaiz.net/tags/d3.js">d3.js</a></li><li><a href="https://www.sambaiz.net/tags/datadog">datadog</a></li><li><a href="https://www.sambaiz.net/tags/event">event</a></li><li><a href="https://www.sambaiz.net/tags/grpc">grpc</a></li><li><a href="https://www.sambaiz.net/tags/hugo">hugo</a></li><li><a href="https://www.sambaiz.net/tags/ios">ios</a></li><li><a href="https://www.sambaiz.net/tags/jenkins">jenkins</a></li><li><a href="https://www.sambaiz.net/tags/jvm">jvm</a></li><li><a href="https://www.sambaiz.net/tags/leveldb">leveldb</a></li><li><a href="https://www.sambaiz.net/tags/math">math</a></li><li><a href="https://www.sambaiz.net/tags/neo4j">neo4j</a></li><li><a href="https://www.sambaiz.net/tags/serialize">serialize</a></li><li><a href="https://www.sambaiz.net/tags/server">server</a></li><li><a href="https://www.sambaiz.net/tags/sonnet">sonnet</a></li><li><a href="https://www.sambaiz.net/tags/spec">spec</a></li><li><a href="https://www.sambaiz.net/tags/statistics">statistics</a></li><li><a href="https://www.sambaiz.net/tags/typescript">typescript</a></li><li><a href="https://www.sambaiz.net/tags/video">video</a></li>
  </ul>
  
</div>

  <div canvas="container" id="container">
    <header>
      <button type="button" class="btn toggle-side">TAG</button>

      <div class="title">
        <img src="https://www.sambaiz.net/images/my.png" width="60px" height="60px" />
        <a class="nl" href="https://www.sambaiz.net/">sambaiz-net</a>
      </div>

      <div class="sns">
        <a class="nl" href="https://twitter.com/sambaiz"><i class="fa fa-2x fa-twitter"></i></a>
        <a class="nl" href="https://github.com/sambaiz"><i class="fa fa-2x fa-github"></i></a>
      </div>
    </header>


<div class="container">

  <div class="row">
    <div class="col-md-12">

      <article class="single">
        <div class="single body">
          <h1>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</h1>
          <p>(2018-01-03)</p>
          

<p>TensorflowのRNN(Recurrent Neural Networks)の<a href="https://www.tensorflow.org/tutorials/recurrent">チュートリアル</a>の<a href="https://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/rnn/ptb/ptb_word_lm.py">コード</a>を読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。</p>

<h2 id="rnn-lstmとは">RNN/LSTMとは</h2>

<p>RNNは入力に対して出力のほかに情報を次のステップに渡すネットワーク。
展開すると同じネットワークに単語を一つずつ入れていくように表現できる。</p>

<p><img src="https://www.sambaiz.net/images/146-rnn.png" alt="RNN" /></p>

<p>TensorflowではいくつかRNNの実装が用意されていて、このコードではそのうちの<code>CudnnLSTM</code>や<code>BasicLSTMCell</code>、<code>LSTMBlockCell</code>を選べるようになっている。<a href="https://developer.nvidia.com/cudnn">cuDNN</a>というのはNVIDIAのCUDAのDNNライブラリのこと。<code>LSTMBlockCell</code>は<code>BasicLSTMCell</code>より速い。</p>

<p>LSTM(Long Short Term Memory networks)はRNNの一種で、入力にtanhを通す通常のRNNの処理に加え、それぞれ重みを持ち、どの値を更新するか決定する<code>input gate</code>や、どの値を忘れるかを決定する<code>forget gate</code>、何を出力するか決定する<code>output gate</code>を通す。
こちらはtanhではなく値域(0,1)のシグモイドを通したものを掛けていくので、0であれば情報は失われ、1であれば完全に残る。</p>

<h2 id="動かしてみる">動かしてみる</h2>

<pre><code>$ git clone https://github.com/tensorflow/models.git
$ cd models/tutorials/rnn/ptb/
$ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz
$ tar xvf simple-examples.tgz 
$ python3 -m venv env
$ . ./env/bin/activate
$ pip install numpy tensorflow
</code></pre>

<pre><code>$ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 5534.452 speed: 894 wps
0.104 perplexity: 845.383 speed: 1277 wps
...
0.803 perplexity: 316.808 speed: 1195 wps
0.903 perplexity: 298.087 speed: 1205 wps
Epoch: 1 Train Perplexity: 283.825
Epoch: 1 Valid Perplexity: 182.132
Epoch: 2 Learning rate: 1.000
...
Epoch: 4 Learning rate: 1.000
...
Epoch: 5 Learning rate: 0.500
...
Epoch: 6 Learning rate: 0.250
...
Epoch: 7 Learning rate: 0.125
...
Epoch: 13 Learning rate: 0.002
...
Test Perplexity: 121.759
</code></pre>

<h2 id="reader">reader</h2>

<p>readerにはテストがあったので、これを使って実際にどんな出力をしているか見てみる。</p>

<h3 id="ptb-raw-data">ptb_raw_data</h3>

<p>単語をIDに変換したものと語彙数が返る。</p>

<pre><code>def setUp(self):
  self._string_data = &quot;\n&quot;.join(
    [&quot; hello there i am&quot;,
     &quot; rain as day&quot;,
     &quot; want some cheesy puffs ?&quot;])

def testPtbRawData(self):
  tmpdir = tf.test.get_temp_dir()
  for suffix in &quot;train&quot;, &quot;valid&quot;, &quot;test&quot;:
    filename = os.path.join(tmpdir, &quot;ptb.%s.txt&quot; % suffix)
    with tf.gfile.GFile(filename, &quot;w&quot;) as fh:
    fh.write(self._string_data)
  # Smoke test
  output = reader.ptb_raw_data(tmpdir)
  print('output: {0}'.format(output))
  # output: (
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # train
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # valid
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # test
  #   12 # vocabulary
  # )
  self.assertEqual(len(output), 4)
</code></pre>

<pre><code>print(word_to_id)
=&gt; {'?': 0, 'am&lt;eos&gt;': 1, 'as': 2, 'cheesy': 3, 'day&lt;eos&gt;': 4, 'hello': 5, 'i': 6, 'puffs': 7, 'rain': 8, 'some': 9, 'there': 10, 'want': 11}
</code></pre>

<h3 id="ptb-producer">ptb_producer</h3>

<p>session.runする度に時系列順に[batch_size, num_steps]のTensorを出力する。
二つ目の返り値は一つ右にずらしたもの。</p>

<pre><code>def testPtbProducer(self):
  raw_data = [
  # t=0↓  t=1↓
    4, 3, 2, 1, 0, 
    5, 6, 1, 1, 1, 
    1, 0, 3, 4, 1
  ]
  batch_size = 3
  num_steps = 2
  x, y = reader.ptb_producer(raw_data, batch_size, num_steps)
  with self.test_session() as session:
    coord = tf.train.Coordinator()
    tf.train.start_queue_runners(session, coord=coord)
    try:
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[4, 3], [5, 6], [1, 0]])
      self.assertAllEqual(yval, [[3, 2], [6, 1], [0, 3]])
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[2, 1], [1, 1], [3, 4]])
      self.assertAllEqual(yval, [[1, 0], [1, 1], [4, 1]])
    finally:
      coord.request_stop()
      coord.join()
</code></pre>

<p>実装はこんな感じ。</p>

<pre><code>i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()
x = tf.strided_slice(data, [0, i * num_steps],
                        [batch_size, (i + 1) * num_steps])
x.set_shape([batch_size, num_steps])
y = tf.strided_slice(data, [0, i * num_steps + 1],
                        [batch_size, (i + 1) * num_steps + 1])
y.set_shape([batch_size, num_steps])
</code></pre>

<p>range_input_producerはその名の通りrangeのように0から値を生成するが、
Threadを調整する<a href="https://www.tensorflow.org/api_docs/python/tf/train/Coordinator">Coordinator</a>を生成し、
<a href="https://www.tensorflow.org/api_docs/python/tf/train/start_queue_runners">start_queue_runners</a>に渡す必要がある。</p>

<pre><code># example of range_input_producer
with self.test_session() as session:
  i = tf.train.range_input_producer(100, shuffle=False).dequeue()
  coord = tf.train.Coordinator()
  tf.train.start_queue_runners(session, coord=coord)
  try:
    print(session.run(i)) # =&gt; 0
    print(session.run(i)) # =&gt; 1
    print(session.run(i)) # =&gt; 2
  finally:
    coord.request_stop()
    coord.join() # Wait for all the threads to terminate.
</code></pre>

<h2 id="model">Model</h2>

<h3 id="入力の準備">入力の準備</h3>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup">embedding_lookup</a>で
embeddingから各stepの単語のものを抽出する。</p>

<pre><code>with tf.device(&quot;/cpu:0&quot;):
  embedding = tf.get_variable(
    &quot;embedding&quot;, [vocab_size, size], dtype=data_type())
  # shape=(batch_size, num_steps, size), dtype=float32
  inputs = tf.nn.embedding_lookup(embedding, input_.input_data)
</code></pre>

<pre><code># example of embedding_lookup
with tf.Session() as session:
  print(session.run(tf.nn.embedding_lookup(
    [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]],
    [[0,1,2], [3,4,5], [6,7,8]]
  ))) 
  # =&gt; [[ 0  2  4]
  #     [ 6  8 10]
  #     [ 1  3  5]]
</code></pre>

<p>学習中の場合、過学習を防ぐためkeep_prob残してDropoutし、RNNのグラフを作り始める。</p>

<pre><code>if is_training and config.keep_prob &lt; 1:
  inputs = tf.nn.dropout(inputs, config.keep_prob)

output, state = self._build_rnn_graph(inputs, config, is_training)
</code></pre>

<h3 id="rnnのグラフ">RNNのグラフ</h3>

<p><code>rnn_mode</code>で実装を選べるようになっているが、基本BLOCK。</p>

<pre><code>def _build_rnn_graph(self, inputs, config, is_training):
  if config.rnn_mode == CUDNN:
    return self._build_rnn_graph_cudnn(inputs, config, is_training)
  else:
    return self._build_rnn_graph_lstm(inputs, config, is_training)
</code></pre>

<p>Cellは<code>LSTMBlockCell</code>をDroopoutWrapperでラップしたもの。
さらにこれをCellの出力が次のCellの入力になる<code>MultiRNNCell</code>で<code>num_layers</code>重ねている。</p>

<p>最初に<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell#zero_state">zero_state</a>の
初期状態から<code>num_steps</code>まわして各stepでのoutputと最後のstateを返す。</p>

<pre><code>def _get_lstm_cell(self, config, is_training):
  if config.rnn_mode == BASIC:
    return tf.contrib.rnn.BasicLSTMCell(
      config.hidden_size, forget_bias=0.0, state_is_tuple=True,
      reuse=not is_training)
  if config.rnn_mode == BLOCK:
    return tf.contrib.rnn.LSTMBlockCell(
      config.hidden_size, forget_bias=0.0)
  raise ValueError(&quot;rnn_mode %s not supported&quot; % config.rnn_mode)

def _build_rnn_graph_lstm(self, inputs, config, is_training):
  def make_cell():
    cell = self._get_lstm_cell(config, is_training)
    if is_training and config.keep_prob &lt; 1:
      cell = tf.contrib.rnn.DropoutWrapper(
        cell, output_keep_prob=config.keep_prob)
    return cell

  cell = tf.contrib.rnn.MultiRNNCell(
    [make_cell() for _ in range(config.num_layers)], state_is_tuple=True)

  self._initial_state = cell.zero_state(config.batch_size, data_type())
  state = self._initial_state

  # [shape=(batch_size, hidden_size) dtype=float32, ...]
  outputs = []
  with tf.variable_scope(&quot;RNN&quot;):
    for time_step in range(self.num_steps):
      if time_step &gt; 0: tf.get_variable_scope().reuse_variables()
      (cell_output, state) = cell(inputs[:, time_step, :], state)
      outputs.append(cell_output)

  # shape=(batch_size * num_steps, hidden_size), dtype=float32
  output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])
  return output, state
</code></pre>

<h3 id="コスト">コスト</h3>

<p>出力層を通したのをlogits(<code>log(p/(1-p)) (0≦p≦1)</code>)として扱い、
<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss">sequence_loss</a>で
logitsのシーケンスの交差エントロピーを求め、その和をコストとする。</p>

<pre><code>output, state = self._build_rnn_graph(inputs, config, is_training)

softmax_w = tf.get_variable(
    &quot;softmax_w&quot;, [size, vocab_size], dtype=data_type())
softmax_b = tf.get_variable(&quot;softmax_b&quot;, [vocab_size], dtype=data_type())
logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)
# shape=(batch_size, num_steps, vocab_size), dtype=float32
logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])

loss = tf.contrib.seq2seq.sequence_loss(
    # logits: [batch_size, sequence_length=num_steps, num_decoder_symbols=vocab_size] and dtype float
    # The logits correspond to the prediction across all classes at each timestep.
    logits,

    # targets: [batch_size, sequence_length=num_steps] and dtype int
    # The target represents the true class at each timestep.
    input_.targets,

    # weights: [batch_size, sequence_length] and dtype float
    # When using weights as masking, set all valid timesteps to 1 and all padded timesteps to 0
    tf.ones([self.batch_size, self.num_steps], dtype=data_type()),

    average_across_timesteps=False,
    average_across_batch=True)

# Update the cost
self._cost = tf.reduce_sum(loss)
self._final_state = state
</code></pre>

<h3 id="勾配">勾配</h3>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/trainable_variables">trainable_variables</a>で
<code>trainable=True</code>(つまり_lr以外)のvariableを取得し、
<a href="https://www.tensorflow.org/api_docs/python/tf/gradients">gradients</a>で各variableに対しての勾配を求め、
<a href="https://www.tensorflow.org/api_docs/python/tf/clip_by_global_norm">clip_by_global_norm</a>で
全体のノルムの大きさを抑える。</p>

<pre><code>if not is_training:
    return

self._lr = tf.Variable(0.0, trainable=False)
tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(self._cost, tvars),
                                    config.max_grad_norm)
</code></pre>

<pre><code># example of trainable_variables
with tf.Session() as session:
  a = tf.Variable(10.0, trainable=False)
  b = tf.Variable(20.0)
  c = tf.get_variable(&quot;c&quot;, [2, 2])
  d = tf.get_variable(&quot;d&quot;, [3, 3], trainable=False)
  session.run(tf.global_variables_initializer())
  print(session.run(tf.trainable_variables()))
  # [20.0, array([[ 1.10110056,  0.6373167 ],
  # [ 0.44673324, -0.11995673]], dtype=float32)]
</code></pre>

<pre><code># example of gradients &amp; clip_by_global_norm
with tf.Session() as session:
  xs = tf.Variable([10., 20., 30.])
  ys = [xs ** 2 + 123, xs * 5]
  grad = tf.gradients(ys,xs)
  session.run(tf.global_variables_initializer())
  print(session.run(grad)) # [20 + 5, 40 + 5, 60 + 5]

  list_clipped, global_norm = session.run(tf.clip_by_global_norm(grad,2))
  # global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))
  # = sqrt(25 ** 2 + 45 ** 2 + 65 ** 2)
  print(global_norm) # 82.9156

  # t_list[i] * clip_norm / max(global_norm, clip_norm)
  # = [25, 45, 65] * 2 / global_norm
  print(list_clipped) # [0.60302269, 1.08544087, 1.56785905]
</code></pre>

<h3 id="optimize">Optimize</h3>

<p>学習率_lrの<code>GradientDescenetOptimizer</code>でoptimizeする。
<a href="https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer#apply_gradients">apply_gradients</a>するたびに
global_stepがインクリメントされる。</p>

<pre><code>optimizer = tf.train.GradientDescentOptimizer(self._lr)
self._train_op = optimizer.apply_gradients(
  zip(grads, tvars),
  global_step=tf.train.get_or_create_global_step())

self._new_lr = tf.placeholder(
  tf.float32, shape=[], name=&quot;new_learning_rate&quot;)
self._lr_update = tf.assign(self._lr, self._new_lr)
</code></pre>

<h3 id="run-epoch">run_epoch</h3>

<p><code>session.run</code>する。</p>

<pre><code>fetches = {
  &quot;cost&quot;: model.cost,
  &quot;final_state&quot;: model.final_state,
}
if eval_op is not None:
  fetches[&quot;eval_op&quot;] = eval_op

for step in range(model.input.epoch_size):
  feed_dict = {}
  for i, (c, h) in enumerate(model.initial_state):
    feed_dict[c] = state[i].c
    feed_dict[h] = state[i].h

  vals = session.run(fetches, feed_dict)
  cost = vals[&quot;cost&quot;]
  state = vals[&quot;final_state&quot;]

  costs += cost
  iters += model.input.num_steps

  if verbose and step % (model.input.epoch_size // 10) == 10:
    print(&quot;%.3f perplexity: %.3f speed: %.0f wps&quot; %
      (step * 1.0 / model.input.epoch_size, np.exp(costs / iters),
       iters * model.input.batch_size * max(1, FLAGS.num_gpus) /
       (time.time() - start_time)))
</code></pre>

<h3 id="main">main</h3>

<p>起点。学習率はmax_epochまで初期値で、それ以後のepochでは指数的に減少させていく。</p>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/train/Supervisor">Supervisor</a>は</p>

<ul>
<li>Threadを調整する<a href="https://www.tensorflow.org/api_docs/python/tf/train/Coordinator">Corrdinator</a></li>
<li>variableを保存する<a href="https://www.tensorflow.org/api_docs/python/tf/train/Saver">Saver</a></li>
<li>チェックポイントからセッションを再開する<a href="https://www.tensorflow.org/api_docs/python/tf/train/SessionManager">SessionManager</a></li>
</ul>

<p>のラッパー。</p>

<pre><code>with tf.Graph().as_default():
  tf.train.import_meta_graph(metagraph)
  for model in models.values():
    model.import_ops()
  sv = tf.train.Supervisor(logdir=FLAGS.save_path)
  config_proto = tf.ConfigProto(allow_soft_placement=soft_placement)
  with sv.managed_session(config=config_proto) as session:
    for i in range(config.max_max_epoch):
      lr_decay = config.lr_decay ** max(i + 1 - config.max_epoch, 0.0)
      m.assign_lr(session, config.learning_rate * lr_decay)

      print(&quot;Epoch: %d Learning rate: %.3f&quot; % (i + 1, session.run(m.lr)))
      train_perplexity = run_epoch(session, m, eval_op=m.train_op,
                                    verbose=True)
      print(&quot;Epoch: %d Train Perplexity: %.3f&quot; % (i + 1, train_perplexity))
      valid_perplexity = run_epoch(session, mvalid)
      print(&quot;Epoch: %d Valid Perplexity: %.3f&quot; % (i + 1, valid_perplexity))

    test_perplexity = run_epoch(session, mtest)
    print(&quot;Test Perplexity: %.3f&quot; % test_perplexity)

    if FLAGS.save_path:
      print(&quot;Saving model to %s.&quot; % FLAGS.save_path)
      sv.saver.save(session, FLAGS.save_path, global_step=sv.global_step)
</code></pre>

<p><a href="https://www.sambaiz.net/article/154/">TensorFlow/RNNで連続的な値を取る時系列データを予測する - sambaiz-net</a></p>

<h2 id="参考">参考</h2>

<p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks &ndash; colah&rsquo;s blog</a></p>

<p><a href="https://qiita.com/t_Signull/items/21b82be280b46f467d1b">わかるLSTM ～ 最近の動向と共に - Qiita</a></p>

<p><a href="http://returnn.readthedocs.io/en/latest/tf_lstm_benchmark.html">TensorFlow LSTM benchmark — RETURNN 1.0-dev documentation</a></p>

        </div>
      </article>
    </div>
  </div>
</div>

</div> 
<script src="//code.jquery.com/jquery-2.1.3.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script src="/js/slidebars.min.js"></script>
<script>
    ( function ( $ ) {
      
      var controller = new slidebars();
      controller.init();

      $( '.toggle-side' ).on( 'click', function ( event ) {
          event.stopPropagation();
          event.preventDefault();

          controller.toggle( 'id-1' );
        } );

        $( '#container' ).on( 'click', function ( event ) {
            controller.close( 'id-1' );
          });
    } ) ( jQuery );
</script>

<script>hljs.initHighlightingOnLoad();</script>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-39190067-3', 'auto');
ga('send', 'pageview');
</script>


  </body>
</html>

