<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sambaiz-net</title>
    <link>https://www.sambaiz.net/index.xml</link>
    <language>ja</language>
    <author>sambaiz</author>
    <rights>(C) 2018</rights>
    <updated>2018-02-25 23:46:00 &#43;0900 JST</updated>

    
      
        <item>
          <title>Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる</title>
          <link>https://www.sambaiz.net/article/157/</link>
          <pubDate>Sun, 25 Feb 2018 23:46:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/157/</guid>
          <description>

&lt;p&gt;UserPoolを作成。デフォルト設定はこんな感じ。
必須項目や、確認メールの文面などを自由にカスタマイズでき、
登録時などのタイミングでLambdaを発火させることもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/157.png&#34; alt=&#34;デフォルト設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作成したUserPoolにアプリクライアントを追加する。
ブラウザで使うのでクライアントシークレットはなし。&lt;/p&gt;

&lt;h2 id=&#34;クライアント側&#34;&gt;クライアント側&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/aws/aws-amplify/tree/master/packages/amazon-cognito-identity-js&#34;&gt;amazon-cognito-identity-js&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;依存するjsを持ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/amazon-cognito-identity.min.js
$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/aws-cognito-sdk.min.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sign UpからAPIを呼ぶところまでのボタンを並べた。
SignInすると以下のデータをそのページのドメインのLocal Storageに保持する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.idToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.accessToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.refreshToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.clockDrift
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.LastAuthUser
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;APIを呼ぶときはidToken(JWT)をAuthorization Headerに乗せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&amp;quot;signUp&amp;quot;&amp;gt;Sign Up&amp;lt;/button&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;label&amp;gt;Code:&amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;code&amp;quot;&amp;gt;&amp;lt;/label&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;button id=&amp;quot;confirm&amp;quot;&amp;gt;Confirm&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;signIn&amp;quot;&amp;gt;Sign In&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;whoAmI&amp;quot;&amp;gt;Who am I?&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;requestAPI&amp;quot;&amp;gt;Request API with token&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;signOut&amp;quot;&amp;gt;Sign Out&amp;lt;/button&amp;gt;

&amp;lt;script src=&amp;quot;aws-cognito-sdk.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;amazon-cognito-identity.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script&amp;gt;
const USER_NAME = &amp;quot;*****&amp;quot;;
const USER_PASSWORD = &amp;quot;*****&amp;quot;;
const USER_EMAIL = &amp;quot;*****&amp;quot;;
class CognitoUserPoolAuth {
  constructor(UserPoolId, clientId, apiEndpoint) {
    const poolData = {
      UserPoolId : UserPoolId,
      ClientId : clientId
    };
    this.userPool = new AmazonCognitoIdentity.CognitoUserPool(poolData);
    this.apiEndpoint = apiEndpoint
  }
  
  signUp(userName, password, email) {
    const attributeList = [];
    if (email) {
      attributeList.push(new AmazonCognitoIdentity.CognitoUserAttribute({
        Name : &#39;email&#39;,
        Value : email
      }));
    }

    return new Promise((resolve, reject) =&amp;gt; {
      this.userPool.signUp(userName, password, attributeList, null, (err, result) =&amp;gt; {
        if (err) {
          return reject(err);
        }
        resolve(result);
      });
    });
  }

  confirmCode(userName, confirmCode) {
    const cognitoUser = this.getCognitoUser(userName);
    return new Promise((resolve, reject) =&amp;gt; {
      cognitoUser.confirmRegistration(confirmCode, true, (err, result) =&amp;gt; {
        if (err) {
          return reject(err);
        }
        resolve(result);
      });
    })
  }

 signIn(userName, password) {
    const authenticationData = {
      Username : userName,
      Password : password,
    };
    const authenticationDetails = new AmazonCognitoIdentity.AuthenticationDetails(authenticationData);
    const cognitoUser = this.getCognitoUser(userName);
    return new Promise((resolve, reject) =&amp;gt; {
      cognitoUser.authenticateUser(authenticationDetails, {
        onSuccess: (result) =&amp;gt; {
          resolve(result.getAccessToken().getJwtToken());
        },

        onFailure: function(err) {
          reject(err);
        },
      });
    });
  }

  signOut() {
    const currentUser = this.currentUser();
    if (!currentUser) return;
    const cognitoUser = this.getCognitoUser(currentUser.username);
    if (!cognitoUser) return;
    cognitoUser.signOut();
  }

  getCognitoUser(userName) {
    const userData = {
      Username : userName,
      Pool : this.userPool
    };
    return new AmazonCognitoIdentity.CognitoUser(userData);
  }

  currentUser() {
    return this.userPool.getCurrentUser()
  }
  
  getJwtToken() {
    return new Promise((resolve, reject) =&amp;gt; {
      const cognitoUser = this.currentUser();
      if (!cognitoUser) {
        return reject(&amp;quot;unauthorized&amp;quot;);
      }
      cognitoUser.getSession((err, result) =&amp;gt; {
        if (err) { 
          return reject(err);
        }
        resolve(result.getIdToken().getJwtToken());
      });
    })
  }

  async requestAPIWithToken() {
    const token = await this.getJwtToken().catch(
      (err) =&amp;gt; {
        console.log(err);
      } 
    );
    const headers = token ? { &#39;Authorization&#39;: token } : {};
    return fetch(this.apiEndpoint, {
      headers: headers
    }).then((response) =&amp;gt; {
      return response.json();
    });
  }
}

(async () =&amp;gt; {
  const auth = new CognitoUserPoolAuth(
    &amp;quot;&amp;lt;poolID&amp;gt;&amp;quot;, 
    &amp;quot;&amp;lt;clientID&amp;gt;&amp;quot;,
    &amp;quot;https://*****.execute-api.us-east-1.amazonaws.com/dev/secret&amp;quot;
  )

  document.getElementById(&amp;quot;signUp&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const result = await auth.signUp(USER_NAME, USER_PASSWORD, USER_EMAIL).catch((err) =&amp;gt; {
      if (err.code === &amp;quot;UsernameExistsException&amp;quot;) {
        return Promise.reject(&amp;quot;User name is already used&amp;quot;);
      } else {
        return Promise.reject(err);
      }
    });
    console.log(`signUp successfully`);
  }, false);

  document.getElementById(&amp;quot;confirm&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const code = document.getElementById(&amp;quot;code&amp;quot;).value;
    const result = await auth.confirmCode(USER_NAME, code);
    console.log(`confirm successfully`);
  }, false);

  document.getElementById(&amp;quot;signIn&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const result = await auth.signIn(USER_NAME, USER_PASSWORD).catch((err) =&amp;gt; {
      if (err.code === &amp;quot;UserNotConfirmedException&amp;quot;) {
        return Promise.reject(&amp;quot;Confirm your email&amp;quot;);
      } else {
        return Promise.reject(err);
      }
    });
    console.log(`signIn successfully`);
  }, false);

  document.getElementById(&amp;quot;whoAmI&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    console.log(auth.currentUser());
  }, false);

  document.getElementById(&amp;quot;requestAPI&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    console.log(await auth.requestAPIWithToken());
  }, false);

  document.getElementById(&amp;quot;signOut&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    auth.signOut();
    console.log(&amp;quot;signout successfully&amp;quot;);
  }, false);
})();
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;api側&#34;&gt;API側&lt;/h2&gt;

&lt;p&gt;Serverless Frameworkで認証の設定をする場合は、
authorizerのarnにUserPoolのARNを入れる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat serverless.yml
service: cognitoapi

provider:
  name: aws
  runtime: nodejs6.10

functions:
  createTodo:
    handler: handler.secret
    events:
      - http:
          path: secret
          cors: true
          method: get
          authorizer:
            arn: ***** # UserPool&#39;s ARN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JWTは.で区切った真ん中がBase64 encodeされたpayloadになっている。これをdecodeして返すだけのAPI。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/136/&#34;&gt;OpenID ConnectのIDトークンの内容と検証 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat handler.js
&#39;use strict&#39;;

module.exports.secret = (event, context, callback) =&amp;gt; {
  const payload = JSON.parse(
    new Buffer(
      event.headers.Authorization.split(&amp;quot;.&amp;quot;)[1], 
      &amp;quot;base64&amp;quot;
    ).toString()
  );
  const response = {
    statusCode: 200,
    body: JSON.stringify({
      userInfo: payload
    }),
    headers: {
      &amp;quot;Access-Control-Allow-Origin&amp;quot;: &amp;quot;*&amp;quot;
    },
  };
  callback(null, response);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。Sign Upしたときにコード付きのメールが送られている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/157.gif&#34; alt=&#34;動作&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ブラウザのwindow間の値渡し</title>
          <link>https://www.sambaiz.net/article/156/</link>
          <pubDate>Fri, 23 Feb 2018 02:01:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/156/</guid>
          <description>

&lt;h2 id=&#34;直接windowを参照する&#34;&gt;直接Windowを参照する&lt;/h2&gt;

&lt;p&gt;プロトコル、ポート、ドメインが全て同じ場合は、親は&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/window.open&#34;&gt;open()&lt;/a&gt;した返り値で、子はwindow.openerで相手のwindowが取れて、直接参照したりDOMを操作したりすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Open window&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;btn2&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
  let win2;
  const button = document.getElementById(&amp;quot;btn&amp;quot;);
  button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    window.foo = &amp;quot;bar from window1&amp;quot;;
    win2 = window.open(&amp;quot;index2.html&amp;quot;);
  }, false);

  const button2 = document.getElementById(&amp;quot;btn2&amp;quot;);
  button2.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    if (win2) {
      win2.close();
    }
  }, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index2.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
  console.log(window.aaa);
  const parentWindow = window.opener;
  const view = document.getElementById(&amp;quot;view&amp;quot;);
  view.textContent = parentWindow.foo; // window1 -&amp;gt; window2

  const button = document.getElementById(&amp;quot;btn&amp;quot;);
  button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    if(!parentWindow) {
      window.close();
    }
    const view = parentWindow.document.getElementById(&amp;quot;view&amp;quot;);
    if (view) {
      view.textContent = &amp;quot;Window2 has been closed by myself&amp;quot;; // window2 -&amp;gt; window1
    }
    window.close();
  }, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認する際はドメインの制約を満たすため&lt;a href=&#34;https://github.com/cloudhead/node-static&#34;&gt;node-static&lt;/a&gt;などでサーバーを立てる必要がある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-1.gif&#34; alt=&#34;直接Windowを参照する値渡し&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;postmessage-https-developer-mozilla-org-ja-docs-web-api-window-postmessage-を使う&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Window/postMessage&#34;&gt;postMessage()&lt;/a&gt;を使う&lt;/h2&gt;

&lt;p&gt;postMessageで送り、messageのeventで受け取れる。ドメインなどが異なっていてもよいが、
どこからでも送れてしまうので、ハンドリングする際は&lt;code&gt;event.origin&lt;/code&gt;が意図したものかチェックしなくてはならない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Open window&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;btn2&amp;quot;&amp;gt;Post to window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
const view = document.getElementById(&amp;quot;view&amp;quot;);
const receiveMessage = (event) =&amp;gt; {
  if (event.origin === &amp;quot;http://localhost:8081&amp;quot;) {
    view.textContent = event.data;
  }
}
window.addEventListener(&amp;quot;message&amp;quot;, receiveMessage, false);

let win2;
const button = document.getElementById(&amp;quot;btn&amp;quot;);
button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
  win2 = window.open(&amp;quot;http://localhost:8081/index2.html&amp;quot;);
}, false);

const button2 = document.getElementById(&amp;quot;btn2&amp;quot;);
button2.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
  win2.postMessage(&amp;quot;bar from window1&amp;quot;, &amp;quot;http://localhost:8081&amp;quot;);
}, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index2.html
&amp;lt;script&amp;gt;
const receiveMessage = (event) =&amp;gt; {
  if (event.origin === &amp;quot;http://localhost:8080&amp;quot;) {
    event.source.postMessage(
      `window2 received data: ${event.data}`,
      event.origin
    );
  }
  window.close();
}
window.addEventListener(&amp;quot;message&amp;quot;, receiveMessage, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;別のポートでも値が渡されていることが確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-2.gif&#34; alt=&#34;postMessage()での値渡し&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;reactでpostmessageする&#34;&gt;ReactでpostMessageする&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;componentDidMount()&lt;/code&gt;でaddEventListenerして&lt;code&gt;componentWillUnmount()&lt;/code&gt;でremoveする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.jsx
class App extends React.Component {
  constructor(props) {
    super(props);
    this.state = {value: &#39;&#39;};
    this.handleChange = this.handleChange.bind(this);
    this.handleMessage = this.handleMessage.bind(this);
    this.openWindow = this.openWindow.bind(this);
  }
  componentDidMount() {
    window.addEventListener(&#39;message&#39;, this.handleMessage);
  }
  componentWillUnmount() {
    window.removeEventListener(&#39;message&#39;, this.handleMessage);
  }
  handleMessage(event) {
    if (
      (window.opener &amp;amp;&amp;amp; event.origin === &amp;quot;http://localhost:8080&amp;quot;) ||
      (!window.opener &amp;amp;&amp;amp; event.origin === &amp;quot;http://localhost:8081&amp;quot;)
    ) {
      this.setState({value: event.data});
    }
  }
  handleChange(event) {
    this.setState({value: event.target.value});
    if (this.newWindow) {
      this.newWindow.postMessage(this.state.value, &amp;quot;http://localhost:8081&amp;quot;); // window1 -&amp;gt; window2
    } else if (window.opener) {
      window.opener.postMessage(this.state.value, &amp;quot;http://localhost:8080&amp;quot;); // window2 -&amp;gt; window1
    }
  }
  openWindow(event) {
    this.newWindow = window.open(&#39;http://localhost:8081/index.html&#39;, &#39;_blank&#39;, &#39;width=640, height=480&#39;);
  }
  render() {
    return &amp;lt;div&amp;gt;
      { !window.opener ? &amp;lt;button onClick={this.openWindow}&amp;gt;Open Window&amp;lt;/button&amp;gt; : &amp;lt;div&amp;gt;&amp;lt;/div&amp;gt;}
      &amp;lt;input type=&amp;quot;text&amp;quot; value={this.state.value} onChange={this.handleChange} /&amp;gt;
    &amp;lt;/div&amp;gt;;
  }
}

ReactDOM.render(
  &amp;lt;App /&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;dic id=&amp;quot;root&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script src=&amp;quot;https://unpkg.com/react@16/umd/react.production.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;https://unpkg.com/react-dom@16/umd/react-dom.production.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev @babel/cli @babel/core @babel/preset-react
$ echo &#39;{ &amp;quot;presets&amp;quot;: [&amp;quot;@babel/preset-react&amp;quot;] }&#39; &amp;gt; .babelrc
$ ./node_modules/.bin/babel index.jsx -o index.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-3.gif&#34; alt=&#34;ReactでpostMessage()での値渡し&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Serverless FrameworkでLambdaをデプロイする</title>
          <link>https://www.sambaiz.net/article/155/</link>
          <pubDate>Sun, 11 Feb 2018 23:20:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/155/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless&#34;&gt;Serverless Framework&lt;/a&gt;でLambda Functionをデプロイする。
Apexが基本的にFunction自体のデプロイしかしないのに対して、こちらはeventの設定なども諸々やってくれて強い。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/140/&#34;&gt;ApexでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g serverless
$ serverless version
1.26.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ApexではFunctionごとにディレクトリが作られたが、Serverlessでは&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/services/#services&#34;&gt;Service&lt;/a&gt;ごとに作られ、
一つのService内で複数のFunctionを定義できる。handlerは同じでも異なっていてもよい。&lt;/p&gt;

&lt;p&gt;Apexの形式の場合、共通の処理をWebpackなどで各Functionに持って来たり、
同じような処理の複数のFunctionを立てる際はコピーする必要があったが、
こちらは必要最小限の変更でそれらを行うことができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless/tree/master/lib/plugins/create/templates&#34;&gt;template&lt;/a&gt;からServiceをcreateする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ serverless create --template aws-nodejs --path testservice
$ ls testservice/
handler.js	serverless.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定ファイル&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/serverless.yml/#serverlessyml-reference&#34;&gt;serverless.yml&lt;/a&gt;
にはLambdaの基本的なもののほかに、VPCやevent、IAM Roleなども書けて、これらはdeploy時に作られるCloudFormationのstackによって管理される。必要なら生のCloudFormationの設定も書ける。&lt;/p&gt;

&lt;p&gt;ApexでもTerraformによって管理することができるが、書くのはこちらの方がはるかに楽。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/144/&#34;&gt;ApexでデプロイしたLambdaのトリガーをTerraformで管理する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat sesrverless.yml
service: testservice

provider:
  name: aws
  profile: foobar
  region: ap-northeast-1
  runtime: nodejs6.10
  memorySize: 512
  timeout: 10
 
functions: 
  hello: 
    handler: handler.hello 
    events:
      - http:
          path: hello/world
          method: get
          cors: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;deployすると&lt;code&gt;{service}-{stage}-{function}&lt;/code&gt;のFunctionが作られる。
今回の場合はtestservice-prd-test。stageをymlでも指定しなかった場合はデフォルト値のdevになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ serverless deploy --stage prd
$ curl https://*****.ap-northeast-1.amazonaws.com/prd/hello/world | jq
{
  &amp;quot;message&amp;quot;: &amp;quot;Go Serverless v1.0! Your function executed successfully!&amp;quot;,
  &amp;quot;input&amp;quot;: {
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;hook&#34;&gt;hook&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless#v1-plugins&#34;&gt;Plugin&lt;/a&gt;で&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/plugins/#lifecycle-events&#34;&gt;Lifecycle Events&lt;/a&gt;を拾えるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppeteer-lambda-starter-kit&lt;/a&gt;は以前からpackage scriptsがあったので、これをServerlessのpackage時に呼ぶことでServerless Framework対応した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev serverless-hooks-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;plugins:
  - serverless-hooks-plugin

custom:
  hooks:
    package:initialize:
      - npm run build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とても便利なのでCloudFormationを使いたくないというわけでなければ、Serverless Frameworkを使っておけばよいと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
          <link>https://www.sambaiz.net/article/154/</link>
          <pubDate>Sun, 11 Feb 2018 19:49:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/154/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/146/&#34;&gt;TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。
全体のコードは&lt;a href=&#34;https://github.com/sambaiz/my_jupyter_notebook/blob/master/rnn-continuous.ipynb&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;入力&#34;&gt;入力&lt;/h3&gt;

&lt;p&gt;以下の関数によって生成した1次元のデータ列。
これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def make_time_series_data(size):
  data = []
  for i in range(size):
    data.append(sin(random.normalvariate(i,0.1)*0.1))
  return np.reshape(np.array(data, dtype=np.float32), (size,1))

def make_batch(data, batch_size, num_steps, num_dimensions, name=None):
  epoch_size =  data.size // (batch_size*num_steps*num_dimensions)
  data = np.lib.stride_tricks.as_strided(
    data, 
    shape=
      (epoch_size,
        batch_size, 
       num_steps+1,
       num_dimensions),
    strides=(
        4*batch_size*num_steps*num_dimensions, 
        4*num_steps*num_dimensions, 
        4*num_dimensions, 
        4 # bytes
    ), 
    writeable=False
  )
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;モデル&#34;&gt;モデル&lt;/h3&gt;

&lt;p&gt;input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。
lossはMSE(Mean squared error)。Optimizerは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer&#34;&gt;GradientDecentOptimizer&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;チュートリアルでは自力で各time_stepの値を&lt;a href=&#34;https://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/rnn/ptb/ptb_word_lm.py#L141&#34;&gt;入れていた&lt;/a&gt;けど、
今回は&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn&#34;&gt;dynamic_rnn()&lt;/a&gt;に任せている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Model(object):dc
  def __init__(self, config, is_training=False):
    # config
    self.batch_size = config.batch_size
    self.num_steps = config.num_steps
    self.num_dimensions = config.num_dimensions
    self.keep_prob = config.keep_prob
    self.hidden_size = config.hidden_size
    self.num_layers = config.num_layers
    
    # placeholder
    self.input = tf.placeholder(tf.float32, [None, self.num_steps, self.num_dimensions], name=&amp;quot;input&amp;quot;)
    self.input_strided = tf.placeholder(tf.float32, [self.batch_size, self.num_steps, self.num_dimensions], name=&amp;quot;input_strided&amp;quot;)
    self.lr = tf.placeholder(tf.float32, name=&amp;quot;learning_rate&amp;quot;)
    
    # input layer
    input = tf.reshape(self.input, [-1, self.num_dimensions])
    input_w = tf.get_variable(&amp;quot;input_w&amp;quot;, [self.num_dimensions, self.hidden_size], dtype=tf.float32)
    input_b = tf.get_variable(&amp;quot;input_b&amp;quot;, [self.hidden_size], dtype=tf.float32)
    input = tf.nn.xw_plus_b(input, input_w, input_b)
    input = tf.reshape(input, [self.batch_size, self.num_steps, self.hidden_size])
    
    # LSTM layer
    output, state = self._build_rnn_graph(input, is_training)
    
    # output layer
    output = tf.reshape(output, [-1, self.hidden_size])
    output_w = tf.get_variable(&amp;quot;output_w&amp;quot;, [self.hidden_size, 1], dtype=tf.float32)
    output_b = tf.get_variable(&amp;quot;output_b&amp;quot;, [1], dtype=tf.float32)
    output = tf.nn.xw_plus_b(output, output_w, output_b)
    self.output = tf.reshape(output, [self.batch_size, self.num_steps, 1])
    
    self.cost = tf.reduce_mean(tf.square(self.output[:, -1, :] - self.input_strided[:, -1, :]))
    self.train_op = tf.train.GradientDescentOptimizer(self.lr).minimize(self.cost, global_step=tf.train.get_or_create_global_step())

  def _build_rnn_graph(self, input, is_training):
    def make_cell():
      cell = tf.contrib.rnn.LSTMBlockCell(
        self.hidden_size, forget_bias=0.0)
      if is_training and self.keep_prob &amp;lt; 1:
        cell = tf.contrib.rnn.DropoutWrapper(
          cell, output_keep_prob=self.keep_prob)
      return cell

    cell = tf.contrib.rnn.MultiRNNCell(
      [make_cell() for _ in range(self.num_layers)], state_is_tuple=True)
    initial_state = cell.zero_state(self.batch_size, tf.float32)
    output, state = tf.nn.dynamic_rnn(cell, input, initial_state=initial_state)
    return output, state

  def learn(self, session, input, input_strided, learning_rate):
    fetches = {
      &amp;quot;cost&amp;quot;: self.cost,
      &amp;quot;train_op&amp;quot;: self.train_op
    }
    feed_dict = {
      self.input: input,
      self.input_strided: input_strided,
      self.lr: learning_rate
    }
    vals = session.run(fetches, feed_dict=feed_dict)
    cost = vals[&amp;quot;cost&amp;quot;]
    return cost

  def predict(self, session, input):
    feed_dict = {
      self.input: np.reshape(input, (1, input.shape[0], input.shape[1]))
    }
    return session.run(self.output, feed_dict=feed_dict)[0,-1]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ハイパーパラメータ&#34;&gt;ハイパーパラメータ&lt;/h3&gt;

&lt;p&gt;調整が難しい。&lt;code&gt;max_epoch&lt;/code&gt;は学習率の初期値(&lt;code&gt;learning_rate&lt;/code&gt;)で学習し続けるepochの数なわけなんだけど、
これを大きくして一気にlossを減らしていこうとしたら案外簡単に収束しなくなってしまった。
&lt;code&gt;num_steps&lt;/code&gt;、つまり予測するのに見る数は今回のデータの場合そんなに大きくある必要はなくて、
むしろ大きくすると平たいグラフになって最大値や最小値との誤差が大きくなった。
&lt;code&gt;hidden_size&lt;/code&gt;や&lt;code&gt;num_layers&lt;/code&gt;は増やしても良さそうだけどメモリが足りなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Config(object):
  init_scale = 0.1
  learning_rate = 1.0
  num_layers = 2
  num_steps = 5
  hidden_size = 200
  max_epoch = 3
  batch_size = 3000
  num_dimensions = 1
  keep_prob = 1.0
  lr_decay = 0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;学習結果&#34;&gt;学習結果&lt;/h3&gt;

&lt;p&gt;300000個のデータから学習して予測させた。
予測値は実際の値と比べて若干振幅が少ないけど、形としては良い感じだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/154.png&#34; alt=&#34;実際のデータと予測結果のグラフ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>xorm reverseでDBスキーマからGoのstructを生成する</title>
          <link>https://www.sambaiz.net/article/153/</link>
          <pubDate>Sat, 10 Feb 2018 15:55:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/153/</guid>
          <description>&lt;p&gt;GoのORMの&lt;a href=&#34;https://github.com/go-xorm/xorm&#34;&gt;xorm&lt;/a&gt;にはxorm reverseというDBのスキーマから以下のようなテンプレートに沿ったGoのstructなどを生成する&lt;a href=&#34;https://github.com/go-xorm/cmd&#34;&gt;ツール&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package {{.Model}}

import (
	{{range .Imports}}&amp;quot;{{.}}&amp;quot;{{end}}
)

{{range .Tables}}
type {{Mapper .Name}} struct {
{{$table := .}}
{{range .Columns}}	{{Mapper .Name}}	{{Type .}}
{{end}}
}

{{end}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リポジトリにある&lt;a href=&#34;https://github.com/go-xorm/cmd/tree/master/xorm/templates&#34;&gt;テンプレート&lt;/a&gt;にxorm用テンプレートとgo用のテンプレートが用意されているように、単体で使うこともできる。
また、テンプレートを書く言語としてもGo以外にC++もサポートしている。&lt;/p&gt;

&lt;p&gt;xormのcmdとドライバをインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/go-xorm/cmd/xorm
$ go get github.com/go-sql-driver/mysql
$ xorm
Version:

    0.2.0524
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;様々な型のカラムを含むテーブルで試す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat schema.sql
CREATE TABLE table1 (
  n_tinyint TINYINT,
  n_int INT,
  n_int_unsigned INT UNSIGNED NOT NULL DEFAULT 1,
  n_bigint BIGINT,
  n_float FLOAT,
  n_double DOUBLE,
  d_date DATE,
  d_datetime DATETIME,
  s_char CHAR(64),
  s_varchar VARCHAR(64),
  s_text TEXT,
  s_json JSON,
  b_binary BLOB,
  e_enum ENUM(&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;)
)

$ cat setup.sh
docker run --name mysql-xorm -p 33306:3306 -e &amp;quot;MYSQL_ALLOW_EMPTY_PASSWORD=yes&amp;quot; -e &amp;quot;MYSQL_DATABASE=testdb&amp;quot; 
while [ $(docker inspect --format &amp;quot;{{.State.Health.Status }}&amp;quot; mysql-xorm) != &amp;quot;healthy&amp;quot; ]; do printf &amp;quot;.&amp;quot;; sleep 1; done
mysql -u root -h 0.0.0.0 -P 33306 -D testdb &amp;lt; schema.sql

$ sh setup.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Goのテンプレートをリポジトリから持ってきてxorm reverseを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls xorm-template
config		struct.go.tpl

$ xorm reverse mysql &amp;quot;root:@tcp(0.0.0.0:33306)/testdb&amp;quot; xorm-template
$ cat model/table1.go 
package model

import (
	&amp;quot;time&amp;quot;
)

type Table1 struct {
	NTinyint     int
	NInt         int
	NIntUnsigned int
	NBigint      int64
	NFloat       float32
	NDouble      float64
	DDate        time.Time
	DDatetime    time.Time
	SChar        string
	SVarchar     string
	SText        string
	SJson        string
	BBinary      []byte
	EEnum        string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;概ねうまくいっているが、現状unsignedは無視されてしまう。
これを修正するには依存しているcoreや&lt;a href=&#34;https://github.com/go-xorm/xorm/blob/430fbe866a716bac8e5307d0c5222346f37cf8cf/engine.go#L340&#34;&gt;xorm本体&lt;/a&gt;に手を入れる必要がありそうだ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DatadogのLambda Integrationで気象データを送ってアラートを飛ばす</title>
          <link>https://www.sambaiz.net/article/152/</link>
          <pubDate>Mon, 05 Feb 2018 23:55:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/152/</guid>
          <description>&lt;p&gt;最近朝が寒くて布団から出るのがつらい。雨や雪が降っていたら尚更のこと、それならそれで現状を把握する必要がある。
そこで、無料から使える気象API &lt;a href=&#34;http://openweathermap.org/&#34;&gt;OpenWeatherMap&lt;/a&gt;のデータをdatadogに送って、特に寒い日や雨雪が降るような朝にはアラートを飛ばすことにした。&lt;/p&gt;

&lt;p&gt;インスタンスが立っていたらDataDog Agentの&lt;a href=&#34;https://docs.datadoghq.com/ja/guides/dogstatsd/&#34;&gt;DogStatsD&lt;/a&gt;経由で送ることができ、
そうでなければ通常は&lt;a href=&#34;https://docs.datadoghq.com/ja/api/#metrics-post&#34;&gt;API&lt;/a&gt;を呼ぶことになるんだけど、Lambdaでは、AWS Integrationを設定すると有効になる&lt;a href=&#34;https://docs.datadoghq.com/ja/integrations/awslambda/&#34;&gt;Lambda Integration&lt;/a&gt;によって
&lt;code&gt;MONITORING|unix_epoch_timestamp|value|metric_type|my.metric.name|#tag1:value,tag2&lt;/code&gt;のフォーマットでconsole.logするだけでメトリクスが送られるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const axios = require(&#39;axios&#39;);

const CITY = &#39;Shibuya&#39;;
const API_KEY = &#39;*****&#39;;
const WEATHER_API = `http://api.openweathermap.org/data/2.5/weather?q=${CITY}&amp;amp;units=metric&amp;amp;appid=${API_KEY}`;

const METRIC_COUNTER = &#39;counter&#39;;
const METRIC_GAUGE = &#39;gauge&#39;;

const monitor = (metricName, metricType, value, tags) =&amp;gt; {
  const unixEpochTimestamp = Math.floor(new Date().getTime());
  console.log(`MONITORING|${unixEpochTimestamp}|${value}|${metricType}|${metricName}|#${tags.join(&#39;,&#39;)}`);
};

exports.handler = async (event, context, callback) =&amp;gt; {
  const data = (await axios.get(WEATHER_API)).data
  const namePrefix = &#39;livinginfo.weather&#39;
  monitor(`${namePrefix}.temperature`, METRIC_GAUGE, data.main.temp, [])
  monitor(`${namePrefix}.rain`, METRIC_GAUGE, data.rain ? data.rain[&amp;quot;3h&amp;quot;] : 0, []);
  monitor(`${namePrefix}.snow`, METRIC_GAUGE, data.snow ? data.snow[&amp;quot;3h&amp;quot;] : 0, []);
  callback(null, &#39;done&#39;);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;送られた。
あとは0度を下回ったときのThreshold Alertや、前日比で下がったときのChange Alertなどを設定すれば良さそうだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/152.png&#34; alt=&#34;グラフ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ローカルでビルドしたimageをminikubeで使う</title>
          <link>https://www.sambaiz.net/article/151/</link>
          <pubDate>Thu, 01 Feb 2018 22:49:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/151/</guid>
          <description>&lt;pre&gt;&lt;code&gt;$ minikube version
minikube version: v0.25.0

$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;9&amp;quot;, GitVersion:&amp;quot;v1.9.2&amp;quot;, GitCommit:&amp;quot;5fa2db2bd46ac79e5e00a4e6ed24191080aa463b&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2018-01-18T21:11:08Z&amp;quot;, GoVersion:&amp;quot;go1.9.2&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;}

$ kubectl config current-context
minikube

$ minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;dockerコマンドがminikube VM内で動いているdocker daemonを参照するようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ minikube docker-env
export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
export DOCKER_HOST=&amp;quot;tcp://192.168.99.100:2376&amp;quot;
export DOCKER_CERT_PATH=&amp;quot;/Users/sambaiz/.minikube/certs&amp;quot;

$ eval $(minikube docker-env)
$ docker info --format &#39;{{json .Name}}&#39;
&amp;quot;minikube&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドするDockerfile。nginxが立ち上がるだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;何もタグを付けない(:latest)とcreate時にDockerレジストリからpullしにいって失敗してしまうため、タグ付きでビルドする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t my/myapp:1.0 .
$ docker images my/myapp
my/myapp   1.0   3f8a4339aadd   5 weeks ago   108 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;deploymentとservice。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: my/myapp:1.0
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
 name: my-app
 labels:
   app: my-app
spec:
 type: NodePort
 ports:
 - port: 80
   nodePort: 30001
 selector:
   app: my-app
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f deployment.yml 
$ kubectl create -f service.yml 
$ kubectl get pods
NAME                      READY     STATUS    RESTARTS   AGE
my-app-5f8c46bf95-xjvrg   1/1       Running   0          11s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドしたimageでpodが動いていることを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl $(minikube service my-app --url)
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
...
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Chromeで任意のscriptを読み込まれる前に差し替える</title>
          <link>https://www.sambaiz.net/article/150/</link>
          <pubDate>Thu, 01 Feb 2018 21:54:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/150/</guid>
          <description>&lt;p&gt;ChromeのDevToolsではSourcesからscriptを書き換えられるようになっているが、
一行目にbreakpointを挟んで更新するとそこで止まるので読み込まれる前に差し替えることができる。
ページの読み込み時に呼ばれるSDKやライブラリの影響範囲を調べたりデバッグしたりするのに便利。&lt;/p&gt;

&lt;p&gt;確認用jsとhtml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;console.log(&amp;quot;original&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&amp;quot;index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;読み込み時に実行されるconsole.logの文章を変えた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/150.gif&#34; alt=&#34;差し替えているところ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す</title>
          <link>https://www.sambaiz.net/article/149/</link>
          <pubDate>Fri, 19 Jan 2018 09:30:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/149/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/pressly/goose&#34;&gt;Goose&lt;/a&gt;はGo製のDB Migrationツール。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/149.gif&#34; alt=&#34;mergeされるとボタンが出る&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/mysql-migration-slack&#34;&gt;コード&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;こんなリポジトリを作成し、各自ブランチを切ってGoose形式のup/downのSQLを書き、終わったらPullRequestを出す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;goose/
  .keep
.circleci/config.yml
create_test_table.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat create_test_table.sql
-- +goose Up
-- SQL in this section is executed when the migration is applied.
CREATE TABLE testtable (
  id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT,
  n INT NOT NULL,
  c VARCHAR (20) NOT NULL UNIQUE
);

-- +goose Down
-- SQL in this section is executed when the migration is rolled back.
DROP TABLE testtable;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事Approveされ、mergeされるとCircleCIが走り、
SQLをgooseディレクトリの中にバージョンを付けて移し、
SlackにpostMessageするエンドポイントにリクエストを飛ばす。&lt;/p&gt;

&lt;p&gt;ここでバージョンを作成することによって、並列で作業し、レビューなどの関係で適用順が前後しても修正する必要をなくしている。ただ、pushされる前に複数のブランチを連続でmergeする場合うまく動かないのでそれはなんとかする必要がある。&lt;/p&gt;

&lt;p&gt;CircleCI 2.0ではApprovalボタンが出せるんだけど、
アクセスしにいくのがちょっと面倒なのと、周知も兼ねてSlackに出したかったので使っていない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: 2
jobs:
  build:
    docker:
      - image: circleci/golang:1.8
    branches:
      only:
        - master
    steps:
      - checkout
      - run:
          name: Create new version
          command: |
            if [ -e *.sql ]; then
              VERSION=$(ls -U1 goose | wc -l | xargs expr 1 + | xargs printf %05d)
              FILENAME=$(find . -maxdepth 1 -name &amp;quot;*.sql&amp;quot; | head | xargs basename)
              mv ${FILENAME} goose/${VERSION}_${FILENAME}
              git config --global user.email &amp;quot;circleci@example.com&amp;quot;
              git config --global user.name &amp;quot;CircleCI&amp;quot;
              git add .
              git commit -m &amp;quot;version ${VERSION}&amp;quot;
              git push origin master
              COMMIT=$(git rev-parse HEAD)
              curl -H &amp;quot;Authorization: Basic $(echo -n &#39;foobar:dolphins&#39; | base64)&amp;quot; &amp;quot;https://*****/auth/message?version=${VERSION}&amp;amp;filename=${FILENAME}&amp;amp;commit=${COMMIT}&amp;quot;
            fi
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;goose/
  .keep
  00001_create_test_table.sql
.circleci/config.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Migrationボタンが押されると、まずボタンを消してRunning状態とし、
処理が終わったら結果を上書きするようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/148/&#34;&gt;SlackのInteractive messagesでボタンの入力を受け付ける - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;slackMessages.action(&#39;migrate&#39;, (payload, respond) =&amp;gt; {
  let replacement = payload.original_message; 
  delete replacement.attachments[0].actions; 
  replacement.attachments[0].text = `start migration by ${payload.user.name} at ${moment().format()}`;
  replacement.attachments[0].fields = [
    { 
       &amp;quot;title&amp;quot;: &amp;quot;State&amp;quot;,
       &amp;quot;value&amp;quot;: &amp;quot;Running&amp;quot;,
       &amp;quot;short&amp;quot;: false
    } 
  ]; 

  exec(
    // Attention to command injection
    `rm -rf ${repositoryName} &amp;amp;&amp;amp; git clone git@github.com:${repositoryPath}.git &amp;amp;&amp;amp; cd ${repositoryName}/goose &amp;amp;&amp;amp; goose mysql &amp;quot;${mySQLConf}&amp;quot; up`, 
    (err, stdout, stderr) =&amp;gt; {
      replacement.attachments[0].fields = [
        { 
          &amp;quot;title&amp;quot;: &amp;quot;Result&amp;quot;,
          &amp;quot;value&amp;quot;: (err || stderr) ? `${stderr || err}` : &amp;quot;Success&amp;quot;,
          &amp;quot;short&amp;quot;: false
        }
      ];
      respond(replacement);
    }
  );
  
  return replacement;
});
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SlackのInteractive messagesでボタンの入力を受け付ける</title>
          <link>https://www.sambaiz.net/article/148/</link>
          <pubDate>Tue, 16 Jan 2018 21:59:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/148/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://api.slack.com/interactive-messages&#34;&gt;Interactive messages&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/148.gif&#34; alt=&#34;ボタンを押す&#34; /&gt;&lt;/p&gt;

&lt;p&gt;まずはサーバーを用意する。コードは&lt;a href=&#34;https://github.com/sambaiz/node-slack-interactive-messages-sample&#34;&gt;ここ&lt;/a&gt;にあって、
Interactive messagesのハンドリングはSlack公式の&lt;a href=&#34;https://github.com/slackapi/node-slack-interactive-messages&#34;&gt;node-slack-interactive-messages&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.use(&#39;/slack&#39;, slackMessages.expressMiddleware());

slackMessages.action(&#39;question_button&#39;, (payload) =&amp;gt; {
  let replacement = payload.original_message;
  replacement.text =`${payload.user.name} likes ${payload.actions[0].value}`;
  delete replacement.attachments[0].actions;
  return replacement;
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ボタンの表示はattachmentsを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;web.chat.postMessage(channelId, &#39;Question&#39;, {
  attachments: [
    {
      text: &amp;quot;Which buttons do you like?&amp;quot;,
      color: &amp;quot;#f9a41b&amp;quot;,
      callback_id: &amp;quot;question_button&amp;quot;,
      actions: [
        {
          name: &amp;quot;primary_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          style: &amp;quot;primary&amp;quot;,
          text: &amp;quot;Primary&amp;quot;,
          value: &amp;quot;Primary Button&amp;quot;,
        },
        {
          name: &amp;quot;normal_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          text: &amp;quot;Normal&amp;quot;,
          value: &amp;quot;Normal Button&amp;quot;
        },
        {
          name: &amp;quot;danger_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          style: &amp;quot;danger&amp;quot;,
          text: &amp;quot;Danger&amp;quot;,
          value: &amp;quot;Danger Button&amp;quot;,
          confirm: {
            title: &amp;quot;Really?&amp;quot;,
            text: &amp;quot;This is danger&amp;quot;,
            ok_text: &amp;quot;Yes&amp;quot;,
            dismiss_text: &amp;quot;No&amp;quot;
          }
        },
      ]
    }
  ]
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;外に公開する必要があるので、メッセージの送信のエンドポイントはBasic認証をかけてみた。
Interactive messagesのエンドポイントはVerification tokenが一致することを確認している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.use(bodyParser.urlencoded({ extended: false }));
app.all(&#39;/auth/*&#39;, (req, res, next) =&amp;gt; {
  const credentials = auth(req);
  if (!credentials || !check(credentials.name, credentials.pass)) {
    res.status(401).send(&#39;Unauthorized&#39;);
  } else {
    next();
  }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://*****.ngrok.com/auth/message -H &amp;quot;Authorization: Basic $(echo -n &#39;foobar:dolphins&#39; | base64)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://api.slack.com/apps&#34;&gt;Build&lt;/a&gt;からWorkspaceを選択してAppを作成し、
Appに紐づくBot Userを追加後、Install Appすると&lt;code&gt;Bot User OAuth Access Token&lt;/code&gt;
が表示されるので、これで&lt;a href=&#34;https://api.slack.com/methods/chat.postMessage&#34;&gt;postMessage&lt;/a&gt;し、Basic InformationのApp Credentialsにある&lt;code&gt;Verification Token&lt;/code&gt;をInteractive messagesのチェックに使う。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://tech.mercari.com/entry/2017/05/23/095500&#34;&gt;GolangでSlack Interactive Messageを使ったBotを書く - Mercari Engineering Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorBoardでsummaryやグラフを見る</title>
          <link>https://www.sambaiz.net/article/147/</link>
          <pubDate>Sun, 07 Jan 2018 21:12:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/147/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/146/&#34;&gt;TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;で読んだコードをTensorboardでみてみる。&lt;/p&gt;

&lt;p&gt;8888がJupyter、6006がTensorboard。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コードをuploadするかJupyterからterminalを開いてcloneしてくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# apt-get update
# apt-get install -y git wget
# git clone https://github.com/tensorflow/models.git
# cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logdirを指定して実行し、Tensorboardを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;flags.DEFINE_string(&amp;quot;save_path&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;Model output directory.&amp;quot;)
sv = tf.train.Supervisor(logdir=FLAGS.save_path)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# tensorboard --logdir=models/tutorials/rnn/ptb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)&lt;/code&gt;による値がリアルタイムに表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard.png&#34; alt=&#34;summaryの推移&#34; /&gt;&lt;/p&gt;

&lt;p&gt;グラフのつながりや、各Operationの入出力やそのshapeを確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard3.png&#34; alt=&#34;グラフ全体&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard2.png&#34; alt=&#34;Operationの入出力&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
          <link>https://www.sambaiz.net/article/146/</link>
          <pubDate>Wed, 03 Jan 2018 21:12:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/146/</guid>
          <description>

&lt;p&gt;TensorflowのRNN(Recurrent Neural Networks)の&lt;a href=&#34;https://www.tensorflow.org/tutorials/recurrent&#34;&gt;チュートリアル&lt;/a&gt;の&lt;a href=&#34;https://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/rnn/ptb/ptb_word_lm.py&#34;&gt;コード&lt;/a&gt;を読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。&lt;/p&gt;

&lt;h2 id=&#34;rnn-lstmとは&#34;&gt;RNN/LSTMとは&lt;/h2&gt;

&lt;p&gt;RNNは入力に対して出力のほかに情報を次のステップに渡すネットワーク。
展開すると同じネットワークに単語を一つずつ入れていくように表現できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/146-rnn.png&#34; alt=&#34;RNN&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TensorflowではいくつかRNNの実装が用意されていて、このコードではそのうちの&lt;code&gt;CudnnLSTM&lt;/code&gt;や&lt;code&gt;BasicLSTMCell&lt;/code&gt;、&lt;code&gt;LSTMBlockCell&lt;/code&gt;を選べるようになっている。&lt;a href=&#34;https://developer.nvidia.com/cudnn&#34;&gt;cuDNN&lt;/a&gt;というのはNVIDIAのCUDAのDNNライブラリのこと。&lt;code&gt;LSTMBlockCell&lt;/code&gt;は&lt;code&gt;BasicLSTMCell&lt;/code&gt;より速い。&lt;/p&gt;

&lt;p&gt;LSTM(Long Short Term Memory networks)はRNNの一種で、入力にtanhを通す通常のRNNの処理に加え、それぞれ重みを持ち、どの値を更新するか決定する&lt;code&gt;input gate&lt;/code&gt;や、どの値を忘れるかを決定する&lt;code&gt;forget gate&lt;/code&gt;、何を出力するか決定する&lt;code&gt;output gate&lt;/code&gt;を通す。
こちらはtanhではなく値域(0,1)のシグモイドを通したものを掛けていくので、0であれば情報は失われ、1であれば完全に残る。&lt;/p&gt;

&lt;h2 id=&#34;動かしてみる&#34;&gt;動かしてみる&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/tensorflow/models.git
$ cd models/tutorials/rnn/ptb/
$ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz
$ tar xvf simple-examples.tgz 
$ python3 -m venv env
$ . ./env/bin/activate
$ pip install numpy tensorflow
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 5534.452 speed: 894 wps
0.104 perplexity: 845.383 speed: 1277 wps
...
0.803 perplexity: 316.808 speed: 1195 wps
0.903 perplexity: 298.087 speed: 1205 wps
Epoch: 1 Train Perplexity: 283.825
Epoch: 1 Valid Perplexity: 182.132
Epoch: 2 Learning rate: 1.000
...
Epoch: 4 Learning rate: 1.000
...
Epoch: 5 Learning rate: 0.500
...
Epoch: 6 Learning rate: 0.250
...
Epoch: 7 Learning rate: 0.125
...
Epoch: 13 Learning rate: 0.002
...
Test Perplexity: 121.759
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;reader&#34;&gt;reader&lt;/h2&gt;

&lt;p&gt;readerにはテストがあったので、これを使って実際にどんな出力をしているか見てみる。&lt;/p&gt;

&lt;h3 id=&#34;ptb-raw-data&#34;&gt;ptb_raw_data&lt;/h3&gt;

&lt;p&gt;単語をIDに変換したものと語彙数が返る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def setUp(self):
  self._string_data = &amp;quot;\n&amp;quot;.join(
    [&amp;quot; hello there i am&amp;quot;,
     &amp;quot; rain as day&amp;quot;,
     &amp;quot; want some cheesy puffs ?&amp;quot;])

def testPtbRawData(self):
  tmpdir = tf.test.get_temp_dir()
  for suffix in &amp;quot;train&amp;quot;, &amp;quot;valid&amp;quot;, &amp;quot;test&amp;quot;:
    filename = os.path.join(tmpdir, &amp;quot;ptb.%s.txt&amp;quot; % suffix)
    with tf.gfile.GFile(filename, &amp;quot;w&amp;quot;) as fh:
    fh.write(self._string_data)
  # Smoke test
  output = reader.ptb_raw_data(tmpdir)
  print(&#39;output: {0}&#39;.format(output))
  # output: (
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # train
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # valid
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # test
  #   12 # vocabulary
  # )
  self.assertEqual(len(output), 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;print(word_to_id)
=&amp;gt; {&#39;?&#39;: 0, &#39;am&amp;lt;eos&amp;gt;&#39;: 1, &#39;as&#39;: 2, &#39;cheesy&#39;: 3, &#39;day&amp;lt;eos&amp;gt;&#39;: 4, &#39;hello&#39;: 5, &#39;i&#39;: 6, &#39;puffs&#39;: 7, &#39;rain&#39;: 8, &#39;some&#39;: 9, &#39;there&#39;: 10, &#39;want&#39;: 11}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ptb-producer&#34;&gt;ptb_producer&lt;/h3&gt;

&lt;p&gt;session.runする度に時系列順に[batch_size, num_steps]のTensorを出力する。
二つ目の返り値は一つ右にずらしたもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def testPtbProducer(self):
  raw_data = [
  # t=0↓  t=1↓
    4, 3, 2, 1, 0, 
    5, 6, 1, 1, 1, 
    1, 0, 3, 4, 1
  ]
  batch_size = 3
  num_steps = 2
  x, y = reader.ptb_producer(raw_data, batch_size, num_steps)
  with self.test_session() as session:
    coord = tf.train.Coordinator()
    tf.train.start_queue_runners(session, coord=coord)
    try:
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[4, 3], [5, 6], [1, 0]])
      self.assertAllEqual(yval, [[3, 2], [6, 1], [0, 3]])
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[2, 1], [1, 1], [3, 4]])
      self.assertAllEqual(yval, [[1, 0], [1, 1], [4, 1]])
    finally:
      coord.request_stop()
      coord.join()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実装はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()
x = tf.strided_slice(data, [0, i * num_steps],
                        [batch_size, (i + 1) * num_steps])
x.set_shape([batch_size, num_steps])
y = tf.strided_slice(data, [0, i * num_steps + 1],
                        [batch_size, (i + 1) * num_steps + 1])
y.set_shape([batch_size, num_steps])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;range_input_producerはその名の通りrangeのように0から値を生成するが、
Threadを調整する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Coordinator&#34;&gt;Coordinator&lt;/a&gt;を生成し、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/start_queue_runners&#34;&gt;start_queue_runners&lt;/a&gt;に渡す必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# example of range_input_producer
with self.test_session() as session:
  i = tf.train.range_input_producer(100, shuffle=False).dequeue()
  coord = tf.train.Coordinator()
  tf.train.start_queue_runners(session, coord=coord)
  try:
    print(session.run(i)) # =&amp;gt; 0
    print(session.run(i)) # =&amp;gt; 1
    print(session.run(i)) # =&amp;gt; 2
  finally:
    coord.request_stop()
    coord.join() # Wait for all the threads to terminate.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;

&lt;h3 id=&#34;入力の準備&#34;&gt;入力の準備&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup&#34;&gt;embedding_lookup&lt;/a&gt;で
embeddingから各stepの単語のものを抽出する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.device(&amp;quot;/cpu:0&amp;quot;):
  embedding = tf.get_variable(
    &amp;quot;embedding&amp;quot;, [vocab_size, size], dtype=data_type())
  # shape=(batch_size, num_steps, size), dtype=float32
  inputs = tf.nn.embedding_lookup(embedding, input_.input_data)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# example of embedding_lookup
with tf.Session() as session:
  print(session.run(tf.nn.embedding_lookup(
    [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]],
    [[0,1,2], [3,4,5], [6,7,8]]
  ))) 
  # =&amp;gt; [[ 0  2  4]
  #     [ 6  8 10]
  #     [ 1  3  5]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;学習中の場合、過学習を防ぐためkeep_prob残してDropoutし、RNNのグラフを作り始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if is_training and config.keep_prob &amp;lt; 1:
  inputs = tf.nn.dropout(inputs, config.keep_prob)

output, state = self._build_rnn_graph(inputs, config, is_training)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rnnのグラフ&#34;&gt;RNNのグラフ&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;rnn_mode&lt;/code&gt;で実装を選べるようになっているが、基本BLOCK。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def _build_rnn_graph(self, inputs, config, is_training):
  if config.rnn_mode == CUDNN:
    return self._build_rnn_graph_cudnn(inputs, config, is_training)
  else:
    return self._build_rnn_graph_lstm(inputs, config, is_training)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cellは&lt;code&gt;LSTMBlockCell&lt;/code&gt;をDroopoutWrapperでラップしたもの。
さらにこれをCellの出力が次のCellの入力になる&lt;code&gt;MultiRNNCell&lt;/code&gt;で&lt;code&gt;num_layers&lt;/code&gt;重ねている。&lt;/p&gt;

&lt;p&gt;最初に&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell#zero_state&#34;&gt;zero_state&lt;/a&gt;の
初期状態から&lt;code&gt;num_steps&lt;/code&gt;まわして各stepでのoutputと最後のstateを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def _get_lstm_cell(self, config, is_training):
  if config.rnn_mode == BASIC:
    return tf.contrib.rnn.BasicLSTMCell(
      config.hidden_size, forget_bias=0.0, state_is_tuple=True,
      reuse=not is_training)
  if config.rnn_mode == BLOCK:
    return tf.contrib.rnn.LSTMBlockCell(
      config.hidden_size, forget_bias=0.0)
  raise ValueError(&amp;quot;rnn_mode %s not supported&amp;quot; % config.rnn_mode)

def _build_rnn_graph_lstm(self, inputs, config, is_training):
  def make_cell():
    cell = self._get_lstm_cell(config, is_training)
    if is_training and config.keep_prob &amp;lt; 1:
      cell = tf.contrib.rnn.DropoutWrapper(
        cell, output_keep_prob=config.keep_prob)
    return cell

  cell = tf.contrib.rnn.MultiRNNCell(
    [make_cell() for _ in range(config.num_layers)], state_is_tuple=True)

  self._initial_state = cell.zero_state(config.batch_size, data_type())
  state = self._initial_state

  # [shape=(batch_size, hidden_size) dtype=float32, ...]
  outputs = []
  with tf.variable_scope(&amp;quot;RNN&amp;quot;):
    for time_step in range(self.num_steps):
      if time_step &amp;gt; 0: tf.get_variable_scope().reuse_variables()
      (cell_output, state) = cell(inputs[:, time_step, :], state)
      outputs.append(cell_output)

  # shape=(batch_size * num_steps, hidden_size), dtype=float32
  output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])
  return output, state
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;コスト&#34;&gt;コスト&lt;/h3&gt;

&lt;p&gt;出力層を通したのをlogits(&lt;code&gt;log(p/(1-p)) (0≦p≦1)&lt;/code&gt;)として扱い、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss&#34;&gt;sequence_loss&lt;/a&gt;で
logitsのシーケンスの交差エントロピーを求め、その和をコストとする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;output, state = self._build_rnn_graph(inputs, config, is_training)

softmax_w = tf.get_variable(
    &amp;quot;softmax_w&amp;quot;, [size, vocab_size], dtype=data_type())
softmax_b = tf.get_variable(&amp;quot;softmax_b&amp;quot;, [vocab_size], dtype=data_type())
logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)
# shape=(batch_size, num_steps, vocab_size), dtype=float32
logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])

loss = tf.contrib.seq2seq.sequence_loss(
    # logits: [batch_size, sequence_length=num_steps, num_decoder_symbols=vocab_size] and dtype float
    # The logits correspond to the prediction across all classes at each timestep.
    logits,

    # targets: [batch_size, sequence_length=num_steps] and dtype int
    # The target represents the true class at each timestep.
    input_.targets,

    # weights: [batch_size, sequence_length] and dtype float
    # When using weights as masking, set all valid timesteps to 1 and all padded timesteps to 0
    tf.ones([self.batch_size, self.num_steps], dtype=data_type()),

    average_across_timesteps=False,
    average_across_batch=True)

# Update the cost
self._cost = tf.reduce_sum(loss)
self._final_state = state
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;勾配&#34;&gt;勾配&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/trainable_variables&#34;&gt;trainable_variables&lt;/a&gt;で
&lt;code&gt;trainable=True&lt;/code&gt;(つまり_lr以外)のvariableを取得し、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/gradients&#34;&gt;gradients&lt;/a&gt;で各variableに対しての勾配を求め、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/clip_by_global_norm&#34;&gt;clip_by_global_norm&lt;/a&gt;で
全体のノルムの大きさを抑える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if not is_training:
    return

self._lr = tf.Variable(0.0, trainable=False)
tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(self._cost, tvars),
                                    config.max_grad_norm)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# example of trainable_variables
with tf.Session() as session:
  a = tf.Variable(10.0, trainable=False)
  b = tf.Variable(20.0)
  c = tf.get_variable(&amp;quot;c&amp;quot;, [2, 2])
  d = tf.get_variable(&amp;quot;d&amp;quot;, [3, 3], trainable=False)
  session.run(tf.global_variables_initializer())
  print(session.run(tf.trainable_variables()))
  # [20.0, array([[ 1.10110056,  0.6373167 ],
  # [ 0.44673324, -0.11995673]], dtype=float32)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# example of gradients &amp;amp; clip_by_global_norm
with tf.Session() as session:
  xs = tf.Variable([10., 20., 30.])
  ys = [xs ** 2 + 123, xs * 5]
  grad = tf.gradients(ys,xs)
  session.run(tf.global_variables_initializer())
  print(session.run(grad)) # [20 + 5, 40 + 5, 60 + 5]

  list_clipped, global_norm = session.run(tf.clip_by_global_norm(grad,2))
  # global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))
  # = sqrt(25 ** 2 + 45 ** 2 + 65 ** 2)
  print(global_norm) # 82.9156

  # t_list[i] * clip_norm / max(global_norm, clip_norm)
  # = [25, 45, 65] * 2 / global_norm
  print(list_clipped) # [0.60302269, 1.08544087, 1.56785905]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;optimize&#34;&gt;Optimize&lt;/h3&gt;

&lt;p&gt;学習率_lrの&lt;code&gt;GradientDescenetOptimizer&lt;/code&gt;でoptimizeする。
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer#apply_gradients&#34;&gt;apply_gradients&lt;/a&gt;するたびに
global_stepがインクリメントされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;optimizer = tf.train.GradientDescentOptimizer(self._lr)
self._train_op = optimizer.apply_gradients(
  zip(grads, tvars),
  global_step=tf.train.get_or_create_global_step())

self._new_lr = tf.placeholder(
  tf.float32, shape=[], name=&amp;quot;new_learning_rate&amp;quot;)
self._lr_update = tf.assign(self._lr, self._new_lr)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;run-epoch&#34;&gt;run_epoch&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;session.run&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fetches = {
  &amp;quot;cost&amp;quot;: model.cost,
  &amp;quot;final_state&amp;quot;: model.final_state,
}
if eval_op is not None:
  fetches[&amp;quot;eval_op&amp;quot;] = eval_op

for step in range(model.input.epoch_size):
  feed_dict = {}
  for i, (c, h) in enumerate(model.initial_state):
    feed_dict[c] = state[i].c
    feed_dict[h] = state[i].h

  vals = session.run(fetches, feed_dict)
  cost = vals[&amp;quot;cost&amp;quot;]
  state = vals[&amp;quot;final_state&amp;quot;]

  costs += cost
  iters += model.input.num_steps

  if verbose and step % (model.input.epoch_size // 10) == 10:
    print(&amp;quot;%.3f perplexity: %.3f speed: %.0f wps&amp;quot; %
      (step * 1.0 / model.input.epoch_size, np.exp(costs / iters),
       iters * model.input.batch_size * max(1, FLAGS.num_gpus) /
       (time.time() - start_time)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;main&#34;&gt;main&lt;/h3&gt;

&lt;p&gt;起点。学習率はmax_epochまで初期値で、それ以後のepochでは指数的に減少させていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Supervisor&#34;&gt;Supervisor&lt;/a&gt;は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Threadを調整する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Coordinator&#34;&gt;Corrdinator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;variableを保存する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Saver&#34;&gt;Saver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;チェックポイントからセッションを再開する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/SessionManager&#34;&gt;SessionManager&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のラッパー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
  tf.train.import_meta_graph(metagraph)
  for model in models.values():
    model.import_ops()
  sv = tf.train.Supervisor(logdir=FLAGS.save_path)
  config_proto = tf.ConfigProto(allow_soft_placement=soft_placement)
  with sv.managed_session(config=config_proto) as session:
    for i in range(config.max_max_epoch):
      lr_decay = config.lr_decay ** max(i + 1 - config.max_epoch, 0.0)
      m.assign_lr(session, config.learning_rate * lr_decay)

      print(&amp;quot;Epoch: %d Learning rate: %.3f&amp;quot; % (i + 1, session.run(m.lr)))
      train_perplexity = run_epoch(session, m, eval_op=m.train_op,
                                    verbose=True)
      print(&amp;quot;Epoch: %d Train Perplexity: %.3f&amp;quot; % (i + 1, train_perplexity))
      valid_perplexity = run_epoch(session, mvalid)
      print(&amp;quot;Epoch: %d Valid Perplexity: %.3f&amp;quot; % (i + 1, valid_perplexity))

    test_perplexity = run_epoch(session, mtest)
    print(&amp;quot;Test Perplexity: %.3f&amp;quot; % test_perplexity)

    if FLAGS.save_path:
      print(&amp;quot;Saving model to %s.&amp;quot; % FLAGS.save_path)
      sv.saver.save(session, FLAGS.save_path, global_step=sv.global_step)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/154/&#34;&gt;TensorFlow/RNNで連続的な値を取る時系列データを予測する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&#34;&gt;Understanding LSTM Networks &amp;ndash; colah&amp;rsquo;s blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/t_Signull/items/21b82be280b46f467d1b&#34;&gt;わかるLSTM ～ 最近の動向と共に - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://returnn.readthedocs.io/en/latest/tf_lstm_benchmark.html&#34;&gt;TensorFlow LSTM benchmark — RETURNN 1.0-dev documentation&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
          <link>https://www.sambaiz.net/article/145/</link>
          <pubDate>Sun, 24 Dec 2017 23:31:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/145/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/athena-admin&#34;&gt;https://github.com/sambaiz/athena-admin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/athena/pricing/&#34;&gt;料金&lt;/a&gt;はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。
データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだけど都度locationを指定して&lt;code&gt;ADD PARTITION&lt;/code&gt;を実行するのは大変。さらにスキーマを変更するのにも&lt;code&gt;ALTER TABLE ADD COLUMNS&lt;/code&gt;などはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。&lt;/p&gt;

&lt;p&gt;ではどうしようもないかというと&lt;code&gt;MSCK REPAIR TABLE&lt;/code&gt;というのがあって、
これはS3のObjectの&lt;code&gt;dt=YYYY-MM-DD&lt;/code&gt;のようなkey=valueのprefixを認識してパーティションを作るもの。作り直す際もこれ1クエリで終わる。それなら最初からそういう風に置けばよいのではというところだけど、勝手に&lt;code&gt;YYYY/MM/DD/HH&lt;/code&gt;のprefixを付けてしまうFirehoseのようなのもある。&lt;/p&gt;

&lt;p&gt;今回作った&lt;a href=&#34;https://github.com/sambaiz/athena-admin&#34;&gt;athena-admin&lt;/a&gt;は以下のような定義ファイルから、
パーティションのkey=valueのprefixが付くように置き換えたり、変更があったらmigrationする。
このファイルを書き換えるだけで基本的にどうにかなるし、バージョン管理すればテーブル定義の変更を追うことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;general&amp;quot;: {
    &amp;quot;athenaRegion&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;,
    &amp;quot;databaseName&amp;quot;: &amp;quot;aaaa&amp;quot;,
    &amp;quot;saveDefinitionLocation&amp;quot;: &amp;quot;s3://saveDefinitionBucket/aaaa.json&amp;quot;
  },
  &amp;quot;tables&amp;quot;: {
    &amp;quot;sample_data&amp;quot;: {
      &amp;quot;columns&amp;quot;: {
        &amp;quot;user_id&amp;quot;: &amp;quot;int&amp;quot;,
        &amp;quot;value&amp;quot;: {
          &amp;quot;score&amp;quot;: &amp;quot;int&amp;quot;,
          &amp;quot;category&amp;quot;: &amp;quot;string&amp;quot;
        } /* &amp;quot;struct&amp;lt;score:int,category:string&amp;gt;&amp;quot; のように書くこともできる */
      },
      &amp;quot;srcLocation&amp;quot;: &amp;quot;s3://src/location/&amp;quot;,
      &amp;quot;partition&amp;quot;: {
        &amp;quot;prePartitionLocation&amp;quot;: &amp;quot;s3://pre/partition/&amp;quot;, /* optional */
        &amp;quot;regexp&amp;quot;: &amp;quot;(\\d{4})/(\\d{2})/(\\d{2})/&amp;quot;, /* optional */
        &amp;quot;keys&amp;quot;: [
          {
            &amp;quot;name&amp;quot;: &amp;quot;dt&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,
            &amp;quot;format&amp;quot;: &amp;quot;{1}-{2}-{3}&amp;quot;, /* optional */
          }
        ]
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使い方はこんな感じ。使い方によっては&lt;code&gt;migrate()&lt;/code&gt;だけ呼ぶこともあると思う。
&lt;code&gt;replaceObjects()&lt;/code&gt;にはmatchedHandlerというのを渡すこともできて、
UTCからJSTに変換するといったこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install athena-admin
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const AthenaAdmin = require(&#39;athena-admin&#39;).AthenaAdmin;
const dbDef = require(&#39;./sampledatabase.json&#39;);
const admin = new AthenaAdmin(dbDef);
await admin.replaceObjects();
await admin.migrate();
await admin.partition();
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ApexでデプロイしたLambdaのトリガーをTerraformで管理する</title>
          <link>https://www.sambaiz.net/article/144/</link>
          <pubDate>Sun, 12 Nov 2017 22:23:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/144/</guid>
          <description>

&lt;p&gt;Apexでfunctionをデプロイするとトリガーが登録されないのであとで追加することになる。
これを手作業で行うこともできるのだけど、せっかくなのでアプリケーションと一緒に管理したい。
そんなときのために&lt;code&gt;terraform&lt;/code&gt;コマンドをラップした&lt;a href=&#34;http://apex.run/#managing-infrastructure&#34;&gt;apex infra&lt;/a&gt;が用意されている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/121/&#34;&gt;TerraformでVPCを管理するmoduleを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;functionsと同列にinfrastructureディレクトリを作成してtfファイルを置く。
その下に環境ごとのディレクトリを作成することもできて、その場合は&lt;code&gt;--env&lt;/code&gt;で指定した環境のものが使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- functions
- infrastructure
  main.tf
  variables.tf
  - modules
    - cloudwatch_schedule
      main.tf
      variables.tf
project.json 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;functionをデプロイするとそのARNが変数で取れるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex list --tfvars
apex_function_hello=&amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回設定するトリガーはCloudwatch Eventのスケジューリング。作成するリソースは以下の通り。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/cloudwatch_event_rule.html&#34;&gt;aws_cloudwatch_event_rule&lt;/a&gt;でイベントルール(今回はschedule)を作成&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/cloudwatch_event_target.html&#34;&gt;aws_cloudwatch_event_target&lt;/a&gt;でルールにターゲット(今回はLambda)を設定&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/lambda_permission.html&#34;&gt;aws_lambda_permission&lt;/a&gt;でルールに対象Lambdaをinvokeする権限を付ける&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ cat infrastructure/modules/cloudwatch_schefule/variables.tf
variable &amp;quot;lambda_function_name&amp;quot; {}
variable &amp;quot;lambda_function_arn&amp;quot; {}
variable &amp;quot;schedule_expression&amp;quot; {
    description = &amp;quot;cloudwatch schedule expression e.g. \&amp;quot;cron(0/5 * * * ? *)\&amp;quot;&amp;quot;
}

$ cat infrastructure/modules/cloudwatch_schefule/main.tf
resource &amp;quot;aws_cloudwatch_event_rule&amp;quot; &amp;quot;lambda&amp;quot; {
  name        = &amp;quot;lambda_rule_${var.lambda_function_name}&amp;quot;
  description = &amp;quot;invoke lambda ${var.lambda_function_name}&amp;quot;
  schedule_expression = &amp;quot;${var.schedule_expression}&amp;quot;
}
 
resource &amp;quot;aws_cloudwatch_event_target&amp;quot; &amp;quot;lambda&amp;quot; {
  target_id = &amp;quot;lambda_target_${var.lambda_function_name}&amp;quot;
  rule      = &amp;quot;${aws_cloudwatch_event_rule.lambda.name}&amp;quot;
  arn       = &amp;quot;${var.lambda_function_arn}&amp;quot;
}
 
resource &amp;quot;aws_lambda_permission&amp;quot; &amp;quot;lambda&amp;quot; {
  statement_id  = &amp;quot;AllowExecutionFromCloudWatch&amp;quot;
  action        = &amp;quot;lambda:InvokeFunction&amp;quot;
  function_name = &amp;quot;${aws_cloudwatch_event_target.lambda.arn}&amp;quot;
  principal     = &amp;quot;events.amazonaws.com&amp;quot;
  source_arn    = &amp;quot;${aws_cloudwatch_event_rule.lambda.arn}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat infrastructure/variables.tf 
variable &amp;quot;apex_function_names&amp;quot; {
    type=&amp;quot;map&amp;quot;
}
variable &amp;quot;apex_function_hello&amp;quot; {}

$ cat infrastructure/main.tf
terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;sambaiz-terraform&amp;quot;
    key    = &amp;quot;usetf.tfstate&amp;quot;
    region = &amp;quot;ap-northeast-1&amp;quot;
  }
}

module &amp;quot;hello_trigger&amp;quot; {
  source = &amp;quot;./modules/cloudwatch_schedule&amp;quot;
  lambda_function_name = &amp;quot;${var.apex_function_names[&amp;quot;hello&amp;quot;]}&amp;quot;
  lambda_function_arn = &amp;quot;${var.apex_function_hello}&amp;quot;
  schedule_expression = &amp;quot;cron(0/5 * * * ? *)&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;init&lt;/code&gt;してbackendを初期化してmoduleを準備する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra init
$ ls infrastructure/.terraform/modules/*****
main.tf		variables.tf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;plan&lt;/code&gt;するとこんな感じ。ApexによってfunctionのARNが渡っていることが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra plan
+ module.hello_trigger.aws_cloudwatch_event_rule.lambda
    arn:                 &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    description:         &amp;quot;invoke lambda usetf_hello&amp;quot;
    is_enabled:          &amp;quot;true&amp;quot;
    name:                &amp;quot;lambda_rule_usetf_hello&amp;quot;
    schedule_expression: &amp;quot;cron(0/5 * * * ? *)&amp;quot;

+ module.hello_trigger.aws_cloudwatch_event_target.lambda
    arn:       &amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
    rule:      &amp;quot;lambda_rule_usetf_hello&amp;quot;
    target_id: &amp;quot;lambda_target_usetf_hello&amp;quot;

+ module.hello_trigger.aws_lambda_permission.lambda
    action:        &amp;quot;lambda:InvokeFunction&amp;quot;
    function_name: &amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
    principal:     &amp;quot;events.amazonaws.com&amp;quot;
    source_arn:    &amp;quot;${aws_cloudwatch_event_rule.lambda.arn}&amp;quot;
    statement_id:  &amp;quot;AllowExecutionFromCloudWatch&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apply&lt;/code&gt;するとトリガーが登録される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra apply
$ apex logs hello
...
/aws/lambda/usetf_hello 2017-11-12T13:20:14.561Z	37e75818-c7ac-11e7-a333-111863808b13	processing event:
...
/aws/lambda/usetf_hello 2017-11-12T13:25:15.182Z	eb178941-c7ac-11e7-bde0-998ea9659640 processing event:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://dev.classmethod.jp/cloud/aws/ami-and-snapshot-delete-with-apex-and-terraform/&#34;&gt;ApexとTerraformでCloudWatch EventsによりInvokeされるLambda関数をデプロイする ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>JavaScriptのrequire/import</title>
          <link>https://www.sambaiz.net/article/143/</link>
          <pubDate>Sat, 11 Nov 2017 20:20:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/143/</guid>
          <description>

&lt;h2 id=&#34;scriptタグを並べる&#34;&gt;scriptタグを並べる&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;body&amp;gt;
&amp;lt;script src=&amp;quot;a.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;b.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先に書かれた&lt;code&gt;a.js&lt;/code&gt;で定義された内容は&lt;code&gt;b.js&lt;/code&gt;で読むことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat a.js 
const a = &#39;a is defined&#39;;
const divA = document.createElement(&#39;div&#39;);
divA.textContent = (typeof b !== &#39;undefined&#39;) ? b : &#39;b is undefined&#39;;
document.body.appendChild(divA);

$ cat b.js 
const b = &#39;b is defined&#39;;
const divB = document.createElement(&#39;div&#39;);
divB.textContent = (typeof a !== &#39;undefined&#39;) ? a : &#39;a is undefined&#39;;
document.body.appendChild(divB);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;依存が増えてくると順番を考えるのが大変。さらにグローバルな名前空間を汚染してしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b is undefined
a is defined
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;amdとcommonjs&#34;&gt;AMDとCommonJS&lt;/h2&gt;

&lt;p&gt;というのも、かつてのJSにはモジュールを読み込む仕組みがなかった。
そこで考えられたのがAMDやCommonJSというフォーマット。
AMD(Asynchronous module definition)は&lt;a href=&#34;http://requirejs.org/&#34;&gt;RequireJS&lt;/a&gt;によって提供される&lt;code&gt;require()&lt;/code&gt;で動的にscriptタグを埋める。CommonJSはNodeでもおなじみの&lt;code&gt;require()&lt;/code&gt;で、これにWebpackを通して一つのファイルにまとめておく。同じ関数名が使われているが全くの別物。&lt;/p&gt;

&lt;h2 id=&#34;es-modules&#34;&gt;ES Modules&lt;/h2&gt;

&lt;p&gt;今は言語仕様にECMAScript Modulesが追加され、普通に&lt;code&gt;import&lt;/code&gt;でモジュールを読み込めるようになったが、
対応ブラウザがまだ少ないこともあり基本的にはWebpackをかけることになる。
Nodeにも実装されつつあるがStableになるのは&lt;a href=&#34;https://nodejs.org/api/esm.html&#34;&gt;まだ先&lt;/a&gt;のようだ。&lt;/p&gt;

&lt;h2 id=&#34;requirejs-http-requirejs-org&#34;&gt;&lt;a href=&#34;http://requirejs.org/&#34;&gt;RequireJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;define()&lt;/code&gt;でモジュールを定義し、&lt;code&gt;require()&lt;/code&gt;で読み込む。
エントリーポイントは&lt;code&gt;data-main&lt;/code&gt;に指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/b.js
require([&#39;a&#39;], (a) =&amp;gt; {
  const divB = document.createElement(&#39;div&#39;);
  divB.textContent = a.a();
  document.body.appendChild(divB);
});

$ cat src/a.js
define({
  a: () =&amp;gt; &#39;a is defined&#39;
});

$ cat src/index.html
&amp;lt;body&amp;gt;
&amp;lt;script data-main=&amp;quot;b.js&amp;quot; src=&amp;quot;require.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CommonJSのモジュールを読み込もうとするとエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/c.js 
const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

$ cat src/d.js 
exports.d = () =&amp;gt; &#39;d is defined&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Uncaught Error: Module name &amp;quot;d&amp;quot; has not been loaded yet for context: _. Use require([])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RequireJSのNode版、&lt;a href=&#34;https://github.com/requirejs/r.js&#34;&gt;r.js&lt;/a&gt;でCommonJSのモジュールをAMDに変換することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g requirejs
$ r.js -convert src out
$ cat c.js 
define(function (require, exports, module) {const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

});

$ cat d.js 
define(function (require, exports, module) {exports.d = () =&amp;gt; &#39;d is defined&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、Webpackのようにコードを一つのjsファイルにbundleすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ r.js -o baseUrl=out name=b out=bundle.js optimize=none
$ cat bundle.js 
define(&#39;a&#39;,{
  a: () =&amp;gt; &#39;a is defined&#39;
});

define(&#39;d&#39;,[&#39;require&#39;,&#39;exports&#39;,&#39;module&#39;],function (require, exports, module) {exports.d = () =&amp;gt; &#39;d is defined&#39;;


});

define(&#39;c&#39;,[&#39;require&#39;,&#39;exports&#39;,&#39;module&#39;,&#39;d&#39;],function (require, exports, module) {const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

});

require([&#39;a&#39;,&#39;c&#39;], (a,c) =&amp;gt; {
  const divB = document.createElement(&#39;div&#39;);
  divB.textContent = a.a();
  document.body.appendChild(divB);

  const divB2 = document.createElement(&#39;div&#39;);
  divB2.textContent = c.c();
  document.body.appendChild(divB2);
});

define(&amp;quot;b&amp;quot;, function(){});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに&lt;code&gt;optimize=none&lt;/code&gt;を付けているのはES6のコードに対応していないため。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;If the source uses ES2015 or later syntax, please pass &amp;quot;optimize: &#39;none&#39;&amp;quot; to r.js and use an ES2015+ compatible minifier after running r.js. The included UglifyJS only understands ES5 or earlier syntax.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/guybedford/require-css&#34;&gt;guybedford/require-css&lt;/a&gt;を使うと
cssも依存に含めることができ、scriptタグと同様にstyleタグが動的に入る。&lt;/p&gt;

&lt;h2 id=&#34;webpack-https-webpack-js-org&#34;&gt;&lt;a href=&#34;https://webpack.js.org/&#34;&gt;Webpack&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;webpack.config.js&lt;/code&gt;の
&lt;code&gt;entry&lt;/code&gt;にエントリーポイント、
&lt;code&gt;output&lt;/code&gt;に出力場所、
&lt;code&gt;module&lt;/code&gt;にJS以外のファイルをbundleするloader、
&lt;code&gt;plugins&lt;/code&gt;に全体を処理するpluginの
設定を書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev webpack html-webpack-plugin
$ cat webpack.config.js 
const HtmlWebpackPlugin = require(&#39;html-webpack-plugin&#39;);
const webpack = require(&#39;webpack&#39;);
const path = require(&#39;path&#39;);

const config = {
  entry: &#39;./src/main.js&#39;,
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;bundle.js&#39;
  },
  module: {},
  plugins: [
    // new webpack.optimize.UglifyJsPlugin(),
    new HtmlWebpackPlugin({template: &#39;./src/index.html&#39;})
  ]
};

module.exports = config;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ES Modulesの記法を使っている。CommonJSにも対応しているが今はこちらが&lt;a href=&#34;https://webpack.js.org/api/module-methods/&#34;&gt;推奨&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js 
import { bar } from &#39;./foo&#39;;
const div = document.createElement(&#39;div&#39;);
div.textContent = bar();
document.body.appendChild(div);

$ cat src/foo.js 
export function bar() {
  return &#39;bar&#39;;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行するとこんな感じにbundleされる。実際はUglifyJsPluginによってもう少しサイズが小さくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ node_modules/.bin/webpack 
$ cat dist/index.html 
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;Test&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;

$ z$ cat dist/bundle.js 
/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
...
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ([
/* 0 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

&amp;quot;use strict&amp;quot;;
Object.defineProperty(__webpack_exports__, &amp;quot;__esModule&amp;quot;, { value: true });
/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__foo__ = __webpack_require__(1);

const div = document.createElement(&#39;div&#39;);
div.textContent = Object(__WEBPACK_IMPORTED_MODULE_0__foo__[&amp;quot;a&amp;quot; /* bar */])();
document.body.appendChild(div);


/***/ }),
/* 1 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

&amp;quot;use strict&amp;quot;;
/* harmony export (immutable) */ __webpack_exports__[&amp;quot;a&amp;quot;] = bar;
function bar() {
  return &#39;bar&#39;;
};


/***/ })
/******/ ]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/webpack-contrib/css-loader&#34;&gt;css-loader&lt;/a&gt;でCSSをbundleする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev style-loader css-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CSS Moduleを有効にして、ほかの同名のクラスに影響を及ぼさないようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module: {
    rules: [
      {
        test: /\.css$/,
        use: [ 
          &#39;style-loader&#39;, 
          {
            loader: &#39;css-loader&#39;,
            options: {
              modules: true,
            }
          }
        ]
      }
    ]
  },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;importするとCSSに書かれたクラスと変換後の対応が取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js 
import { bar } from &#39;./foo&#39;;
import css from &#39;./style.css&#39;;

const div = document.createElement(&#39;div&#39;);
div.textContent = bar();
div.className = css[&#39;bg&#39;]; /* {&amp;quot;bg&amp;quot;:&amp;quot;_2T2hBh3FkCro4-BOuqaGg5&amp;quot;} */
document.body.appendChild(div);

$ cat src/style.css 
.bg {
  background-color: #22ee22;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じでbundleされている。動的にstyleタグが入るのは同じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat dist/bundle.js | grep &amp;quot;#22ee22&amp;quot;
exports.push([module.i, &amp;quot;._2T2hBh3FkCro4-BOuqaGg5 {\n  background-color: #22ee22;\n}\n&amp;quot;, &amp;quot;&amp;quot;]);
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>圧縮アルゴリズムZopfliとBrotli</title>
          <link>https://www.sambaiz.net/article/142/</link>
          <pubDate>Fri, 03 Nov 2017 15:00:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/142/</guid>
          <description>

&lt;p&gt;どちらもGoogleが開発した圧縮アルゴリズム。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppetter-lambda-starter-kit&lt;/a&gt;
の&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/issues/2&#34;&gt;issue&lt;/a&gt;に
現在使っているgzipと、Zopfli、Brotliを比較したデータが上がっていたので調べてみた。&lt;/p&gt;

&lt;h2 id=&#34;zopfli-https-github-com-google-zopfli&#34;&gt;&lt;a href=&#34;https://github.com/google/zopfli&#34;&gt;Zopfli&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;出力としてDeflateに対応している。&lt;/p&gt;

&lt;h3 id=&#34;deflate&#34;&gt;Deflate&lt;/h3&gt;

&lt;p&gt;LZ77(実際は改良版のLZSS)とハフマン記号による可逆圧縮アルゴリズム。
zip、zlib、gzip、pngなどで使われていて、これらはヘッダーやフッターが異なる。
LZSSはバイト列を見ていって同じ部分を発見したらそこを参照するように置き換えていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a b c a b c a b c d d d
=&amp;gt; a b c (距離3, 長さ6) d (距離１, 長さ2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このLZSSにあたる部分をZopfliはがんばってやるので圧縮時間が結構かかるがサイズは小さくなるらしい。
展開は通常のDeflate通り。上げてくれたデータを見ても大体そんな感じだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/google/zopfli
$ cd zopfli
$ make zopfli
$ ./zopfli aaaa
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;brotli-https-github-com-google-brotli&#34;&gt;&lt;a href=&#34;https://github.com/google/brotli&#34;&gt;Brotli&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;LZ77、ハフマン記号に加えて2nd order context modelingというのを使って圧縮する
Deflateではない可逆圧縮アルゴリズム。
Safari以外のモダンなブラウザで既に対応しているか対応しているところ。
対応している場合、&lt;code&gt;Accept-Encoding&lt;/code&gt;や&lt;code&gt;Content-Encoding&lt;/code&gt;ヘッダに含まれるのは&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Content-Encoding&#34;&gt;br&lt;/a&gt;。
圧縮率も展開時間もかなり良さそう。&lt;/p&gt;

&lt;p&gt;Nodeにもblotliのライブラリが&lt;a href=&#34;https://github.com/devongovett/brotli.js&#34;&gt;あって&lt;/a&gt;、
圧縮はEmscriptenで&lt;a href=&#34;https://github.com/google/brotli&#34;&gt;本家のC++コード&lt;/a&gt;から変換し、
展開は手で移植しているようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install blotli
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
const brotli = require(&#39;brotli&#39;);
const TARGET = process.env.TARGET;
const MODE = process.env.MODE;

const compress = () =&amp;gt; {
  const target = fs.readFileSync(TARGET);
  const compressed = brotli.compress(target, {
    quality: 11,
  });
  fs.writeFileSync(`${TARGET}.br`, compressed);
};

const decompress = () =&amp;gt; {
  const target = fs.readFileSync(TARGET);
  const decompressed = brotli.decompress(target);
  fs.writeFileSync(`${TARGET.replace(&#39;.br&#39;, &#39;&#39;)}`, decompressed);
};

(async () =&amp;gt; {
    if (MODE === &#39;decompress&#39;) {
        decompress();
    } else {
        compress();
    }
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただ、これで大きなファイルを圧縮しようとすると以下のようなエラーが出て失敗する。
設定を変えてコンパイルするのも面倒なので、圧縮はCLIでやることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ TARGET=headless_shell node compress.js 
Cannot enlarge memory arrays. Either (1) compile with  -s TOTAL_MEMORY=X  with X higher than the current value 318767104, (2) compile with  -s ALLOW_MEMORY_GROWTH=1  which adjusts the size at runtime but prevents some optimizations, (3) set Module.TOTAL_MEMORY to a higher value before the program runs, or if you want malloc to return NULL (0) instead of this abort, compile with  -s ABORTING_MALLOC=0 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リポジトリをcloneしてきてmake installする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/google/brotli.git
$ cd brotli
$ mkdir out &amp;amp;&amp;amp; cd out
$ ../configure-cmake
$ make
$ make test
$ make install
$ brotli --version
brotli 1.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトで最高レベル(11)で圧縮することもあり、かなり時間がかかる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ time brotli headless_shell
$ time brotli headless_shell

real	18m41.814s
user	18m6.485s
sys	0m7.906s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;gzipだと最高レベルで圧縮しても43MBまでのところ、33MBまで圧縮できた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;131M headless_shell
33M  headless_shell.br
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;展開はすぐ。むしろgzipより速い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ time TARGET=aaaa.br MODE=decompress node compress.js

real	0m5.850s
user	0m4.626s
sys	0m1.030s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということで、brotli対応版を出そうとしたが、Lambdaでdecompressしたら&lt;code&gt;JavaScript heap out of memory&lt;/code&gt;になってしまった。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/7shi/deflate&#34;&gt;Deflate&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/jkr_2255/items/f3dfdf08267f2a8b590a&#34;&gt;Zopfliで高圧縮gzip・PNGほか - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Redashでデータを可視化する</title>
          <link>https://www.sambaiz.net/article/141/</link>
          <pubDate>Mon, 23 Oct 2017 23:59:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/141/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/getredash/redash&#34;&gt;Redash&lt;/a&gt;はOSSのデータ可視化ツール。
BIツールのようにパラメータを変えながら指標を探っていくというよりは、分かっている指標を見るのに使うイメージ。
比較的機能が少ない分処理がわかりやすく、
クエリが自動生成されないため時間がかかるものを実行する前にある程度気づけるのが良いと思う。&lt;/p&gt;

&lt;p&gt;docker-composeで立ち上げることもできるけど、
AWSの各リージョンに&lt;a href=&#34;https://redash.io/help-onpremise/setup/setting-up-redash-instance.html&#34;&gt;AMIが用意されている&lt;/a&gt;のでそれで立ち上げる。&lt;/p&gt;

&lt;p&gt;sshで入って以下のようなのを必要に応じて設定する。
メールを送る場合はSESでメールアドレスをVerifyしてやるのが簡単。
GSuiteを使っている場合、OAuthのClientID、Secretを発行しドメインを登録するとそれで認証できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh ubuntu@*****
$ sudo vi /opt/redash/.env
export REDASH_MAIL_SERVER=&amp;quot;email-smtp.us-east-1.amazonaws.com&amp;quot;
export REDASH_MAIL_USE_TLS=&amp;quot;true&amp;quot;
export REDASH_MAIL_USERNAME=&amp;quot;*****&amp;quot;
export REDASH_MAIL_PASSWORD=&amp;quot;*****&amp;quot;
export REDASH_MAIL_DEFAULT_SENDER=&amp;quot;*****&amp;quot; # Email address to send from

export REDASH_GOOGLE_CLIENT_ID=&amp;quot;&amp;quot;
export REDASH_GOOGLE_CLIENT_SECRET=&amp;quot;&amp;quot;

$ cd /opt/redash/current
$ sudo -u redash bin/run ./manage.py org set_google_apps_domains {{domains}}
$ sudo supervisorctl restart all
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTTPS対応するのに&lt;code&gt;/etc/nginx/sites-available/redash&lt;/code&gt;を編集する。crtとkeyの場所は変える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;upstream rd_servers {
  server 127.0.0.1:5000;
}

server {

  server_tokens off;

  listen 80 default;

  access_log /var/log/nginx/rd.access.log;

  gzip on;
  gzip_types *;
  gzip_proxied any;

  location /ping {
    proxy_set_header Host $http_host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_pass       http://rd_servers;
  }
  
  location / {
    return 301 https://$host$request_uri; 
  }
}

server {
  listen 443 ssl;

  # Make sure to set paths to your certificate .pem and .key files.
  ssl on;
  ssl_certificate /path-to/cert.pem; # or crt
  ssl_certificate_key /path-to/cert.key;

  # Specifies that we don&#39;t want to use SSLv2 (insecure) or SSLv3 (exploitable)
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
  # Uses the server&#39;s ciphers rather than the client&#39;s
  ssl_prefer_server_ciphers on;
  # Specifies which ciphers are okay and which are not okay. List taken from https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html
  ssl_ciphers &amp;quot;EECDH+AESGCM:EDH+AESGCM:ECDHE-RSA-AES128-GCM-SHA256:AES256+EECDH:DHE-RSA-AES128-GCM-SHA256:AES256+EDH:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4&amp;quot;;

  access_log /var/log/nginx/redash.access.log;

  gzip on;
  gzip_types *;
  gzip_proxied any;

  location / {
    proxy_set_header Host $http_host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_pass       http://rd_servers;
    proxy_redirect   off;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;諸々のデータはローカルで動いているPostgreSQLに入っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redash-# \d
                       List of relations
 Schema |               Name               |   Type   | Owner  
--------+----------------------------------+----------+--------
 public | access_permissions               | table    | redash
 public | access_permissions_id_seq        | sequence | redash
 public | alembic_version                  | table    | redash
 public | alert_subscriptions              | table    | redash
 public | alert_subscriptions_id_seq       | sequence | redash
 public | alerts                           | table    | redash
 public | alerts_id_seq                    | sequence | redash
 public | api_keys                         | table    | redash
 public | api_keys_id_seq                  | sequence | redash
 public | changes                          | table    | redash
 public | changes_id_seq                   | sequence | redash
 public | dashboards                       | table    | redash
 public | dashboards_id_seq                | sequence | redash
 public | data_source_groups               | table    | redash
 public | data_source_groups_id_seq        | sequence | redash
 public | data_sources                     | table    | redash
 public | data_sources_id_seq              | sequence | redash
 public | events                           | table    | redash
 public | events_id_seq                    | sequence | redash
 public | groups                           | table    | redash
 public | groups_id_seq                    | sequence | redash
 public | notification_destinations        | table    | redash
 public | notification_destinations_id_seq | sequence | redash
 public | organizations                    | table    | redash
 public | organizations_id_seq             | sequence | redash
 public | queries                          | table    | redash
 public | queries_id_seq                   | sequence | redash
 public | query_results                    | table    | redash
 public | query_results_id_seq             | sequence | redash
 public | query_snippets                   | table    | redash
 public | query_snippets_id_seq            | sequence | redash
 public | users                            | table    | redash
 public | users_id_seq                     | sequence | redash
 public | visualizations                   | table    | redash
 public | visualizations_id_seq            | sequence | redash
 public | widgets                          | table    | redash
 public | widgets_id_seq                   | sequence | redash
(37 rows)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なので&lt;a href=&#34;https://redash.io/help-onpremise/misc/backup-your-redash-database-and-restore-it-on-a-different-server.html&#34;&gt;他の環境に移すとき&lt;/a&gt;はこのdumpを取ってリストアする。バックアップを取っておくと良い。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-start.png&#34; alt=&#34;最初の画面&#34; /&gt;&lt;/p&gt;

&lt;p&gt;データソースを登録する。MySQLやRedshift、AthenaやBigQueryのほかにHive、ElasticSearchなども選べる。
今回はMySQL(Amazon RDS)を選択した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-datasource.png&#34; alt=&#34;データソースの登録&#34; /&gt;&lt;/p&gt;

&lt;p&gt;適当なデータをいれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const mysql = require(&#39;mysql&#39;);
const connection = mysql.createConnection({
  host     : &#39;*****&#39;,
  user     : &#39;*****&#39;,
  password : &#39;*****&#39;,
  database : &#39;*****&#39;
});

const query = (connection, query, params) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {
    connection.query(query, params, (error, results, fields) =&amp;gt; {
      if (error) reject(error);
      resolve(results);
    });
  });
};

(async () =&amp;gt; {
  connection.connect();

  await query(connection,
    `DROP TABLE IF EXISTS hoge`
  );

  await query(connection, 
    `CREATE TABLE hoge (
      id int,
      fuga_id int,
      piyo_id int,
      value int,
      created_at datetime
    )`
  );

  for (let i = 0; i &amp;lt; 100; i++) {
    console.log(i);
    await query(connection,
      `INSERT INTO hoge SET ?`,
      {
       id: i, 
       fuga_id: Math.floor(Math.random() * 3), 
       piyo_id: Math.floor(Math.random() * 10),
       value: Math.floor(Math.random() * 100),
       created_at: new Date(),
      }
    );
  };

  connection.end();
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリを登録する。エディタがあってフォーマットもしてくれる。
毎分や特定の時刻に実行するスケジュール機能もあるので、
重いクエリも事前に実行しておいて必要なときにすぐに見られるようにすることができる。
&lt;code&gt;{{name}}&lt;/code&gt;のようにパラメータを入れることもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-query.png&#34; alt=&#34;クエリの登録&#34; /&gt;&lt;/p&gt;

&lt;p&gt;実行して得られたデータからChartを作る。データはCSVでダウンロードもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-visualization.png&#34; alt=&#34;Chart&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このChartをDashboardに貼る。
パラメータがある場合は入力するフォームが出るので、クエリを書かない人に使ってもらうこともできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-dashboard.png&#34; alt=&#34;Dashbord&#34; /&gt;&lt;/p&gt;

&lt;p&gt;あとは簡単なAlertも登録することができて、
飛ばす先はSettingsのALERT DISTINATIONSに
SlackのWebhookなどを設定できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-alert.png&#34; alt=&#34;Alert&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-slack.png&#34; alt=&#34;Slackに飛ぶメッセージ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ApexでLambdaをデプロイする</title>
          <link>https://www.sambaiz.net/article/140/</link>
          <pubDate>Sun, 22 Oct 2017 16:06:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/140/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/apex/apex&#34;&gt;Apex&lt;/a&gt;でLambdaをデプロイする。
とても簡単に使えるし、変なこともしないので良い感じ。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Serverless Frameworkだとeventの設定までカバーできてより便利。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;インストール。ダウンロードして実行できるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;IAMFullAccess&lt;/li&gt;
&lt;li&gt;AWSLambdaFullAccess&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を付けたIAMのプロファイルを登録しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws configure --profile apex
$ aws configure list --profile apex
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                     apex           manual    --profile
access_key     ****************OVGQ shared-credentials-file    
secret_key     ****************oi5t shared-credentials-file    
    region           ap-northeast-1      config-file    ~/.aws/config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apex init&lt;/code&gt;してnameとdescriptionを入れるとIAMが登録され、
ディレクトリ構造が作られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex init --profile apex
Project name: try-apex
Project description: test  
[+] creating IAM try-apex_lambda_function role
[+] creating IAM try-apex_lambda_logs policy
[+] attaching policy to lambda_function role.
[+] creating ./project.json
[+] creating ./functions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;package.jsonで環境変数などの設定ができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls -R
functions	project.json

./functions:
hello

./functions/hello:
index.js

$ cat project.json 
{
  &amp;quot;name&amp;quot;: &amp;quot;try-apex&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;test&amp;quot;,
  &amp;quot;memory&amp;quot;: 128,
  &amp;quot;timeout&amp;quot;: 5,
  &amp;quot;role&amp;quot;: &amp;quot;arn:aws:iam::524580158183:role/try-apex_lambda_function&amp;quot;,
  &amp;quot;environment&amp;quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apex deploy&lt;/code&gt;するとlambdaが作られる。&lt;code&gt;--dry-run&lt;/code&gt;もできる。
バージョン管理されているので&lt;code&gt;rollback&lt;/code&gt;もできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex deploy hello --profile apex
   • creating function         env= function=hello
   • created alias current     env= function=hello version=1
   • function created          env= function=hello name=try-apex_hello version=1

$ apex list

  hello
    runtime: nodejs6.10
    memory: 128mb
    timeout: 5s
    role: arn:aws:iam::*****:role/try-apex_lambda_function
    handler: index.handle
    arn: arn:aws:lambda:ap-northeast-1:*****:function:try-apex_hello:current
    aliases: current@v1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マネジメントコンソールではここでバージョンが確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/140.png&#34; alt=&#34;バージョンの確認&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;apex invoke&lt;/code&gt;で実行。標準入力でイベントを渡せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex invoke hello
{&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パッケージに含めないファイルは.apexignoreに書く。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsのコードをPrettierでフォーマットしてESLintにかける</title>
          <link>https://www.sambaiz.net/article/139/</link>
          <pubDate>Thu, 19 Oct 2017 00:35:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/139/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/prettier/prettier&#34;&gt;Prettier&lt;/a&gt;はJSやTSのコードフォーマッタで、
ReactやBabel、Yarnなどの開発にも使われている。&lt;/p&gt;

&lt;p&gt;今回はPrettierでフォーマットしたものを
&lt;code&gt;eslint --fix&lt;/code&gt;する&lt;a href=&#34;https://github.com/prettier/prettier-eslint-cli&#34;&gt;prettier-eslint-cli&lt;/a&gt;を使う。役割が被っているけどPrettierは&lt;code&gt;eslint --fix&lt;/code&gt;よりも強力にフォーマットしてくれるようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git init
$ yarn add --dev eslint eslint-config-google prettier-eslint-cli husky lint-staged
$ cat .eslintrc.js 
module.exports = {
    &amp;quot;extends&amp;quot;: &amp;quot;google&amp;quot;,
    &amp;quot;parserOptions&amp;quot;: {
    	&amp;quot;ecmaVersion&amp;quot;: 2017,
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;対象のコードはこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js
/**
 * hoge function
 */
function hoge() {

  const f = (aaaaaaaaaaaaaaa, bbbbbbbbbb, ccccccccc, dddddddddddd, eeeeeeeeeeeeee) =&amp;gt;
    console.log(&#39;a&#39;);


  f(1, 2, 3, 4, 5);
}


hoge();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prettierのドキュメントでも紹介されているように&lt;a href=&#34;https://github.com/okonet/lint-staged&#34;&gt;lint-staged&lt;/a&gt;を使うとCommit時にフォーマットし、Lintをかけることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;precommit&amp;quot;: &amp;quot;lint-staged&amp;quot;,
    &amp;quot;lint&amp;quot;: &amp;quot;eslint src&amp;quot;,
    &amp;quot;format&amp;quot;: &amp;quot;prettier-eslint --write \&amp;quot;src/**/*.js\&amp;quot;&amp;quot;
  },
  &amp;quot;lint-staged&amp;quot;: {
    &amp;quot;*.js&amp;quot;: [
      &amp;quot;prettier-eslint --write&amp;quot;,
      &amp;quot;eslint&amp;quot;,
      &amp;quot;git add&amp;quot;
    ]
  },
  &amp;quot;devDependencies&amp;quot;: {
    &amp;quot;eslint&amp;quot;: &amp;quot;^4.9.0&amp;quot;,
    &amp;quot;eslint-config-google&amp;quot;: &amp;quot;^0.9.1&amp;quot;,
    &amp;quot;husky&amp;quot;: &amp;quot;^0.14.3&amp;quot;,
    &amp;quot;lint-staged&amp;quot;: &amp;quot;^4.2.3&amp;quot;,
    &amp;quot;prettier-eslint-cli&amp;quot;: &amp;quot;^4.4.0&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ git commit -m &amp;quot;test&amp;quot;
husky &amp;gt; npm run -s precommit (node v8.2.1)

 ✔ Running tasks for *.js
[master e325ea3] test

$ cat src/main.js 
/**
 * hoge function
 */
function hoge() {
  const f = (
    aaaaaaaaaaaaaaa,
    bbbbbbbbbb,
    ccccccccc,
    dddddddddddd,
    eeeeeeeeeeeeee
  ) =&amp;gt; console.log(&#39;a&#39;);

  f(1, 2, 3, 4, 5);
}

hoge();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prettierは&lt;code&gt;eslint --fix&lt;/code&gt;で修正されないmax-lenも良い感じにしてくれる。
なのでESLintのフォーマットに関するところはほとんど修正いらないはず。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git commit -m &amp;quot;test&amp;quot;
husky &amp;gt; npm run -s precommit (node v8.2.1)

 ❯ Running tasks for *.js
   ✖ eslint --fix
     git add
✖ eslint --fix found some errors. Please fix them and try committing again.

***/src/main.js
  5:1  error  Line 5 exceeds the maximum line length of 80  max-len

✖ 1 problem (1 error, 0 warnings)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>確率分布(二項分布/ポアソン分布/正規分布)</title>
          <link>https://www.sambaiz.net/article/138/</link>
          <pubDate>Sun, 15 Oct 2017 01:53:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/138/</guid>
          <description>

&lt;h2 id=&#34;二項分布&#34;&gt;二項分布&lt;/h2&gt;

&lt;p&gt;確率pで起きる事象がn回の試行でx回起きる確率関数の離散的確率分布。記号で書くと&lt;code&gt;B[n,p]&lt;/code&gt;。
期待値は&lt;code&gt;np&lt;/code&gt;で、分散は&lt;code&gt;np(1-p)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-binormal-distribution.png&#34; alt=&#34;二項分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-bi-graph.png&#34; alt=&#34;二項分布のグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ポアソン分布&#34;&gt;ポアソン分布&lt;/h2&gt;

&lt;p&gt;二項分布において、起きる確率pが少なく、試行回数nが多いときに代わりに適用できる確率分布。
具体的にはnが50ぐらいだったら、npが5以下のとき。
試行回数が多いとき、二項分布だとCの部分の計算が困難になってしまうのを解決できる。
期待値も分散も&lt;code&gt;np=μ&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-poisson.png&#34; alt=&#34;ポアソン分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-poisson-graph.png&#34; alt=&#34;ポアソン分布のグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;正規分布&#34;&gt;正規分布&lt;/h2&gt;

&lt;p&gt;正規分布は平均値&lt;code&gt;μ&lt;/code&gt;を最大値とし、左右対称な釣鐘型をしている連続的確率分布。記号で書くと&lt;code&gt;N[μ,σ^2]&lt;/code&gt;。
二項分布のnを大きくしていくと正規分布に近づいていく。
p=0.5であれば、n=10の二項分布&lt;code&gt;B[10,0.5]&lt;/code&gt;でも良い近似が得られる(&lt;code&gt;N[5,2.5]&lt;/code&gt;)。
逆にnが大きな二項分布の近似として正規分布を使うこともできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-normal.png&#34; alt=&#34;正規分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-normal-graph.png&#34; alt=&#34;正規分布のグラプ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;N[0,1]&lt;/code&gt;の正規分布を標準正規分布と呼ぶ。
ある正規分布に従う確率変数xを、標準正規分布に従うzに変換することを標準化変換という。
標準正規分布にすると正規分布表の値を使って計算できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-std.png&#34; alt=&#34;標準化変換&#34; /&gt;&lt;/p&gt;

&lt;p&gt;また、平均&lt;code&gt;μ&lt;/code&gt;、分散&lt;code&gt;σ^2&lt;/code&gt;の任意な分布からn個の標本をとったときの平均は&lt;code&gt;N[μ, σ^2/n]&lt;/code&gt;に従う。
言い換えれば、標本の平均と真の平均の誤差は&lt;code&gt;N[0, σ^2/n]&lt;/code&gt;。これを中心極限定理という。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://ruby.kyoto-wu.ac.jp/~konami/Text/&#34;&gt;統計学入門&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Lpノルムと正則化</title>
          <link>https://www.sambaiz.net/article/137/</link>
          <pubDate>Thu, 12 Oct 2017 23:48:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/137/</guid>
          <description>

&lt;h2 id=&#34;ノルムとは&#34;&gt;ノルムとは&lt;/h2&gt;

&lt;p&gt;ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;p(av) = |a| p(v)&lt;/code&gt;: スケーラブル&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(u + v) ≦ p(u) + p(v)&lt;/code&gt;: 三角不等式を満たす&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(v) ≧ 0&lt;/code&gt;: 負の値を取らない&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(v) = 0 &amp;lt;=&amp;gt; v=0&lt;/code&gt;: 距離が0 &amp;lt;=&amp;gt; 零ベクトル&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下の式で表されるノルムをLpノルムと呼ぶ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-norm.png&#34; alt=&#34;Lpノルム&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;l1ノルム-マンハッタン距離&#34;&gt;L1ノルム(マンハッタン距離)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-l1norm.png&#34; alt=&#34;L1ノルムの距離1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;絶対値の和。座標軸方向にしか移動できない縛りでの距離。
StreetとAvenueが格子状になっているマンハッタンではタクシーが移動する距離はL1ノルムのようになる。&lt;/p&gt;

&lt;h3 id=&#34;l2ノルム-ユークリッド距離&#34;&gt;L2ノルム(ユークリッド距離)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-l2norm.png&#34; alt=&#34;L2ノルムの距離1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2乗の和の平方根。普通の距離。&lt;/p&gt;

&lt;h2 id=&#34;正則化-regularization&#34;&gt;正則化(regularization)&lt;/h2&gt;

&lt;p&gt;機械学習で過学習を防ぐためのもの。
Lp正則化は重みのLpノルムをp乗してハイパーパラメータΛを掛けたものを正則化項として
素の損失関数に加える。これを最小化するのだから重みがペナルティとしてはたらく。
L1正則化ではΛが大きければいくつかの重みが0になって次元削減できるが、
L2正則化では重みに比例して小さくなるだけ。それぞれLasso回帰、Ridge回帰ともいう。
また、これらを割合で足して使うElasticNetというものもある。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Norm_(mathematics)&#34;&gt;Norm (mathematics) - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tjo.hatenablog.com/entry/2015/03/03/190000&#34;&gt;RでL1 / L2正則化を実践する - 六本木で働くデータサイエンティストのブログ&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OpenID ConnectのIDトークンの内容と検証</title>
          <link>https://www.sambaiz.net/article/136/</link>
          <pubDate>Mon, 09 Oct 2017 20:01:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/136/</guid>
          <description>

&lt;p&gt;OpenID Connectは認可(AuthoriZation)のプロトコルであるOAuth 2.0を正しく認証(AutheNtication)に使うためのプロトコル。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://openid-foundation-japan.github.io/openid-connect-core-1_0.ja.html&#34;&gt;OpenID Connect Core 1.0(日本語訳)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/48/&#34;&gt;OAuth2.0のメモ - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;OpenID ConnectではOAuthのアクセストークンに加えて
Issuer(IdP)によって署名されたJWT(JSON Web Token)形式のIDトークンも返す。
このIDトークンの署名を検証し、含まれるIssuerとクライアントの情報を参照することで
OAuthのImplicit flowでのトークン置き換え攻撃を防ぐことができる。&lt;/p&gt;

&lt;h2 id=&#34;jwt-idトークン&#34;&gt;JWT/IDトークン&lt;/h2&gt;

&lt;p&gt;JWTは&lt;a href=&#34;https://tools.ietf.org/html/rfc7519&#34;&gt;RFC7519&lt;/a&gt;で定義されている、
パーティ間で安全にClaim(エンドユーザーのようなエンティティの情報)を受け渡すための表現方法。
JSONにエンコードしたClaimは、JOSE(Javascript Object Signing and Encryption)のサブセットである&lt;a href=&#34;https://tools.ietf.org/html/rfc7515&#34;&gt;JWS&lt;/a&gt;(JSON Web Signature)のペイロードとして署名を付与されるか、&lt;a href=&#34;https://tools.ietf.org/html/rfc7519&#34;&gt;JWE&lt;/a&gt;(JSON Web Encryption)で暗号化される。
以下のJWTはJWSのもの。&lt;/p&gt;

&lt;p&gt;JWSには&lt;code&gt;(ヘッダ).(ペイロード).(署名)&lt;/code&gt;の文字列で表現されるCompact SerializationとJSONで表現されるJSON Serializationがあるが、JWTではCompact Serializationを使う。&lt;/p&gt;

&lt;p&gt;ヘッダには署名に使うアルゴリズム&lt;code&gt;alg&lt;/code&gt;が含まれる。
JWTを受け取った際、不正なalgになっていないかチェックする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
  &amp;quot;kid&amp;quot;: &amp;quot;5b0924f6f83c719514987954cf66683b370677d4&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ペイロードには以下のようなClaimが含まれる。これ以外のClaimを含めることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;iss&amp;quot;: &amp;quot;https://server.example.com&amp;quot;, # IssuerのIdentifier。httpsのURL
    &amp;quot;sub&amp;quot;: &amp;quot;24400320&amp;quot;, # Subject Identifier。Issuerでユニークなエンドユーザーの識別子。
    &amp;quot;aud&amp;quot;: &amp;quot;s6BhdRkqt3&amp;quot;, # audience。OAuth2.0のclient_id
    &amp;quot;nonce&amp;quot;: &amp;quot;n-0S6_WzA2Mj&amp;quot;, # リクエストで送ったのがそのまま返ってくる。リプレイ攻撃を防ぐため
    &amp;quot;exp&amp;quot;: 1311281970, # IDトークンの有効期限。時間はすべてUNIXエポック秒
    &amp;quot;iat&amp;quot;: 1311280970, # IDトークンの発行時刻
    &amp;quot;auth_time&amp;quot;: 1311280969 # エンドユーザーの認証時刻
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;idトークンを取得する&#34;&gt;IDトークンを取得する&lt;/h2&gt;

&lt;p&gt;Googleの&lt;a href=&#34;https://developers.google.com/identity/protocols/OpenIDConnect&#34;&gt;OAuth 2.0 API&lt;/a&gt;はOpenID Connectに対応している。これのIDトークンを取得する。&lt;/p&gt;

&lt;p&gt;エンドポイント等は&lt;a href=&#34;https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig&#34;&gt;OpenID Connect Discovery 1.0&lt;/a&gt;の
&lt;code&gt;/.well-known/openid-configuration&lt;/code&gt;で取得できるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://accounts.google.com/.well-known/openid-configuration | jq
{
  &amp;quot;issuer&amp;quot;: &amp;quot;https://accounts.google.com&amp;quot;,
  &amp;quot;authorization_endpoint&amp;quot;: &amp;quot;https://accounts.google.com/o/oauth2/v2/auth&amp;quot;,
  &amp;quot;token_endpoint&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v4/token&amp;quot;,
  &amp;quot;userinfo_endpoint&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v3/userinfo&amp;quot;,
  &amp;quot;revocation_endpoint&amp;quot;: &amp;quot;https://accounts.google.com/o/oauth2/revoke&amp;quot;,
  &amp;quot;jwks_uri&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v3/certs&amp;quot;,
  &amp;quot;response_types_supported&amp;quot;: [
    &amp;quot;code&amp;quot;,
    &amp;quot;token&amp;quot;,
    &amp;quot;id_token&amp;quot;,
    &amp;quot;code token&amp;quot;,
    &amp;quot;code id_token&amp;quot;,
    &amp;quot;token id_token&amp;quot;,
    &amp;quot;code token id_token&amp;quot;,
    &amp;quot;none&amp;quot;
  ],
  &amp;quot;subject_types_supported&amp;quot;: [
    &amp;quot;public&amp;quot;
  ],
  &amp;quot;id_token_signing_alg_values_supported&amp;quot;: [
    &amp;quot;RS256&amp;quot;
  ],
  &amp;quot;scopes_supported&amp;quot;: [
    &amp;quot;openid&amp;quot;,
    &amp;quot;email&amp;quot;,
    &amp;quot;profile&amp;quot;
  ],
  &amp;quot;token_endpoint_auth_methods_supported&amp;quot;: [
    &amp;quot;client_secret_post&amp;quot;,
    &amp;quot;client_secret_basic&amp;quot;
  ],
  &amp;quot;claims_supported&amp;quot;: [
    &amp;quot;aud&amp;quot;,
    &amp;quot;email&amp;quot;,
    &amp;quot;email_verified&amp;quot;,
    &amp;quot;exp&amp;quot;,
    &amp;quot;family_name&amp;quot;,
    &amp;quot;given_name&amp;quot;,
    &amp;quot;iat&amp;quot;,
    &amp;quot;iss&amp;quot;,
    &amp;quot;locale&amp;quot;,
    &amp;quot;name&amp;quot;,
    &amp;quot;picture&amp;quot;,
    &amp;quot;sub&amp;quot;
  ],
  &amp;quot;code_challenge_methods_supported&amp;quot;: [
    &amp;quot;plain&amp;quot;,
    &amp;quot;S256&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テスト用にcodeを受け取ってトークンをリクエストするサーバーを書いた。コードは&lt;a href=&#34;https://github.com/sambaiz/openid-connect-test-client&#34;&gt;ここ&lt;/a&gt;。client_idとclient_secretは&lt;a href=&#34;https://console.developers.google.com/&#34;&gt;API Console&lt;/a&gt;で発行できる。&lt;/p&gt;

&lt;p&gt;立ち上げて&lt;code&gt;https://localhost:3000/auth&lt;/code&gt;にアクセスするとリダイレクトし、以下のような情報が出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;code&amp;quot;: {
    &amp;quot;state&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;code&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;authuser&amp;quot;: &amp;quot;0&amp;quot;,
    &amp;quot;session_state&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;prompt&amp;quot;: &amp;quot;none&amp;quot;
  },
  &amp;quot;token&amp;quot;: {
    &amp;quot;access_token&amp;quot;: &amp;quot;*****.*****.*****&amp;quot;
  },
  &amp;quot;id_token_header&amp;quot;: {
    &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
    &amp;quot;kid&amp;quot;: &amp;quot;5b0924f6f83c719514987954cf66683b370677d4&amp;quot;
  },
  &amp;quot;id_token_payload&amp;quot;: {
    &amp;quot;azp&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;aud&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;sub&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;email&amp;quot;: &amp;quot;****@gmail.com&amp;quot;,
    &amp;quot;email_verified&amp;quot;: true,
    &amp;quot;at_hash&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;nonce&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;iss&amp;quot;: &amp;quot;https://accounts.google.com&amp;quot;,
    &amp;quot;iat&amp;quot;: 1506613038,
    &amp;quot;exp&amp;quot;: 1506616638
  },
  &amp;quot;id_token_verify_signature&amp;quot;: &amp;quot;*****&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このIDトークンのiss, audを見て署名も&lt;a href=&#34;https://developers.google.com/identity/protocols/OpenIDConnect#validatinganidtoken&#34;&gt;検証する&lt;/a&gt;ことで、
たしかに発行元と先が正しいことを確認し、expも過ぎていなければ、
subに示されるIDのエンティティとして認証できる。&lt;/p&gt;

&lt;h2 id=&#34;idトークンの署名を検証する&#34;&gt;IDトークンの署名を検証する&lt;/h2&gt;

&lt;p&gt;検証もやってみた。urlは&lt;code&gt;https://localhost:3000/verify?token=****&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;GoogleのIDトークンのalgを見ると、RS256(RSASSA-PKCS1-v1_5 using SHA-256)で署名されていることがわかる。対象となるデータはJWSの&lt;code&gt;(ヘッダ).(ペイロード)&lt;/code&gt;まで。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/135/&#34;&gt;RSA暗号とPEM/DERの構造 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;公開鍵はDiscoveryのjwks_uriで取得でき、1日に1回更新される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://www.googleapis.com/oauth2/v3/certs
{
 &amp;quot;keys&amp;quot;: [
  {
   &amp;quot;kty&amp;quot;: &amp;quot;RSA&amp;quot;,
   &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
   &amp;quot;use&amp;quot;: &amp;quot;sig&amp;quot;,
   &amp;quot;kid&amp;quot;: &amp;quot;23e255c65b234549cc0fe3073bce15e59bd4d4b0&amp;quot;,
   &amp;quot;n&amp;quot;: &amp;quot;w5i-jGiwEyuPewnvR-lFceBRYh4gx91-OFLaJwwr8yCrSVczAgyc1wywFBCsUBDBhHpKSVilqIGG2fIqhdX2_IFJ-OxYvXDmJtYF69kWTafZjFtnAl8EdIqj1X-y31Pm9gYD_rYeLG3CZhNLjIE_y9fk5_MbOOc0Z-br4_wzing6HfERITbAOAfCd8Ri0_tXDqYgi-C1C_gs2HheYEIWqpZ2se8UsGvIg2uePOCV8G3a0fuvh6hgjutspfJ_VH3eeHwYwyYzieq-sDWcyV5qGlnJp9TZlZ9z242WdYHj3C2kudNTUg76p6svbs6cu1ZiZA9WZkaL9d8hWeJ4tLQg3Q&amp;quot;,
   &amp;quot;e&amp;quot;: &amp;quot;AQAB&amp;quot;
  },
  {
   &amp;quot;kty&amp;quot;: &amp;quot;RSA&amp;quot;,
   &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
   &amp;quot;use&amp;quot;: &amp;quot;sig&amp;quot;,
   &amp;quot;kid&amp;quot;: &amp;quot;db15c5e7c1b82b93388459602e4852bfd9b95931&amp;quot;,
   &amp;quot;n&amp;quot;: &amp;quot;lZUcUSL9piIsbwP_Y84683P7-vX_Y9CEvqpeCNpI4p55HFCDnp9xtnvc5mBEOrFP-vwk6sjlkLVbl74d1CR-jKX-z8zPg3T0qQzYWgedAddfQL1zFUyo2BLbCg2JeYDZF6IHv6qfwzM3hgQIMJMa29izyAyZ2T0zhXf5fU311LEKWCdpemQsNj5V4r5Z52vsTuOhm16Xt7LWx_iWb-_VdYxhDYoQ87pZIVaCdnKDwGON0MPoI4eQJdb-ABrcz290mbGJ8kiI4BU_iA98HCc3ifWDe8eatpV9LK54eYansDTMQJXoYZ6a7C-0-Mh1-g6qaxYjpymJXbJjYitiMejYFQ&amp;quot;,
   &amp;quot;e&amp;quot;: &amp;quot;AQAB&amp;quot;
  },
  ...
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;signature,n,eをそれぞれbase64デコードしたのを整数として扱い、&lt;code&gt;m ≡ (signature)^e (mod n)&lt;/code&gt;で複合するとdigestInfoのDERの前に&lt;code&gt;00 01 ff ff .. 00&lt;/code&gt;のパディングがついたものになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;digestInfo ::= SEQUENCE {
     digestAlgorithm DigestAlgorithmIdentifier,
     digest Digest 
}

Digest ::= OCTET STRING
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const digestInfoDERFromSignature = (signature, e, n) =&amp;gt; {
  const signatureHex = Buffer.from(signature, &#39;base64&#39;).toString(&#39;hex&#39;)
  const eHex  = Buffer.from(e, &#39;base64&#39;).toString(&#39;hex&#39;)
  const nHex = Buffer.from(n, &#39;base64&#39;).toString(&#39;hex&#39;)

  const signatureNum = bigInt(signatureHex, 16)
  const eNum = bigInt(eHex, 16)
  const nNum = bigInt(nHex, 16)  

  const m = signatureNum.modPow(eNum, nNum); // c^e (mod n)
  const decrypted = m.toString(16);
  const paddingRemoved = decrypted.replace(/^1f*00/g, &amp;quot;&amp;quot;);
  return paddingRemoved;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この中のdigestと&lt;code&gt;(ヘッダ).(ペイロード)&lt;/code&gt;のsha256 hashが一致することを確認する。
digestは末尾にくるので簡易的にendsWithで比較している。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RSA暗号とPEM/DERの構造</title>
          <link>https://www.sambaiz.net/article/135/</link>
          <pubDate>Sun, 01 Oct 2017 21:02:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/135/</guid>
          <description>

&lt;h2 id=&#34;rsa暗号とは&#34;&gt;RSA暗号とは&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;暗号化: &lt;code&gt;c ≡ m^e (mod n)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;複合: &lt;code&gt;m ≡ c^d (mod n)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;公開鍵がe,nで秘密鍵がd。nはとても大きく近くない素数p,qの積で、
これを公開しても素因数分解できないのがこの暗号の前提になっている。
768bit(10進数で232桁)では既に解読されているので、少なくとも1024bit以上にする。&lt;/p&gt;

&lt;p&gt;eは&lt;a href=&#34;https://en.wikipedia.org/wiki/Euler%27s_totient_function&#34;&gt;Euler totient function&lt;/a&gt;(1~nまでの整数でnと互いに素なものの個数。今回の場合は&lt;code&gt;φ(n)=(p-1)(q-1)&lt;/code&gt;)未満で互いに素な正の整数で、小さすぎても大きすぎてもだめ。&lt;code&gt;2^16 + 1 = 65537&lt;/code&gt;がよく使われる。&lt;/p&gt;

&lt;p&gt;dは&lt;code&gt;ed ≡ 1 (mod φ(n))&lt;/code&gt;を満たすd。&lt;/p&gt;

&lt;h2 id=&#34;例&#34;&gt;例&lt;/h2&gt;

&lt;p&gt;例として(p,q)=(193,709)とするとこんな感じ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n = p * q = 136837&lt;/li&gt;
&lt;li&gt;φ(n) = (p-1)(q-1) = 135936&lt;/li&gt;
&lt;li&gt;e = 65537 &amp;lt; φ(n)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;秘密鍵dは&lt;code&gt;65537*d ≡ 1 (mod 135936)&lt;/code&gt;の式を変形した
&lt;code&gt;65537*d - 135936*x = gcd(65537,135936) = 1&lt;/code&gt;を、拡張されたユークリッドの互除法で解く。
以下のように135936と65537を残しながら展開していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;135936 = 65537 * 2 + 4862 
=&amp;gt; 4862 = 135936 * 1 + 65537 * -2

65537 = 4862 * 13 + 2331 
=&amp;gt; 2331 = 65537 - (135936 * 1 + 65537 * -2) * 13
        = 135936 * -13 + 65537 * 27

4862 = 2331 * 2 + 200 
=&amp;gt; 200 = (135936 * 1 + 65537 * -2) - (135936 * -13 + 65537 * 27) * 2
       = 135936 * 27 + 65537 * -56

2331 = 200 * 11 + 131 
=&amp;gt; 131 = (135936 * -13 + 65537 * 27) - (135936 * 27 + 65537 * -56) * 11
       = 135936 * -310 + 65537 * 643 
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをコードに表したのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const d = (phi,e) =&amp;gt; {
    let history = {[phi]: [1,0], [e]:[0,1]} // [x,y] =&amp;gt; φ * x + e * y
    let x = phi
    let y = e
    while(y &amp;gt; 1){
        const nextY = x % y
        history[x % y] = history[x].map((vx,index) =&amp;gt; vx - history[y][index] * Math.floor(x/y))
        x = y
        y = nextY;
    }
    return history;
}

const phi = (193-1) * (709-1)
const e = 65537
const result = d(phi,e);
console.log(result);
console.log(`1 = ${phi}*${result[1][0]} + ${e}*${result[1][1]}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{ &#39;1&#39;: [ 9503, -19711 ],
  &#39;6&#39;: [ -8519, 17670 ],
  &#39;7&#39;: [ 984, -2041 ],
  &#39;62&#39;: [ -647, 1342 ],
  &#39;69&#39;: [ 337, -699 ],
  &#39;131&#39;: [ -310, 643 ],
  &#39;200&#39;: [ 27, -56 ],
  &#39;2331&#39;: [ -13, 27 ],
  &#39;4862&#39;: [ 1, -2 ],
  &#39;65537&#39;: [ 0, 1 ],
  &#39;135936&#39;: [ 1, 0 ] }
1 = 135936*9503 + 65537*-19711
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;135936*-65537 + 65537*135936 = 0&lt;/code&gt;より
&lt;code&gt;1 = 135936*(9503-65537) + 65537*(-19711 + 135936)&lt;/code&gt;なので
&lt;code&gt;d=116225&lt;/code&gt;。実際&lt;code&gt;(65537*116225) % 135936 = 1&lt;/code&gt;が成り立つ。&lt;/p&gt;

&lt;p&gt;平文が12345とすると、公開鍵で暗号化したのが&lt;code&gt;(12345 ** 65537) % 136837 = 6964&lt;/code&gt;。
これを秘密鍵で複合すると&lt;code&gt;(6964 ** 116225) % 136837 = 12345&lt;/code&gt;のように平文が得られる。&lt;/p&gt;

&lt;h2 id=&#34;鍵ファイルの生成&#34;&gt;鍵ファイルの生成&lt;/h2&gt;

&lt;p&gt;ssh-keygenで生成されるようなPEMファイルを作る。&lt;/p&gt;

&lt;h3 id=&#34;用語&#34;&gt;用語&lt;/h3&gt;

&lt;p&gt;DER(Distinguished Encoding Rules)は
&lt;a href=&#34;https://ja.wikipedia.org/wiki/Abstract_Syntax_Notation_One&#34;&gt;ASN.1(Abstract Syntax Notation One)&lt;/a&gt;記法で定義されたデータを
エンコードするルールの一つ。
&lt;code&gt;1a(INTEGER) 0b(byte) 68 65 6c 6c 6f 20 77 6f 72 6c 64(&amp;quot;hello world&amp;quot;))&lt;/code&gt;
のようなtype-length-valueで表す。&lt;/p&gt;

&lt;p&gt;PEM(Privacy-enhanced Electronic Mail)は
公開鍵のフォーマットの定義&lt;a href=&#34;https://en.wikipedia.org/wiki/X.509&#34;&gt;X.509&lt;/a&gt;で
定められている拡張子で、Base64でエンコードされたDER。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/PKCS&#34;&gt;PKCS(Public-Key Cryptography Standards)&lt;/a&gt;は公開鍵暗号における標準仕様を定めたもの。PKCS#1(&lt;a href=&#34;https://tools.ietf.org/html/rfc2313&#34;&gt;RFC2313&lt;/a&gt;)にはRSA暗号の方式やASN.1表現などが含まれている。&lt;/p&gt;

&lt;p&gt;RFC2313に書かれているASN.1を見ながらPEMの内容を確認する。&lt;/p&gt;

&lt;h3 id=&#34;rsaprivatekey&#34;&gt;RSAPrivateKey&lt;/h3&gt;

&lt;p&gt;n,e,dに加えて生成に使った素数まで含んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RSAPrivateKey ::= SEQUENCE {
     version Version,
     modulus INTEGER, -- n
     publicExponent INTEGER, -- e
     privateExponent INTEGER, -- d
     prime1 INTEGER, -- p
     prime2 INTEGER, -- q
     exponent1 INTEGER, -- d mod (p-1)
     exponent2 INTEGER, -- d mod (q-1)
     coefficient INTEGER -- (inverse of q) mod p }

   Version ::= INTEGER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pemを生成し、Base64デコードしてDERにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa 1024 &amp;gt; secret.pem
$ cat secret.pem 
-----BEGIN RSA PRIVATE KEY-----
(内容)
-----END RSA PRIVATE KEY-----

$ echo (内容) | base64 -D | xxd
00000000: 3082 025c 0201 0002 8181 .... .... .... 
00000080: .... .... .... .... .... ..02 0301 0001
00000090: 0281 80..
00000110: .... ..02 41.. 
00000150: .... .... .... 0241 ....
00000190: .... .... .... .... ..02 40.. 
000001d0: .... .... .... .... .... ..02 41.. ....  
00000210: .... .... .... .... .... .... .... 0240 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;整理するとこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[0000] 30 82 02 5c       
(30-&amp;gt;Type=SEQUENCE 82-&amp;gt;先頭bitが1なのでlengthに使うバイト数(2bytes) 025c-&amp;gt;Length=605bytes)

  [0000] 02 01 00
  (version: 02-&amp;gt;Type=INTEGER, 01-&amp;gt;先頭が0なのでそのままLength=3bytes, Value=0)

  [0000] 02 81 81 .. 
  (modulus: Type=INTEGER, Length=129bytes)

  [0080] 02 03 01 00 01 
  (publicExponent: Type=INTEGER, Length=3bytes, Value=65537)

  [0090] 02 81 80 ..
  (privateExponent: Type=INTEGER, Length=128bytes)

  [0110] 02 41 ..
  (prime1: Type=INTEGER, Length=65bytes)

  [0150] 02 41 .. 
  (prime2: Type=INTEGER, Length=65bytes)

  [0190] 02 40 ..
  (exponent1: Type=INTEGER, Length=64bytes)

  [01d0] 02 41 ..
  (exponent2: Type=INTEGER, Length=65bytes)

  [0210] 02 40 ..
  (coefficient: Type=INTEGER, Length=64bytes)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rsapublickey&#34;&gt;RSAPublicKey&lt;/h3&gt;

&lt;p&gt;nとeだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RSAPublicKey ::= SEQUENCE {
     modulus INTEGER, -- n
     publicExponent INTEGER -- e }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秘密鍵から公開鍵を生成して同様にDERにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl rsa -pubout &amp;lt; secret.pem &amp;gt; public.pem
$ cat public.pem 
-----BEGIN PUBLIC KEY-----
(内容)
-----END PUBLIC KEY-----

$ echo (内容) | base64 -D | xxd
00000000: 3081 9f30 0d06 092a 8648 86f7 0d01 0101
00000010: 0500 0381 8d00 3081 8902 8181 .... ....
00000090: .... .... .... .... .... .... ..02 0301 
000000a0: 0001
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[0000] 30 81 9f
(Type=SEQUENCE, Length=159bytes)
  [0000] 30 0d
  (Type=SEQUENCE, Length=13bytes)
    [0000] 06 09 2a 86 48 86 f7 0d 01 01 01
    (Type=OBJECT IDENTIFIER, Length=9bytes, 
    value=http://www.oid-info.com/get/1.2.840.113549.1.1.1
          最上位ビットは区切りのサイン
          2a ((0)010 1010) =&amp;gt; 40 * 1 + 2 =&amp;gt; 1(iso) 2(member-body)
          86 48 ((1)000 0110 (0)100 1000) =&amp;gt; 840(us)
          86 f7 0d ((1)000 0110 (1)111 0111 (0)000 1101) =&amp;gt; 113549(rsadsi)
          01 ((0)000 0001) =&amp;gt; 1(pkcs)
          01 ((0)000 0001) =&amp;gt; 1(pcks-1)
          01 ((0)000 0001) =&amp;gt; 1(rsaEncryption)

    [0010] 05 00
    (アルゴリズムパラメータ: Type=Null 0byte)

    [0010] 03 81 8d 00 
    (Type=BIT STRING, 141bytes, 最終byteの切り捨て0bit)

      [0010] 30 81 89
      (Type=SEQUENCE, 137bytes)

        [0010] 02 81 81 ..
        (modulus: Type=INTEGER, Length=129bytes)

        [0090] 02 03 01 00 01
        (publicExponent: Type=INTEGER, Length=3bytes, Value=65537)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;digestinfo&#34;&gt;digestInfo&lt;/h3&gt;

&lt;p&gt;署名に使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;digestInfo ::= SEQUENCE {
     digestAlgorithm DigestAlgorithmIdentifier,
     digest Digest 
}

Digest ::= OCTET STRING
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;digestAlgorithmでデータをハッシュ化したものをdigestInfoに詰め、秘密鍵で暗号化したものを署名とし、
公開鍵で複合してdigestと実際のハッシュ値が一致することを確認する。
RSASSA-PKCS1-v1_5では暗号化の前に&lt;code&gt;00 01 ff ff ff .. 00&lt;/code&gt;のパディングを加える。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://people.csail.mit.edu/rivest/Rsapaper.pdf&#34;&gt;A Method for Obtaining Digital Signatures and Public-Key Cryptosystems&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.livedoor.jp/k_urushima/archives/979220.html&#34;&gt;自堕落な技術者の日記 : 図説RSA署名の巻&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bearmini.hatenablog.com/entry/2014/02/05/143510&#34;&gt;RSA 秘密鍵/公開鍵ファイルのフォーマット - bearmini&amp;rsquo;s blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://crypto.stackexchange.com/questions/29115/how-is-oid-2a-86-48-86-f7-0d-parsed-as-1-2-840-113549&#34;&gt;openssl - How is OID 2a 86 48 86 f7 0d parsed as 1.2.840.113549? - Cryptography Stack Exchange&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>自己情報量、エントロピー、KL情報量、交差エントロピー</title>
          <link>https://www.sambaiz.net/article/134/</link>
          <pubDate>Mon, 25 Sep 2017 23:50:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/134/</guid>
          <description>

&lt;h2 id=&#34;自己情報量&#34;&gt;自己情報量&lt;/h2&gt;

&lt;p&gt;P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-self-information.png&#34; alt=&#34;自己情報量の定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-self-information-graph.png&#34; alt=&#34;自己情報量のグラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;log(P)+log(Q)=log(P*Q)&lt;/code&gt;より加法性がある。
例えば、サイコロで1の目が2回連続で出る(P=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;36&lt;/sub&gt;)情報量(5.16bits)はサイコロで1の目が出る(P=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;)情報量(2.58bits)の2倍と等しい。
確率が高ければ高いほど自己情報量は小さくなり、&lt;code&gt;P(ω)=1&lt;/code&gt;では0bitになる。&lt;/p&gt;

&lt;h2 id=&#34;エントロピー&#34;&gt;エントロピー&lt;/h2&gt;

&lt;p&gt;確率分布Pに従う確率変数Xのエントロピーは以下の式で定義される。情報量の平均。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-entropy.png&#34; alt=&#34;エントロピーの定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これは情報を送る際に必要なビット数の平均の下限になっている。
例えば、Xが1~4の値を(0.8, 0.1, 0.06, 0.04)の確率でとるとする。
4通りなのだからそれぞれ2bits(00, 01, 10, 11)のコードで表すこともできるが、
ほとんど3や4は出ないのだからbit数を偏らせて(0, 10, 110, 111)のコードで表すと
&lt;code&gt;0.8*1 + 0.1*2 + 0.06*3 + 0.04*3 = 1.3bits&lt;/code&gt;まで減らすことができる。
この場合のエントロピーは1.01bitsで、これより小さくすることはできない。&lt;/p&gt;

&lt;h2 id=&#34;カルバック-ライブラー情報量&#34;&gt;カルバック・ライブラー情報量&lt;/h2&gt;

&lt;p&gt;離散確率分布PのQに対するカルバック・ライブラー情報量は以下の式で定義される。連続確率分布では積分する。
Qの自己情報量からPの自己情報量を引いて平均を取ったもの。ギブスの不等式より非負の値を取る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-kl.png&#34; alt=&#34;KL情報量の定義&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;交差エントロピー&#34;&gt;交差エントロピー&lt;/h2&gt;

&lt;p&gt;離散確率分布PとQの交差エントロピーは以下の式で定義される。連続確率分布では積分する。
PのエントロピーにPのQに対するKL情報量を足したもの。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-cross-entropy.png&#34; alt=&#34;交差エントロピーの定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これはQの分布に最適化されたコードでPの分布の確率変数の情報を送ってしまった際に必要なビット数の平均の下限になっている。KL情報量が余分な分。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Self-information&#34;&gt;Self-information - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&#34;&gt;Kullback–Leibler divergence - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://postd.cc/visual-information-theory-3/&#34;&gt;情報理論を視覚的に理解する (&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;) | コンピュータサイエンス | POSTD&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ニューラルネットワークと活性化関数</title>
          <link>https://www.sambaiz.net/article/133/</link>
          <pubDate>Mon, 18 Sep 2017 23:50:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/133/</guid>
          <description>

&lt;p&gt;ニューラルネットワークの活性化関数は各層での重み掛けバイアス足しのあとに適用する非線形の関数。
というのも、線形な計算を繰り返したところで&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;f(x) = ax + b
g(x) = f(f(x)) = (a^2)x + (ab + b)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;のように単一の線形関数で表現できてしまい、多層にする意味がないため。
また、バックプロバゲーション(誤差逆伝播法)のために微分できる必要もある。&lt;/p&gt;

&lt;p&gt;Tensorflowでも以下の活性化関数が&lt;a href=&#34;https://www.tensorflow.org/api_guides/python/nn#Activation_Functions&#34;&gt;用意されている&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;sigmoid-https-www-tensorflow-org-api-docs-python-tf-sigmoid&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/sigmoid&#34;&gt;sigmoid&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-sigmoid.png&#34; alt=&#34;シグモイド関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;y = 1 / (1 + exp(-x))&lt;/code&gt;。値域は(0,1)で&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89&#34;&gt;シグマの語末系ςに似たS字を描く&lt;/a&gt;。
xが大きいときに微分係数が小さくなるため、何層もこの関数を適用するとき、バックプロバゲーションで微分係数を掛けた結果、勾配が消滅(Gradient vanishing)する問題があり、あまり使われないようだ。値域が(-1,1)で似たグラフを描く&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/tanh&#34;&gt;tanh&lt;/a&gt;(Hyperbolic tangent)もある。&lt;/p&gt;

&lt;h3 id=&#34;softsign-https-www-tensorflow-org-api-docs-python-tf-nn-softsign&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/softsign&#34;&gt;softsign&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softsign.png&#34; alt=&#34;softsign&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x/(1 + abs(x))&lt;/code&gt;。tanhと比べて漸近線に近づく速度が遅くなっている。
それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。&lt;/p&gt;

&lt;h3 id=&#34;softplus-https-www-tensorflow-org-api-docs-python-tf-nn-softplus&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/softplus&#34;&gt;softplus&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softplus.png&#34; alt=&#34;softplus&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;log(1 + exp(x))&lt;/code&gt;。ReLUに続く。&lt;/p&gt;

&lt;h3 id=&#34;relu-https-www-tensorflow-org-api-docs-python-tf-nn-relu-rectified-linear-unit&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/relu&#34;&gt;ReLU&lt;/a&gt;(Rectified Linear Unit)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-relu.png&#34; alt=&#34;ReLU&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;max(0, x)&lt;/code&gt;。単純だけど最有力。Gradient vanishingも起きない。
softplusと比べてexpやlogを含まない分高速に計算できるので、
膨大で複雑なデータセットに対して多くの層を用いることができる。&lt;/p&gt;

&lt;p&gt;0以下は等しく0になるため、トレーニング中に落ちてしまうとニューロンが死んでしまうことがある。
そのような場合は0以下のとき&lt;code&gt;y = exp(x) - 1&lt;/code&gt;にする&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/elu&#34;&gt;ELU&lt;/a&gt;(Exponential Linear Unit)
などを使う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-elu.png&#34; alt=&#34;ELU&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/towards-data-science/activation-functions-and-its-types-which-is-better-a9a5310cc8f&#34;&gt;Activation functions and it’s types-Which is better?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.orsj.or.jp/archive2/or60-4/or60_4_191.pdf&#34;&gt;最適化から見たディープラーニングの考え方&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf&#34;&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Rectifier_(neural_networks)&#34;&gt;Rectifier (neural networks) - Wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った</title>
          <link>https://www.sambaiz.net/article/132/</link>
          <pubDate>Sun, 10 Sep 2017 23:45:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/132/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34;&gt;Puppeteer&lt;/a&gt;でHeadless Chromeを動かすコードを
Lambda上で動かすStarter Kitを作った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppeteer-lambda-starter-kit&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;chromeの準備&#34;&gt;Chromeの準備&lt;/h2&gt;

&lt;p&gt;Puppeteerのインストール時に落としてくるChromeをLambda上で動かそうとしても
Lambdaにないshared libraryに依存しているため失敗する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;error while loading shared libraries: libpangocairo-1.0.so.0: cannot open shared object file: No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lambda上でHeadless Chromeを動かす例がないか調べたら&lt;a href=&#34;https://github.com/adieuadieu/serverless-chrome&#34;&gt;serverless-chrome&lt;/a&gt;というのがあって、
Headless用の設定でChromeをビルドしていた。
ほかには&lt;a href=&#34;https://github.com/graphcool/chromeless&#34;&gt;chromeless&lt;/a&gt;というのもあるけど
これはserverless-chromeに
&lt;a href=&#34;https://github.com/graphcool/chromeless/blob/master/serverless/serverless.yml#L46&#34;&gt;依存している&lt;/a&gt;。
最小構成でPuppeteerを使いたかったので、今回はこれらを使わず一から作ることにした。&lt;/p&gt;

&lt;p&gt;serverless-chromeにもビルドしたものが置いてあるが、少しバージョンが古いようだったので最新版でビルドした。
基本的には&lt;a href=&#34;https://github.com/adieuadieu/serverless-chrome/tree/master/chrome&#34;&gt;書いてある&lt;/a&gt;
通りやればうまくいく。他のプロセスとのshared memoryとして/dev/shmを使っているのを、/tmpに&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/blob/master/chrome/buildChrome.sh#L20&#34;&gt;置き換える&lt;/a&gt;
ようにしないと、実行時の&lt;code&gt;page.goto()&lt;/code&gt;で&lt;code&gt;Failed Provisional Load: ***, error_code: -12&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;ビルドしたheadless_shellには問題になった依存は含まれていないようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ldd headless_shell 
	linux-vdso.so.1 =&amp;gt;  (0x00007ffcb6fed000)
	libpthread.so.0 =&amp;gt; /lib64/libpthread.so.0 (0x00007f5f17dbe000)
	libdl.so.2 =&amp;gt; /lib64/libdl.so.2 (0x00007f5f17bba000)
	librt.so.1 =&amp;gt; /lib64/librt.so.1 (0x00007f5f179b1000)
	libnss3.so =&amp;gt; /usr/lib64/libnss3.so (0x00007f5f17692000)
	libnssutil3.so =&amp;gt; /usr/lib64/libnssutil3.so (0x00007f5f17466000)
	libsmime3.so =&amp;gt; /usr/lib64/libsmime3.so (0x00007f5f1723e000)
	libnspr4.so =&amp;gt; /lib64/libnspr4.so (0x00007f5f17001000)
	libexpat.so.1 =&amp;gt; /lib64/libexpat.so.1 (0x00007f5f16dd8000)
	libfontconfig.so.1 =&amp;gt; not found
	libfreetype.so.6 =&amp;gt; /usr/lib64/libfreetype.so.6 (0x00007f5f16b3b000)
	libm.so.6 =&amp;gt; /lib64/libm.so.6 (0x00007f5f16839000)
	libstdc++.so.6 =&amp;gt; /usr/lib64/libstdc++.so.6 (0x00007f5f16533000)
	libgcc_s.so.1 =&amp;gt; /lib64/libgcc_s.so.1 (0x00007f5f1631d000)
	libc.so.6 =&amp;gt; /lib64/libc.so.6 (0x00007f5f15f5b000)
	/lib64/ld-linux-x86-64.so.2 (0x000055ba0af5e000)
	libplc4.so =&amp;gt; /lib64/libplc4.so (0x00007f5f15d55000)
	libplds4.so =&amp;gt; /lib64/libplds4.so (0x00007f5f15b51000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Puppetterで落としてくる普通のChromeは&lt;a href=&#34;http://docs.aws.amazon.com/lambda/latest/dg/limits.html&#34;&gt;Lambdaの制限&lt;/a&gt;の50MBを超えていたが、
ビルドしたものはぎりぎり超えていないのでパッケージに含められるようになった。
PuppeteerのChromeは環境変数&lt;code&gt;PUPPETEER_SKIP_CHROMIUM_DOWNLOAD&lt;/code&gt;を設定することで&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/blob/2817130fe099a7431e98c20ce1f44c6e547d4ca9/docs/api.md#puppeteer&#34;&gt;含めないようにできる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;他のパッケージのサイズによっては50MBを超えてしまうこともあるので、
パッケージに含めず&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/blob/v0.9.0/src/util.js#L62&#34;&gt;S3からダウンロード&lt;/a&gt;できるようにもした。&lt;/p&gt;

&lt;p&gt;いずれの場合も最終的な置き先はLambdaで唯一書き込める&lt;code&gt;/tmp&lt;/code&gt;になる。
この領域は512MBまで使えるので展開してもまだ余裕がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: EROFS: read-only file system, open &#39;node_modules/puppeteer/.local-chromium&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chromeのlaunch時のoption&#34;&gt;ChromeのLaunch時のOption&lt;/h2&gt;

&lt;p&gt;いろいろ試した結果、最低限必要だったのはこのあたり。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;exports.launchOptionForLambda = [
    // error when launch(); No usable sandbox! Update your kernel
    &#39;--no-sandbox&#39;,
    // error when launch(); Failed to load libosmesa.so
    &#39;--disable-gpu&#39;, 
    // freeze when newPage()
    &#39;--single-process&#39;
];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーは分かりづらいものが多く、ときにはエラーすら出ずに止まってしまうこともある。
デバッグの際はdumpioを有効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const browser = await puppeteer.launch({
    ...
    dumpio: !!util.DEBUG,
});  
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;babel&#34;&gt;Babel&lt;/h2&gt;

&lt;p&gt;現在のLambdaのNodeのバージョンはv6.10.3。
&lt;a href=&#34;http://node.green/&#34;&gt;node.green&lt;/a&gt;によるとES2015は99%対応していて、ES2016もべき乗演算子(2 ** 3 = 8)以外は対応しているが、ES2017のasync/awaitは7.6からなので、8系に対応するまではbabelにかける必要がある。
ちなみにPuppeteerは6.4以降で&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/tree/master/utils/node6-transform&#34;&gt;動く&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev babel-cli babel-preset-env
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/babel/babel-preset-env&#34;&gt;babel-preset-env&lt;/a&gt;
.babelrcはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat .babelrc
{
  &amp;quot;presets&amp;quot;: [
    [&amp;quot;env&amp;quot;, {
      &amp;quot;targets&amp;quot;: {
        &amp;quot;node&amp;quot;: &amp;quot;6.10&amp;quot;
      }
    }]
  ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Headless Chromeでファイルをダウンロードする</title>
          <link>https://www.sambaiz.net/article/131/</link>
          <pubDate>Sun, 03 Sep 2017 18:51:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/131/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://chromedevtools.github.io/devtools-protocol/&#34;&gt;Chrome DevTools Protocol&lt;/a&gt;に
Experimentalだけど&lt;a href=&#34;https://chromedevtools.github.io/devtools-protocol/tot/Page#method-setDownloadBehavior&#34;&gt;Page.setDownloadBehavior&lt;/a&gt;
というのがあったので、これを呼んでファイルをダウンロードしてみた。&lt;/p&gt;

&lt;p&gt;今回は公式のDevToolsのNode API、&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34;&gt;Puppeteer&lt;/a&gt;を使うけど、
setDownloadBehaviorを送るAPIはまだ&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/blob/64124df62f4e81999fe1a0ab45c6fb9718a0e413/lib/Page.js#L29&#34;&gt;なく&lt;/a&gt;、直接clientを取ってsendするので他のライブラリでもやることは変わらないと思う。
Puppeteerのインストールの際にChromiumも入る。setDownloadBehaviorは現行Chromeの60では&lt;a href=&#34;https://bugs.chromium.org/p/chromium/issues/detail?id=696481&#34;&gt;対応していない&lt;/a&gt;ようだけど、62が入ったのでなんとかなりそう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add puppeteer
$ find . -name &amp;quot;*chrome*&amp;quot;
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_100_percent.pak
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_200_percent.pak
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、このChromeをLambda上で実行しようとすると失敗する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/132/&#34;&gt;Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ChromeでChromeをダウンロードしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const puppeteer = require(&#39;puppeteer&#39;),
      fs        = require(&#39;fs&#39;);

const headless     = true,
      downloadPath = &#39;./Download&#39;;

(async () =&amp;gt; {
  const browser = await puppeteer.launch({headless: headless});
  
  const page = await browser.newPage();
  await page._client.send(
    &#39;Page.setDownloadBehavior&#39;,
    {behavior : &#39;allow&#39;, downloadPath: downloadPath}
  );

  await page.goto(&#39;https://www.google.co.jp/chrome/browser/desktop/index.html&#39;, {waitUntil: &#39;networkidle&#39;});
  await page.click(&#39;a.download-button&#39;);  /* Chromeをダウンロード         */
  await page.click(&#39;button#eula-accept&#39;); /* 利用規約に同意してインストール */

  await waitDownloadComplete(downloadPath)
        .catch((err) =&amp;gt; console.error(err));
 
  console.log(&#39;finished&#39;);
  browser.close();  
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイルがダウンロードできたかどうかは.crdownloadのありなしで判定している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const waitDownloadComplete = async (path, waitTimeSpanMs = 1000, timeoutMs = 60 * 1000) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {

    const wait = (waitTimeSpanMs, totalWaitTimeMs) =&amp;gt; setTimeout(
      () =&amp;gt; isDownloadComplete(path).then(
        (completed) =&amp;gt; {
          if (completed) { 
            resolve();
          } else {

            const nextTotalTime = totalWaitTimeMs + waitTimeSpanMs;
            if (nextTotalTime &amp;gt;= timeoutMs) {
              reject(&#39;timeout&#39;);
            }

            const nextSpan = Math.min(
              waitTimeSpanMs,
              timeoutMs - nextTotalTime
            );
            wait(nextSpan, nextTotalTime);
          }           
        }
      ).catch(
        (err) =&amp;gt; { reject(err); }
      ),
      waitTimeSpanMs
    );
    
    wait(waitTimeSpanMs, 0);
  }); 
}

const isDownloadComplete = async (path) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {
    fs.readdir(path, (err, files) =&amp;gt; {
      if (err) {
        reject(err);
      } else {
        if (files.length === 0) {
          resolve(false);
          return;
        }
        for(let file of files){

          // .crdownloadがあればダウンロード中のものがある
          if (/.*\.crdownload$/.test(file)) { 
            resolve(false);
            return;
          }
        }
        resolve(true);
      }
    });
  });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Headlessだと何もでてこないのでうまくいったか良くわからないけど、
指定したパスを見にいったらちゃんと保存されていた。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;機能的には近い立ち位置の&lt;a href=&#34;http://www.nightmarejs.org/&#34;&gt;NightmareJS&lt;/a&gt;の方も、
v1の&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;、現行v2の&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;を経て
v3ではHeadless Chromeに&lt;a href=&#34;https://github.com/segmentio/nightmare/issues/1092&#34;&gt;なるかもしれない&lt;/a&gt;。
速いし、ウィンドウがないので&lt;a href=&#34;https://en.wikipedia.org/wiki/Xvfb&#34;&gt;xvfb(X virtual framebuffer)&lt;/a&gt;も&lt;a href=&#34;https://developers.google.com/web/updates/2017/04/headless-chrome&#34;&gt;必要ない&lt;/a&gt;し良さそうなんだけど、
現在のChrome DevTools ProtocolではNightmareの既存APIをサポートできなかったり、
Puppeteerとの住み分けはどうするのって話になっているみたいだ。&lt;/p&gt;

&lt;p&gt;現状Nightmare自体にダウンロード機能は含まれていないが、
Electronの&lt;a href=&#34;https://github.com/electron/electron/blob/master/docs-translations/jp/api/download-item.md&#34;&gt;will-download&lt;/a&gt;イベントを
ハンドリングする
&lt;a href=&#34;https://github.com/rosshinkley/nightmare-download-manager&#34;&gt;nightmare-download-manager&lt;/a&gt;や
&lt;a href=&#34;https://github.com/rosshinkley/nightmare-inline-download&#34;&gt;nightmare-inline-download&lt;/a&gt;
といったライブラリがある。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>floatとdoubleの表現と精度</title>
          <link>https://www.sambaiz.net/article/130/</link>
          <pubDate>Sat, 02 Sep 2017 12:47:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/130/</guid>
          <description>

&lt;p&gt;IEEE754の仕様。記憶が薄れていたのでまとめておく。&lt;/p&gt;

&lt;p&gt;float(32bit)は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1bit: 符号&lt;/li&gt;
&lt;li&gt;8bit: 指数部(exponent)&lt;/li&gt;
&lt;li&gt;23bit: 仮数部(fraction)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;double(64bit)は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1bit: 符号&lt;/li&gt;
&lt;li&gt;11bit: 指数部&lt;/li&gt;
&lt;li&gt;52bit: 仮数部&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;で表される。&lt;/p&gt;

&lt;p&gt;例えば-5.25(2進で-101.01)を表す場合、
&lt;code&gt;-1.0101 * 2^2&lt;/code&gt;のように&lt;code&gt;±1.xxxx * 2^n&lt;/code&gt;の形にして、負なら符号を1に、指数部を正(1~254or2046)にするため
nに127or1023のバイアスを足した数を入れ、仮数部にはxxxxの部分の後ろに0を詰めたのをそのまま入れる。
したがって、-5.25のfloatは&lt;code&gt;1 10000001 01010000000000000000000&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;ただし、指数部が0のときは仮数部xxxxに対して&lt;code&gt;0.xxxx * 2^-126or1022&lt;/code&gt;のように解釈し、
0や指数部で表すことができる数(2^-126or1022)より絶対値が小さい非正規化数を表すことができるようになっている。
また、Infinityはそれぞれ(255or2047,0)、NaNは(255or2047,0以外)で表す。&lt;/p&gt;

&lt;p&gt;精度は仮数部の大きさに依存し、floatが10進で&lt;code&gt;Math.log10(2 ** 23) = 6.92&lt;/code&gt;桁で、doubleが&lt;code&gt;Math.log10(2 ** 52) = 15.65&lt;/code&gt;桁。JavaScriptの数値はdoubleなので
&lt;code&gt;1234567890.1234569&lt;/code&gt;が&lt;code&gt;1234567890.123457&lt;/code&gt;になり16~17桁目で値がおかしくなることが確認できる。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/IEEE_754&#34;&gt;IEEE 754 - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Double-precision_floating-point_format&#34;&gt;Double-precision floating-point format - Wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pythonのインタラクティブな可視化ライブラリBokehでグラフを描く</title>
          <link>https://www.sambaiz.net/article/129/</link>
          <pubDate>Sat, 26 Aug 2017 18:02:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/129/</guid>
          <description>

&lt;p&gt;Pythonの可視化というと&lt;a href=&#34;https://github.com/matplotlib/matplotlib&#34;&gt;matplotlib&lt;/a&gt;や、
そのラッパーの&lt;a href=&#34;https://github.com/mwaskom/seaborn&#34;&gt;seaborn&lt;/a&gt;、
データ解析ライブラリの&lt;a href=&#34;https://github.com/pandas-dev/pandas&#34;&gt;Pandas&lt;/a&gt;にもそういう機能があるけど、
これらが表示するのが静止画なのに対して、&lt;a href=&#34;https://github.com/bokeh/bokeh&#34;&gt;Bokeh&lt;/a&gt;はD3.jsで描画し、
拡大したりスクロールしたり、動的に何か表示することができる。Bokehはカメラのボケ。
似たようなのに&lt;a href=&#34;https://github.com/plotly/plotly.py&#34;&gt;Plotly&lt;/a&gt;というのもあるけど、
こちらはPandasと同じpydata.orgドメインで、スターが多い。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/jupyter/datascience-notebook/&#34;&gt;jupyter/datascience-notebook&lt;/a&gt;イメージにもBokehがインストールされている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d -p 8888:8888 jupyter/datascience-notebook start-notebook.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;簡単なグラフを描く&#34;&gt;簡単なグラフを描く&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;output_notebook&lt;/code&gt;でJupytor Notebokに出力する。ファイルに出力する場合は&lt;code&gt;ouput_file&lt;/code&gt;を呼ぶ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from bokeh.plotting import figure
from bokeh.io import output_notebook, show
output_notebook()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.figure&#34;&gt;figure()&lt;/a&gt;でplotするFigureオブジェクトを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p = figure(
    title=&amp;quot;Hoge&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;,
    y_axis_type=&amp;quot;log&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.line&#34;&gt;line()&lt;/a&gt;で線をつないで&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.circle&#34;&gt;circle()&lt;/a&gt;で円を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
y0 = [i**2 for i in x]
y1 = [10**i for i in x]
y2 = [10**(i**2) for i in x]

p.line(x, x, legend=&amp;quot;y=x&amp;quot;)
p.circle(x, x, legend=&amp;quot;y=x&amp;quot;, fill_color=&amp;quot;white&amp;quot;, size=8)

p.line(x, y0, legend=&amp;quot;y=x^2&amp;quot;, line_width=3)

p.line(x, y1, legend=&amp;quot;y=10^x&amp;quot;, line_color=&amp;quot;red&amp;quot;)
p.circle(x, y1, legend=&amp;quot;y=10^x&amp;quot;, fill_color=&amp;quot;red&amp;quot;, line_color=&amp;quot;red&amp;quot;, size=6)

p.line(x, y2, legend=&amp;quot;y=10^x^2&amp;quot;, line_color=&amp;quot;orange&amp;quot;, line_dash=&amp;quot;4 4&amp;quot;)

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129.png&#34; alt=&#34;折れ線グラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.vbar&#34;&gt;vbar()&lt;/a&gt;で
縦棒を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]

p.vbar(x, top=x, width=0.2, bottom=0, color=&amp;quot;#CAB2D6&amp;quot;)

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-vbar.png&#34; alt=&#34;棒グラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.annular_wedge&#34;&gt;annular_wedge()&lt;/a&gt;で弧を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import math
from collections import namedtuple

Data = namedtuple(&#39;Data&#39;, (&#39;name&#39;, &#39;value&#39;, &#39;color&#39;))
rates = [Data(&amp;quot;A&amp;quot;, 0.6, &amp;quot;#7FC97F&amp;quot;), Data(&amp;quot;B&amp;quot;, 0.4, &amp;quot;#DD1C77&amp;quot;)]

start_angle = 0

for rate in rates:
    p.annular_wedge(
            x=0, 
            y=0,
            inner_radius=0.2, 
            outer_radius=0.5, 
            start_angle=math.pi * 2 * start_angle, 
            end_angle=math.pi * 2 * (start_angle + rate.value),
            color=rate.color,
            legend=rate.name
    )
    start_angle += rate.value

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-c.png&#34; alt=&#34;円グラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;複数のグラフを連動させる&#34;&gt;複数のグラフを連動させる&lt;/h2&gt;

&lt;p&gt;複数のfigureでrangeを合わせると連動する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]

left = figure(
    title=&amp;quot;Left&amp;quot;, 
    width=400,
    y_axis_type=&amp;quot;log&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;
)

right = figure(
    title=&amp;quot;Right&amp;quot;, 
    width=400,
    x_range=left.x_range,
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;
)

left.line(x, x, legend=&amp;quot;y=x&amp;quot;)
right.line(x, x, legend=&amp;quot;y=x&amp;quot;)

p = gridplot([[left, right]])

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129.gif&#34; alt=&#34;連動するグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ホバーで情報を表示する&#34;&gt;ホバーで情報を表示する&lt;/h2&gt;

&lt;p&gt;figureのtoolsにhoverを追加し、sourceに&lt;code&gt;CoulumnDataSource&lt;/code&gt;を渡して、
以下のように&lt;code&gt;select_one(HoverTool)&lt;/code&gt;するとホバーで情報を表示できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import math
from bokeh.models import HoverTool, ColumnDataSource
from collections import namedtuple

p = figure(
    title=&amp;quot;Hoge&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;,
    tools=&amp;quot;hover,save&amp;quot;
)

Data = namedtuple(&#39;Data&#39;, (&#39;name&#39;, &#39;value&#39;, &#39;color&#39;))
rates = [Data(&amp;quot;A&amp;quot;, 0.6, &amp;quot;#7FC97F&amp;quot;), Data(&amp;quot;B&amp;quot;, 0.4, &amp;quot;#DD1C77&amp;quot;)]

start_angle = 0

for rate in rates:
    
    source = ColumnDataSource(
        data=dict(
            value=[rate.value],
        )
    )
    
    p.annular_wedge(
            x=0, 
            y=0,
            inner_radius=0.2, 
            outer_radius=0.5, 
            start_angle=math.pi * 2 * start_angle, 
            end_angle=math.pi * 2 * (start_angle + rate.value),
            color=rate.color,
            legend=rate.name,
            source=source
    )
    start_angle += rate.value

p.select_one(HoverTool).tooltips = [
    (&amp;quot;value&amp;quot;, &amp;quot;@value&amp;quot;)
]

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-c2.png&#34; alt=&#34;Tooltips&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
          <link>https://www.sambaiz.net/article/128/</link>
          <pubDate>Thu, 24 Aug 2017 09:22:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/128/</guid>
          <description>

&lt;h2 id=&#34;hiveとは-https-cwiki-apache-org-confluence-display-hive-home-home-apachehive&#34;&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/Home#Home-ApacheHive&#34;&gt;Hiveとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Hadoop上で動くデータウェアハウスソフトウェア。
SQLを拡張したHiveQLを書くとデータを処理するMapReduceやSpark、Tezのジョブが生成される。
クエリの実行に時間がかかり、耐障害性があるのでDailyやHourlyのバッチで使われる。&lt;/p&gt;

&lt;p&gt;ちなみにAthenaにも使われている&lt;a href=&#34;https://prestodb.io/&#34;&gt;Presto&lt;/a&gt;
はタスクを並列に実行し、中間データをメモリ上に持つことで数分以内に結果が得られるので
ダッシュボードなどの用途でアドホックに使える。中間データが大きいと&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/top-10-performance-tuning-tips-for-amazon-athena/&#34;&gt;時間がかかったり失敗する&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/5-5-x/topics/impala.html&#34;&gt;Impala&lt;/a&gt;はさらに速いけどメモリの消費が激しいらしい。&lt;/p&gt;

&lt;h2 id=&#34;cloudera-docker-imageを起動する-https-www-cloudera-com-documentation-enterprise-latest-topics-quickstart-docker-container-html&#34;&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/latest/topics/quickstart_docker_container.html&#34;&gt;Cloudera Docker Imageを起動する&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Cloudera Docker Imageには&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html&#34;&gt;CDH&lt;/a&gt;: Clouderaのディストリビューション。Hadoop、Hive、SparkなどのOSSで構成されている。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/latest/topics/cloudera_manager.html&#34;&gt;Cloudera Manager&lt;/a&gt;: CDHクラスタを管理する。無料のExpressと有料のEnterpriseで使える機能に&lt;a href=&#34;https://www.cloudera.com/content/dam/www/static/documents/datasheets/cloudera-enterprise-datasheet.pdf&#34;&gt;差がある&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;が含まれていて、これを起動すると諸々立ち上がる。CDHクラスタを組むのはサポートされていないようなのでテスト用らしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull cloudera/quickstart:latest
$ docker run --hostname=quickstart.cloudera --privileged=true -itd -p 8888 -p 7180 -p 80 cloudera/quickstart /usr/bin/docker-quickstart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;80がチュートリアルで、8888がHadoopのWeb UIの&lt;a href=&#34;https://github.com/cloudera/hue&#34;&gt;Hue&lt;/a&gt;、7180がCloudera Manager。Dockerに割り当てるメモリが2GBだと&lt;code&gt;Failed to contact an active Resource Manager&lt;/code&gt;になってしまったので4GBにした。&lt;/p&gt;

&lt;h2 id=&#34;hiveのテーブルを作成して実行する&#34;&gt;Hiveのテーブルを作成して実行する&lt;/h2&gt;

&lt;p&gt;チュートリアルでは&lt;a href=&#34;http://sqoop.apache.org/&#34;&gt;Sqoop&lt;/a&gt;を使ってDBから取り込んでいるんだけど、
今回はjsonのログのテーブルを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sqoop import-all-tables \
    -m 1 \
    --connect jdbc:mysql://localhost:3306/retail_db \
    --username=retail_dba \
    --password=cloudera \
    --compression-codec=snappy \
    --as-parquetfile \
    --warehouse-dir=/user/hive/warehouse \
    --hive-import
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JSONを扱うにはStringから&lt;code&gt;LATERAL VIEW json_tuple(json_str, &amp;quot;field1&amp;quot;, &amp;quot;field2&amp;quot;) j AS field1, field2&lt;/code&gt;のように実行時にパースする方法と、&lt;a href=&#34;https://github.com/rcongiu/Hive-JSON-Serde&#34;&gt;JSON SerDe&lt;/a&gt;で最初から別カラムにいれる方法があるが、今回はSerDeでやる。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;json_tupleを使う場合、配列はStringになってしまうのでこれをArrayにするには便利なUDF(User-Defined Functions)をまとめた&lt;a href=&#34;https://github.com/klout/brickhouse&#34;&gt;brickhouse&lt;/a&gt;のjson_splitが使える。例えば、&lt;code&gt;SELECT col1 FROM table LATERAL VIEW explode(json_split(&#39;[&amp;quot;a&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;c&amp;quot; ]&#39;)) a as ja&lt;/code&gt;のようにするとArrayになったStringがexplodeしてtableの各列に3種のカラムjaが並ぶ。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;col1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;ja&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;c&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;c&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Arrayが空の場合にexplodeすると消滅してしまうので、LEFT JOINのように残すにはarray(null)に加工してやるとよい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CASE WHEN size(json_split(arr)) &amp;gt; 0 THEN json_split(arr) ELSE array(null) END AS arr
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;JSON SerDeのjarを持ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://www.congiu.net/hive-json-serde/1.3.8/cdh5/json-serde-1.3.8-jar-with-dependencies.jar &amp;gt; /usr/lib/hive/lib/json-serde-1.3.8-jar-with-dependencies.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリはHueから実行できて、初期ユーザー名とパスワードはどちらもcloudera。&lt;/p&gt;

&lt;p&gt;CREATE TABLEはこんな感じ。スキーマ情報はmetastoreに入る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ADD JAR /usr/lib/hive/lib/json-serde-1.3.8-jar-with-dependencies.jar;

CREATE EXTERNAL TABLE jinrou (
        participant ARRAY&amp;lt;STRUCT&amp;lt;user_id:INT,role:STRING,team:STRING&amp;gt;&amp;gt;,
        win_team    STRING,
        ts          STRING
      )
      ROW FORMAT SERDE &#39;org.openx.data.jsonserde.JsonSerDe&#39;
      WITH SERDEPROPERTIES ( &amp;quot;mapping.ts&amp;quot; = &amp;quot;timestamp&amp;quot; )
      LOCATION &#39;/user/cloudera/jinrou&#39;;
      
ADD JAR /usr/lib/hive/lib/hive-contrib.jar;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指定したLOCATIONにログをアップロードする。これもHueからできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;participant&amp;quot;:[{&amp;quot;user_id&amp;quot;:1,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:2,&amp;quot;role&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;wolf&amp;quot;},{&amp;quot;user_id&amp;quot;:3,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:4,&amp;quot;role&amp;quot;:&amp;quot;medium&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:5,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:6,&amp;quot;role&amp;quot;:&amp;quot;fortune-teller&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;}],&amp;quot;win_team&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;timestamp&amp;quot;:&amp;quot;2017-08-21T01:23:45.678+0900&amp;quot;}
{&amp;quot;participant&amp;quot;:[{&amp;quot;user_id&amp;quot;:3,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:4,&amp;quot;role&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;wolf&amp;quot;},{&amp;quot;user_id&amp;quot;:1,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:2,&amp;quot;role&amp;quot;:&amp;quot;medium&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:6,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:5,&amp;quot;role&amp;quot;:&amp;quot;fortune-teller&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;}],&amp;quot;win_team&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;timestamp&amp;quot;:&amp;quot;2017-08-21T02:34:56.789+0900&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SELECT文を実行すると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT user_id, role, SUM(is_win)/COUNT(1) AS wp FROM (
  SELECT 
    par.user_id,
    par.role, 
    CASE WHEN par.role = win_team THEN 1 ELSE 0 END AS is_win
    FROM jinrou
  LATERAL VIEW explode(participant) p AS par
) j GROUP BY user_id, role;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参照できている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;user_id,role,wp
1,villager,0.5
2,medium,0.0
2,wolf,1.0
3,villager,0.5
4,medium,0.0
4,wolf,0.0
5,fortune-teller,0.0
5,villager,0.0
6,fortune-teller,0.0
6,villager,1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テーブルの定義よりjsonのフィールドが多いと無視されて、ないものはNULLになる。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog-jp.treasuredata.com/entry/2014/07/10/150250&#34;&gt;『Prestoとは何か，Prestoで何ができるか』 - トレジャーデータ（Treasure Data）公式ブログ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://recruit.gmo.jp/engineer/jisedai/blog/presto_spark_hive/&#34;&gt;スケールアウト可能なSQLエンジンのベンチマークテスト：Presto vs Spark SQL vs Hive on Tez | GMOインターネット 次世代システム研究室&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CloudflareでカスタムドメインのGitHub PagesにHTTPSでアクセスできるようにする</title>
          <link>https://www.sambaiz.net/article/127/</link>
          <pubDate>Mon, 21 Aug 2017 23:15:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/127/</guid>
          <description>

&lt;p&gt;このサイトはGitHub Pagesでカスタムドメインsambaiz.netを設定して、
Apex Domain(sambaiz.net)に&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain/&#34;&gt;Aレコード&lt;/a&gt;を登録して運用していたのだけれど、これだとカスタムドメインの証明書を置けないのでHTTPSでアクセスすると警告が出てしまう。
いい加減HTTPだと許されない風潮になってきたのでCloudflareを前に挟んでHTTPSでアクセスできるようにした。
ついでにCNAMEを登録できないApex Domain(sambaiz.net)をやめてwww.sambaiz.netに向ける。&lt;/p&gt;

&lt;h2 id=&#34;dnsの設定をする&#34;&gt;DNSの設定をする&lt;/h2&gt;

&lt;p&gt;Cloudflareでドメインを入れると既存のDNS Recordsを読み込むので必要に応じて修正する。
Cloudflareでは&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/200169056-CNAME-Flattening-RFC-compliant-support-for-CNAME-at-the-root&#34;&gt;CNAME Flattening&lt;/a&gt;によってApex Domainにも設定上ではCNAMEを与えることができ、内部でAレコードに解決してくれる。
そのためApex Domainをそのまま使っても実は問題ないのだけど、今後のために変えておく。
www.sambaiz.netにGitHub PagesのCNAMEを設定し、sambaiz.net(@)にはwww.sambaiz.netをCNAMEとして設定した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/127.png&#34; alt=&#34;DNS設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;あとGitHub Pagesの方のカスタムドメインもwww.sambaiz.netにした。
wwwを設定するとApex Domainでアクセスしたときにリダイレクトするように&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain-and-www-subdomain/&#34;&gt;なっている&lt;/a&gt;ので
既存のリンクが切れたり混在することはない。&lt;/p&gt;

&lt;p&gt;指示された&lt;code&gt;*.ns.cloudflare.com&lt;/code&gt;のようなCloudflareのネームサーバーをドメインに設定する。
さくらの場合、Apex Domainのネームサーバーはゾーン表示ではなくWHOIS情報のところから変更できる。
設定してしばらくするとCloudflareを通してアクセスが飛び警告なくHTTPSでアクセスできるようになる。
証明書は共有のものになっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/127-2.png&#34; alt=&#34;共有証明書&#34; /&gt;&lt;/p&gt;

&lt;p&gt;正常にアクセスできることを確認できたら今HTTPになっている画像やリンクもHTTPSにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ find . -name &#39;.git*&#39; -prune -o -name &#39;public&#39; -prune -o -name &#39;static&#39; -prune -o -type d -o -print | xargs sed -i &amp;quot;&amp;quot; &amp;quot;s/http:\/\/sambaiz.net/https:\/\/www.sambaiz.net/g&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cloudflareの機能&#34;&gt;Cloudflareの機能&lt;/h2&gt;

&lt;p&gt;Cloudflareにはいくつか&lt;a href=&#34;https://www.cloudflare.com/plans/&#34;&gt;プラン&lt;/a&gt;があって、今回はFreeプランにした。&lt;/p&gt;

&lt;h3 id=&#34;analytics&#34;&gt;Analytics&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;キャッシュされている/ないリクエスト数や帯域、それによる節約量&lt;/li&gt;
&lt;li&gt;ブロックした&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/204191238-What-are-the-types-of-Threats-&#34;&gt;脅威&lt;/a&gt;の数&lt;/li&gt;
&lt;li&gt;何人/どこの国からアクセスが来たか&lt;/li&gt;
&lt;li&gt;コンテンツ(HTML/CSS/PNG)ごとのリクエストの割合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;などがわかる。FreeだとWeb TrafficやGeographyが直近24時間より短いスパンで取れない。&lt;/p&gt;

&lt;h3 id=&#34;crypto&#34;&gt;Crypto&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudflare.com/ssl/&#34;&gt;SSL&lt;/a&gt;まわりの設定。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Flexible: クライアントとCloudflareはHTTPS、CloudflareとオリジンサーバーはHTTPで通信する。&lt;/li&gt;
&lt;li&gt;Full: デフォルト。Cloudflareとオリジンサーバーの通信もHTTPSで行うが、証明書の検証は行われない。&lt;/li&gt;
&lt;li&gt;Full(Strict) 証明書の検証も行う。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;から選択する。Business以上のPlanだと共有の証明書ではなく独自のものを上げることもできる。&lt;/p&gt;

&lt;p&gt;HTTPで来たらHTTPSにリダイレクトさせるのと、ブラウザでHTTPをHTTPSに置き換える&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/Security/HTTP_Strict_Transport_Security&#34;&gt;HTTP Strict Transport Security(HSTS)&lt;/a&gt;
の設定もある。
HSTSを設定するときに出るように
将来HTTPSをサポートしなくなった場合、HSTSの期限が残っているブラウザからはアクセスできなくなるので注意。
まあ今後HTTPのみに戻すということは考えにくいのだけど、推奨の有効期限は6ヶ月になっている。
あとNo-Sniff Headerの設定もここにあって、これをオンのままにしておくとContent-Typeがtext/cssでない
styleやJavaScriptのMIME Typeでないscriptのリクエストは&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options&#34;&gt;ブロック&lt;/a&gt;しXSSを防ぐ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Strict-Transport-Security: max-age=15552000
X-Content-Type-Options: nosniff
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;firewall&#34;&gt;Firewall&lt;/h3&gt;

&lt;p&gt;IPアドレスや国でブロックしたりとか。Pro以上のプランだと&lt;a href=&#34;https://www.cloudflare.com/waf/&#34;&gt;Web Application Firewall&lt;/a&gt;を有効にできる。&lt;/p&gt;

&lt;h3 id=&#34;speed&#34;&gt;Speed&lt;/h3&gt;

&lt;p&gt;JS/CSS/HTMLを自動でMinifyしたり、モバイルの場合リダイレクトさせたりできる。
Proプランでは画像を最適化してくれる。&lt;/p&gt;

&lt;h3 id=&#34;caching&#34;&gt;Caching&lt;/h3&gt;

&lt;p&gt;キャッシュをパージしたり、どのレベルでキャッシュするかの設定など。&lt;/p&gt;

&lt;h3 id=&#34;page-rules&#34;&gt;Page Rules&lt;/h3&gt;

&lt;p&gt;URL単位でルールを設定できる。example.com/hoge/*は静的なページなのでHTMLもキャッシュするとか。
3つルールが作れて、5つ追加するのに月5ドル。&lt;/p&gt;

&lt;h3 id=&#34;network&#34;&gt;Network&lt;/h3&gt;

&lt;p&gt;最大アップロードサイズやWebSocketを有効にするかなどの設定。
ユーザーのIPアドレスをTrue-Client-IPに乗せるのはEnterpriseプランが必要。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HDFS(Hadoop Distributed File System)とは</title>
          <link>https://www.sambaiz.net/article/126/</link>
          <pubDate>Mon, 14 Aug 2017 22:52:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/126/</guid>
          <description>

&lt;h2 id=&#34;hdfsとは&#34;&gt;HDFSとは&lt;/h2&gt;

&lt;p&gt;Hadoopの分散ファイルシステム。
Hadoopの抽象化されたファイルシステム実装の一つで、他の実装にはLocal fileやS3などがある。
データのサイズが大きい場合に特に問題になるディスクI/Oを分散させ、
読み書きする最小の単位であるブロックサイズを大きくしシークのコストを減らすことで
スループットを高めている。
ディスクI/Oがどれくらい遅いかというと、
シークがデータセンター内での往復の通信の20倍(10ms)、
1MBの読み込みが40倍の時間(20ms)&lt;a href=&#34;https://gist.github.com/jboner/2841832&#34;&gt;かかる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;一方、小さなデータに低レイテンシでアクセスするというのは得意でなく、
また、1ファイルあたり150バイトのメタデータがNameNodeのメモリ上に乗っかるため大量のファイルを扱うのは大変。
あとデータは追記しかできない。&lt;/p&gt;

&lt;h3 id=&#34;namenodeとdatanode&#34;&gt;NameNodeとDataNode&lt;/h3&gt;

&lt;p&gt;クラスタの中にはおおよそ2種類のノードがあって、
ブロックがあるいくらかのDataNodeと、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ファイルの階層とメタデータ&lt;/li&gt;
&lt;li&gt;どのDataNodeにそのファイルのブロックがあるか&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の情報が含まれる&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;fsimage(メタデータのスナップショット)&lt;/li&gt;
&lt;li&gt;edit log(fsimageに含まれていない変更ログ)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を保存する、名前空間に単一のNameNodeがある。
もう一つSecondary NameNodeというのがあって、これはedit logが大きくならないよう
定期的にedit logをfsimageにマージするもの。&lt;/p&gt;

&lt;p&gt;NameNodeが機能停止すると読み書きできなくなってしまうので、
新しいNameNodeを立てる必要がある。
その際fsimageにedit logを適用して状態を復元するため
これらのファイルを別のファイルシステムにバックアップなどして失われないようにする。&lt;/p&gt;

&lt;p&gt;巨大なクラスタだとNameNodeを立ち上げるのに30分以上かかることもあるため、
Secondary NameNodeの代わりにStandby NameNodeを立ててHigh Availabilityにすることもできる。
Standby NameNodeはNameNodeと共有ストレージでedit logを共有し、最新の状態がメモリ上に乗っているので
NameNodeが死んだと判断されてから数十秒ほどで切り替えることができる。&lt;/p&gt;

&lt;h2 id=&#34;書き込みと読み込み&#34;&gt;書き込みと読み込み&lt;/h2&gt;

&lt;h3 id=&#34;書き込み&#34;&gt;書き込み&lt;/h3&gt;

&lt;p&gt;ファイルシステムがNameNodeとやりとりして、ファイルが存在しているか、パーミッションがあるかを確認し、問題なければFSDataOutputStreamをクライアントに返す。
書き込むデータはdata queueにまず入って、
どのDataNodeに書き込むかはDataStreamerというのがNameNodeとやりとりして決める。
レプリカの設定数分DataNodeが選ばれ、順に書き込まれるようDataNode間でパイプラインを作る。
正常に書き込まれたDetaNodeからはack packetが返ってくるのでこれはack queryに入れて
全て正しく書き込まれたことが確認できたら消す。
失敗したDataNodeがあったら、そこに中途半端に書き込まれた分を復活したら消すようにして、パイプラインから除き
新しいパイプラインを作る。&lt;/p&gt;

&lt;h3 id=&#34;読み込み&#34;&gt;読み込み&lt;/h3&gt;

&lt;p&gt;ファイルシステムがNameNodeにファイルのブロックがどこにあるかを聞く。
NameNodeは、ブロックがあるDataNodeをクライアントからネットワークトポロジ的に近い順にソートしてアドレスを返す。
ファイルシステムはそのアドレスが含まれたFSDataInputStreamをクライアントに返して、クライアントが順にreadしていく。&lt;/p&gt;

&lt;h2 id=&#34;singlenode-clusterで動かす-http-hadoop-apache-org-docs-current-hadoop-project-dist-hadoop-common-singlecluster-html&#34;&gt;&lt;a href=&#34;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html&#34;&gt;SingleNode Clusterで動かす&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ yum --enablerepo=epel -y install pdsh
$ echo $JAVA_HOME
/usr/lib/jvm/jre
$ wget http://ftp.jaist.ac.jp/pub/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz
$ tar xvzf hadoop-2.7.3.tar.gz 
$ cd hadoop-2.7.3
$ bin/hadoop version
Hadoop 2.7.3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトのファイルシステムをHDFSにしてレプリカを1にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vi etc/hadoop/core-site.xml
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
...
&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;

$ vi etc/hadoop/hdfs-site.xml
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
...
&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hadoopデーモンを起動/終了させるためにsshできるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa
$ cat ~/.ssh/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
$ ssh localhost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs namenode -format
$ sbin/start-dfs.sh
localhost: starting namenode, ...
localhost: starting datanode, ...
0.0.0.0: starting secondarynamenode, ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ディレクトリやファイルを作成して参照する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs dfs -mkdir /home
$ bin/hdfs dfs -mkdir /user/ec2-user
$ echo &#39;aaaaa&#39; &amp;gt; hoge
$ bin/hdfs dfs -put hoge ./
$ bin/hdfs dfs -put hoge ./
put: `hoge&#39;: File exists

$ bin/hdfs dfs -appendToFile hoge hoge
$ bin/hdfs dfs -ls ./
Found 1 items
-rw-r--r--   1 ec2-user supergroup         12 2017-08-14 13:44 hoge

$ bin/hdfs dfs -cat hoge
aaaaa
aaaaa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Filesystem check utilityを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs fsck ./ -files -blocks
Connecting to namenode via http://localhost:50070/fsck?ugi=ec2-user&amp;amp;files=1&amp;amp;blocks=1&amp;amp;path=%2Fuser%2Fec2-user
FSCK started by ec2-user (auth:SIMPLE) from /127.0.0.1 for path /user/ec2-user at Mon Aug 14 13:44:48 UTC 2017
/user/ec2-user &amp;lt;dir&amp;gt;
/user/ec2-user/hoge 12 bytes, 1 block(s):  OK
0. BP-478671077-172.31.3.159-1502715364675:blk_1073741825_1002 len=12 repl=1

Status: HEALTHY
 Total size:	12 B
 Total dirs:	1
 Total files:	1
 Total symlinks:		0
 Total blocks (validated):	1 (avg. block size 12 B)
 Minimally replicated blocks:	1 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	0 (0.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	1
 Average block replication:	1.0
 Corrupt blocks:		0
 Missing replicas:		0 (0.0 %)
 Number of data-nodes:		1
 Number of racks:		1
FSCK ended at Mon Aug 14 13:44:48 UTC 2017 in 2 milliseconds
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://shop.oreilly.com/product/0636920033448.do&#34;&gt;Hadoop: The Definitive Guide, 4th Edition&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.cloudera.com/blog/2014/03/a-guide-to-checkpointing-in-hadoop/&#34;&gt;A Guide to Checkpointing in Hadoop – Cloudera Engineering Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PythonのLintとFormatter</title>
          <link>https://www.sambaiz.net/article/125/</link>
          <pubDate>Fri, 11 Aug 2017 14:57:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/125/</guid>
          <description>

&lt;h2 id=&#34;yapf-https-github-com-google-yapf&#34;&gt;&lt;a href=&#34;https://github.com/google/yapf&#34;&gt;YAPF&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;スタイルに沿って整形してくれる、Goでいう&lt;code&gt;go fmt&lt;/code&gt;みたいなもの。
デフォルトはPython公式のスタイルガイド&lt;a href=&#34;https://www.python.org/dev/peps/pep-0008/&#34;&gt;PEP8&lt;/a&gt;でフォーマットされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install yapf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VSCodeでPythonを書くときは、
&lt;a href=&#34;https://github.com/DonJayamanne/pythonVSCode/wiki&#34;&gt;Pythonプラグイン&lt;/a&gt;
を入れてこんな設定をWorkspaceのconfigに入れておいて、
保存した時にフォーマットがかかるようにすると快適。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;editor.formatOnSave&amp;quot;: true,
&amp;quot;python.formatting.provider&amp;quot;: &amp;quot;yapf&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lint&#34;&gt;Lint&lt;/h2&gt;

&lt;p&gt;YAPFでフォーマットされた以下のコードにLintをかける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class FizzBuzz:
    def __init__(self, start=0):
        self.num = start

    def __iter__(self):
        return self

    def __next__(self):
        self.num += 1
        if self.num % 15 == 0:
            return &amp;quot;FizzBuzz&amp;quot;
        if self.num % 3 == 0:
            return &amp;quot;Fizz&amp;quot;
        if self.num % 5 == 0:
            return &amp;quot;Buzz&amp;quot;
        return self.num


if __name__ == &amp;quot;__main__&amp;quot;:
    fizzBuzz = FizzBuzz()
    for i in range(100):
        print(next(fizzBuzz))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pylint&#34;&gt;Pylint&lt;/h3&gt;

&lt;p&gt;Pythonプラグインではデフォルトで&lt;a href=&#34;https://github.com/PyCQA/pylint/&#34;&gt;Pylint&lt;/a&gt;が使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install pylint
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必要ならパスをUserのconfigでパスを指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;python.linting.pylintPath&amp;quot;: &amp;quot;***&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コマンドライン上で実行するとこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pylint main.py 
No config file found, using default configuration
************* Module main
C: 22, 0: Final newline missing (missing-final-newline)
C:  1, 0: Missing module docstring (missing-docstring)
C:  1, 0: Missing class docstring (missing-docstring)
R:  1, 0: Too few public methods (0/2) (too-few-public-methods)
C: 20, 4: Invalid constant name &amp;quot;fizzBuzz&amp;quot; (invalid-name)

-----------------------------------
Your code has been rated at 7.22/10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指摘された項目を見ると下の二つは余計かなと感じる。
そんな場合、コメントで&lt;code&gt;# pylint: disable=invalid-name&lt;/code&gt;のように書くか、
設定ファイル&lt;code&gt;pylintrc&lt;/code&gt;のdisableに追加すれば無視できる。
&lt;code&gt;--generate-rc-file&lt;/code&gt;でとても長い設定ファイルが生成される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pylint --generate-rcfile &amp;gt; pylintrc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;10点満点にしたのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot;
FizzBuzz main
&amp;quot;&amp;quot;&amp;quot;

class FizzBuzz: # pylint: disable=too-few-public-methods
    &amp;quot;&amp;quot;&amp;quot;
    FizzBuzz is incrementing a number and
    if the number is divisible by both 3 and 5, output &amp;quot;FizzBuzz&amp;quot;,
    if divisible by 3, &amp;quot;Fizz&amp;quot;,
    if divisible by 5, &amp;quot;Buzz&amp;quot;,
    Otherwise, output the number.
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(self, start=0):
        self.num = start

    def __iter__(self):
        return self

    def __next__(self):
        self.num += 1
        if self.num % 15 == 0:
            return &amp;quot;FizzBuzz&amp;quot;
        if self.num % 3 == 0:
            return &amp;quot;Fizz&amp;quot;
        if self.num % 5 == 0:
            return &amp;quot;Buzz&amp;quot;
        return self.num

if __name__ == &amp;quot;__main__&amp;quot;:
    fizzBuzz = FizzBuzz() # pylint: disable=invalid-name
    for i in range(100):
        print(next(fizzBuzz))
        
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;flake8-https-github-com-pycqa-flake8&#34;&gt;&lt;a href=&#34;https://github.com/PyCQA/flake8&#34;&gt;Flake8&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;他のLintとしてFlake8を使うこともできる。これは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/PyCQA/pyflakes&#34;&gt;PyFlakes&lt;/a&gt;: エラー&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/PyCQA/pycodestyle&#34;&gt;pycodestyle&lt;/a&gt;(元pep8): PEP8&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pycqa/mccabe&#34;&gt;Ned Batchelder&amp;rsquo;s McCabe script&lt;/a&gt;: &lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%BE%AA%E7%92%B0%E7%9A%84%E8%A4%87%E9%9B%91%E5%BA%A6&#34;&gt;循環的複雑度&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のチェッカーを合わせたもの。
&lt;a href=&#34;https://github.com/PyCQA/flake8-docstrings&#34;&gt;docstring&lt;/a&gt;は別に入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install flake8 flake8_docstrings
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VSCodeでの設定はこんな感じ。Pylintと同時に使うこともできなくはない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;python.linting.pylintEnabled&amp;quot;: false
&amp;quot;python.linting.flake8Enabled&amp;quot;: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同じコードにLintをかけてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ flake8 main.py
main.py:1:1: D100 Missing docstring in public module
main.py:1:1: D101 Missing docstring in public class
main.py:2:1: D102 Missing docstring in public method
main.py:5:1: D105 Missing docstring in magic method
main.py:8:1: D105 Missing docstring in magic method
main.py:22:30: W292 no newline at end of file
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;flake8-docstringは&lt;a href=&#34;https://www.python.org/dev/peps/pep-0257/&#34;&gt;PEP257&lt;/a&gt;に忠実にチェックしているのでちょっと厳しめ。&lt;code&gt;# flake8: noqa:D105&lt;/code&gt;のように無視することもできるし、
設定ファイル&lt;code&gt;.flake8&lt;/code&gt;に書くこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[flake8]
ignore = D105
exclude =
    .git,
    __pycache__,
    build,
    dist
max-complexity = 10
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
          <link>https://www.sambaiz.net/article/124/</link>
          <pubDate>Sun, 06 Aug 2017 23:54:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/124/</guid>
          <description>

&lt;p&gt;AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリ&lt;a href=&#34;https://github.com/deepmind/sonnet&#34;&gt;Sonnet&lt;/a&gt;を使う。
当初はPython2しか対応していないようだったけど、今は3にも対応している。&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;TensorFlowを使うライブラリはほかにもいくつかあるのだけど、
&lt;a href=&#34;https://github.com/fchollet/keras&#34;&gt;Keras&lt;/a&gt;と比較してみると、
KerasがTensorFlowの部分を完全にラップしているのに対して、
Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。&lt;/p&gt;

&lt;p&gt;SonnetとTensorFlowとPython3入りイメージをDockerHubに&lt;a href=&#34;https://hub.docker.com/r/sambaiz/sonnet/&#34;&gt;上げた&lt;/a&gt;。
Dockerfileは&lt;a href=&#34;https://github.com/sambaiz/docker-sonnet&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;内容は基本的にREADME通りだけど、
configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。
あとは、&lt;a href=&#34;https://github.com/deepmind/sonnet/issues/25&#34;&gt;TensorFlowのビルドに使われているGCCのバージョンが古い&lt;/a&gt;ようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに&lt;code&gt;--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;&lt;/code&gt;を付けている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet
$ docker logs sonnet
...
   Copy/paste this URL into your browser when you connect for the first time,
    to login with a token:
        http://localhost:8888/?token=*****
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sonnet as snt
import tensorflow as tf
snt.resampler(tf.constant([0.]), tf.constant([0.]))
# =&amp;gt; &amp;lt;tf.Tensor &#39;resampler/Resampler:0&#39; shape=(1,) dtype=float32&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mnist&#34;&gt;MNIST&lt;/h2&gt;

&lt;p&gt;TensorFlowのチュートリアルのデータを使って、畳み込みを行わない簡単なMNISTをやってみる。
このデータはtrain、validation、test用に最初から&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/contrib/learn/python/learn/datasets/base.py#L37&#34;&gt;分かれていて&lt;/a&gt;、
それぞれピクセル濃度配列の画像データと、その画像がどの数字なのかを表すone-hot vectorのラベルを&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/contrib/learn/python/learn/datasets/mnist.py#L105&#34;&gt;含んでいる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)
train, validation, test = mnist
print(train.images[0]) # ピクセルの濃度を[0,1]の値で表した配列: [0, 0, ..., 0.41568631  0.6156863, 0.99607849, ...]
print(len(train.images[0])) # 28 * 28 = 784
print(train.labels[0]) # 正解のみ1のone-hot vector: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]
images, labels = mnist.train.next_batch(100)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sonnetではニューラルネットワークの一部をModuleとして表現し、それらをTensorFlowの計算グラフに接続していく。
Moduleはグラフに複数回接続することができ、中の変数は共有される。
素のTensorFlowだと&lt;a href=&#34;https://www.tensorflow.org/programmers_guide/variable_scope&#34;&gt;変数のスコープ&lt;/a&gt;を作って共有するのに
reuse=Trueで&lt;code&gt;tf.variable_scope&lt;/code&gt;して&lt;code&gt;tf.get_variable&lt;/code&gt;したりするけど、そのあたりは抽象化されているので
&lt;code&gt;tf.Variable&lt;/code&gt;を含むような処理はModuleで行う。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/deepmind/sonnet/blob/v1.8/sonnet/python/modules/basic.py&#34;&gt;Linear Module&lt;/a&gt;は
重みの乗算とバイアスの加算をするもの。
これに&lt;code&gt;tf.Sigmoid&lt;/code&gt;のような活性化関数を適用するのを繰り返し、最後に出力層とつなげるとMulti Layer Perceptronを構築できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sonnet as snt
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

FLAGS = tf.flags.FLAGS

tf.flags.DEFINE_integer(&amp;quot;hidden_size&amp;quot;, 100, &amp;quot;Size of hidden layer.&amp;quot;)
tf.flags.DEFINE_integer(&amp;quot;output_size&amp;quot;, 10, &amp;quot;Size of output layer.&amp;quot;)

mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)

x = tf.placeholder(tf.float32, [None, 784])
y_ = tf.placeholder(tf.float32, [None, 10])
lin_to_hidden = snt.Linear(output_size=FLAGS.hidden_size, name=&#39;inp_to_hidden&#39;)
hidden_to_out = snt.Linear(output_size=FLAGS.output_size, name=&#39;hidden_to_out&#39;)
mlp = snt.Sequential([lin_to_hidden, tf.sigmoid, hidden_to_out, tf.nn.softmax])
y = mlp(x)
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(1000):
        images, labels = mnist.train.next_batch(100)
        sess.run(train_step, feed_dict={x: mnist.train.images, y_: mnist.train.labels})
    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
    # =&amp;gt; 0.9307
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;moduleを作る&#34;&gt;Moduleを作る&lt;/h2&gt;

&lt;p&gt;Moduleを作るには&lt;code&gt;snt.AbstractModule&lt;/code&gt;を継承し、
スーパークラスのコンストラクタを呼んで、グラフに接続されるたびに呼ばれる&lt;code&gt;_build&lt;/code&gt;メソッドを実装する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class MyMLP(snt.AbstractModule):
  &amp;quot;&amp;quot;&amp;quot;test mlp module&amp;quot;&amp;quot;&amp;quot;
  def __init__(self, hidden_size, output_size,
               nonlinearity=tf.sigmoid, name=&amp;quot;my_mlp&amp;quot;):
    &amp;quot;&amp;quot;&amp;quot;hidden_size &amp;amp; output_size is required&amp;quot;&amp;quot;&amp;quot;
    super(MyMLP, self).__init__(name=name)
    self._hidden_size = hidden_size
    self._output_size = output_size
    self._nonlinearity = nonlinearity
  
  def _build(self, inputs):
    &amp;quot;&amp;quot;&amp;quot;Compute output Tensor from input Tensor.&amp;quot;&amp;quot;&amp;quot;
    lin_to_hidden = snt.Linear(output_size=self._hidden_size, name=&#39;inp_to_hidden&#39;)
    hidden_to_out = snt.Linear(output_size=self._output_size, name=&#39;hidden_to_out&#39;)
    return snt.Sequential([lin_to_hidden, self._nonlinearity, hidden_to_out, tf.nn.softmax])(inputs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このModuleを使うとこんな感じ。
&lt;a href=&#34;https://github.com/deepmind/sonnet/blob/v1.8/sonnet/examples/dataset_shakespeare.py#L177&#34;&gt;example&lt;/a&gt;のように
データセットもModuleにすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)

mymlp = MyMLP(hidden_size=FLAGS.hidden_size, output_size=FLAGS.output_size)

x = tf.placeholder(tf.float32, [None, 784])
y_ = tf.placeholder(tf.float32, [None, 10])
y = mymlp(x)
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(1000):
        images, labels = mnist.train.next_batch(100)
        sess.run(train_step, feed_dict={x: mnist.train.images, y_: mnist.train.labels})
    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
    # =&amp;gt; 0.9307
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsをTypeScriptで書く</title>
          <link>https://www.sambaiz.net/article/123/</link>
          <pubDate>Sat, 29 Jul 2017 19:34:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/123/</guid>
          <description>

&lt;p&gt;公式の&lt;a href=&#34;https://github.com/Microsoft/TypeScript-Node-Starter&#34;&gt;TypeScript-Node-Starter&lt;/a&gt;から始めてもいいけど、依存が少し余分なので一から作ることにした。&lt;/p&gt;

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/typescript-nodejs-sample&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev typescript tslint tslint-microsoft-contrib jest ts-jest @types/jest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;package-json&#34;&gt;package.json&lt;/h2&gt;

&lt;p&gt;scriptsとテストフレームワーク&lt;a href=&#34;https://facebook.github.io/jest/&#34;&gt;Jest&lt;/a&gt;の設定を追加。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;devDependencies&amp;quot;: {
    ...
    &amp;quot;typescript&amp;quot;: &amp;quot;^2.4.2&amp;quot;
  },
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;start&amp;quot;: &amp;quot;npm run build &amp;amp;&amp;amp; node dist/app.js&amp;quot;,
    &amp;quot;build&amp;quot;: &amp;quot;npm run lint &amp;amp;&amp;amp; tsc&amp;quot;,
    &amp;quot;test&amp;quot;: &amp;quot;jest --forceExit&amp;quot;,
    &amp;quot;lint&amp;quot;: &amp;quot;tslint -c tslint.json -p tsconfig.json --type-check&amp;quot;
  },
  &amp;quot;jest&amp;quot;: {
    &amp;quot;transform&amp;quot;: {
      &amp;quot;^.+\\.ts$&amp;quot;: &amp;quot;./node_modules/ts-jest/preprocessor.js&amp;quot;
    },
    &amp;quot;testRegex&amp;quot;: &amp;quot;/test/.*\\.test\\.(ts|js)$&amp;quot;,
    &amp;quot;moduleFileExtensions&amp;quot;: [
      &amp;quot;ts&amp;quot;,
      &amp;quot;js&amp;quot;
    ],
    &amp;quot;testEnvironment&amp;quot;: &amp;quot;node&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tsconfig-json-https-www-typescriptlang-org-docs-handbook-tsconfig-json-html&#34;&gt;&lt;a href=&#34;https://www.typescriptlang.org/docs/handbook/tsconfig-json.html&#34;&gt;tsconfig.json&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;公式のそのまま。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;compilerOptions&amp;quot;: {
        &amp;quot;module&amp;quot;: &amp;quot;commonjs&amp;quot;,
        &amp;quot;target&amp;quot;: &amp;quot;es6&amp;quot;,
        &amp;quot;noImplicitAny&amp;quot;: true,
        &amp;quot;moduleResolution&amp;quot;: &amp;quot;node&amp;quot;,
        &amp;quot;sourceMap&amp;quot;: true,
        &amp;quot;outDir&amp;quot;: &amp;quot;dist&amp;quot;,
        &amp;quot;baseUrl&amp;quot;: &amp;quot;.&amp;quot;,
        &amp;quot;paths&amp;quot;: {
            &amp;quot;*&amp;quot;: [
                &amp;quot;node_modules/*&amp;quot;,
                &amp;quot;src/types/*&amp;quot;
            ]
        }
    },
    &amp;quot;include&amp;quot;: [
        &amp;quot;src/**/*&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tslint-json-https-palantir-github-io-tslint-usage-tslint-json&#34;&gt;&lt;a href=&#34;https://palantir.github.io/tslint/usage/tslint-json/&#34;&gt;tslint.json&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;MSでも使われているらしいルールを使うことにする。
結構厳しくて&lt;code&gt;console.log&lt;/code&gt;なんかもエラーになるので必要に応じてruleを追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;extends&amp;quot;: &amp;quot;tslint-microsoft-contrib&amp;quot;,
    &amp;quot;rules&amp;quot;: {
        &amp;quot;no-console&amp;quot;: [&amp;quot;&amp;quot;],
        &amp;quot;no-relative-imports&amp;quot;: false,
        &amp;quot;no-http-string&amp;quot;: false,
        &amp;quot;no-backbone-get-set-outside-model&amp;quot;: false
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使うパッケージをインストール&#34;&gt;使うパッケージをインストール&lt;/h2&gt;

&lt;p&gt;本体と型。&lt;/p&gt;

&lt;p&gt;以前は型ファイルを持ってくるのにtsdとかtypingsが使われていたけど
今は&lt;a href=&#34;https://github.com/DefinitelyTyped/DefinitelyTyped&#34;&gt;DefinelyTyped&lt;/a&gt;の内容が
npmの@types/~に&lt;a href=&#34;https://github.com/Microsoft/types-publisher&#34;&gt;上がる&lt;/a&gt;ようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add express
$ yarn add --dev @types/express
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;コードを書く&#34;&gt;コードを書く&lt;/h2&gt;

&lt;p&gt;VSCodeだったらtslintプラグインがあるので入れる。tsとtslintをglobal installする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import * as express from &#39;express&#39;;

/**
 * GET /echo
 * Return a string same as &amp;quot;say&amp;quot; query param.
 */
export function echoApi(req: express.Request, res: express.Response): void {

    const query: { say: string } = &amp;lt;{ say: string }&amp;gt; req.query;
    if (query.say === undefined) {
        res.send(echo(query.say));
    } else {
        res.status(400).send(&#39;&amp;quot;say&amp;quot; query param is required&#39;);
    }
}

/**
 * return a string same as input
 * @param say input (= output)
 */
export function echo(say: string): string {
    return say;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;テストを書く&#34;&gt;テストを書く&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/visionmedia/superagent&#34;&gt;superagent&lt;/a&gt;を使って
HTTPサーバーのテストを行う&lt;a href=&#34;https://github.com/visionmedia/supertest&#34;&gt;supertest&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev supertest @types/supertest
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import * as supertest from &#39;supertest&#39;;
import { app } from &#39;../src/app&#39;;
import { echo } from &#39;../src/echo&#39;;

let request: supertest.SuperTest&amp;lt;supertest.Test&amp;gt;;
beforeAll(() =&amp;gt; {
  request = supertest(app);
});

/**
 * integration test
 */
describe(&#39;GET /echo&#39;, () =&amp;gt; {
  it(&#39;should return a string same as &amp;quot;say&amp;quot; query param&#39;, (): {} =&amp;gt; {
    const say: string = &#39;Aa 1あ&#39;;

    return request
    .get(&#39;/echo&#39;)
    .query({ say: say })
    .expect(200, say);
  });

  it(&#39;is bad request that &amp;quot;say&amp;quot; query param is not given&#39;, (): {} =&amp;gt; {
    return request
    .get(&#39;/echo&#39;)
    .expect(400);
  });
});

/**
 * unit test
 */
describe(&#39;echo&#39;, () =&amp;gt; {
  it(&#39;should return a string same as input&#39;, () =&amp;gt; {
    const say: string = &#39;Aa 1あ&#39;;
    expect(echo(say)).toBe(say);
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;requestしたのをreturnするのを忘れるとテストが無条件で通ってしまうので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm test
...
 PASS  test/echo.test.ts
  GET /echo
    ✓ should return a string same as &amp;quot;say&amp;quot; query param (34ms)
    ✓ is bad request that &amp;quot;say&amp;quot; query param is not given (4ms)
  echo
    ✓ should return a string same as input (1ms)

Test Suites: 1 passed, 1 total
Tests:       3 passed, 3 total
Snapshots:   0 total
Time:        1.601s, estimated 2s
Ran all test suites.
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>k8sのパッケージマネージャーHelmを使う</title>
          <link>https://www.sambaiz.net/article/122/</link>
          <pubDate>Wed, 26 Jul 2017 01:33:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/122/</guid>
          <description>&lt;p&gt;Kubernatesが操舵手なのに対して、Helmは舵。
パッケージは&lt;a href=&#34;https://github.com/kubernetes/charts&#34;&gt;Chart&lt;/a&gt;(海図)と呼ばれている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/helm&#34;&gt;Helm&lt;/a&gt;をインストールし、&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;minikube&lt;/a&gt;を立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install kubernetes-helm
$ helm version
Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.5.0&amp;quot;, GitCommit:&amp;quot;012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}

# brew cask install virtualbox minikube
$ minikube version
minikube version: v0.20.0

$ minikube start
Kubectl is now configured to use the cluster.

$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.2&amp;quot;, GitCommit:&amp;quot;922a86cfcd65915a9b2f69f3f193b8907d741d9c&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2017-07-21T19:06:19Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;6&amp;quot;, GitVersion:&amp;quot;v1.6.4&amp;quot;, GitCommit:&amp;quot;d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-06-22T04:31:09Z&amp;quot;, GoVersion:&amp;quot;go1.7.5&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}

$ kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;k8sクラスタ上にHelmの管理サーバーTillerをインストールする必要がある。
ついでにリポジトリもupdateする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm init
$ helm repo update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-search&#34;&gt;search&lt;/a&gt;でChartを検索する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm search mysql
NAME                  	VERSION	DESCRIPTION                                       
stable/mysql          	0.2.6  	Fast, reliable, scalable, and easy to use open-...
stable/percona        	0.2.0  	free, fully compatible, enhanced, open source d...
stable/gcloud-sqlproxy	0.1.0  	Google Cloud SQL Proxy                            
stable/mariadb        	0.6.3  	Fast, reliable, scalable, and easy to use open-...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-inspect&#34;&gt;inspect&lt;/a&gt;でChartの内容を確認することができる。
&lt;code&gt;---&lt;/code&gt;より上がChartの情報のChart.yamlで、下がデフォルト値のvalues.yaml。
この値は&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/deployment.yaml#L54&#34;&gt;template&lt;/a&gt;で
参照される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm inspect stable/mysql
description: Fast, reliable, scalable, and easy to use open-source relational database
  system.
engine: gotpl
home: https://www.mysql.com/
icon: https://www.mysql.com/common/logos/logo-mysql-170x115.png
keywords:
- mysql
- database
- sql
maintainers:
- email: viglesias@google.com
  name: Vic Iglesias
name: mysql
sources:
- https://github.com/kubernetes/charts
- https://github.com/docker-library/mysql
version: 0.2.6

---
## mysql image version
## ref: https://hub.docker.com/r/library/mysql/tags/
##
image: &amp;quot;mysql&amp;quot;
imageTag: &amp;quot;5.7.14&amp;quot;

## Specify password for root user
##
## Default: random 10 character string
# mysqlRootPassword: testing

## Create a database user
##
# mysqlUser:
# mysqlPassword:

## Allow unauthenticated access, uncomment to enable
##
# mysqlAllowEmptyPassword: true

## Create a database
##
# mysqlDatabase:

## Specify an imagePullPolicy (Required)
## It&#39;s recommended to change this to &#39;Always&#39; if the image tag is &#39;latest&#39;
## ref: http://kubernetes.io/docs/user-guide/images/#updating-images
##
imagePullPolicy: IfNotPresent

## Persist data to a persitent volume
persistence:
  enabled: true
  ## If defined, volume.beta.kubernetes.io/storage-class: &amp;lt;storageClass&amp;gt;
  ## Default: volume.alpha.kubernetes.io/storage-class: default
  ##
  # storageClass:
  accessMode: ReadWriteOnce
  size: 8Gi

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 256Mi
    cpu: 100m

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mysqlDatabaseの値を渡してinstallしてみる。
パスワードなどをを保持する&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret/&#34;&gt;Secret&lt;/a&gt;、
&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;Persistent Volumes&lt;/a&gt;(PV)を要求する&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;PersistentVolumeClaim&lt;/a&gt;(PVC)と
ServiceとDeploymentが作成された。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{mysqlDatabase: user0db}&#39; &amp;gt; config.yaml
$ helm install -f config.yaml stable/mysql
...
RESOURCES:
==&amp;gt; v1/Secret
NAME                    TYPE    DATA  AGE
pioneering-hydra-mysql  Opaque  2     1s

==&amp;gt; v1/PersistentVolumeClaim
NAME                    STATUS  VOLUME                                    CAPACITY  ACCESSMODES  STORAGECLASS  AGE
pioneering-hydra-mysql  Bound   pvc-9649c097-7088-11e7-8dd5-0800270629d8  8Gi       RWO          standard      1s

==&amp;gt; v1/Service
NAME                    CLUSTER-IP  EXTERNAL-IP  PORT(S)   AGE
pioneering-hydra-mysql  10.0.0.216  &amp;lt;none&amp;gt;       3306/TCP  1s

==&amp;gt; v1beta1/Deployment
NAME                    DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
pioneering-hydra-mysql  1        1        1           0          1s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pods
NAME                                      READY     STATUS    RESTARTS   AGE
pioneering-hydra-mysql-3456603420-0pldk   1/1       Running   0          4m
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/secrets.yaml#L15&#34;&gt;生成された&lt;/a&gt;Secretの値は&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/deployment.yaml#L44&#34;&gt;secretKeyRef&lt;/a&gt;で参照できる。&lt;/p&gt;

&lt;p&gt;PVというのは管理者によってクラスタにプロビジョニングされた、あるいは動的にされる、Podとは独立したライフサイクルを持つVolume。PVCは&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#storageclasses&#34;&gt;StorageClass&lt;/a&gt;、ReadWriteOnceのようなアクセスモード、容量でリクエストする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get storageclasses
NAME                 TYPE
standard (default)   k8s.io/minikube-hostpath 
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Secretからrootパスワードを取得し、他のpodから接続できるのとDBが作成されていることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get secret --namespace default pioneering-hydra-mysql -o jsonpath=&amp;quot;{.data.mysql-root-password}&amp;quot; | base64 --decode; echo
******

$ kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il
$ apt-get update &amp;amp;&amp;amp; apt-get install mysql-client -y
$ mysql -h pioneering-hydra-mysql -p
mysql&amp;gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
| user0db            |
+--------------------+
5 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-list&#34;&gt;ls&lt;/a&gt;でインストールしたものを確認でき、
&lt;a href=&#34;https://docs.helm.sh/helm/#helm-delete&#34;&gt;delete&lt;/a&gt;で削除できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm ls
NAME            	REVISION	UPDATED                 	STATUS CHART      	NAMESPACE
pioneering-hydra	1       	Tue Jul 25 00:55:59 2017	DEPLOYEmysql-0.2.6	default  

$ helm delete pioneering-hydra
$ kubectl get secret --namespace default pioneering-hydra-mysql -o jsonpath=&amp;quot;{.data.mysql-root-password}&amp;quot; | base64 --decode; echo
Error from server (NotFound): secrets &amp;quot;pioneering-hydra-mysql&amp;quot; not found
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TerraformでVPCを管理するmoduleを作る</title>
          <link>https://www.sambaiz.net/article/121/</link>
          <pubDate>Sun, 23 Jul 2017 02:54:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/121/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install terraform
$ terraform -v
Terraform v0.9.11
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;terraformの設定要素&#34;&gt;Terraformの設定要素&lt;/h2&gt;

&lt;h3 id=&#34;provider-https-www-terraform-io-docs-providers-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/index.html&#34;&gt;provider&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;IaaS(e.g. AWS)、PaaS(e.g. Heroku)、SaaS(e.g. CloudFlare)など。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/&#34;&gt;AWS Provider&lt;/a&gt;はこんな感じ。
ここに直接access_keyやsecret_keyを書くこともできるけど、誤って公開されてしまわないように環境変数か
variableで渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;aws&amp;quot; {
  # access_key = &amp;quot;${var.access_key}&amp;quot;
  # secret_key = &amp;quot;${var.secret_key}&amp;quot;
  region = &amp;quot;us-east-1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ export AWS_ACCESS_KEY_ID=&amp;quot;anaccesskey&amp;quot;
$ export AWS_SECRET_ACCESS_KEY=&amp;quot;asecretkey&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;varibale-https-www-terraform-io-docs-configuration-variables-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/variables.html&#34;&gt;varibale&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;CLIでオーバーライドできるパラメーター。typeにはstringのほかにmapやlistを渡すことができ、
何も渡さないとdefault値のものが、それもなければstringになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;key&amp;quot; {
  type    = &amp;quot;string&amp;quot;
  default = &amp;quot;value&amp;quot;
  description = &amp;quot;description&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;値を渡す方法はTF_VAR_をprefixとする環境変数、-var、-var-fileがある。
また、moduleのinputとして渡されることもある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export TF_VAR_somelist=&#39;[&amp;quot;ami-abc123&amp;quot;, &amp;quot;ami-bcd234&amp;quot;]&#39;
$ terraform apply -var foo=bar -var foo=baz
$ terraform apply -var-file=foo.tfvars -var-file=bar.tfvars
$ cat foo.tfvars
foo = &amp;quot;bar&amp;quot;
xyz = &amp;quot;abc&amp;quot;

somelist = [
  &amp;quot;one&amp;quot;,
  &amp;quot;two&amp;quot;,
]

somemap = {
  foo = &amp;quot;bar&amp;quot;
  bax = &amp;quot;qux&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;output-https-www-terraform-io-docs-configuration-outputs-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/outputs.html&#34;&gt;output&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;variableがinputなのに対して、こちらはoutput。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;output &amp;quot;ip&amp;quot; {
  value = &amp;quot;${aws_eip.ip.public_ip}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行した後に取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform apply
...

$ terraform output ip
50.17.232.209
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;resource-https-www-terraform-io-docs-configuration-resources-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/resources.html&#34;&gt;resource&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;物理サーバーやVMのような低レベルのものからDNSレコードのような高レベルのものまで含むインフラのコンポーネント。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_instance&amp;quot; &amp;quot;web&amp;quot; {
  ami           = &amp;quot;ami-408c7f28&amp;quot;
  instance_type = &amp;quot;t1.micro&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;provisioner-https-www-terraform-io-docs-provisioners-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/provisioners/index.html&#34;&gt;provisioner&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;デフォルトでは作成されたときに実行されるコマンド。&lt;code&gt;when = &amp;quot;destroy&amp;quot;&lt;/code&gt;で終了時に実行させることもできる。
on_failureで失敗したときの挙動を設定することができ、デフォルトはコマンド自体が失敗する&amp;rdquo;fail&amp;rdquo;になっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_instance&amp;quot; &amp;quot;web&amp;quot; {
  # ...

  provisioner &amp;quot;local-exec&amp;quot; {
    command = &amp;quot;echo ${self.private_ip_address} &amp;gt; file.txt&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;data-https-www-terraform-io-docs-configuration-data-sources-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/data-sources.html&#34;&gt;data&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;情報を取得する。Terraform以外で作られたリソースのものも取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data &amp;quot;aws_ami&amp;quot; &amp;quot;web&amp;quot; {
  filter {
    name   = &amp;quot;state&amp;quot;
    values = [&amp;quot;available&amp;quot;]
  }

  filter {
    name   = &amp;quot;tag:Component&amp;quot;
    values = [&amp;quot;web&amp;quot;]
  }

  most_recent = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;module-https-www-terraform-io-docs-modules-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/modules/index.html&#34;&gt;module&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;設定をまとめたもの。variableの値を渡すことができ、再利用することができる。
GitHubのurlをsourceに指定することもできる。最初に&lt;code&gt;terraform get&lt;/code&gt;する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module &amp;quot;assets_bucket&amp;quot; {
  source = &amp;quot;./publish_bucket&amp;quot;
  name   = &amp;quot;assets&amp;quot;
}

module &amp;quot;media_bucket&amp;quot; {
  source = &amp;quot;./publish_bucket&amp;quot;
  name   = &amp;quot;media&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# publish_bucket/bucket-and-cloudfront.tf
variable &amp;quot;name&amp;quot; {} # this is the input parameter of the module
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;backend-https-www-terraform-io-docs-backends-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/backends/index.html&#34;&gt;backend&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;0.9.0から&lt;code&gt;terraform remote&lt;/code&gt;の代わりに使われるようになったもの。
管理下のresourceと今の状態を表すtfstateファイルを各自のローカルではなくリモートで一元的に管理する。
オプションではあるけど、applyしたあとにtfstateを上げるのを忘れたりするのを防ぐこともできるため
相当変わった用途でもない限り使わない理由がないと思う。最初に&lt;code&gt;terraform init&lt;/code&gt;する必要がある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/docs/backends/types/s3.html&#34;&gt;S3&lt;/a&gt;に置く場合はこんな感じ。
DynamoDBでロックをかけられる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;mybucket&amp;quot;
    key    = &amp;quot;path/to/my/key&amp;quot;
    region = &amp;quot;us-east-1&amp;quot;
    dynamodb_table = &amp;quot;tflocktable&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;vpcのmoduleを作る&#34;&gt;VPCのmoduleを作る&lt;/h2&gt;

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/terraform-example-vpc&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;community-moduleにも&lt;a href=&#34;https://github.com/terraform-community-modules/tf_aws_vpc&#34;&gt;VPCのモジュール&lt;/a&gt;があるんだけど、今回は自分で作ってみる。&lt;/p&gt;

&lt;p&gt;variableはこんな感じ。同じファイルに書くこともできるが別に分けた方が見やすい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;vpc_name&amp;quot; {
    description = &amp;quot;vpc&#39;s name, e.g. main-vpc&amp;quot;
}

variable &amp;quot;vpc_cidr_block&amp;quot; {
    description = &amp;quot;vpc&#39;s cidr block, e.g. 10.0.0.0/16&amp;quot;
}

variable &amp;quot;public_subnet_cidr_blocks&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;10.0.0.0/24\&amp;quot;, \&amp;quot;10.0.1.0/24\&amp;quot;]&amp;quot;
}

variable &amp;quot;public_subnet_availability_zones&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;ap-northeast-1a\&amp;quot;,\&amp;quot;ap-northeast-1c\&amp;quot;]&amp;quot;
}

variable &amp;quot;private_subnet_cidr_blocks&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;private subnets&#39; cidr blocks, e.g. [\&amp;quot;10.0.2.0/24\&amp;quot;, \&amp;quot;10.0.3.0/24\&amp;quot;]&amp;quot;
}

variable &amp;quot;private_subnet_availability_zones&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;ap-northeast-1a\&amp;quot;,\&amp;quot;ap-northeast-1c\&amp;quot;]&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/vpc.html&#34;&gt;VPC&lt;/a&gt;を作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_vpc&amp;quot; &amp;quot;vpc&amp;quot; {
    cidr_block = &amp;quot;${var.vpc_cidr_block}&amp;quot;
    enable_dns_hostnames = true
    tags {
        Name = &amp;quot;${var.vpc_name}&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にVPCにpublicとprivate用の&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/subnet.html&#34;&gt;サブネット&lt;/a&gt;を、
それぞれcidr_block分作成する。&lt;/p&gt;

&lt;p&gt;vpc_idでvpcのresourceを参照している。したがって、これを実行するためには既にvpcが作られている必要がある。
&lt;code&gt;depends_on&lt;/code&gt;で明示的に依存関係を示すこともできるのだけど、
大抵はそうする必要がなくて&lt;a href=&#34;https://www.terraform.io/intro/getting-started/dependencies.html#implicit-and-explicit-dependencies&#34;&gt;暗黙的な依存関係&lt;/a&gt;をterraformが解決してくれる。
これは&lt;a href=&#34;https://www.terraform.io/docs/commands/graph.html&#34;&gt;terraform graph&lt;/a&gt;で確認できる。&lt;/p&gt;

&lt;p&gt;AZで使われている&lt;a href=&#34;https://www.terraform.io/docs/configuration/interpolation.html#element-list-index-&#34;&gt;element(list, index)&lt;/a&gt;
は要素数以上のindexを渡してもmodの要領で選ぶので数を合わせなくてもよい。&lt;/p&gt;

&lt;p&gt;複数作ったものは&lt;code&gt;aws_subnet.public-subnet.0&lt;/code&gt;のように0から始まるindexで&lt;a href=&#34;https://www.terraform.io/docs/configuration/interpolation.html#attributes-of-other-resources&#34;&gt;参照でき&lt;/a&gt;、
&lt;code&gt;aws_subnet.public-subnet.*.id&lt;/code&gt;のようにすると要素のリストを得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-subnet&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    count = &amp;quot;${length(var.public_subnet_cidr_blocks)}&amp;quot;
    cidr_block = &amp;quot;${var.public_subnet_cidr_blocks[count.index]}&amp;quot;
    availability_zone = &amp;quot;${element(var.public_subnet_availability_zones, count.index)}&amp;quot;
    map_public_ip_on_launch = true
    tags {
        Name = &amp;quot;${var.vpc_name}-public-${element(var.public_subnet_availability_zones, count.index)}&amp;quot;
    }
}

resource &amp;quot;aws_subnet&amp;quot; &amp;quot;private-subnet&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    count = &amp;quot;${length(var.private_subnet_cidr_blocks)}&amp;quot;
    cidr_block = &amp;quot;${var.private_subnet_cidr_blocks[count.index]}&amp;quot;
    availability_zone = &amp;quot;${element(var.private_subnet_availability_zones, count.index)}&amp;quot;
    tags {
        Name = &amp;quot;${var.vpc_name}-private-${element(var.private_subnet_availability_zones, count.index)}&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;public用のサブネットが外と通信できるように&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/internet_gateway.html&#34;&gt;インターネットゲートウェイ&lt;/a&gt;をVPCにアタッチし、
これを登録した&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/route_table.html&#34;&gt;カスタムルートテーブル&lt;/a&gt;
をサブネットに&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/route_table_association.html&#34;&gt;関連付ける&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_internet_gateway&amp;quot; &amp;quot;igw&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    tags {
        Name = &amp;quot;${var.vpc_name}-igw&amp;quot;
    }
}

resource &amp;quot;aws_route_table&amp;quot; &amp;quot;public-route-table&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    route {
        cidr_block = &amp;quot;0.0.0.0/0&amp;quot;
        gateway_id = &amp;quot;${aws_internet_gateway.igw.id}&amp;quot;
    }
    tags {
        Name = &amp;quot;${var.vpc_name}-public-route-table&amp;quot;
    }
}

resource &amp;quot;aws_route_table_association&amp;quot; &amp;quot;route-table-association&amp;quot; {
    count          = &amp;quot;${length(var.public_subnet_cidr_blocks)}&amp;quot;
    subnet_id      = &amp;quot;${element(aws_subnet.public-subnet.*.id, count.index)}&amp;quot;
    route_table_id = &amp;quot;${aws_route_table.public-route-table.id}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;privateのサブネットからはNATして外に出られるようにする。
publicなサブネットにNATする&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-comparison.html&#34;&gt;インスタンス&lt;/a&gt;を立ててもいいけど、&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html&#34;&gt;NATゲートウェイ&lt;/a&gt;を使うと自分でメンテする必要がなくて楽。
&lt;a href=&#34;https://aws.amazon.com/jp/vpc/pricing/&#34;&gt;料金&lt;/a&gt;は時間と通信量による。&lt;/p&gt;

&lt;p&gt;ということで、&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/eip.html&#34;&gt;EIP&lt;/a&gt;を割り当て、
適当なpublicのサブネットに&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/nat_gateway.html&#34;&gt;NATゲートウェイ&lt;/a&gt;を作成する。
ドキュメントに書いてある通り、明示的にigwを依存に入れている。&lt;/p&gt;

&lt;p&gt;NATゲートウェイを&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/main_route_table_assoc.html&#34;&gt;メインルートテーブル&lt;/a&gt;に登録する。
これは&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html#nat-gateway-basics&#34;&gt;AWSのドキュメント&lt;/a&gt;に書いてある通りの構成で、
明示的にルートテーブルと関連付けていないサブネットは
メインルートテーブルに
&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#RouteTables&#34;&gt;関連付けられる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_eip&amp;quot; &amp;quot;nat&amp;quot; {
    vpc = true
}

resource &amp;quot;aws_nat_gateway&amp;quot; &amp;quot;ngw&amp;quot; {
    allocation_id = &amp;quot;${aws_eip.nat.id}&amp;quot;
    subnet_id     = &amp;quot;${aws_subnet.public-subnet.0.id}&amp;quot;
    depends_on = [&amp;quot;aws_internet_gateway.igw&amp;quot;]
}

resource &amp;quot;aws_route_table&amp;quot; &amp;quot;main-route-table&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    route {
        cidr_block = &amp;quot;0.0.0.0/0&amp;quot;
        nat_gateway_id = &amp;quot;${aws_nat_gateway.ngw.id}&amp;quot;
    }
    tags {
        Name = &amp;quot;${var.vpc_name}-main-route-table&amp;quot;
    }
}

resource &amp;quot;aws_main_route_table_association&amp;quot; &amp;quot;main-route-table-association&amp;quot; {
  vpc_id         = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
  route_table_id = &amp;quot;${aws_route_table.main-route-table.id}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行&#34;&gt;実行&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;terraform&amp;quot;
    key    = &amp;quot;terraform.tfstate&amp;quot;
    region = &amp;quot;ap-northeast-1&amp;quot;
  }
}

provider &amp;quot;aws&amp;quot; {
  region = &amp;quot;ap-northeast-1&amp;quot;
}

module &amp;quot;test-vpc&amp;quot; {
  source                            = &amp;quot;./vpc&amp;quot;
  vpc_name                          = &amp;quot;test-vpc&amp;quot;
  vpc_cidr_block                    = &amp;quot;10.0.0.0/16&amp;quot;
  public_subnet_cidr_blocks         = [&amp;quot;10.0.0.0/24&amp;quot;, &amp;quot;10.0.1.0/24&amp;quot;]
  public_subnet_availability_zones  = [&amp;quot;ap-northeast-1a&amp;quot;, &amp;quot;ap-northeast-1c&amp;quot;]
  private_subnet_cidr_blocks        = [&amp;quot;10.0.2.0/24&amp;quot;, &amp;quot;10.0.3.0/24&amp;quot;]
  private_subnet_availability_zones = [&amp;quot;ap-northeast-1a&amp;quot;, &amp;quot;ap-northeast-1c&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;planして問題なければapplyする流れ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform init
$ terraform get
$ terraform plan
+ module.test-vpc.aws_eip.nat
    allocation_id:     &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    association_id:    &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    domain:            &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    instance:          &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface: &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    private_ip:        &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    public_ip:         &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    vpc:               &amp;quot;true&amp;quot;

+ module.test-vpc.aws_internet_gateway.igw
    tags.%:    &amp;quot;1&amp;quot;
    tags.Name: &amp;quot;test-vpc-igw&amp;quot;
    vpc_id:    &amp;quot;${aws_vpc.vpc.id}&amp;quot;

...
Plan: 13 to add, 0 to change, 0 to destroy.

$ terraform apply
...
Apply complete! Resources: 13 added, 0 changed, 0 destroyed.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;applyするとresourceが作成・更新され、tfstateファイルがbackendまたはローカルに出力される。
次回以降はこのtfstateとの差分を取って変更されるので、このファイルがないとまた同じものが作成されてしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;version&amp;quot;: 3,
    &amp;quot;terraform_version&amp;quot;: &amp;quot;0.9.11&amp;quot;,
    &amp;quot;serial&amp;quot;: 1,
    &amp;quot;lineage&amp;quot;: &amp;quot;f97ad997-5a19-4a3d-9921-b553c5f2532b&amp;quot;,
    &amp;quot;modules&amp;quot;: [
        {
            &amp;quot;path&amp;quot;: [
                &amp;quot;root&amp;quot;
            ],
            &amp;quot;outputs&amp;quot;: {},
            &amp;quot;resources&amp;quot;: {},
            &amp;quot;depends_on&amp;quot;: []
        },
        {
            &amp;quot;path&amp;quot;: [
                &amp;quot;root&amp;quot;,
                &amp;quot;test-vpc&amp;quot;
            ],
            &amp;quot;outputs&amp;quot;: {},
            &amp;quot;resources&amp;quot;: {
                &amp;quot;aws_eip.nat&amp;quot;: {
                    &amp;quot;type&amp;quot;: &amp;quot;aws_eip&amp;quot;,
                    &amp;quot;depends_on&amp;quot;: [],
                    &amp;quot;primary&amp;quot;: {
                        &amp;quot;id&amp;quot;: &amp;quot;eipalloc-3046f054&amp;quot;,
                        &amp;quot;attributes&amp;quot;: {
                            &amp;quot;association_id&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;domain&amp;quot;: &amp;quot;vpc&amp;quot;,
                            &amp;quot;id&amp;quot;: &amp;quot;eipalloc-3046f054&amp;quot;,
                            &amp;quot;instance&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;network_interface&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;private_ip&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;public_ip&amp;quot;: &amp;quot;13.114.59.186&amp;quot;,
                            &amp;quot;vpc&amp;quot;: &amp;quot;true&amp;quot;
                        },
                        &amp;quot;meta&amp;quot;: {},
                        &amp;quot;tainted&amp;quot;: false
                    },
                    &amp;quot;deposed&amp;quot;: [],
                    &amp;quot;provider&amp;quot;: &amp;quot;&amp;quot;
                },
                &amp;quot;aws_internet_gateway.igw&amp;quot;: {
                    &amp;quot;type&amp;quot;: &amp;quot;aws_internet_gateway&amp;quot;,
                    &amp;quot;depends_on&amp;quot;: [
                        &amp;quot;aws_vpc.vpc&amp;quot;
                    ],
                    &amp;quot;primary&amp;quot;: {
                        &amp;quot;id&amp;quot;: &amp;quot;igw-d2659bb6&amp;quot;,
                        &amp;quot;attributes&amp;quot;: {
                            &amp;quot;id&amp;quot;: &amp;quot;igw-d2659bb6&amp;quot;,
                            &amp;quot;tags.%&amp;quot;: &amp;quot;1&amp;quot;,
                            &amp;quot;tags.Name&amp;quot;: &amp;quot;test-vpc-igw&amp;quot;,
                            &amp;quot;vpc_id&amp;quot;: &amp;quot;vpc-3cf6a358&amp;quot;
                        },
                        &amp;quot;meta&amp;quot;: {},
                        &amp;quot;tainted&amp;quot;: false
                    },
                    &amp;quot;deposed&amp;quot;: [],
                    &amp;quot;provider&amp;quot;: &amp;quot;&amp;quot;
                },
                ...
            },
            &amp;quot;depends_on&amp;quot;: []
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;planすると変更なしになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan
...
No changes. Infrastructure is up-to-date.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;terafform destroy&lt;/code&gt;で管理下のresourceを消すことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan -destroy
...
Plan: 0 to add, 0 to change, 13 to destroy.

$ terraform destroy
...
Destroy complete! Resources: 13 destroyed.

$ terraform plan
...
Plan: 13 to add, 0 to change, 0 to destroy.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/CkReal/items/1dbbc78888e157a80668&#34;&gt;お金をかけずに、TerraformでAWSのVPC環境を準備する - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensでのUnityアプリケーションのフレームレート</title>
          <link>https://www.sambaiz.net/article/120/</link>
          <pubDate>Sun, 16 Jul 2017 23:32:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/120/</guid>
          <description>

&lt;h2 id=&#34;hololensディスプレイのフレームレート-https-developer-microsoft-com-en-us-windows-mixed-reality-hologram-stability-frame-rate&#34;&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/mixed-reality/hologram_stability#frame_rate&#34;&gt;HoloLensディスプレイのフレームレート&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;HoloLensのディスプレイは60fpsでリフレッシュされるので、アプリケーションもこれに合わせて60fps、
つまり16msごとにOSにイメージを渡せるのがベスト。
ただし、安定して60fpsが実現できないような重いアプリケーションの場合、
変動してしまうよりは下げて安定させる方が良い。&lt;/p&gt;

&lt;p&gt;フレームレートはDevice Portalから確認することができ、キャプチャする際は30fpsに制限される。&lt;/p&gt;

&lt;h2 id=&#34;unityアプリケーションのフレームレート&#34;&gt;Unityアプリケーションのフレームレート&lt;/h2&gt;

&lt;p&gt;Unityでのフレームレートは
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Application-targetFrameRate.html&#34;&gt;Application.targetFrameRate&lt;/a&gt;
で設定できる。デフォルト値は-1で、その場合プラットフォームごとのデフォルト設定が使われる。
何も設定しない状態でHoloLensで動かしたところ60fpsになった。&lt;/p&gt;

&lt;h2 id=&#34;debugビルドでのフレームレートの低下&#34;&gt;Debugビルドでのフレームレートの低下&lt;/h2&gt;

&lt;p&gt;Debugビルドだと&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/4696&#34;&gt;Space Robot Kyle&lt;/a&gt;
だけ描画するだけでもフレームレートが20まで下がってしまった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/119/&#34;&gt;HoloLensで剣振ってみた - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/120-frame.png&#34; alt=&#34;フレームレートの低下&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DebugビルドだったのをRelasseビルドに変えたら60fpsになった。
Relaseビルドではコードの最適化にチェックが入っていたりするんだけど、
その辺りを外してみても特に変わらなかったのでそれではないらしい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensで剣振ってみた</title>
          <link>https://www.sambaiz.net/article/119/</link>
          <pubDate>Sun, 09 Jul 2017 23:55:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/119/</guid>
          <description>&lt;p&gt;かつてCardboardでやったようにHoloLensでも剣を振ってみた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/29/&#34;&gt;剣を振るVRゲームを作った - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/119-ss.png&#34; alt=&#34;スクリーンショット&#34; /&gt;&lt;/p&gt;

&lt;p&gt;剣を振ってロボットに当てると爆発する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_gt6ePsqrRc&#34;&gt;動画&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;剣の方は前回と同じくiOSアプリから傾きをBLEで送信している。今回は傘がなかったのでペットボトルにくくりつけた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/119-sword.jpg&#34; alt=&#34;ミニッツメイドソード&#34; /&gt;&lt;/p&gt;

&lt;p&gt;HoloLensのアプリの方はUWPのネイティブプラグインを作った。
Creater&amp;rsquo;s UpdateのAPIがまだ使えなかったので一つ前のAPIを使ってビルドしている。
なお、ペアリングはアプリ内ではなくOSの設定画面から行なっている。
エラーについては原因が分からずハンドリングできていないものもあるけど、つなぎ直すと大抵どうにかなった。
つなぎ直す際はHoloLens側だけではなくiOS側の方の設定も削除する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/105/&#34;&gt;Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ロボットを小さくしているのは近づいても視野角に収まるようにするため。
小さいとどこにいるか分からないので目印を出したほうが良い。
近接武器じゃなきゃ敵に近づかなくてよくなるのでましになるかも。&lt;/p&gt;

&lt;p&gt;上の動画を見れば分かるように、全体的に動きが重くて素でframerateが20ぐらいしか出ていない。
これはReleaseビルドにすると改善された。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/120/&#34;&gt;HoloLensでのUnityアプリケーションのフレームレート - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensのSpartial MappingでNavMeshを生成してランダムにAgentを出現・移動させる</title>
          <link>https://www.sambaiz.net/article/118/</link>
          <pubDate>Sun, 02 Jul 2017 23:12:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/118/</guid>
          <description>&lt;pre&gt;&lt;code&gt;Unity 5.6.2f1
HoloToolkit v1.5.7.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unity 5.6から動的にNavMeshを生成できるようになったので
HoloLensのSpartial MappingしたものをNavMeshにしてAgentを動かしてみる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/117/&#34;&gt;Unityで動的にNavMeshを生成する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Spartial MappingしたものをNavMeshにするのは以下の記事の&lt;a href=&#34;https://gist.github.com/tarukosu/7bc78c189d8a7de8e94ca3fcfc8f7738#file-spatialmappingnavmesh-cs&#34;&gt;スクリプト&lt;/a&gt;を使った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tarukosu.hatenablog.com/entry/2017/04/23/183546&#34;&gt;HoloLens の空間マップで NavMesh を使ってみる - たるこすの日記&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents&#34;&gt;Unity-Technologies/NavMeshComponents&lt;/a&gt;から
&lt;code&gt;LocalNavMeshBuilder&lt;/code&gt;と&lt;code&gt;NavMeshSourceTag&lt;/code&gt;を持ってきてLocalNavMeshBuilderのObjectを置いておき、
Spartial MappingしたものにNavMeshSourceTagを付けられればExampleと同様にNavMeshにできる。
そこで、このスクリプトではSpatialMappingSourceを取得し、イベントハンドラでNavMeshSourceTagが追加されるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using HoloToolkit.Unity.SpatialMapping;
using UnityEngine;
using HoloToolkit.Unity;

public class SpatialMappingNavMesh : MonoBehaviour
{
    public GameObject SpatialMapping;

    private void Awake()
    {
        var spatialMappingSources = SpatialMapping.GetComponents&amp;lt;SpatialMappingSource&amp;gt;();
        foreach (var source in spatialMappingSources)
        {
            source.SurfaceAdded += SpatialMappingSource_SurfaceAdded;
            source.SurfaceUpdated += SpatialMappingSource_SurfaceUpdated;
        }
    }

    private void SpatialMappingSource_SurfaceAdded(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceObject&amp;gt; e)
    {
        e.Data.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;();
    }

    private void SpatialMappingSource_SurfaceUpdated(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceUpdate&amp;gt; e)
    {
        var navMeshSourceTag = e.Data.New.Object.GetComponent&amp;lt;NavMeshSourceTag&amp;gt;();
        if (navMeshSourceTag == null)
        {
            e.Data.New.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NavMeshのランダムな場所を取得するには、適当なPointを取り、
&lt;a href=&#34;https://docs.unity3d.com/ja/540/ScriptReference/NavMesh.SamplePosition.html&#34;&gt;NavMesh.SamplePosition&lt;/a&gt;で
そこから最も近いNavMeshのPointを取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bool RandomPoint(Vector3 center, float range, out Vector3 result) {
    for (int i = 0; i &amp;lt; 30; i++) {
        Vector3 randomPoint = center + Random.insideUnitSphere * range;
        NavMeshHit hit;
        if (NavMesh.SamplePosition(randomPoint, out hit, 1.0f, NavMesh.AllAreas)) {
            result = hit.position;
            return true;
        }
    }
    result = Vector3.zero;
    return false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;動かすAgentはこんな感じ。こけないようにFreeze Rotationしている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/118.png&#34; alt=&#34;Agentの設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このAgentを出現させて移動させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using UnityEngine;
using UnityEngine.AI;

public class RandomSpawn : MonoBehaviour {

    public GameObject player;
    public GameObject agent;
    public GameObject counter;

    private List&amp;lt;GameObject&amp;gt; spawnedAgents = new List&amp;lt;GameObject&amp;gt;();
    private float interval = 0.0f;

    static int MAX_SPAWN_NUM = 10;
    static float SPAWN_RANGE = 10.0f;

	// Use this for initialization
	void Start () {
        counter.GetComponent&amp;lt;TextMesh&amp;gt;().text = spawnedAgents.Count + &amp;quot;&amp;quot;;
    }

    // Update is called once per frame
    void Update () {

        interval += Time.deltaTime;
        if(interval &amp;gt; 5.0f)
        {
            if (spawnedAgents.Count &amp;lt; MAX_SPAWN_NUM)
            {
                Spawn();
            }
            Move();
            interval = 0.0f;
        }
    }

    void Spawn()
    {
        Vector3 spawnPoint;
        if (GetRandomPosition(player.transform.position, SPAWN_RANGE, out spawnPoint))
        {
            var obj = Instantiate(agent, spawnPoint, Quaternion.identity);
            counter.GetComponent&amp;lt;TextMesh&amp;gt;().text = spawnedAgents.Count + &amp;quot;&amp;quot;;
            spawnedAgents.Add(obj);
        }
    }

    void Move()
    {
        foreach(var agent in spawnedAgents)
        {
            Vector3 next;
            if(GetRandomPosition(agent.transform.position, SPAWN_RANGE, out next)){
                agent.GetComponent&amp;lt;NavMeshAgent&amp;gt;().destination = next;
            }
        }
        
    }

    bool GetRandomPosition(Vector3 center, float range, out Vector3 result)
    {
        for (int i = 0; i &amp;lt; 30; i++)
        {
            Vector3 randomPoint = center + UnityEngine.Random.insideUnitSphere * range;
            NavMeshHit hit;
            if (NavMesh.SamplePosition(randomPoint, out hit, 1.0f, NavMesh.AllAreas))
            {
                result = hit.position;
                return true;
            }
        }
        result = Vector3.zero;
        return false;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと床や壁を認識して移動している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/118.gif&#34; alt=&#34;移動するAgent&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityで動的にNavMeshを生成する</title>
          <link>https://www.sambaiz.net/article/117/</link>
          <pubDate>Sat, 01 Jul 2017 23:50:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/117/</guid>
          <description>&lt;p&gt;Unity5.6から動的にNavMeshを生成できるようになった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents&#34;&gt;Unity-Technologies/NavMeshComponents&lt;/a&gt;の
Exampleの2_drop_blankのsceneを開く。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample.png&#34; alt=&#34;Exampleの2_drop_blank&#34; /&gt;&lt;/p&gt;

&lt;p&gt;分断されたCubeの床と、その上に黄色いCylindarと赤いCubeがあって、
クリックしたところに黄色いCylindarが動くんだけど、床がつながっていないのでそのままでは赤いCubeまではたどり着けない。
スペースを押すと目の前に板が出てくるのでこの上を渡って移動することができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample2.png&#34; alt=&#34;スペースを押すと板が出てくる&#34; /&gt;&lt;/p&gt;

&lt;p&gt;板の上がNavMeshとして認識されている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample3.png&#34; alt=&#34;スペースを押すと板が出てくる&#34; /&gt;&lt;/p&gt;

&lt;p&gt;床のCubeと追加される板には&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents/blob/5.6.0b4/Assets/Examples/Scripts/NavMeshSourceTag.cs&#34;&gt;NavMeshSourceTag.cs&lt;/a&gt;が付いていて、staticな&lt;code&gt;m_Meshes&lt;/code&gt;と&lt;code&gt;m_Terrains&lt;/code&gt;にそれぞれ追加している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static List&amp;lt;MeshFilter&amp;gt; m_Meshes = new List&amp;lt;MeshFilter&amp;gt;();
public static List&amp;lt;Terrain&amp;gt; m_Terrains = new List&amp;lt;Terrain&amp;gt;();

void OnEnable()
{
    var m = GetComponent&amp;lt;MeshFilter&amp;gt;();
    if (m != null)
    {
        m_Meshes.Add(m);
    }

    var t = GetComponent&amp;lt;Terrain&amp;gt;();
    if (t != null)
    {
        m_Terrains.Add(t);
    }
}

void OnDisable()
{
    var m = GetComponent&amp;lt;MeshFilter&amp;gt;();
    if (m != null)
    {
        m_Meshes.Remove(m);
    }

    var t = GetComponent&amp;lt;Terrain&amp;gt;();
    if (t != null)
    {
        m_Terrains.Remove(t);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらはCollectメソッドでNavMeshBuildSourceのリストを生成するのに使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void Collect(ref List&amp;lt;NavMeshBuildSource&amp;gt; sources)
{
    sources.Clear();

    for (var i = 0; i &amp;lt; m_Meshes.Count; ++i)
    {
        var mf = m_Meshes[i];
        if (mf == null) continue;

        var m = mf.sharedMesh;
        if (m == null) continue;

        var s = new NavMeshBuildSource();
        s.shape = NavMeshBuildSourceShape.Mesh;
        s.sourceObject = m;
        s.transform = mf.transform.localToWorldMatrix;
        s.area = 0;
        sources.Add(s);
    }

    for (var i = 0; i &amp;lt; m_Terrains.Count; ++i)
    {
       ...
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents/blob/5.6.0b4/Assets/Examples/Scripts/LocalNavMeshBuilder.cs&#34;&gt;LocalNavMeshBuilder.cs&lt;/a&gt;から呼び、&lt;a href=&#34;https://docs.unity3d.com/ScriptReference/AI.NavMeshBuilder.UpdateNavMeshData.html&#34;&gt;NavMeshBuilder.UpdateNavMeshData&lt;/a&gt;に渡してNavMeshDataを更新している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NavMeshData m_NavMesh;
AsyncOperation m_Operation;
NavMeshDataInstance m_Instance;
List&amp;lt;NavMeshBuildSource&amp;gt; m_Sources = new List&amp;lt;NavMeshBuildSource&amp;gt;();

IEnumerator Start()
{
    while (true)
    {
        UpdateNavMesh(true);
        yield return m_Operation;
    }
}

void UpdateNavMesh(bool asyncUpdate = false)
{
    NavMeshSourceTag.Collect(ref m_Sources);
    var defaultBuildSettings = NavMesh.GetSettingsByID(0);
    var bounds = QuantizedBounds();

    if (asyncUpdate)
        m_Operation = NavMeshBuilder.UpdateNavMeshDataAsync(m_NavMesh, defaultBuildSettings, m_Sources, bounds);
    else
        NavMeshBuilder.UpdateNavMeshData(m_NavMesh, defaultBuildSettings, m_Sources, bounds);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Fluentdのout_copyのstoreのエラーは他のstoreに影響する</title>
          <link>https://www.sambaiz.net/article/116/</link>
          <pubDate>Sat, 01 Jul 2017 18:53:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/116/</guid>
          <description>&lt;p&gt;Fluentdの&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/out_copy&#34;&gt;out_copy&lt;/a&gt;プラグインは
一つのeventを複数のoutputに渡すために使われる。
ただ、複数設定した中のstoreでエラーが起きると他のstoreにも影響してしまう。&lt;/p&gt;

&lt;p&gt;例えばこんなの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fileの方で&lt;code&gt;queue size exceeds limit&lt;/code&gt;になるとstdoutも出力されなくなってしまう。&lt;/p&gt;

&lt;p&gt;ちなみに一旦relabelしてもだめ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store&amp;gt;
    @type relabel
    @label @file
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;label @file&amp;gt;
  &amp;lt;match dummy&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/match&amp;gt;
&amp;lt;/label&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ドキュメントでも紹介されている、sonots氏の&lt;a href=&#34;https://github.com/sonots/fluent-plugin-copy_ex&#34;&gt;out_copy_ex&lt;/a&gt;では
storeにignore_errorを付けるとrescueするようになっているので他に巻き込まれなくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-copy_ex
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy_ex

  &amp;lt;store ignore_error&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store ignore_error&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;dummy: {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
[error]:  error_class=Fluent::BufferQueueLimitError error=&amp;quot;queue size exceeds limit&amp;quot;
dummy: {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
[error]:  error_class=Fluent::BufferQueueLimitError error=&amp;quot;queue size exceeds limit&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityの経路探索: NavMeshとAgentとObstacle</title>
          <link>https://www.sambaiz.net/article/115/</link>
          <pubDate>Thu, 29 Jun 2017 00:17:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/115/</guid>
          <description>

&lt;h2 id=&#34;navmeshと経路探索-https-docs-unity3d-com-jp-540-manual-nav-innerworkings-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-InnerWorkings.html&#34;&gt;NavMeshと経路探索&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;NavMeshというのはエージェントが移動できる面についてのデータ構造で、凸ポリゴンの面と位置関係を含んでいる。
経路探索は2点間を一番近いポリゴンにマッピングし、&lt;a href=&#34;https://ja.wikipedia.org/wiki/A*&#34;&gt;A*アルゴリズム&lt;/a&gt;を用いて行われる。あとからオブジェクトが追加されるなどして道を塞いでしまってもCarvingしてNavMeshに穴をあければ別の経路で移動することができるが、このようなグローバルの経路探索に影響を及ぼす操作は計算にコストがかかるので、各エージェントローカルの衝突回避で済むならそのほうがよい。&lt;/p&gt;

&lt;h2 id=&#34;navmeshをbakeする-https-docs-unity3d-com-jp-540-manual-nav-buildingnavmesh-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-BuildingNavMesh.html&#34;&gt;NavMeshをbakeする&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;こんな感じで床に適当なオブジェクトを置いてみた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-stage.png&#34; alt=&#34;stage&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-stageh.png&#34; alt=&#34;階層&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Window -&amp;gt; Navigation&lt;/code&gt;でBakeするのを選択してNavigation Staticし(StaticになってBakeの対象になる)、
Bakeボタンを押すとこんな感じでBakeされる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-bake.png&#34; alt=&#34;bake&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトの上がNavMeshに含まれていないのはAgent sizeのStep Heightよりも高いため。
段差を移動するときに浮いてしまうのを避けるためにはAdvancedの&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-HeightMesh.html&#34;&gt;Height Mesh&lt;/a&gt;をオンにする。
また、端が含まれていないのはこのAgentの中心が入れる位置を表しているためで、
Agent Radiusを変更すると広がったり狭まったりするのを確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-agentsize.png&#34; alt=&#34;Agent size&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;navmesh-agent-https-docs-unity3d-com-jp-540-manual-nav-createnavmeshagent-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-CreateNavMeshAgent.html&#34;&gt;NavMesh Agent&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Radius0.5, Height2のCylindarを作成し、Nav Mesh Agentを追加する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-navmesh-agent.png&#34; alt=&#34;NavMesh Agent&#34; /&gt;&lt;/p&gt;

&lt;p&gt;で、ゴールにオブジェクトを置いてそこまで移動させてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine.AI;

public GameObject goal;

void Start () {
    var agent = GetComponent&amp;lt;NavMeshAgent&amp;gt;();
    agent.destination = goal.transform.position;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move.gif&#34; alt=&#34;ゴールまでたどり着くNavMesh Agent&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;navmesh-obstacle&#34;&gt;NavMesh Obstacle&lt;/h2&gt;

&lt;p&gt;障害物。上で通った経路上にNavMesh Obstacleを追加したCubeを置いたところうまく避けてゴールまでたどり着いた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move2.gif&#34; alt=&#34;Obstacleを置いた&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただ、完全に道をふさいでしまうと立ち往生してしまうので
Carveにチェックを入れるとCarvingされ、他の経路でゴールまで進むようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move3.gif&#34; alt=&#34;Carvingした&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/117/&#34;&gt;Unityで動的にNavMeshを生成する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityの物理エンジン・衝突: RigidbodyとCollidarとJoint</title>
          <link>https://www.sambaiz.net/article/114/</link>
          <pubDate>Sun, 25 Jun 2017 23:26:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/114/</guid>
          <description>

&lt;h2 id=&#34;rigidbody-https-docs-unity3d-com-ja-current-manual-rigidbodiesoverview-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/RigidbodiesOverview.html&#34;&gt;Rigidbody&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GameObjectを物理特性によって制御し、力の影響を受けるようにする。
&lt;code&gt;Mass(質量)&lt;/code&gt;や&lt;code&gt;Drag(空気抵抗)&lt;/code&gt;、&lt;code&gt;Use Gravity&lt;/code&gt;などのプロパティがある。&lt;/p&gt;

&lt;p&gt;移動させるのに自分でTransformは変更せず力をかけて物理演算に任せる。
&lt;code&gt;Is Kinematic&lt;/code&gt;にチェックを入れると物理エンジンによって移動しないようになるので、
Transformを直接変更する場合は有効にする。
ただし、スクリプトで動的にIs Kinematicを切り替えるのはパフォーマンスが良くない。&lt;/p&gt;

&lt;h2 id=&#34;collidar-https-docs-unity3d-com-ja-current-manual-collidersoverview-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/CollidersOverview.html&#34;&gt;Collidar&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;RigidBodyの物理特性の境界を定義する。衝突させるには両方にCollidarが設定されている必要がある。
RigidBodyなしのCollidarを静的Collidarといって、無効にしたり移動しないことを前提に最適化される。
移動したりするものについてはRigidBodyを付けて、必要ならIs Kinematicを有効にする。&lt;/p&gt;

&lt;p&gt;衝突時には&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionEnter.html&#34;&gt;OnCollisionEnter()&lt;/a&gt;
が呼ばれる。ほかに離れたときの&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionExit.html&#34;&gt;OnCollisionExit()&lt;/a&gt;、
触れている間、毎フレーム呼ばれる&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionStay.html&#34;&gt;OnCollisionStay()&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void OnCollisionEnter(Collision collision)
{
    foreach (ContactPoint contact in collision.contacts)
    {
        if (contact.otherCollider.tag == &amp;quot;Player&amp;quot;)
        {
            Debug.Log(collision.relativeVelocity.magnitude);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Is Trigger&lt;/code&gt;にチェックを入れると物理エンジンには無視されてすり抜け、侵入に対してトリガーイベントが呼ばれる。
OnCollistionと同様に
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerEnter.html&#34;&gt;OnTriggerEnter()&lt;/a&gt;、
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerExit.html&#34;&gt;OnTriggerExit()&lt;/a&gt;、
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerStay.html&#34;&gt;OnTriggerStay()&lt;/a&gt;
がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void OnTriggerEnter(Collider other)
{
    Debug.Log(other.tag);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;joint-https-docs-unity3d-com-ja-current-manual-joints-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/Joints.html&#34;&gt;Joint&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Rigitbodyを他のRigitbodyとつなげるもの。
例えばSprint Jointだとオブジェクト間がばねのように伸縮する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/114-joint.png&#34; alt=&#34;Spring Joint&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする</title>
          <link>https://www.sambaiz.net/article/113/</link>
          <pubDate>Sun, 25 Jun 2017 00:35:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/113/</guid>
          <description>

&lt;p&gt;デプロイやスループットの調整を簡単にするため、BeanstalkでAggregatorを立ち上げた。&lt;/p&gt;

&lt;h2 id=&#34;負荷分散&#34;&gt;負荷分散&lt;/h2&gt;

&lt;p&gt;TCPの24224(設定による)が通るようにEC2,ELBのSGとリスナーの設定をする必要があって、
ELBのSGのアウトバウンドの設定が見落とされがち。ELBのクロスゾーン分散は有効になっている。&lt;/p&gt;

&lt;p&gt;まず、ELBに3台、それぞれ別のAZ(1b, 1c, 1d)に配置されている状態でログを送り始めるとそれぞれ均等にログが届いた。
その状態から4台(1b * 2, 1c, 1d)にすると、2つのインスタンス(1b, 1c)のみに均等にログが届くようになった。
4台になると(1b, 1c)と(1b, 1d)に分けられてELBのノードがそれらの組に紐づいたということだと思う。
各ノードにはDNSラウンドロビンするようになっている。実際restartすると今度は別の組の方に送られた。&lt;/p&gt;

&lt;p&gt;では、なぜ一度送り始めると同じ方にしか飛ばないかというと、forwardプラグインの&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/out_forward#expirednscache&#34;&gt;expire_dns_cache&lt;/a&gt;がデフォルトでnilになっていて、
heartbeatが届いている間は&lt;a href=&#34;https://github.com/fluent/fluentd/blob/v0.14.18/lib/fluent/plugin/out_forward.rb#L688&#34;&gt;無期限にDNSキャッシュする&lt;/a&gt;ようになっているため。これに0(キャッシュしない)か秒数を指定すると、
その間隔で他の組のインスタンスにもログが届くようになった。
&lt;code&gt;expire_dns_cache&lt;/code&gt;しなくても複数のインスタンスからラウンドロビンされるため全体でいえば分散される。&lt;/p&gt;

&lt;h2 id=&#34;heartbeat&#34;&gt;heartbeat&lt;/h2&gt;

&lt;p&gt;ELB配下のEC2を全て落としても&lt;a href=&#34;https://github.com/fluent/fluentd/blob/v0.14.18/lib/fluent/plugin/out_forward.rb#L665&#34;&gt;heartbeat&lt;/a&gt;に失敗しないため、standyに移行せずELBのバックエンド接続エラーになってログがロストしてしまうようだ。
ログにも出ず、以下のようにactive-standbyの設定をしてもstandbyに移行しない。
全てのインスタンスが同時に落ちるというのは滅多に起きないだろうけど、少なくとも検知できるようにはしておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;server&amp;gt;
    name td1
    host autoscale-td1.us-east-1.elasticbeanstalk.com
    port 24224
&amp;lt;/server&amp;gt;
&amp;lt;server&amp;gt;
    name td2
    host autoscale-td2.us-east-1.elasticbeanstalk.com
    port 24224
    standby
&amp;lt;/server&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;blue-green-deployment&#34;&gt;Blue/Green Deployment&lt;/h2&gt;

&lt;p&gt;Blue-Green Deploymentというのは、2つの系を用意し、activeでない方にデプロイし、
スワップして反映させるもの。ダウンタイムなしで問題が起きた際にもすぐに切り戻すことができる。
スワップして向き先を変えるには&lt;code&gt;expire_dns_cache&lt;/code&gt;を設定する必要がある。&lt;/p&gt;

&lt;h2 id=&#34;auto-scaling&#34;&gt;Auto Scaling&lt;/h2&gt;

&lt;p&gt;増えるのはいいとして減るときに、
送り先で一時的に障害が起きていたりするとバッファをflushできずにログがロストする可能性がある。
それでいうとログの送り元でも同じことが起こりうるんだけど、通常Aggregatorにしか送らないので比較的問題になりにくい。&lt;/p&gt;

&lt;p&gt;これを避けたい場合、Auto Scalingグループの設定で
&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/autoscaling/latest/userguide/as-instance-termination.html#instance-protection&#34;&gt;スケールインから保護&lt;/a&gt;を有効にして
これから立ち上がるインスタンスはスケールインしなくすることができる。
それまでに立ち上がっていたインスタンスには適用されないので注意。&lt;/p&gt;

&lt;p&gt;スケールインしないということは最大の台数で止まってしまうので、
ピークを過ぎたらスワップしてバッファが全て掃けたことを確認してからTerminateすることになる。
これを日常的にやるのは面倒なので、実際は予期しない流量の増加に備えて一応設定しておき、
普段はしきい値にひっかからないような最低台数で待ち構えておくことにするかな。&lt;/p&gt;

&lt;p&gt;あとはヘルスチェックによって潰される可能性はなくもないけど、それはもうやむなし・・・。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/elb-configuration-guide-1&#34;&gt;AWS ELBの社内向け構成ガイドを公開してみる 負荷分散編 – Cross-Zone Routingを踏まえて ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのMecanimでヒューマノイドアニメーションさせる</title>
          <link>https://www.sambaiz.net/article/112/</link>
          <pubDate>Tue, 20 Jun 2017 23:58:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/112/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/4696&#34;&gt;Space Robot Kyle&lt;/a&gt;を動かす。&lt;/p&gt;

&lt;h2 id=&#34;アバターの作成&#34;&gt;アバターの作成&lt;/h2&gt;

&lt;p&gt;Assetsの&lt;code&gt;Model/Robot Kyle&lt;/code&gt;を選択し、RigのAnimation TypeをHumanoidにすると、
自動的にボーン構造を解析して人型にマッピングしたアバターが設定される。
Configure Avatarで確認すると正しく設定されているようだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-rig.png&#34; alt=&#34;アバター&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;モーションの設定&#34;&gt;モーションの設定&lt;/h2&gt;

&lt;p&gt;KyleのAnimatorのAnimationに設定するAnimation Controllerを作成する。
まずは2つCreate Stateし、それぞれMotionに適当なモーション(今回は&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/36286&#34;&gt;Fighter Pack Bundle FREE&lt;/a&gt;を使った)を設定し、
Make Transitionで相互に結ぶと、オレンジになっているデフォルトステートから交互にモーションする。
ステートには&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/StateMachineBehaviour.html&#34;&gt;StateMachineBehaviour&lt;/a&gt;のScriptを設定することもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-animation.png&#34; alt=&#34;モーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次にParametersでモーションを変化させる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-animation2.png&#34; alt=&#34;分岐したモーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Animatorの左上、parametersタブからBoolのWalkを追加する。
そして片方のTransitionのConditionにWalkがfalse、もう片方にはWalkがtrueを追加すると、
状態によって違うモーションをするようになる。
ちなみに、AnyStateからConditionを設定したTransitionを設定すると、どこのStateからでもそれで遷移させることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-parameters.png&#34; alt=&#34;パラメータ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このParameterはこんな感じに値を設定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Update () {
	GetComponent&amp;lt;Animator&amp;gt; ().SetBool (&amp;quot;Walk&amp;quot;, Random.value &amp;lt; 0.5);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;一部だけモーションさせる&#34;&gt;一部だけモーションさせる&lt;/h2&gt;

&lt;p&gt;人体の一部だけをモーションさせるにはAvatar Maskを使う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-avatar-mask.png&#34; alt=&#34;Avatar Mask&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-avatar-mask-motion.png&#34; alt=&#34;Avatar Maskしたモーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Animationで複数のレイヤーを作成すれば、異なるMaskでそれぞれステートを持たせることができる。&lt;/p&gt;

&lt;h2 id=&#34;animation-override-controller&#34;&gt;Animation Override Controller&lt;/h2&gt;

&lt;p&gt;作ったAnimationを違うモーションで再利用することができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-override.png&#34; alt=&#34;Animator Override Controller&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>NorikraでログをJOINする</title>
          <link>https://www.sambaiz.net/article/111/</link>
          <pubDate>Thu, 15 Jun 2017 00:17:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/111/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/109/&#34;&gt;NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;適当なログを出すコードを書いた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/lottery-log&#34;&gt;sambaiz/lottery-log&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。
広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// lottery.log
{&amp;quot;ts&amp;quot;:1497453504.6818597,&amp;quot;uid&amp;quot;:&amp;quot;b18c0d98-19b2-4e37-8fc4-6b00a4b728c3&amp;quot;,&amp;quot;prize&amp;quot;:855,&amp;quot;isWin&amp;quot;:true}
// received.log
{&amp;quot;ts&amp;quot;:1497453515.932101,&amp;quot;uid&amp;quot;:&amp;quot;bc4f578f-4a5f-47f1-a4e0-1ef0b43c316e&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリはこんな感じ。一つはlotteryログとreceivedログをuidでJOINするもので、
received_rateの計算にはサブクエリも使っている。
received_rateの計算で分母に小さな値を足しているのはNaNやInfinityにならないようにするため。
receivedログは最大30秒遅れて出力されるため、40秒前までのreceivedログをwin:timeで見ている。
これをtime_batchにしてしまうと期待通りの結果にならないので注意。&lt;/p&gt;

&lt;p&gt;もう一つはJavaの関数でboolを0/1にして平均をとることでisWinがtrueである割合を出している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec norikra norikra-client query add lottery_agg &#39;
SELECT COUNT(*) as received_count, (COUNT(*) / (SELECT COUNT(*) + 0.00001 FROM lottery.win:time_batch(1 sec, 0).std:unique(uid))) as received_rate, AVG(prize) as prize_avg, SUM(prize) as prize_sum FROM lottery.win:time(40 sec).std:unique(uid) as a, received.win:time_batch(1 sec, 0).std:unique(uid) as b WHERE a.uid = b.uid&#39;

$ docker exec norikra norikra-client query add lottery_win_rate &#39;SELECT avg(Boolean.compare(isWin, false)) as win_rate FROM lottery.win:time_batch(1 sec)&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、このクエリの結果をElasticsearchに送って可視化してみたのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type tail
  path /var/log/lottery.log
  pos_file /etc/td-agent/log.pos
  tag event.lottery
  format json
&amp;lt;/source&amp;gt;

&amp;lt;source&amp;gt;
  @type tail
  path /var/log/received.log
  pos_file /etc/td-agent/log.pos
  tag event.received
  format json
&amp;lt;/source&amp;gt;

&amp;lt;match event.*&amp;gt;
  @type   norikra
  norikra localhost:26571
  
  remove_tag_prefix event # event.*の部分が
  target_map_tag    yes   # targetになる

  &amp;lt;default&amp;gt;
    auto_field false 
  &amp;lt;/default&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;source&amp;gt;
  @type   norikra
  norikra localhost:26571
  &amp;lt;fetch&amp;gt;
    method   event
    target   lottery_agg
    tag      string data.lottery_agg
    interval 1m
  &amp;lt;/fetch&amp;gt;
  &amp;lt;fetch&amp;gt;
    method   event
    target   lottery_win_rate
    tag      string data.lottery_win_rate
    interval 1m
  &amp;lt;/fetch&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match data.lottery_agg&amp;gt;
  @type elasticsearch
  host 172.31.5.20
  port 9200
  logstash_prefix lottery
  type_name lottery_agg
  logstash_format true
&amp;lt;/match&amp;gt;

&amp;lt;match data.lottery_win_rate&amp;gt;
  @type elasticsearch
  host 172.31.5.20
  port 9200
  logstash_prefix lottery
  type_name lottery_win_rate
  logstash_format true
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;received_rateを計算するときのウィンドウが1secと小さく、タイミングによってはreceivedの数がlotteryの数を上回ることがあるため1以下で絞っている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/111v.png&#34; alt=&#34;可視化したもの&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>VSでのネイティブプラグインのビルドからUnityでのWSAのビルドまでをバッチでする</title>
          <link>https://www.sambaiz.net/article/110/</link>
          <pubDate>Tue, 13 Jun 2017 00:32:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/110/</guid>
          <description>

&lt;h2 id=&#34;vsでのネイティブプラグインのビルド&#34;&gt;VSでのネイティブプラグインのビルド&lt;/h2&gt;

&lt;p&gt;VSが使っているビルドツール
&lt;a href=&#34;https://docs.microsoft.com/ja-jp/visualstudio/msbuild/msbuild&#34;&gt;MSBuild&lt;/a&gt;を使う。
VSのプロジェクトファイルにはMSBuildのXMLが含まれている。
これ自体はVSに依存していないため、単体で動かすこともできる。&lt;/p&gt;

&lt;p&gt;パスが通ってなかったらパスを通す。管理者権限が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; MSBuild
&#39;MSBuild&#39; は、内部コマンドまたは外部コマンド、
操作可能なプログラムまたはバッチ ファイルとして認識されていません。

&amp;gt;　SETX /M PATH &amp;quot;%PATH%;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\Bin&amp;quot;

成功: 指定した値は保存されました。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;別プロセスから適用されるので立ち上げ直すとパスが通っていることを確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; MSBuild /version
Microsoft (R) Build Engine バージョン 15.1.1012.6693
Copyright (C) Microsoft Corporation.All rights reserved.

15.1.1012.6693
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドして&lt;code&gt;Assets\Plugins&lt;/code&gt;に配置する。これは前作ったBLEのネイティブプラグインのもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/105/&#34;&gt;Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; git clone git@github.com:sambaiz/UnityBLE_UWP.git
&amp;gt; cd UnityBLE_UWP
&amp;gt; MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;quot;x86&amp;quot;
&amp;gt; MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release
&amp;gt; copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA
&amp;gt; copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.dll ..\Assets\Plugins
&amp;gt; cd ..
&amp;gt; rmdir /S /Q UnityBLE_UWP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなエラーが出てきたらmscorlib.dllをインポートできていないのが原因のようで、
restoreしたらうまくいった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;error CS0518: 定義済みの型 &#39;System.Object&#39; は定義、またはインポートされていません
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;unityでのwsaのビルド&#34;&gt;UnityでのWSAのビルド&lt;/h2&gt;

&lt;p&gt;同様にUnityもパスが通ってなかったら通す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; Unity
&#39;Unity&#39; は、内部コマンドまたは外部コマンド、
操作可能なプログラムまたはバッチ ファイルとして認識されていません。

&amp;gt;　SETX /M PATH &amp;quot;%PATH%;C:\Program Files\Unity\Editor&amp;quot;

成功: 指定した値は保存されました。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/BuildPipeline.BuildPlayer.html&#34;&gt;スクリプト&lt;/a&gt;
をAssets/Editorの中に置く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEditor;

public class Build {

    static void PerformBuild()
    {
        string[] scenes = { &amp;quot;Assets/main.unity&amp;quot; };
        BuildPipeline.BuildPlayer(scenes, &amp;quot;build&amp;quot;,
            BuildTarget.WSAPlayer, BuildOptions.None);

    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このstaticメソッドを&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/CommandLineArguments.html&#34;&gt;executeMethod&lt;/a&gt;
で渡してビルドする。Unityを開いたままだと失敗するので閉じる必要がある。&lt;/p&gt;

&lt;p&gt;この例だとbuildディレクトリに出力される。もし出力されなかったらEditorログを見る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; Unity -quit -batchmode -executeMethod Build.PerformBuild
&amp;gt; type C:\Users\(username)\AppData\Local\Unity\Editor\Editor.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;まとめたもの&#34;&gt;まとめたもの&lt;/h2&gt;

&lt;p&gt;ということでこんなバッチをUnityプロジェクトの直下に置いておくことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone git@github.com:sambaiz/UnityBLE_UWP.git
cd UnityBLE_UWP
MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;quot;x86&amp;quot;
MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release
copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA
copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.dll ..\Assets\Plugins
cd ..
rmdir /S /Q UnityBLE_UWP

rmdir /S /Q build
Unity -quit -batchmode -executeMethod Build.PerformBuild
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://sh-yoshida.hatenablog.com/entry/2017/05/27/012755&#34;&gt;MSBuildでコマンドラインからビルドする - 1.21 jigowatts&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
          <link>https://www.sambaiz.net/article/109/</link>
          <pubDate>Sat, 10 Jun 2017 12:00:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/109/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://norikra.github.io/&#34;&gt;Norikra&lt;/a&gt;はTD社の&lt;a href=&#34;https://github.com/tagomoris&#34;&gt;tagomoris&lt;/a&gt;氏が作った、
スキーマレスのストリーミングデータを処理するOSS。&lt;/p&gt;

&lt;p&gt;モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだけど、
流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。&lt;/p&gt;

&lt;h2 id=&#34;norikraを立ち上げてクエリを実行する&#34;&gt;Norikraを立ち上げてクエリを実行する&lt;/h2&gt;

&lt;p&gt;公式で紹介されているDockerイメージがあったのでこれで動かしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -e &amp;quot;TZ=Asia/Tokyo&amp;quot; -p 26578:26578 -p 26571:26571 -v `pwd`:/var/tmp/norikra:rw -d myfinder/docker-norikra norikra start --stats /var/tmp/norikra/stats.json -l /var/tmp/norikra 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほかの&lt;a href=&#34;https://github.com/norikra/norikra/blob/master/lib/norikra/cli.rb&#34;&gt;オプション&lt;/a&gt;として&lt;code&gt;-Xms&lt;/code&gt;や&lt;code&gt;-Xmx&lt;/code&gt;でJVMのヒープメモリの量を設定したり、Experimentalではあるけど&lt;code&gt;--shutoff&lt;/code&gt;でヒープメモリが一杯になる前に弾いて
OutOfMemoryを防ぐことができる。
また、Norikraのコアエンジンで使われているOSSの
&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%A4%87%E5%90%88%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E5%87%A6%E7%90%86&#34;&gt;CEP&lt;/a&gt;
(Complex event processing)エンジン、
&lt;a href=&#34;http://www.espertech.com/products/esper.php&#34;&gt;Esper&lt;/a&gt;
のパフォーマンスチューニングとして&lt;code&gt;--micro&lt;/code&gt;や&lt;code&gt;--small&lt;/code&gt;などを渡すこともできるけど試していない。&lt;/p&gt;

&lt;p&gt;公式サイトの例に従ってクライアントからデータを入れてクエリを実行してみる。&lt;/p&gt;

&lt;p&gt;まずはtargetをopenする。targetというのはスキーマレスのイベントストリームのこと。
ここで定義したフィールドは必須になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client target open www path:string status:integer referer:string agent:string userid:integer
$ norikra-client target list
TARGET	AUTO_FIELD
www	true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にクエリを追加する。一見普通のSQLのように見えるけど、EsperのクエリであるEPL(Event Processing Language)。
ただしSELECTしか使えないのも含めてクエリにいくらかの制限がある。&lt;/p&gt;

&lt;p&gt;このクエリでは&lt;code&gt;win:time_batch&lt;/code&gt;で10秒のWindowを定義し、eventをgroup byして、その数をeventとして出力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client query add www.toppageviews &#39;SELECT count(*) AS cnt FROM www.win:time_batch(10 sec) WHERE path=&amp;quot;/&amp;quot; AND status=200&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;eventを流す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/login&amp;quot;, &amp;quot;status&amp;quot;:301, &amp;quot;referer&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリの値をfetchする。送るのが遅くてgroup byされなかったけどこんな感じ。
eventがこなかったはじめのWindowは0が出力されるが、それ以降のWindowでは出力されない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client event fetch www.toppageviews
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 20:58:13&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:42:33&amp;quot;,&amp;quot;cnt&amp;quot;:1}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:42:43&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:13&amp;quot;,&amp;quot;cnt&amp;quot;:1}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:23&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:33&amp;quot;,&amp;quot;cnt&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとWeb-uiが用意されていて、クエリを追加したり、targetやクエリの一覧、メモリの使用量やサーバーログなどが取得できる。デフォルトでは26578ポート。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/109-norikra.png&#34; alt=&#34;web-ui&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;クエリ-epl-http-norikra-github-io-query-html&#34;&gt;&lt;a href=&#34;http://norikra.github.io/query.html&#34;&gt;クエリ(EPL)&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;windowなし&#34;&gt;Windowなし&lt;/h3&gt;

&lt;p&gt;上の例では&lt;code&gt;time_batch&lt;/code&gt;でWindowを定義したけど、定義しないクエリを追加してみる。
以下のようなクエリを登録し、再びeventを流してfetchすると流した分が全てとれる。
ただし、このようなクエリはfetchされないと大量のoutput eventが溜まる可能性がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT path, status AS cnt FROM www WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-nowin
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 23:06:12&amp;quot;,&amp;quot;cnt&amp;quot;:200,&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 23:09:10&amp;quot;,&amp;quot;cnt&amp;quot;:200,&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-time-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-time-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-time-batch&#34;&gt;win:time_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;10 sec&lt;/code&gt;のように秒以外にも&lt;code&gt;msec&lt;/code&gt;、&lt;code&gt;min&lt;/code&gt;、&lt;code&gt;hour&lt;/code&gt;、どう使うか想像できないけど&lt;code&gt;year&lt;/code&gt;まで指定でき、
&lt;code&gt;10 minutes 30 seconds&lt;/code&gt;みたいに組み合わせることも&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl_clauses.html#epl-syntax-time-periods&#34;&gt;できる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;また、第二引数にミリ秒を渡すと出力するタイミングを指定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) AS cnt FROM www.win:time_batch(1min, 0L) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-tb-opts
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 00:43:00&amp;quot;,&amp;quot;cnt&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-ext-timed-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-ext-time-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-ext-time-batch&#34;&gt;win:ext_timed_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;来た時間ではなくフィールドのUNIXミリ秒を参照するWindow。時系列順にソートされている必要があって、
tagomoris氏いわく&lt;a href=&#34;https://twitter.com/tagomoris/status/486851407140507648&#34;&gt;おすすめしない&lt;/a&gt;とのこと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) AS cnt FROM www.win:ext_timed_batch(timestamp, 1 min) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3, &amp;quot;timestamp&amp;quot;:1496852100000 }&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3, &amp;quot;timestamp&amp;quot;:1496852200000 }&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-ext_timed
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 01:19:02&amp;quot;,&amp;quot;cnt&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-length-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-length-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-length-batch&#34;&gt;win:length_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;event数のWindow。毎回渡した数ずつ集計できると思いきや、数が集まらなければfetchできず、
それ以上集まったらfetchできるようだ。使いづらいような気がする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT avg(userid) as nosense FROM www.win:length_batch(2) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat

$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat

$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:2}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:42:20&amp;quot;,&amp;quot;nosense&amp;quot;:2.0}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-length-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-length&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-length&#34;&gt;win:length&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;こっちは渡した数スライドして集計するもの。Windowなしのときと同様、大量に溜まる可能性がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT avg(userid) as nosense FROM www.win:length(2) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:5}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:4}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-len
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:11&amp;quot;,&amp;quot;nosense&amp;quot;:3.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:22&amp;quot;,&amp;quot;nosense&amp;quot;:2.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:32&amp;quot;,&amp;quot;nosense&amp;quot;:3.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:45&amp;quot;,&amp;quot;nosense&amp;quot;:4.5}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他にもいろいろあるし、JOINやサブクエリも使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/111/&#34;&gt;NorikraでログをJOINする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;fluentdとやり取りする&#34;&gt;fluentdとやり取りする&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/norikra/fluent-plugin-norikra&#34;&gt;fluent-plugin-norikra&lt;/a&gt;でNorikraサーバーにeventを送り、
eventを受け取ってファイルに出力する。&lt;/p&gt;

&lt;p&gt;c4.large(2コア,メモリ3.75GiB)でDockerでNorikraを立ち上げ、以下の設定でtd-agentを実行した。
&lt;code&gt;auto_field&lt;/code&gt;は来たeventのフィールドを自動でtargetに登録するかの設定で、
true(デフォルト)にするとどんなフィールドが来ているかNorikra上で確認することができる。
falseにしてもクエリで使う分は自動で登録される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag event.dummy
  rate 1000
&amp;lt;/source&amp;gt;
   
&amp;lt;match event.*&amp;gt;
  @type   norikra
  norikra localhost:26571
  
  remove_tag_prefix event # event.*の部分が
  target_map_tag    yes   # targetになる

  &amp;lt;default&amp;gt;
    auto_field false 
  &amp;lt;/default&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;source&amp;gt;
  @type   norikra
  norikra localhost:26571
  &amp;lt;fetch&amp;gt;
    method   event
    # norikra-client query add dummy_count_1sec &#39;SELECT COUNT(*) AS count FROM dummy.win:time_batch(1 sec)&#39;
    target   dummy_count_1sec
    tag      string data.dummy_count_1sec
 #  tag      field FIELDNAME : tag by value with specified field name in output event
    interval 1m
  &amp;lt;/fetch&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match data.*&amp;gt;
  @type file
  path /var/log/td-agent/dummy_count
  time_slice_format %Y%m%d%H
  time_slice_wait 10s
  time_format %Y%m%dT%H%M%S%z
  compress gzip
  symlink_path /var/log/td-agent/dummy_count
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Norikraのスループットは以下の要素が影響する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;number of targets
number of queries
how complex queries are
how complex UDFs are
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、目安としてはこんな感じらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10 queries
2,000 events per seconds
5% usage of 4core CPU
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1target、単純な1クエリなら秒間10000送ってみても問題なかった。
あまり現実的なケースではないけど限界を目指してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail -f dummy_count
20170609T212717+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212718+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212719+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212720+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212721+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212722+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212723+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212724+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212725+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212726+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 8256 root      20   0 1878m 249m  19m S 29.3  6.6   6:46.94 java
 9812 root      20   0  296m  68m 6288 S 20.0  1.8   2:38.08 ruby  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秒間40000送ってみるとカウントがおかしい。
dummyの方の限界かと思ってnorikraを外してみたらおおよそ数が合ったので
Norikraサーバーかやり取りの部分で処理が追いついていないようだ。
一旦rateを下げてみたところ20000あたりを境目にこうなってしまった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail -f dummy_count
20170609T222018+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:31248}
20170609T222019+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:27468}
20170609T222020+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:35309}
20170609T222021+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:31944}
20170609T222022+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:22805}
20170609T222023+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:30716}
20170609T222024+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:33617}
20170609T222025+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:28740}
20170609T222026+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:32058}
20170609T222027+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:27253}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CPUの使用量をみてみると、ほぼ限界まで使用されていた。
fluentdはrubyの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B0%E3%83%AD%E3%83%BC%E3%83%90%E3%83%AB%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%97%E3%83%AA%E3%82%BF%E3%83%AD%E3%83%83%E3%82%AF&#34;&gt;GIL&lt;/a&gt;
(Global Interpreter Lock = GVL(Giant VM Lock))のため同時に&lt;a href=&#34;https://docs.ruby-lang.org/ja/2.3.0/doc/spec=2fthread.html&#34;&gt;1ネイティブスレッドしか動かせず&lt;/a&gt;、1コアしかCPUを使えないが、
jrubyで動くNorikraは残りのコアを使うことができる。
今回はtargetもクエリも一つだし、データ量も小さいためかメモリにはまだ余裕があった。
ログのサイズやウィンドウサイズが大きければメモリを使う量が増えるため、実際のログをしばらく
流してどちらが問題になりそうか確認するべき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
11378 root      20   0  350m 111m 6336 S 96.1  3.0   1:53.03 ruby
8256 root      20   0 1892m 642m  19m S 84.2 17.1  34:36.38 java   
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;HEAP MEMORY USED: 244MB (55.8%), COMMITTED: 437MB, MAX: 437MB
NON-HEAP MEMORY USED: 51MB (23.8%), COMMITTED: 81MB, MAX: 214MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1Gbps、1Mevent/sを超えるような高トラフィックではStormなどのフレームワークを使えとのこと。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでKinesis streamsに送るときの性能確認</title>
          <link>https://www.sambaiz.net/article/108/</link>
          <pubDate>Mon, 05 Jun 2017 23:48:00 &#43;0900</pubDate>
          <author></author>
          <guid>https://www.sambaiz.net/article/108/</guid>
          <description>

&lt;h2 id=&#34;localでのstreamsとproducerのbenchmark&#34;&gt;localでのstreamsとproducerのbenchmark&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;の
&lt;code&gt;make benchmark&lt;/code&gt;はlocalにDummyServerを&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis/blob/v1.1.3/benchmark/task.rake#L18&#34;&gt;立ち上げて&lt;/a&gt;送っている。&lt;/p&gt;

&lt;p&gt;空でもいいのでroleをつけておく必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/awslabs/aws-fluent-plugin-kinesis.git
$ cd aws-fluent-plugin-kinesis
$ yum install -y ruby-devel gcc
$ echo &#39;gem &amp;quot;io-console&amp;quot;&#39; &amp;gt;&amp;gt; Gemfile
$ make
$ make benchmark
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATEを指定しなければデフォルトで&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis/blob/v1.1.3/benchmark/task.rake#L19&#34;&gt;秒間1000レコード&lt;/a&gt;が送られる設定。
fluentdを起動してから10秒後にプロセスをkillし、そのレコード数などを出力している。&lt;/p&gt;

&lt;p&gt;t2.microでデフォルト(RATE=1000)で実行した結果がこれ。
固める分producerの方はややパフォーマンスが落ちる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 20, raw_records: 9400, records: 9400
bundle exec rake benchmark TYPE=producer
Results: requets: 14, raw_records: 1005, records: 8900
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATE=3000のとき。producerではraw_recordsが1/100、リクエスト数は1/5。
streamsだとシャードを増やしていく必要があるけど、producerの方は当分大丈夫そうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 57, raw_records: 27600, records: 27600
bundle exec rake benchmark TYPE=producer
Results: requets: 12, raw_records: 241, records: 25200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATE=10000のとき。raw_records, requestの圧縮率はさらに上がり、
パフォーマンスの差が大きくなってきている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 177, raw_records: 88000, records: 88000
bundle exec rake benchmark TYPE=producer
Results: requets: 26, raw_records: 385, records: 75000
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実際にkinesis-streamsに送ってみる&#34;&gt;実際にkinesis streamsに送ってみる&lt;/h2&gt;

&lt;p&gt;ap-northeast-1でシャードは3のKinesis streamsにt2.microインスタンス1台から送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1000
&amp;lt;/source&amp;gt;

&amp;lt;source&amp;gt;
  @type monitor_agent
  bind 0.0.0.0
  port 24220
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type kinesis_streams
  region ap-northeast-1
  stream_name test

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秒間3000まではほとんどキューにたまらず送れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:24220/api/plugins.json | jq
{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 0,
      &amp;quot;buffer_total_queued_size&amp;quot;: 17500,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4000にするとそのうちretryが発生してしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
     &amp;quot;buffer_queue_length&amp;quot;: 60,
      &amp;quot;buffer_total_queued_size&amp;quot;: 56544178,
      &amp;quot;retry_count&amp;quot;: 5,
      &amp;quot;retry&amp;quot;: {
        &amp;quot;steps&amp;quot;: 5,
        &amp;quot;next_time&amp;quot;: &amp;quot;2017-06-05 14:05:38 +0000&amp;quot;
      }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たしかにスループットが超過している。スペック通りだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/108.png&#34; alt=&#34;書き込みスループットの超過&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次に30シャードにしてみる。一度にシャード数は倍から半分にしかできないので作り直し。&lt;/p&gt;

&lt;p&gt;これに秒間30000を送ってみると、キューにいくらか溜まった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 7,
      &amp;quot;buffer_total_queued_size&amp;quot;: 7752600,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに倍にして60シャード。これに秒間60000で送ってみる。キューに溜まるものの増え続けはしないのでなんとか送れてそうだ。
td-agentのプロセスがCPUを99%使っているので、このインスタンスではこの辺が限界かもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 15,
      &amp;quot;buffer_total_queued_size&amp;quot;: 16105807,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ついでにus-east-1にも30シャードのStreamsを作成して30000送ってみたところ、キューに溜まる量が格段に増えた。
早くFirehoseやAnalyticsが東京リージョンにも来てほしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 50,
      &amp;quot;buffer_total_queued_size&amp;quot;: 52432436,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    

  </channel>
</rss>
