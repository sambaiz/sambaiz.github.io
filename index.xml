<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sambaiz-net</title>
    <link>https://www.sambaiz.net/</link>
    <language>ja</language>
    <author>sambaiz</author>
    <rights>(C) 2020</rights>
    <updated>2020-04-01 23:55:00 &#43;0900 JST</updated>

    
      
        <item>
          <title>Bellman–Ford法とDijkstra法で最短経路問題を解く</title>
          <link>https://www.sambaiz.net/article/267/</link>
          <pubDate>Wed, 01 Apr 2020 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/267/</guid>
          <description>

&lt;p&gt;Bellman–Ford法とDijkstra法で最短経路問題を解く。&lt;/p&gt;

&lt;h2 id=&#34;bellman-ford法&#34;&gt;Bellman-Ford法&lt;/h2&gt;

&lt;p&gt;始点の距離が0、それ以外の頂点の距離が無限大な初期状態から、
全辺を見て各辺を通るとしたときに現在の距離を下回るなら更新する、というのを繰り返すアルゴリズム。
辺の重みは負でも問題ないが、総和が負の値になる閉路が存在する場合、そこで無限ループしてしまうので決まらない。
その場合を除けば、頂点の数を&lt;code&gt;|V|&lt;/code&gt;、辺の数を&lt;code&gt;|E|&lt;/code&gt;とすると、繰り返しは&lt;code&gt;|V|-1&lt;/code&gt;回で終わり、計算量は&lt;code&gt;O(|V||E|)&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/267-bf.png&#34; alt=&#34;Bellman-Ford法&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;dijkstra法&#34;&gt;Dijkstra法&lt;/h2&gt;

&lt;p&gt;同じく始点の距離が0、それ以外の頂点の距離が無限大な初期状態から、
まだ選ばれていない頂点の中から最小の距離のものを1つ選んでその最短距離を確定させ、そこから伸びている辺を見て更新していく、というのを繰り返す。
Bellman-Ford法が全ての頂点から同時に探索するのに対してDijkstra法は始点から着実に進んでいくイメージ。
頂点を選ぶ/取り除くのに&lt;code&gt;O(log|V|)&lt;/code&gt;かかる二分ヒープのpriority queueで実装すると計算量は&lt;code&gt;O((|E|+|V|)log|V|)&lt;/code&gt;となる。
Bellman-Ford法より高速だが、負の重みがあると選んだ頂点の現在の距離が最短であることが確定しないので適用できない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/267-dijk.png&#34; alt=&#34;Dijkstra法&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;cheapest-flights-within-k-stops-leetcode-https-leetcode-com-problems-cheapest-flights-within-k-stops&#34;&gt;&lt;a href=&#34;https://leetcode.com/problems/cheapest-flights-within-k-stops/&#34;&gt;Cheapest Flights Within K Stops - LeetCode&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;乗継K回以内のフライトの最安値を返す問題。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;There are n cities connected by m flights. Each flight starts from city u and arrives at v with a price w.

Now given all the cities and flights, together with starting city src and the destination dst, your task is to find the cheapest price from src to dst with up to k stops. If there is no such route, output -1.

Example 1:
Input: 
n = 3, edges = [[0,1,100],[1,2,100],[0,2,500]]
src = 0, dst = 2, k = 1
Output: 200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずはBellman-Ford法で解く。繰り返しを最大K+1回で止めることで乗継K回以内という制約をかけている。
実行時間は128ms。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Solution {
public:
    int inf = 1000 * 100 + 1;
    int findCheapestPrice(int n, vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt;&amp;amp; flights, int src, int dst, int K) {
        vector costs(n, inf);
        costs[src] = 0;
        int step = min(K + 1, n - 1);
        for (int i = 0; i &amp;lt; step; i++) {
            vector nextCosts = costs;
            for(vector&amp;lt;int&amp;gt; flight: flights) {
                nextCosts[flight[1]] = min(nextCosts[flight[1]], costs[flight[0]] + flight[2]);
            }
            costs = nextCosts;
        }
        
        if (costs[dst] == inf) {
            return -1;
        }
        return costs[dst];
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にDijkstra法で解く。価格と共に乗継数を持ち超過したルートは無視することで、最安でなくても乗継数が少ないルートも採用されるようにする。
実行時間は172msとあまり振るわず。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://leetcode.com/problems/cheapest-flights-within-k-stops/discuss/115541/JavaPython-Priority-Queue-Solution&#34;&gt;[Java/Python] Priority Queue Solution - LeetCode Discuss&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Solution {
public:
    int inf = 1000 * 100 + 1;
    int findCheapestPrice(int n, vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt;&amp;amp; flights, int src, int dst, int K) {
        map&amp;lt;int, map&amp;lt;int, int&amp;gt;&amp;gt; costs;
        for (vector&amp;lt;int&amp;gt; flight: flights) {
            costs[flight[0]][flight[1]] = flight[2]; // [from][to] = cost
        }
        
        auto compare = [](vector&amp;lt;int&amp;gt; a, vector&amp;lt;int&amp;gt; b) { return a[1] &amp;gt; b[1]; };
        priority_queue&amp;lt;vector&amp;lt;int&amp;gt;, vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt;, decltype(compare)&amp;gt; Q(compare);
        Q.push({src, 0, 0}); // city, price, stop 
        
        while(!Q.empty()) {
            vector&amp;lt;int&amp;gt; current = Q.top();
            Q.pop();
            if (current[0] == dst) {
                return current[1];
            }
            if (current[2] &amp;gt; K) {
                continue;
            }
            for (auto cost: costs[current[0]]) {
                Q.push({cost.first, current[1] + cost.second, current[2] + 1});
            }
        }
        return -1;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://nw.tsuda.ac.jp/lec/BellmanFord/&#34;&gt;Bellman-Ford法: 負の重みのエッジを含むグラフにおける最短経路&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ss.cs.meiji.ac.jp/CCP024.html&#34;&gt;ダイクストラ法&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm&#34;&gt;Dijkstra&amp;rsquo;s algorithm - Wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>作ったライブラリをCocoaPods/Carthageでimportする</title>
          <link>https://www.sambaiz.net/article/266/</link>
          <pubDate>Sat, 28 Mar 2020 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/266/</guid>
          <description>

&lt;h2 id=&#34;cocoapods-https-cocoapods-org&#34;&gt;&lt;a href=&#34;https://cocoapods.org&#34;&gt;CocoaPods&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;長らく使われている依存ライブラリ管理ツール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo gem install cocoapods
$ pod --version
1.9.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;podspec-https-guides-cocoapods-org-syntax-podspec-html&#34;&gt;&lt;a href=&#34;https://guides.cocoapods.org/syntax/podspec.html&#34;&gt;podspec&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;まずはライブラリ側の作業。podspecを埋めていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls
SampleFramework			SampleFramework.xcodeproj	SampleFrameworkTests

$ pod spec create SampleFrameworkSambaiz

Specification created at SampleFrameworkSambaiz.podspec

$ cat SampleFrameworkSambaiz.podspec 
Pod::Spec.new do |spec|
  spec.name             = &#39;SampleFrameworkSambaiz&#39;
  spec.version          = &#39;0.0.2&#39;
  spec.license          = { :type =&amp;gt; &#39;MIT&#39;, :file =&amp;gt; &#39;LICENSE&#39; }
  spec.homepage         = &#39;https://github.com/sambaiz/ios-sample-framework&#39;
  spec.authors          = { &#39;Taiki Sakamoto&#39; =&amp;gt; &#39;godgourd@gmail.com&#39; }
  spec.summary          = &#39;Sample Framework&#39;
  spec.description      = &amp;lt;&amp;lt;-DESC
                            This 
                            is 
                            a sample framework
                          DESC
  spec.source           = { :git =&amp;gt; &#39;https://github.com/sambaiz/ios-sample-framework.git&#39;, :tag =&amp;gt; &#39;v0.0.2&#39; }
  spec.source_files = &#39;SampleFramework/**/*.{h,m,swift}&#39;
  spec.requires_arc     = true
  spec.ios.deployment_target = &#39;9.0&#39;
  spec.swift_version = &#39;4.0&#39;
  spec.frameworks       = []
  spec.weak_frameworks  = []
end

$ pod spec lint

SampleFrameworkSambaiz.podspec passed validation.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://guides.cocoapods.org/syntax/podspec.html#subspec&#34;&gt;subspec&lt;/a&gt;に分割すると一部だけインストールできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;spec.default_subspecs = &#39;All&#39;

spec.subspec &#39;All&#39; do |sdk|
  sdk.dependency              &#39;SampleFrameworkSambaiz/Foo&#39;
  sdk.dependency              &#39;SampleFrameworkSambaiz/Bar&#39;
end

spec.subspec &#39;Foo&#39; do |core|
  core.source_files         = &#39;SampleFramework/Foo/**/*.{h,m,swift}&#39;
end

spec.subspec &#39;Bar&#39; do |core|
  core.source_files         = &#39;SampleFramework/Bar/**/*.{h,m,swift}&#39;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;trunk-https-guides-cocoapods-org-making-getting-setup-with-trunk-html&#34;&gt;&lt;a href=&#34;https://guides.cocoapods.org/making/getting-setup-with-trunk.html&#34;&gt;trunk&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;publishする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pod trunk register godgourd@gmail.com &#39;Taiki Sakamoto&#39; --description=&#39;mbp&#39;
[!] Please verify the session by clicking the link in the verification email that has been sent to godgourd@gmail.com

$ pod trunk me
  - Name:     Taiki Sakamoto
  - Email:    godgourd@gmail.com
  - Since:    March 27th, 16:02
  - Pods:     None
  - Sessions:
    - March 27th, 16:02 - August 2nd, 16:04. IP: xxx.xxx.xxx.xxx Description: test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pushすると&lt;a href=&#34;https://github.com/CocoaPods/Specs&#34;&gt;CocoaPods/Spec&lt;/a&gt;にpodspecが上がる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pod trunk push SampleFrameworkSambaiz.podspec
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;import&#34;&gt;import&lt;/h3&gt;

&lt;p&gt;アプリ側の作業。Podfileを書いていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pod init
$ git status
On branch master
Untracked files:
  (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)
	Podfile

$ vi Podfile
# Uncomment the next line to define a global platform for your project
# platform :ios, &#39;9.0&#39;

target &#39;SampleApp&#39; do
  # Comment the next line if you don&#39;t want to use dynamic frameworks
  use_frameworks!

  # Pods for SampleApp
  pod &#39;SampleFrameworkSambaiz/Foo&#39;,  &#39;0.0.3&#39;

  target &#39;SampleAppTests&#39; do
    # Pods for testing
  end

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なお、trunkではなく直接Gitリポジトリを参照することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pod &#39;SampleFrameworkSambaiz/Foo&#39;, :git =&amp;gt; &#39;https://github.com/sambaiz/ios-sample-framework.git&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pushしただけではローカルに反映されていないのでupdateしてからinstallする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pod repo update
Updating spec repo `trunk`

$ pod install
$ tree ~/.cocoapods/repos/trunk/Specs/f/5/4/SampleFrameworkSambaiz
/Users/sambaiz/.cocoapods/repos/trunk/Specs/f/5/4/SampleFrameworkSambaiz
├── 0.0.3
│   ├── SampleFrameworkSambaiz.podspec.json
│   └── SampleFrameworkSambaiz.podspec.json.etag
└── 0.0.4
    ├── SampleFrameworkSambaiz.podspec.json
    └── SampleFrameworkSambaiz.podspec.json.etag
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podsディレクトリとxcworkspaceができている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git status
On branch master
Changes not staged for commit:
  (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to update what will be committed)
  (use &amp;quot;git restore &amp;lt;file&amp;gt;...&amp;quot; to discard changes in working directory)
	modified:   SampleApp.xcodeproj/project.pbxproj

Untracked files:
  (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)
	Podfile
	Podfile.lock
	Pods/
	SampleApp.xcworkspace/

$ tree Pods/SampleFrameworkSambaiz
Pods/SampleFrameworkSambaiz
├── LICENSE
└── SampleFramework
    └── Foo
        └── Foo.swift
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;xcworkspaceを開くと元々のアプリとPodsのprojectが入っていて、
依存frameworkにPodsのものが追加されているのでそのままimportできるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/266.png&#34; alt=&#34;xcworkspaceの構成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通常、アプリのビルド時にPodsの方もビルドするのでライブラリのサイズによっては時間がかかってしまう。
これを解消するには&lt;a href=&#34;https://github.com/leavez/cocoapods-binary&#34;&gt;cocoapods-binary&lt;/a&gt;で
&lt;a href=&#34;http://guides.cocoapods.org/plugins/pre-compiling-dependencies.html&#34;&gt;Pre-compiling&lt;/a&gt;するか
Carthageを使う。&lt;/p&gt;

&lt;h2 id=&#34;carthage-https-github-com-carthage-carthage&#34;&gt;&lt;a href=&#34;https://github.com/Carthage/Carthage&#34;&gt;Carthage&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;後発の依存ライブラリ管理ツール。ハンニバルのカルタゴであるが、カーセッジと発音する人もいる。
update時にframeworkをビルドするのでアプリケーションのビルドが遅くならず、workspaceを生成せず依存も触らないので挙動がシンプル。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install carthage
$ carthage version
0.34.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ライブラリ側はManaged SchemasのSharedにチェックを入れるだけ。&lt;/p&gt;

&lt;h3 id=&#34;import-1&#34;&gt;import&lt;/h3&gt;

&lt;p&gt;Cartfileを書いてupdateする。CocoaPodsのtrunkのようなものは存在せず、直接リポジトリを参照する。
updateするとBuildディレクトリにframeworkができるのでこれを依存に入れればimportできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Cartfile
github &amp;quot;sambaiz/ios-sample-framework&amp;quot; &amp;gt;= 0.0.4

$ carthage update
*** Fetching ios-sample-framework
*** Checking out ios-sample-framework at &amp;quot;v0.0.5&amp;quot;
*** xcodebuild output can be found in /var/folders/1x/bzw0n3ss6_j0t7nlphn2cjrm7ngzh2/T/carthage-xcodebuild.Owsxl9.log
*** Building scheme &amp;quot;SampleFramework&amp;quot; in SampleFramework.xcodeproj

$ tree -L 3 Carthage/
Carthage/
├── Build
│   └── iOS
│       ├── 33F1736C-D538-3EE2-9BF7-86004B596A9B.bcsymbolmap
│       ├── SampleFramework.framework
│       └── SampleFramework.framework.dSYM
└── Checkouts
    └── ios-sample-framework
        ├── LICENSE
        ├── SampleFramework
        ├── SampleFramework.xcodeproj
        ├── SampleFrameworkSambaiz.podspec
        └── SampleFrameworkTests
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとはBuild PhasesのScriptに &lt;code&gt;carthage copy-frameworks&lt;/code&gt; を入れる。
これは提出用アプリにシミュレーター用のバイナリが含まれないようにするためらしい。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/syoikeda/carthagen&#34;&gt;Carthageについて知りたいn個のこと&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>iOSのipa(app)のProfileを異なるTeamのものに置き換えて実機で動かす</title>
          <link>https://www.sambaiz.net/article/265/</link>
          <pubDate>Tue, 24 Mar 2020 22:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/265/</guid>
          <description>

&lt;p&gt;Profileを置き換えて有効期限やDevice IDを更新する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/264/&#34;&gt;iOSアプリのProvisioning profile - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;codesignでの試み&#34;&gt;codesignでの試み&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;.ipa&lt;/code&gt; をunzipすると &lt;code&gt;.app&lt;/code&gt; が出てくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ unzip my-test-app.ipa
$ tree Payload/
Payload/
└── my-test-app.app
    ├── Base.lproj
    │   └── LaunchScreen.storyboardc
    │       ├── 01J-lp-oVM-view-Ze5-6b-2t3.nib
    │       ├── Info.plist
    │       └── UIViewController-01J-lp-oVM.nib
    ├── Info.plist
    ├── PkgInfo
    ├── _CodeSignature
    │   └── CodeResources
    ├── embedded.mobileprovision
    └── my-test-app
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;codesign&lt;/code&gt; で entitlements を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ codesign -d --entitlements :- my-test-app.app &amp;gt; entitlements.plist
$ cat entitlements.plist 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE plist PUBLIC &amp;quot;-//Apple//DTD PLIST 1.0//EN&amp;quot; &amp;quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&amp;quot;&amp;gt;
&amp;lt;plist version=&amp;quot;1.0&amp;quot;&amp;gt;
&amp;lt;dict&amp;gt;
	&amp;lt;key&amp;gt;application-identifier&amp;lt;/key&amp;gt;
	&amp;lt;string&amp;gt;****.net.sambaiz.test-app&amp;lt;/string&amp;gt;
	&amp;lt;key&amp;gt;com.apple.developer.team-identifier&amp;lt;/key&amp;gt;
	&amp;lt;string&amp;gt;****&amp;lt;/string&amp;gt;
	&amp;lt;key&amp;gt;get-task-allow&amp;lt;/key&amp;gt;
	&amp;lt;true/&amp;gt;
	&amp;lt;key&amp;gt;keychain-access-groups&amp;lt;/key&amp;gt;
	&amp;lt;array&amp;gt;
		&amp;lt;string&amp;gt;****.net.sambaiz.test-app&amp;lt;/string&amp;gt;
	&amp;lt;/array&amp;gt;
&amp;lt;/dict&amp;gt;
&amp;lt;/plist&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--force&lt;/code&gt; で上書き署名する。entitlementsなしで署名すると
&lt;code&gt;The application could not be verified&lt;/code&gt; になった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ codesign --force \ 
--sign &amp;quot;Apple Development: *****@***** (******)&amp;quot; \ 
--entitlements entitlements.plist \ 
my-test-app.app
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでデプロイしたところ &lt;code&gt;A valid provisioning profile for this executable was not found&lt;/code&gt; のエラーが出た。
単にcodesignするだけでは &lt;code&gt;embedded.mobileprovision&lt;/code&gt; は元のままだ。
また、Teamが異なればApp IDのPrefixも異なるので &lt;code&gt;entitlements.plist&lt;/code&gt; や &lt;code&gt;Info.plist&lt;/code&gt; を編集する必要があったりとなかなかやることが多い。&lt;/p&gt;

&lt;h2 id=&#34;fastlaneのsighでのresign&#34;&gt;fastlaneのsighでのresign&lt;/h2&gt;

&lt;p&gt;調べてみるとfastlaneの&lt;a href=&#34;https://docs.fastlane.tools/actions/sigh/&#34;&gt;sigh&lt;/a&gt;
でresignするとApp IDの変更や &lt;code&gt;embedded.mobileprovision&lt;/code&gt; の置き換えなどもやってくれるらしい。&lt;/p&gt;

&lt;p&gt;fastlaneのインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install fastlane
$ fastlane -v
fastlane 2.143.0

$ export FASTLANE_USER=****@****
# store password in the macOS Keychain
$ fastlane fastlane-credentials add -u ${FASTLANE_USER}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;resignする。Profileはマニュアルで作ってダウンロードするか、
&lt;code&gt;~/Library/MobileDevice/Provisioning Profiles&lt;/code&gt; を探して使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ fastlane sigh resign my-test-app.ipa --signing_identity &amp;quot;Apple Development: ****&amp;quot; -p &amp;quot;****.mobileprovision&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;a href=&#34;https://github.com/ios-control/ios-deploy&#34;&gt;ios-deploy&lt;/a&gt;でデプロイしたところ無事成功した。便利。
試しにデプロイするDeviceを外したProfileでresignしてみると
&lt;code&gt;The executable was signed with invalid entitlements&lt;/code&gt; でインストールできなくなったので新しいProfileが効いてそうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ unzip my-test-app.ipa
$ ios-deploy --debug --bundle Payload/my-test-app.app
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.minimalab.com/blog/2016/04/14/resign-ipa/&#34;&gt;ipa ファイルを再署名する&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/seyself/items/8f62677547ef597cee67&#34;&gt;ipaファイルのProvisioningを差し替える - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/toshi0383/items/2d82104c5e70c249f0a1&#34;&gt;iOS受託開発における署名付け替えの技術 - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>iOSアプリのProvisioning Profile</title>
          <link>https://www.sambaiz.net/article/264/</link>
          <pubDate>Tue, 24 Mar 2020 21:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/264/</guid>
          <description>

&lt;p&gt;アプリを実機にデプロイするために必要なもの。
App ID (prefix + Bundle ID)やインストール可能なDevice ID、
&lt;a href=&#34;https://developer.apple.com/jp/support/code-signing/&#34;&gt;コード署名&lt;/a&gt;に用いた
Apple発行の&lt;a href=&#34;https://help.apple.com/developer-account/#/deveedc0daa0&#34;&gt;証明書&lt;/a&gt;などを含む。これらが一致しないとインストールできない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/264.png&#34; alt=&#34;Xcode上で見られる情報&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次のTypeのProfileが存在する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://help.apple.com/developer-account/#/devf2eb157f8&#34;&gt;development profile&lt;/a&gt;:
開発用のprofile。TeamのDeviceで動かす。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.apple.com/developer-account/#/dev4fd1495fc&#34;&gt;ad hoc profile&lt;/a&gt;:
テスト用のprofile。UDIDを登録したDeviceに配布できる。
AccountにDevice family (iPhone, iPad, etc.)ごとに100台まで登録可能。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.apple.com/developer-account/#/devbd904d1a5&#34;&gt;App Store profile&lt;/a&gt;:
App Storeに上げるためのprofile。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ ls ~/Library/MobileDevice/Provisioning\ Profiles
****.mobileprovision
...

$ security cms -D -i ~/Library/MobileDevice/Provisioning\ Profiles/****.mobileprovision
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE plist PUBLIC &amp;quot;-//Apple//DTD PLIST 1.0//EN&amp;quot; &amp;quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&amp;quot;&amp;gt;
&amp;lt;plist version=&amp;quot;1.0&amp;quot;&amp;gt;
&amp;lt;dict&amp;gt;
	&amp;lt;key&amp;gt;AppIDName&amp;lt;/key&amp;gt;
	&amp;lt;string&amp;gt;XC net sambaiz test-app&amp;lt;/string&amp;gt;
	&amp;lt;key&amp;gt;ApplicationIdentifierPrefix&amp;lt;/key&amp;gt;
	&amp;lt;array&amp;gt;
	&amp;lt;string&amp;gt;****&amp;lt;/string&amp;gt;
	&amp;lt;/array&amp;gt;
	&amp;lt;key&amp;gt;CreationDate&amp;lt;/key&amp;gt;
	&amp;lt;date&amp;gt;2020-03-18T11:05:13Z&amp;lt;/date&amp;gt;
	&amp;lt;key&amp;gt;Platform&amp;lt;/key&amp;gt;
	&amp;lt;array&amp;gt;
		&amp;lt;string&amp;gt;iOS&amp;lt;/string&amp;gt;
	&amp;lt;/array&amp;gt;
	&amp;lt;key&amp;gt;IsXcodeManaged&amp;lt;/key&amp;gt;
	&amp;lt;true/&amp;gt;
	&amp;lt;key&amp;gt;DeveloperCertificates&amp;lt;/key&amp;gt;
	&amp;lt;array&amp;gt;
	  &amp;lt;data&amp;gt;****&amp;lt;/data&amp;gt;
    &amp;lt;data&amp;gt;****&amp;lt;/data&amp;gt;
  &amp;lt;/array&amp;gt;

								
	&amp;lt;key&amp;gt;Entitlements&amp;lt;/key&amp;gt;
	&amp;lt;dict&amp;gt;
				
				&amp;lt;key&amp;gt;application-identifier&amp;lt;/key&amp;gt;
		&amp;lt;string&amp;gt;****.net.sambaiz.test-app&amp;lt;/string&amp;gt;
				
				&amp;lt;key&amp;gt;keychain-access-groups&amp;lt;/key&amp;gt;
		&amp;lt;array&amp;gt;
				&amp;lt;string&amp;gt;****.*&amp;lt;/string&amp;gt;
		&amp;lt;/array&amp;gt;
				
				&amp;lt;key&amp;gt;get-task-allow&amp;lt;/key&amp;gt;
		&amp;lt;true/&amp;gt;
				
				&amp;lt;key&amp;gt;com.apple.developer.team-identifier&amp;lt;/key&amp;gt;
		&amp;lt;string&amp;gt;****&amp;lt;/string&amp;gt;

	&amp;lt;/dict&amp;gt;
	&amp;lt;key&amp;gt;ExpirationDate&amp;lt;/key&amp;gt;
	&amp;lt;date&amp;gt;2020-03-25T11:05:13Z&amp;lt;/date&amp;gt;
	&amp;lt;key&amp;gt;Name&amp;lt;/key&amp;gt;
	&amp;lt;string&amp;gt;iOS Team Provisioning Profile: net.sambaiz.test-app&amp;lt;/string&amp;gt;
	&amp;lt;key&amp;gt;ProvisionedDevices&amp;lt;/key&amp;gt;
	&amp;lt;array&amp;gt;
		&amp;lt;string&amp;gt;****&amp;lt;/string&amp;gt;
	&amp;lt;/array&amp;gt;
	&amp;lt;key&amp;gt;LocalProvision&amp;lt;/key&amp;gt;
	&amp;lt;true/&amp;gt;
	&amp;lt;key&amp;gt;TeamIdentifier&amp;lt;/key&amp;gt;
	&amp;lt;array&amp;gt;
		&amp;lt;string&amp;gt;****&amp;lt;/string&amp;gt;
	&amp;lt;/array&amp;gt;
	&amp;lt;key&amp;gt;TeamName&amp;lt;/key&amp;gt;
	&amp;lt;string&amp;gt;Taiki Sakamoto&amp;lt;/string&amp;gt;
	&amp;lt;key&amp;gt;TimeToLive&amp;lt;/key&amp;gt;
	&amp;lt;integer&amp;gt;7&amp;lt;/integer&amp;gt;
	&amp;lt;key&amp;gt;UUID&amp;lt;/key&amp;gt;
	&amp;lt;string&amp;gt;*****-****&amp;lt;/string&amp;gt;
	&amp;lt;key&amp;gt;Version&amp;lt;/key&amp;gt;
	&amp;lt;integer&amp;gt;1&amp;lt;/integer&amp;gt;
&amp;lt;/dict&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://help.apple.com/xcode/mac/current/#/dev80cc24546&#34;&gt;automatic manage signing&lt;/a&gt;
を有効にすると、Xcodeが自動で証明書を要求しダウンロードしてきて署名しProvisioning Profileを生成する。
証明書はkeychainに保存されていて、CIで署名するのに必要ならそこから秘密鍵(.p12)を出力できる。&lt;/p&gt;

&lt;p&gt;証明書やProvisioning Profileは
&lt;a href=&#34;https://developer.apple.com/account&#34;&gt;developer.apple.com/account&lt;/a&gt; からマニュアルで生成することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ security find-identity -v -p codesigning 
1) ***************************** &amp;quot;Apple Development: ****@****.com (******)&amp;quot;
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/kazuhidet/items/5db08fdfeece820ece64&#34;&gt;iOS .mobileprovisionのデベロッパー証明書を確認する - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのツールのバージョンをgo.modで指定する</title>
          <link>https://www.sambaiz.net/article/263/</link>
          <pubDate>Sun, 22 Mar 2020 01:19:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/263/</guid>
          <description>&lt;p&gt;依存moduleと同様にツールもバージョンを指定し、挙動や出力が変わらないようにする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/go-modules-by-example/index/blob/master/010_tools/README.md&#34;&gt;Tools as dependencies&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;まず次の &lt;code&gt;tools.go&lt;/code&gt; のようなファイルを作ってimportし、
&lt;code&gt;go mod tidy&lt;/code&gt; で消えないようにする。
build tagが付いているので通常のbuild時には影響を及ぼさない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat tools.go
// +build tools

package pkg

import (
	_ &amp;quot;golang.org/x/lint/golint&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にGOBINを変更して &lt;code&gt;go install&lt;/code&gt; し指定したディレクトリにバイナリを持ってきてこれを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export GOBIN:=$(PWD)/bin

$(GOBIN)/golint:
	go install golang.org/x/lint/golint

.PHONY: test

test: $(GOBIN)/golint
	go test -v ./pkg/...
	bin/golint ./pkg/...
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Go Modulesのreplaceでforkしたコードのimportを書き換えずにfork後のpackageに向ける</title>
          <link>https://www.sambaiz.net/article/262/</link>
          <pubDate>Sun, 01 Mar 2020 21:19:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/262/</guid>
          <description>&lt;p&gt;Goはimportの際に相対パスやモジュール名ではなく&lt;code&gt;github.com/foo/bar&lt;/code&gt;のようなフルパスで指定するため、forkしたコードを使うと参照するpackageは元のままになってしまう。Go Modulesのreplace directiveを使うとコードを書き換えずに依存先を変えることができる。相対パスも使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive&#34;&gt;When should I use the replace directive? · golang/go Wiki · GitHub&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module example.com/me/hello

require (
    example.com/foo/bar v0.0.0
)

replace (
    example.com/foo/bar/aaa =&amp;gt; ./
    example.com/foo/bar/bbb =&amp;gt; example.com/hoge/bar/bbb v1.0.0
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fork元のmodule。文字列を出力するだけのもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat go-something/lib/lib.go 
package lib

import &amp;quot;fmt&amp;quot;

func Do() {
	fmt.Println(&amp;quot;this is original&amp;quot;)
}

$ cat go-something/main.go 
package main

import &amp;quot;github.com/sambaiz/go-something/lib&amp;quot;

func main() {
	lib.Do()
}

$ go run go-something/main.go 
this is original
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fork先のmodule。出力する文字列を変えている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat go-something-fork/lib/lib.go 
package lib

import &amp;quot;fmt&amp;quot;

func Do() {
	fmt.Println(&amp;quot;this is fork&amp;quot;) // edit
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しかし、これを実行すると元々の文字列が出力されてしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat go-something-fork/go.mod 
module github.com/sambaiz/go-something-fork

go 1.13

require github.com/sambaiz/go-something v0.0.0-20200301104436-97bba924e129

$ go run go-something-fork/main.go 
this is original
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;replaceを追加して実行すると文字列が変わり、fork先のpackageをimportしていることが確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat go-something-fork/go.mod 
module github.com/sambaiz/go-something-fork

go 1.13

require github.com/sambaiz/go-something v0.0.0-00010101000000-000000000000

replace github.com/sambaiz/go-something =&amp;gt; ./

$ go run go-something-fork/main.go 
this is fork
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Go Modulesのproxyとsumdb</title>
          <link>https://www.sambaiz.net/article/261/</link>
          <pubDate>Sat, 29 Feb 2020 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/261/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/module-mirror-launch&#34;&gt;Module Mirror and Checksum Database Launched - The Go Blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Go1.13からデフォルトで使われるようになったGo Modulesのミラーとchecksumを返すサーバー。
Googleによって運営されている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://proxy.golang.org/&#34;&gt;proxy.golang.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://index.golang.org/&#34;&gt;index.golang.org&lt;/a&gt;: proxyで利用可能なmoduleとバージョンの一覧&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sum.golang.org/&#34;&gt;sum.golang.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ curl &amp;quot;https://proxy.golang.org/github.com/labstack/echo/v4/@v/v4.1.14.mod&amp;quot;
module github.com/labstack/echo/v4

go 1.12

require (
        github.com/dgrijalva/jwt-go v3.2.0+incompatible
        github.com/labstack/gommon v0.3.0
        github.com/mattn/go-colorable v0.1.4 // indirect
        github.com/mattn/go-isatty v0.0.11 // indirect
        github.com/stretchr/testify v1.4.0
        github.com/valyala/fasttemplate v1.1.0
        golang.org/x/crypto v0.0.0-20191227163750-53104e6ec876
        golang.org/x/net v0.0.0-20191209160850-c0dbc17a3553 // indirect
        golang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8 // indirect
        golang.org/x/text v0.3.2 // indirect
)

$ wget &amp;quot;https://proxy.golang.org/github.com/labstack/echo/v4/@v/v4.1.14.zip&amp;quot;

$ curl &amp;quot;https://index.golang.org/index?since=2020-02-28T09:00:00.000000Z&amp;amp;limit=5&amp;quot;
{&amp;quot;Path&amp;quot;:&amp;quot;github.com/openebs/api&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v0.0.0-20200228085622-f3442fff37bf&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:00:05.62813Z&amp;quot;}
{&amp;quot;Path&amp;quot;:&amp;quot;github.com/dirkarnez/dirk-commons&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v0.0.0-20200228090031-1926f326c678&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:00:50.00608Z&amp;quot;}
{&amp;quot;Path&amp;quot;:&amp;quot;github.com/jfrog-solutiontest/food&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v4.107.0+incompatible&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:01:10.76502Z&amp;quot;}
{&amp;quot;Path&amp;quot;:&amp;quot;github.com/nexus49/dapr-components&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v0.0.0-20200228090009-67e985bdc953&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:01:15.618406Z&amp;quot;}
{&amp;quot;Path&amp;quot;:&amp;quot;github.com/Krajiyah/ble-sdk&amp;quot;,&amp;quot;Version&amp;quot;:&amp;quot;v0.0.7-0.20200228090109-03b5ffe425a0&amp;quot;,&amp;quot;Timestamp&amp;quot;:&amp;quot;2020-02-28T09:01:23.38344Z&amp;quot;}

$ curl &amp;quot;https://sum.golang.org/lookup/github.com/labstack/echo/v4@v4.1.14&amp;quot;
732868
github.com/labstack/echo/v4 v4.1.14 h1:h8XP66UfB3tUm+L3QPw7tmwAu3pJaA/nyfHPCcz46ic=
github.com/labstack/echo/v4 v4.1.14/go.mod h1:Q5KZ1vD3V5FEzjM79hjwVrC3ABr7F5IdM23bXQMRDGg=

go.sum database tree
823876
ZBYxqpUFH3ncXs339d5qBfgo3tHnWPr8D10JLtW4Jck=

— sum.golang.org Az3grhvh6SDXL4PTk3rZJCs2x9Bbgfz5u1PudLDRYcToGxRUazHb59qSrBx9GeniTj8AO7zSFKQyBNHS+13M4FcFMQo=
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;proxyを通すことでオリジナルのリポジトリが消えてビルドできなくなるのを回避でき、
コミット履歴を含まないコードを持って来るので高速化される。一度proxyに乗ったバージョンは取り下げられない。
また、sumに問い合わせることで、初回getで &lt;code&gt;go.sum&lt;/code&gt; がなくてもコードの真正性を保証でき、
他のproxyを使ったとしてもセキュリティが担保される。&lt;/p&gt;

&lt;h3 id=&#34;環境変数-https-golang-org-doc-go1-13-modules&#34;&gt;&lt;a href=&#34;https://golang.org/doc/go1.13#modules&#34;&gt;環境変数&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;GOPROXY&lt;/code&gt; / &lt;code&gt;GOSUMDB&lt;/code&gt; で向き先を変えることができる。
例えば、&lt;code&gt;GOPROXY&lt;/code&gt; をdirectのみにするとproxyは使われない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go version
go version go1.13 darwin/azmd64

$ go env GOPROXY
https://proxy.golang.org,direct

$ go env GOSUMDB
sum.golang.org

$ go env -w GOPROXY=direct
$ go env -w GOSUMDB=off
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、 &lt;code&gt;GOPRIVATE&lt;/code&gt; のパスに前方一致するmoduleはproxyおよびsumdbの対象外になる。
&lt;code&gt;GONOPROXY&lt;/code&gt; / &lt;code&gt;GONOSUMDB&lt;/code&gt; を設定すると別個にオーバーライドされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go env -w GOPRIVATE=*.example.com,*.example.net/foo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sumからアクセスできないprivateなmoduleをgo getしようとすると &lt;code&gt;410 Gone&lt;/code&gt; になってしまうので &lt;code&gt;GOPRIVATE&lt;/code&gt; に入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/sambaiz/test-private-go-module
go: finding github.com/sambaiz/test-private-go-module latest
go: downloading github.com/sambaiz/test-private-go-module v0.0.0-20200301002106-c8098ddbacf5
verifying github.com/sambaiz/test-private-go-module@v0.0.0-20200301002106-c8098ddbacf5: github.com/sambaiz/test-private-go-module@v0.0.0-20200301002106-c8098ddbacf5: reading https://sum.golang.org/lookup/github.com/sambaiz/test-private-go-module@v0.0.0-20200301002106-c8098ddbacf5: 410 Gone

$ go env -w GOPRIVATE=github.com/sambaiz/test-private-go-module
$ go get github.com/sambaiz/test-private-go-module
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DAX (DynamoDB Accelerator)の特性と挙動確認</title>
          <link>https://www.sambaiz.net/article/260/</link>
          <pubDate>Wed, 26 Feb 2020 23:21:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/260/</guid>
          <description>

&lt;h2 id=&#34;daxとは&#34;&gt;DAXとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/dynamodb/dax/&#34;&gt;DAX&lt;/a&gt;はDynamoDBの前段に置かれるマネージドなインメモリキャッシュで、
Read速度の向上(数ms-&amp;gt;数百μs)とテーブルのRead Capacityの節約に効果がある。&lt;/p&gt;

&lt;p&gt;DynamoDBとSDKのAPIの互換性があるため置き換えるだけで使えるようになっている。
クライアントの実装としてはHTTPではない独自のプロトコルで&lt;a href=&#34;https://github.com/aws/aws-dax-go/blob/19b34c5c99ea4b76610dcbae7d87fd572de012df/dax/internal/client/single.go#L278&#34;&gt;通信している&lt;/a&gt;点が異なる。&lt;/p&gt;

&lt;p&gt;クラスタ作成時に指定するのはノード数とインスタンスタイプで、
ノード数はスループットに、インスタンスタイプはスループットとメモリ量(キャッシュヒット率)に&lt;a href=&#34;https://docs.amazonaws.cn/en_us/amazondynamodb/latest/developerguide/DAX.concepts.cluster.html#DAX.concepts.nodes&#34;&gt;影響する&lt;/a&gt;。
複数のノードがある場合、一つがWriteするプライマリーノードになり、他はリードレプリカになる。
なのでノード数を増やしてもWriteのスループットは上がらない。プライマリーノードに問題が発生したら&lt;a href=&#34;https://docs.amazonaws.cn/en_us/amazondynamodb/latest/developerguide/DAX.concepts.cluster.html#DAX.concepts.clusters&#34;&gt;自動でフェイルオーバーする&lt;/a&gt;。
ノードは最大10個まで増減できるが、インスタンスタイプは変更できない。最大10個というのは足りるのかと思ったが、数百万RPS捌けるようなので十分そうだ。&lt;/p&gt;

&lt;p&gt;インスタンスに対して時間課金が発生し、可用性のために3ノード以上にすることが推奨されている。
そのため、リクエストがそれほどなかったり、キャッシュミスばかりだとインスタンス代の方が高くつくこともあるが、
そこそこReadするなら目に見えてコスト削減されるはずだ。ただしどれくらい次の整合性を許容できるかによる。&lt;/p&gt;

&lt;h2 id=&#34;キャッシュの整合性-https-docs-aws-amazon-com-ja-jp-amazondynamodb-latest-developerguide-dax-consistency-html&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/DAX.consistency.html&#34;&gt;キャッシュの整合性&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;DAXはDynamoDBとは異なり、&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html&#34;&gt;結果整合性のある読み込み(Eventually Consistent Reads)&lt;/a&gt;のみをサポートしているので、プライマリノードにキャッシュされ、全てのノードにレプリケーションが完了するまでの間は異なる結果を返す可能性がある。また、DAXからDynamoDBへのリクエストも結果整合性のある読み込みで行われる。&lt;/p&gt;

&lt;p&gt;リクエストの結果は、Itemがなかった場合のネガティブキャッシュも含めて、
Item Cache(&lt;code&gt;GetItem&lt;/code&gt;,&lt;code&gt;BatchGetItem&lt;/code&gt;)とQuery Cache(&lt;code&gt;Query&lt;/code&gt;,&lt;code&gt;Scan&lt;/code&gt;)にキャッシュされ、
それぞれパラメータグループで設定された&lt;a href=&#34;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.cluster-management.html#DAX.cluster-management.custom-settings.ttl&#34;&gt;TTL&lt;/a&gt;が過ぎるか、LRUアルゴリズムによって破棄される。
TTLのデフォルトは5分。&lt;/p&gt;

&lt;p&gt;書き込みリクエストが来るとまずDynamoDBに書き込んで成功したことを確認してからキャッシュしてレスポンスを返す。
この際Item Cacheは更新されるが、Query Cacheは更新されずTTL/LRUによって破棄されるまで同じ値を返し続けてしまう。
もし問題がある場合は、TTLを短くするかDynamoDBを直接見に行くことになるが、そうするとDAXの効果が薄れてしまう。
また、大量のデータを書き込むと、その分レイテンシが増加したり、それらがすべてキャッシュに乗ることで既存のものがLRUで追い出されてキャッシュヒット率が悪くなることがあり、それらを回避するため直接書き込むという選択肢もあるが、Item Cacheが更新されないことを許容する必要がある。&lt;/p&gt;

&lt;h2 id=&#34;取れるメトリクス&#34;&gt;取れるメトリクス&lt;/h2&gt;

&lt;p&gt;CPU使用率や、キャッシュヒット数、各リクエスト数や接続数が取れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/260.png&#34; alt=&#34;メトリクス&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ノードごとのCPU使用率も取れる。Writeやキャッシュミスによるプライマリーノードの負荷の高まりに注意。
レイテンシが大きくなり接続数が増える悪循環に陥る。&lt;/p&gt;

&lt;h2 id=&#34;挙動確認&#34;&gt;挙動確認&lt;/h2&gt;

&lt;p&gt;DAX/DynamoへリクエストするだけだったらLambdaでも良いが、負荷をかけるのでECS上にアプリケーションをデプロイすることにした。
以前作ったBoilerplateベースで、コードは&lt;a href=&#34;https://github.com/sambaiz/dax-test&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/259/&#34;&gt;ECSでアプリケーションを動かすBoilerplateを作った - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;TableとDAXのClusterを作成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;createDynamoTable() {
  return new dynamodb.Table(this, &#39;DynamoTable&#39;, {
    tableName: &amp;quot;dax-test-table&amp;quot;,
    partitionKey: { name: &#39;id&#39;, type: dynamodb.AttributeType.STRING },
    readCapacity: 50,
    writeCapacity: 50,
  });
}

createDaxCluster(subnetIds: string[]) {
  const subnetGroup = new dax.CfnSubnetGroup(this, &#39;DaxSubnetGroup&#39;, {
    subnetGroupName: &amp;quot;dax-test-subntgroup&amp;quot;,
    description: &amp;quot;for dax test&amp;quot;,
    subnetIds: subnetIds,
  })
  const daxRole = new iam.Role(this, &#39;DaxRole&#39;, {
    assumedBy: new iam.ServicePrincipal(&#39;dax.amazonaws.com&#39;),
    managedPolicies: [
      iam.ManagedPolicy.fromAwsManagedPolicyName(&#39;AmazonDynamoDBFullAccess&#39;)
    ]
  })
  return new dax.CfnCluster(this, &#39;DaxCluster&#39;, {
    clusterName: &amp;quot;dax-test&amp;quot;,
    nodeType: &amp;quot;dax.r4.large&amp;quot;,
    replicationFactor: 1,
    iamRoleArn: daxRole.roleArn,
    subnetGroupName: subnetGroup.subnetGroupName,
  })
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DynamoDBとinterfaceが同じなので&lt;a href=&#34;https://github.com/guregu/dynamo&#34;&gt;guregu/dynamo&lt;/a&gt;もそのまま使えた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newDynamoClient(tableName string, throughDax bool) (*dynamo.DB, error) {
	var (
		client dynamodbiface.DynamoDBAPI
		err    error
	)
	if throughDax {
		cfg := dax.DefaultConfig()
		cfg.HostPorts = []string{os.Getenv(&amp;quot;DAX_CLUSTER_URL&amp;quot;)}
		cfg.Region = os.Getenv(&amp;quot;AWS_REGION&amp;quot;)
		client, err = dax.New(cfg)
		if err != nil {
			return nil, err
		}
	} else {
		client = dynamodb.New(session.New())
	}
	return dynamo.NewFromIface(client), nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DAXを通したときと通さなかった時の差を確認するため、クエリパラメータで振り分けるようにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func handleItem(db *dynamo.DB, dax *dynamo.DB) func(w http.ResponseWriter, r *http.Request) {
	return auth(func(w http.ResponseWriter, r *http.Request) {
		client := db
		if r.URL.Query().Get(&amp;quot;dax&amp;quot;) == &amp;quot;1&amp;quot; {
			client = dax
		}
		switch r.Method {
		case http.MethodGet:
			var item item
			before := time.Now()
			if err := client.Table(tableName).Get(&amp;quot;id&amp;quot;, r.URL.Query().Get(&amp;quot;id&amp;quot;)).One(&amp;amp;item); err != nil {
				if err != dynamo.ErrNotFound {
					log.Printf(&amp;quot;failed to get an item: %v&amp;quot;, err)
					http.Error(w, &amp;quot;Internal Server Error&amp;quot;, http.StatusInternalServerError)
				}
				return
			}
			fmt.Fprintln(w, response{
				Message:      r.URL.Query().Get(&amp;quot;message&amp;quot;),
				TimeMicrosec: time.Now().Sub(before).Nanoseconds() / 1000,
			})
		...
		}
	})
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初期データを挿入する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ BASE_URL=http://***
$ TOKEN=DAXTEST
$ curl -X POST -H &amp;quot;Authorization: token ${TOKEN}&amp;quot; &amp;quot;${BASE_URL}/initialize&amp;quot;
ok
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;read速度の向上&#34;&gt;Read速度の向上&lt;/h3&gt;

&lt;p&gt;DynamoDBとDAXにそれぞれ&lt;code&gt;GetItem&lt;/code&gt;すると、DynamoDBは5ms前後かかるところ、DAXはキャッシュされてからは500-1000μs前後で返ってきた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -H &amp;quot;Authorization: token ${TOKEN}&amp;quot; &amp;quot;${BASE_URL}/item?id=1&amp;quot;
{ 4768}

$ curl -H &amp;quot;Authorization: token ${TOKEN}&amp;quot; &amp;quot;${BASE_URL}/item?id=1&amp;amp;dax=1&amp;quot;
{ 30628}

$ curl -H &amp;quot;Authorization: token ${TOKEN}&amp;quot; &amp;quot;${BASE_URL}/item?id=1&amp;amp;dax=1&amp;quot;
{ 593}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一方書き込みは前述したように遅くなる。思いの外差があった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X POST -H &amp;quot;Authorization: token ${TOKEN}&amp;quot; &amp;quot;${BASE_URL}/item&amp;quot; --data &#39;{&amp;quot;id&amp;quot;: &amp;quot;AAA&amp;quot;, &amp;quot;title&amp;quot;: &amp;quot;aaa&amp;quot;}&#39;
{ 6135}

$ curl -X POST -H &amp;quot;Authorization: token ${TOKEN}&amp;quot; &amp;quot;${BASE_URL}/item?dax=1&amp;quot; --data &#39;{&amp;quot;id&amp;quot;: &amp;quot;BBB&amp;quot;, &amp;quot;title&amp;quot;: &amp;quot;bbb&amp;quot;}&#39;
{ 39011}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;read-capacityの節約&#34;&gt;Read capacityの節約&lt;/h3&gt;

&lt;p&gt;全てキャッシュヒットするパターンで負荷をかけてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ulimit -n 2000
$ ab -n 10000 -c 1000 -r -H &amp;quot;Authorization: token ${TOKEN}&amp;quot; &amp;quot;${BASE_URL}/item?id=1&amp;amp;dax=1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;裏側のTableのキャパシティが全く使われないことを確認できた。&lt;/p&gt;

&lt;h3 id=&#34;ノードが落ちたときの挙動&#34;&gt;ノードが落ちたときの挙動&lt;/h3&gt;

&lt;p&gt;ノードを1台にして再起動するとnetwork errorになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;failed to get an item: InternalServerError: network error
caused by: dial tcp 172.31.34.26:8111: connect: connection refused
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ノードを2台に増やし、
負荷をかけている途中におそらくプライマリーノードであろう最初の1台を落としてみる。
フェイルオーバー中にいくらかエラーが返ることを想定していたが、そんなこともなく全て200で返った。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ab -n 20000 -c 10 -r -H &amp;quot;Authorization: token ${TOKEN}&amp;quot; &amp;quot;${BASE_URL}/item?id=1&amp;amp;dax=1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ECSでアプリケーションを動かすBoilerplateを作った</title>
          <link>https://www.sambaiz.net/article/259/</link>
          <pubDate>Mon, 24 Feb 2020 16:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/259/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/ecs-boilerplate&#34;&gt;https://github.com/sambaiz/ecs-boilerplate&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ECS上でアプリケーションを動かすBoilerplateを作った。CDKでデプロイする。以前Digdagを動かしたときのを汎用的にしたもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/234/&#34;&gt;CDKでECS+Fargate上にDigdagを立ててCognito認証を挟む - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new ECSStack(app, &#39;ECSBoilerplateSampleStack&#39;, {
    /*
    // If vpcAttributes is not specified, new VPC is created.
    vpcAttributes: {
        vpcId: &#39;&#39;,
        availabilityZones: [],
        publicSubnetIds: [],
        privateSubnetIds: [],
    },

    // DNS record. Even if this is not specified, you can access with ELB domain (***.elb.amazonaws.com)
    route53: {
        zoneId: &#39;&#39;,
        zoneName: &#39;example.com&#39;,
        recordName: &#39;foo&#39;,
    },
    // Certificate Manager ARN. Required if accessing with HTTPS
    acmArn: &#39;arn:aws:acm:****&#39;

    // default values
    containerPort: 8080,
    cpu: 256,
    memoryLimitMiB: 512,
    minCapacity: 1,
    maxCapacity: 5,
    scaleCPUPercent: 80
    */
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CDKがECRへのpushまでやってくれるので&lt;code&gt;cdk deploy&lt;/code&gt;すれば動き始め、削除するときもStackを消せばよい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Makefile
.PHONY: deploy destroy

deploy:
	cd cdk &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; npm run cdk -- deploy

destroy:
	cd cdk &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run cdk -- destroy
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AndroidのListViewで再利用されるViewのgetGlobalVisibleRect()が意図した値を返さない</title>
          <link>https://www.sambaiz.net/article/257/</link>
          <pubDate>Tue, 11 Feb 2020 01:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/257/</guid>
          <description>

&lt;h2 id=&#34;listviewのviewの再利用&#34;&gt;ListViewのViewの再利用&lt;/h2&gt;

&lt;p&gt;まずはListViewのViewが再利用されていることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package com.example.listviewglobalvisiblerect

import android.widget.BaseAdapter
import android.content.Context
import android.view.View
import android.view.ViewGroup
import android.app.Activity
import android.graphics.Color
import android.graphics.Rect
import android.util.Log
import android.widget.TextView


data class SampleData(val id: Long, val value: String)

class SampleAdapter: BaseAdapter {
    private val context: Context
    private val items: List&amp;lt;SampleData&amp;gt;
    private val views = ArrayList&amp;lt;View&amp;gt;()

    constructor(context: Context, items: List&amp;lt;SampleData&amp;gt;) {
        this.context = context
        this.items = items
    }

    override fun getCount(): Int {
        return items.size
    }

    override fun getItem(position: Int): Any {
        return items.get(position)
    }

    override fun getItemId(position: Int): Long {
        return items.get(position).id
    }

    override fun getView(position: Int, convertView: View?, container: ViewGroup?): View {
        var view = convertView ?: (this.context as Activity).layoutInflater.inflate(R.layout.sample_list_item, container, false)
        if (convertView == null) {
            Log.v(&amp;quot;SampleAdapter&amp;quot;, &amp;quot;view ${position} is created&amp;quot;)
            view.tag = position
            if (position == 0) {
                view.setBackgroundColor(Color.LTGRAY)
            }
            views.add(view)
        } else {
            Log.v(&amp;quot;SampleAdapter&amp;quot;, &amp;quot;view ${convertView.tag} is recycled at ${position}&amp;quot;)
        }
        view.findViewById&amp;lt;TextView&amp;gt;(R.id.text_view).setText(items.get(position).value)
        return view
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;position == 0&lt;/code&gt; のCellだけ生成時に背景色を灰色にしたところ、他のpositionでも再利用された灰色のCellが登場した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/257.png&#34; alt=&#34;再利用されて色が変わったままのCell&#34; /&gt;&lt;/p&gt;

&lt;p&gt;画面に表示される分のViewが生成され、スクロールすると画面外に出たViewが再利用された。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;V/SampleAdapter: view 0 is created
V/SampleAdapter: view 1 is created
V/SampleAdapter: view 2 is created
V/SampleAdapter: view 3 is created
V/SampleAdapter: view 4 is created
V/SampleAdapter: view 0 is recycled at 5
V/SampleAdapter: view 1 is recycled at 6
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;各viewにgetglobalvisiblerect-を実行した結果&#34;&gt;各ViewにgetGlobalVisibleRect()を実行した結果&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.android.com/reference/android/view/View.html#getGlobalVisibleRect(android.graphics.Rect)&#34;&gt;getGlobalVisibleRect()&lt;/a&gt;はViewの可視領域を取得できる関数で、領域がない場合falseを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;views.forEach { v -&amp;gt;
    var rect = Rect();
    if (v.getGlobalVisibleRect(rect)) {
        Log.v(&amp;quot;SampleAdapter&amp;quot;, &amp;quot;view ${v.tag} visible rect: ${rect} has_parent: ${v.parent != null}&amp;quot;)
    } else {
        Log.v(&amp;quot;SampleAdapter&amp;quot;, v.tag.toString() + &amp;quot; is not visible&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再利用待ち(&lt;code&gt;parent=false&lt;/code&gt;)の画面内にないView 1はfalseを返すと思っていたが、実際はtrueを返し正しくない値が入ってしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;V/SampleAdapter: view 0 visible rect: Rect(0, 1520 - 1080, 2018) has_parent: true
V/SampleAdapter: view 1 visible rect: Rect(0, 0 - 1185, 498) has_parent: false
V/SampleAdapter: view 2 visible rect: Rect(0, 66 - 1080, 515) has_parent: true
V/SampleAdapter: view 3 visible rect: Rect(0, 518 - 1080, 1016) has_parent: true
V/SampleAdapter: view 4 visible rect: Rect(0, 1019 - 1080, 1517) has_parent: true
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Buildkitとは</title>
          <link>https://www.sambaiz.net/article/258/</link>
          <pubDate>Tue, 11 Feb 2020 01:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/258/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/moby/buildkit&#34;&gt;Buildkit&lt;/a&gt;は高速でセキュアなコンテナイメージのビルドツール。
Docker本体にも18.09から&lt;a href=&#34;https://docs.docker.com/develop/develop-images/build_enhancements/&#34;&gt;統合され&lt;/a&gt;、
&lt;code&gt;DOCKER_BUILDKIT=1 docker build&lt;/code&gt; するとBuildkitが使われるようになった。&lt;/p&gt;

&lt;h3 id=&#34;llb-low-level-builder&#34;&gt;LLB (low-level builder)&lt;/h3&gt;

&lt;p&gt;BuildkitはDockerfileなどをLLBという中間言語にコンパイルする。
LLBは依存関係を表すDAG(Directed acyclic graph; 有向非巡回グラフ)で、
protobufで&lt;a href=&#34;https://github.com/moby/buildkit/blob/758c61e8730eac0da8a8cce72ec4009868c92165/solver/pb/ops.proto&#34;&gt;定義されている&lt;/a&gt;。
これによって処理を並列に実行したり、Dockerfileを変更してもそれ以降のステージのキャッシュを全て破棄する必要がなくなった。&lt;/p&gt;

&lt;h3 id=&#34;mount-type-cache&#34;&gt;&lt;code&gt;--mount=type=cache&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;Dockerfileを変更しても残せるキャッシュ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# syntax = docker/dockerfile:1.1-experimental
FROM golang

RUN --mount=type=cache,target=/root/.cache/go-build \ 
    go build ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;mount-type-secret&#34;&gt;&lt;code&gt;--mount=type=secret&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;秘密鍵など一度ADDしてしまったファイルは最終的に消してもレイヤ上に残ってしまうが、&lt;code&gt;--mount=type=secret&lt;/code&gt; でマウントすると残らない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# syntax = docker/dockerfile:1.1-experimental
FROM alpine:20200122

RUN apk add --no-cache git openssh

RUN --mount=type=secret,id=ssh,dst=/root/.ssh/id_rsa \
    ssh-keyscan -H github.com &amp;gt;&amp;gt; /root/.ssh/known_hosts &amp;amp;&amp;amp; \
    git clone ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_BUILDKIT=1 docker build --secret id=ssh,src=./id_rsa .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.mobyproject.org/introducing-buildkit-17e056cc5317&#34;&gt;Introducing BuildKit - Moby Blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/nttlabs/docker-v18-09-%E6%96%B0%E6%A9%9F%E8%83%BD-%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8%E3%83%93%E3%83%AB%E3%83%89-%E3%82%BB%E3%82%AD%E3%83%A5%E3%83%AA%E3%83%86%E3%82%A3-9534714c26e2&#34;&gt;Docker 18.09 新機能 (イメージビルド&amp;amp;セキュリティ) - nttlabs - Medium&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SwiftでGCDのDispatchQueueに処理を投げて並列実行させる</title>
          <link>https://www.sambaiz.net/article/256/</link>
          <pubDate>Sat, 25 Jan 2020 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/256/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://developer.apple.com/documentation/DISPATCH&#34;&gt;GCD (Grand Central Dispatch)&lt;/a&gt;はmacOSやiOSのマルチコア環境で、
効率的に並列処理を実行するための仕組み。
&lt;a href=&#34;https://developer.apple.com/documentation/foundation/operationqueue&#34;&gt;OperationQueue&lt;/a&gt;というのもあるが、これもGCD上で動く。&lt;/p&gt;

&lt;h2 id=&#34;dispatchqueue-https-developer-apple-com-documentation-dispatch-dispatchqueue&#34;&gt;&lt;a href=&#34;https://developer.apple.com/documentation/dispatch/dispatchqueue&#34;&gt;DispatchQueue&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;処理をどのスレッドで実行するか管理するキュー。
どこからでも参照できるmainとglobalのキュー以外に新しくキューを作成することもできる。
labelは衝突しないようにreverse-DNS nameにすることが推奨されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DispatchQueue.main.async {}
DispatchQueue.global(qos: .default).async {}
DispatchQueue.global(qos: .background).async {}
DispatchQueue(label: &amp;quot;net.sambaiz.serial_dispatch_queue&amp;quot;).async {}
DispatchQueue(label: &amp;quot;net.sambaiz.concurrent_dispatch_queue&amp;quot;, attributes: .concurrent).async {}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;sync-async&#34;&gt;sync/async&lt;/h3&gt;

&lt;p&gt;ブロッキングする&lt;code&gt;sync()&lt;/code&gt;としない&lt;code&gt;async()&lt;/code&gt;。排他制御ではないのに注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DispatchQueue.global().async {
    print(&amp;quot;async&amp;quot;)
    DispatchQueue.main.sync { print(&amp;quot;sync&amp;quot;) }
    print(&amp;quot;done&amp;quot;)
}
print(&amp;quot;run&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;run
async
sync
done
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;serial-concurrent&#34;&gt;serial/concurrent&lt;/h3&gt;

&lt;p&gt;処理を単一のスレッドで行う(serial)か、複数のスレッドで行う(concurrent)かはキューによって決まり、
メインスレッドで動かすmainはserial、globalはconcurrentになっている。
自作のキューの場合は作成時に &lt;code&gt;attributes: .concurrent&lt;/code&gt; を渡すとconcurrentになり、渡さないとserialになる。&lt;/p&gt;

&lt;p&gt;まずはconcurrentの例から。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in 1...3 {
    DispatchQueue.global().async {
        print(&amp;quot;start concurrent \(i) thread: \(Thread.current)&amp;quot;)
        print(&amp;quot;return concurrent \(i) thread: \(Thread.current)&amp;quot;)
    }
}
print(&amp;quot;return thread: \(Thread.current)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;別スレッドで並列に動いている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;start concurrent 3 thread: &amp;lt;NSThread: 0x600001646440&amp;gt;{number = 5, name = (null)}
start concurrent 2 thread: &amp;lt;NSThread: 0x600001631600&amp;gt;{number = 6, name = (null)}
return thread: &amp;lt;NSThread: 0x60000160a8c0&amp;gt;{number = 1, name = main}
start concurrent 1 thread: &amp;lt;NSThread: 0x600001640b80&amp;gt;{number = 7, name = (null)}
return concurrent 1 thread: &amp;lt;NSThread: 0x600001640b80&amp;gt;{number = 7, name = (null)}
return concurrent 3 thread: &amp;lt;NSThread: 0x600001646440&amp;gt;{number = 5, name = (null)}
return concurrent 2 thread: &amp;lt;NSThread: 0x600001631600&amp;gt;{number = 6, name = (null)}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にserialの例。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in 1...3 {
    DispatchQueue.global().async {
        print(&amp;quot;start concurrent \(i) thread: \(Thread.current)&amp;quot;)
        DispatchQueue.main.sync {
            print(&amp;quot;  start serial \(i) thread: \(Thread.current)&amp;quot;)
            print(&amp;quot;  return serial \(i) thread: \(Thread.current)&amp;quot;)
        }
        print(&amp;quot;return concurrent \(i) thread: \(Thread.current)&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;シングルスレッドで、ある処理が実行されている間は他の処理が走っていない。
古くからある&lt;a href=&#34;https://developer.apple.com/documentation/foundation/nslock&#34;&gt;NSLock&lt;/a&gt;でも排他制御することはできるが、
&lt;a href=&#34;https://developer.apple.com/library/archive/documentation/General/Conceptual/ConcurrencyProgrammingGuide/ThreadMigration/ThreadMigration.html#//apple_ref/doc/uid/TP40008091-CH105-SW3&#34;&gt;コストが高い&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;start concurrent 1 thread: &amp;lt;NSThread: 0x600001c0c200&amp;gt;{number = 5, name = (null)}
start concurrent 3 thread: &amp;lt;NSThread: 0x600001c60080&amp;gt;{number = 6, name = (null)}
start concurrent 2 thread: &amp;lt;NSThread: 0x600001c26200&amp;gt;{number = 4, name = (null)}
  start serial 1 thread: &amp;lt;NSThread: 0x600001c2a8c0&amp;gt;{number = 1, name = main}
  return serial 1 thread: &amp;lt;NSThread: 0x600001c2a8c0&amp;gt;{number = 1, name = main}
  start serial 2 thread: &amp;lt;NSThread: 0x600001c2a8c0&amp;gt;{number = 1, name = main}
return concurrent 1 thread: &amp;lt;NSThread: 0x600001c0c200&amp;gt;{number = 5, name = (null)}
  return serial 2 thread: &amp;lt;NSThread: 0x600001c2a8c0&amp;gt;{number = 1, name = main}
  start serial 3 thread: &amp;lt;NSThread: 0x600001c2a8c0&amp;gt;{number = 1, name = main}
return concurrent 2 thread: &amp;lt;NSThread: 0x600001c26200&amp;gt;{number = 4, name = (null)}
  return serial 3 thread: &amp;lt;NSThread: 0x600001c2a8c0&amp;gt;{number = 1, name = main}
return concurrent 3 thread: &amp;lt;NSThread: 0x600001c60080&amp;gt;{number = 6, name = (null)}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/mixi-inc/iOSTraining/blob/master/Swift/pages/day3/1-2_Grand-Central-Dispatch.md&#34;&gt;iOSTraining/1-2_Grand-Central-Dispatch.md at master · mixi-inc/iOSTraining&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>貪欲法(Greedy algorithm)で問題を解く</title>
          <link>https://www.sambaiz.net/article/255/</link>
          <pubDate>Mon, 13 Jan 2020 21:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/255/</guid>
          <description>

&lt;p&gt;貪欲法(Greedy algorithm)は問題を分割し、それぞれにおいて貪欲に最適な選択をしていくアルゴリズムの総称。
必ずしも最適解になるとは限らないが、うまくいけば簡潔に計算量を減らすことができる。&lt;/p&gt;

&lt;h2 id=&#34;best-time-to-buy-and-sell-stock-ii-leetcode-https-leetcode-com-problems-best-time-to-buy-and-sell-stock-ii&#34;&gt;&lt;a href=&#34;https://leetcode.com/problems/best-time-to-buy-and-sell-stock-ii/&#34;&gt;Best Time to Buy and Sell Stock II - LeetCode&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;配列で株価が与えられ、売買して得られる最大の利益を返す問題。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Say you have an array for which the ith element is the price of a given stock on day i.
Design an algorithm to find the maximum profit. You may complete as many transactions as you like (i.e., buy one and sell one share of the stock multiple times).

Example 1:
Input: [7,1,5,3,6,4]
Output: 7
Explanation: Buy on day 2 (price = 1) and sell on day 3 (price = 5), profit = 5-1 = 4.
             Then buy on day 4 (price = 3) and sell on day 5 (price = 6), profit = 6-3 = 3.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;局所的な利益の最大化が単純に全体の利益の最大化になるので、上がるなら持ち続け、下がるなら売るのが最適。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Solution {
public:
    int maxProfit(vector&amp;lt;int&amp;gt;&amp;amp; prices) {
        if (prices.size() &amp;lt;= 1) {
            return 0;
        }
        int ret = 0;
        int buyidx = 0;
        for (int i = 1; i &amp;lt; prices.size(); i++) {
            if (prices[i] &amp;gt;= prices[i-1]) {
                continue;
            }
            ret += prices[i-1] - prices[buyidx];
            buyidx = i;
        }
        ret += prices[prices.size()-1] - prices[buyidx];
        return ret;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://leetcode.com/problems/wiggle-subsequence/&#34;&gt;Wiggle Subsequence - LeetCode&lt;/a&gt;も同様に解ける。&lt;/p&gt;

&lt;h2 id=&#34;jump-game-leetcode-https-leetcode-com-problems-jump-game&#34;&gt;&lt;a href=&#34;https://leetcode.com/problems/jump-game/&#34;&gt;Jump Game - LeetCode&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;最大配列の数字の分進めて、最初のindexから最後のindexに到達できるかを返す問題。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Given an array of non-negative integers, you are initially positioned at the first index of the array.
Each element in the array represents your maximum jump length at that position.
Determine if you are able to reach the last index.

Example 1:
Input: [2,3,1,1,4]
Output: true
Explanation: Jump 1 step from index 0 to 1, then 3 steps to the last index.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前から探索するといくつ進めばいいのか分からないので、
後ろから辿り、終わりまで到達できる地点を見つけたら、次はその地点まで到達できる地点を探すというのを繰り返し、先頭まで繋がるかどうかで判定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Solution {
public:
    bool canJump(vector&amp;lt;int&amp;gt;&amp;amp; nums) {
        int pos = nums.size() - 1;
        for (int i = nums.size() - 2; i &amp;gt;= 0; i--) {
            if (pos &amp;lt;= i + nums[i]) {
                pos = i;   
            }
        }
        return pos == 0;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;jump-game-ii-leetcode-https-leetcode-com-problems-jump-game-ii&#34;&gt;&lt;a href=&#34;https://leetcode.com/problems/jump-game-ii/&#34;&gt;Jump Game II - LeetCode&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Jump Gameの最短ジャンプ回数を返す版。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Given an array of non-negative integers, you are initially positioned at the first index of the array.
Each element in the array represents your maximum jump length at that position.
Your goal is to reach the last index in the minimum number of jumps.

Example:
Input: [2,3,1,1,4]
Output: 2
Explanation: The minimum number of jumps to reach the last index is 2.
    Jump 1 step from index 0 to 1, then 3 steps to the last index.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後ろから辿っていくのはJump Gameと同様だが、最短回数にするため、到達できる地点を見つけるたびにそれまでの地点に止まる必要があるかを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Solution {
public:
    int jump(vector&amp;lt;int&amp;gt;&amp;amp; nums) {
        if (nums.size() &amp;lt;= 1) {
            return 0;
        }
        int pos = nums.size() - 1;
        deque&amp;lt;int&amp;gt; stops = {pos};
        for (int i = nums.size() - 2; i &amp;gt;= 0; i--) {
            if (pos &amp;lt;= i + nums[i]) {
                stops.push_back(pos);
                pos = i;
                while(stops.size() &amp;gt;= 2) {
                    if (stops[stops.size() - 2] &amp;gt; i + nums[i]) {
                        break;
                    }
                    stops.pop_back();
                }
            }
        }
        return stops.size();
    }
};
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Objective-CでFrameworkを作りSwiftからimportする</title>
          <link>https://www.sambaiz.net/article/254/</link>
          <pubDate>Sun, 12 Jan 2020 17:41:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/254/</guid>
          <description>

&lt;h2 id=&#34;frameworkの作成&#34;&gt;Frameworkの作成&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;New -&amp;gt; Project&lt;/code&gt;でFrameworkをLanguage Objective-Cで作成。&lt;/p&gt;

&lt;p&gt;最低限の実装とHeaderを書いた。このHeaderはBuild PhasesのHeadersにPublicとして登録されている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TestObjcFramework.m&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#import &amp;lt;Foundation/Foundation.h&amp;gt;

void hello() {
    NSLog(@&amp;quot;hello&amp;quot;);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;TestObjcFramework.h&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#import &amp;lt;UIKit/UIKit.h&amp;gt;

//! Project version number for TestObjcFramework.
FOUNDATION_EXPORT double TestObjcFrameworkVersionNumber;

//! Project version string for TestObjcFramework.
FOUNDATION_EXPORT const unsigned char TestObjcFrameworkVersionString[];

// In this header, you should import all the public headers of your framework using statements like #import &amp;lt;TestObjcFramework/PublicHeader.h&amp;gt;

void hello(void);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;arm64(実機)/x86_64(Simulator)両方で使えるUniversal Frameworkをビルドするため、
&lt;code&gt;New -&amp;gt; Target&lt;/code&gt;でAggregateを作成し、Build PhasesのNew Run Script Phaseで、
各環境で&lt;code&gt;xcodebuild&lt;/code&gt;して&lt;code&gt;lipo&lt;/code&gt;でUniversal Binaryにする次のスクリプトを追加する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gist.github.com/cromandini/1a9c4aeab27ca84f5d79#file-universal-framework-sh&#34;&gt;https://gist.github.com/cromandini/1a9c4aeab27ca84f5d79#file-universal-framework-sh&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/254.png&#34; alt=&#34;Build Phases&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Targetを追加したAggregateにしてビルドするとFrameworkができる。
Frameworkはライブラリを内包したディレクトリ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tree TestObjcFramework.framework/
TestObjcFramework.framework/
├── Headers
│   └── TestObjcFramework.h
├── Info.plist
├── Modules
│   └── module.modulemap
├── TestObjcFramework
└── _CodeSignature
    └── CodeResources
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;swiftからimport&#34;&gt;Swiftからimport&lt;/h2&gt;

&lt;p&gt;適当にSingle View Appを作成。FrameworkをProjectのディレクトリ直下に置き、Dynamic frameworkなのでEmebedded BinariesにFrameworkを追加。
ビルド時に見つからなかったらBuild SettingsのFramework Search Pathsに&lt;code&gt;$(PROJECT_DIR)&lt;/code&gt;が含まれていることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import UIKit
import TestObjcFramework

class ViewController: UIViewController {

    override func viewDidLoad() {
        super.viewDidLoad()
        hello()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常Framework名と同名のHeaderがあるので誤解していたが、importのところに書くのはimportしたいHeader名ではなくFramework名。
&lt;code&gt;Modules/module.modulemap&lt;/code&gt;にumbrella headerが書かれていて、これが読まれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;framework module TestObjcFramework {
  umbrella header &amp;quot;TestObjcFramework.h&amp;quot;

  export *
  module * { export * }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>C&#43;&#43; STLのContainersとAlgorithms</title>
          <link>https://www.sambaiz.net/article/253/</link>
          <pubDate>Sat, 04 Jan 2020 21:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/253/</guid>
          <description>

&lt;p&gt;STL(Standard Template Library)はC++の標準ライブラリ。
その名の通りtemplateで実装され、様々な型で使えるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// https://github.com/microsoft/STL/blob/1e8b8d4eef4b2dddeb7533c5231c876383bd0ea6/stl/inc/algorithm#L3501
template &amp;lt;class _RanIt, class _Pr&amp;gt;
void sort(const _RanIt _First, const _RanIt _Last, _Pr _Pred) { // order [_First, _Last), using _Pred
    _Adl_verify_range(_First, _Last);
    const auto _UFirst = _Get_unwrapped(_First);
    const auto _ULast  = _Get_unwrapped(_Last);
    _Sort_unchecked(_UFirst, _ULast, _ULast - _UFirst, _Pass_fn(_Pred));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下の例は&lt;code&gt;C++14&lt;/code&gt;で、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ g++-8 -dM -E -x c++  /dev/null | grep -F __cplusplus
#define __cplusplus 201402L
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;全部入りHeader &lt;code&gt;bits/stdc++.h&lt;/code&gt; をincludeし、&lt;code&gt;std::&lt;/code&gt; を省略している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;bits/stdc++.h&amp;gt;
using namespace std;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;containers&#34;&gt;Containers&lt;/h2&gt;

&lt;p&gt;データを保存するオブジェクト。&lt;/p&gt;

&lt;h3 id=&#34;vector&#34;&gt;vector&lt;/h3&gt;

&lt;p&gt;可変長配列。ランダムアクセスが可能。末尾の挿入/削除はO(1)で、それ以外はO(n)。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector&amp;lt;int&amp;gt; vec = {3, 1, 2, 4};
vec.erase(vec.begin() + 2);
sort(vec.rbegin(), vec.rend());
vec.insert(vec.begin(), 5);
vec.push_back(6);
for (int i = 0; i &amp;lt; vec.size(); i++)
{
    cout &amp;lt;&amp;lt; vec[i] &amp;lt;&amp;lt; endl; // =&amp;gt; 5 4 3 1 6
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;list&#34;&gt;list&lt;/h3&gt;

&lt;p&gt;双方向連結リスト。メモリ領域が連続しておらず、アクセスはO(n)かかるが、挿入/削除がO(1)でできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;list&amp;lt;int&amp;gt; ls = {3, 1, 2, 4};
ls.erase(ls.begin());
ls.sort();
ls.insert(ls.begin(), 5);
ls.push_back(6);
for (list&amp;lt;int&amp;gt;::iterator it = ls.begin(); it != ls.end(); it++)
{
    cout &amp;lt;&amp;lt; *it &amp;lt;&amp;lt; endl; // =&amp;gt; 5 1 2 4 6
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;set&#34;&gt;set&lt;/h3&gt;

&lt;p&gt;集合。通常二分木が使われ、アクセスや挿入/削除するのにO(log n)かかる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;set&amp;lt;int&amp;gt; st = {3, 1, 2, 4};
st.erase(3);
st.insert(4);
st.insert(5);
if (st.find(5) != st.end())
{
    cout &amp;lt;&amp;lt; &amp;quot;5 is found&amp;quot; &amp;lt;&amp;lt; endl; // =&amp;gt; 5 is found
}
if (st.find(6) != st.end())
{
    cout &amp;lt;&amp;lt; &amp;quot;6 is found&amp;quot; &amp;lt;&amp;lt; endl;
}
for (int x : st)
{
    cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; endl; // =&amp;gt; 1 2 4 5
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;map&#34;&gt;map&lt;/h3&gt;

&lt;p&gt;連想配列。通常二分木が使われ、オーダーははsetと同じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;map&amp;lt;string, int&amp;gt; mp = {{&amp;quot;a&amp;quot;, 3}, {&amp;quot;b&amp;quot;, 4}, {&amp;quot;c&amp;quot;, 5}};
mp.erase(&amp;quot;b&amp;quot;);
mp[&amp;quot;d&amp;quot;] = 6;
if (mp.count(&amp;quot;d&amp;quot;) != 0)
{
    cout &amp;lt;&amp;lt; &amp;quot;d is found&amp;quot; &amp;lt;&amp;lt; endl; // =&amp;gt; d is found
}
if (mp.count(&amp;quot;e&amp;quot;) != 0)
{
    cout &amp;lt;&amp;lt; &amp;quot;e is found&amp;quot; &amp;lt;&amp;lt; endl;
}
for (auto it = mp.begin(); it != mp.end(); it++)
{
    cout &amp;lt;&amp;lt; it-&amp;gt;first &amp;lt;&amp;lt; &amp;quot;:&amp;quot; &amp;lt;&amp;lt; it-&amp;gt;second &amp;lt;&amp;lt; endl; // a:3 c:5 d:6
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;deque-double-ended-queue&#34;&gt;deque (double-ended queue)&lt;/h3&gt;

&lt;p&gt;O(1)で両端に挿入/削除できるキュー。deckと発音するらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;deque&amp;lt;int&amp;gt; mp = {1, 2, 3};
cout &amp;lt;&amp;lt; mp.back() &amp;lt;&amp;lt; endl;  // =&amp;gt; 3
cout &amp;lt;&amp;lt; mp.front() &amp;lt;&amp;lt; endl; // =&amp;gt; 1
mp.pop_back();
mp.pop_front();
mp.push_back(4);
mp.push_front(5);
for (int i = 0; i &amp;lt; mp.size(); i++)
{
    cout &amp;lt;&amp;lt; mp[i] &amp;lt;&amp;lt; endl; // 5 2 4
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;priority-queue&#34;&gt;priority_queue&lt;/h3&gt;

&lt;p&gt;入れた順ではなく優先度の高い順で取り出されるqueue。通常二分ヒープが使われる。
二分ヒープは子のノードが親以上(あるいは以下)の値を持つ二分木で、先頭の取り出しはO(1)だが他は基本setと同じ。
単にヒープと呼ぶこともあってメモリのヒープ領域と関係があるのかと思って調べてみたが、少なくとも今はないらしい。&lt;/p&gt;

&lt;p&gt;デフォルトの比較関数は&lt;code&gt;less&lt;/code&gt;(降順)。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector&amp;lt;int&amp;gt; vec = {3, 1, 2, 4};
priority_queue&amp;lt;int&amp;gt; Q(vec.begin(), vec.end());
Q.push(2);
while (!Q.empty())
{
    cout &amp;lt;&amp;lt; Q.top() &amp;lt;&amp;lt; endl; // 4 3 2 2 1
    Q.pop();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テンプレートパラメータで&lt;code&gt;greater&lt;/code&gt;(昇順)や自作の比較関数を指定することができる。
lambdaを使う場合、テンプレートパラメータに&lt;code&gt;decltype()&lt;/code&gt;で取った型を渡した上で、コンストラクタ引数に渡す必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;priority_queue&amp;lt;int, vector&amp;lt;int&amp;gt;, greater&amp;lt;int&amp;gt;&amp;gt; Q2(vec.begin(), vec.end());
Q2.push(2);
while (!Q2.empty())
{
    cout &amp;lt;&amp;lt; Q2.top() &amp;lt;&amp;lt; endl; // 1 2 2 3 4
    Q2.pop();
}

auto compare = [](string a, string b) { return a.size() &amp;lt; b.size(); };
priority_queue&amp;lt;string, vector&amp;lt;string&amp;gt;, decltype(compare)&amp;gt; Q3(compare);
Q3.push(&amp;quot;AAAA&amp;quot;);
Q3.push(&amp;quot;AAA&amp;quot;);
Q3.push(&amp;quot;A&amp;quot;);
while (!Q3.empty())
{
    cout &amp;lt;&amp;lt; Q3.top() &amp;lt;&amp;lt; endl; // AAAA AAA A
    Q3.pop();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h2&gt;

&lt;h3 id=&#34;for-each&#34;&gt;for_each&lt;/h3&gt;

&lt;p&gt;値を書き換えることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector&amp;lt;int&amp;gt; vec = {3, 1, 2, 4};
for_each(vec.begin(), vec.end(), [](int &amp;amp;x) { x *= 2; });
for_each(vec.begin(), vec.end(), [](int x) { cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; endl; }); // =&amp;gt; 6 2 4 8
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;sort&#34;&gt;sort&lt;/h3&gt;

&lt;p&gt;priority_queueと同様デフォルトの比較関数は&lt;code&gt;less&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector&amp;lt;string&amp;gt; vec = {&amp;quot;AAAA&amp;quot;, &amp;quot;BBB&amp;quot;, &amp;quot;CC&amp;quot;, &amp;quot;D&amp;quot;};
sort(vec.begin(), vec.end(), [](string a, string b) { return a.size() &amp;lt; b.size(); });
for_each(vec.begin(), vec.end(), [](string &amp;amp;x) { cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; endl; }); // D CC BBB AAAA
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;copy&#34;&gt;copy&lt;/h3&gt;

&lt;p&gt;指定した範囲の値を順に代入していく。
&lt;code&gt;inserter()&lt;/code&gt; と &lt;code&gt;back_inserter()&lt;/code&gt; は代入する代わりに引数の &lt;code&gt;.insert()&lt;/code&gt; や &lt;code&gt;.push_back()&lt;/code&gt; を呼ぶoutput iteratorを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector&amp;lt;int&amp;gt; vec = {3, 1, 2, 4};
copy(vec.begin(), vec.end(), back_inserter(vec));
set&amp;lt;int&amp;gt; st;
copy(vec.begin(), vec.end(), inserter(st, st.end()));
for_each(vec.begin(), vec.end(), [](int x) { cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; endl; }); // =&amp;gt; 3 1 2 4 3 1 2 4
for_each(st.begin(), st.end(), [](int x) { cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; endl; });   // =&amp;gt; 1 2 3 4
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Standard_Template_Library&#34;&gt;Standard Template Library - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ufcpp.net/study/stl&#34;&gt;C++ STL | ++C++; // 未確認飛行 C&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/h_hiro_/items/a83a8fd2391d4a3f0e1c&#34;&gt;[C++] STLの型の使い分け - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cpprefjp.github.io/&#34;&gt;cpprefjp - C++日本語リファレンス&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MacのVSCodeでC&#43;&#43;を書く環境構築</title>
          <link>https://www.sambaiz.net/article/252/</link>
          <pubDate>Sat, 04 Jan 2020 01:36:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/252/</guid>
          <description>

&lt;h2 id=&#34;extension&#34;&gt;Extension&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=ms-vscode.cpptools&#34;&gt;C/C++&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を入れてHello Worldを書いたところ、&lt;code&gt;stdio.h&lt;/code&gt;が見つからず&lt;code&gt;#include&lt;/code&gt;の行に赤線が付いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;

int main(void)
{
    printf(&amp;quot;Hello World!\n&amp;quot;);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Command Palletteから &lt;code&gt;C/C++: Edit Configurations (JSON)&lt;/code&gt; を選ぶと
&lt;code&gt;.vscode/c_cpp_properties.json&lt;/code&gt; が生成されるので編集していく。&lt;/p&gt;

&lt;p&gt;Xcode 10から&lt;code&gt;/usr/include&lt;/code&gt;にHeaderファイルが置かれなくなったようなので&lt;code&gt;includePath&lt;/code&gt;にXcodeのSDKのパスを追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ xcode-select --install
$ xcrun --show-sdk-path
/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk

$ ls -l /Library/Developer/CommandLineTools/SDKs/
total 0
drwxr-xr-x  7 root  wheel  224  7 23 08:49 MacOSX.sdk
lrwxr-xr-x  1 root  wheel   10  7 23 08:48 MacOSX10.14.sdk -&amp;gt; MacOSX.sdk

$ ls /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/ | grep &amp;quot;stdio.h&amp;quot;
_stdio.h
stdio.h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ついでに&lt;code&gt;compilerPath&lt;/code&gt;をclangにした。これはIntelliSenseをうまく働かせるための設定らしい。
clangはLLVMバックエンドのC/C++コンパイラで、Macだとgccコマンドもclangを使うようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcc -v
Apple LLVM version 10.0.1 (clang-1001.0.46.4)

$ clang -v
Apple LLVM version 10.0.1 (clang-1001.0.46.4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;c_cpp_properties.json&lt;/code&gt; はこんな感じになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;configurations&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Mac&amp;quot;,
            &amp;quot;includePath&amp;quot;: [
                &amp;quot;${workspaceFolder}/**&amp;quot;,
                &amp;quot;/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/**&amp;quot;
            ],
            &amp;quot;defines&amp;quot;: [],
            &amp;quot;macFrameworkPath&amp;quot;: [],
            &amp;quot;compilerPath&amp;quot;: &amp;quot;/usr/local/bin/clang&amp;quot;,
            &amp;quot;cStandard&amp;quot;: &amp;quot;c11&amp;quot;,
            &amp;quot;cppStandard&amp;quot;: &amp;quot;c++17&amp;quot;,
            &amp;quot;intelliSenseMode&amp;quot;: &amp;quot;clang-x64&amp;quot;
        }
    ],
    &amp;quot;version&amp;quot;: 4
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで赤線が消えた。補完や定義ジャンプ、コードフォーマッタも効いている。&lt;/p&gt;

&lt;h2 id=&#34;debug&#34;&gt;Debug&lt;/h2&gt;

&lt;p&gt;F5でStart Debuggingすると &lt;code&gt;.vscode/tasks.json&lt;/code&gt; と &lt;code&gt;.vscode/launch.json&lt;/code&gt; が生成され、ビルド後デバッグが始まる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat .vscode/tasks.json
{
    &amp;quot;tasks&amp;quot;: [
        {
            &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
            &amp;quot;label&amp;quot;: &amp;quot;clang++ build active file&amp;quot;,
            &amp;quot;command&amp;quot;: &amp;quot;/usr/bin/clang++&amp;quot;,
            &amp;quot;args&amp;quot;: [
                &amp;quot;-g&amp;quot;,
                &amp;quot;${file}&amp;quot;,
                &amp;quot;-o&amp;quot;,
                &amp;quot;${fileDirname}/${fileBasenameNoExtension}&amp;quot;
            ],
            &amp;quot;options&amp;quot;: {
                &amp;quot;cwd&amp;quot;: &amp;quot;/usr/bin&amp;quot;
            }
        }
    ],
    &amp;quot;version&amp;quot;: &amp;quot;2.0.0&amp;quot;
}

$ cat .vscode/launch.json
{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    &amp;quot;version&amp;quot;: &amp;quot;0.2.0&amp;quot;,
    &amp;quot;configurations&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;clang++ build and debug active file&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;cppdbg&amp;quot;,
            &amp;quot;request&amp;quot;: &amp;quot;launch&amp;quot;,
            &amp;quot;program&amp;quot;: &amp;quot;${fileDirname}/${fileBasenameNoExtension}&amp;quot;,
            &amp;quot;args&amp;quot;: [],
            &amp;quot;stopAtEntry&amp;quot;: false,
            &amp;quot;cwd&amp;quot;: &amp;quot;${workspaceFolder}&amp;quot;,
            &amp;quot;environment&amp;quot;: [],
            &amp;quot;externalConsole&amp;quot;: false,
            &amp;quot;MIMode&amp;quot;: &amp;quot;lldb&amp;quot;,
            &amp;quot;preLaunchTask&amp;quot;: &amp;quot;clang++ build active file&amp;quot;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/252.png&#34; alt=&#34;Debug中&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;bits-stdc-h&#34;&gt;bits/stdc++.h&lt;/h2&gt;

&lt;p&gt;競プロで使われる全部入りHeader &lt;code&gt;bits/stdc++.h&lt;/code&gt; はclangでは提供されていないので、必要な場合はgccのを持ってくる。
&lt;code&gt;includePath&lt;/code&gt;に含めたところ、いくつかの依存Headerが見つからなかったので、コピーしてきてそれらを除いた。
あるいはg++でビルドするようにしてもよい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install gcc@8
$ gcc-8 -v
gcc version 8.3.0 (Homebrew GCC 8.3.0_2)

$ cp /usr/local/Cellar/gcc@8/8.3.0_2/include/c++/8.3.0/x86_64-apple-darwin18/bits/stdc++.h .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/yoya/items/c0b26cba3c040c581643&#34;&gt;macOS Catalina(10.15) の Xcode11 だと /usr/include が無い - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>動的計画法(DP)で計算結果を再利用して計算量を減らす</title>
          <link>https://www.sambaiz.net/article/251/</link>
          <pubDate>Mon, 30 Dec 2019 19:28:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/251/</guid>
          <description>

&lt;p&gt;動的計画法(DP, Dynamic Programming)は記録した計算結果を、帰納的に求められるより大きな計算で利用するアルゴリズムの総称。
例えば、フィボナッチ数列の項&lt;code&gt;f(x)&lt;/code&gt;を求めるのに、&lt;code&gt;f(x-1)&lt;/code&gt;と&lt;code&gt;f(x-2)&lt;/code&gt;の結果を記録しておけばそれらを足すだけで済む。&lt;/p&gt;

&lt;p&gt;いくつか問題を解いてみる。&lt;/p&gt;

&lt;h2 id=&#34;longest-palindromic-substring-leetcode-https-leetcode-com-problems-longest-palindromic-substring&#34;&gt;&lt;a href=&#34;https://leetcode.com/problems/longest-palindromic-substring/&#34;&gt;Longest Palindromic Substring - LeetCode&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;文字列に含まれる最長の回文を返す問題。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.

Example 1:
Input: &amp;quot;babad&amp;quot;
Output: &amp;quot;bab&amp;quot;
Note: &amp;quot;aba&amp;quot; is also a valid answer.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最初に書いたコードはこれ。オーダーは部分文字列を網羅するのにO(n^2)＊回文かチェックするのにO(n)=O(n^3)で、タイムアウトしてしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cclass Solution {
    bool isPalindromic(string s) {
        for (int i = 0; i &amp;lt; (s.length() / 2) + 1; i++) {
            if (s[i] != s[s.length() - 1 - i]) {
                return false;
            }
        }
        return true;
    }
public:
    string longestPalindrome(string s) {
        string ret = &amp;quot;&amp;quot;;
        for (int i = 0; i &amp;lt; s.length(); i++) {
            if (ret.length() &amp;gt;= s.length() - i) {
                break;
            }
            for (int j = s.length(); j &amp;gt;= i+1; j--) {
                if (ret.length() &amp;gt;= j - i) {
                    break;
                }
                string substr = s.substr(i, j - i);
                if (isPalindromic(substr)) {
                    ret = substr;
                    break;
                }
            }
        }
        return ret;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回の問題ではある文字列&lt;code&gt;S&lt;/code&gt;が回文なら、その両端に同じ文字&lt;code&gt;c&lt;/code&gt;が付いた文字列&lt;code&gt;cSc&lt;/code&gt;も回文であることを利用し、
中央の文字を決めて、回文である限り範囲を両端に伸ばしていくことで、回文判定が両端の文字の一致だけのO(1)でできるようになった。
これにより全体のオーダーがO(n^2)に改善され、タイムアウトしなくなった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Solution {
    bool isPalindromic(string s) {
        return s[0] == s[s.length() - 1];
    }
public:
    string longestPalindrome(string s) {
        string ret = &amp;quot;&amp;quot;;
        for (int i = 0; i &amp;lt; s.length(); i++) {
            if (ret.length() &amp;gt;= min(i*2+2, int(s.length()-i)*2+2)) {
                break;
            }
            for (int j = 1; j &amp;lt;= 2; j++) {
                if(i+j &amp;gt; s.length()) {
                    break;
                }
                string substr = s.substr(i, j);
                if (!isPalindromic(substr)) {
                    break;
                }
                for (int k = 0; k &amp;lt;= i; k++) {
                    if (i+j+k &amp;gt; s.length()) {
                        break;
                    }
                    substr = s.substr(i-k, j+k*2);
                    if (!isPalindromic(substr)) {
                        break;
                    }
                    if (ret.length() &amp;lt; substr.length()) {
                        ret = substr;
                    }
                }
            }
        }
        return ret;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ugly-number-ii-leetcode-https-leetcode-com-problems-ugly-number-ii&#34;&gt;&lt;a href=&#34;https://leetcode.com/problems/ugly-number-ii/&#34;&gt;Ugly Number II - LeetCode&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;2, 3, 5のみで素因数分解できるn番目の正数を返す問題。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Write a program to find the n-th ugly number.
Ugly numbers are positive numbers whose prime factors only include 2, 3, 5. 

Example:
Input: n = 10
Output: 12
Explanation: 1, 2, 3, 4, 5, 6, 8, 9, 10, 12 is the sequence of the first 10 ugly numbers.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nが条件を満たすなら、N*2, N*3, N*5が条件を満たすので、これらの値を重複しないように記録していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Solution {
public:
    int nthUglyNumber(int n) {
        if (n &amp;lt;= 0) {
            return 0;
        }
        if (n == 1) {
            return 1;
        }
        
        vector&amp;lt;int&amp;gt; U;
        U.push_back(1);
        int idx2 = 0, idx3 = 0, idx5 = 0;
        for (int i = 2; i &amp;lt;= n; i++) {
            int next = min(U[idx2] * 2, min(U[idx3] * 3, U[idx5] * 5));
            U.push_back(next);
            while (U[idx2] * 2 &amp;lt;= next) idx2++;
            while (U[idx3] * 3 &amp;lt;= next) idx3++;
            while (U[idx5] * 5 &amp;lt;= next) idx5++;
        }
        return U[U.size() - 1];
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;対象の素数が引数で渡される&lt;a href=&#34;https://leetcode.com/problems/super-ugly-number/&#34;&gt;Super Ugly Number - LeetCode&lt;/a&gt;も同様に解ける。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>LA,ディズニーランドからre:Inventに参加しグランドキャニオンへドライブしてきた</title>
          <link>https://www.sambaiz.net/article/250/</link>
          <pubDate>Sun, 22 Dec 2019 23:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/250/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/103/&#34;&gt;一昨年&lt;/a&gt;、&lt;a href=&#34;https://www.sambaiz.net/article/164/&#34;&gt;去年&lt;/a&gt;と参加したGoogle I/Oのチケットが今年は当たらなかったので、前から行ってみたかったAWSのre:Inventに参加することにした。
会場はラスベガスで、会期は12/2-6。前後の土日ともう2日つなげて現地時間10日間の旅程にした。
去年、カナダのバンクーバーから西海岸のシアトル、ポートランド、サンフランシスコは巡ったので、今回はまだ訪れていないロサンゼルスからスタートすることにした。会期後はグランドキャニオンまで足を伸ばす。&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;例年通りExpediaで航空券と宿を取り、加えてラスベガスからグランドキャニオンへ行くためにレンタカーを予約した。
I/O会期中のシリコンバレー近辺とは異なり、ラスベガスのホテルは本当に安くて、OYO(元フーターズ)が一泊2千円で取れた。
re:Inventは65000人規模のイベントなんだが現地のUberドライバー曰く、最大20万人規模のイベントもやったりするらしいのでキャパシティは十分そうだ。
多くの人が申し込むJTBのツアーはホテルのグレードを考えてもかなり割高に感じた。&lt;/p&gt;

&lt;p&gt;LAでは北のハリウッド、南のアナハイム、ディズニーランドまで行くことを考えてダウンタウンに宿を取った。
価格だけで選ぶとスキッド・ロウといった危ないエリアの近くになりかねないので注意が必要だ。
ディズニーのチケットも事前に購入した。2パークいけるパークホッパーチケットに、色々な特典を含むMaxPassを付けて$214。
高い日のPeak料金ではあるんだが、家族連れで来たら大変じゃないかと思う。&lt;/p&gt;

&lt;p&gt;ラスベガスといえばカジノとショーの街だというし、シルク・ドゥ・ソレイユ Oのチケットを買った。
チケットを印刷するのを忘れていたので現地のFedex Officeで印刷した。ファイルを添付してメールを送るとコードが送られてくるので、それを印刷機に入力するだけで簡単。&lt;/p&gt;

&lt;p&gt;アメリカでの運転は初めてで往復できるか不安だったので、グランドキャニオンの南、フラッグスタッフという町の空港で乗り捨てられるAlamoで予約した。
日本でも5年は走っていないペーパードライバーなので、2時間出張教習してもらい、後はタイムズのカーシェアで練習した。
それと免許センターで国際免許を発行した。特に試験とかはなくて手数料だけ払えばもらえる。警察署でも発行してくれるようだが即日発行ではないようだ。&lt;/p&gt;

&lt;p&gt;今回のSIMはこれ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/dp/B07L4TB1TF&#34;&gt;Amazon.co.jp： 【AT&amp;amp;T】ハワイ・アメリカ本土 プリペイドSIM 30日 データ容量8GB 大容量通話付き: 家電・カメラ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;回線はAT&amp;amp;Tで、30日、8GB、テザリング可で電話もできる(香港の番号だが国際通話ができる)と、申し分ないスペックに対して安すぎるのが若干不安だったが、
ドキュメント通り現地でSIMを挿してAPNを作成したらすぐにつながり、その後も全く問題なかった。すごい。&lt;/p&gt;

&lt;h2 id=&#34;la-ディズニーランド&#34;&gt;LA/ディズニーランド&lt;/h2&gt;

&lt;p&gt;行きの航空券が関空乗り継ぎだった。国内線スタートの良いところは搭乗時間の締め切りが国際線よりはるかに緩いことで、実際それに救われた。&lt;/p&gt;

&lt;p&gt;10時間ほどのフライトでLAXに到着。Lax-itというライドシェア用の乗り場を目指す。
国際線ターミナルからは逆のところにあるので、ひっきりなしに走っているシャトルバスに乗る。
Uberをこの辺りに呼ぶとLax-it内のポート番号が表示される仕様だ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-1.jpg&#34; alt=&#34;Uber乗り場案内&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ホテルにチェックイン後、Cole&amp;rsquo;sという店のDip sandwitchを食べに行く。サンドイッチを肉汁のスープに浸して食べる。
カフェみたいなのをイメージしていったら酒場で緊張した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-2.jpg&#34; alt=&#34;dip sandwitch&#34; /&gt;&lt;/p&gt;

&lt;p&gt;地下鉄でハリウッドに移動。運賃はTapというカードにチャージする仕組み。
持ってなかったら$2くらい余分に払うと自販機から出てくる。距離に関係なく同一運賃。
このカードでMetroのバスにも乗れるが、バスではチャージできないそうなので乗る場合は少し余分に入れておく。
ただ、結局バスは乗らなかった。ディズニーランド行きのバスもあっておそらく最安なんだが、
Localなのでとても時間がかかるし、サウス・ロサンゼルスというこれまた治安悪いエリアを突っ切るのが怖かったからだ。&lt;/p&gt;

&lt;p&gt;ハリウッドではWalk of Fameの有名人の名前プレートを見ながら散歩していた。途中ハリウッドサインが見えたが想像していたより遠い。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-3.png&#34; alt=&#34;ハリウッドサイン&#34; /&gt;&lt;/p&gt;

&lt;p&gt;せっかくなのでビバリーヒルズのロデオドライブにも行ってきた。表参道みたいな感じであまり用がなかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-4.jpg&#34; alt=&#34;ロデオドライブ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次の日はディズニーランドに行く前にGrand Central MarketのEggslutで朝食を取った。8時開店で8時半には着いたんだが、既に20人くらいの行列ができている人気店だ。
よく分からなかったのでslutというのを注文した。食べるまで気づかなかったんだが星野珈琲のモーニングのあれだ。美味しい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-5.jpg&#34; alt=&#34;slut&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Uberでディズニーランドに向かう。そういえばアプリ入れてないなと思ってPlayストアで調べたがひっかからない。もしやと思って調べてみると&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-6.png&#34; alt=&#34;This item isn&#39;t available in your country&#34; /&gt;&lt;/p&gt;

&lt;p&gt;は？？しょうがないのでアカウントの地域をアメリカに切り替えて入れた。1年間変更できず、日本向けのアプリをダウンロードできなくなった。納得いかない。
ともあれ、これでアプリからファストパスが取れるようになった。ファストパスは30分に1回取れるが、既に持ってるものを消費しなくてはいけない。
人気のアトラクションはかなり先の時間になってしまうか取れなくなってしまうので、
東京と同様のアトラクションが結構あるディズニーランドパークよりカリフォルニアアドベンチャーの方を先に回った方が良さそう。
ただ、パークの方でもスターウォーズのエリアはかなり作り込んであって新鮮だし、写真を撮ってくれる人もいるので暗くなる前に行くべきかもしれない。
撮ってもらった写真はMaxPassならアプリからダウンロードできる。一人って言ったら、&amp;rdquo;Oh, Solo&amp;rdquo;って言われたのにうまく反応できなくて悔しい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-7.jpeg&#34; alt=&#34;ミレニアム・ファルコンと僕&#34; /&gt;&lt;/p&gt;

&lt;p&gt;カリフォルニアアドベンチャーの方はカーズのアトラクションが一番人気で、ファストパスを取るならそれが最有力だと思う。
スピード感がありながらフワッとする感じはなくて楽しかった。
撮影ポイントがあって出たところのモニターにアプリに入力するコードが表示されているんだが、
切り替わるのが早すぎるので、カメラで撮るなりして一旦コードだけ控えておいたほうが良い。
あとミッキーの顔が書かれた観覧車にも乗った。Swingするのに乗ったら、それこそバイキングかってぐらい揺らしてきて
泣きそうになった。実際泣き出す子もいると思う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-8.jpg&#34; alt=&#34;傾く景色&#34; /&gt;&lt;/p&gt;

&lt;p&gt;パークの城が東京で見るのと違うなと思ったら、こっちの城はシンデレラ城じゃなくて眠れる森の美女の城らしい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-9.jpg&#34; alt=&#34;眠れる森の美女の城&#34; /&gt;&lt;/p&gt;

&lt;p&gt;行きのUberは$40くらいだったのに対して帰りは$60くらいかかった。需要と供給だ。&lt;/p&gt;

&lt;h2 id=&#34;ラスベガス-re-invent&#34;&gt;ラスベガス/re:Invent&lt;/h2&gt;

&lt;p&gt;re:Invent前日にLAXからLASへ。
もう降りたところからスロットマシンが置いてあってさすがカジノの街だ。ここのUber乗り場はパーキングにある。&lt;/p&gt;

&lt;p&gt;2千円のOYOの部屋はこんな感じ。間取り的には同僚が泊まっていた2万円のミラージュと変わらない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-10.jpg&#34; alt=&#34;OYOの部屋&#34; /&gt;&lt;/p&gt;

&lt;p&gt;強いて言えば、隣の部屋の開閉に合わせて扉が軋んだり、Do not disturb札がなかったり、トイレが詰まって風呂が水浸しになったり、エレベーターのボタン押しても素通りすることはあったが、
概ね問題なかった。立地も悪くなくて、会場の一つになっているMGM GRANDの向かいにあるため、そこから出ているモノレールやシャトルバスに乗ることができる。&lt;/p&gt;

&lt;p&gt;会場に向かい、Registrationを終え、SWAG(パーカー)、空のボトルを獲得。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-12.jpg&#34; alt=&#34;SWAGと空のボトル&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LINQの近くにあるGordon Ramsayという有名シェフのフィッシュ&amp;amp;チップス屋に行った。魚がふわふわでソースが美味しい。
一人で食べるにはちょっとポテトが多め。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-13.jpg&#34; alt=&#34;Gordon Ramsay FISH &amp;amp; CHIPS&#34; /&gt;&lt;/p&gt;

&lt;p&gt;カジノにも行ったが、滞在中資金がプラスに転じることは一度もないまま、有り金全て失った。
スロットは1クレジット1¢と書かれてたので1円で遊べると思ったら、1回回す度に75クレジットずつ消費し始めた。
$20札がものの数分、時おり明滅する画面を見るだけで50¢バウチャーになるのはエンターテイメントのかけらもない、ソシャゲのガチャと同質の体験だ。
ブラックジャックもやった。札を置くとチップに交換され、MIN BET $10か$5あたりを置き、指で台をトントンして引くか、手を空中で振って止めるかするのをチップが0枚になるまで繰り返す処理だ。しばらくプレイしているとフリードリンクを聞きにくるんだが、それにしても高いビール代になった。&lt;/p&gt;

&lt;p&gt;予約したシルク・ドゥ・ソレイユ Oを見に行った。
ステージに巨大なプールがあってシンクロや飛び込んだりする。
演出が素晴らしいし、空中ブランコなどはすごい体勢でひやひやした。
ピエロの幕間も面白かった。最後に撮影が許可されるタイミングがある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-14.jpg&#34; alt=&#34;シルク・ド・ソレイユ O&#34; /&gt;&lt;/p&gt;

&lt;p&gt;その後、re:Inventの前夜祭、Midnight Madnessのためベネチアンへ。これと最終日のre:Playはバックパックの持ち込みができない。
バスケのアクロバティックシュートや鶏肉の早食い大会、エアギター世界一の人の演奏など。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-15.jpg&#34; alt=&#34;JUSTIN &amp;quot;NORDIC THUNDER&amp;quot; HOWARD&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最後にGANで伴奏を生成するサービスDeepComposerが発表された。
多分この後まもなくWorkshopが追加されたんだが、気づいたときには12セッション全て埋まっていた。
ただReserveできなかったとしてもWalkup列の前の方にいれば大体入れる。来ない人の分もあるが、元々Walkup枠がいくらかあるようだ。
1時間前から並ぶことができると言われていたが、DeepComposerのWorkshopは人気すぎて1時間半前から実質の列が形成されていた。&lt;/p&gt;

&lt;p&gt;1日目は高負荷動画サービスを中心にセッションを聞いていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=98001&#34;&gt;CMY302 - Scaling Hotstar.com for 25 million concurrent viewers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hotstarはクリケットのワールドカップで同時接続25.3Mの記録を出したインドの動画ストリーミングサービス。
実際の試合の前に、機械学習で予測したトラフィックパターンで負荷をかけたり、Chaos EngineeringするGamedayを行い、
スケーリング戦略や、どこが障害点やボトルネックになるのかを把握した。
Insufficient capacity errorが起きるなどの理由でAuto Scaling Groupは使わず自前でスケールさせることにしたそうだ。
障害時はクリティカルでないサービスを止めることで優先度の高いコンポーネントは動き続けられるようにしているらしい。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=96882&#34;&gt;ANT348 - How Prime Video processes 8 percent of all US internet traffic on AWS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;全米トラフィックの8%を占めるPrime Videoのデータ収集アーキテクチャの変遷の話。
最初はユーザーデバイスからAPI Gatewayで受けてLambdaで処理し、FirehoseでS3に保存したのをGlueのデータカタログでマッピングだけしてAthenaで見られるようにするというサーバーレスな構成だったが、負荷に耐えられなかった。
それをELBと多段のEC2+Kinesisで受けるようにして、Athenaで実行するには重すぎるクエリをEMRで行うようにしたところ、
負荷には耐えられるようにはなったが、依然クエリの実行には時間がかかり、
これを解決するためにEC2でDynamoDBやElasticacheを使ってKinesisから直接集計することにした。
最終的にこれをKinesis Analyticsに置き換えてリアルタイムにデータが見られるようにしたそうだ。&lt;/p&gt;

&lt;p&gt;あと、Lambda、ML系サービス、Step Functionsを使って動画などを解析するサーバーレスなワークフローを構築する&lt;a href=&#34;https://github.com/awslabs/aws-media-insights-engine&#34;&gt;Media Insight Engine&lt;/a&gt;のBuilders Sessionにも行った。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=98558&#34;&gt;AIM355-R - [REPEAT] Automate creation of redacted content with the Media Insights Engine&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-16.jpg&#34; alt=&#34;Builders Session&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Builders Sessionは最大6人でテーブルを囲み、AWSの中の人から説明を受けて質問したり実際に動かしたりできるセッション。
すごく距離が近い。特にこの回は2人で、もう自分に向けて話してくれているような感じで緊張したが、分かりやすく説明してくれた。&lt;/p&gt;

&lt;p&gt;あとは時間が余ったのでAWSやパートナー企業のブースがあるEXPOで、酒と食べ物を手にうろうろしていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-18.jpg&#34; alt=&#34;EXPO&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Tシャツやワイヤレス充電器などのグッズをもらった。良いお土産だ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-17.jpg&#34; alt=&#34;企業グッズ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;1日目最後はMonday Night Live、第1のKeynoteだ。夜だけあってワゴンでビールが運ばれてくる。
EC2インスタンス間でTCPよりも高スループットな通信を行えるようにする
&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/efa.html&#34;&gt;Elastic Fabric Adapter(EFA)&lt;/a&gt;が発表された。
HPC(High Performance Computing)や機械学習用途に効く。
あと機械学習用のチップ&lt;a href=&#34;https://aws.amazon.com/jp/machine-learning/inferentia/&#34;&gt;AWS Inferentia&lt;/a&gt;も開発してるらしい。&lt;/p&gt;

&lt;p&gt;2日目も朝からKeynote。AWSのCEO、Andy Jassyだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-34.jpg&#34; alt=&#34;Keynote by Andy Jessy&#34; /&gt;&lt;/p&gt;

&lt;p&gt;EKSのFargate対応、Redshiftのパフォーマンスを他のDWHの10倍にするキャッシュ、AQUA(Advanced Query Accelerator)や、
AutoMLのSageMaker Autopilot、自動コードレビューのCodeGuruなどなど。特にSageMaker系の発表が多かった。&lt;/p&gt;

&lt;p&gt;昼ごはんは日替わりのビュッフェかランチボックスを選べる。朝ごはんは1日も行けなかったので知らない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-38.jpg&#34; alt=&#34;Lunch&#34; /&gt;&lt;/p&gt;

&lt;p&gt;午後はGameDayに参加した。4人でチームを組んでサービスを動かしスコアを競う。今回のお題はユニコーンのレンタル業者だった。
一人で行っても来た人からチームを組んでくれる。内容はネタバレになるので言えないが楽しかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-37.jpg&#34; alt=&#34;GameDay&#34; /&gt;&lt;/p&gt;

&lt;p&gt;3日目は早朝からチャリティランがあったのだが起きられなくてスキップ。
量子コンピューターの新サービス、&lt;a href=&#34;https://aws.amazon.com/jp/braket/&#34;&gt;Amazon Braket&lt;/a&gt;のセッションからスタート。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=101592&#34;&gt;CMP213-R - [NEW LAUNCH!] [REPEAT] Introducing quantum computing with AWS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;あのD-waveが個人でも使えるというだけでテンションが上がるんだが、実際どう使われ得るのかイメージできていなかったので、
機械学習でのGPUのようにco-processorとして使うというのは分かりやすかった。&lt;/p&gt;

&lt;p&gt;午後はDeepComposerのWorkshopに行った。実際にメロディを入力して伴奏を生成するところから、GANのモデルを学習させるところまでやる。
このセッションに出ると$99のDeepComposerキーボードが貰えた。MIDIキーボードとしても普通に使えるものだ。嬉しい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-32.jpg&#34; alt=&#34;DeepComposerのWorkshop&#34; /&gt;&lt;/p&gt;

&lt;p&gt;夜はBingo Nightに出た。賞品はFire TVシリーズだったが全く揃わなかった。素直にBoard Game Nightの方に行っとけばよかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-33.jpg&#34; alt=&#34;Bingo Night&#34; /&gt;&lt;/p&gt;

&lt;p&gt;4日目も朝からKeynoteがあったが、充電器をなくしてスマホ・PC共に既に電源がつかない状態だったので行けなかった。
とりあえずHelp Deskに行ってみるが届いていなくて、Workshopの部屋にもなかった。ホテルのSecurity Deskにも聞いてみたがやはりない。&lt;/p&gt;

&lt;p&gt;しょうがないのでFASHIN SHOWというショッピングモールのApple Storeに向かった。スマホが使えないとUberも呼べないので歩いていける距離にあって良かった。しかしまさかの在庫切れ。終わったと思ったら、近くに他のApple Storeがあるらしい。さすがラスベガス。
だが地図アプリを開くこともできないんだ。そう言うと充電器を持ってきてくれて充電させてくれた。やはり実店舗を持つ会社は違う。
Apple最高だ。もう一つのStoreには在庫があった。&lt;/p&gt;

&lt;p&gt;気を取り直して、Ping Pong Tournamentに出場した。2日目に登録があったようだが当日参加列もあった。
結果は11-1で初戦敗退。全く歯が立たなかった。次の試合は2時間先と言われていたのでチャンピオンシップまでの試合数はそう多くなさそう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-28.jpg&#34; alt=&#34;Ping Pong Tournament&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hands-on Labsに来た。&lt;a href=&#34;https://www.qwiklabs.com/&#34;&gt;QWIKLABS&lt;/a&gt;というサービスで実際に操作しながら学べる。
新サービスが触れるかと思ったらそんなことはなかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-29.jpg&#34; alt=&#34;Hands-on Labs&#34; /&gt;&lt;/p&gt;

&lt;p&gt;AWS Japanによる日本語のWrapup Sessionを聞いて、最後のパーティーre:Play会場に向かう。&lt;/p&gt;

&lt;p&gt;食べ物の種類が多くて食べきれない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-35.jpg&#34; alt=&#34;食べ物ブース&#34; /&gt;&lt;/p&gt;

&lt;p&gt;列に並んでいた5人組に混ぜてもらいBattleballというのをやってきた。
ボール5個のドッジボールだ。ドンドコ太鼓が鳴る中やるのでバトル感がある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-36.jpg&#34; alt=&#34;Battleball&#34; /&gt;&lt;/p&gt;

&lt;p&gt;テントの中はライブ会場だ。
トリのAnderson.Paakまで聞いていたがったが、
最後までいると帰るのが遅くなってしまいそうなのと、Battleballで体力を使い果たしたので途中離脱した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-30.jpg&#34; alt=&#34;ライブ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;グランドキャニオン&#34;&gt;グランドキャニオン&lt;/h2&gt;

&lt;p&gt;空港の近くにあるレンタカー会社がまとまっている建物にAlamoもある。
コンパクトカーで予約していたんだが、フラッグスタッフまで行くならSUVの方がいいよと言われたのでアップグレードしてもらい
日産のROGUE、日本でいうエクストレイルになった。
ROAD SIDE PLUSという電話サポートのオプションにも入った。日本語対応してくれるらしい。
一応カーナビも借りたんだがこれは必要なかった。スマホで十分だ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-20.jpg&#34; alt=&#34;カーナビ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;アメリカでの運転は不安だったが、聞いていた通り道が広くて運転しやすかった。標識も見れば大体分かるし、馴染みがないのはYIELD(優先道路ではない)やALL STOPS(一旦止まって先に来た車から出て行く交差点)くらい。日本での運転難しすぎない？
右車線を走るのも左折時に注意するぐらいだし、左ハンドルも結局は位置取りが左右逆になるだけだ。なお、ワイパーとウィンカーは何回も間違えた。&lt;/p&gt;

&lt;p&gt;グランドキャニオンへの道のりは東へひたすら進んでウィリアムズあたりから北上するだけのルートなので、
一度フリーウェイに乗ってしまえばあとはトラックを追い抜くとき車線変更するくらいしかすることがない。
それすらも、サイドミラーに1台も車が映らない場面がほとんどで、タイミングを計る必要がある東京に比べたら全く簡単だ。&lt;/p&gt;

&lt;p&gt;日本のように道中にコンビニがあるわけではなく、ガソリンスタンドがその役割を果たしている。
給油は、機械でなくカウンターで払う場合、適当に先払いして終わったらお釣りをもらいにいくのと、
ガソリンの表記がレギュラーじゃなくてUnleadedなこと以外は日本のとそう違いはないと思う。&lt;/p&gt;

&lt;p&gt;道中、Route66沿いの街キングマンとセリグマンで休憩した。セリグマンはカーズの舞台になった町だ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-19.jpg&#34; alt=&#34;セリグマン&#34; /&gt;&lt;/p&gt;

&lt;p&gt;北上する道のりはさしたる町もなく17時をすぎるとかなり暗い。対向車のライトが眩しい。
Spotifyで音楽をストリーミング再生していたが、途中で圏外になって流れなくなった。&lt;/p&gt;

&lt;p&gt;2つのラウンドアバウトを過ぎた少し先に国立公園のゲートがあって入場料を払う。カードも可。
休憩込み6時間くらいで宿泊先のBright Angel Lodgeに到着。寒い。
フロントに弱いWifiがあるが客室には飛んでこない。ネットから隔離された状況ですることもないので早く寝る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-21.jpg&#34; alt=&#34;客室&#34; /&gt;&lt;/p&gt;

&lt;p&gt;翌朝、フロントの裏がグランドキャニオンらしい景色になっていたので少し散歩した後、公園の西、Dessert View Watchoverへ出発。
公園内も含めて道路はしっかり除雪されている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-22.jpg&#34; alt=&#34;道路&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Dessert View Watchoverにはその名の通り見張り台らしい塔がある。売店もある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-23.jpg&#34; alt=&#34;グランドキャニオン&#34; /&gt;&lt;/p&gt;

&lt;p&gt;公園を出てフラッグスタッフを目指す。北上すればモニュメントバレーを目指すこともできたが圏外でナビを更新できなかった。
フラッグスタッフへの道は荒野のど真ん中を舗装された道路がまっすぐ伸びているという感じで、なかなか気分がよい。&lt;/p&gt;

&lt;p&gt;フラッグスタッフに着いた時点でまだレンタカーを返すには早かったので、さらに南下してセドナにも行ってみることにした。
セドナへの道はフラッグスタッフまでのそれとは対象的に山道のうねった道。Uターンのようなカーブが幾度も続く。セドナで給油することにしたんだが、二列のラウンドアバウトに苦戦して何周もしてしまった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-25.png&#34; alt=&#34;ラウンドアバウト&#34; /&gt;&lt;/p&gt;

&lt;p&gt;そんなこんなで辺りも暗くなってきたので、特にどこに行くわけでもなく引き上げることにした。セドナの町はライトアップされてて良い感じだった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-24.jpg&#34; alt=&#34;セドナ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;レンタカーの返却は空港の外の路肩に停めて鍵を返す感じで営業時間外でも大丈夫そう。総走行距離750kmくらい。
こんな距離走ったのは初めてだったが楽しいドライブだった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-26.png&#34; alt=&#34;ドライブコース&#34; /&gt;&lt;/p&gt;

&lt;p&gt;モーテル近くのカレー屋で最後の晩餐。タンドリーチキンとシシカバブが付いてくるちょっと豪華なカレーセットを頼んだはずだったが
カレー、ナン、ライスと山盛りのタンドリーチキンとシシカバブが来た。大変だ。ちなみにライスも盛ってある量と同じくらいの量が下にも詰まっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-27.jpg&#34; alt=&#34;カレーセット&#34; /&gt;&lt;/p&gt;

&lt;p&gt;翌朝、空港に向かおうとしたところ朝7時と早い便だからかUberを呼んでも来なかったので、モーテルの人にタクシーを呼んでもらった。
ゲートが2つの小さな空港なので入り口から荷物検査、ゲートまですぐ。1時間前には着いていたが十分すぎた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/250-39.jpg&#34; alt=&#34;フラッグスタッフ空港&#34; /&gt;&lt;/p&gt;

&lt;p&gt;大きい荷物はゲートを通るときにタグを付けられるので乗るときに貨物室に入れてもらう。高速バスみたいな感じだ。
この荷物は降りるときにボーディングブリッジで直接渡されるのでそのまま乗り継ぎ先に飛んでいったりしない。
ダラスでの乗り継ぎが国際線かつ別ターミナルなのに1時間しかなくて焦ったが、まあちゃんと乗れて日本に帰って来られたので問題なかった。
問題ないのは良いことだ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SwiftのError enumとtry, if case</title>
          <link>https://www.sambaiz.net/article/249/</link>
          <pubDate>Sun, 24 Nov 2019 23:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/249/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://docs.swift.org/swift-book/LanguageGuide/ErrorHandling.html&#34;&gt;Error Handling — The Swift Programming Language (Swift 5.1)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SwiftではErrorをenumで列挙でき、次の例でいうsomeParamのようにAssociated valuesを含めることもできる。
throwすると他の言語ではスタックトレースを作るので重い処理になるが、Swiftは作らないのでreturnするようにエラーを返せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import UIKit

enum SampleError: Error {
    case ReasonFoo
    case ReasonBar(someParam: Int)
}

func errorFunc() throws -&amp;gt; String {
    throw SampleError.ReasonBar(someParam: 100)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;throws付きの関数を呼ぶ際はdo-catchするtryか、nilが返るtry?、落ちるtry!のいずれかを付ける。
Associated valuesがある場合、&lt;code&gt;==&lt;/code&gt;は使えず、&lt;code&gt;if case .ReasonBar = error&lt;/code&gt;のように比較する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;do {
    try errorFunc()
} catch SampleError.ReasonFoo {
    print(&amp;quot;foo!&amp;quot;)
} catch SampleError.ReasonBar(let someParam) {
    print(&amp;quot;bar! \(someParam)&amp;quot;) // =&amp;gt; bar! 100
}

do {
    try errorFunc()
} catch let error {
    if case .ReasonBar = error as! SampleError {
        print(&amp;quot;error is bar!&amp;quot;) // =&amp;gt; error is bar!
    }
}

do {
    try? errorFunc() // =&amp;gt; nil
} catch is SampleError {
    print(error) // unreachable
}

do {
    try! errorFunc() // =&amp;gt; Fatal error
} catch {
    print(error) // unreachable
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SwiftのXMLParser</title>
          <link>https://www.sambaiz.net/article/248/</link>
          <pubDate>Sun, 24 Nov 2019 23:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/248/</guid>
          <description>&lt;p&gt;Swiftの&lt;a href=&#34;https://developer.apple.com/documentation/foundation/xmlparser&#34;&gt;XMLParser&lt;/a&gt;はイベント駆動のparser。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import UIKit

class ParserSample: NSObject {
    private let parser: XMLParser
    
    init(data: Data) {
        parser = XMLParser(data: data)
        super.init()
        parser.delegate = self
    }
    
    func parse() {
        guard parser.parse() else {
            guard let err = parser.parserError else {
                print(&amp;quot;parse error but unknown reason&amp;quot;)
                return
            }
            print(&amp;quot;parse error: \(err.localizedDescription)&amp;quot;)
            return
        }
        print(&amp;quot;after parse()&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.apple.com/documentation/foundation/xmlparserdelegate&#34;&gt;XMLParserDelegate&lt;/a&gt;でイベントを拾ってオブジェクトに詰めるなりする。全て実装する必要はなく、この例ではタグの開始と文字列、CDATA、エラー、パース終了時の関数を実装している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;extension ParserSample: XMLParserDelegate {
    func parser(_ parser: XMLParser, didStartElement elementName: String, namespaceURI: String?, qualifiedName qName: String?, attributes attributeDict: [String : String] = [:]) {
        print(&amp;quot;parsing &amp;lt;\(elementName)&amp;gt;&amp;quot;)
        if elementName == &amp;quot;ERROR&amp;quot; {
            self.parser.abortParsing() // test
        }
    }
    
    func parser(_ parser: XMLParser, foundCharacters string: String) {
        print(&amp;quot;found \(string)&amp;quot;)
    }
    
    func parser(_ parser: XMLParser,
                foundCDATA CDATABlock: Data) {
        let data = String(bytes: CDATABlock, encoding: .utf8)
        print(&amp;quot;foundCDATA \(data!)&amp;quot;)
    }
    
    func parser(_ parser: XMLParser, parseErrorOccurred parseError: Error) {
        print(&amp;quot;parser error: \(parseError.localizedDescription)&amp;quot;)
    }
    
    func parserDidEndDocument(_ parser: XMLParser) {
        print(&amp;quot;parse done&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後まで正常にパースされる場合と、途中で中断される場合を実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(&amp;quot;-- case 1 (success) --&amp;quot;)

guard let data1 = &amp;quot;&amp;lt;A&amp;gt;&amp;lt;B&amp;gt;\n&amp;lt;D&amp;gt;value&amp;lt;/D&amp;gt;&amp;lt;/B&amp;gt;&amp;lt;C&amp;gt;&amp;lt;![CDATA[ccccc]]&amp;gt;&amp;lt;/C&amp;gt;&amp;lt;/A&amp;gt;&amp;quot;.data(using: .utf8) else {
    print(&amp;quot;cast to data1 error&amp;quot;)
    exit(1)
}
ParserSample(data: data1).parse()

print(&amp;quot;-- case 2 (abort) --&amp;quot;)

guard let data2 = &amp;quot;&amp;lt;ERROR&amp;gt;&amp;lt;/ERROR&amp;gt;&amp;quot;.data(using: .utf8) else {
    print(&amp;quot;cast to data2 error&amp;quot;)
    exit(1)
}
ParserSample(data: data2).parse()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後までパースすると&lt;code&gt;parserDidEndDocument()&lt;/code&gt;が実行された後&lt;code&gt;parse()&lt;/code&gt;がtrueを返し、
途中で中断すると&lt;code&gt;parseErrorOccurred&lt;/code&gt;の関数が呼ばれて&lt;code&gt;parse()&lt;/code&gt;がfalseを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- case 1 (success) --
parsing &amp;lt;A&amp;gt;
parsing &amp;lt;B&amp;gt;
found 

parsing &amp;lt;D&amp;gt;
found value
parsing &amp;lt;C&amp;gt;
foundCDATA ccccc
parse done
after parse()
-- case 2 (abort) --
parsing &amp;lt;ERROR&amp;gt;
parser error: The operation couldn’t be completed. (NSXMLParserErrorDomain error 512.)
parse error: The operation couldn’t be completed. (NSXMLParserErrorDomain error 512.)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ECS(EC2)のCloudFormation最小構成</title>
          <link>https://www.sambaiz.net/article/247/</link>
          <pubDate>Fri, 15 Nov 2019 20:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/247/</guid>
          <description>&lt;p&gt;EC2でECSのServiceを動かすCFnテンプレートを書く。以前Fargateで動かしたものを一部再利用する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/221/&#34;&gt;ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;EC2で動かす場合、自分でリソースが不足しないようにインスタンスのスケールを気遣うことになるが、VPC外での実行や&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task_definition_parameters.html#variablelist&#34;&gt;privilegedをtrueにする&lt;/a&gt;などEC2でしかできないことがある。あと同リソースで比較すると安い。&lt;/p&gt;

&lt;p&gt;まずはEC2インスタンス以外のリソースを書く。LaunchType以外はFargateのときとほぼ同じ。
LBなしでバッチのようなものを動かすことを想定した最小構成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ECSCluster:
  Type: AWS::ECS::Cluster
  Properties:
    ClusterName: &#39;test-cluster&#39;
LogGroup:
  Type: AWS::Logs::LogGroup
  Properties: 
    LogGroupName: &#39;test-task-log-group&#39;
    RetentionInDays: 1
TaskDefinition:
  Type: AWS::ECS::TaskDefinition
  Properties: 
    RequiresCompatibilities:
      - EC2
    Cpu: &#39;256&#39;
    Memory: &#39;512&#39;
    ContainerDefinitions: 
      - Name: &#39;app&#39;
        Image: &#39;busybox&#39;
        EntryPoint: 
          - &#39;sh&#39;
          - &#39;-c&#39;
        Command: 
          - &#39;while true; do echo &amp;quot;{\&amp;quot;foo\&amp;quot;:1000,\&amp;quot;time\&amp;quot;:\&amp;quot;2019-05-09T20:00:00+09:00\&amp;quot;}&amp;quot;; sleep 10; done&#39;
        Essential: &#39;true&#39;
        LogConfiguration:
          LogDriver: &#39;awslogs&#39;
          Options:
            awslogs-group: !Ref LogGroup
            awslogs-region: &#39;ap-northeast-1&#39;
            awslogs-stream-prefix: &#39;app&#39;
        Environment:
          - Name: &#39;TZ&#39;
            Value: &#39;Asia/Tokyo&#39;
    Volumes: 
      - Name: &#39;varlog&#39;
ECSService:
  Type: AWS::ECS::Service
  Properties:
    Cluster: !Ref ECSCluster
    LaunchType: EC2
    DesiredCount: 1
    TaskDefinition: !Ref TaskDefinition
    ServiceName: &#39;test-service&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EC2インスタンスとECSクラスタの紐付きはAssociationのようなリソースがあるわけではなく、
&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/ecs-optimized_AMI.html&#34;&gt;ECS-optimized AMI&lt;/a&gt;から&lt;code&gt;echo ECS_CLUSTER=&amp;lt;cluster name&amp;gt; &amp;gt;&amp;gt; /etc/ecs/ecs.config&lt;/code&gt;で指定したクラスタにインスタンスを登録する。そのために必要なroleを付ける。&lt;/p&gt;

&lt;p&gt;各リージョンごとのAMI IDをMappingsで書き並べてもいいが、次のように書くとParameter Storeから最新のAMI IDを&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/retrieve-ecs-optimized_AMI.html&#34;&gt;取得できる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Parameters:
  ECSAMI:
    Description: AMI ID
    Type: AWS::SSM::Parameter::Value&amp;lt;AWS::EC2::Image::Id&amp;gt;
    Default: /aws/service/ecs/optimized-ami/amazon-linux-2/recommended/image_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なお、amazon-linux2ルートデバイスは&lt;code&gt;/dev/sda1&lt;/code&gt;ではなく&lt;code&gt;/dev/xvda&lt;/code&gt;なので
間違えると &lt;code&gt;Client.InstanceInitiatedShutdown: Instance initiated shutdown&lt;/code&gt;
でインスタンスが落ち続けてServiceがstableにならず失敗する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ECSAutoScalingGroup: 
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties: 
      AvailabilityZones: 
        !GetAZs &amp;quot;&amp;quot;
      LaunchConfigurationName: !Ref LaunchConfig
      MinSize: &amp;quot;1&amp;quot;
      MaxSize: &amp;quot;1&amp;quot;
EC2Role:
  Type: AWS::IAM::Role
  Properties:
    AssumeRolePolicyDocument:
      Statement:
      - Effect: Allow
        Principal:
          Service: [&#39;ec2.amazonaws.com&#39;]
        Action: [&#39;sts:AssumeRole&#39;]
    Path: /
    Policies:
    - PolicyName: ecs-service
      PolicyDocument:
        Statement:
        - Effect: Allow
          Action: 
            - &#39;ecs:CreateCluster&#39;
            - &#39;ecs:DeregisterContainerInstance&#39;
            - &#39;ecs:DiscoverPollEndpoint&#39;
            - &#39;ecs:Poll&#39;
            - &#39;ecs:RegisterContainerInstance&#39;
            - &#39;ecs:StartTelemetrySession&#39;
            - &#39;ecs:Submit*&#39;
            - &#39;logs:CreateLogStream&#39;
            - &#39;logs:PutLogEvents&#39;
          Resource: &#39;*&#39;
EC2InstanceProfile:
  Type: AWS::IAM::InstanceProfile
  Properties:
    Path: /
    Roles: 
      - !Ref &#39;EC2Role&#39;
LaunchConfig: 
  Type: AWS::AutoScaling::LaunchConfiguration
  Properties:
    ImageId: !Ref ECSAMI
    IamInstanceProfile: !Ref EC2InstanceProfile
    UserData:
      Fn::Base64: !Sub |
        #!/bin/bash -xe
        echo ECS_CLUSTER=${ECSCluster} &amp;gt;&amp;gt; /etc/ecs/ecs.config          
    InstanceType: &amp;quot;t2.small&amp;quot;
    BlockDeviceMappings: 
      - DeviceName: &amp;quot;/dev/xvda&amp;quot;
        Ebs: 
          VolumeSize: &amp;quot;30&amp;quot;
          VolumeType: &amp;quot;gp2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>単調性のある式の解を二分法で数値的に求める</title>
          <link>https://www.sambaiz.net/article/246/</link>
          <pubDate>Mon, 28 Oct 2019 22:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/246/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://atcoder.jp/contests/abc144&#34;&gt;AtCoder Beginner Contest 144&lt;/a&gt;の
&lt;a href=&#34;https://atcoder.jp/contests/abc144/tasks/abc144_d&#34;&gt;D - Water Bottle&lt;/a&gt;をやってみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;高橋君は、底面が1辺 a cm の正方形であり、高さが b cm であるような直方体型の水筒を持っています。(水筒の厚みは無視できます。)
この水筒の中に体積 x cm^3 の水を入れ、底面の正方形の1辺を軸として、この水筒を徐々に傾けます。
水を溢れさせずに水筒を傾けることができる最大の角度を求めてください。

水を溢れさせずに水筒を傾けることができる最大の角度を度数法で出力せよ。
出力は、ジャッジの出力との絶対誤差または相対誤差が10^6以下のとき正解と判定される。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;水が溢れるパターンは次の2通りあって、水が入っている、または入ってない部分の三角柱を除いた部分の体積がxになるようなθをatanで出せる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/246.png&#34; alt=&#34;水が溢れるパターン&#34; /&gt;&lt;/p&gt;

&lt;p&gt;解説を見ると、これに加えて二分法を使って数値的に求める解法も紹介されていた。
二分法というのは解が含まれる区間の中間での値を求め、その値が解より小さいか大きいかによって二分したどちらかの区間を選ぶ操作を繰り返すことで区間の幅を狭めて解を求めるアルゴリズム。収束条件として式に単調性がある必要があるが、θに対してこぼれる限界の水の体積の式は単調減少するので用いることができる。
解説にもコードが付いていたがまずは見ずに書いてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;cmath&amp;gt;
#include &amp;lt;iomanip&amp;gt;
using namespace std;

double waterVolume(int a, int b, double rad)
{
    if (rad &amp;lt; atan(1.0 * b / a))
    {
        return a * a * b - (a * (a * tan(rad)) / 2 * a);
    }
    else
    {
        return b * (b * tan(M_PI / 2 - rad)) / 2 * a;
    }
}

int main()
{
    double a, b, x;
    cin &amp;gt;&amp;gt; a &amp;gt;&amp;gt; b &amp;gt;&amp;gt; x;
    double min = 0, max = M_PI / 2;
    while (true)
    {
        double m = (min + max) / 2;
        double vol = waterVolume(a, b, m);
        if (abs(vol - x) &amp;lt; pow(10, -6))
        {
            cout &amp;lt;&amp;lt; setprecision(8) &amp;lt;&amp;lt; m / M_PI * 180 &amp;lt;&amp;lt; endl;
            return 0;
        }
        else if (vol &amp;gt; x)
        {
            min = m;
        }
        else
        {
            max = m;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://atcoder.jp/contests/abc144/submissions/8133803&#34;&gt;解説のコード&lt;/a&gt;では、パターンの判定で&lt;code&gt;a * tan(theta) &amp;lt;= b&lt;/code&gt;を使っているのと、有限回のループでxを上回らない最大のθを探すようになっていた。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>goyaccでparserを生成しLispのcons,car,cdrの式を評価する</title>
          <link>https://www.sambaiz.net/article/244/</link>
          <pubDate>Tue, 15 Oct 2019 09:41:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/244/</guid>
          <description>

&lt;p&gt;GoでLispのcons,car,cdrの式を評価したい。
流れとしては字句解析器(lexer, tokenizer, scanner)でソースコードを分割しtoken列にして、構文解析器(parser)で構文木を作るなりして評価できるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install clisp
$ clisp
&amp;gt; (cons 1 ())
(1)
&amp;gt; (cons () 1)
(NIL . 1)
&amp;gt; (car (cons 1 (cons 2 3)))
1
&amp;gt; (cdr (cons 1 (cons 2 3)))
(2 . 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;goの字句解析器と構文解析器&#34;&gt;Goの字句解析器と構文解析器&lt;/h2&gt;

&lt;p&gt;Goの字句解析器と構文解析器がGoが実装されているので見てみる。&lt;/p&gt;

&lt;h3 id=&#34;go-scanner-https-golang-org-pkg-go-scanner&#34;&gt;&lt;a href=&#34;https://golang.org/pkg/go/scanner/&#34;&gt;go/scanner&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;ソースコードを分割して&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/token/token.go&#34;&gt;go/token&lt;/a&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;go/token&amp;quot;
	&amp;quot;go/scanner&amp;quot;
)

func main() {
	var sc scanner.Scanner
	src := []byte(`(&amp;quot;A&amp;quot; + &amp;quot;B&amp;quot;) + &amp;quot;C&amp;quot;`)
	errorHandler := func(pos token.Position, msg string) { fmt.Printf(&amp;quot;ERROR %v %v\n&amp;quot;, pos, msg)}
	sc.Init(token.NewFileSet().AddFile(&amp;quot;&amp;quot;, -1, len(src)), src, errorHandler, 0)
	fmt.Printf(&amp;quot;%6v %6v %6v\n&amp;quot;, &amp;quot;pos&amp;quot;, &amp;quot;tok&amp;quot;, &amp;quot;lit&amp;quot;)
	for {
		pos, tok, lit := sc.Scan()
		if tok == token.EOF {
			break
		}
		fmt.Printf(&amp;quot;%6v %6v %6v\n&amp;quot;, pos, tok, lit)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;pos    tok    lit
  1      (       
  2 STRING    &amp;quot;A&amp;quot;
  6      +       
  8 STRING    &amp;quot;B&amp;quot;
 11      )       
 13      +       
 15 STRING    &amp;quot;C&amp;quot;
 18      ;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/scanner/scanner.go&#34;&gt;実装&lt;/a&gt;を見ていく。&lt;/p&gt;

&lt;p&gt;まず&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/scanner/scanner.go#L703&#34;&gt;skipWhitespace()&lt;/a&gt;でスペースやタブなどを無視して読み進める(&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/scanner/scanner.go#L56&#34;&gt;next()&lt;/a&gt;)。
その後、見ている文字(s.ch)によってどう読み進めるかを判断する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (s *Scanner) Scan() (pos token.Pos, tok token.Token, lit string) {
scanAgain:
	s.skipWhitespace()

	// current token start
	pos = s.file.Pos(s.offset)

	// determine token value
	insertSemi := false
	switch ch := s.ch; {
	case isLetter(ch):
		...
	default:
		s.next() // always make progress
		switch ch {
		case -1:
			if s.insertSemi {
				s.insertSemi = false // EOF consumed
				return pos, token.SEMICOLON, &amp;quot;\n&amp;quot;
			}
			tok = token.EOF
		case &#39;&amp;quot;&#39;:
			...
		}
	}
	if s.mode&amp;amp;dontInsertSemis == 0 {
		s.insertSemi = insertSemi
	}

	return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文字列だったら(&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/scanner/scanner.go#L342&#34;&gt;isLetter()&lt;/a&gt;=true)、
&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/scanner/scanner.go#L350&#34;&gt;scanIdentifier()&lt;/a&gt;で文字列の最後まで読み進めて、
&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/token/token.go#L290&#34;&gt;Lookup()&lt;/a&gt;で
trueやbreakといったキーワードなのか、そうでないのか(token.IDENT)を判定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case isLetter(ch):
    lit = s.scanIdentifier()
    if len(lit) &amp;gt; 1 {
        // keywords are longer than one letter - avoid lookup otherwise
        tok = token.Lookup(lit)
        switch tok {
        case token.IDENT, token.BREAK, token.CONTINUE, token.FALLTHROUGH, token.RETURN:
            insertSemi = true
        }
    } else {
        insertSemi = true
        tok = token.IDENT
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;&amp;quot;&lt;/code&gt;は&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/scanner/scanner.go#L636&#34;&gt;scanString()&lt;/a&gt;で次の&lt;code&gt;&amp;quot;&lt;/code&gt;が来るまで
中身をstringとして読み進める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case &#39;&amp;quot;&#39;:
    insertSemi = true
    tok = token.STRING
    lit = s.scanString()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;+&lt;/code&gt;や&lt;code&gt;-&lt;/code&gt;は&lt;code&gt;++&lt;/code&gt;や&lt;code&gt;+=&lt;/code&gt;かもしれないので次の文字を見て判断したり、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case &#39;+&#39;:
    tok = s.switch3(token.ADD, token.ADD_ASSIGN, &#39;+&#39;, token.INC)
    if tok == token.INC {
        insertSemi = true
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt;は&lt;code&gt;...&lt;/code&gt;かもしれないのでさらにその次の文字まで見ていたりする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case &#39;.&#39;:
    // fractions starting with a &#39;.&#39; are handled by outer switch
    tok = token.PERIOD
    if s.ch == &#39;.&#39; &amp;amp;&amp;amp; s.peek() == &#39;.&#39; {
        s.next()
        s.next() // consume last &#39;.&#39;
        tok = token.ELLIPSIS
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;go-parser-https-golang-org-pkg-go-parser&#34;&gt;&lt;a href=&#34;https://golang.org/pkg/go/parser/&#34;&gt;go/parser&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/ast/ast.go&#34;&gt;go/ast&lt;/a&gt;を生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main
    
import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;go/ast&amp;quot;
    &amp;quot;go/parser&amp;quot;
)

func f(a string) string {
    return &amp;quot;X&amp;quot;
}

func main() {
    exprs := []string{
        &amp;quot;1 + 1&amp;quot;,
        &amp;quot;true || !false&amp;quot;,
        `(1 + 1) * f(&amp;quot;A&amp;quot;)`,
		&amp;quot;X ((Y))))&amp;quot;,
    }
    for _, e := range exprs {
        expr, err := parser.ParseExpr(e)
        if err != nil {
            fmt.Printf(&amp;quot;%s =&amp;gt; %s&amp;quot;, e, err)
            continue
        } 
        if be, ok := expr.(*ast.BinaryExpr); ok {
            fmt.Printf(&amp;quot;%s =&amp;gt; %T(%+v) %T(%+v) %T(%+v)\n&amp;quot;, e, be.X, be.X, be.Op, be.Op, be.Y, be.Y)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1 + 1 =&amp;gt; *ast.BasicLit(&amp;amp;{ValuePos:1 Kind:INT Value:1}) token.Token(+) *ast.BasicLit(&amp;amp;{ValuePos:5 Kind:INT Value:1})
true || !false =&amp;gt; *ast.Ident(true) token.Token(||) *ast.UnaryExpr(&amp;amp;{OpPos:9 Op:! X:false})
(1 + 1) * f(&amp;quot;A&amp;quot;) =&amp;gt; *ast.ParenExpr(&amp;amp;{Lparen:1 X:0xc00006a1b0 Rparen:7}) token.Token(*) *ast.CallExpr(&amp;amp;{Fun:f Lparen:12 Args:[0xc0000720c0] Ellipsis:0 Rparen:16})
X ((Y)))) =&amp;gt; 1:8: expected &#39;EOF&#39;, found &#39;)&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.13.1/src/go/parser/parser.go&#34;&gt;実装&lt;/a&gt;を見てみたが再帰の連続でかなり骨が折れた。
調べてみると&lt;a href=&#34;https://godoc.org/golang.org/x/tools/cmd&#34;&gt;golang.org/x/tools/cmd&lt;/a&gt;にあるgoyaccを使うと文法からparserを生成できるようなので
これを使うことにした。&lt;/p&gt;

&lt;h2 id=&#34;goyacc&#34;&gt;goyacc&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/tools/cmd/goyacc&#34;&gt;goyacc&lt;/a&gt;はparser generatorであるyacc(yet another compiler compiler)のGo版。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get golang.org/x/tools/cmd/goyacc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;yacc文法ファイル&lt;a href=&#34;https://github.com/golang/tools/blob/gopls/v0.1.7/cmd/goyacc/testdata/expr/expr.y&#34;&gt;expr.y&lt;/a&gt;に対して実行すると
&lt;code&gt;y.go&lt;/code&gt;ができる。実行すると入力を受け付け、式を評価して表示するが、これはgoyaccの機能ではなく文法ファイルに書いてある挙動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/golang/tools/gopls/v0.1.7/cmd/goyacc/testdata/expr/expr.y
$ goyacc -p &amp;quot;expr&amp;quot; expr.y
$ go run y.go
&amp;gt; 2 * ((2 + 2) - 1) / 2
3
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;yacc文法ファイル&#34;&gt;yacc文法ファイル&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;%%&lt;/code&gt;で区切られた3つの部分からなる。&lt;/p&gt;

&lt;h3 id=&#34;定義部&#34;&gt;定義部&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;%{&lt;/code&gt;と&lt;code&gt;%}&lt;/code&gt;で囲まれた部分にコードを書けるのでpackage名やimportを書く。
&lt;code&gt;%union&lt;/code&gt;は取り得る型の共用体で、&lt;code&gt;%token &amp;lt;type&amp;gt;&lt;/code&gt;で規則によってreduceされる非終端記号を、&lt;code&gt;%type &amp;lt;type&amp;gt;&lt;/code&gt;で終端記号の種類と型を定義する。
大文字と小文字は区別され、非終端記号は小文字で、終端記号は大文字にすることが多いようだ。
&lt;code&gt;&#39;&#39;&lt;/code&gt;で囲まれた一文字記号はここで定義しなくても規則で使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%{

package main

import (
	&amp;quot;bufio&amp;quot;
	&amp;quot;bytes&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;math/big&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;unicode/utf8&amp;quot;
)

%}

%union {
	num *big.Rat
}

%type	&amp;lt;num&amp;gt;	expr expr1 expr2 expr3

%token &#39;+&#39; &#39;-&#39; &#39;*&#39; &#39;/&#39; &#39;(&#39; &#39;)&#39;

%token	&amp;lt;num&amp;gt;	NUM
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;規則部&#34;&gt;規則部&lt;/h3&gt;

&lt;p&gt;BNF(Backus-Naur Form)のような記法で、&lt;code&gt;左辺: 右辺&lt;/code&gt;で右辺が左辺にreduceされる規則を表す。
&lt;code&gt;{}&lt;/code&gt;の中にはコードが書けて、&lt;code&gt;$$&lt;/code&gt;が左辺で&lt;code&gt;$n&lt;/code&gt;が右辺のn番目のtokenになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;top:
	expr
	{
		if $1.IsInt() {
			fmt.Println($1.Num().String())
		} else {
			fmt.Println($1.String())
		}
	}

expr:
	expr1
|	&#39;+&#39; expr
	{
		$$ = $2
	}
|	&#39;-&#39; expr
	{
		$$ = $2.Neg($2)
	}

expr1:
	expr2
|	expr1 &#39;+&#39; expr2
	{
		$$ = $1.Add($1, $3)
	}
|	expr1 &#39;-&#39; expr2
	{
		$$ = $1.Sub($1, $3)
	}

expr2:
	expr3
|	expr2 &#39;*&#39; expr3
	{
		$$ = $1.Mul($1, $3)
	}
|	expr2 &#39;/&#39; expr3
	{
		$$ = $1.Quo($1, $3)
	}

expr3:
	NUM
|	&#39;(&#39; expr &#39;)&#39;
	{
		$$ = $2
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ユーザ定義部&#34;&gt;ユーザ定義部&lt;/h3&gt;

&lt;p&gt;コードを書けてそのまま出力されるが、別のgoファイルに分けた方がエディタのシンタックスハイライトやエラーチェックが効くので書きやすいと思う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
func main() {
	in := bufio.NewReader(os.Stdin)
	for {
		if _, err := os.Stdout.WriteString(&amp;quot;&amp;gt; &amp;quot;); err != nil {
			log.Fatalf(&amp;quot;WriteString: %s&amp;quot;, err)
		}
		line, err := in.ReadBytes(&#39;\n&#39;)
		if err == io.EOF {
			return
		}
		if err != nil {
			log.Fatalf(&amp;quot;ReadBytes: %s&amp;quot;, err)
		}

		exprParse(&amp;amp;exprLex{line: line})
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;prefix&amp;gt;Parse&lt;/code&gt;はgoyaccによって作られる関数で、&lt;code&gt;Lex(*&amp;lt;prefix&amp;gt;SymType) int&lt;/code&gt;と&lt;code&gt;Error(string)&lt;/code&gt;を実装したLexerを引数に取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// The parser uses the type &amp;lt;prefix&amp;gt;Lex as a lexer. It must provide
// the methods Lex(*&amp;lt;prefix&amp;gt;SymType) int and Error(string).
type exprSymType struct {
    yys int
    num *big.Rat
}
type exprLexer interface {
    Lex(lval *exprSymType) int
    Error(s string)
}
func exprParse(exprlex exprLexer) int {
    return exprNewParser().Parse(exprlex)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Lex()&lt;/code&gt;は値を&lt;code&gt;*&amp;lt;prefix&amp;gt;SymType&lt;/code&gt;に入れて、一文字記号はそのruneをintにキャストしたものを、それ以外のtoken(NUM)はgoyaccによって数値が割り当てられているのでそれを返す。
最後まで読んだら0を返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const eof = 0

func (x *exprLex) Lex(yylval *exprSymType) int {
	for {
		c := x.next()
		switch c {
		case eof:
			return eof
		case &#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;:
			return x.num(c, yylval)
		case &#39;+&#39;, &#39;-&#39;, &#39;*&#39;, &#39;/&#39;, &#39;(&#39;, &#39;)&#39;:
			return int(c)

		// Recognize Unicode multiplication and division
		// symbols, returning what the parser expects.
		case &#39;×&#39;:
			return &#39;*&#39;
		case &#39;÷&#39;:
			return &#39;/&#39;

		case &#39; &#39;, &#39;\t&#39;, &#39;\n&#39;, &#39;\r&#39;:
		default:
			log.Printf(&amp;quot;unrecognized character %q&amp;quot;, c)
		}
	}
}

const NUM = 57346

func (x *exprLex) num(c rune, yylval *exprSymType) int {
        add := func(b *bytes.Buffer, c rune) {
                if _, err := b.WriteRune(c); err != nil {
                        log.Fatalf(&amp;quot;WriteRune: %s&amp;quot;, err)
                }
        }
        var b bytes.Buffer
        add(&amp;amp;b, c)
L:
        for {
                c = x.next()
                switch c {
                case &#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;.&#39;, &#39;e&#39;, &#39;E&#39;:
                        add(&amp;amp;b, c)
                default:
                        break L
                }
        }
        if c != eof {
                x.peek = c
        }
        yylval.num = &amp;amp;big.Rat{}
        _, ok := yylval.num.SetString(b.String())
        if !ok {
                log.Printf(&amp;quot;bad number %q&amp;quot;, b.String())
                return eof
        }
        return NUM
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cons-car-cdr評価器を作る&#34;&gt;cons,car,cdr評価器を作る&lt;/h2&gt;

&lt;p&gt;ということでcons,car,cdr評価器を作る。全体のコードはGitHubにある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/goyacc-carcdr-evaluator&#34;&gt;sambaiz/goyacc-carcdr-evaluator&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;yacc文法ファイル-1&#34;&gt;yacc文法ファイル&lt;/h3&gt;

&lt;p&gt;文法ファイルのコードは最低限にして同じpackageのgoファイルに書いているのでユーザ定義部は空。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%{

package parser

import (
	&amp;quot;bytes&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;strconv&amp;quot;
)

%}

%union {
	value *Value
	num float64
}

%type &amp;lt;value&amp;gt; expr list nil atom 

%token CAR CDR CONS NIL

%token &amp;lt;num&amp;gt; NUM

%%

expr:
	list
|	atom

list:
	&#39;(&#39; CAR list &#39;)&#39;
	{
		$$ = $3.Left
	}
|	&#39;(&#39; CDR list &#39;)&#39;
	{
		$$ = $3.Right
	}
|	&#39;(&#39; CONS expr expr &#39;)&#39;
	{
		$$ = &amp;amp;Value{Left: $3, Right: $4}
	}
|	nil

nil:
	NIL
	{
		$$ = &amp;amp;Value{IsNil: true}
	}
|	&#39;(&#39; &#39;)&#39;
	{
		$$ = &amp;amp;Value{IsNil: true}
	}

atom: 
	NUM
	{
		$$ = &amp;amp;Value{Num: $1}
	}

%%
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;lexer&#34;&gt;Lexer&lt;/h3&gt;

&lt;p&gt;サンプルコードをベースにcons,car,cdr,nilに対応した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package parser

import (
	&amp;quot;bytes&amp;quot;
	&amp;quot;errors&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;strconv&amp;quot;
	&amp;quot;unicode&amp;quot;
	&amp;quot;unicode/utf8&amp;quot;
)

type lexer struct {
	line []byte
	peek *rune
	err error
}

func newLexer(line []byte) *lexer {
	return &amp;amp;lexer{
		line: line,
	}
}

const eof = 0

func (x *lexer) Lex(yylval *exprSymType) int {
	for {
		c := x.next()
		if &#39;a&#39; &amp;lt;= c &amp;amp;&amp;amp; c &amp;lt;= &#39;z&#39; || &#39;A&#39; &amp;lt;= c &amp;amp;&amp;amp; c &amp;lt;= &#39;Z&#39;  {
			return x.token(c, yylval)
		}
		switch c {
		case eof:
			return eof
		case &#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;:
			return x.num(c, yylval)
		case &#39;(&#39;, &#39;)&#39;:
			return int(c)

		case &#39; &#39;, &#39;\t&#39;, &#39;\n&#39;, &#39;\r&#39;:
		default:
			log.Printf(&amp;quot;unrecognized character %q&amp;quot;, c)
		}
	}
}

func (x *lexer) next() rune {
	...
}

func (x *lexer) num(c rune, yylval *exprSymType) int {
	...
}

var tokenMap = map[string]int{
	&amp;quot;car&amp;quot;: CAR,
	&amp;quot;cdr&amp;quot;: CDR,
	&amp;quot;cons&amp;quot;: CONS,
	&amp;quot;nil&amp;quot;: NIL,
}

func (x *lexer) token(c rune, yylval *exprSymType) int {
	add := func(b *bytes.Buffer, c rune) {
		if _, err := b.WriteRune(c); err != nil {
			log.Fatalf(&amp;quot;WriteRune: %s&amp;quot;, err)
		}
	}
	var b bytes.Buffer
	add(&amp;amp;b, unicode.ToLower(c))
	for {
		c = x.next()
		if &#39;a&#39; &amp;lt;= c &amp;amp;&amp;amp; c &amp;lt;= &#39;z&#39; || &#39;A&#39; &amp;lt;= c &amp;amp;&amp;amp; c &amp;lt;= &#39;Z&#39; {
			add(&amp;amp;b, unicode.ToLower(c))
		} else {
			x.peek = &amp;amp;c
			break
		}
	}
	token, ok := tokenMap[b.String()]
	if !ok {
		log.Printf(&amp;quot;unknown token %q&amp;quot;, b.String())
		return eof
	}
	return token
}


func (x *lexer) Error(s string) {
	x.err = errors.New(s)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テストを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package parser

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;github.com/stretchr/testify/assert&amp;quot;
	&amp;quot;testing&amp;quot;
)

func TestLexerLex(t *testing.T) {
	tests := []struct {
		expr []byte
		outs []int
		symTypes []*exprSymType
	} {
		{
			expr: []byte(&amp;quot;123.456&amp;quot;),
			outs: []int{NUM},
			symTypes: []*exprSymType{
				{
					num: 123.456,
				},
			},
		},
		{
			expr: []byte(&amp;quot;(cons 1 2)&amp;quot;),
			outs: []int{&#39;(&#39;, CONS, NUM, NUM, &#39;)&#39;},
			symTypes: []*exprSymType{
				{},
				{},
				{
					num: 1,
				},
				{
					num: 2,
				},
				{},
			},
		},
		{
			expr: []byte(&amp;quot;(cdr (CONS (car (cons () NIL)) 1e5))&amp;quot;),
			outs: []int{&#39;(&#39;, CDR, &#39;(&#39;, CONS, &#39;(&#39;, CAR, &#39;(&#39;, CONS, &#39;(&#39;, &#39;)&#39;, NIL, &#39;)&#39;, &#39;)&#39;, NUM, &#39;)&#39;, &#39;)&#39;},
			symTypes: []*exprSymType{
				{},
				{}, // CDR
				{},
				{}, // CONS
				{},
				{}, // CAR
				{},
				{}, // CONS
				{},
				{},
				{}, // NIL
				{},
				{},
				{
					num: 1e5,
				},
				{},
				{},
			},
		},
	}
	for _, test := range tests {
		t.Run(fmt.Sprintf(&amp;quot;%s -&amp;gt; %v&amp;quot;, string(test.expr), test.outs), func(t *testing.T) {
			i := 0
			lexer := newLexer([]byte(test.expr))
			for {
				symType := &amp;amp;exprSymType{}
				char := lexer.Lex(symType)
				if char == eof {
					break
				}
				assert.Equal(t, test.outs[i], char)
				assert.Equal(t, test.symTypes[i], symType)
				i++
			}
			assert.Equal(t, i, len(test.outs))
		})
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;parser&#34;&gt;Parser&lt;/h3&gt;

&lt;p&gt;サンプルでは直接&lt;code&gt;&amp;lt;prefix&amp;gt;Parse()&lt;/code&gt;を呼んでいたが、評価した値を扱えるように&lt;code&gt;&amp;lt;prefix&amp;gt;ParserImpl&lt;/code&gt;からParseする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package parser

func Parse(line string) (*Value, error) {
	exprErrorVerbose = true
	parser := &amp;amp;exprParserImpl{}
	lexer := newLexer([]byte(line))
	parser.Parse(lexer)
	if lexer.err != nil {
		return nil, lexer.err
	}
	if len(parser.stack) &amp;lt; 2 {
		return nil, nil
	}
	return parser.stack[1].value, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;package parser

import (
	&amp;quot;github.com/stretchr/testify/assert&amp;quot;
	&amp;quot;testing&amp;quot;
)

func TestParse(t *testing.T) {
	tests := []struct {
		in string
		expected string
	} {
		{
			in: &amp;quot;123.456&amp;quot;,
			expected: &amp;quot;123.456&amp;quot;,
		},
		{
			in: &amp;quot;(cdr (CONS (car (cons () NIL)) 1e5))&amp;quot;,
			expected: &amp;quot;100000&amp;quot;,
		},
		{
			in: &amp;quot;(cons (cons 1 2) 3)&amp;quot;,
			expected: &amp;quot;((1 . 2) . 3)&amp;quot;,
		},
	}
	for _, test := range tests {
		t.Run(test.in, func(t *testing.T) {
			out, err := Parse(test.in)
			assert.Equal(t, test.expected, out.String())
			assert.Nil(t, err)
		})
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;実行結果&#34;&gt;実行結果&lt;/h3&gt;

&lt;p&gt;動いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go run main.go
&amp;gt; (car (cdr (cons 1 (cons (cons 20 300.4) (cons 50 60)))))
(20 . 300.4)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.eidos.ic.i.u-tokyo.ac.jp/~tau/lecture/programming_languages/gen/slides/pdf/09-lexer-parser.pdf&#34;&gt;プログラミング言語 8 字句解析器(lexer)と構文解析器(parser)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://i.loveruby.net/ja/rhg/book/yacc.html&#34;&gt;第9章 速習yacc&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ISUCON9予選と本選に出た</title>
          <link>https://www.sambaiz.net/article/243/</link>
          <pubDate>Sat, 05 Oct 2019 23:41:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/243/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://isucon.net/&#34;&gt;ISUCON&lt;/a&gt;はLINEが運営しているIikanjini Speed Up CONtestで、Webサービスをチューニングしベンチマークのスコアを競う。
&lt;a href=&#34;https://github.com/hidelberq&#34;&gt;@hiderberq&lt;/a&gt;と&lt;a href=&#34;https://github.com/satoshun&#34;&gt;@satoshun&lt;/a&gt;と出た。初出場。&lt;/p&gt;

&lt;h2 id=&#34;前&#34;&gt;前&lt;/h2&gt;

&lt;p&gt;@hiderberqに誘ってもらいチームSsstohが結成された。言語はGoで行くと決めて3回くらい集まって過去問を少しやった。&lt;/p&gt;

&lt;h2 id=&#34;予選&#34;&gt;予選&lt;/h2&gt;

&lt;p&gt;会社が計画停電だったので話せるネットカフェでやった。
デプロイスクリプトを整えてnginxのアクセスログを&lt;a href=&#34;https://github.com/tkuchiki/alp&#34;&gt;alp&lt;/a&gt;で見られるようにする準備や
MySQLのSlow Queryを出すところまでは良かったが、pprofのエンドポイントを叩くタイミングが悪くて
profileが出力できずbcryptがボトルネックであることに最後まで気づけなかった。
最後そろそろ複数マシンで動かすかという段になったが、時間があまり残っていなかったしうまく動かすことができなかった。急いでやって最後のベンチマークがFailするよりはましだったかもしれない。仕様をたいして読まなかったのでキャンペーンの数値が変えられることも忘れていた。仕様を読み込むのは本当に重要。
これはだめだなと思ったらなぜか通過していた。600チーム中20位だ。ありがとう@satoshun。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://satoshun.github.io/2019/09/isucon2019-qualify/&#34;&gt;ISUCON9 予選ログ  - stsnブログ&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;間&#34;&gt;間&lt;/h2&gt;

&lt;p&gt;pprofやnginxのLB、あとMySQLのEXPLAINを練習した。あとAPMを用意していった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/241/&#34;&gt;K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;本選&#34;&gt;本選&lt;/h2&gt;

&lt;p&gt;本選はLINE本社、新宿のミライナタワーで行われる。ミライナタワー改札というのがあってアクセスが良い。
会場のカフェスペースもソファー席や座敷もあったりして良いスペースだった。&lt;/p&gt;

&lt;p&gt;受付でかっこいいTシャツとイカしたステッカーを獲得。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/243-1.jpg&#34; alt=&#34;Tシャツとステッカー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ベンチマークが最初からFailするようになってて大変だった。
急いで開発したという設定で、コードや設定に不要なものが多く含まれていて翻弄された。
ロジックが複雑でこれを何とかしないと始まらないのではと思ったが、インデックスによってFailしなくなったのでそんなことはなかった。&lt;/p&gt;

&lt;p&gt;昼には弁当が来た。美味しい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/243-2.jpg&#34; alt=&#34;弁当&#34; /&gt;&lt;/p&gt;

&lt;p&gt;午後はサーバーを1台再起不能にした。あとはN+1をやって終了。表彰と講評。ブラウザチェックNGで参考記録になったが、スコアは3611で17位相当だった。
1位の白金動物園は35801、2位のnilは29704(しかも一人で)とスコアを見ると全くかなわないという感じ。
ただN+1やインデックスなど基本的なところは押さえていたようだったので、まずはそのステージを超えなくてはいけなかった。
また一通りインメモリにデータを持ったら負荷のパラメータである日数を伸ばしたときにOOMになった。
今回はメモリが少なかったのでSQLの修正でスコアを上げられるようになっていたそうだ。&lt;/p&gt;

&lt;p&gt;全てが終わり懇親会が始まった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/243-3.jpg&#34; alt=&#34;懇親会&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;感想&#34;&gt;感想&lt;/h2&gt;

&lt;p&gt;普段クラウドのマネージドなサービスや金で解決することに慣れているとこんなに何もできないものかと愕然した。チームの二人には申し訳なさがある。
テーブルの変更などこれやるの億劫だなというところも上位チームは普通にやっていたりして要所の見極めや実装力が足りなかったり、
なんでこれができなかったんだというポイントが多々あるので練度が低く、本番の焦燥感に打ち負けた。
その点では本選まで来れたことは今後の資産になるだろうし、とても楽しかったので実質優勝だ。嬉しい。
運営にも感謝だ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HTTPのCache-Control Header</title>
          <link>https://www.sambaiz.net/article/242/</link>
          <pubDate>Fri, 04 Oct 2019 14:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/242/</guid>
          <description>

&lt;p&gt;HTTPで&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control&#34;&gt;Cache-Control&lt;/a&gt; Headerを付けてレスポンスすると、
クライアントにキャッシュさせてリクエストの回数やレスポンスの通信量を削減することができる。CDNによって挙動が異なるようなので注意が必要。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://tech.mercari.com/entry/2017/06/22/204500&#34;&gt;CDN切り替え作業における、Web版メルカリの個人情報流出の原因につきまして - Mercari Engineering Blog&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;max-age&#34;&gt;max-age&lt;/h3&gt;

&lt;p&gt;キャッシュが有効な秒数を表す。&lt;code&gt;s-maxage&lt;/code&gt;というのもあってこれはプロキシやCDNといった共有キャッシュでのみ適用される時間。
&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Expires&#34;&gt;Expires&lt;/a&gt; Headerがあったとしてもこれらが優先される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cache-Control: max-age=30
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;private&#34;&gt;private&lt;/h3&gt;

&lt;p&gt;単一ユーザー向けのレスポンスであることを表し、共有キャッシュに保存させないようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cache-Control: private, max-age=30
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;no-cache&#34;&gt;no-cache&lt;/h3&gt;

&lt;p&gt;ETag付きのリクエストを毎回投げる。
&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag&#34;&gt;ETag&lt;/a&gt;はリソースの識別子を表すHeaderで、
前回返ってきたETagをリクエストの&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/If-None-Match&#34;&gt;If-None-Match&lt;/a&gt; Headerで渡すと、変更されてない場合は代わりに&lt;code&gt;304 Not Modified&lt;/code&gt;が返るのでキャッシュを使い、帯域を節約できる。
つまりキャッシュされないというわけではない。&lt;/p&gt;

&lt;h3 id=&#34;no-store&#34;&gt;no-store&lt;/h3&gt;

&lt;p&gt;キャッシュさせない。毎回リクエストが飛びレスポンスが返る。&lt;/p&gt;

&lt;p&gt;max-ageもExpires Headerもない場合でも&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Last-Modified&#34;&gt;Last-Modified&lt;/a&gt; Headerがあれば
&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching#Freshness&#34;&gt;キャッシュされる&lt;/a&gt;のでキャッシュさせたくない場合は明示的に書いたほうがよい。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching&#34;&gt;HTTP キャッシュ  |  Web Fundamentals  |  Google Developers&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ipa.go.jp/security/awareness/vendor/programmingv2/contents/405.html&#34;&gt;IPA ISEC　セキュア・プログラミング講座：Webアプリケーション編　第5章 暴露対策：プロキシキャッシュ対策&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする</title>
          <link>https://www.sambaiz.net/article/241/</link>
          <pubDate>Tue, 01 Oct 2019 23:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/241/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/elastic/cloud-on-k8s&#34;&gt;Elastic Cloud on Kubernetes (ECK)&lt;/a&gt;で
Kubernetesクラスタ上にElasticsearch, KibanaとAPM Serverを立ち上げ、外部のGo製APIサーバーのリクエストをトレースする。
クラスタはGKEで作成し、ノードプールはn2-highmem-4(2vCPU, 13GB)の3台にした。&lt;/p&gt;

&lt;h2 id=&#34;インストール-https-www-elastic-co-guide-en-cloud-on-k8s-0-9-k8s-quickstart-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/cloud-on-k8s/0.9/k8s-quickstart.html&#34;&gt;インストール&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ElasticSearchやKibana, APM ServerのCRDやelastic-operatorなどをインストールする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/182/&#34;&gt;KubernetesのCustom Resource Definition(CRD)とCustom Controller - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl apply -f https://download.elastic.co/downloads/eck/0.9.0/all-in-one.yaml
customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/trustrelationships.elasticsearch.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created
clusterrole.rbac.authorization.k8s.io/elastic-operator created
clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created
namespace/elastic-system created
statefulset.apps/elastic-operator created
secret/webhook-server-secret created
serviceaccount/elastic-operator created
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pod -n elastic-system
NAME                 READY   STATUS    RESTARTS   AGE
elastic-operator-0   1/1     Running   1          91s

$ kubectl -n elastic-system logs -f statefulset.apps/elastic-operator
...
{&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1569230702.0881083,&amp;quot;logger&amp;quot;:&amp;quot;kubebuilder.controller&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;Starting workers&amp;quot;,&amp;quot;controller&amp;quot;:&amp;quot;elasticsearch-controller&amp;quot;,&amp;quot;worker count&amp;quot;:1}
{&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1569230702.1144261,&amp;quot;logger&amp;quot;:&amp;quot;kubebuilder.webhook&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;starting the webhook server.&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;

&lt;h3 id=&#34;elasticsearch-https-github-com-elastic-cloud-on-k8s-blob-0-9-0-operators-pkg-apis-elasticsearch-v1alpha1-elasticsearch-types-go-l19&#34;&gt;&lt;a href=&#34;https://github.com/elastic/cloud-on-k8s/blob/0.9.0/operators/pkg/apis/elasticsearch/v1alpha1/elasticsearch_types.go#L19&#34;&gt;Elasticsearch&lt;/a&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cat &amp;lt;&amp;lt;EOF | kubectl apply -f -
apiVersion: elasticsearch.k8s.elastic.co/v1alpha1
kind: Elasticsearch
metadata:
  name: myes
spec:
  version: 7.2.0
  nodes:
  - nodeCount: 1
    config:
      node.master: true
      node.data: true
      node.ingest: true
    volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 10Gi
          storageClassName: standard
EOF

$ kubectl get elasticsearch
NAME   HEALTH   NODES   VERSION   PHASE         AGE
myes   green    1       7.2.0     Operational   4m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podが立ち上がるまで少し時間がかかる。ユーザーelasticのパスワードはsecretにある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get secret | grep &#39;myes&#39;
myes-es-7jzg7sqxqt-certs         Opaque                                3      4m42s
myes-es-7jzg7sqxqt-config        Opaque                                1      4m42s
myes-es-elastic-user             Opaque                                1      4m42s
myes-es-http-ca-internal         Opaque                                2      4m43s
myes-es-http-certs-internal      Opaque                                2      4m43s
myes-es-http-certs-public        Opaque                                1      4m43s
myes-es-internal-users           Opaque                                3      4m42s
myes-es-transport-ca-internal    Opaque                                2      4m42s
myes-es-transport-certs-public   Opaque                                1      4m42s
myes-es-xpack-file-realm         Opaque                                3      4m42s

$ PASSWORD=$(kubectl get secret myes-es-elastic-user -o=jsonpath=&#39;{.data.elastic}&#39; | base64 -D)
$ kubectl port-forward service/myes-es-http 9200 &amp;amp;
$ curl -u &amp;quot;elastic:$PASSWORD&amp;quot; -k &amp;quot;https://localhost:9200&amp;quot; | jq &amp;quot;.cluster_name&amp;quot;
&amp;quot;myes&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kibana-https-github-com-elastic-cloud-on-k8s-blob-0-9-0-operators-pkg-apis-kibana-v1alpha1-kibana-types-go-l20&#34;&gt;&lt;a href=&#34;https://github.com/elastic/cloud-on-k8s/blob/0.9.0/operators/pkg/apis/kibana/v1alpha1/kibana_types.go#L20&#34;&gt;Kibana&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;port-forwardなしで外からアクセスできるようにserviceをLoadBalancerにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat &amp;lt;&amp;lt;EOF | kubectl apply -f -
apiVersion: kibana.k8s.elastic.co/v1alpha1
kind: Kibana
metadata:
  name: mykibana
spec:
  version: 7.2.0
  nodeCount: 1
  http:
    service:
      spec:
        type: LoadBalancer
  elasticsearchRef:
    name: myes
EOF

$ kubectl get kibana
NAME       HEALTH   NODES   VERSION   AGE
mykibana   green    1       7.2.0     1m

$ open https://$(kubectl get service mykibana-kb-http -o=jsonpath=&#39;{.status.loadBalancer.ingress[0].ip}:{.spec.ports[0].port}&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ユーザーelasticでログインできる。&lt;/p&gt;

&lt;h3 id=&#34;apmserver-https-github-com-elastic-cloud-on-k8s-blob-0-9-0-operators-pkg-apis-apm-v1alpha1-apmserver-types-go-l19&#34;&gt;&lt;a href=&#34;https://github.com/elastic/cloud-on-k8s/blob/0.9.0/operators/pkg/apis/apm/v1alpha1/apmserver_types.go#L19&#34;&gt;ApmServer&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;今回はクラスタ外から送るので同じくLoadBalancerにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat &amp;lt;&amp;lt;EOF | kubectl apply -f -
apiVersion: apm.k8s.elastic.co/v1alpha1
kind: ApmServer
metadata:
  name: myapm-server
spec:
  version: 7.2.0
  nodeCount: 1
  http:
    service:
      spec:
        type: LoadBalancer
  elasticsearchRef:
    name: myes
EOF

$ kubectl get apmserver
NAME           HEALTH   NODES   VERSION   AGE
myapm-server   green    1       7.2.0     9m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;KibanaからAPM Serverが動いていることを確認する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/241.png&#34; alt=&#34;APM Server status&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;apm-agentの設定&#34;&gt;APM Agentの設定&lt;/h2&gt;

&lt;p&gt;APM Agentをモニタリングするアプリケーションに入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get go.elastic.co/apm

$ export ELASTIC_APM_SERVER_URL=https://$(kubectl get service myapm-server-apm-http -o=jsonpath=&#39;{.status.loadBalancer.ingress[0].ip}:{.spec.ports[0].port}&#39;)

$ export ELASTIC_APM_SECRET_TOKEN=$(kubectl get secret/myapm-server-apm-token -o=jsonpath=&#39;{.data.secret-token}&#39; | base64 -D)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/apm/agent/go/1.x/instrumenting-source.html#builtin-modules-apmhttp&#34;&gt;module/apmhttp&lt;/a&gt;や
&lt;a href=&#34;https://www.elastic.co/guide/en/apm/agent/go/1.x/instrumenting-source.html#builtin-modules-apmsql&#34;&gt;module/apmsql&lt;/a&gt;を使うと、
リクエスト全体のTransactionに対してそれぞれの処理部分がSpanとしてトレースされる。
contextを渡してやらないとTransactionを追跡できずSpanが作成されない。
自前でTransactionやSpanを&lt;a href=&#34;https://www.elastic.co/guide/en/apm/agent/go/1.x/instrumenting-source.html#custom-instrumentation&#34;&gt;作成する&lt;/a&gt;こともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
	&amp;quot;net/http&amp;quot;

	&amp;quot;go.elastic.co/apm/module/apmhttp&amp;quot;
	&amp;quot;go.elastic.co/apm/module/apmsql&amp;quot;
	_ &amp;quot;go.elastic.co/apm/module/apmsql/mysql&amp;quot;
)

var tracingClient = apmhttp.WrapClient(http.DefaultClient)

func main() {
	mux := http.NewServeMux()
  mux.HandleFunc(&amp;quot;/ping&amp;quot;, func(w http.ResponseWriter, r *http.Request) {
    	db, err := apmsql.Open(&amp;quot;mysql&amp;quot;, dsn)
      tracingClient.Do(req.WithContext(ctx))
      fmt.Fprintf(w, &amp;quot;ok&amp;quot;)
  })
	http.ListenAndServe(&amp;quot;:8080&amp;quot;, apmhttp.Wrap(mux))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行しCheck agent statusしても&lt;code&gt;No data has been received from agents yet&lt;/code&gt;から変わらない。
デフォルトでログが出ないので&lt;a href=&#34;https://www.elastic.co/guide/en/apm/agent/go/current/configuration.html#config-log-file&#34;&gt;ELASTIC_APM_LOG_FILE&lt;/a&gt;に値を入れてログを見てみたところ証明書で引っかかっていることが分かった。
&lt;a href=&#34;https://www.elastic.co/guide/en/apm/agent/go/current/configuration.html#config-server-cert&#34;&gt;ELASTIC_APM_VERIFY_SERVER_CERT&lt;/a&gt;をfalseにしたところ送られるようになったのでLaunch APMする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export ELASTIC_APM_LOG_FILE=stderr
{&amp;quot;level&amp;quot;:&amp;quot;error&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2019-10-01T19:18:15+09:00&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;config request failed: sending config request failed: Get https://104.155.169.150:8200/config/v1/agents?service.name=isucari: x509: cannot validate certificate for 104.155.169.150 because it doesn&#39;t contain any IP SANs&amp;quot;}

$ export ELASTIC_APM_VERIFY_SERVER_CERT=false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/isucon/isucon9-qualify.git&#34;&gt;ISUCON9の予選問題&lt;/a&gt;に入れてみた。
リクエスト中の外部サーバーへのリクエストやDBのクエリのタイミングやかかっている時間がTimeline上に表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/241-2.png&#34; alt=&#34;Timeline&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/jp/blog/how-to-instrument-your-go-app-with-the-elastic-apm-go-agent&#34;&gt;How to instrument your Go application with the Elastic APM Go agent | Elastic Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLのslow queryを出してEXPLAINしてインデックスを張る</title>
          <link>https://www.sambaiz.net/article/240/</link>
          <pubDate>Sat, 21 Sep 2019 22:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/240/</guid>
          <description>

&lt;p&gt;MySQLのslow queryを出してEXPLAINしてインデックスを張るのを
&lt;a href=&#34;https://github.com/isucon/isucon9-qualify.git&#34;&gt;ISUCON9の予選問題&lt;/a&gt;でやってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mysql --version
mysql  Ver 8.0.17 for osx10.14 on x86_64 (Homebrew)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;slow_query_log&lt;/code&gt;をONにすると実行時間が&lt;code&gt;long_query_time&lt;/code&gt;を超えていて&lt;code&gt;min_examined_row_limit&lt;/code&gt;以上の行を返すクエリがslow query logに出力される。
&lt;code&gt;log_queries_not_using_indexes&lt;/code&gt;が有効ならインデックスを使用してないクエリもログに出て、
&lt;code&gt;log_throttle_queries_not_using_indexes&lt;/code&gt;でその分あたりの数を制限できる。
MySQL 8.0.14から追加された&lt;code&gt;log_slow_extra&lt;/code&gt;をONにするとフィールドが&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/slow-query-log.html#slow-query-log-contents&#34;&gt;追加される&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; show variables like &#39;%slow%&#39;;
+---------------------------+-----------------------------------+
| Variable_name             | Value                             |
+---------------------------+-----------------------------------+
| log_slow_admin_statements | OFF                               |
| log_slow_extra            | OFF                               |
| log_slow_slave_statements | OFF                               |
| slow_launch_time          | 2                                 |
| slow_query_log            | OFF                               |
| slow_query_log_file       | /usr/local/var/mysql/mbp-slow.log |
+---------------------------+-----------------------------------+
6 rows in set (0.00 sec)

mysql&amp;gt; show variables like &#39;%long_query%&#39;;
+-----------------+-----------+
| Variable_name   | Value     |
+-----------------+-----------+
| long_query_time | 10.000000 |
+-----------------+-----------+
1 row in set (0.00 sec)

mysql&amp;gt; show variables like &#39;%not_using_indexes%&#39;;
+----------------------------------------+-------+
| Variable_name                          | Value |
+----------------------------------------+-------+
| log_queries_not_using_indexes          | OFF   |
| log_throttle_queries_not_using_indexes | 0     |
+----------------------------------------+-------+
2 rows in set (0.00 sec)


mysql&amp;gt; show variables like &#39;%min_examined%&#39;;
+------------------------+-------+
| Variable_name          | Value |
+------------------------+-------+
| min_examined_row_limit | 0     |
+------------------------+-------+
1 row in set (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということで&lt;code&gt;slow_query_log&lt;/code&gt;をONにして100ms以上のクエリを出すようにする。
&lt;code&gt;set persist&lt;/code&gt;はMySQL 8.0からの構文で&lt;code&gt;set global&lt;/code&gt;とは異なり再起動しても消えない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; set persist slow_query_log = ON;
mysql&amp;gt; set persist long_query_time = 0.1;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ベンチマークを実行しslow.logが出ていることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./bin/benchmarker
{&amp;quot;pass&amp;quot;:true,&amp;quot;score&amp;quot;:2510,&amp;quot;campaign&amp;quot;:0,&amp;quot;language&amp;quot;:&amp;quot;Go&amp;quot;,&amp;quot;messages&amp;quot;:[]}

$ head /usr/local/var/mysql/mbp-slow.log 
/usr/local/Cellar/mysql/8.0.17_1/bin/mysqld, Version: 8.0.17 (Homebrew). started with:
Tcp port: 3306  Unix socket: /tmp/mysql.sock
Time                 Id Command    Argument
# Time: 2019-09-19T00:52:13.957303Z
# User@Host: isucari[isucari] @ localhost [127.0.0.1]  Id:    23
# Query_time: 0.121599  Lock_time: 0.000058 Rows_sent: 49  Rows_examined: 50051
use isucari;
SET timestamp=1568854333;
SELECT * FROM `items` WHERE `seller_id` = 818 AND `status` IN (&#39;on_sale&#39;,&#39;trading&#39;,&#39;sold_out&#39;) AND (`created_at` &amp;lt; &#39;2019-08-12 09:59:09&#39;  OR (`created_at` &amp;lt;= &#39;2019-08-12 09:59:09&#39; AND `id` &amp;lt; 28740)) ORDER BY `created_at` DESC, `id` DESC LIMIT 49;
# Time: 2019-09-19T00:52:14.000428Z
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/mysqldumpslow.html&#34;&gt;mysqldumpslow&lt;/a&gt;で平均実行時間(at)順にまとめて出力できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mysqldumpslow -s at /usr/local/var/mysql/mbp-slow.log

Reading mysql slow query log from /usr/local/var/mysql/mbp-slow.log
Count: 44  Time=0.29s (12s)  Lock=0.00s (0s)  Rows=49.0 (2156), isucari[isucari]@localhost
  SELECT * FROM `items` WHERE `status` IN (&#39;S&#39;,&#39;S&#39;) AND (`created_at` &amp;lt; &#39;S&#39;  OR (`created_at` &amp;lt;= &#39;S&#39; AND `id` &amp;lt; N)) ORDER BY `created_at` DESC, `id` DESC LIMIT N

Count: 5  Time=0.19s (0s)  Lock=0.00s (0s)  Rows=0.0 (0), isucari[isucari]@localhost
  #

Count: 24  Time=0.19s (4s)  Lock=0.00s (0s)  Rows=34.2 (821), isucari[isucari]@localhost
  SELECT * FROM `items` WHERE `seller_id` = N AND `status` IN (&#39;S&#39;,&#39;S&#39;,&#39;S&#39;) AND (`created_at` &amp;lt; &#39;S&#39;  OR (`created_at` &amp;lt;= &#39;S&#39; AND `id` &amp;lt; N)) ORDER BY `created_at` DESC, `id` DESC LIMIT N

Count: 6  Time=0.19s (1s)  Lock=0.00s (0s)  Rows=9.2 (55), isucari[isucari]@localhost
  SELECT * FROM `items` WHERE (`seller_id` = N OR `buyer_id` = N) AND `status` IN (&#39;S&#39;,&#39;S&#39;,&#39;S&#39;,&#39;S&#39;,&#39;S&#39;) ORDER BY `created_at` DESC, `id` DESC LIMIT N

Count: 10  Time=0.18s (1s)  Lock=0.00s (0s)  Rows=49.0 (490), isucari[isucari]@localhost
  SELECT * FROM `items` WHERE `status` IN (&#39;S&#39;,&#39;S&#39;) AND category_id IN (N, N, N, N) AND (`created_at` &amp;lt; &#39;S&#39;  OR (`created_at` &amp;lt;= &#39;S&#39; AND `id` &amp;lt; N)) ORDER BY `created_at` DESC, `id` DESC LIMIT N

Count: 48  Time=0.18s (8s)  Lock=0.00s (0s)  Rows=17.2 (828), isucari[isucari]@localhost
  SELECT * FROM `items` WHERE `seller_id` = N AND `status` IN (&#39;S&#39;,&#39;S&#39;,&#39;S&#39;) ORDER BY `created_at` DESC, `id` DESC LIMIT N

Count: 92  Time=0.17s (15s)  Lock=0.00s (0s)  Rows=49.0 (4508), isucari[isucari]@localhost
  SELECT * FROM `items` WHERE `status` IN (&#39;S&#39;,&#39;S&#39;) AND category_id IN (N, N, N, N, N) AND (`created_at` &amp;lt; &#39;S&#39;  OR (`created_at` &amp;lt;= &#39;S&#39; AND `id` &amp;lt; N)) ORDER BY `created_at` DESC, `id` DESC LIMIT N

Count: 1  Time=0.17s (0s)  Lock=0.00s (0s)  Rows=49.0 (49), isucari[isucari]@localhost
  SELECT * FROM `items` WHERE `status` IN (&#39;S&#39;,&#39;S&#39;) AND category_id IN (N, N, N, N, N, N) ORDER BY created_at DESC, id DESC LIMIT N
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最も時間がかかっていた形式のクエリをEXPLAINしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; EXPLAIN SELECT * FROM `items` WHERE `status` IN (&#39;on_sale&#39;,&#39;sold_out&#39;) AND (`created_at` &amp;lt; &#39;2019-08-12 15:41:31&#39;  OR (`created_at` &amp;lt;= &#39;2019-08-12 15:41:31&#39; AND `id` &amp;lt; 49288)) ORDER BY `created_at` DESC, `id` DESC LIMIT 49 \G;
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: items
   partitions: NULL
         type: ALL
possible_keys: PRIMARY
          key: NULL
      key_len: NULL
          ref: NULL
         rows: 43831
     filtered: 16.29
        Extra: Using where; Using filesort
1 row in set, 1 warning (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;UNIONやサブクエリがないので&lt;code&gt;select_type=SIMPLE&lt;/code&gt;で、またJOINもしていないので一件しか返ってこない。&lt;code&gt;possible_keys&lt;/code&gt;が&lt;code&gt;PRIMARY&lt;/code&gt;しかないため何のインデックスも使わず(&lt;code&gt;key=NULL&lt;/code&gt;)フルテーブルスキャン(&lt;code&gt;type=ALL&lt;/code&gt;)しているのをなんとかしたい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; show index from items \G;
*************************** 1. row ***************************
        Table: items
   Non_unique: 0
     Key_name: PRIMARY
 Seq_in_index: 1
  Column_name: id
    Collation: A
  Cardinality: 43827
     Sub_part: NULL
       Packed: NULL
         Null: 
   Index_type: BTREE
      Comment: 
Index_comment: 
      Visible: YES
   Expression: NULL
*************************** 2. row ***************************
        Table: items
   Non_unique: 1
     Key_name: idx_category_id
 Seq_in_index: 1
  Column_name: category_id
    Collation: A
  Cardinality: 34
     Sub_part: NULL
       Packed: NULL
         Null: 
   Index_type: BTREE
      Comment: 
Index_comment: 
      Visible: YES
   Expression: NULL
2 rows in set (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこで&lt;code&gt;created_at&lt;/code&gt;にインデックスを張る。&lt;code&gt;(status, created_at)&lt;/code&gt;の複合キーも試してみたが&lt;code&gt;status&lt;/code&gt;のカーディナリティが低いからか使われなかった。&lt;code&gt;created_at&lt;/code&gt;は範囲で取るので&lt;code&gt;(created_at, status)&lt;/code&gt;だと&lt;code&gt;status&lt;/code&gt;を絞るためにB+Treeのleaf nodeを全て見ていく必要があり意味がない。
また、SELECTのカラムを絞って必要なデータがleaf nodeに揃っているカバリングインデックスにできれば、PKのB+Treeを見にいく必要がなくなり速くなるが、今回はクエリの内容は変えないことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; ALTER TABLE items ADD INDEX idx_created_at (created_at);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EXPLAINしてインデックスが使われていることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; ALTER TABLE items ADD INDEX idx_created_at (created_at);
mysql&amp;gt; EXPLAIN SELECT * FROM `items` WHERE `status` IN (&#39;on_sale&#39;,&#39;sold_out&#39;) AND (`created_at` &amp;lt; &#39;2019-08-12 15:41:31&#39;  OR (`created_at` &amp;lt;= &#39;2019-08-12 15:41:31&#39; AND `id` &amp;lt; 49288)) ORDER BY `created_at` DESC, `id` DESC LIMIT 49 \G;
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: items
   partitions: NULL
         type: range
possible_keys: PRIMARY,idx_created_at
          key: idx_created_at
      key_len: 13
          ref: NULL
         rows: 21916
     filtered: 40.00
        Extra: Using index condition; Using where; Backward index scan
1 row in set, 1 warning (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この状態で再度ベンチマークを実行したところ少しスコアが上がりslow.logに対象のクエリが出なくなった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ rm /usr/local/var/mysql/mbp-slow.log
$ touch /usr/local/var/mysql/mbp-slow.log
$ mysql.server restart
$ ./bin/benchmarker
{&amp;quot;pass&amp;quot;:true,&amp;quot;score&amp;quot;:2710,&amp;quot;campaign&amp;quot;:0,&amp;quot;language&amp;quot;:&amp;quot;Go&amp;quot;,&amp;quot;messages&amp;quot;:[]}

$ $ mysqldumpslow -s at /usr/local/var/mysql/mbp-slow.log | grep &#39;SELECT * FROM `items` WHERE `SELECT * FROM `items` WHERE `status` IN (&#39;S&#39;,&#39;S&#39;) AND (`created_at` &amp;lt; &#39;S&#39;  OR (`created_at` &amp;lt;= &#39;S&#39; AND `id` &amp;lt; N)) ORDER BY `created_at` DESC, `id` DESC LIMIT N&#39;

Reading mysql slow query log from /usr/local/var/mysql/mbp-slow.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://nippondanji.blogspot.com/2009/03/mysqlexplain.html&#34;&gt;漢(オトコ)のコンピュータ道: MySQLのEXPLAINを徹底解説!!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://techlife.cookpad.com/entry/2017/04/18/092524&#34;&gt;MySQL with InnoDB のインデックスの基礎知識とありがちな間違い - クックパッド開発者ブログ&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Ansibleでnginxを入れてLoad Balancingさせる</title>
          <link>https://www.sambaiz.net/article/239/</link>
          <pubDate>Tue, 17 Sep 2019 09:42:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/239/</guid>
          <description>

&lt;p&gt;EC2でUbuntu Server 18.04 LTS (ami-07d0cf3af28718ef8) の t3.medium (2vCPU, 4GiB) インスタンスを3台立ち上げた。この内1台をLB用とし、2台のAppサーバーに負荷分散させる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/ansible-nginx-lb-example&#34;&gt;https://github.com/sambaiz/ansible-nginx-lb-example&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;nginx-conf&#34;&gt;nginx.conf&lt;/h2&gt;

&lt;p&gt;LBとAppのnginx.conf。upstreamはデフォルトでラウンドロビンする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat conf/lb/nginx.conf
...
http {
  ...

  upstream app-server {
    server ip-172-31-94-208.ec2.internal;
    server ip-172-31-88-90.ec2.internal;
  }

  server {
    listen          80;
    server_name     .compute-1.amazonaws.com;
    access_log      /var/log/nginx/app-server.log main;

    location / {
      proxy_pass      http://app-server;
    }
  }
}

$ cat conf/app/nginx.conf
...
http {
  ...
  server {
    listen       80;
    server_name  .compute-1.amazonaws.com;

    location / {
      proxy_pass  http://127.0.0.1:8080;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ansibleの実行&#34;&gt;Ansibleの実行&lt;/h2&gt;

&lt;p&gt;まず&lt;a href=&#34;https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html&#34;&gt;Inventory&lt;/a&gt;を書いて疎通確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install --user ansible
$ cat hosts
[lb]
ec2-3-227-2-54.compute-1.amazonaws.com        ansible_ssh_private_key_file=***.pem        ansible_user=ubuntu

[app]
ec2-3-229-113-100.compute-1.amazonaws.com        ansible_ssh_private_key_file=***.pem     ansible_user=ubuntu
ec2-35-175-201-30.compute-1.amazonaws.com        ansible_ssh_private_key_file=***.pem     ansible_user=ubuntu

$ ansible all -i ./hosts -m ping
ec2-3-227-2-54.compute-1.amazonaws.com | SUCCESS =&amp;gt; {
    &amp;quot;ansible_facts&amp;quot;: {
        &amp;quot;discovered_interpreter_python&amp;quot;: &amp;quot;/usr/bin/python3&amp;quot;
    }, 
    &amp;quot;changed&amp;quot;: false, 
    &amp;quot;ping&amp;quot;: &amp;quot;pong&amp;quot;
}
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ansible Galaxyからnginx公式の&lt;a href=&#34;https://galaxy.ansible.com/nginxinc/nginx&#34;&gt;role&lt;/a&gt;を持ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ansible-galaxy install nginxinc.nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Playbookはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
- hosts: lb
  become: yes
  become_user: root
  roles:
  - role: nginxinc.nginx
    vars:
      nginx_main_upload_enable: true
      nginx_main_upload_src: conf/lb/nginx.conf
      nginx_main_upload_dest: /etc/nginx/
- hosts: app
  become: yes
  become_user: root
  roles:
  - role: nginxinc.nginx
    vars:
      nginx_main_upload_enable: true
      nginx_main_upload_src: conf/app/nginx.conf
      nginx_main_upload_dest: /etc/nginx/
  tasks:
  - name: Copy app
    copy:
      src: main
      dest: /root/app
      owner: root
      group: root
      mode: &#39;700&#39;
  - name: Copy service file
    copy:
      src: conf/app/myapp.service
      dest: /lib/systemd/system/myapp.service
      owner: root
      group: root
      mode: &#39;644&#39;
  - name: restart myapp.service
    systemd:
      name: myapp.service
      state: restarted
      daemon_reload: yes
      enabled: yes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Playbookを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ansible-playbook -i ./hosts playbook.yml

$ ansible app -i ./hosts -m shell -a &amp;quot;systemctl status myapp&amp;quot;
ec2-35-175-201-30.compute-1.amazonaws.com | CHANGED | rc=0 &amp;gt;&amp;gt;
● myapp.service - My app service
   Loaded: loaded (/lib/systemd/system/myapp.service; enabled; vendor preset: enabled)
   Active: active (running) since Mon 2019-09-16 14:45:20 UTC; 18min ago
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;動作確認&#34;&gt;動作確認&lt;/h2&gt;

&lt;p&gt;Apache Benchを実行し負荷分散できていることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Single machine
$ ab -n 100 -c 10 http://ec2-3-229-113-100.compute-1.amazonaws.com/
...
Requests per second:    7.67 [#/sec] (mean)
Time per request:       130.409 [ms] (mean, across all concurrent requests)

# Load balanced
$ ab -n 100 -c 10 http://ec2-3-227-2-54.compute-1.amazonaws.com/
...
Requests per second:    11.47 [#/sec] (mean)
Time per request:       87.209 [ms] (mean, across all concurrent requests)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/239-1.png&#34; alt=&#34;2台のCPU使用率&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのnet/http/pprofでCPUやMemoryをprofileする流れと内部実装</title>
          <link>https://www.sambaiz.net/article/238/</link>
          <pubDate>Mon, 16 Sep 2019 13:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/238/</guid>
          <description>

&lt;p&gt;Goの&lt;a href=&#34;https://golang.org/pkg/net/http/pprof/&#34;&gt;net/http/pprof&lt;/a&gt;は
&lt;a href=&#34;https://github.com/google/pprof&#34;&gt;pprof&lt;/a&gt;で可視化できるprofile.protoを返すAPIを提供するpackage。
profileを出力する方法はほかにもあるが、サーバーのような動き続けるアプリケーションのprofileを取るのに使う。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/47/&#34;&gt;go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;profileを取る&#34;&gt;profileを取る&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;import _ &amp;quot;net/http/pprof&amp;quot;&lt;/code&gt;して&lt;code&gt;http.ListenAndServe()&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;net/http&amp;quot;
	_ &amp;quot;net/http/pprof&amp;quot;
	&amp;quot;time&amp;quot;

	&amp;quot;golang.org/x/crypto/bcrypt&amp;quot;
)

func handler(w http.ResponseWriter, r *http.Request) {
	for i := 0; i &amp;lt; 3; i++ {
		bcrypt.GenerateFromPassword([]byte(&amp;quot;PASSWORD&amp;quot;), bcrypt.DefaultCost)
	}
	arr := []int{}
	for i := 0; i &amp;lt;  10000; i++ {
		arr = append(arr, i)
	}
	fmt.Fprintf(w, &amp;quot;OK&amp;quot;)
}

func main() {
	http.HandleFunc(&amp;quot;/foo&amp;quot;, handler)
	fmt.Println(&amp;quot;Listening on :8080&amp;quot;)
	if err := http.ListenAndServe(&amp;quot;:8080&amp;quot;, nil); err != nil {
		panic(err)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CPUは&lt;code&gt;debug/pprof/profile&lt;/code&gt;を叩いた後の一定時間のみprofileするのでその間にリクエストを送る必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.PHONY: build clean run request cpu_profile memory_profile

build: clean
	go build main.go

clean:
	rm main

run: build
	./main

cpu_profile: request
	bash -c &#39;sleep 5s; for var in `seq 100`; do curl -s http://localhost:8080/foo; done&#39; &amp;gt; /dev/null &amp;amp;
	go tool pprof -http=&amp;quot;:8000&amp;quot; ./main localhost:8080/debug/pprof/profile?seconds=10

memory_profile: request
	bash -c &#39;sleep 5s; for var in `seq 100`; do curl -s http://localhost:8080/foo; done&#39; &amp;gt; /dev/null
	go tool pprof -http=&amp;quot;:8000&amp;quot; ./main localhost:8080/debug/pprof/allocs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;profileが終わるとWeb UIが立ち上がる。Flame Graphの縦はスタックを、横の長さは時間や量を表す。これはCPUのもの。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/238-2.png&#34; alt=&#34;CPUのFlame Graph&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ここから&lt;code&gt;blowfish.ExpandKey()&lt;/code&gt;で呼ばれている&lt;code&gt;blowfish.encryptBlock()&lt;/code&gt;が実行時間のほとんど全てを占めていることが分かり、Sourceからコードと合わせて行ごとのかかった時間を見ることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/238-1.png&#34; alt=&#34;行ことのかかった時間&#34; /&gt;&lt;/p&gt;

&lt;p&gt;flatとcumの違いは呼び出した関数の時間も含めるかどうかで、他の関数を呼んでいない&lt;code&gt;encryptBlock()&lt;/code&gt;では同じ値になっているが、呼び出し元をみると微小のflatに対してcumが大きくなっていることが確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;49 10ms 10ms   for i := 0; i &amp;lt; 256; i += 2 { 
50 20ms 2.44s    l, r = encryptBlock(l, r, c) 
51 .    .        c.s0[i], c.s0[i+1] = l, r 
52 .    .      } 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Costを最小にして再度profileを取ってみると、&lt;code&gt;encryptBlock()&lt;/code&gt;の割合が少なくなり他の関数が表に出てくる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/238-3.png&#34; alt=&#34;MinCostでのFlame Graph&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;内部実装&#34;&gt;内部実装&lt;/h2&gt;

&lt;p&gt;importすると&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/net/http/pprof/pprof.go#L72&#34;&gt;init()&lt;/a&gt;でエンドポイントが追加される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func init() {
	http.HandleFunc(&amp;quot;/debug/pprof/&amp;quot;, Index)
	http.HandleFunc(&amp;quot;/debug/pprof/cmdline&amp;quot;, Cmdline)
	http.HandleFunc(&amp;quot;/debug/pprof/profile&amp;quot;, Profile)
	http.HandleFunc(&amp;quot;/debug/pprof/symbol&amp;quot;, Symbol)
	http.HandleFunc(&amp;quot;/debug/pprof/trace&amp;quot;, Trace)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;debug-pprof&#34;&gt;/debug/pprof/*&lt;/h3&gt;

&lt;p&gt;profileの一覧ページおよびCPU以外のprofileを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Index(w http.ResponseWriter, r *http.Request) {
	if strings.HasPrefix(r.URL.Path, &amp;quot;/debug/pprof/&amp;quot;) {
		name := strings.TrimPrefix(r.URL.Path, &amp;quot;/debug/pprof/&amp;quot;)
		if name != &amp;quot;&amp;quot; {
			handler(name).ServeHTTP(w, r)
			return
		}
	}

	var profiles []profile
	for _, p := range pprof.Profiles() {
		profiles = append(profiles, profile{
			Name:  p.Name(),
			Href:  p.Name() + &amp;quot;?debug=1&amp;quot;,
			Desc:  profileDescriptions[p.Name()],
			Count: p.Count(),
		})
	}
	...
	if err := indexTmpl.Execute(w, profiles); err != nil {
		log.Print(err)
	}
}

func (name handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	p := pprof.Lookup(string(name))
	...
	p.WriteTo(w, debug)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/runtime/pprof/pprof.go#L226&#34;&gt;Lookup()&lt;/a&gt;は
名前からprofileを取得する関数。
built-inのprofileに加えて独自のprofileを&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/runtime/pprof/pprof.go#L279&#34;&gt;Add()&lt;/a&gt;することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Lookup(name string) *Profile {
	lockProfiles()
	defer unlockProfiles()
	return profiles.m[name]
}

func lockProfiles() {
	profiles.mu.Lock()
	if profiles.m == nil {
		// Initial built-in profiles.
		profiles.m = map[string]*Profile{
			&amp;quot;goroutine&amp;quot;:    goroutineProfile,
			&amp;quot;threadcreate&amp;quot;: threadcreateProfile,
			&amp;quot;heap&amp;quot;:         heapProfile,
			&amp;quot;allocs&amp;quot;:       allocsProfile,
			&amp;quot;block&amp;quot;:        blockProfile,
			&amp;quot;mutex&amp;quot;:        mutexProfile,
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Profileは&lt;code&gt;count()&lt;/code&gt;や&lt;code&gt;write()&lt;/code&gt;する関数を持つstruct。それぞれ
&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/runtime/pprof/pprof.go#L252&#34;&gt;p.Count()&lt;/a&gt;と
&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/runtime/pprof/pprof.go#L324&#34;&gt;p.WrireTo()&lt;/a&gt;で呼ばれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Profile struct {
	name  string
	mu    sync.Mutex
	m     map[interface{}][]uintptr
	count func() int
	write func(io.Writer, int) error
}

var allocsProfile = &amp;amp;Profile{
	name:  &amp;quot;allocs&amp;quot;,
	count: countHeap,
	write: writeAlloc,
}

func countHeap() int {
	n, _ := runtime.MemProfile(nil, true)
	return n
}

func writeAlloc(w io.Writer, debug int) error {
	return writeHeapInternal(w, debug, &amp;quot;alloc_space&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;debug-pprof-profile&#34;&gt;/debug/pprof/profile&lt;/h3&gt;

&lt;p&gt;CPU profileをStartして一定時間経ったらStopする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if err := pprof.StartCPUProfile(w); err != nil {
	...
}
sleep(w, time.Duration(sec)*time.Second)
pprof.StopCPUProfile()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/runtime/pprof/pprof.go#L226&#34;&gt;StartCPUProfile()&lt;/a&gt;は
&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/runtime/cpuprof.go#L54&#34;&gt;SetCPUProfileRate()&lt;/a&gt;してprofileを書いていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func StartCPUProfile(w io.Writer) error {
	const hz = 100
	...
	cpu.profiling = true
	runtime.SetCPUProfileRate(hz)
	go profileWriter(w)
	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;SetCPUProfileRate()&lt;/code&gt;の内部では、OSに対応する
&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/runtime/signal_unix.go#L236&#34;&gt;setProcessCPUProfiler()&lt;/a&gt;と
&lt;a href=&#34;https://github.com/golang/go/blob/go1.13/src/runtime/signal_unix.go#L256&#34;&gt;setThreadCPUProfiler()&lt;/a&gt;
が呼ばれ、Unixの場合&lt;code&gt;setitimer(ITIMER_PROF)&lt;/code&gt;システムコールでCPU時間10ms経過後SIGPROFが送られるようにして、これをハンドリングしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func setProcessCPUProfiler(hz int32) {
	if hz != 0 {
		// Enable the Go signal handler if not enabled.
		if atomic.Cas(&amp;amp;handlingSig[_SIGPROF], 0, 1) {
			atomic.Storeuintptr(&amp;amp;fwdSig[_SIGPROF], getsig(_SIGPROF))
			setsig(_SIGPROF, funcPC(sighandler))
		}
	}
	...
}

func setThreadCPUProfiler(hz int32) {
	var it itimerval
	if hz == 0 {
		setitimer(_ITIMER_PROF, &amp;amp;it, nil)
	} else {
		it.it_interval.tv_sec = 0
		it.it_interval.set_usec(1000000 / hz)
		it.it_value = it.it_interval
		setitimer(_ITIMER_PROF, &amp;amp;it, nil)
	}
	...
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>User NamespaceでrootになってNetwork Namespaceを作りvethとNATで外と通信する</title>
          <link>https://www.sambaiz.net/article/237/</link>
          <pubDate>Fri, 06 Sep 2019 02:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/237/</guid>
          <description>

&lt;p&gt;LinuxのNamespaceはuidやpid、networkなどを分離できる機能で、Dockerなどのコンテナ技術で使われている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Amazon Linux 2 (ami-0ff21806645c5e492)
$ uname -r
4.14.138-114.102.amzn2.x86_64
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;user-namespaceでrootになる&#34;&gt;User NamespaceでRootになる&lt;/h2&gt;

&lt;p&gt;rootでないと正常終了しないコードを書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /tmp/root_only.sh
#!/bin/sh

if [ &amp;quot;$(id -u)&amp;quot; != &amp;quot;0&amp;quot; ]; then
  echo &amp;quot;you are not root...&amp;quot;
  exit 1
fi
echo &amp;quot;you are root!&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際ec2-userでは&lt;code&gt;exit 1&lt;/code&gt;になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ id -u
1000

$ sh /tmp/root_only.sh; echo $?
you are not root...
1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;User Namespaceを作る。rootでないとそれ以外のNamespaceは作れない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ unshare --net
unshare: unshare failed: Operation not permitted

$ unshare --user
$ id
uid=65534(nfsnobody) gid=65534(nfsnobody) groups=65534(nfsnobody)

$ echo $$
3537
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他のshellを開き、Namespaceの外側からuid_mapを書き込む。
外側の1000から始まるuidを、このNamespaceの0から始まるuidに範囲1でマッピングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Namespace外
$ echo &#39;0 1000 1&#39; &amp;gt; /proc/3537/uid_map
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要するに、uid=1000だったec2-userは、このNamespaceではuid=0(root)になる。上のコードも正常終了した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ id -u
0

$ sh /tmp/root_only.sh 
you are root!
0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;権限昇格してしまったように見えるかもしれないが、もちろんそんなことはなくて元々のユーザーのパーミッションでできなかったことはできない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ touch /root_power
touch: cannot touch &#39;/root_power&#39;: Permission denied
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Namespace内で作ったファイルをNamespace外で見ると、元々のユーザーで作ったことになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ touch /home/ec2-user/fake_root_power
$ ls -l /home/ec2-user/
total 0
-rw-rw-r-- 1 root nfsnobody 0 Sep  5 11:48 fake_root_power

# Namespace外
$ ls -l /home/ec2-user/
total 0
-rw-rw-r-- 1 ec2-user ec2-user 0 Sep  5 11:48 fake_root_power
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;network-namespaceを作りvethでnamespace外と通信できるようにする&#34;&gt;Network Namespaceを作りvethでNamespace外と通信できるようにする&lt;/h2&gt;

&lt;p&gt;ではrootだからといって特に何もできないのかというとそんなことはなく、User以外のNamespaceが作れる。&lt;/p&gt;

&lt;p&gt;Namespace外のネットワークはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ip addr 
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 06:fa:1d:4e:ec:92 brd ff:ff:ff:ff:ff:ff
    inet 172.31.14.149/20 brd 172.31.15.255 scope global dynamic eth0
       valid_lft 3449sec preferred_lft 3449sec
    inet6 fe80::4fa:1dff:fe4e:ec92/64 scope link 
       valid_lft forever preferred_lft forever

$ ip route show table main
default via 172.31.0.1 dev eth0 
169.254.169.254 dev eth0 
172.31.0.0/20 dev eth0 proto kernel scope link src 172.31.14.149
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Namespaceを作るとloopbackしかアドレスが表示されなくなり、ルートテーブルが空になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ unshare --net
$ ip addr
1: lo: &amp;lt;LOOPBACK&amp;gt; mtu 65536 qdisc noop state DOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00

$ ip r
(empty)

$ curl 8.8.8.8
curl: (7) Couldn&#39;t connect to server

$ echo $$
1011
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2つのインタフェース間で通信できるvethのインタフェースを作成し、一つはNamespaceの中に移動する。sudoが必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Namespace外
$ sudo ip link add name veth0-host type veth peer name veth0-ct
$ ip link
...
3: veth0-ct@veth0-host: &amp;lt;BROADCAST,MULTICAST,M-DOWN&amp;gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether b2:09:b8:a4:65:3d brd ff:ff:ff:ff:ff:ff
4: veth0-host@veth0-ct: &amp;lt;BROADCAST,MULTICAST,M-DOWN&amp;gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 4e:89:1e:aa:84:ec brd ff:ff:ff:ff:ff:ff

$ sudo ip addr add 192.168.10.1/24 dev veth0-host
$ sudo ip link set up veth0-host

$ sudo ip link set veth0-ct netns 1011
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インタフェースを立ち上げるとルートテーブルが更新され、Namespace内外が通信できるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ip addr add 192.168.10.2/24 dev veth0-ct
$ ping 192.168.10.1
connect: Network is unreachable

$ ip link set up veth0-ct
$ ip r
192.168.10.0/24 dev veth0-ct proto kernel scope link src 192.168.10.2

$ ip addr
1: lo: &amp;lt;LOOPBACK&amp;gt; mtu 65536 qdisc noop state DOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
3: veth0-ct§if4: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether b2:09:b8:a4:65:3d brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 192.168.10.2/24 scope global veth0-ct
       valid_lft forever preferred_lft forever
    inet6 fe80::b009:b8ff:fea4:653d/64 scope link 
       valid_lft forever preferred_lft forever

$ ping 192.168.10.1
PING 192.168.10.1 (192.168.10.1) 56(84) bytes of data.
64 bytes from 192.168.10.1: icmp_seq=1 ttl=255 time=0.027 ms
64 bytes from 192.168.10.1: icmp_seq=2 ttl=255 time=0.031 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;natしてインターネットと通信できるようにする&#34;&gt;NATしてインターネットと通信できるようにする&lt;/h2&gt;

&lt;p&gt;まだインターネットにはルーティングされていないので通信できない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ping 8.8.8.8
connect: Network is unreachable
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Namespace外でIPマスカレードする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Namespace外
$ sudo bash -c &#39;echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward
$ sudo iptables --table nat --flush
$ sudo iptables --table nat --append POSTROUTING --source 192.168.10.0/24 --jump MASQUERADE
$ sudo iptables --table nat --list
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination         

Chain INPUT (policy ACCEPT)
target     prot opt source               destination         

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         

Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination         
MASQUERADE  all  --  ip-192-168-10-0.ap-northeast-1.compute.internal/24  anywhere
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトゲートウェイをNamespace外のvethにするとインターネットと通信できるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ip route add default via 192.168.10.1
$ ip r
default via 192.168.10.1 dev veth0-ct 
192.168.10.0/24 dev veth0-ct proto kernel scope link src 192.168.10.2

$ ping 8.8.8.8
PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
64 bytes from 8.8.8.8: icmp_seq=1 ttl=41 time=2.70 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=41 time=2.78 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gihyo.jp/admin/serial/01/linux_containers/0006&#34;&gt;第6回　Linuxカーネルのコンテナ機能［5］ ─ネットワーク：LXCで学ぶコンテナ入門 －軽量仮想化環境を実現する技術｜gihyo.jp … 技術評論社&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://gihyo.jp/admin/serial/01/linux_containers/0016&#34;&gt;第16回　Linuxカーネルのコンテナ機能 [6] ─ユーザ名前空間：LXCで学ぶコンテナ入門 －軽量仮想化環境を実現する技術｜gihyo.jp … 技術評論社&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.kamijin-fanta.info/2018/12/netns/&#34;&gt;LinuxのNetns/veth/Bridge/NATで仮想ネットワーク構築 - kamijin-fanta&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SystemdのService</title>
          <link>https://www.sambaiz.net/article/236/</link>
          <pubDate>Fri, 30 Aug 2019 00:16:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/236/</guid>
          <description>

&lt;p&gt;SystemdはLinuxで動くServiceの管理などを行うデーモン。initの後継でchkconfig/servicceの代わりにsystemctlコマンドを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ systemctl start name.service
$ systemctl stop name.service
$ systemctl status name.service
$ systemctl enable name.service
$ systemctl disable name.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serviceの一覧を見る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ systemctl list-units --type service --all
UNIT                               LOAD   ACTIVE SUB     DESCRIPTION
accounts-daemon.service            loaded active running Accounts Service
acpid.service                      loaded active running ACPI event daemon
apparmor.service                   loaded active exited  LSB: AppArmor initialization
apport.service                     loaded active exited  LSB: automatic crash report generation

$ systemctl list-unit-files --type service
UNIT FILE                                  STATE   
accounts-daemon.service                    enabled 
acpid.service                              disabled
apport-forward@.service                    static   # WantedByがない
apt-daily-upgrade.service                  static
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serviceは次のようなファイルで定義される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ systemctl cat ssh
# /lib/systemd/system/ssh.service
[Unit]
Description=OpenBSD Secure Shell server
After=network.target auditd.service # 対象Unitがactiveになった後に開始する
# Wants= # 対象Unitを開始しactiveかどうかにかかわらずその後に開始する
# 対象ファイルが存在している(!がついていたらいない)場合開始する
ConditionPathExists=!/etc/ssh/sshd_not_to_be_run

[Service]
EnvironmentFile=-/etc/default/ssh # 環境変数の設定。ただしファイル内で環境変数は使えない。
ExecStartPre=/usr/sbin/sshd -t # 起動する前に実行するコマンド
ExecStart=/usr/sbin/sshd -D $SSHD_OPTS # 起動するとき
ExecReload=/usr/sbin/sshd -t # リロードするとき
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
Restart=on-failure
RestartPreventExitStatus=255
Type=notify

[Install]
WantedBy=multi-user.target # enableにしたとき対象UnitのWantsにこのUnitが加わって自動起動するようになる
Alias=sshd.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;簡単なServiceを動かしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /lib/systemd/system/my-test.service 
[Unit]
Description=My test service

[Service]
ExecStart=/usr/bin/yes
KillMode=process
Restart=on-failure
Type=simple

[Install]
WantedBy=multi-user.target

$ systemctl start my-test.service
$ systemctl status my-test.service -l
● my-test.service - My test service
   Loaded: loaded (/lib/systemd/system/my-test.service; disabled; vendor preset: enabled)
   Active: active (running) since Wed 2019-08-30 22:20:46 JST; 58s ago
 Main PID: 26063 (yes)
    Tasks: 1
   Memory: 88.0K
      CPU: 13ms
   CGroup: /system.slice/my-test.service
           └─26063 /usr/bin/yes

Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y
Aug 30 22:21:16 150-95-202-235 yes[26063]: y          
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;systemd-journald.serviceがsystemdのログを書いていて、journalctlで見ることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ journalctl -u my-test.service -f
-- Logs begin at Wed 2019-08-30 23:40:16 JST. --
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
Aug 30 23:43:46 150-95-202-235 yes[26063]: y
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/system_administrators_guide/sect-managing_services_with_systemd-targets&#34;&gt;10.3. systemd ターゲットでの作業 Red Hat Enterprise Linux 7 | Red Hat Customer Portal&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PR上でCDKのレビューやデプロイを行うツールcdkbotを作った</title>
          <link>https://www.sambaiz.net/article/235/</link>
          <pubDate>Thu, 29 Aug 2019 22:53:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/235/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/cdkbot&#34;&gt;sambaiz/cdkbot&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PRのコメントで&lt;code&gt;/diff&lt;/code&gt;や&lt;code&gt;/deploy&lt;/code&gt;と打つと&lt;code&gt;cdk diff&lt;/code&gt;や&lt;code&gt;cdk deploy&lt;/code&gt;が走る。
diffを見てレビューし、良ければ&lt;code&gt;/deploy&lt;/code&gt;でデプロイし完了するとmergeされる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/235.png&#34; alt=&#34;diff &amp;amp; deploy&#34; /&gt;&lt;/p&gt;

&lt;p&gt;以前CircleCIでmerge時にdeployされる仕組みを作った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/223/&#34;&gt;CDK/CircleCI/GitHubでAWSリソース管理リポジトリを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ただ、この仕組みだと
CFnの実行時エラーのためにデプロイできない状態のものがmasterブランチにmergeされてしまい、その修正のために何回も試行錯誤のPRを出すことになったり、
Stack間の依存がある場合リソースを削除すると&lt;code&gt;cdk deploy&lt;/code&gt;によって依存解決された順序だと失敗してしまうという問題があった。
cdkbotでは必要ならデプロイするStackを選べて、完了してからmergeすることでこれらの問題を解決した。
また、AWS外のCIにとても強い権限を与えていたがそれも必要なくなった。&lt;/p&gt;

&lt;p&gt;単純にブランチの状態でデプロイしてしまうと古い状態に巻き戻ってしまう可能性があるので、内部でbaseブランチをmergeしていたり、
ラベルによってそのPRがデプロイ可能かどうかを制御していたりする。
最低限デプロイできるようになってから、この辺りの仕組みを整えるまでに存外に時間がかかった。&lt;/p&gt;

&lt;p&gt;Serverless Application Repositoryに公開してあるので簡単にインストールできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/207/&#34;&gt;AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;追記 (2019-10-26): ap-northeast-1に対応していないのと、ECSのリソースを作成できないため、Serverless Application Repositoryに公開するのはやめた。makeでインストールできる。
&lt;a href=&#34;https://www.sambaiz.net/article/245/&#34;&gt;Lambda環境でできない処理をECSで実行する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;外部コマンド&#34;&gt;外部コマンド&lt;/h3&gt;

&lt;p&gt;gitやnpmといった外部コマンドを実行する必要があるが、標準では入っていないのでLambda Layerで入れている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/233&#34;&gt;Lambda上でnpm installできるLayerを作った - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;go-moduleのキャッシュ&#34;&gt;Go moduleのキャッシュ&lt;/h3&gt;

&lt;p&gt;Dockerコンテナ内でテストを実行しているが、毎回go moduleの解決が走ることで時間はかかるし、テザリングの容量に大打撃を受けたので、
ローカルのキャッシュをコピーするようにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test:
	docker build -t cdkbot-npmbin ./npm-lambda-layer
	docker build -t cdkbot-test -f ./test/Dockerfile .
	docker rm -f cdkbot-test || true
	docker run -itd --name cdkbot-test cdkbot-test /bin/sh
	docker cp . cdkbot-test:/root/cdkbot
	go mod download
	docker cp `go env GOPATH`/pkg/mod/cache cdkbot-test:/go/pkg/mod/cache
	docker exec cdkbot-test make _test
	docker rm -f cdkbot-test

_test:
	go test ./...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CircleCIではキャッシュをキャッシュしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- restore_cache:
  keys:
    - gomod-cache-v1-{{ checksum &amp;quot;go.sum&amp;quot; }}
    - gomod-cache-v1-
...
- save_cache:
  key: gomod-cache-v1-{{ checksum &amp;quot;go.sum&amp;quot; }}
  paths:
    - /go/pkg/mod/cache
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CDKでECS&#43;Fargate上にDigdagを立ててCognito認証を挟む</title>
          <link>https://www.sambaiz.net/article/234/</link>
          <pubDate>Wed, 31 Jul 2019 03:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/234/</guid>
          <description>

&lt;p&gt;AWSでワークフローエンジン&lt;a href=&#34;https://www.digdag.io/&#34;&gt;Digdag&lt;/a&gt;を立てるにあたりスケールを見越してECS+Fargateで動かす。
全体のコードは&lt;a href=&#34;https://github.com/sambaiz/digdag-cdk-ecs-fargate&#34;&gt;GitHub&lt;/a&gt;にある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/196/&#34;&gt;FargateでECSを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;リソースはCDKで作る。最近GAになったので高レベルのクラスを積極的に使っている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/222/&#34;&gt;AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm run cdk -- --version
1.2.0 (build 6b763b7)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;vpc&#34;&gt;VPC&lt;/h2&gt;

&lt;p&gt;FargateなのでVPCが必要。
テンプレートを書くとSubnetやRouteTable、NATGatewayなど記述量が多くなるところだが、CDKだとこれだけで済む。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/206/&#34;&gt;CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const vpc = new ec2.Vpc(this, &#39;VPC&#39;, {
  cidr: props.vpcCidr,
  natGateways: 1,
  maxAzs: 2,
  subnetConfiguration: [
    {
      name: &#39;digdag-public&#39;,
      subnetType: ec2.SubnetType.PUBLIC,
    },
    {
      name: &#39;digdag-private&#39;,
      subnetType: ec2.SubnetType.PRIVATE,
    },
    {
      name: &#39;digdag-db&#39;,
      subnetType: ec2.SubnetType.ISOLATED,
    }
  ]
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;db&#34;&gt;DB&lt;/h2&gt;

&lt;p&gt;DigdagはPostgreSQLを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const db = new rds.DatabaseCluster(this, &#39;DBCluster&#39;, {
  engine: rds.DatabaseClusterEngine.AURORA_POSTGRESQL,
  engineVersion: &#39;10.7&#39;,
  instances: 1,
  masterUser: {
    username: &#39;digdag&#39;,
  },
  defaultDatabaseName: databaseName,
  port: dbPort,
  instanceProps: {
    instanceType: ec2.InstanceType.of(ec2.InstanceClass.R5, ec2.InstanceSize.LARGE),
    vpc: vpc,
    vpcSubnets: {
      subnetType: ec2.SubnetType.ISOLATED
    }
  },
  parameterGroup: new rds.ClusterParameterGroup(this, &#39;DBClusterPArameterGroup&#39;, {
    family: &#39;aurora-postgresql10&#39;,
    parameters: {
      application_name: &#39;digdag&#39;,
    }
  }),
  removalPolicy: cdk.RemovalPolicy.DESTROY // for test
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ecs&#34;&gt;ECS&lt;/h2&gt;

&lt;p&gt;ECS Cluster, Service, TaskやRole, Route53のRecordを作り、
デフォルトでDBのIngressが空なのでServiceからアクセスできるようにする。
&lt;code&gt;ecsPatterns.LoadBalancedFargateService&lt;/code&gt; によって少ない記述量で実現できている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ecs.ContainerImage.fromAsset&lt;/code&gt; でStackをデプロイする前にDocker buildが走って &lt;code&gt;cdk bootstrap&lt;/code&gt; で作られたBucketに上がる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const cluster = new ecs.Cluster(this, &#39;ECSCluster&#39;, {
  clusterName: &#39;digdag&#39;,
  vpc: vpc
})
const executionRole = new iam.Role(this, &#39;ExecutionRole&#39;, {
  assumedBy: new iam.ServicePrincipal(&#39;ecs-tasks.amazonaws.com&#39;),
  managedPolicies: [
    iam.ManagedPolicy.fromAwsManagedPolicyName(&#39;service-role/AmazonECSTaskExecutionRolePolicy&#39;)
  ]
})
const taskRole = new iam.Role(this, &#39;TaskRole&#39;, {
  assumedBy: new iam.ServicePrincipal(&#39;ecs-tasks.amazonaws.com&#39;),
  managedPolicies: [
    iam.ManagedPolicy.fromAwsManagedPolicyName(&#39;AdministratorAccess&#39;)
  ]
})
const domainZone = route53.HostedZone.fromHostedZoneAttributes(this, &#39;HostedZone&#39;, {
  hostedZoneId: props.route53ZoneId,
  zoneName: props.route53ZoneName
})
const service = new ecsPatterns.LoadBalancedFargateService(this, &#39;Service&#39;, {
  cluster,
  image: ecs.ContainerImage.fromAsset(&#39;./docker&#39;),
  loadBalancerType: ecsPatterns.LoadBalancerType.APPLICATION,
  certificate: certificatemanager.Certificate.fromCertificateArn(this, &#39;Certificate&#39;, props.acmArn),
  domainName: `${props.route53RecordName}.${props.route53ZoneName}.`,
  domainZone,
  cpu: 256,
  memoryLimitMiB: 512,
  environment: {
    DB_USERNAME: db.secret!.secretValueFromJson(&#39;username&#39;).toString(),
    DB_PASSWORD: db.secret!.secretValueFromJson(&#39;password&#39;).toString(),
    DB_HOST: db.secret!.secretValueFromJson(&#39;host&#39;).toString(),
    DB_PORT: db.secret!.secretValueFromJson(&#39;port&#39;).toString(),
    DB_DATABASE: databaseName,
    S3_LOG_BUCKET: props.logBucket
  },
  executionRole,
  taskRole
})
const dbSG = ec2.SecurityGroup.fromSecurityGroupId(this, &#39;DBSG&#39;, db.securityGroupId)
const serviceSG = ec2.SecurityGroup.fromSecurityGroupId(this, &#39;ServiceSG&#39;, service.service.connections.securityGroups[0].securityGroupId)
dbSG.addIngressRule(serviceSG, ec2.Port.tcp(dbPort))
dbSG.addIngressRule(serviceSG, ec2.Port.tcp(dbPort))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;認証&#34;&gt;認証&lt;/h2&gt;

&lt;p&gt;ECSに飛ばす前にCognito認証を挟む。デフォルトでALBのSGのEgressがServiceへの80番ポートしか開いていないため、HTTPS通信できず認証前に500エラーになってしまう。
そのためSGのIDを取ってルールを追加することになるのだが、
&lt;code&gt;string[]&lt;/code&gt; である &lt;code&gt;service.loadBalancer.loadBalancerSecurityGroups&lt;/code&gt; から &lt;code&gt;loadBalancerSecurityGroups[0]&lt;/code&gt; のように取ろうとすると
Tokenが解決されず &lt;code&gt;#{TOKEN[Foo.1234]}&lt;/code&gt; のような文字列になってしまうため
Fn::Selectを使う&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/cdk/latest/guide/tokens.html#tokens_list&#34;&gt;必要がある。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/227/&#34;&gt;LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const lbSG = ec2.SecurityGroup.fromSecurityGroupId(this, &#39;LBSG&#39;,
  cdk.Fn.select(0, service.loadBalancer.loadBalancerSecurityGroups))
lbSG.addEgressRule(ec2.Peer.anyIpv4(), ec2.Port.tcp(443))
lbSG.addEgressRule(ec2.Peer.anyIpv6(), ec2.Port.tcp(443))
new loadbalancer.CfnListenerRule(this, &#39;AuthListenerRule&#39;, {
  conditions: [{
    field: &#39;path-pattern&#39;,
    values: [&#39;/*&#39;]
  }],
  listenerArn: service.listener.listenerArn,
  priority: 10,
  actions: [{
    type: &#39;authenticate-cognito&#39;,
    order: 1,
    authenticateCognitoConfig: {
      onUnauthenticatedRequest: &#39;authenticate&#39;,
      userPoolArn: props.userPoolArn,
      userPoolClientId: props.userPoolClientId,
      userPoolDomain: props.userPoolDomain
    }
  }, {
    type: &#39;forward&#39;,
    order: 2,
    targetGroupArn: service.targetGroup.targetGroupArn
  }]
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;digdag-properties-https-docs-digdag-io-command-reference-html&#34;&gt;&lt;a href=&#34;https://docs.digdag.io/command_reference.html&#34;&gt;digdag.properties&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ログはS3に送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server.bind = 0.0.0.0
server.port = 80
database.type = postgresql
database.user = &amp;lt;DB_USERNAME&amp;gt;
database.password = &amp;lt;DB_PASSWORD&amp;gt;
database.host = &amp;lt;DB_HOST&amp;gt;
database.port = &amp;lt;DB_PORT&amp;gt;
database.database = &amp;lt;DB_DATABASE&amp;gt;
log-server.type=s3
log-server.s3.bucket=&amp;lt;S3_LOG_BUCKET&amp;gt;
log-server.s3.path=logs/
log-server.s3.direct_download=false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行時に環境変数の値に書き換えている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh 
sed -i -e &amp;quot;s/&amp;lt;DB_USERNAME&amp;gt;/${DB_USERNAME}/&amp;quot; \
    -e &amp;quot;s/&amp;lt;DB_PASSWORD&amp;gt;/${DB_PASSWORD}/&amp;quot; \
    -e &amp;quot;s/&amp;lt;DB_HOST&amp;gt;/${DB_HOST}/&amp;quot; \
    -e &amp;quot;s/&amp;lt;DB_PORT&amp;gt;/${DB_PORT}/&amp;quot; \
    -e &amp;quot;s/&amp;lt;DB_DATABASE&amp;gt;/${DB_DATABASE}/&amp;quot; \
    -e &amp;quot;s/&amp;lt;S3_LOG_BUCKET&amp;gt;/${S3_LOG_BUCKET}/&amp;quot; digdag.properties

/usr/local/bin/digdag server --config digdag.properties
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ワークフローの実行&#34;&gt;ワークフローの実行&lt;/h2&gt;

&lt;p&gt;認証後WebUIに飛び、適当なdigファイルを作りRunボタンを押してログが出たら成功。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+hello:
    echo&amp;gt;: &amp;quot;Hello Digdag&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/234.png&#34; alt=&#34;実行結果&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://techblog.zozo.com/entry/digdag_ha&#34;&gt;DigdagをHA構成にしてみた - ZOZO Technologies TECH BLOG&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Lambda上でnpm installできるLayerを作った</title>
          <link>https://www.sambaiz.net/article/233/</link>
          <pubDate>Tue, 23 Jul 2019 23:44:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/233/</guid>
          <description>&lt;p&gt;Lambda上でnpm installするためにnpmとnode, npmrc入りのLambda Layerを作った。
&lt;a href=&#34;https://github.com/sambaiz/npm-lambda-layer&#34;&gt;GitHub&lt;/a&gt;にある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/232/&#34;&gt;Lambda Layerでバイナリやライブラリを切り出す - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;まずは&lt;code&gt;/usr/bin/npm&lt;/code&gt;をそのまま入れて実行してみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM lambci/lambda-base:build

WORKDIR /opt

RUN curl -sL https://rpm.nodesource.com/setup_12.x | bash - &amp;amp;&amp;amp; \
    yum install -y nodejs &amp;amp;&amp;amp; \
    mkdir bin &amp;amp;&amp;amp; \
    cp /usr/bin/node bin/node &amp;amp;&amp;amp; \
    cp /usr/bin/npm bin/ &amp;amp;&amp;amp; \
    zip -yr /tmp/npm-layer.zip ./*
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t npmbin .
$ docker run npmbin cat /tmp/npm-layer.zip &amp;gt; npm-layer.zip &amp;amp;&amp;amp; unzip npm-layer.zip -d layer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相対パスでの参照に失敗したようだが対象のパスが見当たらない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;internal/modules/cjs/loader.js:628
    throw err;
    ^

Error: Cannot find module &#39;../lib/utils/unsupported.js&#39;
Require stack:
- /opt/bin/npm
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:625:15)
    at Function.Module._load (internal/modules/cjs/loader.js:527:27)
    at Module.require (internal/modules/cjs/loader.js:683:19)
    at require (internal/modules/cjs/helpers.js:16:16)
    at /opt/bin/npm:19:21
    at Object.&amp;lt;anonymous&amp;gt; (/opt/bin/npm:152:3)
    at Module._compile (internal/modules/cjs/loader.js:776:30)
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)
    at Module.load (internal/modules/cjs/loader.js:643:32)
    at Function.Module._load (internal/modules/cjs/loader.js:556:12) {
  code: &#39;MODULE_NOT_FOUND&#39;,
  requireStack: [ &#39;/opt/bin/npm&#39; ]
}
 exit status 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;というのもnpmはシンボリックリンクで、その参照先に対象のパスがあった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls -l /usr/bin/npm 
lrwxrwxrwx 1 root root 38 Jul 23 09:34 /usr/bin/npm -&amp;gt; ../lib/node_modules/npm/bin/npm-cli.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これごとLayerに含めることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM lambci/lambda-base:build

WORKDIR /opt

RUN curl -sL https://rpm.nodesource.com/setup_12.x | bash - &amp;amp;&amp;amp; \
    yum install -y nodejs &amp;amp;&amp;amp; \
    mkdir bin nodejs &amp;amp;&amp;amp; \
    cp /usr/bin/node bin/node &amp;amp;&amp;amp; \
    cp -r /usr/lib/node_modules ./nodejs/node_modules &amp;amp;&amp;amp; \
    ln -s ../nodejs/node_modules/npm/bin/npm-cli.js ./bin/npm &amp;amp;&amp;amp; \
    zip -yr /tmp/npm-layer.zip ./*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;すると次のエラーに変わった。Lambdaは&lt;code&gt;/tmp&lt;/code&gt;にしかwriteできないのに$HOMEに書こうとしているようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Unhandled rejection Error: EACCES: permission denied, mkdir &#39;/home/sbx_user1051&#39;
npm ERR! cb() never called!

npm ERR! This is an error with npm itself. Please report this error at:
npm ERR!     &amp;lt;https://npm.community&amp;gt;
exit status 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;npm configのデフォルト値をみてみたところ、いくつか$HOMEを参照している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm config ls -l | grep $HOME
cache = &amp;quot;/root/.npm&amp;quot;
init-module = &amp;quot;/root/.npm-init.js&amp;quot;
userconfig = &amp;quot;/root/.npmrc&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこでこれらの値を書き換えたnpmrcを含めた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ENV NPM_CONFIG_USERCONFIG /opt/nodejs/.npmrc

RUN ...
    npm config set cache /tmp/.npm &amp;amp;&amp;amp; \
    npm config set init-module /tmp/.npm-init.js &amp;amp;&amp;amp; \ 
    npm config set update-notifier false &amp;amp;&amp;amp; \
    chmod a+r $NPM_CONFIG_USERCONFIG &amp;amp;&amp;amp; \
    ln -s ../nodejs/node_modules/npm/bin/npm-cli.js ./bin/npm &amp;amp;&amp;amp; \
    zip -yr /tmp/npm-layer.zip ./*
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {
	if err := os.Setenv(&amp;quot;NPM_CONFIG_USERCONFIG&amp;quot;, &amp;quot;/opt/nodejs/.npmrc&amp;quot;); err != nil {
		return events.APIGatewayProxyResponse{
			Body:       err.Error(),
			StatusCode: 500,
		}, nil
	}
	...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでlocalでうまくいくことが確認できたのでデプロイしてみたところ、
&lt;code&gt;Error: Cannot find module &#39;../lib/utils/unsupported.js&#39;&lt;/code&gt; が再発してしまった。
原因はシンボリックリンクがコピーになっているためで、&lt;a href=&#34;https://github.com/awslabs/aws-sam-cli/pull/1140&#34;&gt;PR&lt;/a&gt;が上がっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;out, err = exec.Command(&amp;quot;ls&amp;quot;, &amp;quot;-l&amp;quot;, &amp;quot;/opt/bin/npm&amp;quot;).CombinedOutput()
// =&amp;gt; ls: -rwxr-xr-x 1 root root 4566 Jul 24 2019 /opt/bin/npm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;代わりにshell scriptを置くことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM lambci/lambda-base:build

WORKDIR /opt

ENV NPM_CONFIG_USERCONFIG /opt/nodejs/.npmrc

RUN curl -sL https://rpm.nodesource.com/setup_12.x | bash - &amp;amp;&amp;amp; \
    yum install -y nodejs &amp;amp;&amp;amp; \
    mkdir bin nodejs &amp;amp;&amp;amp; \
    cp /usr/bin/node bin/node &amp;amp;&amp;amp; \
    cp -r /usr/lib/node_modules ./nodejs/node_modules &amp;amp;&amp;amp; \
    npm config set cache /tmp/.npm &amp;amp;&amp;amp; \
    npm config set init-module /tmp/.npm-init.js &amp;amp;&amp;amp; \ 
    npm config set update-notifier false &amp;amp;&amp;amp; \
    chmod a+r $NPM_CONFIG_USERCONFIG &amp;amp;&amp;amp; \
    echo -e &amp;quot;#!/bin/sh\n/opt/nodejs/node_modules/npm/bin/npm-cli.js \$@&amp;quot; &amp;gt; ./bin/npm &amp;amp;&amp;amp; \
    chmod a+x ./bin/npm &amp;amp;&amp;amp; \
    zip -yr /tmp/npm-layer.zip ./*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとはタイムアウト対策のためMemorySizeを1024に増やしてようやく返ってくるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm notice created a lockfile as package-lock.json. You should commit this file.
npm WARN tmp@1.0.0 No description
npm WARN tmp@1.0.0 No repository field.

+ express@4.17.1
added 50 packages from 37 contributors and audited 126 packages in 3.455s
found 0 vulnerabilities
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Lambda Layerでバイナリやライブラリを切り出す</title>
          <link>https://www.sambaiz.net/article/232/</link>
          <pubDate>Mon, 22 Jul 2019 21:09:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/232/</guid>
          <description>&lt;p&gt;Lambdaで実行したい外部コマンドがある場合、通常バイナリをパッケージに含めることになりデプロイに時間がかかってしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;os/exec&amp;quot;

	&amp;quot;github.com/aws/aws-lambda-go/events&amp;quot;
	&amp;quot;github.com/aws/aws-lambda-go/lambda&amp;quot;
)

func handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {
	cmd := exec.Command(&amp;quot;git&amp;quot;, &amp;quot;clone&amp;quot;, &amp;quot;https://github.com/sambaiz/foobar.git&amp;quot;, &amp;quot;/tmp/repo&amp;quot;)
	output, err := cmd.CombinedOutput()
	if err != nil {
		return events.APIGatewayProxyResponse{
			Body:       fmt.Sprintf(&amp;quot;%s %s&amp;quot;, string(output), err.Error()),
			StatusCode: 500,
		}, nil
	}
	return events.APIGatewayProxyResponse{
		Body:       string(output),
		StatusCode: 200,
	}, nil
}

func main() {
	lambda.Start(handler)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;exec: &amp;quot;git&amp;quot;: executable file not found in $PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/configuration-layers.html&#34;&gt;Lambda Layer&lt;/a&gt;を使うと
ライブラリやバイナリを切り出すことができ、複数Functionで共有することもできる。
ディレクトリをzipにしてLayerに指定すると中身が&lt;code&gt;/opt&lt;/code&gt;に展開され、&lt;code&gt;/opt/bin&lt;/code&gt;にはPATHが、&lt;code&gt;/opt/lib&lt;/code&gt;にはLD_LIBRARY_PATHが通るほか、
言語ごとのパッケージ置き場がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tree layer/
layer/
└── bin
    └── some-command
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;zipはS3に上げておくこともできるが、
SAMでは&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/serverless-application-model/latest/developerguide/serverless-sam-template.html#serverless-sam-template-layerversion&#34;&gt;AWS::Lambda::LayerVersion&lt;/a&gt;のContentUriでローカルのパスを指定することもでき、
&lt;code&gt;sam local&lt;/code&gt; でも適用される。
そうする場合packageするのにAWS CLIのバージョンが1.16.67以降である
&lt;a href=&#34;https://github.com/awslabs/aws-sam-cli/issues/831#issuecomment-444513671&#34;&gt;必要がある&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/207/&#34;&gt;AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat template.yaml 
...
Resources:
  HelloWorldFunction:
    Type: AWS::Serverless::Function 
    Properties:
      CodeUri: hello-world/
      Handler: hello-world
      Runtime: go1.x
      Layers:
        - !Ref ExampleLayer
      Events:
        CatchAll:
          Type: Api
          Properties:
            Path: /hello
            Method: GET
  ExampleLayer:
    Type: AWS::Serverless::LayerVersion
    Properties:
      LayerName: SomeCommandLayer
      Description: some-command binary is included
      ContentUri: &#39;./layer&#39;
      CompatibleRuntimes:
        - go1.x
      RetentionPolicy: Delete
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;というこどで&lt;a href=&#34;https://github.com/lambci/git-lambda-layer&#34;&gt;lambci/git-lambda-layer&lt;/a&gt;を入れてgitを使えるようにしようと思ったが、
調べているうちに&lt;a href=&#34;https://github.com/src-d/go-git&#34;&gt;src-d/go-git&lt;/a&gt;を見つけたのでこちらを使うことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_, err := git.PlainClone(&amp;quot;/tmp/repo&amp;quot;, false, &amp;amp;git.CloneOptions{
	URL:      &amp;quot;https://github.com/sambaiz/foobar.git&amp;quot;,
	Progress: os.Stdout,
})
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AWS SAMとGoでPRのコメントに対して返事を返すGitHub Appを作る</title>
          <link>https://www.sambaiz.net/article/231/</link>
          <pubDate>Fri, 19 Jul 2019 21:21:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/231/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://developer.github.com/apps/&#34;&gt;GitHub App&lt;/a&gt;はリポジトリにインストールできるアプリケーションで、
Access TokenやOAuth Appと&lt;a href=&#34;https://developer.github.com/apps/differences-between-apps/&#34;&gt;異なり&lt;/a&gt;
ユーザーとは独立した権限を与えて実行することができる。&lt;/p&gt;

&lt;p&gt;今回はPRの特定のコメントに反応して返事を返すAppを作る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/231.png&#34; alt=&#34;Botによるコメント投稿&#34; /&gt;&lt;/p&gt;

&lt;p&gt;AWS SAMでデプロイする。全体のコードは&lt;a href=&#34;https://github.com/sambaiz/sam-github-app-hooks-example&#34;&gt;GitHub&lt;/a&gt;にある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/207/&#34;&gt;AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;github-appの作成&#34;&gt;GitHub Appの作成&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Settings &amp;gt; Developer settings&lt;/code&gt; から作成できる。いろいろ項目はあるが、NameとHomepage URL、Webhook URLを入れればひとまず作成はできる。
Webhook URLはあとで決まるので適当な値を入れておく。必須にはなっていないがリクエストを検証するため適当なWebhook secretも入れる。
PermissionsはPull requestsではなくIssueのRead &amp;amp; Writeが必要で、
さらにそうすると表示されるようになるSubscribe to eventsのIssue commentにチェックを入れる。&lt;/p&gt;

&lt;p&gt;作成すると秘密鍵がダウンロードできるのでSecretsmanagerに上げておき、LambdaのRoleにもこれを取得できるRoleを付ける。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/204/&#34;&gt;AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws secretsmanager create-secret --name GitHubCdkAppSecretKey --secret-string $(cat private-key.pem)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Policies:
  - PolicyName: read-cdk-github-app-secret-key
    PolicyDocument:
    Version: &amp;quot;2012-10-17&amp;quot;
    Statement:
      - Effect: Allow
        Action: secretsmanager:GetSecretValue
        Resource: &amp;lt;secret-key arn&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;webhooksのリクエスト内容-https-developer-github-com-webhooks-example-delivery&#34;&gt;&lt;a href=&#34;https://developer.github.com/webhooks/#example-delivery&#34;&gt;Webhooksのリクエスト内容&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;設定でチェックを入れたeventが起きると次のようなリクエストが送られてくる。
Headerの &lt;code&gt;X-GitHub-Event&lt;/code&gt; によってbodyの中身が決まり、
&lt;code&gt;X-Hub-Signature&lt;/code&gt; と、bodyと設定したWebhook secretから生成したHMACのMAC値を比較することで
リクエストを&lt;a href=&#34;https://developer.github.com/webhooks/securing/#validating-payloads-from-github&#34;&gt;検証する&lt;/a&gt;ことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;POST /payload HTTP/1.1
Host: localhost:4567
X-GitHub-Delivery: 72d3162e-cc78-11e3-81ab-4c9367dc0958
X-Hub-Signature: sha1=7d38cdd689735b008b3c702edd92eea23791c5f6
User-Agent: GitHub-Hookshot/044aadd
Content-Type: application/json
Content-Length: 6615
X-GitHub-Event: issues
{
  &amp;quot;action&amp;quot;: &amp;quot;opened&amp;quot;,
  &amp;quot;issue&amp;quot;: {
    &amp;quot;url&amp;quot;: &amp;quot;https://api.github.com/repos/octocat/Hello-World/issues/1347&amp;quot;,
    &amp;quot;number&amp;quot;: 1347,
    ...
  },
  &amp;quot;repository&amp;quot; : {
    &amp;quot;id&amp;quot;: 1296269,
    &amp;quot;full_name&amp;quot;: &amp;quot;octocat/Hello-World&amp;quot;,
    &amp;quot;owner&amp;quot;: {
      &amp;quot;login&amp;quot;: &amp;quot;octocat&amp;quot;,
      &amp;quot;id&amp;quot;: 1,
      ...
    },
    ...
  },
  &amp;quot;sender&amp;quot;: {
    &amp;quot;login&amp;quot;: &amp;quot;octocat&amp;quot;,
    &amp;quot;id&amp;quot;: 1,
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;p&gt;Signatureを検証し、対応するEventのstructにパースして処理を行う流れ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
	&amp;quot;context&amp;quot;
	&amp;quot;errors&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;time&amp;quot;

	&amp;quot;github.com/aws/aws-lambda-go/events&amp;quot;
	&amp;quot;github.com/aws/aws-lambda-go/lambda&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws/awserr&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws/session&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/service/secretsmanager&amp;quot;
	jwt &amp;quot;github.com/dgrijalva/jwt-go&amp;quot;
	&amp;quot;github.com/google/go-github/v26/github&amp;quot;
	&amp;quot;go.uber.org/zap&amp;quot;
	&amp;quot;golang.org/x/oauth2&amp;quot;
)

func handler(event events.APIGatewayProxyRequest) (Response, error) {
	ctx := context.Background()
	if err := github.ValidateSignature(event.Headers[&amp;quot;X-Hub-Signature&amp;quot;], []byte(event.Body), []byte(webhookSecret)); err != nil {
		logger.Info(&amp;quot;Signature is invalid&amp;quot;, zap.Error(err))
		return Response{
			StatusCode: http.StatusBadRequest,
		}, nil
	}
	hook, err := github.ParseWebHook(event.Headers[&amp;quot;X-GitHub-Event&amp;quot;], []byte(event.Body))
	if err != nil {
		logger.Error(&amp;quot;Failed to parse hook&amp;quot;, zap.Error(err))
		return Response{
			StatusCode: http.StatusBadRequest,
		}, nil
	}
	switch hook := hook.(type) {
	case *github.IssueCommentEvent:
		err = processIssueCommentEvent(ctx, hook)
	}
	if err != nil {
		logger.Error(&amp;quot;Failed to process an event&amp;quot;, zap.Error(err))
		return Response{
			StatusCode: http.StatusInternalServerError,
		}, err
	}
	return Response{
		StatusCode: http.StatusOK,
	}, nil
}

func processIssueCommentEvent(
	ctx context.Context,
	hook *github.IssueCommentEvent) error {
	if hook.GetComment().GetBody() != &amp;quot;ping&amp;quot; {
		return nil
	}
	client, err := newGitHubClient(ctx, hook.GetInstallation().GetID())
	if err != nil {
		return err
	}
	_, _, err = client.Issues.CreateComment(
		ctx,
		hook.GetRepo().GetOwner().GetLogin(),
		hook.GetRepo().GetName(),
		hook.GetIssue().GetNumber(),
		&amp;amp;github.IssueComment{
			Body: &amp;amp;[]string{&amp;quot;pong&amp;quot;}[0],
		},
	)
	return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なお無条件に返すようにするとbotの投稿でさらにeventが発火して無限ループしてしまう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/231-2.png&#34; alt=&#34;無限ループ&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;クライアントの生成-https-developer-github-com-apps-building-github-apps-authenticating-with-github-apps&#34;&gt;&lt;a href=&#34;https://developer.github.com/apps/building-github-apps/authenticating-with-github-apps/&#34;&gt;クライアントの生成&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;リポジトリに対してAPIを呼ぶには、まずダウンロードした秘密鍵でJWTを作り、これでInstallationTokenを取得してHeaderに乗せる必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newGitHubClient(ctx context.Context, installationID int64) (*github.Client, error) {
	now := time.Now()
	payload := jwt.NewWithClaims(jwt.SigningMethodRS256, jwt.MapClaims{
		&amp;quot;iat&amp;quot;: now.Unix(),
		&amp;quot;exp&amp;quot;: now.Add(10 * time.Minute).Unix(),
		&amp;quot;iss&amp;quot;: appID,
	})
	pem, err := getSecret(privateKeyArn)
	if err != nil {
		return nil, err
	}
	privateKey, err := jwt.ParseRSAPrivateKeyFromPEM([]byte(pem))
	if err != nil {
		return nil, err
	}
	token, err := payload.SignedString(privateKey)
	if err != nil {
		return nil, err
	}
	ts := oauth2.StaticTokenSource(
		&amp;amp;oauth2.Token{AccessToken: token},
	)
	tc := oauth2.NewClient(ctx, ts)
	client := github.NewClient(tc)

	installationToken, _, err := client.Apps.CreateInstallationToken(ctx, installationID)
	if _, _, err := client.Apps.Get(ctx, &amp;quot;&amp;quot;); err != nil {
		return nil, fmt.Errorf(&amp;quot;Failed to create installation token: %s&amp;quot;, err.Error())
	}
	ts = oauth2.StaticTokenSource(
		&amp;amp;oauth2.Token{AccessToken: installationToken.GetToken()},
	)
	tc = oauth2.NewClient(ctx, ts)
	client = github.NewClient(tc)
	return client, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;動作確認&#34;&gt;動作確認&lt;/h2&gt;

&lt;p&gt;実際動かしてみるとなかなかうまくいかない。
&lt;code&gt;GitHub Apps &amp;gt; Advanced&lt;/code&gt; から送られたイベントとそれに対するレスポンスが確認でき、再送することもできて便利。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/231-3.png&#34; alt=&#34;送られたイベント&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KaggleのHouse Prices CompetitionをXGBoostで解く</title>
          <link>https://www.sambaiz.net/article/230/</link>
          <pubDate>Tue, 09 Jul 2019 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/230/</guid>
          <description>

&lt;p&gt;以前TitanicをやったXGBoostでHome Prices Competitionに挑戦する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/168/&#34;&gt;KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
df_train = pd.read_csv(&#39;house-prices/train.csv&#39;)
df_test= pd.read_csv(&#39;house-prices/test.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;欠損値の処理&#34;&gt;欠損値の処理&lt;/h2&gt;

&lt;p&gt;以前確認したように欠損値が含まれるので一つずつ見ていって埋めていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/216/&#34;&gt;KaggleのHome Prices CompetitionのKernelからデータの探り方を学ぶ - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np

def fillna(df):
  # PoolQC: Pool quality
  print(np.unique(df[&#39;PoolQC&#39;].values.tolist())) # [&#39;Ex&#39; &#39;Fa&#39; &#39;Gd&#39; &#39;nan&#39;]
  df[&amp;quot;PoolQC&amp;quot;] = df[&amp;quot;PoolQC&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # MiscFeature: Miscellaneous feature not covered in other categories
  print(np.unique(df[&#39;MiscFeature&#39;].values.tolist())) # [&#39;Gar2&#39; &#39;Othr&#39; &#39;Shed&#39; &#39;TenC&#39; &#39;nan&#39;]
  df[&amp;quot;MiscFeature&amp;quot;] = df[&amp;quot;MiscFeature&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # Alley: Type of alley access
  print(np.unique(df[&#39;Alley&#39;].values.tolist())) # [&#39;Grvl&#39; &#39;Pave&#39; &#39;nan&#39;]
  df[&amp;quot;Alley&amp;quot;] = df[&amp;quot;Alley&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # Fence: Fence quality
  print(np.unique(df[&#39;Fence&#39;].values.tolist())) # [&#39;GdPrv&#39; &#39;GdWo&#39; &#39;MnPrv&#39; &#39;MnWw&#39; &#39;nan&#39;]
  df[&amp;quot;Fence&amp;quot;] = df[&amp;quot;Fence&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # FireplaceQu: Fireplace quality
  print(np.unique(df[&#39;FireplaceQu&#39;].values.tolist())) # [&#39;Ex&#39; &#39;Fa&#39; &#39;Gd&#39; &#39;Po&#39; &#39;TA&#39; &#39;nan&#39;]
  df[&amp;quot;FireplaceQu&amp;quot;] = df[&amp;quot;FireplaceQu&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # LotFrontage: Linear feet of street connected to property
  print(df[&amp;quot;LotFrontage&amp;quot;].describe())
  &#39;&#39;&#39;
  mean       70.049958
  std        24.284752
  min        21.000000
  25%        59.000000
  50%        69.000000
  75%        80.000000
  max       313.000000
  &#39;&#39;&#39;
  df[&amp;quot;LotFrontage&amp;quot;] = df[&amp;quot;LotFrontage&amp;quot;].median()

  # GarageCond: Garage condition
  print(np.unique(df[&amp;quot;GarageCond&amp;quot;].values.tolist())) # [&#39;Ex&#39; &#39;Fa&#39; &#39;Gd&#39; &#39;Po&#39; &#39;TA&#39; &#39;nan&#39;]
  df[&amp;quot;GarageCond&amp;quot;] = df[&amp;quot;GarageCond&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # GarageType: Garage location
  print(np.unique(df[&amp;quot;GarageType&amp;quot;].values.tolist())) # [&#39;2Types&#39; &#39;Attchd&#39; &#39;Basment&#39; &#39;BuiltIn&#39; &#39;CarPort&#39; &#39;Detchd&#39; &#39;nan&#39;]
  df[&amp;quot;GarageType&amp;quot;] = df[&amp;quot;GarageType&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # GarageYrBlt: Year garage was built
  print(np.unique(df[&amp;quot;GarageYrBlt&amp;quot;].values.tolist())) # [1900. 1906. ... 2008. 2009.  2010.  nan]
  df[&amp;quot;GarageYrBlt&amp;quot;] = df[&amp;quot;GarageYrBlt&amp;quot;].fillna(0)

  # GarageFinish: Interior finish of the garage
  print(np.unique(df[&amp;quot;GarageFinish&amp;quot;].values.tolist())) # [&#39;Fin&#39; &#39;RFn&#39; &#39;Unf&#39; &#39;nan&#39;]
  df[&amp;quot;GarageFinish&amp;quot;] = df[&amp;quot;GarageFinish&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # GarageQual: Garage quality
  print(np.unique(df[&amp;quot;GarageQual&amp;quot;].values.tolist())) # [&#39;Ex&#39; &#39;Fa&#39; &#39;Gd&#39; &#39;Po&#39; &#39;TA&#39; &#39;nan&#39;]
  df[&amp;quot;GarageQual&amp;quot;] = df[&amp;quot;GarageQual&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # BsmtExposure: Walkout or garden level basement walls
  print(np.unique(df[&amp;quot;BsmtExposure&amp;quot;].values.tolist())) # [&#39;Av&#39; &#39;Gd&#39; &#39;Mn&#39; &#39;No&#39; &#39;nan&#39;]
  df[&amp;quot;BsmtExposure&amp;quot;] = df[&amp;quot;BsmtExposure&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # BsmtFinType2: Quality of second finished area (if present)
  print(np.unique(df[&amp;quot;BsmtFinType2&amp;quot;].values.tolist())) # [&#39;ALQ&#39; &#39;BLQ&#39; &#39;GLQ&#39; &#39;LwQ&#39; &#39;Rec&#39; &#39;Unf&#39; &#39;nan&#39;]
  df[&amp;quot;BsmtFinType2&amp;quot;] = df[&amp;quot;BsmtFinType2&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # BsmtFinType1: Quality of basement finished area
  print(np.unique(df[&amp;quot;BsmtFinType1&amp;quot;].values.tolist())) # [&#39;ALQ&#39; &#39;BLQ&#39; &#39;GLQ&#39; &#39;LwQ&#39; &#39;Rec&#39; &#39;Unf&#39; &#39;nan&#39;]
  df[&amp;quot;BsmtFinType1&amp;quot;] = df[&amp;quot;BsmtFinType1&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # BsmtCond: General condition of the basement
  print(np.unique(df[&amp;quot;BsmtCond&amp;quot;].values.tolist())) # [&#39;Fa&#39; &#39;Gd&#39; &#39;Po&#39; &#39;TA&#39; &#39;nan&#39;]
  df[&amp;quot;BsmtCond&amp;quot;] = df[&amp;quot;BsmtCond&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # BsmtQual: Height of the basement
  print(np.unique(df[&amp;quot;BsmtQual&amp;quot;].values.tolist())) # [&#39;Ex&#39; &#39;Fa&#39; &#39;Gd&#39; &#39;TA&#39; &#39;nan&#39;]
  df[&amp;quot;BsmtQual&amp;quot;] = df[&amp;quot;BsmtQual&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # MasVnrArea: Masonry veneer area in square feet
  print(df[&amp;quot;MasVnrArea&amp;quot;].describe())
  &#39;&#39;&#39;
  count     1460.0
  unique     328.0
  top          0.0
  freq       861.0
  &#39;&#39;&#39;
  df[&amp;quot;MasVnrArea&amp;quot;] = df[&amp;quot;MasVnrArea&amp;quot;].fillna(0)

  # MasVnrType: Masonry veneer type
  print(np.unique(df[&amp;quot;MasVnrType&amp;quot;].values.tolist())) # [&#39;BrkCmn&#39; &#39;BrkFace&#39; &#39;None&#39; &#39;Stone&#39; &#39;nan&#39;]
  print(df[&amp;quot;MasVnrType&amp;quot;].describe())
  &#39;&#39;&#39;
  count     1452
  unique       4
  top       None
  freq       864
  &#39;&#39;&#39;
  df[&amp;quot;MasVnrType&amp;quot;] = df[&amp;quot;MasVnrType&amp;quot;].fillna(&amp;quot;None&amp;quot;)

  # Electrical: Electrical system
  print(np.unique(df[&amp;quot;Electrical&amp;quot;].values.tolist())) # [&#39;FuseA&#39; &#39;FuseF&#39; &#39;FuseP&#39; &#39;Mix&#39; &#39;SBrkr&#39; &#39;nan&#39;]
  df[&amp;quot;Electrical&amp;quot;] = df[&amp;quot;Electrical&amp;quot;].fillna(&amp;quot;None&amp;quot;)
  return df
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ハイパーパラメータの最適化&#34;&gt;ハイパーパラメータの最適化&lt;/h2&gt;

&lt;p&gt;ベイズ最適化でハイパーパラメータを決める。
他にもいろいろなパラメータがあるが、やみくもに増やしても提出した後のスコアが良くならなかった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/169/&#34;&gt;ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;! pip install bayesian-optimization

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from bayes_opt import BayesianOptimization

num_boost_round=500

def optimize_params(df):
  def train(
      learning_rate, 
      colsample_bytree,
      sub_sample):
    train_x = df.drop(&#39;SalePrice&#39;, axis=1)
    train_y = df.SalePrice
    (train_x, test_x ,train_y, test_y) = train_test_split(train_x, train_y, test_size = 0.3)
    dtrain = xgb.DMatrix(train_x, label=train_y)
    param = {
        &#39;learning_rate&#39;: learning_rate, 
        &#39;colsample_bytree&#39;: colsample_bytree,
        &#39;sub_sample&#39;: sub_sample}
    bst = xgb.train(param, dtrain, num_boost_round)
    preds = bst.predict(xgb.DMatrix(test_x))
    # Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price
    return -np.sqrt(mean_squared_error(
        np.log(np.clip(np.nan_to_num(test_y), 1e-6, None)),
        np.log(np.clip(np.nan_to_num(preds), 1e-6, None))
    ))
  bo = BayesianOptimization(
    train,
    {&#39;learning_rate&#39;: (0.01, 0.5), # default=0.3
     &#39;colsample_bytree&#39;: (0.1, 1.0),  # default=1
     &#39;sub_sample&#39;: (0.1, 1.0), # default=1
    })
  bo.maximize(n_iter=50, alpha=1e-5)
  return bo.max[&#39;params&#39;]

params = optimize_params(df_train_filled)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果こんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(params)
# =&amp;gt; {&#39;colsample_bytree&#39;: 0.485528388652188, &#39;learning_rate&#39;: 0.010027583064377935, &#39;sub_sample&#39;: 0.10000002653848854}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行&#34;&gt;実行&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;pd.get_dummies()&lt;/code&gt;でカテゴリカル変数をone hot vectorに変換し、学習して予測結果を出力する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/220/&#34;&gt;カテゴリカル変数をLabel/OneHotEncoderやget_dummiesで変換する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df_train_filled = fillna(df_train)
df_train_filled = pd.get_dummies(df_train_filled)
params = optimize_params(df_train_filled)
bst = xgb.train(
    params, 
    xgb.DMatrix(df_train_filled.drop(&#39;SalePrice&#39;, axis=1).as_matrix(), label=df_train_filled.SalePrice),
    num_boost_round)

df_test_filled = fillna(df_test)
df_test_filled = pd.get_dummies(df_test_filled)
for miss_key in [key for key in df_train_filled.drop(&#39;SalePrice&#39;, axis=1).keys() if key not in df_test]:
  df_test_filled[miss_key] = 0 
preds = bst.predict(xgb.DMatrix(df_test_filled.as_matrix()))
submit_data =  pd.Series(preds, name=&#39;SalePrice&#39;, index=df_test[&#39;Id&#39;])
submit_data.to_csv(&#39;submit.csv&#39;, header=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;スコアは &lt;code&gt;0.16164&lt;/code&gt; だった。学習時のスコアは &lt;code&gt;0.11&lt;/code&gt; ほどだったのにかなり下がってしまった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ColabでKaggleのAPIを呼んで学習データのダウンロードと提出を行う</title>
          <link>https://www.sambaiz.net/article/229/</link>
          <pubDate>Tue, 09 Jul 2019 01:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/229/</guid>
          <description>&lt;p&gt;Colabではランタイムがリセットされるたびにファイルが消えてしまうのでその度に学習データをアップロードするのが面倒。
そこで&lt;a href=&#34;https://github.com/Kaggle/kaggle-api&#34;&gt;Kaggle API&lt;/a&gt;でファイルを持ってきてついでに提出まで行う。&lt;/p&gt;

&lt;p&gt;Notebookを公開することも考えてなるべく認証情報を直書きしたくないのでGoogle DriveをマウントしてそこからTokenを持ってくることにする。
KaggleのMy AccountからAPI Tokenを発行しGoogle Driveに上げておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from google.colab import drive
drive.mount(&#39;/content/gdrive&#39;)
! mkdir -p ~/.kaggle
! cp &amp;quot;gdrive/My Drive/kaggle/kaggle.json&amp;quot; ~/.kaggle/
! pip install kaggle --upgrade
! kaggle config view
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Kaggle/kaggle-api#download-competition-files&#34;&gt;competitions download&lt;/a&gt;でファイルをダウンロードしてくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;! kaggle competitions download house-prices-advanced-regression-techniques -p house-prices

import pandas as pd
df_train = pd.read_csv(&#39;house-prices/train.csv&#39;)
df_test= pd.read_csv(&#39;house-prices/test.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Kaggle/kaggle-api#submit-to-a-competition&#34;&gt;competitions submit&lt;/a&gt;で提出し、
&lt;a href=&#34;https://github.com/Kaggle/kaggle-api#list-competition-submissions&#34;&gt;competitions submissions&lt;/a&gt;で提出履歴とスコアが見える。
リーダーボードは&lt;a href=&#34;https://github.com/Kaggle/kaggle-api#get-competition-leaderboard&#34;&gt;competitions leaderboard&lt;/a&gt;で取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;! kaggle competitions submit house-prices-advanced-regression-techniques -f submit.csv -m &amp;quot;test submission&amp;quot;
! kaggle competitions submissions house-prices-advanced-regression-techniques
! kaggle competitions leaderboard --show house-prices-advanced-regression-techniques
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;fileName         date                 description                             status    publicScore  privateScore  
---------------  -------------------  --------------------------------------  --------  -----------  ------------  
submit.csv       2019-07-08 13:19:19  test submission                         complete  0.17933      None          
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;submitし過ぎると上限にひっかかる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;403 - Your team has used its submission allowance (10 of 10). This resets at midnight UTC (10 hours from now).&lt;/code&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Cognito UserPoolのPreSignUp時に呼ばれるLambdaで登録ユーザーを制限する</title>
          <link>https://www.sambaiz.net/article/228/</link>
          <pubDate>Sun, 07 Jul 2019 17:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/228/</guid>
          <description>

&lt;p&gt;サードパーティのIdPからCognitoにSignUpできるようにする場合、特定のドメインのメールアドレスといったような制限をかけたいことがある。
PreSignUp時のLambdaでこれを弾いてやることでUserPoolに入らないようにすることができる。&lt;/p&gt;

&lt;h2 id=&#34;lambda&#34;&gt;Lambda&lt;/h2&gt;

&lt;p&gt;CognitoEventUserPoolsPreSignupを&lt;a href=&#34;https://github.com/aws/aws-lambda-go/blob/master/events/README_Cognito_UserPools_PreSignup.md&#34;&gt;受け取って返す&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;errors&amp;quot;
	&amp;quot;fmt&amp;quot;

	&amp;quot;github.com/aws/aws-lambda-go/events&amp;quot;
	&amp;quot;github.com/aws/aws-lambda-go/lambda&amp;quot;
)

func handler(event events.CognitoEventUserPoolsPreSignup) (events.CognitoEventUserPoolsPreSignup, error) {
	fmt.Printf(&amp;quot;PreSignup of user: %s\n&amp;quot;, event.UserName)
	if event.Request.UserAttributes[&amp;quot;email&amp;quot;] != &amp;quot;godgourd@gmail.com&amp;quot; {
		return event, errors.New(&amp;quot;Forbidden&amp;quot;)
	}
	return event, nil
}

func main() {
	lambda.Start(handler)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;リソース&#34;&gt;リソース&lt;/h2&gt;

&lt;p&gt;UserPoolの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-properties-cognito-userpool-lambdaconfig.html&#34;&gt;LambdaConfig&lt;/a&gt;でトリガーを設定できる。
CognitoからLambdaを呼べるPermissionが必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;UserPool:
  Type: AWS::Cognito::UserPool
  Properties:
    ...
    LambdaConfig:
      PreSignUp: !GetAtt PresignupLambdaFunction.Arn
UserPoolLambdaInvokePermission:
  Type: AWS::Lambda::Permission
  Properties:
    Action: lambda:invokeFunction
    Principal: cognito-idp.amazonaws.com
    FunctionName: !GetAtt PresignupLambdaFunction.Arn
    SourceArn: arn:aws:cognito-idp:&amp;lt;region&amp;gt;:&amp;lt;account_id&amp;gt;:userpool/*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なおALBのActionでCognito認証を入れると登録失敗時に500エラーになってしまう。これを回避するには自前でやるしかないのかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/227/&#34;&gt;LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/226/&#34;&gt;API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす</title>
          <link>https://www.sambaiz.net/article/227/</link>
          <pubDate>Wed, 03 Jul 2019 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/227/</guid>
          <description>

&lt;p&gt;ALBのTargetとしてLambdaが&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/lambda-functions-as-targets-for-application-load-balancers/&#34;&gt;選択できるようになり&lt;/a&gt;、
若干の時間課金が発生する代わりに柔軟にルーティングできるAPI Gatewayのように使えるようになった。
ActionとしてCognito認証を入れて認証に失敗したらログイン画面を表示させる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/226/&#34;&gt;API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;acmで証明書を発行する&#34;&gt;ACMで証明書を発行する&lt;/h2&gt;

&lt;p&gt;HTTPSでListenするため証明書が必要。
&lt;a href=&#34;https://aws.amazon.com/jp/certificate-manager/&#34;&gt;AWS Certificate Manager (ACM)&lt;/a&gt;でAWSで使える証明書を無料で発行でき参照できる。
外部で取ったドメインでもよい。
検証方法はDNSとメールとで選ぶことができて、DNSで行う場合Route53ならワンクリックで検証用のCNAMEレコードを作成できる。
検証までやや時間がかかるのでちゃんと通ってるかnslookupで確認しといた方がよい。&lt;/p&gt;

&lt;h2 id=&#34;application-load-balancer-alb-https-docs-aws-amazon-com-ja-jp-elasticloadbalancing-latest-application-introduction-html&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/introduction.html&#34;&gt;Application Load Balancer (ALB)&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;次の要素から構成されるL7のロードバランサー。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/load-balancer-listeners.html&#34;&gt;Listener&lt;/a&gt;: 指定したプロトコルとポートでリクエストを受ける。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/listener-update-rules.html&#34;&gt;ListenerRule&lt;/a&gt;: パスやHeaderなどの値を条件にどのTargetGroupにルーティングするかのルール。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/load-balancer-target-groups.html&#34;&gt;TargetGroup&lt;/a&gt;: ルーティングする1つ以上のTarget。Instance, IP, Lambdaが選べる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ruleの作成&#34;&gt;Ruleの作成&lt;/h2&gt;

&lt;p&gt;Serverless FrameworkではALBの&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/events/alb/&#34;&gt;enent&lt;/a&gt;を付けるだけでLambdaに向くRuleが作成されるが、そこにはCognitoを追加できなさそうなので使っていない。OnUnauthenticatedRequestで認証失敗時の挙動を選択できる。UserPoolとSecretありのClientはあらかじめ作っておく。コールバックURLには&lt;code&gt;https://&amp;lt;domain&amp;gt;/oauth2/idpresponse&lt;/code&gt;を追加する。&lt;/p&gt;

&lt;p&gt;API Gatewayだとタイムアウトの上限が&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/limits.html&#34;&gt;30秒&lt;/a&gt;なのに対してALBはLambdaの上限まで待てる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat serverless.yml
service: alb-cognito-auth-example
frameworkVersion: &amp;quot;&amp;gt;=1.28.0 &amp;lt;2.0.0&amp;quot;

provider:
  name: aws
  runtime: go1.x
  region: ap-northeast-1

package:
 exclude:
   - ./**
 include:
   - ./bin/**

functions:
  privateapi:
    handler: bin/privateapi
    timeout: 30

resources:
  Resources:
    ALBTargetGroup:
      DependsOn: InvokeLambdaPermissionForALB
      Type: AWS::ElasticLoadBalancingV2::TargetGroup
      Properties:
        Name: &amp;quot;private-lambda-target-group&amp;quot;
        TargetType: &amp;quot;lambda&amp;quot;
        Targets:
          - Id: !GetAtt PrivateapiLambdaFunction.Arn # Reference functions.privateapi
    InvokeLambdaPermissionForALB:
      Type: AWS::Lambda::Permission
      Properties: 
        Action: &amp;quot;lambda:InvokeFunction&amp;quot;
        FunctionName: !Ref PrivateapiLambdaFunction
        Principal: &amp;quot;elasticloadbalancing.amazonaws.com&amp;quot;
    ALB: 
      Type: &amp;quot;AWS::ElasticLoadBalancingV2::LoadBalancer&amp;quot;
      Properties: 
        Name: &amp;quot;serverless-auth-example-alb&amp;quot;
        Scheme: &amp;quot;internet-facing&amp;quot;
        LoadBalancerAttributes: 
          - Key: &amp;quot;idle_timeout.timeout_seconds&amp;quot;
            Value: 30
        SecurityGroups:
          - &amp;quot;sg-*****&amp;quot;
        Subnets:
          - &amp;quot;subnet-*****&amp;quot;
          - &amp;quot;subnet-*****&amp;quot;
    ALBListener: 
      Type: &amp;quot;AWS::ElasticLoadBalancingV2::Listener&amp;quot;
      Properties: 
        DefaultActions: 
          - Type: authenticate-cognito
            Order: 1
            AuthenticateCognitoConfig: 
              OnUnauthenticatedRequest: authenticate
              UserPoolArn: &amp;quot;arn:aws:cognito-idp:ap-northeast-1:*****&amp;quot;
              UserPoolClientId: &amp;quot;*****&amp;quot;
              UserPoolDomain: &amp;quot;*****.auth.ap-northeast-1.amazoncognito.com&amp;quot;
          - Type: forward
            Order: 2
            TargetGroupArn: !Ref ALBTargetGroup
        LoadBalancerArn: !Ref ALB
        Port: 443
        Protocol: HTTPS
        Certificates: 
          - CertificateArn: &amp;quot;arn:aws:acm:ap-northeast-1:*****:certificate/*****&amp;quot;
    RecordSet:
      Type: AWS::Route53::RecordSet
      Properties: 
        Type: &amp;quot;A&amp;quot; # or AAAA (IPv6)
        HostedZoneName: &amp;quot;foo.example.com.&amp;quot;
        Name: &amp;quot;auth-example.foo.example.com.&amp;quot;
        AliasTarget: 
          HostedZoneId: !GetAtt ALB.CanonicalHostedZoneID
          DNSName: !GetAtt ALB.DNSName
        Comment: &amp;quot;Added by servereless-alb-cognito-auth-example&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/listener-authenticate-users.html#user-claims-encoding&#34;&gt;x-amzn-oidc-data&lt;/a&gt; HeaderにALBが署名したJWTトークンが入っているので、
それがALBから来ているものかを検証しclaimを参照できる。リクエストはAPI Gatewayと同じような形式。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ParseToken(tokenString string) (jwt.MapClaims, error) {
	token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
		// ES256
		if _, ok := token.Method.(*jwt.SigningMethodECDSA); !ok {
			return nil, fmt.Errorf(&amp;quot;unexpected signing method: %v&amp;quot;, token.Header[&amp;quot;alg&amp;quot;])
		}
		url := fmt.Sprintf(&amp;quot;https://public-keys.auth.elb.ap-northeast-1.amazonaws.com/%s&amp;quot;, token.Header[&amp;quot;kid&amp;quot;])
		resp, err := http.Get(url)
		if err != nil {
			return nil, err
		}
		body, err := ioutil.ReadAll(resp.Body)
		return jwt.ParseECPublicKeyFromPEM(body)
	})
	if err != nil {
		return nil, err
	}
	if claims, ok := token.Claims.(jwt.MapClaims); ok &amp;amp;&amp;amp; token.Valid {
		return claims, nil
	} else {
		return nil, errors.New(&amp;quot;token is invalid&amp;quot;)
	}
}

type Response events.APIGatewayProxyResponse

func Handler(request events.APIGatewayProxyRequest) (Response, error) {
	var buf bytes.Buffer

	_, err := ParseToken(request.Headers[&amp;quot;x-amzn-oidc-data&amp;quot;])
	if err != nil {
		return Response{StatusCode: http.StatusUnauthorizeds}, err
	}

	resp := Response{
		StatusCode:      http.StatusOK,
		Body:            &amp;quot;ok&amp;quot;,
	}

	return resp, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://tech.gunosy.io/entry/alb-login&#34;&gt;まだログイン認証で消耗してるの？ ~ALBで簡単認証機構~ - Gunosy Tech Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く</title>
          <link>https://www.sambaiz.net/article/226/</link>
          <pubDate>Wed, 03 Jul 2019 20:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/226/</guid>
          <description>

&lt;p&gt;ブラウザから直接API GatewayのエンドポイントにアクセスしたときにCognitoのTokenで認証し、失敗したらログイン画面を表示させる。
API GatewayでCognitoの認証をかける場合、AuthorizerでUserPoolを指定するのが最も簡単なパターンだが、
これだとHeaderにTokenを付けてアクセスする必要があり認証に失敗するとUnauthorizedが返る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/157/&#34;&gt;Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;なおAPI GatewayではなくALBをLambdaの前段に挟めば今回やることが簡単に実現できる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/227/&#34;&gt;LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;UserPoolとClientを作成する。
CloudFormationで作成する場合SchemaのMutableのデフォルトがfalseなのに注意。変えると作り直される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Resources:
  Userpool:
    Type: AWS::Cognito::UserPool
    Properties:
      AdminCreateUserConfig:
        AllowAdminCreateUserOnly: false
      Schema:
        - Mutable: true
          Name: email
          Required: true
        - Mutable: true
          Name: name
          Required: true
      UsernameAttributes:
        - email
      UserPoolName: testpool
  UserpoolClient:
    Type: AWS::Cognito::UserPoolClient
    Properties:
      UserPoolId:
        Ref: Userpool
      ClientName: testclient
      GenerateSecret: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回はフェデレーションでGoogleアカウントでログインできるようにする。
ややこしい用語であるがID Poolの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/cognito-identity.html&#34;&gt;フェデレーティッドアイデンティティ&lt;/a&gt;とは異なる。&lt;/p&gt;

&lt;p&gt;UserPoolのドメインや、&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/cognito-user-pools-social-idp.html&#34;&gt;GoogleのOAuth Client ID&lt;/a&gt;の発行とAttributes Mapping、Clientの設定はCloudFormationでできないので手でやる。
Attributes Mappingで変えられるがusernameは&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/user-pool-settings-attributes.html#user-pool-settings-usernames&#34;&gt;変更不可な値&lt;/a&gt;なのでsubのままにしておく。&lt;/p&gt;

&lt;p&gt;設定が終わったら &lt;code&gt;https://&amp;lt;user-pool-domain&amp;gt;/login?client_id=&amp;lt;client-id&amp;gt;&amp;amp;redirect_uri=&amp;lt;redirect-uri&amp;gt;&amp;amp;response_type=code&lt;/code&gt;
にアクセスし、&lt;code&gt;&amp;lt;redirect-uri&amp;gt;?code=&amp;lt;code&amp;gt;&lt;/code&gt; までリダイレクトされることを確認する。
invalid_requestとだけ出てしまった場合はClientのAuthorization code grantにチェックが入っているか確認する。&lt;/p&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;p&gt;Authorization Flowを行う。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/48/&#34;&gt;OAuth2.0のメモ - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cookieで渡ってきたTokenを検証し、失敗した場合はログイン画面にリダイレクトさせる。
identity_providerを指定するかClientに一つしか紐づいていなければそのプロバイダのログイン画面に飛び、そうでなければ選択する画面が表示される。
ログインしてクエリパラメータとして渡ってきたcodeとstateもこの関数で受け取り、検証してTokenを発行し一旦返してCookieに焼く。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/136/&#34;&gt;OpenID ConnectのIDトークンの内容と検証 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;通常stateはサーバーに保持されるがDBを持たなくていいようにCookieに焼いている。
CSRF対策のためのものなのでCookieが攻撃者に読み書きされなければ意味を為すと思っているが、このフローで問題がある場合は教えてほしい。
State、Token共にCookieに焼いているためCORSのAccess-Control-Allow-Originを*などにしてしまうと穴が開く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package auth

import (
	&amp;quot;encoding/base64&amp;quot;
	&amp;quot;encoding/json&amp;quot;
	&amp;quot;errors&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;net/url&amp;quot;
	&amp;quot;strings&amp;quot;
	&amp;quot;time&amp;quot;

	&amp;quot;github.com/gofrs/uuid&amp;quot;

	&amp;quot;github.com/aws/aws-lambda-go/events&amp;quot;
	jwt &amp;quot;github.com/dgrijalva/jwt-go&amp;quot;
	&amp;quot;github.com/lestrrat/go-jwx/jwk&amp;quot;
)

const (
	stateCookieName = &amp;quot;st&amp;quot;
	tokenCookieName = &amp;quot;ck&amp;quot;
)

type TokenResponse struct {
	AccessToken  string  `json:&amp;quot;access_token&amp;quot;`
	RefreshToken string  `json:&amp;quot;refresh_token&amp;quot;`
	IdToken      string  `json:&amp;quot;id_token&amp;quot;`
	TokenType    string  `json:&amp;quot;token_type&amp;quot;`
	ExpiresIn    int     `json:&amp;quot;expires_in&amp;quot;`
	Error        *string `json:&amp;quot;error&amp;quot;`
}

func AuthOrLogin(
	request events.APIGatewayProxyRequest,
	userPoolClientID string,
	userPoolClientSecret string,
	userPoolURL string,
	userPoolID string,
	region string) *events.APIGatewayProxyResponse {
	myselfURL := fmt.Sprintf(&amp;quot;https://%s/%s%s&amp;quot;, request.Headers[&amp;quot;Host&amp;quot;], request.RequestContext.Stage, request.Path)

	if code := getCodeFromParams(request.QueryStringParameters); code != nil {
		if err := checkState(request); err != nil {
			fmt.Printf(err.Error())
			return newErrorResponse()
		}
		tokenResp, err := requestTokenByCode(*code, userPoolClientID, userPoolClientSecret, myselfURL, userPoolURL)
		if err != nil {
			fmt.Println(err.Error())
			return newErrorResponse()
		}
		resp := newRedirectResponse(myselfURL)
		resp.MultiValueHeaders = map[string][]string{
			&amp;quot;Set-Cookie&amp;quot;: []string{
				fmt.Sprintf(&amp;quot;%s=%s; Secure; HttpOnly&amp;quot;, tokenCookieName, tokenResp.AccessToken),
				// delete state
				fmt.Sprintf(&amp;quot;%s=; Expires=Thu, 1-Jan-1990 00:00:00 GMT; Secure; HttpOnly&amp;quot;, stateCookieName),
			},
		}
		return resp
	}

	if token := getTokenFromCookie(request.Headers); token != nil {
		claims, err := parseToken(*token, userPoolClientID, userPoolID, region)
		if err == nil {
			fmt.Println(claims)
			return nil // ok
		} else {
			fmt.Println(err.Error()) // re-login
		}
	}

	loginURL, state, err := makeLoginURL(userPoolURL, userPoolClientID, myselfURL)
	if err != nil {
		fmt.Println(err.Error())
		return newErrorResponse()

	}
	resp := newRedirectResponse(loginURL)
	resp.MultiValueHeaders = map[string][]string{
		&amp;quot;Set-Cookie&amp;quot;: []string{
			// delete old token
			fmt.Sprintf(&amp;quot;%s=; Expires=Thu, 1-Jan-1990 00:00:00 GMT; Secure; HttpOnly&amp;quot;, tokenCookieName),
			fmt.Sprintf(&amp;quot;%s=%s; Secure; HttpOnly&amp;quot;, stateCookieName, state),
		},
	}
	return resp
}

func getCodeFromParams(params map[string]string) *string {
	if code, ok := params[&amp;quot;code&amp;quot;]; ok {
		return &amp;amp;code
	}
	return nil
}

func getStateFromCookie(headers map[string]string) *string {
	if cookie, ok := headers[&amp;quot;Cookie&amp;quot;]; ok {
		header := http.Header{}
		header.Add(&amp;quot;Cookie&amp;quot;, cookie)
		request := http.Request{Header: header}
		c, err := request.Cookie(stateCookieName)
		if err != nil {
			return nil
		}
		return &amp;amp;c.Value
	}
	return nil
}

func getTokenFromCookie(headers map[string]string) *string {
	if cookie, ok := headers[&amp;quot;Cookie&amp;quot;]; ok {
		header := http.Header{}
		header.Add(&amp;quot;Cookie&amp;quot;, cookie)
		request := http.Request{Header: header}
		c, err := request.Cookie(tokenCookieName)
		if err != nil {
			return nil
		}
		return &amp;amp;c.Value
	}
	return nil
}

func newRedirectResponse(location string) *events.APIGatewayProxyResponse {
	return &amp;amp;events.APIGatewayProxyResponse{
		StatusCode: http.StatusFound,
		Headers: map[string]string{
			&amp;quot;Location&amp;quot;: location,
		},
	}
}

func newErrorResponse() *events.APIGatewayProxyResponse {
	return &amp;amp;events.APIGatewayProxyResponse{
		StatusCode: http.StatusInternalServerError,
	}
}

func makeState() (string, error) {
	uuid, err := uuid.NewV4()
	if err != nil {
		return &amp;quot;&amp;quot;, err
	}
	return uuid.String(), nil
}

func checkState(request events.APIGatewayProxyRequest) error {
	if state, ok := request.QueryStringParameters[&amp;quot;state&amp;quot;]; ok {
		if hasState := getStateFromCookie(request.Headers); hasState != nil {
			if state == *hasState {
				return nil
			}
		}
	}
	return errors.New(&amp;quot;state is invalid&amp;quot;)
}

func requestTokenByCode(code string, userPoolClientID string, userPoolClientSecret string, myselfURL string, userPoolURL string) (*TokenResponse, error) {
	// https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/token-endpoint.html
	form := url.Values{}
	form.Add(&amp;quot;grant_type&amp;quot;, &amp;quot;authorization_code&amp;quot;)
	form.Add(&amp;quot;code&amp;quot;, code)
	form.Add(&amp;quot;redirect_uri&amp;quot;, myselfURL)
	body := strings.NewReader(form.Encode())
	req, err := http.NewRequest(&amp;quot;POST&amp;quot;, fmt.Sprintf(&amp;quot;%s/oauth2/token&amp;quot;, userPoolURL), body)
	if err != nil {
		return nil, err
	}
	req.Header.Add(&amp;quot;Authorization&amp;quot;,
		fmt.Sprintf(&amp;quot;Basic %s&amp;quot;,
			base64.StdEncoding.EncodeToString(
				[]byte(fmt.Sprintf(&amp;quot;%s:%s&amp;quot;, userPoolClientID, userPoolClientSecret)))))
	req.Header.Add(&amp;quot;Content-Type&amp;quot;, &amp;quot;application/x-www-form-urlencoded&amp;quot;)
	res, err := http.DefaultClient.Do(req)
	if err != nil {
		return nil, err
	}
	defer res.Body.Close()
	var tokenResp TokenResponse
	bytes, err := ioutil.ReadAll(res.Body)
	if err := json.Unmarshal(bytes, &amp;amp;tokenResp); err != nil {
		return nil, err
	}
	if tokenResp.Error != nil {
		return nil, errors.New(*tokenResp.Error)
	}
	return &amp;amp;tokenResp, nil
}

func makeLoginURL(userPoolURL string, userPoolClientID string, myselfURL string) (string, string, error) {
	// https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/authorization-endpoint.html
	u, err := url.Parse(fmt.Sprintf(&amp;quot;%s/oauth2/authorize&amp;quot;, userPoolURL))
	if err != nil {
		return &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, errors.New(&amp;quot;failed to parse&amp;quot;)
	}
	q := u.Query()
	q.Set(&amp;quot;response_type&amp;quot;, &amp;quot;code&amp;quot;)
	q.Set(&amp;quot;client_id&amp;quot;, userPoolClientID)
	q.Set(&amp;quot;redirect_uri&amp;quot;, myselfURL)
	q.Set(&amp;quot;identity_provider&amp;quot;, &amp;quot;Google&amp;quot;)
	state, err := makeState()
	if err != nil {
		return &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, errors.New(&amp;quot;failed to make state&amp;quot;)
	}
	q.Set(&amp;quot;state&amp;quot;, state)
	u.RawQuery = q.Encode()
	return u.String(), state, nil
}

func parseToken(tokenString string, userPoolClientID string, userPoolID string, region string) (jwt.MapClaims, error) {
	token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
		// RS256
		if _, ok := token.Method.(*jwt.SigningMethodRSA); !ok {
			return nil, fmt.Errorf(&amp;quot;unexpected signing method: %v&amp;quot;, token.Header[&amp;quot;alg&amp;quot;])
		}
		return getKey(token, userPoolID, region)
	})
	if err != nil {
		return nil, err
	}
	if claims, ok := token.Claims.(jwt.MapClaims); ok &amp;amp;&amp;amp; token.Valid {
		// https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-verifying-a-jwt.html
		if v, ok := claims[&amp;quot;exp&amp;quot;].(float64); ok {
			if int64(v) &amp;lt; time.Now().Unix() {
				return nil, errors.New(&amp;quot;token is expired&amp;quot;)
			}
		} else {
			return nil, errors.New(&amp;quot;failed to get claims[exp]&amp;quot;)
		}
		// instead of aud
		if v, ok := claims[&amp;quot;client_id&amp;quot;].(string); ok {
			if v != userPoolClientID {
				return nil, errors.New(&amp;quot;token has invalid audience&amp;quot;)
			}
		} else {
			return nil, errors.New(&amp;quot;failed to get claims[client_id]&amp;quot;)
		}
		if v, ok := claims[&amp;quot;iss&amp;quot;].(string); ok {
			if v != fmt.Sprintf(&amp;quot;https://cognito-idp.%s.amazonaws.com/%s&amp;quot;, region, userPoolID) {
				return nil, errors.New(&amp;quot;token has invalid issuer&amp;quot;)
			}
		} else {
			return nil, errors.New(&amp;quot;failed to get claims[iss]&amp;quot;)
		}

		return claims, nil
	}
	return nil, errors.New(&amp;quot;token is invalid&amp;quot;)
}

func getKey(token *jwt.Token, userPoolID string, region string) (interface{}, error) {
	set, err := jwk.FetchHTTP(
		fmt.Sprintf(&amp;quot;https://cognito-idp.%s.amazonaws.com/%s/.well-known/jwks.json&amp;quot;, region, userPoolID),
	)
	if err != nil {
		return nil, err
	}

	keyID, ok := token.Header[&amp;quot;kid&amp;quot;].(string)
	if !ok {
		return nil, errors.New(&amp;quot;expecting JWT header to have string kid&amp;quot;)
	}

	if key := set.LookupKeyID(keyID); len(key) == 1 {
		return key[0].Materialize()
	}

	return nil, errors.New(&amp;quot;unable to find key&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ReactのFunction ComponentとHooks</title>
          <link>https://www.sambaiz.net/article/225/</link>
          <pubDate>Thu, 20 Jun 2019 19:23:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/225/</guid>
          <description>

&lt;p&gt;久々に&lt;a href=&#34;https://github.com/facebook/create-react-app&#34;&gt;create-react-app&lt;/a&gt;を実行したら
コンポーネントがReact.ComponentのクラスではなくFunction Componentになっていた。&lt;/p&gt;

&lt;h2 id=&#34;function-component&#34;&gt;Function Component&lt;/h2&gt;

&lt;p&gt;Function Componentは関数で書かれるStateを持たないコンポーネントで、
簡潔に書けるだけではなく&lt;code&gt;React.createElement()&lt;/code&gt;と比べて45%くらい速いらしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/missive-app/45-faster-react-functional-components-now-3509a668e69f&#34;&gt;45% Faster React Functional Components, Now – Missive App – Medium&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const App: React.FC = () =&amp;gt; {
  return (
    &amp;lt;div className=&amp;quot;App&amp;quot;&amp;gt;
      {FunctionalComponent({title: &amp;quot;HELLO FC&amp;quot;})}
    &amp;lt;/div&amp;gt;
  );
}

interface Props {
  title: string
}

const FunctionalComponent: React.FC&amp;lt;Props&amp;gt; = (props) =&amp;gt; {
  return (
    &amp;lt;div&amp;gt;
      {props.title}
    &amp;lt;/div&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/blog/2018/10/23/react-v-16-6.html&#34;&gt;v16.6&lt;/a&gt;でリリースされた
&lt;a href=&#34;https://reactjs.org/docs/react-api.html#reactmemo&#34;&gt;React.memo()&lt;/a&gt;を使うと
&lt;a href=&#34;https://reactjs.org/docs/react-api.html#reactpurecomponent&#34;&gt;PureComponent&lt;/a&gt;
のようにpropsが変わらない場合は再レンダリングさせなくすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const App: React.FC = () =&amp;gt; {
  return (
    &amp;lt;div className=&amp;quot;App&amp;quot;&amp;gt;
      &amp;lt;FunctionalComponent title=&amp;quot;HELLO FC&amp;quot; /&amp;gt;
    &amp;lt;/div&amp;gt;
  );
}

interface Props {
  title: string
}

const FunctionalComponent = React.memo((props) =&amp;gt; {
  return (
    &amp;lt;div&amp;gt;
      {props.title}
    &amp;lt;/div&amp;gt;
  );
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;react-hooks-https-ja-reactjs-org-docs-hooks-intro-html&#34;&gt;&lt;a href=&#34;https://ja.reactjs.org/docs/hooks-intro.html&#34;&gt;React Hooks&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Function ComponentはClass Componentのようにstateを持ったり、&lt;code&gt;componentDidMount()&lt;/code&gt;といった
ライフサイクルメソッドを生やすことができなかったが、
&lt;a href=&#34;https://reactjs.org/blog/2019/02/06/react-v16.8.0.html&#34;&gt;v16.8&lt;/a&gt;でリリースされた
React Hooksによってこれらを
&lt;a href=&#34;https://ja.reactjs.org/docs/hooks-faq.html#how-do-lifecycle-methods-correspond-to-hooks&#34;&gt;実現できる&lt;/a&gt;ようになった。&lt;/p&gt;

&lt;p&gt;React HooksというのはReactの機能と接続する関数で、
次のような&lt;a href=&#34;https://ja.reactjs.org/docs/hooks-reference.html&#34;&gt;組み込みのHooks&lt;/a&gt;に加えて
&lt;a href=&#34;https://ja.reactjs.org/docs/hooks-custom.html&#34;&gt;独自のHooks&lt;/a&gt;を作ることもでき、
例えばreact-reduxにも&lt;a href=&#34;https://react-redux.js.org/next/api/hooks&#34;&gt;Hooks API&lt;/a&gt;がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.reactjs.org/docs/hooks-state.html&#34;&gt;useState()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reactが管理するstateの値と、変更する関数を返す。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.reactjs.org/docs/hooks-effect.html&#34;&gt;useEffect()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;副作用を起こす関数をrender後に非同期で実行させる。
クリーンアップ処理の関数を返すことができ、Unmount時や次回の副作用の前に実行される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import React, { useState, useEffect } from &#39;react&#39;;

const FunctionalComponent: React.FC&amp;lt;Props&amp;gt; = (props) =&amp;gt; {
  const [count, setCount] = useState(0);

  // Similar to componentDidMount and componentDidUpdate:
  useEffect(() =&amp;gt; {
    // Update the document title using the browser API
    document.title = `You clicked ${count} times`;
    // Specify how to clean up after this effect
    return () =&amp;gt; {
      console.log(&amp;quot;Clean up&amp;quot;)
    }
  });

  return (
    &amp;lt;div&amp;gt;
      &amp;lt;p&amp;gt;You clicked {count} times&amp;lt;/p&amp;gt;
      &amp;lt;button onClick={() =&amp;gt; setCount(count + 1)}&amp;gt;
        Click me
      &amp;lt;/button&amp;gt;
    &amp;lt;/div&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;useEffect()の第二引数に配列を渡すと、そこに含まれる値が変わらない場合は
実行を&lt;a href=&#34;https://ja.reactjs.org/docs/hooks-effect.html#tip-optimizing-performance-by-skipping-effects&#34;&gt;スキップさせる&lt;/a&gt;ことができる。
空の配列を渡すと最初の1度しか実行されない。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/daikoncl/items/a3806d8a8bf35f086487&#34;&gt;Functional Component と PureComponentの違い・使い分け - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AWS DeepRacerを始める</title>
          <link>https://www.sambaiz.net/article/224/</link>
          <pubDate>Mon, 10 Jun 2019 23:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/224/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/deepracer/&#34;&gt;AWS DeepRacer&lt;/a&gt;は自走する1/18スケールのレーシングカーで、
SageMakerやRoboMaker&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/deepracer/latest/developerguide/deepracer-dependent-aws-services.html&#34;&gt;など&lt;/a&gt;を使って強化学習し、実機を走らせたりバーチャルのDeepRacerリーグで競うことができる。
カメラの画像の処理や、強化学習のアルゴリズムの実装の必要はなく、報酬関数だけで動いてくれるので敷居が低い。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/202/&#34;&gt;強化学習とDQN(Deep Q-network) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;設定項目&#34;&gt;設定項目&lt;/h2&gt;

&lt;h3 id=&#34;action-space&#34;&gt;Action space&lt;/h3&gt;

&lt;p&gt;取りうるアクションである速度とステアリングの組み合わせのリスト。次の項目から生成される。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Maximum steering angle (1 - 30)&lt;/li&gt;
&lt;li&gt;Steering angle granularity (3, 5, 7)&lt;/li&gt;
&lt;li&gt;Maximum speed (0.8 - 8)&lt;/li&gt;
&lt;li&gt;Speed granularity (1, 2, 3)&lt;/li&gt;
&lt;li&gt;Loss type (Mean square error, Huber)&lt;/li&gt;
&lt;li&gt;Number of experience episodes between each policy-updating iteration (5 - 100)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/224.png&#34; alt=&#34;Action space&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;reward-function&#34;&gt;Reward function&lt;/h3&gt;

&lt;p&gt;強化学習の報酬関数。次の&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/deepracer/latest/developerguide/deepracer-reward-function-input.html&#34;&gt;入力パラメータ&lt;/a&gt;を用いて実装する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;all_wheels_on_track&amp;quot;: Boolean,    # flag to indicate if the vehicle is on the track
    &amp;quot;x&amp;quot;: float,                        # vehicle&#39;s x-coordinate in meters
    &amp;quot;y&amp;quot;: float,                        # vehicle&#39;s y-coordinate in meters
    &amp;quot;distance_from_center&amp;quot;: float,     # distance in meters from the track center 
    &amp;quot;is_left_of_center&amp;quot;: Boolean,      # Flag to indicate if the vehicle is on the left side to the track center or not. 
    &amp;quot;heading&amp;quot;: float,                  # vehicle&#39;s yaw in degrees
    &amp;quot;progress&amp;quot;: float,                 # percentage of track completed
    &amp;quot;steps&amp;quot;: int,                      # number steps completed
    &amp;quot;speed&amp;quot;: float,                    # vehicle&#39;s speed in meters per second (m/s)
    &amp;quot;steering_angle&amp;quot;: float,          # vehicle&#39;s steering angle in degrees
    &amp;quot;track_width&amp;quot;: float,              # width of the track
    &amp;quot;waypoints&amp;quot;: [[float, float], … ], # list of [x,y] as milestones along the track center
    &amp;quot;closest_waypoints&amp;quot;: [int, int]    # indices of the two nearest waypoints.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;hyperparameters&#34;&gt;Hyperparameters&lt;/h3&gt;

&lt;p&gt;学習アルゴリズムとして&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/deepracer/latest/developerguide/create-deepracer-project.html&#34;&gt;サポートされている&lt;/a&gt;のは&lt;a href=&#34;https://openai.com/blog/openai-baselines-ppo/&#34;&gt;PPO(Proximal Policy Optimization)&lt;/a&gt;のみで、次のハイパーパラメータが設定できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Gradient descent batch size (32, 64, 128, 256, 512)&lt;/li&gt;
&lt;li&gt;Number of epochs (3 - 10)&lt;/li&gt;
&lt;li&gt;Learning rate (1e-8 - 1e-3)&lt;/li&gt;
&lt;li&gt;Entropy (0 - 1)&lt;/li&gt;
&lt;li&gt;Discount factor (0 - 1)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;stop-conditions-5-480-mins&#34;&gt;Stop conditions (5 - 480 mins)&lt;/h3&gt;

&lt;p&gt;最大学習時間。学習に$3/hourくらいかかるようなのであまり長く走らせ過ぎると大変。&lt;/p&gt;

&lt;h2 id=&#34;サンプルモデルの提出&#34;&gt;サンプルモデルの提出&lt;/h2&gt;

&lt;p&gt;サンプルモデルSample-Follow-center-lineで現在開催されているKumo Torakkuレースに参加してみる。
その名の通り中央線に近いほど高い報酬を与える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def reward_function(params):
    &#39;&#39;&#39;
    Example of rewarding the agent to follow center line
    &#39;&#39;&#39;
    
    # Read input parameters
    track_width = params[&#39;track_width&#39;]
    distance_from_center = params[&#39;distance_from_center&#39;]
    
    # Calculate 3 markers that are at varying distances away from the center line
    marker_1 = 0.1 * track_width
    marker_2 = 0.25 * track_width
    marker_3 = 0.5 * track_width
    
    # Give higher reward if the car is closer to center line and vice versa
    if distance_from_center &amp;lt;= marker_1:
        reward = 1.0
    elif distance_from_center &amp;lt;= marker_2:
        reward = 0.5
    elif distance_from_center &amp;lt;= marker_3:
        reward = 0.1
    else:
        reward = 1e-3  # likely crashed/ close to off track
    
    return float(reward)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Submitしたところ1分ちょっとで完走した。ランキングの上の方は10秒台なのでまだまだだ。&lt;/p&gt;

&lt;h2 id=&#34;モデルの作成&#34;&gt;モデルの作成&lt;/h2&gt;

&lt;p&gt;とりあえず同じReward functionでAction spaceのMaximum speedを最大の8にして学習させてみる。
学習中にもTotal rewardと併せてシミュレーション映像が流れるので徐々にうまく走れるようになっていくのが見られる&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/224-2.png&#34; alt=&#34;学習中&#34; /&gt;&lt;/p&gt;

&lt;p&gt;はずだったんだが、最後までうまく走れずに時間切れ。Submitしたが当然完走できずに終わり。残念だ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CDK/CircleCI/GitHubでAWSリソース管理リポジトリを作る</title>
          <link>https://www.sambaiz.net/article/223/</link>
          <pubDate>Mon, 20 May 2019 09:23:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/223/</guid>
          <description>

&lt;p&gt;AWS CDKでリソースを記述し、PullRequestに対して自動で&lt;code&gt;cdk diff&lt;/code&gt;で変更があるものを表示して、mergeしたときに&lt;code&gt;cdk deploy&lt;/code&gt;する。
全体のコードは&lt;a href=&#34;https://github.com/sambaiz/aws-cdk-circleci-sample&#34;&gt;GitHub&lt;/a&gt;にある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/222/&#34;&gt;AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;追記 (2019-08-29): このフローで起こったいくつかの問題を解決するため新しいツールを作った。
&lt;a href=&#34;https://www.sambaiz.net/article/235/&#34;&gt;PR上でCDKのレビューやデプロイを行うツールcdkbotを作った - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;ci-userの作成&#34;&gt;CI Userの作成&lt;/h2&gt;

&lt;p&gt;まずcdkコマンドを実行するためのCI Userを作成する。これはCDK管理外のスタックで、AWSコンソール上から手動で上げる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/72/&#34;&gt;AWSのAssumeRole - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AssumeRoleしかできないCIUserからCIAssumeRoleをassumeすることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AWSTemplateFormatVersion: &#39;2010-09-09&#39;
Resources:
  CIAssumeRole:
    Type: &#39;AWS::IAM::Role&#39;
    Properties:
      RoleName: &#39;CIAssumeRole&#39;
      ManagedPolicyArns:
        - &#39;arn:aws:iam::aws:policy/AdministratorAccess&#39;
      AssumeRolePolicyDocument: 
        Version: &#39;2012-10-17&#39;
        Statement: 
          - Effect: &#39;Allow&#39;
            Principal: 
              AWS: 
                - !Ref AWS::AccountId
            Action: 
              - &#39;sts:AssumeRole&#39;
  CIGroup:
    Type: &#39;AWS::IAM::Group&#39;
    Properties:
      GroupName: &#39;CI&#39;
  CIPolicies:
    Type: &#39;AWS::IAM::Policy&#39;
    Properties:
      PolicyName: &#39;CI&#39;
      PolicyDocument:
        Statement:
          - Effect: Allow
            Action: &#39;sts:AssumeRole&#39;
            Resource: !GetAtt CIAssumeRole.Arn
      Groups:
        - !Ref CIGroup
  CIUser:
    Type: &#39;AWS::IAM::User&#39;
    Properties:
      UserName: &#39;CI&#39;
      Groups:
        - !Ref CIGroup
  CIUserKeys:
    Type: &#39;AWS::IAM::AccessKey&#39;
    Properties:
      UserName: !Ref CIUser
Outputs:
  AccessKey:
    Value: !Ref CIUserKeys
  SecretKey:
    Value: !GetAtt CIUserKeys.SecretAccessKey
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アップロードするとAccessKeyがOutputされるので、これに加え、SlackのWebhook URLとGitHubの&lt;a href=&#34;https://github.com/settings/tokens&#34;&gt;Token&lt;/a&gt;を作成しCircleCIのEnvironment Variablesに追加する。また、PR作成時にビルドが走るようにビルド設定のOnly build pull requestsをオンにする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/223-1.png&#34; alt=&#34;Environment Variables&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;circleciの設定&#34;&gt;CircleCIの設定&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;.circleci/config.yml&lt;/code&gt;はこんな感じ。PRが立っていればdiffと、develop/masterにmergeするとstg/prd環境へのdeployを行う。
ただ、Only build pull requestsをオンにすると、PR以外ではdefault branchにしているmasterへのpushでしかjobが走らなくなってしまうので、
stg環境へのデプロイはdevelop-&amp;gt;masterへのPRが存在していなければPRを作成したときに行われる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/217/&#34;&gt;CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: 2.1
orbs:
  slack: circleci/slack@3.2.0
executors:
  default:
    docker:
      - image: &#39;circleci/node:12.2.0&#39;
    environment:
      AWS_REGION: &#39;ap-northeast-1&#39;
jobs:
  build:
    executor: &#39;default&#39;
    steps:
      - run:
          name: &#39;assume_role&#39;
          command: |
            sudo apt-get install awscli
            unset AWS_SESSION_TOKEN
            echo $ASSUME_ROLE_ARN
            temp_role=$(aws sts assume-role --role-arn $ASSUME_ROLE_ARN --role-session-name $CIRCLE_PROJECT_REPONAME)
            echo &amp;quot;export AWS_ACCESS_KEY_ID=$(echo $temp_role | jq .Credentials.AccessKeyId | xargs)&amp;quot; &amp;gt;&amp;gt; $BASH_ENV
            echo &amp;quot;export AWS_SECRET_ACCESS_KEY=$(echo $temp_role | jq .Credentials.SecretAccessKey | xargs)&amp;quot; &amp;gt;&amp;gt; $BASH_ENV
            echo &amp;quot;export AWS_SESSION_TOKEN=$(echo $temp_role | jq .Credentials.SessionToken | xargs)&amp;quot; &amp;gt;&amp;gt; $BASH_ENV
      - checkout
      - run:
          name: &#39;build&#39;
          command: |
            npm install
            npm run build
      - run:
          name: &#39;cdk_diff&#39;
          command: |
            if [ -n &amp;quot;$CIRCLE_PULL_REQUEST&amp;quot; ]; then
              export ENV=stg
              if [ &amp;quot;${CIRCLE_BRANCH}&amp;quot; == &amp;quot;develop&amp;quot; ]; then
                export ENV=prd
              fi 
              pr_number=${CIRCLE_PULL_REQUEST##*/}
              block=&#39;```&#39;
              diff=$(echo -e &amp;quot;cdk diff (env=${ENV})\n${block}\n$(npm run --silent ci_diff)\n${block}&amp;quot;)
              data=$(jq -n --arg body &amp;quot;$diff&amp;quot; &#39;{ body: $body }&#39;) # escape
              curl -X POST -H &#39;Content-Type:application/json&#39; \
                -H &#39;Accept: application/vnd.github.v3+json&#39; \
                -H &amp;quot;Authorization: token ${GITHUB_TOKEN}&amp;quot; \
                -d &amp;quot;$data&amp;quot; \
                &amp;quot;https://api.github.com/repos/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}/issues/${pr_number}/comments&amp;quot;
            fi
      - run:
          name: &#39;cdk_deploy&#39;
          command: |
            if [ &amp;quot;${CIRCLE_BRANCH}&amp;quot; == &amp;quot;master&amp;quot; ]; then
              ENV=prd npm run ci_deploy
            elif [ &amp;quot;${CIRCLE_BRANCH}&amp;quot; == &amp;quot;develop&amp;quot; ]; then
              ENV=stg npm run ci_deploy
            fi 
      - slack/status:
          success_message: &amp;quot;cdk build/deploy (${CIRCLE_BRANCH}) has succeeded :tada:&amp;quot;
          failure_message: &amp;quot;cdk build/deploy (${CIRCLE_BRANCH}) has failed :crying_cat_face:&amp;quot;
          webhook: $SLACK_WEBHOOK
          only_for_branches: &amp;quot;develop,master&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assumeしたkeyは&lt;code&gt;$BASH_ENV&lt;/code&gt;でexportされるようにして以後のstepでも&lt;a href=&#34;https://circleci.com/docs/2.0/env-vars/#using-bash_env-to-set-environment-variables&#34;&gt;自動で読み込まれる&lt;/a&gt;ようにする。
GitHubの&lt;a href=&#34;https://developer.github.com/v3/issues/comments/#create-a-comment&#34;&gt;コメント作成API&lt;/a&gt;を呼ぶのにPR番号が必要で&lt;code&gt;$CIRCLE_PR_NUMBER&lt;/code&gt;を使おうとしたが、folkされたPRでしか&lt;a href=&#34;https://circleci.com/docs/2.0/env-vars/#built-in-environment-variables&#34;&gt;入らない&lt;/a&gt;ので&lt;code&gt;$CIRCLE_PULL_REQUEST&lt;/code&gt;のURLから/末尾を取り出して使っている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cdk diff&lt;/code&gt;は差分があるとstderrに出力し終了ステータスを1で&lt;a href=&#34;https://github.com/awslabs/aws-cdk/issues/2111&#34;&gt;返してしまい&lt;/a&gt;、ビルドが中断してしまうのでstderrをstdoutに向けて&lt;code&gt;||true&lt;/code&gt;で強制的に成功させている。sedでは色を付けるためのescape sequenceを取り除いている。&lt;code&gt;-c&lt;/code&gt;でenvの値をcontextとして渡して各環境のStackが作られるようにしていて、deploy時に&lt;code&gt;--require-approval never&lt;/code&gt;を付けているのはsgへのルール追加時などに確認が入ってCIが止まらないようにするため。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/typicode/husky&#34;&gt;husky&lt;/a&gt;でcommit時に&lt;a href=&#34;https://github.com/prettier/prettier&#34;&gt;prettier&lt;/a&gt;を走らせている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat package.json | jq &amp;quot;.scripts&amp;quot;
&amp;quot;scripts&amp;quot;: {
  &amp;quot;build&amp;quot;: &amp;quot;tsc&amp;quot;,
  &amp;quot;watch&amp;quot;: &amp;quot;tsc -w&amp;quot;,
  &amp;quot;format&amp;quot;: &amp;quot;prettier --write \&amp;quot;lib/**/*.ts\&amp;quot;&amp;quot;,
  &amp;quot;ci_diff&amp;quot;: &amp;quot;cdk diff -c env=${ENV:-stg} 2&amp;gt;&amp;amp;1 | sed -r &#39;s/\\x1B\\[([0-9]{1,2}(;[0-9]{1,2})?)?[mGK]//g&#39; || true&amp;quot;,
  &amp;quot;ci_deploy&amp;quot;: &amp;quot;cdk deploy -c env=${ENV:-stg} --require-approval never&amp;quot;
}

$ cat .huskyrc.json 
{
  &amp;quot;hooks&amp;quot;: {
    &amp;quot;pre-commit&amp;quot;: &amp;quot;npm run format &amp;amp;&amp;amp; git add .&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PRを作成すると&lt;code&gt;cdk diff&lt;/code&gt;の結果が表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/223-2.png&#34; alt=&#34;PRに投げられたcdk diffの結果&#34; /&gt;&lt;/p&gt;

&lt;p&gt;deployが完了するとSlackに通知が飛ぶ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/223-3.png&#34; alt=&#34;Slackの通知&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする</title>
          <link>https://www.sambaiz.net/article/222/</link>
          <pubDate>Sun, 19 May 2019 01:43:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/222/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/cdk/api/latest/&#34;&gt;AWS CDK&lt;/a&gt;(Cloud Development Kit)はTypeScriptやJavaなどのコードから
CloudFormationのテンプレートを生成して差分を確認しデプロイできる公式のツール。まだdeveloper preview。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm i -g aws-cdk
$ cdk --version
0.33.0 (build 50d71bf)

$ mkdir cdk-vpc
$ cd cdk-vpc
$ cdk init app --language=typescript
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CloudFormationのリソースと対応する&lt;code&gt;CfnFoo&lt;/code&gt;や、それを内部で作成する高レベル(L2)の&lt;a href=&#34;https://github.com/awslabs/aws-cdk/blob/master/design/aws-guidelines.md#resource-class&#34;&gt;Resource Class&lt;/a&gt;&lt;code&gt;Foo&lt;/code&gt;が実装されている。
ただし、現状&lt;code&gt;CfnFoo&lt;/code&gt;に対応するResource Classが存在しないものや、複数のリソースを内部で作成するResource Classが存在する。
例えば、&lt;a href=&#34;https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-ec2.Vpc.html&#34;&gt;ec2.Vpc&lt;/a&gt;は&lt;a href=&#34;https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-ec2.CfnVPC.html&#34;&gt;CfnVPC&lt;/a&gt;だけではなく、Public/Private Subnet、NATGatewayまでまとめて一般的な構成で作る。Resource Classはまだ変更が多い。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/206/&#34;&gt;CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;型があり補完が効くので通常のテンプレートと比べて書きやすいし、ループしたりすることもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/222.png&#34; alt=&#34;補完&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import * as cdk from &#39;@aws-cdk/cdk&#39;
import * as ec2 from &#39;@aws-cdk/aws-ec2&#39;

interface Export {
  vpc: ec2.Vpc
}

export class VPCStack extends cdk.Stack {
  protected deployEnv: string
  export: Export
  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props)
    this.deployEnv = this.node.getContext(&#39;env&#39;)
    const vpc = this.vpc()

    this.export = {
      vpc: vpc
    }
  }

  private vpc() {
    let cidr: string | null
    if (this.deployEnv === &#39;stg&#39;) {
      cidr = &#39;172.32.1.0/24&#39;
    } else if (this.deployEnv === &#39;prd&#39;) {
      cidr = &#39;172.32.2.0/24&#39;
    } else {
      throw new Error(`unknown env ${this.deployEnv}`)
    }
    return new ec2.Vpc(this, `${this.deployEnv}-vpc`, {
      cidr: cidr,
      maxAZs: 2,
      subnetConfiguration: [
        {
          cidrMask: 26,
          subnetType: ec2.SubnetType.Public,
          name: `${this.deployEnv}-vpc-public`
        },
        {
          cidrMask: 26,
          subnetType: ec2.SubnetType.Private,
          name: `${this.deployEnv}-vpc-private`
        }
      ]
    })
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プロパティを渡せばRefやGetAttになる。Stack間のExportやImportValueも同様で、さらに依存関係を考慮した順序でStackを更新してくれる。
必要であれば&lt;code&gt;cdk.Fn.ImportValue()&lt;/code&gt;で外部からImportValueしたり、
&lt;code&gt;cdk.CfnOutput()&lt;/code&gt;でOutputすることもできる。
Serverless FrameworkなどのCDK外StackからImportする際は、自動で作られたExportはCDK内で依存がなくなると消そうとしてしまうので、
明示的にExportしたものをImportした方が良さそう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const vpcStackExport = new VPCStack(app, `${deployEnv}VPCStack`).export
new SomeAppStack(app, `${deployEnv}SomeAppStack`, {
    dbSubnetIds: vpcStackExport.vpc.privateSubnets.map(v =&amp;gt; v.subnetId)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;cdk synth&lt;/code&gt;でテンプレートを出力して確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm run build
$ cdk synth -o ./outputs
./outputs/CdkVpcStack.template.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;cdk diff&lt;/code&gt;で作成/削除されるリソースを見て、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cdk diff
Stack CdkVpcStack
Resources
[+] AWS::EC2::VPC test-vpc testvpc8985080E 
[+] AWS::EC2::Subnet test-vpc/test-publicSubnet1/Subnet testvpctestpublicSubnet1SubnetF24995A1 
[+] AWS::EC2::RouteTable test-vpc/test-publicSubnet1/RouteTable testvpctestpublicSubnet1RouteTableF3DE8760 
[+] AWS::EC2::SubnetRouteTableAssociation test-vpc/test-publicSubnet1/RouteTableAssociation testvpctestpublicSubnet1RouteTableAssociation13140377 
[+] AWS::EC2::Route test-vpc/test-publicSubnet1/DefaultRoute testvpctestpublicSubnet1DefaultRoute06B168C8 
[+] AWS::EC2::EIP test-vpc/test-publicSubnet1/EIP testvpctestpublicSubnet1EIP5E036D64 
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;cdk deploy&lt;/code&gt;でデプロイできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cdk deploy 
CdkVpcStack: deploying...
CdkVpcStack: creating CloudFormation changeset...
  0/25 | 20:59:21 | CREATE_IN_PROGRESS   | AWS::EC2::EIP                         | test-vpc/test-publicSubnet2/EIP (testvpctestpublicSubnet2EIPCB02013C) 
  0/25 | 20:59:21 | CREATE_IN_PROGRESS   | AWS::CDK::Metadata                    | CDKMetadata 
  0/25 | 20:59:22 | CREATE_IN_PROGRESS   | AWS::EC2::InternetGateway             | test-vpc/IGW (testvpcIGW2C2BA83F) 
  0/25 | 20:59:22 | CREATE_IN_PROGRESS   | AWS::EC2::EIP                         | test-vpc/test-publicSubnet1/EIP (testvpctestpublicSubnet1EIP5E036D64) 
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/223/&#34;&gt;CDK/CircleCI/GitHubでAWSリソース管理リポジトリを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する</title>
          <link>https://www.sambaiz.net/article/221/</link>
          <pubDate>Thu, 09 May 2019 23:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/221/</guid>
          <description>

&lt;p&gt;DAEMONを動かすことは&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/ecs_services.html#service_scheduler&#34;&gt;できず&lt;/a&gt;、
fluentd logdriverも&lt;a href=&#34;https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_LogConfiguration.html&#34;&gt;サポートされていない&lt;/a&gt;Fargateで、
サイドカーとしてFluentdのコンテナを動かしてアプリケーションのログをS3に送る。
全体のコードは&lt;a href=&#34;https://github.com/sambaiz/ecs-fargate-fluentd-sidecar&#34;&gt;GitHub&lt;/a&gt;にある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/196/&#34;&gt;FargateでECSを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/159/&#34;&gt;Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;fluentd&#34;&gt;Fluentd&lt;/h2&gt;

&lt;p&gt;必要なプラグインと設定ファイルを入れたイメージを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM fluent/fluentd:v1.4-1

USER root

COPY ./fluent.conf /fluentd/etc/

# install plugin
RUN apk add --update-cache --virtual .build-deps sudo build-base ruby-dev \
    &amp;amp;&amp;amp; gem install fluent-plugin-s3 -v 1.0.0 --no-document \
    &amp;amp;&amp;amp; gem install uuidtools \
    &amp;amp;&amp;amp; gem sources --clear-all \
    &amp;amp;&amp;amp; apk del .build-deps \
    &amp;amp;&amp;amp; rm -rf /var/cache/apk/* \
    /home/fluent/.gem/ruby/*/cache/*.gem

# set timezone (Alpine)
RUN apk --update-cache add tzdata &amp;amp;&amp;amp; \
    cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime &amp;amp;&amp;amp; \
    apk del tzdata &amp;amp;&amp;amp; \
    rm -rf /var/cache/apk/*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fluent.confはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
    @type tail
    format json
    path /var/log/test.log
    pos_file /var/log/test.log.pos
    tag test
    &amp;lt;parse&amp;gt;
      @type json
      time_type string
      time_format &#39;%Y-%m-%dT%H:%M:%S%:z&#39;
      keep_time_key true
    &amp;lt;/parse&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match test&amp;gt;
  @type s3

  s3_bucket my-test-logs-bbbbbb
  s3_region ap-northeast-1
  path test-log/
  time_slice_format ymd=%Y-%m-%d/hour=%-H/
  s3_object_key_format %{path}%{time_slice}%{uuid_flush}.json.%{file_extension}

  &amp;lt;buffer tag,time&amp;gt;
    @type file
    path /var/log/fluent/test
    timekey 60
    timekey_wait 60
    chunk_limit_size 30m
  &amp;lt;/buffer&amp;gt;
  &amp;lt;format&amp;gt;
    @type json
  &amp;lt;/format&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pushするとCircleCIでビルドしECRにpushされるようにした。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/217/&#34;&gt;CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;workflows:
  build-push:
    jobs:
      - aws-ecr/build_and_push_image:
          name: &#39;build-latest&#39;
          executor: default
          repo: &#39;${ECR_REPO}&#39;
          tag: latest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;role-https-docs-aws-amazon-com-ja-jp-awscloudformation-latest-userguide-aws-resource-iam-role-html&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html&#34;&gt;Role&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ECRからPullできるExecutionRoleとS3にPutできるTaskRoleを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ExecutionRole:
  Type: &#39;AWS::IAM::Role&#39;
  Properties:
    RoleName: &#39;test-execution-role&#39;
    AssumeRolePolicyDocument: 
      Version: &#39;2012-10-17&#39;
      Statement: 
        - Effect: &#39;Allow&#39;
          Principal:
            Service: &#39;ecs-tasks.amazonaws.com&#39;
          Action: 
            - &#39;sts:AssumeRole&#39;
    Policies: 
      - PolicyName: &#39;test-execution-role&#39;
        PolicyDocument: 
          Version: &#39;2012-10-17&#39;
          Statement: 
            - Effect: &#39;Allow&#39;
              Action:
                - ecr:GetAuthorizationToken
                - ecr:BatchCheckLayerAvailability
                - ecr:GetDownloadUrlForLayer
                - ecr:BatchGetImage
                - logs:CreateLogStream
                - logs:PutLogEvents
              Resource: &#39;*&#39;
TaskRole:
  Type: &#39;AWS::IAM::Role&#39;
  Properties:
    RoleName: &#39;test-task-role&#39;
    AssumeRolePolicyDocument: 
      Version: &#39;2012-10-17&#39;
      Statement: 
        - Effect: &#39;Allow&#39;
          Principal:
            Service: &#39;ecs-tasks.amazonaws.com&#39;
          Action: 
            - &#39;sts:AssumeRole&#39;
    Policies: 
      - PolicyName: &#39;test-task-role&#39;
        PolicyDocument: 
          Version: &#39;2012-10-17&#39;
          Statement: 
            - Effect: &#39;Allow&#39;
              Action: &#39;s3:ListBucket&#39;
              Resource: !GetAtt Bucket.Arn
            - Effect: &#39;Allow&#39;
              Action: 
                - &#39;s3:GetObject&#39;
                - &#39;s3:PutObject&#39;
              Resource: !Join [ &#39;/&#39;, [ !GetAtt Bucket.Arn, &#39;*&#39; ] ]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;taskdefinition-https-docs-aws-amazon-com-ja-jp-awscloudformation-latest-userguide-aws-resource-ecs-taskdefinition-html&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-ecs-taskdefinition.html&#34;&gt;TaskDefinition&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Fargateで動かすのでNetworkModeはawsvpcになる。K8sのときと同様にvolumeをmountしてファイルを共有する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TaskDefinition:
  Type: AWS::ECS::TaskDefinition
  Properties: 
    RequiresCompatibilities:
      - &#39;EC2&#39;
      - &#39;FARGATE&#39;
    NetworkMode: &#39;awsvpc&#39;
    ExecutionRoleArn: !Ref ExecutionRole
    TaskRoleArn : !Ref TaskRole
    Cpu: &#39;256&#39;
    Memory: &#39;512&#39;
    ContainerDefinitions: 
      - Name: &#39;app&#39;
        Image: &#39;busybox&#39;
        EntryPoint: 
          - &#39;sh&#39;
          - &#39;-c&#39;
        Command: 
          - &#39;while true; do echo &amp;quot;{\&amp;quot;foo\&amp;quot;:1000,\&amp;quot;time\&amp;quot;:\&amp;quot;2019-05-09T20:00:00+09:00\&amp;quot;}&amp;quot; &amp;gt;&amp;gt; /var/log/test.log; sleep 1; done&#39;
        Essential: &#39;true&#39;
        LogConfiguration:
          LogDriver: &#39;awslogs&#39;
          Options:
            awslogs-group: !Ref LogGroup
            awslogs-region: &#39;ap-northeast-1&#39;
            awslogs-stream-prefix: &#39;app&#39;
        Environment:
          - Name: &#39;TZ&#39;
            Value: &#39;Asia/Tokyo&#39;
        MountPoints: 
          - SourceVolume: &amp;quot;varlog&amp;quot;
            ContainerPath: &amp;quot;/var/log&amp;quot;
      - Name: &#39;fluentd&#39;
        Image: !Join [ &#39;/&#39;, [ &#39;&amp;lt;your_account_id&amp;gt;.dkr.ecr.ap-northeast-1.amazonaws.com&#39;, !Ref Repository ] ]
        Essential: &#39;true&#39;
        LogConfiguration:
          LogDriver: &#39;awslogs&#39;
          Options:
            awslogs-group: !Ref LogGroup
            awslogs-region: &#39;ap-northeast-1&#39;
            awslogs-stream-prefix: &#39;fluentd&#39;
        MountPoints: 
          - SourceVolume: &amp;quot;varlog&amp;quot;
            ContainerPath: &amp;quot;/var/log&amp;quot;
    Volumes: 
      - Name: &#39;varlog&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;service-https-docs-aws-amazon-com-ja-jp-awscloudformation-latest-userguide-aws-resource-ecs-service-html&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-ecs-service.html&#34;&gt;Service&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;VPCやサブネットはこのスタックでは作らない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/206/&#34;&gt;CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Service:
  Type: AWS::ECS::Service
  Properties:
    Cluster: !Ref Cluster
    LaunchType: FARGATE
    DesiredCount: 1
    TaskDefinition: !Ref TaskDefinition
    NetworkConfiguration:
      AwsvpcConfiguration:
        # If private subnet is placed, set &#39;DISABLED&#39; to pull images
        AssignPublicIp: &#39;ENABLED&#39;
        Subnets: !Ref Subnets
    ServiceName: &#39;test-service&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;確認&#34;&gt;確認&lt;/h2&gt;

&lt;p&gt;スタックを上げるとServiceからTaskが動き、S3の正しいパスにログが保存される。
保存されないときはfluent.confとCloudWatchにあるFluentdのログを、&lt;code&gt;ymd=1970-01-01&lt;/code&gt;になってしまった場合はtime_formatの内容や場所を、
時間がずれている場合はFluentdコンテナのタイムゾーンが正しいか確認する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/221.png&#34; alt=&#34;S3に保存されているログ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>カテゴリカル変数をLabel/OneHotEncoderやget_dummiesで変換する</title>
          <link>https://www.sambaiz.net/article/220/</link>
          <pubDate>Mon, 06 May 2019 15:59:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/220/</guid>
          <description>

&lt;pre&gt;&lt;code&gt;data = [&amp;quot;tokyo&amp;quot;, &amp;quot;berlin&amp;quot;, &amp;quot;tokyo&amp;quot;, &amp;quot;paris&amp;quot;, &amp;quot;amsterdam&amp;quot;, &amp;quot;paris&amp;quot;, &amp;quot;amsterdam&amp;quot;, &amp;quot;berlin&amp;quot;]
partial_data = data[:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;scikit-learnの&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html&#34;&gt;preprocessing.LabelEncoder&lt;/a&gt;でカテゴリカル変数を数値のラベルに変換できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn import preprocessing
le = preprocessing.LabelEncoder()
le.fit(data)
print(le.classes_) # [&#39;amsterdam&#39; &#39;berlin&#39; &#39;paris&#39; &#39;tokyo&#39;]
encoded = le.transform(partial_data)
print(encoded) # [3 1 3]
print(le.inverse_transform(encoded)) # [&#39;tokyo&#39; &#39;berlin&#39; &#39;tokyo&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html&#34;&gt;preprocessing.OneHotEncoder&lt;/a&gt;
でone hot vectorに変換できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;oh = preprocessing.OneHotEncoder()
oh.fit([[d] for d in data])
print(oh.categories_[0]) # [&#39;amsterdam&#39; &#39;berlin&#39; &#39;paris&#39; &#39;tokyo&#39;]
encoded = oh.transform([[d] for d in partial_data]).toarray()
print(encoded) # [[0. 0. 0. 1.] [0. 1. 0. 0.] [0. 0. 0. 1.]]
print(oh.inverse_transform(encoded)) # [[&#39;tokyo&#39;] [&#39;berlin&#39;] [&#39;tokyo&#39;]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pandasでは&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html&#34;&gt;get_dummies&lt;/a&gt;で
one hot vectorに変換できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
print(pd.get_dummies(data))
&#39;&#39;&#39;
   amsterdam  berlin  paris  tokyo
0          0       0      0      1
1          0       1      0      0
2          0       0      0      1
3          0       0      1      0
4          1       0      0      0
5          0       0      1      0
6          1       0      0      0
7          0       1      0      0
&#39;&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;カテゴリ変数を扱える決定木ではLabelEncoderを使うとデータ量が少なくなって良いが、
通常はラベルの数値の大小の影響を受けないようにone hot vectorにする。
カテゴリが多いとその分次元も増えるので、次元の呪いを抑えるため必要なら主成分分析(PCA)で次元削減する。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor&#34;&gt;scikit learn - When to use One Hot Encoding vs LabelEncoder vs DictVectorizor? - Data Science Stack Exchange&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DatadogのAWS integrationとAlertの設定をTerraformで行う</title>
          <link>https://www.sambaiz.net/article/219/</link>
          <pubDate>Sat, 04 May 2019 19:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/219/</guid>
          <description>

&lt;p&gt;DatadogのAWS integrationとAlertの設定をTerraformで行い、バージョン管理やレビューできるようにする。
全体のコードは&lt;a href=&#34;https://github.com/sambaiz/datadog-terraform-sample&#34;&gt;GitHub&lt;/a&gt;に置いてある。&lt;/p&gt;

&lt;h2 id=&#34;aws-integration&#34;&gt;AWS Integration&lt;/h2&gt;

&lt;p&gt;まず&lt;a href=&#34;https://www.terraform.io/docs/providers/datadog/r/integration_aws.html&#34;&gt;datadog_integration_aws&lt;/a&gt;でAWS integrationの設定を作成してExternalIDを取得し、Policy/Roleを作成する。必要な権限は&lt;a href=&#34;https://docs.datadoghq.com/integrations/amazon_web_services/?tab=allpermissions#datadog-aws-iam-policy&#34;&gt;ドキュメント&lt;/a&gt;を参照。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;datadog_integration_aws&amp;quot; &amp;quot;test&amp;quot; {
  account_id  = &amp;quot;${var.aws_account_id}&amp;quot;
  role_name   = &amp;quot;${var.aws_integration_role_name}&amp;quot;
  filter_tags = [&amp;quot;datadog:1&amp;quot;]
}

data &amp;quot;aws_iam_policy_document&amp;quot; &amp;quot;datadog_aws_integration_assume_role&amp;quot; {
  statement {
    actions = [&amp;quot;sts:AssumeRole&amp;quot;]

    principals {
      type        = &amp;quot;AWS&amp;quot;
      identifiers = [&amp;quot;arn:aws:iam::464622532012:root&amp;quot;]
    }

    condition {
      test     = &amp;quot;StringEquals&amp;quot;
      variable = &amp;quot;sts:ExternalId&amp;quot;

      values = [
        &amp;quot;${datadog_integration_aws.test.external_id}&amp;quot;,
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Datadog providerにはないSlackなどその他のintegrationは手動で設定する必要がある。
また、Logも集める場合Serverless Application Repositoryから公式の&lt;a href=&#34;https://serverlessrepo.aws.amazon.com/applications/arn:aws:serverlessrepo:us-east-1:464622532012:applications~Datadog-Log-Forwarder&#34;&gt;Datadog-Log-Forwarder&lt;/a&gt;を入れて
AWS IntegrationのところにLambdaのARNを入れるのも手動。&lt;/p&gt;

&lt;h2 id=&#34;alert&#34;&gt;Alert&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/datadog/r/monitor.html&#34;&gt;datadog_monitor&lt;/a&gt;でAlertを作成する。
今回はLambdaの実行が失敗したときと、WARNという文字列が含まれるログが一定数出力されたときにAlertを飛ばすようにしてみた。
なおinfoやwarnといったログレベルはjsonのlevelフィールドに入れればデフォルトのpipelineでマップされるので通常は文字列比較などする必要はない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/219-2.png&#34; alt=&#34;pipeline&#34; /&gt;&lt;/p&gt;

&lt;p&gt;初めに作るときは一度画面で意図通りアラートが飛ぶものを作成し、クエリなどをコピーするのが確実。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;datadog_monitor&amp;quot; &amp;quot;lambda-error-alert&amp;quot; {
  name    = &amp;quot;lambda-error-alert&amp;quot;
  type    = &amp;quot;metric alert&amp;quot;
  message = &amp;quot;Error occurred. @slack-alert&amp;quot;

  # Note: We highly recommend a delay of at least 900s for AWS metrics.
  evaluation_delay = 900

  query = &amp;quot;sum(last_1m):avg:aws.lambda.errors{*} by {functionname}.as_count() &amp;gt;= 3&amp;quot;

  thresholds {
    ok                = 0
    critical          = 3
    critical_recovery = 2
  }

  renotify_interval = 10
}

resource &amp;quot;datadog_monitor&amp;quot; &amp;quot;lambda-warn-log-alert&amp;quot; {
  name    = &amp;quot;lambda-warn-log-alert&amp;quot;
  type    = &amp;quot;log alert&amp;quot;
  message = &amp;quot;Many warn logs are being outputted. @slack-alert&amp;quot;

  query = &amp;quot;logs(\&amp;quot;service:lambda WARN\&amp;quot;).index(\&amp;quot;main\&amp;quot;).rollup(\&amp;quot;count\&amp;quot;).by(\&amp;quot;functionname\&amp;quot;).last(\&amp;quot;5m\&amp;quot;) &amp;gt; 4&amp;quot;

  thresholds {
    ok       = 0
    warning  = 2
    critical = 4
  }

  renotify_interval = 10
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一定確率でログやエラーを出すLambdaを動かしてAlertが飛ぶことを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Handler(ctx context.Context) (string, error) {
	if rand.Intn(10) &amp;lt; 7 {
		fmt.Println(&amp;quot;[WARN] some problem&amp;quot;)
	}

	if rand.Intn(100) &amp;gt; 10 {
		return &amp;quot;&amp;quot;, errors.New(&amp;quot;error&amp;quot;)
	}

	return &amp;quot;done&amp;quot;, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/219.png&#34; alt=&#34;Slackに流れるAlert&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Box-Cox transformationで非正規分布のデータを正規分布に近づける</title>
          <link>https://www.sambaiz.net/article/218/</link>
          <pubDate>Tue, 30 Apr 2019 17:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/218/</guid>
          <description>

&lt;p&gt;Box-Cox Transormationは次の式による変換。λ=0のときはlog(x)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/218-1.png&#34; alt=&#34;式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;λが1より大きい場合は小さな値の間隔が圧縮され、小さい場合は大きな値の間隔が圧縮されるように変換される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
from scipy.special import boxcox1p
import matplotlib.pyplot as plt
from bokeh.plotting import figure
from bokeh.io import output_notebook, show
output_notebook()

p = figure(
    title=&amp;quot;Box-Cox Transformations&amp;quot;,
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;λ&#39;,
)

for lam in [-1, 0, 1, 2]:
  v = np.array([boxcox1p(i, lam) for i in range(10)])
  v = v / v.max()
  p.line(v, lam)
  p.circle(v, lam, size=8)

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/218-2.png&#34; alt=&#34;λごとの変換後の間隔&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これによって左右非対称な分布を対称(skew=0)な正規分布に近づけることができる。
以前正規分布に近づけるのに対数を取ったが、これはBox-Cox transformationの1ケースだといえる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/216/&#34;&gt;KaggleのHome Prices CompetitionのKernelからデータの探り方を学ぶ - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;試しに適当な左右非対称な分布のデータを変換してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import seaborn as sns

p = np.array([500, 2000, 3000, 2500, 1000, 500, 125, 125, 0.0125, 0.0125])
p = p / p.sum()
data = np.random.choice([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], size=1000, p=p) * np.random.rand(1000)
df = pd.DataFrame({
    &#39;x&#39;: data
})
print(&#39;skew={:.3}&#39;.format(df[&#39;x&#39;].skew())) # skew=1.08
sns.distplot(df[&#39;x&#39;], hist=False, label=(&#39;data&#39;))
sns.distplot(np.random.normal(df[&#39;x&#39;].mean(), np.sqrt(df[&#39;x&#39;].var()), len(data)), hist=False, label=(&#39;normal distribution&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/218-3.png&#34; alt=&#34;データの分布と正規分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;評価値としてソートしたデータと正規分布のCDF(cumulative distribution function; 累積分布関数)の逆関数の相関係数を用いる。
逆関数はppf()で、(0,1)の定義域で(-∞,∞)の値を取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from scipy.stats import norm
import matplotlib.pyplot as plt

x = [x * 0.001 for x in range(0, 1001)]
y = norm.ppf(x) # inverse CDF
plt.plot(x, y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/218-6.png&#34; alt=&#34;正規分布のCDFの逆関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;-2~2まで0.1刻みでλを動かして相関係数をプロットする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from scipy.special import boxcox1p

lams = [ i * 0.1 for i in range(-20, 20) ]
data.sort()
xs = [norm.ppf(((i+1) - 0.5) / len(data)) for  i in range(len(data))]
yss = [np.array([boxcox1p(d, lam) for d in data]) for lam in lams] # boxcox1p(x) = ((x + 1) ** lam - 1) / lam
cors = [np.corrcoef(xs, ys)[0, 1] for ys in yss]
best_cor = -1.0
for i, cor in enumerate(cors):
  if best_cor &amp;lt; cor:
    best_cor = cor
    best_lam = lams[i]
    best_ys = yss[i]
plt.plot(lams, cors)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/218-4.png&#34; alt=&#34;λごとの相関係数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最良のλで変換したところskewが大きく減少し正規分布に近づいた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from scipy.stats import skew

print(&#39;lambda={} skew={:.3}&#39;.format(best_lam, skew(best_ys))) # lambda=-0.1 skew=0.11
sns.distplot(best_ys, hist=False, label=(&#39;transformed data&#39;))
sns.distplot(np.random.normal(best_ys.mean(), np.sqrt(best_ys.var()), len(best_ys)), hist=False, label=(&#39;normal distribution&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/218-5.png&#34; alt=&#34;変換したデータの分布と正規分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.inv_boxcox1p.html&#34;&gt;inv_boxcox1p&lt;/a&gt;で元に戻せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from scipy.special import inv_boxcox1p
inv_ys = inv_boxcox1p(best_ys, best_lam)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://onlinestatbook.com/2/transformations/box-cox.html&#34;&gt;Box-Cox Transformations&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる</title>
          <link>https://www.sambaiz.net/article/217/</link>
          <pubDate>Sat, 13 Apr 2019 23:13:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/217/</guid>
          <description>&lt;p&gt;CircleCI 2.1から&lt;a href=&#34;https://circleci.com/docs/2.0/orb-intro/&#34;&gt;Orb&lt;/a&gt;というjobをパッケージ化したものが使えるようになり、
自分でjobを書かずとも様々な処理を実行させることができるようになった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/183/&#34;&gt;CircleCI 2.0でDocker imageをbuildしてタグを付けてContainer Registryに上げる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今回は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://circleci.com/orbs/registry/orb/circleci/aws-ecr&#34;&gt;aws-ecr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://circleci.com/orbs/registry/orb/circleci/slack&#34;&gt;slack&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を使ってdocker buildしてECRにpushし、バージョンタグが付いている場合はSlackに通知させる。&lt;/p&gt;

&lt;p&gt;AWS_ACCESS_KEY_IDとAWS_SECRET_ACCESS_KEYを環境変数に入れて、ECRのリポジトリを作成し、
SlackのwebhookのURLを&lt;a href=&#34;https://slack.com/services/new/incoming-webhook&#34;&gt;発行&lt;/a&gt;しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: 2.1
orbs:
  aws-ecr: circleci/aws-ecr@3.1.0
  slack: circleci/slack@2.3.0

executors:
  default:
    machine: true
    environment:
      ECR_REPO: &#39;test-ecr-push&#39;
      AWS_ECR_ACCOUNT_URL: &#39;&amp;lt;account_id&amp;gt;.dkr.ecr.&amp;lt;region&amp;gt;.amazonaws.com&#39;
      AWS_REGION: &#39;&amp;lt;region&amp;gt;&#39;
      CLUSTER_NAME: &#39;test&#39;

jobs:
  notify_slack:
    executor: default
    steps:
      - slack/status:
          success_message: &#39;${ECR_REPO}:${CIRCLE_TAG} was released&#39;
          webhook: &#39;https://hooks.slack.com/services/******&#39;

workflows:
  build-push:
    jobs:
      - aws-ecr/build_and_push_image:
          name: &amp;amp;build_version &#39;build-version&#39;
          executor: default
          repo: &#39;${ECR_REPO}&#39;
          tag: &#39;${CIRCLE_TAG}&#39;
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /^v.*/
      - aws-ecr/build_and_push_image:
          name: &#39;build-latest&#39;
          executor: default
          repo: &#39;${ECR_REPO}&#39;
          tag: latest
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /^v.*/
      - aws-ecr/build_and_push_image:
          name: &#39;build-hash&#39;
          executor: default
          repo: &#39;${ECR_REPO}&#39;
          tag: &#39;${CIRCLE_SHA1}&#39;
      - notify_slack:
          requires:
            - *build_version
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /^v.*/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけでAWS CLIのインストールやDockerのセットアップから一通りやってくれる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/217.png&#34; alt=&#34;aws-ecr/build_and_push_imageの内容&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Slackへも通知される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/217-2.png&#34; alt=&#34;Slack通知&#34; /&gt;&lt;/p&gt;

&lt;p&gt;同じjobを複数走らせる場合にrequiresで指定するにはnameが必須になる。
そうでなくてもworkflowで見やすくなるので付けておいた方が良い。
環境変数の記述をjob間で共有するのに、これも2.1から追加された&lt;a href=&#34;https://circleci.com/docs/2.0/configuration-reference/#executors-requires-version-21&#34;&gt;executor&lt;/a&gt;を使っている。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KaggleのHouse Prices CompetitionのKernelからデータの探り方を学ぶ</title>
          <link>https://www.sambaiz.net/article/216/</link>
          <pubDate>Mon, 08 Apr 2019 21:01:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/216/</guid>
          <description>

&lt;p&gt;Kaggleの家の売値を予測するCompetitionのKernelからデータの探り方を学ぶ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python&#34;&gt;Comprehensive data exploration with Python&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;正規化&#34;&gt;正規化&lt;/h2&gt;

&lt;p&gt;予測する値であるSalePriceの分布を出すと、やや左に寄った非対称の分布をしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import seaborn as sns
df = pd.read_csv(&#39;train.csv&#39;)
df[&#39;SalePrice&#39;].describe()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;count      1460.000000
mean     180921.195890
std       79442.502883
min       34900.000000
25%      129975.000000
50%      163000.000000
75%      214000.000000
max      755000.000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/216-1.png&#34; alt=&#34;SalePriceの分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.probplot.html&#34;&gt;scipy.stats.probplot()&lt;/a&gt;で
プロットしても直線で表されている正規分布から外れていることが分かるが、正規分布であることが望ましい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from scipy import stats
import matplotlib.pyplot as plt
res = stats.probplot(df[&#39;SalePrice&#39;], dist=&#39;norm&#39;, plot=plt)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/216-4.png&#34; alt=&#34;SalePriceの分布と正規分布のprobplot()&#34; /&gt;&lt;/p&gt;

&lt;p&gt;そこで対数をとって正規分布に近づけてやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
res = stats.probplot(np.log(df[&#39;SalePrice&#39;]), dist=&#39;norm&#39;, plot=plt)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/216-5.png&#34; alt=&#34;SalePriceの分布と正規分布のprobplot()&#34; /&gt;&lt;/p&gt;

&lt;p&gt;なお、この変換はBox-Cox transformationのλ=0のときにあたる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/218/&#34;&gt;Box-Cox transformationで非正規分布のデータを正規分布に近づける - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;欠損値&#34;&gt;欠損値&lt;/h2&gt;

&lt;h3 id=&#34;欠損率&#34;&gt;欠損率&lt;/h3&gt;

&lt;p&gt;特徴量の欠損(NA)率を多い順にならべてみると次のようにいくつかはほとんど欠損していることが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;total = df.isnull().sum().sort_values(ascending=False)
percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=[&#39;Total&#39;, &#39;Percent&#39;])
print(missing_data.head(10))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;        Total   Percent
PoolQC         1453  0.995205
MiscFeature    1406  0.963014
Alley          1369  0.937671
Fence          1179  0.807534
FireplaceQu     690  0.472603
LotFrontage     259  0.177397
GarageCond       81  0.055479
GarageType       81  0.055479
GarageYrBlt      81  0.055479
GarageFinish     81  0.055479
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;パラメータ間の相関&#34;&gt;パラメータ間の相関&lt;/h3&gt;

&lt;p&gt;まず各パラメータ間の相関を見てみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sns.heatmap(df.corr(), square=True);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/216-3.png&#34; alt=&#34;各パラメータの相関&#34; /&gt;&lt;/p&gt;

&lt;p&gt;色が濃くなっているところが強い相関がある組み合わせで、例えばSalePriceの行を見てみると
OverallQual(品質)やGrLivArea(延べ床面積?)の正の相関が比較的強く、
実際OverallQualとSalePriceの相関係数を出すと0.79とかなり高い。箱ひげ図で見ても分かりやすい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import matplotlib.pyplot as plt
data = pd.concat([df[&#39;SalePrice&#39;], df[&#39;OverallQual&#39;]], axis=1)
f, ax = plt.subplots(figsize=(8, 6))
fig = sns.boxplot(x=&#39;OverallQual&#39;, y=&amp;quot;SalePrice&amp;quot;, data=data)
fig.axis(ymin=0, ymax=800000);
print(df[&#39;SalePrice&#39;].corr(df[&#39;OverallQual&#39;])) # =&amp;gt; 0.7909816005838044
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/216-2.png&#34; alt=&#34;OverallQualとSalePriceの箱ひげ図&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;欠損値の扱い&#34;&gt;欠損値の扱い&lt;/h3&gt;

&lt;p&gt;欠損率があまりに多かったり、他に相関が強く代替できるものがあれば、
取り除いてやったり、ほとんど欠損してない場合は欠損しているレコードだけ取り除くこともできるが、取り除き過ぎると精度が上がらない。
そこでなるべく自然な、連続値であれば中央値や0といった値を埋めて使いたい。ドメイン知識が必要になるところだと思う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df[&amp;quot;PoolQC&amp;quot;].fillna(&amp;quot;None&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;外れ値&#34;&gt;外れ値&lt;/h2&gt;

&lt;p&gt;X軸をGrLivArea、Y軸をSalePriceとしてPlotすると右下2点が外れ値になっていることが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data = pd.concat([df[&#39;SalePrice&#39;], df[&#39;GrLivArea&#39;]], axis=1)
data.plot.scatter(x=&#39;GrLivArea&#39;, y=&#39;SalePrice&#39;, ylim=(0,800000));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/216-6.png&#34; alt=&#34;X軸をGrLivArea、Y軸をSalePriceとしてPlotしたもの&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これらに引っ張られないように除去してやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df = df.drop(df.sort_values(by = &#39;GrLivArea&#39;, ascending = False)[:2][&#39;Id&#39;].index)
data = pd.concat([df[&#39;SalePrice&#39;], df[&#39;GrLivArea&#39;]], axis=1)
data.plot.scatter(x=&#39;GrLivArea&#39;, y=&#39;SalePrice&#39;, ylim=(0,800000));
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React, Material-UI, Unstated, RechartsでTODOを作った</title>
          <link>https://www.sambaiz.net/article/215/</link>
          <pubDate>Thu, 28 Mar 2019 17:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/215/</guid>
          <description>

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/215.gif&#34; alt=&#34;動作&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/react-unstated-materialui-recharts&#34;&gt;コード&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;create-react-app-https-github-com-facebook-create-react-app&#34;&gt;&lt;a href=&#34;https://github.com/facebook/create-react-app&#34;&gt;create-react-app&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;create-react-appでアプリを作成した。
TypeScriptを&lt;a href=&#34;https://facebook.github.io/create-react-app/docs/adding-typescript&#34;&gt;有効にしている&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npx create-react-app react-todo-unstated --typescript
$ cd react-todo-unstated
$ tree src/
src/
├── App.css
├── App.test.tsx
├── App.tsx
├── index.css
├── index.tsx
├── logo.svg
├── react-app-env.d.ts
└── serviceWorker.ts

$ npm start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;material-ui-https-material-ui-com&#34;&gt;&lt;a href=&#34;https://material-ui.com/&#34;&gt;Material-UI&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;UIはMaterial-UIでUIで作った。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save @material-ui/core @material-ui/icons
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;public/index.html&lt;/code&gt;に&lt;a href=&#34;https://fonts.google.com/specimen/Roboto&#34;&gt;Roboto&lt;/a&gt;フォントを入れた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://fonts.googleapis.com/css?family=Roboto:300,400,500&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;unstated-https-github-com-jamiebuilds-unstated&#34;&gt;&lt;a href=&#34;https://github.com/jamiebuilds/unstated&#34;&gt;Unstated&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;UnstatedはReact v16からの&lt;a href=&#34;https://reactjs.org/docs/context.html&#34;&gt;Context API&lt;/a&gt;を使ったStateを管理するための薄いライブラリ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save unstated
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stateを持つContainerを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class TodoContainer extends Container&amp;lt;TodoState&amp;gt; {
  state: TodoState = {
    newTodo: &amp;quot;&amp;quot;,
    todos: [],
    isCreating: false
  };

  changeNewTodo(newTodo: string) {
    this.setState({ newTodo: newTodo });
  }

  async createTodo() {
    if (!this.canCreateTodo()) {
      return
    }
    this.setState({ isCreating: true });
    const newTodo = { title: this.state.newTodo, isDone: false }
    await axios.post&amp;lt;Todo[]&amp;gt;(&amp;quot;http://localhost:3001/todo&amp;quot;, newTodo)
    await this.loadTodo()
    this.setState({ newTodo: &amp;quot;&amp;quot;, isCreating: false })
  }

  canCreateTodo() {
    return this.state.newTodo.length !== 0 &amp;amp;&amp;amp; !this.state.isCreating
  }

  async setIsDone(id: number, status: boolean) {
    const target = this.state.todos.find((t) =&amp;gt; t.id === id)
    if (target) {
      target.isDone = status
      await axios.put&amp;lt;Todo[]&amp;gt;(`http://localhost:3001/todo/${id}`, target)
      await this.loadTodo()
    }
  }

  async deleteTodo(id: number) {
    await axios.delete(`http://localhost:3001/todo/${id}`)
    await this.loadTodo()
  }

  async loadTodo() {
    const resp = await axios.get&amp;lt;Todo[]&amp;gt;(&amp;quot;http://localhost:3001/todo&amp;quot;)
    this.setState({ todos: resp.data })
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;Provider&amp;gt;&lt;/code&gt;の中で&lt;code&gt;&amp;lt;Subscript to={[Container]}&amp;gt;&lt;/code&gt;するとContainerが渡ってくるので、
このstateにアクセスしたりメソッドを呼んでstateを更新でき、変更があったら再レンダリングされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Provider&amp;gt;
    ...
    &amp;lt;div className=&amp;quot;App&amp;quot;&amp;gt;
        &amp;lt;div className=&amp;quot;Form&amp;quot;&amp;gt;&amp;lt;TodoForm&amp;gt;&amp;lt;/TodoForm&amp;gt;&amp;lt;/div&amp;gt;
        &amp;lt;div className=&amp;quot;Chart&amp;quot;&amp;gt;&amp;lt;DoneChart&amp;gt;&amp;lt;/DoneChart&amp;gt;&amp;lt;/div&amp;gt;
        &amp;lt;TodoList&amp;gt;&amp;lt;/TodoList&amp;gt;
    &amp;lt;/div&amp;gt;
&amp;lt;/Provider&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# &amp;lt;DoneChart&amp;gt;
&amp;lt;Subscribe to={[TodoContainer]}&amp;gt;
    {(container: TodoContainer) =&amp;gt;
        &amp;lt;PieChart width={200} height={200}&amp;gt;
            &amp;lt;Pie data={this.data(container).data} dataKey=&amp;quot;value&amp;quot; innerRadius={60} outerRadius={80}&amp;gt;
                {
                    this.data(container).data.map(d =&amp;gt; &amp;lt;Cell fill={d.color} /&amp;gt;)
                }
            &amp;lt;/Pie&amp;gt;
            &amp;lt;text x={100} y={105} textAnchor=&amp;quot;middle&amp;quot;&amp;gt;{this.data(container).ratio}&amp;lt;/text&amp;gt;
        &amp;lt;/PieChart&amp;gt;
    }
&amp;lt;/Subscribe&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;recharts-http-recharts-org-en-us&#34;&gt;&lt;a href=&#34;http://recharts.org/en-US/&#34;&gt;Recharts&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Rechartsでグラフを描いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save recharts @types/recharts
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;PieChart width={200} height={200}&amp;gt;
    &amp;lt;Pie data={this.data(container).data} dataKey=&amp;quot;value&amp;quot; innerRadius={60} outerRadius={80}&amp;gt;
        {
            this.data(container).data.map(d =&amp;gt; &amp;lt;Cell fill={d.color} /&amp;gt;)
        }
    &amp;lt;/Pie&amp;gt;
    &amp;lt;text x={100} y={105} textAnchor=&amp;quot;middle&amp;quot;&amp;gt;{this.data(container).ratio}&amp;lt;/text&amp;gt;
&amp;lt;/PieChart&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HI-VAE(Heterogeneous-Incomple VAE)の論文を読んで処理を追う</title>
          <link>https://www.sambaiz.net/article/214/</link>
          <pubDate>Fri, 22 Mar 2019 20:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/214/</guid>
          <description>

&lt;p&gt;HI-VAE(Heterogeneous-Incomple VAE)は現実のデータセットにありがちな連続値と離散値が混ざっていたり欠損値を含んでいるものを扱えるようにしたVAE。&lt;/p&gt;

&lt;p&gt;論文: &lt;a href=&#34;https://arxiv.org/abs/1807.03653&#34;&gt;Alfredo Nazabal, Pablo M. Olmos, Zoubin Ghahramani, Isabel Valera (2018) Handling Incomplete Heterogeneous Data using VAEs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/201/&#34;&gt;生成モデルVAE(Variational Autoencoder) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubにTensorFlow実装が&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE&#34;&gt;上がっている&lt;/a&gt;ので論文と合わせて追ってみる。&lt;/p&gt;

&lt;h2 id=&#34;入力データ&#34;&gt;入力データ&lt;/h2&gt;

&lt;p&gt;入力データ&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/defaultCredit/data.csv&#34;&gt;data.csv&lt;/a&gt;と、そのスキーマ&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/defaultCredit/data_types.csv&#34;&gt;data_types.csv&lt;/a&gt;が用意されていて、
様々なtypeのデータが含まれる24次元のデータセットであることが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type,dim,nclass
pos,1,
cat,3,3
cat,7,7
cat,4,4
count,1,
ordinal,11,11
ordinal,11,11
ordinal,11,11
ordinal,11,11
ordinal,11,11
ordinal,11,11
real,1,
real,1,
real,1,
real,1,
real,1,
real,1,
pos,1,
pos,1,
pos,1,
pos,1,
pos,1,
pos,1,
cat,2,2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これに対して、xx%の確率でランダムな次元を欠損値として扱う際に対象とする行と次元を表す
&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/defaultCredit/Missing30_1.csv&#34;&gt;Missingxx_y.csv&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2,1
3,1
...
29985,24
29998,24
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;typeごとのデータの扱い&#34;&gt;typeごとのデータの扱い&lt;/h2&gt;

&lt;h3 id=&#34;real-実数値&#34;&gt;real(実数値)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-real.png&#34; alt=&#34;type=realのdecoder分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L55&#34;&gt;標準化して&lt;/a&gt;encoderに入力し、decoderでは正規分布の平均と分散を
&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L243&#34;&gt;出力し&lt;/a&gt;
サンプリングしてデータを&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/master/loglik_models_missing_normalize.py#L47&#34;&gt;生成する&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;pos-正の実数&#34;&gt;pos(正の実数)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-pos.png&#34; alt=&#34;type=posのdecoder分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L61&#34;&gt;対数を標準化して&lt;/a&gt;encoderに入力し、decoderでは正規分布の平均と分散を
&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L227&#34;&gt;出力し&lt;/a&gt;
サンプリングしたデータを&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/master/loglik_models_missing_normalize.py#L80&#34;&gt;exp()で元のレンジに戻す&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;count&#34;&gt;count&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-count.png&#34; alt=&#34;type=countのdecoder分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L71&#34;&gt;対数を取って&lt;/a&gt;encoderに入力し、decoderではポアソン分布の平均λを
&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L236&#34;&gt;出力し&lt;/a&gt;
サンプリングしてデータを&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/master/loglik_models_missing_normalize.py#L151&#34;&gt;生成する&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;cat-カテゴリ&#34;&gt;cat(カテゴリ)&lt;/h3&gt;

&lt;p&gt;読み込み時に&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/read_functions.py#L54&#34;&gt;one hotに変換&lt;/a&gt;し以後はそのまま扱う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat 2 -&amp;gt; [0. 0. 1. 0. 0. 0. 0.] # one hot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-cat.png&#34; alt=&#34;type=catのdecoder分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;decoderでは各カテゴリのlogitの配列を&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L243&#34;&gt;出力し&lt;/a&gt;、
softmax()したカテゴリカル分布からサンプリングしてデータを&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/loglik_models_missing_normalize.py#L100&#34;&gt;生成する&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;ordinal-順序&#34;&gt;ordinal(順序)&lt;/h3&gt;

&lt;p&gt;読み込み時に&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/read_functions.py#L66&#34;&gt;thermometerに変換&lt;/a&gt;し以後はそのまま扱う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ordinal 4 -&amp;gt; [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] # thermometer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-ordinal.png&#34; alt=&#34;type=ordinalのdecoder分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;decoderでは各カテゴリの閾値Θと、znにおける値を&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L251&#34;&gt;出力し&lt;/a&gt;、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Θ_{n-1} &amp;lt; Θ_n&lt;/code&gt;になるように&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/loglik_models_missing_normalize.py#L117&#34;&gt;softplus()で正数にしたものを累積する&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/loglik_models_missing_normalize.py#L118&#34;&gt;Θと平均値の差をSigmoid関数に入れて&lt;/a&gt;その次元が1になる確率を求める&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/loglik_models_missing_normalize.py#L119&#34;&gt;一つ下の次元との差を取って&lt;/a&gt;znが各カテゴリに属する確率を求める&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;したカテゴリカル分布からサンプリングして&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/sequence_mask&#34;&gt;mask&lt;/a&gt;を
&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/loglik_models_missing_normalize.py#L130&#34;&gt;生成する&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;欠損値の扱い&#34;&gt;欠損値の扱い&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/main.py#L121&#34;&gt;欠損値は0にする&lt;/a&gt;ことでDropoutさせる。以後登場する添字^oは欠損していないデータを表し、x~nはxnの欠損値を0にしたものを表す。&lt;/p&gt;

&lt;h2 id=&#34;encoder-https-github-com-probabilistic-learning-hi-vae-blob-855b255d15451f80cf337cc648ff6acab5d86402-model-hivae-inputdropout-py-l17&#34;&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/model_HIVAE_inputDropout.py#L17&#34;&gt;encoder&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-encoder.png&#34; alt=&#34;encoder&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-ps-pzs.png&#34; alt=&#34;q(s)とq(z|s)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通常のVAEでは入力xのみから単純なガウス分布で潜在変数zを作っていたが、HI-VAEではまず
&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L95&#34;&gt;Gumbel-softmaxでノイズを入れて微分できるようにしたカテゴリカル分布sを作り&lt;/a&gt;
これとxを&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/VAE_functions.py#L102&#34;&gt;concat()して&lt;/a&gt;GMM(混合ガウスモデル)でzを作る。&lt;/p&gt;

&lt;h2 id=&#34;decoder-https-github-com-probabilistic-learning-hi-vae-blob-855b255d15451f80cf337cc648ff6acab5d86402-model-hivae-inputdropout-py-l32&#34;&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/model_HIVAE_inputDropout.py#L32&#34;&gt;decoder&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-decoder.png&#34; alt=&#34;decoder&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-gen.png&#34; alt=&#34;p(x,z,s)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;まずsからzの分布を&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/master/model_HIVAE_inputDropout.py#L37&#34;&gt;作っている&lt;/a&gt;が、これはELBOの計算のためで生成では使われない。&lt;/p&gt;

&lt;p&gt;encodeされたzからyを&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/model_HIVAE_inputDropout.py#L40&#34;&gt;作り&lt;/a&gt;、生成するデータごとのγに&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/model_HIVAE_inputDropout.py#L43&#34;&gt;分割して&lt;/a&gt;、これからtypeごとに対応する&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/model_HIVAE_inputDropout.py#L46&#34;&gt;パラメータ&lt;/a&gt;で分布を作りサンプリングして&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/855b255d15451f80cf337cc648ff6acab5d86402/model_HIVAE_inputDropout.py#L49&#34;&gt;生成する&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;cost-https-github-com-probabilistic-learning-hi-vae-blob-cebe6acda50b346a206257d9d5480fc8112178b4-model-hivae-inputdropout-py-l53&#34;&gt;&lt;a href=&#34;https://github.com/probabilistic-learning/HI-VAE/blob/cebe6acda50b346a206257d9d5480fc8112178b4/model_HIVAE_inputDropout.py#L53&#34;&gt;cost&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/214-elbo.png&#34; alt=&#34;ELBO&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ELBOは欠損値を除いた負の再生成誤差からsとzの正則化項を引いたものになる。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://musyoku.github.io/2016/11/12/Categorical-Reparameterization-with-Gumbel-Softmax/&#34;&gt;Categorical Reparameterization with Gumbel-Softmax [arXiv:1611.01144] – ご注文は機械学習ですか？&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>VAEでエンコードしたMNISTの潜在空間をt-SNEで可視化する</title>
          <link>https://www.sambaiz.net/article/213/</link>
          <pubDate>Sun, 10 Mar 2019 19:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/213/</guid>
          <description>

&lt;p&gt;t-SNEは多次元のデータを2,3次元上にマッピングして可視化できるようにする手法の一つで、
Stochastic Neighbor Embedding(SNE, 確率的近傍埋め込み)という手法をベースに、t分布を用いるなどして改良したもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf&#34;&gt;Visualizing Data using t-SNE&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;sne&#34;&gt;SNE&lt;/h2&gt;

&lt;p&gt;まず入力データ間の類似度をユークリッド距離を用いた次の条件付き確率p_{j|i}で表す。
これはx_iを中心とした正規分布上で、確率密度に基づいて隣り合うデータを選ぶ場合x_jが選ばれる確率となる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/213-p.png&#34; alt=&#34;入力データ間の類似度p_{j|i}&#34; /&gt;&lt;/p&gt;

&lt;p&gt;同様に出力データでも次の条件付き確率q_{j|i}を計算する。&lt;code&gt;σ=1/sqrt(2)&lt;/code&gt;とする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/213-q.png&#34; alt=&#34;出力データ間の類似度q_{j|i}&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この分布間のKL情報量を勾配降下法で最小化していくことで出力を最適化するのがSME。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/213-c.png&#34; alt=&#34;コスト&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/134/&#34;&gt;自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/191/&#34;&gt;ロジスティック回帰の尤度と交差エントロピーと勾配降下法 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;t-sne&#34;&gt;t-SNE&lt;/h2&gt;

&lt;p&gt;t-SNEでは条件付き確率ではなく同時確率を用いる。また、qを自由度1のt分布で表す。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/213-p2.png&#34; alt=&#34;p_ij&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/213-q2.png&#34; alt=&#34;q_ij&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/213-c2.png&#34; alt=&#34;コスト&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;mnistの潜在空間をt-sneで可視化した結果&#34;&gt;MNISTの潜在空間をt-SNEで可視化した結果&lt;/h2&gt;

&lt;p&gt;以前作ったVAEのMNISTモデルの潜在空間を
scikit-learnの&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html&#34;&gt;TSNE&lt;/a&gt;で可視化する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/212/&#34;&gt;PyTorchでVAEのモデルを実装してMNISTの画像を生成する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%matplotlib inline
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from random import random

colors = [&amp;quot;red&amp;quot;, &amp;quot;green&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;orange&amp;quot;, &amp;quot;purple&amp;quot;, &amp;quot;brown&amp;quot;, &amp;quot;fuchsia&amp;quot;, &amp;quot;grey&amp;quot;, &amp;quot;olive&amp;quot;, &amp;quot;lightblue&amp;quot;]
def visualize_zs(zs, labels):
  plt.figure(figsize=(10,10))
  points = TSNE(n_components=2, random_state=0).fit_transform(zs)
  for p, l in zip(points, labels):
    plt.scatter(p[0], p[1], marker=&amp;quot;${}$&amp;quot;.format(l), c=colors[l])
  plt.show()

model.eval()
zs = []
for x, t in dataloader_valid:
    x = x.to(device)
    t = t.to(device)
    # generate from x
    y, z = model(x)
    z = z.cpu()
    t = t.cpu()
    visualize_zs(z.detach().numpy(), t.cpu().detach().numpy())
    break
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同じ数字や似ている数字の潜在変数が近いところに配置されていて、潜在空間をうまく可視化できているように見える。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/213-z.png&#34; alt=&#34;MNISTの潜在空間をt-SNEで次元削減したもの&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PyTorchでVAEのモデルを実装してMNISTの画像を生成する</title>
          <link>https://www.sambaiz.net/article/212/</link>
          <pubDate>Thu, 07 Mar 2019 19:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/212/</guid>
          <description>

&lt;p&gt;PyTorchでVAEを実装しMNISTの画像を生成する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/201/&#34;&gt;生成モデルVAE(Variational Autoencoder) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;学習データ&#34;&gt;学習データ&lt;/h2&gt;

&lt;p&gt;datasetsのMNIST画像を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.ToTensor(), 
    transforms.Lambda(lambda x: x.view(-1))])

dataset_train = datasets.MNIST(
    &#39;~/mnist&#39;, 
    train=True, 
    download=True, 
    transform=transform)
dataset_valid = datasets.MNIST(
    &#39;~/mnist&#39;, 
    train=False, 
    download=True, 
    transform=transform)

dataloader_train = utils.data.DataLoader(dataset_train,
                                          batch_size=1000,
                                          shuffle=True,
                                          num_workers=4)
dataloader_valid = utils.data.DataLoader(dataset_valid,
                                          batch_size=1000,
                                          shuffle=True,
                                          num_workers=4)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;vae&#34;&gt;VAE&lt;/h2&gt;

&lt;p&gt;それぞれ3層のEncoderとDecoder。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import torch
import torch.nn as nn
import torch.nn.functional as F

device = &#39;cuda&#39;

class VAE(nn.Module):
    def __init__(self, z_dim):
      super(VAE, self).__init__()
      self.dense_enc1 = nn.Linear(28*28, 200)
      self.dense_enc2 = nn.Linear(200, 200)
      self.dense_encmean = nn.Linear(200, z_dim)
      self.dense_encvar = nn.Linear(200, z_dim)
      self.dense_dec1 = nn.Linear(z_dim, 200)
      self.dense_dec2 = nn.Linear(200, 200)
      self.dense_dec3 = nn.Linear(200, 28*28)
    
    def _encoder(self, x):
      x = F.relu(self.dense_enc1(x))
      x = F.relu(self.dense_enc2(x))
      mean = self.dense_encmean(x)
      var = F.softplus(self.dense_encvar(x))
      return mean, var
    
    def _sample_z(self, mean, var):
      epsilon = torch.randn(mean.shape).to(device)
      return mean + torch.sqrt(var) * epsilon
 
    def _decoder(self, z):
      x = F.relu(self.dense_dec1(z))
      x = F.relu(self.dense_dec2(x))
      x = F.sigmoid(self.dense_dec3(x))
      return x

    def forward(self, x):
      mean, var = self._encoder(x)
      z = self._sample_z(mean, var)
      x = self._decoder(z)
      return x, z
    
    def loss(self, x):
      mean, var = self._encoder(x)
      KL = -0.5 * torch.mean(torch.sum(1 + torch.log(var) - mean**2 - var))
      z = self._sample_z(mean, var)
      y = self._decoder(z)
      reconstruction = torch.mean(torch.sum(x * torch.log(y) + (1 - x) * torch.log(1 - y)))
      lower_bound = [-KL, reconstruction]                                      
      return -sum(lower_bound)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;学習&#34;&gt;学習&lt;/h2&gt;

&lt;p&gt;潜在変数zの次元は10で学習させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
from torch import optim

model = VAE(10).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
model.train()
for i in range(20):
  losses = []
  for x, t in dataloader_train:
      x = x.to(device)
      model.zero_grad()
      y = model(x)
      loss = model.loss(x)
      loss.backward()
      optimizer.step()
      losses.append(loss.cpu().detach().numpy())
  print(&amp;quot;EPOCH: {} loss: {}&amp;quot;.format(i, np.average(losses)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;生成&#34;&gt;生成&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

fig = plt.figure(figsize=(10, 3))

model.eval()
zs = []
for x, t in dataloader_valid:
    # original
    for i, im in enumerate(x.view(-1, 28, 28).detach().numpy()[:10]):
      ax = fig.add_subplot(3, 10, i+1, xticks=[], yticks=[])
      ax.imshow(im, &#39;gray&#39;)
    x = x.to(device)
    # generate from x
    y, z = model(x)
    zs.append(z)
    y = y.view(-1, 28, 28)
    for i, im in enumerate(y.cpu().detach().numpy()[:10]):
      ax = fig.add_subplot(3, 10, i+11, xticks=[], yticks=[])
      ax.imshow(im, &#39;gray&#39;)
    # generate from z
    z1to0 = torch.cat([z[1] * (i * 0.1) + z[0] * ((9 - i) * 0.1) for i in range(10)])
    y2 = model._decoder(z1to0).view(-1, 28, 28)
    for i, im in enumerate(y2.cpu().detach().numpy()):
      ax = fig.add_subplot(3, 10, i+21, xticks=[], yticks=[])
      ax.imshow(im, &#39;gray&#39;)
    break
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1行目が元データの画像で、それをエンコードした潜在変数から生成したのが2行目。
3行目は左から1番目(3)と2番目(6)の潜在変数を割合を変えなから足したものから生成したもので、
3と6の特徴を割合で持った画像を生成できている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/212.png&#34; alt=&#34;生成画像&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/213/&#34;&gt;VAEでエンコードしたMNISTの潜在空間をt-SNEで可視化する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SageMaker NotebookでGitリポジトリにSSHでpush/pullできるようにする</title>
          <link>https://www.sambaiz.net/article/211/</link>
          <pubDate>Mon, 04 Mar 2019 22:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/211/</guid>
          <description>&lt;p&gt;Sagemaker NotebookはAWSの機械学習のワークフローを提供する&lt;a href=&#34;https://aws.amazon.com/jp/sagemaker/&#34;&gt;SageMaker&lt;/a&gt;の一部である
マネージドなJupyter Notebooksで、可視化などはもちろん、ここから複数インタンスでの学習ジョブを実行したりすることができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/amazon-sagemaker-notebooks-now-support-git-integration-for-increased-persistence-collaboration-and-reproducibility/&#34;&gt;Git統合&lt;/a&gt;
によってノートブック作成時にGitHubなどのリポジトリを指定すると前もって持ってきてくれるようになったが、
今のところHTTPSエンドポイントにしか対応していないようで、ユーザー名・パスワードまたはトークンといった個人に紐づく認証情報が必要になる。
今回はこの機能を使わずに、ライフサイクル設定でssh鍵を置き、これでpush/pullできるようにする。&lt;/p&gt;

&lt;p&gt;パスフレーズなしの鍵を作って公開鍵を対象リポジトリのDeployKeyに登録してread/writeできるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir sagemaker-sshkey
$ cd sagemaker-sshkey
$ ssh-keygen -t rsa -b 4096 -f id_rsa -N &amp;quot;&amp;quot;
$ pbcopy &amp;lt; id_rsa.pub
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秘密鍵はSSMのParameter Storeに登録する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/204/&#34;&gt;AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws ssm put-parameter --name &amp;quot;sagemaker-sshkey&amp;quot; --value &amp;quot;`cat id_rsa`&amp;quot; --type String --overwrite
$ aws ssm get-parameters --names &amp;quot;sagemaker-sshkey&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ライフサイクル設定でノートブック開始時に次のスクリプトが実行されるようにする。
このスクリプトはrootで実行される。Parameter Storeが読める権限をNotebookのIAMに付けておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash

set -e

su - ec2-user &amp;lt;&amp;lt;EOF
cd /home/ec2-user
aws ssm get-parameters --names &amp;quot;sagemaker-sshkey&amp;quot; | jq -r &amp;quot;.Parameters[0].Value&amp;quot; &amp;gt; .ssh/id_rsa
echo -e &amp;quot;Host github.com\n\tStrictHostKeyChecking no&amp;quot; &amp;gt; .ssh/config
chmod 600 .ssh/*
git config --global user.name &amp;quot;Sagemaker&amp;quot;
cd SageMaker
if [ ! -e &amp;quot;sagemaker-pytorch-example&amp;quot; ]; then
  git clone git@github.com:sambaiz/sagemaker-pytorch-example.git
fi
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとはノートブック作成時にこのライフサイクル設定を選べば、最初からリポジトリがpullされ、左のGitタブからpush/pullできる状態で立ち上がる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/211-git.png&#34; alt=&#34;Git&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>生成モデルGAN(Generative Adversarial Network)</title>
          <link>https://www.sambaiz.net/article/210/</link>
          <pubDate>Fri, 22 Feb 2019 23:38:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/210/</guid>
          <description>

&lt;p&gt;GAN(Generative Adversarial Network)は生成器Gと、データが本物かどうか識別する識別器Dを交互に最適化していく生成モデル。
データの評価は識別器によって行われるので、VAEと異なり分布を仮定して尤度を用いる必要がなく、より良いデータが生成できるが、
GとDを交互に最適化した結果振動してしまいナッシュ均衡に収束せず、またどちらかが先に最適化されてしまうと
同じようなデータばかり生成してしまうmode collapseや勾配が消えてしまったりして
うまく学習できないことがある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/201/&#34;&gt;生成モデルVAE(Variational Autoencoder) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;識別器-discriminator&#34;&gt;識別器(Discriminator)&lt;/h2&gt;

&lt;p&gt;生成されたデータの分布をp&lt;em&gt;g(x)、真のデータの分布をp&lt;/em&gt;{data}(x)として、同数のデータにそれぞれy=0, 1のラベルを付ける。
識別器D(x)はyが0か1かの分類モデルで、負の交差エントロピー誤差V(D)を最大化するように学習する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/210.png&#34; alt=&#34;負の交差エントロピー誤差&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最適化したあとのDをD^&lt;em&gt;とすると、目的関数V(D^&lt;/em&gt;)はJensen-Shannon(JS)ダイバージェンスを使って表せる。これを最小化するのがGANの目的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/210-2.png&#34; alt=&#34;識別器の目的関数とJSダイバージェンス&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;生成器-generator&#34;&gt;生成器(Generator)&lt;/h2&gt;

&lt;p&gt;p_dataとp_gのJSダイバージェンスが小さくなるように学習する。生成器Gを学習するための目的関数は次の通りで、これを最小化する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/210-3.png&#34; alt=&#34;生成器の目的関数&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Chrome ExtensionsとChrome Apps</title>
          <link>https://www.sambaiz.net/article/209/</link>
          <pubDate>Tue, 19 Feb 2019 23:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/209/</guid>
          <description>

&lt;h2 id=&#34;chrome-extrnsions&#34;&gt;Chrome Extrnsions&lt;/h2&gt;

&lt;p&gt;ツールバーに表示され、ChromeのAPIを呼んで色々できる拡張機能で、manifestとhtml, js, cssなどから構成される。
開発中はディレクトリごとchrome://extensions/から読み込むとインストールでき、ツールバーにアイコンが表示される。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/test-chrome-extension&#34;&gt;test-chrome-extension&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;manifest-json-https-developer-chrome-com-extensions-manifest&#34;&gt;&lt;a href=&#34;https://developer.chrome.com/extensions/manifest&#34;&gt;manifest.json&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;manifest_version, name, versionと、brower_actionかpage_actionのどちらかはRequired。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;manifest_version&amp;quot;: 2,
    &amp;quot;name&amp;quot;: &amp;quot;test-chrome-extension&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;1.0&amp;quot;,
    &amp;quot;icons&amp;quot;: {
        &amp;quot;128&amp;quot;: &amp;quot;images/icon-128.png&amp;quot;
    },
    &amp;quot;page_action&amp;quot;: {
        &amp;quot;default_icon&amp;quot;: {
            &amp;quot;32&amp;quot;: &amp;quot;images/icon-32.png&amp;quot;
        }
    },
    &amp;quot;options_page&amp;quot;: &amp;quot;options.html&amp;quot;,
    &amp;quot;background&amp;quot;: {
        &amp;quot;scripts&amp;quot;: [
            &amp;quot;background.js&amp;quot;
        ],
        &amp;quot;persistent&amp;quot;: false
    },
    &amp;quot;permissions&amp;quot;: [
        &amp;quot;declarativeContent&amp;quot;,
        &amp;quot;storage&amp;quot;
    ],
    &amp;quot;content_security_policy&amp;quot;: &amp;quot;script-src &#39;self&#39;; object-src &#39;self&#39;&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.chrome.com/extensions/pageAction&#34;&gt;page_action&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;常にツールバーに表示されている&lt;a href=&#34;https://developer.chrome.com/extensions/browserAction&#34;&gt;browser_action&lt;/a&gt;に対して、限られたページでのみ有効なAction。
有効かどうかは
&lt;a href=&#34;https://developer.chrome.com/extensions/declarativeContent#event-onPageChanged&#34;&gt;declarativeContent.onPageChanged&lt;/a&gt;の
conditionsや、&lt;a href=&#34;https://developer.chrome.com/extensions/tabs#event-onUpdated&#34;&gt;tags.onUpdated&lt;/a&gt;のリスナー内で制御する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.chrome.com/extensions/options&#34;&gt;options_page&lt;/a&gt;: &amp;ldquo;拡張機能のオプション&amp;rdquo;で表示されるページ&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.chrome.com/extensions/background_pages&#34;&gt;background&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;インストール時や更新時など必要なときにロードされるスクリプト。イベントリスナーはここで設定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chrome.runtime.onInstalled.addListener(() =&amp;gt; {
    chrome.declarativeContent.onPageChanged.removeRules(undefined, () =&amp;gt; {
        chrome.declarativeContent.onPageChanged.addRules([
            {
                conditions: [
                    new chrome.declarativeContent.PageStateMatcher({
                        pageUrl: { hostEquals: &#39;www.google.com&#39;, schemes: [&#39;https&#39;] },
                    })
                ],
                actions: [new chrome.declarativeContent.ShowPageAction()]
            }
        ]);
    });
});

chrome.pageAction.onClicked.addListener((tab) =&amp;gt; {
    console.log(&amp;quot;Clicked&amp;quot;);
});

chrome.runtime.onSuspend.addListener(() =&amp;gt; {
    alert(&amp;quot;Unloading.&amp;quot;);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで出力したログはchrome://extensions/の&amp;rdquo;バックグラウンドページ&amp;rdquo;から確認でき、
&lt;a href=&#34;https://www.google.com&#34;&gt;https://www.google.com&lt;/a&gt;を開いてアイコンを押すと&amp;rdquo;Clicked&amp;rdquo;が出力される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/209.png&#34; alt=&#34;バックグラウンドページ&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.chrome.com/extensions/declare_permissions&#34;&gt;permissions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.chrome.com/extensions/storage&#34;&gt;storage&lt;/a&gt;などのAPIを使えるようにしたり、
HTML5の&lt;a href=&#34;https://w3c.github.io/geolocation-api/&#34;&gt;geolocation&lt;/a&gt;をユーザーの許可なしに使えるようにするといった権限。
permissonが足りないと次のようなエラーが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error in event handler: TypeError: Cannot read property &#39;onPageChanged&#39; of undefined
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.chrome.com/extensions/contentSecurityPolicy&#34;&gt;content_security_policy&lt;/a&gt;: 主にXSS対策のためのリソースのドメイン制限などの記述&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;chrome-apps&#34;&gt;Chrome Apps&lt;/h2&gt;

&lt;p&gt;Extensionと同じようなmanifestとhtml, js, cssなどで構成されるネイティブアプリ。
かつてはクロスプラットフォームで動かすことができたが、
Webアプリで事足りるようになったということで、Chrome OS以外でのサポートが&lt;a href=&#34;https://blog.chromium.org/2016/08/from-chrome-apps-to-web.html&#34;&gt;切られて&lt;/a&gt;しまった。
そのChromeOSでも&lt;a href=&#34;https://blog.google/products/chromebooks/the-google-play-store-coming-to/&#34;&gt;Android&lt;/a&gt;や&lt;a href=&#34;https://support.google.com/chromebook/answer/9145439&#34;&gt;Linux&lt;/a&gt;のアプリがサポートされつつあって、いつまでサポートされるかは分からない。&lt;/p&gt;

&lt;p&gt;ということでChrome OS以外ではストアから入れることはできないが、MacのChrome 72.0.3626.109時点では
Extensionと同様にchrome://extensions/から読み込むとChromeアプリとして認識された。&lt;/p&gt;

&lt;h3 id=&#34;manifest-json-https-developer-chrome-com-apps-manifest&#34;&gt;&lt;a href=&#34;https://developer.chrome.com/apps/manifest&#34;&gt;manifest.json&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Extensionのmanifestと比べると、backgroundがappの中に入りRequiredになっていたり、
socketsやbluetoothといったデバイスに関するものや、
&lt;a href=&#34;https://developer.chrome.com/apps/manifest/kiosk_enabled&#34;&gt;kioskモード&lt;/a&gt;の項目がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;test-app&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;1.0&amp;quot;,
  &amp;quot;icons&amp;quot;: {
    &amp;quot;128&amp;quot;: &amp;quot;images/icon-128.png&amp;quot;
  },
  &amp;quot;app&amp;quot;: {
    &amp;quot;background&amp;quot;: {
      &amp;quot;scripts&amp;quot;: [&amp;quot;background.js&amp;quot;]
    }
  },
  &amp;quot;bluetooth&amp;quot;: {
    &amp;quot;low_energy&amp;quot;: true,
    &amp;quot;uuids&amp;quot;: [&amp;quot;180a&amp;quot;]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;制約&#34;&gt;制約&lt;/h3&gt;

&lt;p&gt;Chrome Appsでは&lt;a href=&#34;https://developer.chrome.com/apps/app_architecture#security&#34;&gt;セキュリティモデル&lt;/a&gt;によって、
外部のコンテンツをiframeで埋め込んだり、インラインスクリプトやeval()を実行することが&lt;a href=&#34;https://developer.chrome.com/apps/app_external&#34;&gt;できない&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Refused to frame &#39;https://*****&#39; because it violates the following Content Security Policy directive: &amp;quot;frame-src &#39;self&#39; blob: filesystem: data: chrome-extension-resource:&amp;quot;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そのためiframeの代わりに&lt;a href=&#34;https://developer.chrome.com/apps/tags/webview&#34;&gt;webview&lt;/a&gt;を使う必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;webview id=&amp;quot;foo&amp;quot; src=&amp;quot;https://www.google.com/&amp;quot; style=&amp;quot;width:640px; height:480px&amp;quot;&amp;gt;&amp;lt;/webview&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webviewではプロセスが分離され、permissionもイベントリスナーで許可しないと付与されない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const webview = document.getElementById(&amp;quot;foo&amp;quot;);
webview.addEventListener(&#39;permissionrequest&#39;, function(e) {
  if (e.permission === &#39;media&#39;) {
    e.request.allow();
  }
});
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Apache SparkのRDD, DataFrame, DataSetとAction, Transformation</title>
          <link>https://www.sambaiz.net/article/208/</link>
          <pubDate>Wed, 13 Feb 2019 21:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/208/</guid>
          <description>

&lt;h2 id=&#34;sparkとは&#34;&gt;Sparkとは&lt;/h2&gt;

&lt;p&gt;ハイパフォーマンスな汎用分散処理システム。
HDFSやS3といった分散ストレージとHadoop YARNといったクラスタマネージャと共に使われる。
中間データをメモリに置いておくことでHadoopのMapReduceよりも高速に処理することができる。
APIはJava, Scala, Python, Rのものがあって、
Pythonは手軽に書ける一方、パフォーマンスはJVMとのやりとりが発生するため落ちる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/126/&#34;&gt;HDFS(Hadoop Distributed File System)とは - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;rddとdataframeとdataset&#34;&gt;RDDとDataFrameとDataSet&lt;/h2&gt;

&lt;p&gt;RDD(Resilient Distributed Dataset)はSpark Coreの低レベルな
&lt;a href=&#34;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala&#34;&gt;インタフェース&lt;/a&gt;で、
型を持つイミュータブルな分散コレクション。&lt;/p&gt;

&lt;p&gt;DataFrameはSpark SQLのテーブル状で型を持たないデータ形式で、
Tungstenというバイトレベルの最適化や
Catalystというクエリのオプティマイザが効くので自分でRDDのAPIを呼ぶよりパフォーマンスが良い。&lt;/p&gt;

&lt;p&gt;DataSetは型を持つDataFrameで、Spark 2.0からはDataFrameもDataset[Row]のエイリアスになった。&lt;/p&gt;

&lt;h2 id=&#34;actionとtransformation&#34;&gt;ActionとTransformation&lt;/h2&gt;

&lt;p&gt;外部への出力といった副作用を持つActionに対して
RDDを返すだけの処理をTransformationという。
Transformationは都度実行されるのではなく
Actionが実行される際に、依存関係を表すDAG(Directed Acyclic Graph)
をもとに必要なものが遅延評価される。DAGはWeb UIで可視化できる。
また、ネットワークやノードの障害によって計算結果が失われても依存関係をたどり、
並列に計算することで高速に復旧できるようになっている。&lt;/p&gt;

&lt;h2 id=&#34;narrow-dependencyとwide-dependency&#34;&gt;narrow dependencyとwide dependency&lt;/h2&gt;

&lt;p&gt;TransformationはRDDのパーティションに対して各Executorが並列に実行する。
mapやfilterなどの、見るパーティションが単一か他と被らない依存関係をnarrow dependencyといって、
そのExecutorだけで処理が完結するためパイプラインでまとめて実行でき速い。
一方、groupByKeyなどの一つのパーティションが複数のパーティションの処理で必要とされる依存関係をwide dependencyといって、
そのパーティションをExecutorが持っていない場合、コストが高いシャッフルが発生する。
シャッフルを必要としない一連の実行単位をstageという。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://shop.oreilly.com/product/0636920046967.do&#34;&gt;High Performance Spark - O&amp;rsquo;Reilly Media&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html&#34;&gt;RDD vs DataFrames and Datasets: A Tale of Three Apache Spark APIs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-DAGScheduler-Stage.html&#34;&gt;Stage — Physical Unit Of Execution · Mastering Apache Spark&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する</title>
          <link>https://www.sambaiz.net/article/207/</link>
          <pubDate>Sun, 10 Feb 2019 16:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/207/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/serverless-application-model/latest/developerguide/what-is-sam.html&#34;&gt;AWS SAM (Serverless Application Model)&lt;/a&gt;はAWS公式の
サーバーレスアプリケーションのビルドツール。
CloudFormationのテンプレートを設定ファイルに書くことでLambda関数と共にイベントトリガーや他のリソースも含めてデプロイでき、
その点で&lt;a href=&#34;https://serverless.com/&#34;&gt;Serverless Framework&lt;/a&gt;と立ち位置が近いが、向こうがLambda以外のサーバーレス環境にも対応していたり、
プラグインによって機能拡張できるようになっている一方、こちらは比較的薄いツールになっている。
ただ、&lt;a href=&#34;https://aws.amazon.com/jp/serverless/serverlessrepo/&#34;&gt;Serverless Application Repository&lt;/a&gt;で公開するにはSAMの形式にする必要があり、
Serverless FrameworkにもSAMのテンプレートを出力する&lt;a href=&#34;https://github.com/SAPessi/serverless-sam&#34;&gt;プラグイン&lt;/a&gt;がある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;sam-cliのインストール&#34;&gt;SAM CLIのインストール&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ brew tap aws/tap
$ brew install aws-sam-cli
$ sam --version
SAM CLI, version 0.11.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;init&#34;&gt;init&lt;/h2&gt;

&lt;p&gt;initすると次の構成のディレクトリが作られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sam init --runtime go1.x -n test-sam
$ cd test-sam/
$ ls
Makefile	README.md	hello-world	template.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;template.yaml&lt;/code&gt;の中に関数の設定やCloudFormationのテンプレートを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat template.yaml
AWSTemplateFormatVersion: &#39;2010-09-09&#39;
Transform: AWS::Serverless-2016-10-31
Description: &amp;gt;
    test-sam
    
    Sample SAM Template for test-sam

# More info about Globals: https://github.com/awslabs/serverless-application-model/blob/master/docs/globals.rst
Globals:
    Function:
    Timeout: 5

Resources:
    HelloWorldFunction:
    Type: AWS::Serverless::Function # More info about Function Resource: https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md#awsserverlessfunction
    Properties:
        CodeUri: hello-world/
        Handler: hello-world
        Runtime: go1.x
        Tracing: Active # https://docs.aws.amazon.com/lambda/latest/dg/lambda-x-ray.html
        Events:
        CatchAll:
            Type: Api # More info about API Event Source: https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md#api
            Properties:
            Path: /hello
            Method: GET
        Environment: # More info about Env Vars: https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md#environment-object
        Variables:
            PARAM1: VALUE

Outputs:
    HelloWorldAPI:
    Description: &amp;quot;API Gateway endpoint URL for Prod environment for First Function&amp;quot;
    Value: !Sub &amp;quot;https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/&amp;quot;

    HelloWorldFunction:
    Description: &amp;quot;First Lambda Function ARN&amp;quot;
    Value: !GetAtt HelloWorldFunction.Arn

    HelloWorldFunctionIamRole:
    Description: &amp;quot;Implicit IAM Role created for Hello World function&amp;quot;
    Value: !GetAtt HelloWorldFunctionRole.Arn
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ローカルで実行&#34;&gt;ローカルで実行&lt;/h2&gt;

&lt;p&gt;コンテナ内で実行される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ make build
$ sam local start-api
$ curl localhost:3000/hello
Fetching lambci/lambda:go1.x Docker container image.....
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;package&#34;&gt;package&lt;/h2&gt;

&lt;p&gt;アプリケーションをS3にアップロードし、そのURIを含むテンプレートを出力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sam package --output-template-file packaged.yaml --s3-bucket &amp;lt;bucket_name&amp;gt;
$ cat packaged.yaml 
AWSTemplateFormatVersion: &#39;2010-09-09&#39;
Description: &#39;test-sam

    Sample SAM Template for test-sam

    &#39;
Globals:
    Function:
    Timeout: 5
Outputs:
    HelloWorldAPI:
    Description: API Gateway endpoint URL for Prod environment for First Function
    Value:
        Fn::Sub: https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/
    HelloWorldFunction:
    Description: First Lambda Function ARN
    Value:
        Fn::GetAtt:
        - HelloWorldFunction
        - Arn
    HelloWorldFunctionIamRole:
    Description: Implicit IAM Role created for Hello World function
    Value:
        Fn::GetAtt:
        - HelloWorldFunctionRole
        - Arn
Resources:
    HelloWorldFunction:
    Properties:
        CodeUri: s3://&amp;lt;bucket_name&amp;gt;/c97948866b9a6fb535aeb5fa092a633d
        Environment:
        Variables:
            PARAM1: VALUE
        Events:
        CatchAll:
            Properties:
            Method: GET
            Path: /hello
            Type: Api
        Handler: hello-world
        Runtime: go1.x
        Tracing: Active
    Type: AWS::Serverless::Function
Transform: AWS::Serverless-2016-10-31
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deploy&#34;&gt;deploy&lt;/h2&gt;

&lt;p&gt;CloudFormationのStackを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sam deploy --template-file packaged.yaml --stack-name test-sam-app --capabilities CAPABILITY_IAM --region us-east-1
Successfully created/updated stack - test-sam-app

$ aws cloudformation describe-stacks --stack-name test-sam-app --query &#39;Stacks[].Outputs&#39;
[
    [
        {
            &amp;quot;Description&amp;quot;: &amp;quot;Implicit IAM Role created for Hello World function&amp;quot;, 
            &amp;quot;OutputKey&amp;quot;: &amp;quot;HelloWorldFunctionIamRole&amp;quot;, 
            &amp;quot;OutputValue&amp;quot;: &amp;quot;arn:aws:iam::*****:role/test-sam-app-HelloWorldFunctionRole-1TEAXP5ELXA9V&amp;quot;
        }, 
        {
            &amp;quot;Description&amp;quot;: &amp;quot;API Gateway endpoint URL for Prod environment for First Function&amp;quot;, 
            &amp;quot;OutputKey&amp;quot;: &amp;quot;HelloWorldAPI&amp;quot;, 
            &amp;quot;OutputValue&amp;quot;: &amp;quot;https://gr67rdb1qj.execute-api.us-east-1.amazonaws.com/Prod/hello/&amp;quot;
        }, 
        {
            &amp;quot;Description&amp;quot;: &amp;quot;First Lambda Function ARN&amp;quot;, 
            &amp;quot;OutputKey&amp;quot;: &amp;quot;HelloWorldFunction&amp;quot;, 
            &amp;quot;OutputValue&amp;quot;: &amp;quot;arn:aws:lambda:us-east-1:*****:function:test-sam-app-HelloWorldFunction-1QOX2RNRJ7G4L&amp;quot;
        }
    ]
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ aws cloudformation delete-stack --stack-name test-sam-app
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;serverless-application-repositoryに公開-https-docs-aws-amazon-com-serverlessrepo-latest-devguide-serverless-app-publishing-applications-html&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/serverlessrepo/latest/devguide/serverless-app-publishing-applications.html&#34;&gt;Serverless Application Repositoryに公開&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;template.yaml&lt;/code&gt;にServerless Application Repository用のMetadataを追加して再packageする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Metadata:
  AWS::ServerlessRepo::Application:
    Name: test-sam
    Description: hello world
    Author: test
    SpdxLicenseId: Apache-2.0
    LicenseUrl: s3://&amp;lt;bucket-name&amp;gt;/LICENSE.txt
    ReadmeUrl: s3://&amp;lt;bucket-name&amp;gt;/README.md
    Labels: [&#39;tests&#39;]
    HomePageUrl: https://github.com/test/test
    SemanticVersion: 0.0.1
    SourceCodeUrl: https://github.com/test/test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最初、LicenseUrlとReadmeUrlを単にLICENSE.txt、README.mdとしたところ、次のエラーがでてpublishできなかった。
一見packageに失敗しているように見えて原因が分からず困ったが、&lt;code&gt;--debug&lt;/code&gt;を付けて実行するとどこで失敗しているかが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: Your SAM template contains invalid S3 URIs. Please make sure that you have uploaded application artifacts to S3 by packaging the template: &#39;sam package --template-file &amp;lt;file-path&amp;gt;&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;バケットポリシーに次のStatementを追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
    &amp;quot;Statement&amp;quot;: [
        {
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Principal&amp;quot;: {
                &amp;quot;Service&amp;quot;:  &amp;quot;serverlessrepo.amazonaws.com&amp;quot;
            },
            &amp;quot;Action&amp;quot;: &amp;quot;s3:GetObject&amp;quot;,
            &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:s3:::&amp;lt;your-bucket-name&amp;gt;/*&amp;quot;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ sam publish -t packaged.yaml
Publish Succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトではprivateになっていて、AWSアカウントを指定して限定公開することもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/207.png&#34; alt=&#34;private application&#34; /&gt;&lt;/p&gt;

&lt;p&gt;デプロイボタンを押すとStackが作成されデプロイされる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う</title>
          <link>https://www.sambaiz.net/article/206/</link>
          <pubDate>Sun, 03 Feb 2019 17:31:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/206/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/rds/aurora/serverless/&#34;&gt;Aurora Serverless&lt;/a&gt;はオートスケールするAuroraで、
使ったAurora Capacity Unit (ACU)によって&lt;a href=&#34;https://aws.amazon.com/jp/rds/aurora/pricing/&#34;&gt;料金&lt;/a&gt;が発生するため、
使用頻度が少なかったり変動するアプリケーションにおいて安くRDBを使うことができる。
インスタンスを立てると最低でも月3000円くらいかかるが、Serverlessだとほとんどストレージ分から運用することができて趣味でも使いやすい。
ただしLambdaと同様に常に同等のリソースを使っている状態だとインスタンスと比べて割高になる。&lt;/p&gt;

&lt;p&gt;今回はLambdaで使う。
Serverlessと名前には付いているが用途としてはLambdaに限らず、
むしろコンテナの数が容易に増え得るLambdaは同時接続数が問題になるRDBと一般に相性が良くない。
現在Betaの、コネクションを張らずにHTTPSでクエリを投げられる&lt;a href=&#34;https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html&#34;&gt;Data API&lt;/a&gt;はこの問題を解消すると思われるが、トランザクションが張れなかったり、レスポンスサイズに制限があるようだ。今回はコンソール上から初期クエリを流すためにData APIを有効にしている。&lt;/p&gt;

&lt;p&gt;他の選択肢として、DynamoDBは現状最有力で最近&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/new-amazon-dynamodb-transactions/&#34;&gt;トランザクションもサポート&lt;/a&gt;されたがSQLのように複雑なクエリは投げられない。
Athenaはクエリは投げられるがそこそこ時間がかかるし、INSERT/UPDATEはできずクエリごとに料金が発生する。&lt;/p&gt;

&lt;p&gt;Serverless Frameworkを使ってリソースを作成しデプロイする。リポジトリは&lt;a href=&#34;https://github.com/sambaiz/aurora-serverless-test&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;vpcの作成&#34;&gt;VPCの作成&lt;/h2&gt;

&lt;p&gt;Aurora Serverlessの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/aurora-serverless.html#aurora-serverless.limitations&#34;&gt;制限&lt;/a&gt;の一つとしてVPC内からしか接続しかできないというものがある。ということでVPCから作成していく。以前Terraformで作ったのと同じリソースをCloudFormationで作る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/121/&#34;&gt;TerraformでVPCを管理するmoduleを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/vpc.html&#34;&gt;LambdaをVPC内で動かす&lt;/a&gt;とコンテナ起動時に&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/using-eni.html&#34;&gt;ENI&lt;/a&gt;も作成するため立ち上がりの際時間がかかる。必要なら定期的に呼び出して削除されないようにする。
また、今回はテストのため&lt;code&gt;/24&lt;/code&gt;でVPCを切っているが、小さいとENIのIPアドレスが枯渇する可能性がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc.html&#34;&gt;VPC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;TestVPC:
  Type: AWS::EC2::VPC
  Properties:
    CidrBlock: 172.32.0.0/24
    Tags:
      - Key: Name
        Value: test-vpc
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnet.html&#34;&gt;Subnet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Aurora Serverlessのために少なくとも2つのサブネットが必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TestPublicSubnet:
  Type: AWS::EC2::Subnet
  Properties:
    VpcId: !Ref TestVPC
    CidrBlock: 172.32.0.0/25
    AvailabilityZone: us-east-1d
    Tags:
      - Key: Name
        Value: test-public-subnet1
TestPrivateSubnet1:
  Type: AWS::EC2::Subnet
  Properties:
    VpcId: !Ref TestVPC
    CidrBlock: 172.32.0.128/26
    AvailabilityZone: us-east-1a
    Tags:
      - Key: Name
        Value: test-private-subnet1
TestPrivateSubnet2:
  Type: AWS::EC2::Subnet
  Properties:
    VpcId: !Ref TestVPC
    CidrBlock: 172.32.0.192/26
    AvailabilityZone: us-east-1b
    Tags:
      - Key: Name
        Value: test-private-subnet2
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-internetgateway.html&#34;&gt;InternetGateway&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;TestInternetGateway:
  Type: AWS::EC2::InternetGateway
  Properties:
    Tags:
      - Key: Name
        Value: test-igw
VPCGatewayAttachment:
  Type: AWS::EC2::VPCGatewayAttachment
  Properties:
    VpcId: !Ref TestVPC
    InternetGatewayId: !Ref TestInternetGateway
TestPublicRouteTable:
  Type: AWS::EC2::RouteTable
  Properties:
    VpcId: !Ref TestVPC
    Tags:
      - Key: Name
        Value: test-public-route-table
TestPublicRoute:
  Type: AWS::EC2::Route
  Properties:
    RouteTableId: !Ref TestPublicRouteTable
    DestinationCidrBlock: 0.0.0.0/0
    GatewayId: !Ref TestInternetGateway
TestPublicSubnetRouteTableAssociation:
  Type: AWS::EC2::SubnetRouteTableAssociation
  Properties:
    SubnetId: !Ref TestPublicSubnet
    RouteTableId: !Ref TestPublicRouteTable
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-natgateway.html&#34;&gt;NatGateway&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;TestEIP:
  Type: AWS::EC2::EIP
  Properties:
    Domain: vpc
TestNatGateway:
  Type: AWS::EC2::NatGateway
  Properties:
    AllocationId: !GetAtt TestEIP.AllocationId
    SubnetId: !Ref TestPublicSubnet
    Tags:
      - Key: Name
        Value: TestNatGateway
TestPrivateRouteTable:
  Type: AWS::EC2::RouteTable
  Properties:
    VpcId: !Ref TestVPC
    Tags:
      - Key: Name
        Value: test-private-route-table
TestPrivateRoute:
  Type: AWS::EC2::Route
  Properties:
    RouteTableId: !Ref TestPrivateRouteTable
    DestinationCidrBlock: 0.0.0.0/0
    NatGatewayId: !Ref TestNatGateway
TestPrivateSubnet1RouteTableAssociation:
  Type: AWS::EC2::SubnetRouteTableAssociation
  Properties:
    SubnetId: !Ref TestPrivateSubnet1
    RouteTableId: !Ref TestPrivateRouteTable
TestPrivateSubnet2RouteTableAssociation:
  Type: AWS::EC2::SubnetRouteTableAssociation
  Properties:
    SubnetId: !Ref TestPrivateSubnet2
    RouteTableId: !Ref TestPrivateRouteTable
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html&#34;&gt;SecurityGroup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;TestSecurityGroup:
  Type: AWS::EC2::SecurityGroup
  Properties:
    VpcId: !Ref TestVPC
    GroupName: test-sg
    GroupDescription: test security group
    Tags:
      - Key: Name
        Value: test-sg
TestSecurityGroupIngress:
  Type: AWS::EC2::SecurityGroupIngress
  Properties:
    GroupId: !Ref TestSecurityGroup
    SourceSecurityGroupId: !Ref TestSecurityGroup
    IpProtocol: -1
    FromPort: -1
    ToPort: -1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;aurora-serverlessの作成&#34;&gt;Aurora Serverlessの作成&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-secretsmanager-secret.html&#34;&gt;Secret&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbcluster.html&#34;&gt;DBCluster&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;認証情報はSecretsManagerに置いてパスワードも自動生成させる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/204/&#34;&gt;AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ACUが0の状態で確認しやすくするためSecondsUntilAutoPauseを最短の300にしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AuroraSecret:
  Type: AWS::SecretsManager::Secret
  Properties:
    GenerateSecretString:
      SecretStringTemplate: &#39;{&amp;quot;username&amp;quot;: &amp;quot;test&amp;quot;}&#39;
      GenerateStringKey: &#39;password&#39;
      PasswordLength: 16
      ExcludeCharacters: &#39;&amp;quot;@/\&#39;
 SecretRDSInstanceAttachment:
  Type: AWS::SecretsManager::SecretTargetAttachment
  Properties:
    SecretId: !Ref AuroraSecret
    TargetId: !Ref AuroraServerless
    TargetType: AWS::RDS::DBCluster
TestSubnetGroup:
  Type: &amp;quot;AWS::RDS::DBSubnetGroup&amp;quot;
  Properties: 
    DBSubnetGroupDescription: test subnet group
    SubnetIds:
      - !Ref TestPrivateSubnet1
      - !Ref TestPrivateSubnet2
    Tags:
      - Key: Name
        Value: test-subnet-group
AuroraServerless:
  Type: AWS::RDS::DBCluster
  Properties:
    Engine: aurora
    EngineMode: serverless
    DeletionProtection: true
    Port: 3306
    DatabaseName: test
    MasterUsername: !Join [&#39;&#39;, [&#39;{{resolve:secretsmanager:&#39;, !Ref AuroraSecret, &#39;:SecretString:username}}&#39; ]]
    MasterUserPassword: !Join [&#39;&#39;, [&#39;{{resolve:secretsmanager:&#39;, !Ref AuroraSecret, &#39;:SecretString:password}}&#39; ]]
    DBSubnetGroupName: !Ref TestSubnetGroup
    VpcSecurityGroupIds:
      - !Ref TestSecurityGroup
    ScalingConfiguration:
      AutoPause: true
      MaxCapacity: 2
      SecondsUntilAutoPause: 300
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;環境変数とVPCまわりの設定はこんな感じ。
ServerlessFrameworkではデプロイ時にSecretを解決することもできるが、ローテーションすることも考えて実行時に取りに行っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;environment:
  TZ: Asia/Tokyo
  DB_SECRET: !Ref AuroraSecret
vpc:
  securityGroupIds:
    - !Ref TestSecurityGroup
  subnetIds:
    - !Ref TestPrivateSubnet1
    - !Ref TestPrivateSubnet2
iamRoleStatements:
  - Effect: &amp;quot;Allow&amp;quot;
    Action:
      - &amp;quot;ec2:CreateNetworkInterface&amp;quot;
      - &amp;quot;ec2:DescribeNetworkInterfaces&amp;quot;
      - &amp;quot;ec2:DeleteNetworkInterface&amp;quot;
    Resource:
      - &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;アプリケーション&#34;&gt;アプリケーション&lt;/h2&gt;

&lt;p&gt;Secretsにはusernameやpasswordだけではなくhostやport、dbNameまで含まれているのでこれだけで接続情報が作れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type dbConfig struct {
  Password string `json:&amp;quot;password&amp;quot;`
  DbName   string `json:&amp;quot;dbname&amp;quot;`
  Engine   string `json:&amp;quot;engine&amp;quot;`
  Port     int    `json:&amp;quot;port&amp;quot;`
  Host     string `json:&amp;quot;host&amp;quot;`
  UserName string `json:&amp;quot;username&amp;quot;`
}

func dbSrc() (string, error) {
  secret, err := secret.GetSecretString(os.Getenv(&amp;quot;DB_SECRET&amp;quot;))
  if err != nil {
    return &amp;quot;&amp;quot;, err
  }
  var config dbConfig
  if err := json.Unmarshal([]byte(secret), &amp;amp;config); err != nil {
    return &amp;quot;&amp;quot;, err
  }
  return fmt.Sprintf(
    &amp;quot;%s:%s@tcp(%s:%d)/%s?parseTime=true&amp;quot;,
    config.UserName,
    config.Password,
    config.Host,
    config.Port,
    config.DbName,
  ), nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;トランザクションを張ってINSERTしSELECTする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
tx, err := db.Begin()
if err != nil {
  return Response{StatusCode: http.StatusInternalServerError}, err
}

_, err = tx.Exec(&amp;quot;INSERT INTO b (a_id) VALUES (1)&amp;quot;)
if err != nil {
  tx.Rollback()
  return Response{StatusCode: http.StatusInternalServerError}, err
}

if err := tx.Commit(); err != nil {
  return Response{StatusCode: http.StatusInternalServerError}, err
}

rows, err := db.Query(&amp;quot;SELECT b.id FROM a JOIN b ON (a.id = b.a_id)&amp;quot;)
if err != nil {
  return Response{StatusCode: http.StatusInternalServerError}, err
}
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;初期クエリの実行&#34;&gt;初期クエリの実行&lt;/h2&gt;

&lt;p&gt;デプロイ後、DBの設定からData APIを有効にしてコンソールのQuery Editorから初期クエリを流す。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/206.png&#34; alt=&#34;Data APIを有効にする&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE a (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(128) NOT NULL
);

CREATE TABLE b (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    a_id BIGINT UNSIGNED NOT NULL,
    FOREIGN KEY (a_id) REFERENCES a (id)
);

INSERT INTO a (id, name) VALUES (1, &#39;1&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;レスポンスタイム&#34;&gt;レスポンスタイム&lt;/h2&gt;

&lt;p&gt;ENIなし、ACUが0の状態で呼んだところAPI Gatewayの上限30秒でタイムアウトしてしまった。
ENIがある状態でも25秒前後ほどかかって、いずれも立ち上がっている状態では800ms前後。
API Gatewayの後ろでAutoPauseなAurora Serverlessを使う場合は、時々レスポンスに時間がかかることを許容した上で、
タイムアウトしたときにクライアントでリトライさせるなりする必要がある。
Auroraへのアクセスはバッチで行い、API呼び出し時は別のデータソースを参照するといった使い方が良いかもしれない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PyTorchでMNISTする</title>
          <link>https://www.sambaiz.net/article/205/</link>
          <pubDate>Sat, 19 Jan 2019 23:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/205/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;はFacebookによるOSSの機械学習フレームワーク。
TensorFlow(v1)よりも簡単に使うことができる。
TensorFlow 2.0ではPyTorchのようにDefine-by-runなeager executionがデフォルトになるのに加え、パッケージも整理されるようなのでいくらか近くなると思われる。&lt;/p&gt;

&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;

&lt;h3 id=&#34;インストール&#34;&gt;インストール&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/&#34;&gt;Colab&lt;/a&gt;で動かす。まずpipで&lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;インストール&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;!pip install torch torchvision
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;autograd-https-pytorch-org-tutorials-beginner-blitz-autograd-tutorial-html-自動微分&#34;&gt;&lt;a href=&#34;https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html&#34;&gt;autograd&lt;/a&gt;(自動微分)&lt;/h3&gt;

&lt;p&gt;Tensorは自身が作成された関数の参照&lt;code&gt;.grad_fn&lt;/code&gt;を持ち、backward()が呼ばれるとbackpropして&lt;code&gt;requires_grad=True&lt;/code&gt;なTensorの勾配を自動で計算し&lt;code&gt;.grad&lt;/code&gt;に入れてくれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/192/&#34;&gt;MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import torch
x = torch.randn(4, 4)
y = torch.randn(4, 1)
w = torch.randn(4, 1, requires_grad=True)
b = torch.randn(1, requires_grad=True)
y_pred = torch.matmul(x, w) + b
loss = (y_pred - y).pow(2).sum()

print(x.grad, w.grad) # None None 
loss.backward()
print(x.grad, w.grad) # None tensor([...])

with torch.no_grad():
    y_eval = torch.matmul(x, w) + b
print(y_eval.requires_grad) # False
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;module&#34;&gt;Module&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://pytorch.org/docs/stable/nn.html&#34;&gt;nn&lt;/a&gt;パッケージにLinearやConv2dといった&lt;a href=&#34;https://pytorch.org/docs/stable/nn.html#torch.nn.Module&#34;&gt;Module&lt;/a&gt;が実装されていて、次のように呼び出すとforward()が
&lt;a href=&#34;https://github.com/pytorch/pytorch/blob/v1.0.0/torch/nn/modules/module.py#L489&#34;&gt;呼ばれ&lt;/a&gt;順伝播する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model = nn.Sequential(
    nn.Conv2d(1,20,5),
    nn.ReLU(),
    nn.Conv2d(20,64,5),
    nn.ReLU()
)
y = model(x)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;nn.Moduleを継承すれば自分でModuleを作ることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
       x = F.relu(self.conv1(x))
       return F.relu(self.conv2(x))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;train()とeval()で学習/推論のモードが切り替わり
&lt;a href=&#34;https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout&#34;&gt;Dropout&lt;/a&gt;などの挙動に影響する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model.train() 
model.eval()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;optimizer&#34;&gt;Optimizer&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://pytorch.org/docs/stable/optim.html&#34;&gt;optim&lt;/a&gt;パッケージにOptimizerが実装されていて、step()で勾配をもとにパラメータが更新される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)
for input, target in dataset:
    optimizer.zero_grad()
    output = model(input)
    loss = loss_fn(output, target)
    loss.backward()
    optimizer.step()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;save-load-https-pytorch-org-tutorials-beginner-saving-loading-models-html&#34;&gt;&lt;a href=&#34;https://pytorch.org/tutorials/beginner/saving_loading_models.html&#34;&gt;Save/Load&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;学習したモデルのパラメータをSave/Loadする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;torch.save(model.state_dict(), PATH)
model.load_state_dict(torch.load(PATH))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;torchvision-https-pytorch-org-docs-stable-torchvision-index-html&#34;&gt;&lt;a href=&#34;https://pytorch.org/docs/stable/torchvision/index.html&#34;&gt;torchvision&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset&#34;&gt;Dataset&lt;/a&gt;やモデルが含まれるパッケージ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import torchvision
dataset_train = torchvision.datasets.MNIST(&#39;~/mnist&#39;, train=True, download=True)
!ls ~/mnist/processed # =&amp;gt; test.pt  training.pt

%matplotlib inline
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
plt.imshow(np.asarray(dataset_train[0][0]))
print(dataset_train[0][1]) # tensor(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/205.png&#34; alt=&#34;MNIST Datasetの内容&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Datasetを&lt;a href=&#34;https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader&#34;&gt;DataLoader&lt;/a&gt;
に渡してやるとシャッフルなどしてイテレーションしてくれるが、MNISTのデータはPIL Imageで入っているのでそのまま渡すと
&lt;code&gt;TypeError: batch must contain tensors, numbers, dicts or lists; found &amp;lt;class &#39;PIL.Image.Image&#39;&amp;gt;&lt;/code&gt;のエラーになる。
そこで&lt;a href=&#34;https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor&#34;&gt;transforms.ToTesnor()&lt;/a&gt;でTensorに変換してやる必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import torch
import torchvision
dataset_train = torchvision.datasets.MNIST(&#39;~/mnist&#39;, train=True, download=True, transform=torchvision.transforms.ToTensor())
dataloader_train = torch.utils.data.DataLoader(dataset_train,
                                          batch_size=4,
                                          shuffle=True,
                                          num_workers=0)
for x, t in dataloader_train:
    print(x.shape, t.shape) # torch.Size([4, 1, 28, 28]) torch.Size([4])
    break
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;gpuを使う&#34;&gt;GPUを使う&lt;/h3&gt;

&lt;p&gt;GPUで計算させるには&lt;a href=&#34;https://pytorch.org/docs/stable/tensors.html#torch.Tensor.to&#34;&gt;to()&lt;/a&gt;でdeviceを明示する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;device = torch.device(&amp;quot;cuda&amp;quot; if torch.cuda.is_available() else &amp;quot;cpu&amp;quot;)
model.to(device)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mnistのモデル作成&#34;&gt;MNISTのモデル作成&lt;/h2&gt;

&lt;p&gt;MNISTのモデルを作りtorchvisionのDatasetで学習させてみる。&lt;/p&gt;

&lt;h3 id=&#34;dataset&#34;&gt;Dataset&lt;/h3&gt;

&lt;p&gt;まずDatasetを準備する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from torchvision import datasets, transforms, models
from torch import nn, optim, utils, device as device_, cuda
import torch.nn.functional as F
import numpy as np
from sklearn import metrics

dataset_train = datasets.MNIST(
    &#39;~/mnist&#39;, 
    train=True, 
    download=True, 
    transform=transforms.ToTensor())
dataset_valid = datasets.MNIST(
    &#39;~/mnist&#39;, 
    train=False, 
    download=True, 
    transform=transforms.ToTensor())

dataloader_train = utils.data.DataLoader(dataset_train,
                                          batch_size=1000,
                                          shuffle=True,
                                          num_workers=4)
dataloader_valid = utils.data.DataLoader(dataset_valid,
                                          batch_size=1000,
                                          shuffle=True,
                                          num_workers=4)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;モデル&#34;&gt;モデル&lt;/h3&gt;

&lt;p&gt;モデルとOptimizer、損失関数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lr = 0.01

device = device_(&amp;quot;cuda&amp;quot; if cuda.is_available() else &amp;quot;cpu&amp;quot;)

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, 5) # -&amp;gt; 24x24
        self.pool1 = nn.MaxPool2d(2) # -&amp;gt; 12x12
        self.conv2 = nn.Conv2d(64, 128, 5) # -&amp;gt; 8x8
        self.dropout = nn.Dropout(p=0.4)
        self.dense = nn.Linear(128 * 8 * 8, 10)

    def forward(self, x):
       x = F.relu(self.conv1(x))
       x = self.pool1(x)
       x = F.relu(self.conv2(x))
       x = self.dropout(x)
       x = x.view(x.size(0), -1) # Flatten
       return F.relu(self.dense(x))
    
model = Model().to(device)
optimizer = optim.SGD(model.parameters(), lr=lr)
criterion = nn.CrossEntropyLoss()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;学習&#34;&gt;学習&lt;/h3&gt;

&lt;p&gt;trainモードにして学習していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model.train()
for i in range(20):
  print(i)
  for x, t in dataloader_train:
      x = x.to(device)
      t = t.to(device)
      model.zero_grad()
      y = model(x)
      loss = criterion(y, t)
      loss.backward()
      optimizer.step()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;評価&#34;&gt;評価&lt;/h3&gt;

&lt;p&gt;evalモードにしてテストする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model.eval()
labels = []
preds = []
losses = []
for x, t in dataloader_valid:
    x = x.to(device)
    t = t.to(device)
    labels.extend(t.tolist())
    y = model(x)
    loss = criterion(y, t)
    losses.append(loss.cpu().data)
    pred = y.argmax(1)
    preds.extend(pred.tolist())
print(&#39;Loss: {:.3f}, Accuracy: {:.3f}&#39;.format(
    np.mean(losses),
    metrics.accuracy_score(labels, preds, normalize=True)
))
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する</title>
          <link>https://www.sambaiz.net/article/204/</link>
          <pubDate>Mon, 07 Jan 2019 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/204/</guid>
          <description>

&lt;p&gt;DBのパスワードやAPIトークンといった認証情報をバージョン管理するコードや設定ファイル上に書くとOSS化など公開範囲を広げるときにやや困るし漏れるリスクが高まるのでなるべく避けたい。
そこでSSMのParameter Storeに値を置き、実行時やデプロイ時に参照する。&lt;/p&gt;

&lt;h2 id=&#34;ssmのparameter-storeとsecrets-manager&#34;&gt;SSMのParameter StoreとSecrets Manager&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/systems-manager/&#34;&gt;Systems Manager (SSM)&lt;/a&gt;はAWSのリソースを可視化したり操作を自動化したりするサービス群で、
設定を持つ&lt;a href=&#34;https://aws.amazon.com/jp/systems-manager/features/&#34;&gt;Parameter Store&lt;/a&gt;はその一つ。値は暗号化して持つこともできる。
&lt;a href=&#34;https://aws.amazon.com/jp/systems-manager/pricing/&#34;&gt;料金&lt;/a&gt;はかからない。&lt;/p&gt;

&lt;p&gt;SSMのParameter Storeと似たような別のAWSのサービスに
&lt;a href=&#34;https://aws.amazon.com/jp/secrets-manager/&#34;&gt;Secrets Manager&lt;/a&gt;というのがあって、RDSなどと連携してLambdaによって定期的に新しい値を生成しローテーションさせることができる。
ただし&lt;a href=&#34;https://aws.amazon.com/jp/secrets-manager/pricing/&#34;&gt;料金&lt;/a&gt;がシークレットの件数($0.4/月)とAPIコール($0.05/10000回)でかかる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/206/&#34;&gt;CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今はParamter StoreとSecrets Managerが&lt;a href=&#34;https://aws.amazon.com/jp/about-aws/whats-new/2018/07/aws-systems-manager-parameter-store-integrates-with-aws-secrets-manager-and-adds-parameter-version-labeling/&#34;&gt;統合されていて&lt;/a&gt;、Parameter StoreのAPIでどちらも参照できるようだ。
今回はローテーションしないので単純に料金がかからないParameter Storeの方に書き込むことにする。
ただし、Parameter Storeは現状一度に大量のリクエストが飛ぶような使い方をするとRate exceededに&lt;a href=&#34;https://forums.aws.amazon.com/thread.jspa?messageID=834134&amp;amp;tstart=0&#34;&gt;なってしまう&lt;/a&gt;問題がある。&lt;/p&gt;

&lt;h2 id=&#34;実行時の値取得&#34;&gt;実行時の値取得&lt;/h2&gt;

&lt;p&gt;実行時に値を取得するのはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;

	&amp;quot;github.com/aws/aws-sdk-go/aws&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws/awserr&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws/session&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/service/ssm&amp;quot;
)

type Parameter struct {
	ssm *ssm.SSM
}

func newParameter(sess *session.Session) *Parameter {
	return &amp;amp;Parameter{
		ssm: ssm.New(sess),
	}
}

func (s *Parameter) Get(name string, decrypt bool) (string, error) {
	param, err := s.ssm.GetParameter(&amp;amp;ssm.GetParameterInput{
		Name:           aws.String(name),
		WithDecryption: aws.Bool(decrypt),
	})
	if err != nil {
		return &amp;quot;&amp;quot;, err
	}
	var secret string
	if param.Parameter.Value != nil {
		secret = *param.Parameter.Value
	}
	return secret, nil
}

func main() {
	secret := newParameter(session.New())
	param, err := secret.Get(&amp;quot;test&amp;quot;, true)
	if err != nil {
		panic(err)
	}
	fmt.Println(param) // =&amp;gt; ok

	param, err = secret.Get(&amp;quot;notfound&amp;quot;, true)
	if err != nil {
		if awsErr, ok := err.(awserr.Error); ok {
			fmt.Println(awsErr.Code()) // =&amp;gt; ParameterNotFound
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ AWS_SDK_LOAD_CONFIG=1 AWS_PROFILE=**** go run main.go
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;serverless-framework&#34;&gt;Serverless Framework&lt;/h2&gt;

&lt;p&gt;Serverless Frameworkの設定ファイルserverless.ymlでもSSMを&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/variables/#reference-variables-using-the-ssm-parameter-store&#34;&gt;参照でき&lt;/a&gt;、デプロイ時に解決される。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider:
  name: aws
  ...
  environment:
    SECRET: ${ssm:test~true}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/tomoya_oka/items/a3dd44879eea0d1e3ef5&#34;&gt;AWSのParameter StoreとSecrets Manager、結局どちらを使えばいいのか？比較 - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する</title>
          <link>https://www.sambaiz.net/article/203/</link>
          <pubDate>Tue, 01 Jan 2019 17:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/203/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/glue/&#34;&gt;AWS Glue&lt;/a&gt;はマネージドなETL(Extract/Transform/Load)サービスで、&lt;a href=&#34;https://spark.apache.org/&#34;&gt;Spark&lt;/a&gt;を使ってS3などにあるデータを読み込み加工して変換出力したり、AthenaやRedshift Spectrumで参照できるデータカタログを提供する。
今回はS3のCSVを読み込んで加工し、列指向フォーマットParquetに変換しパーティションを切って出力、その後クローラを回してデータカタログにテーブルを作成してAthenaで参照できることを確認する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/glue/pricing/&#34;&gt;料金&lt;/a&gt;はジョブがDPU(4vCPU/16GBメモリ)時間あたり$0.44(最低2DPU/10分)かかる。
また、クローラも同様にDPUで課金される。結構高い。&lt;/p&gt;

&lt;p&gt;なお、Athenaの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/athena/latest/ug/ctas.html&#34;&gt;CTAS&lt;/a&gt;でもParquetを出力することができる。
出力先にファイルがないようにする必要があったり重いクエリは失敗することがあるが手軽で良い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import * as athena from &#39;athena-client&#39;
const clientConfig: athena.AthenaClientConfig = {
	bucketUri: &#39;s3://*****/*****&#39;
  skipFetchResult: true,
};
const awsConfig: athena.AwsConfig = {
	region: &#39;us-east-1&#39;,
};

const client = athena.createClient(clientConfig, awsConfig);

(async () =&amp;gt; {
	await client.execute(`
		CREATE TABLE *****
    WITH (
      format = &#39;PARQUET&#39;,
      external_location = &#39;s3://*****&#39;
    ) AS (
      SELECT ~~
    )
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;開発用エンドポイント&#34;&gt;開発用エンドポイント&lt;/h2&gt;

&lt;p&gt;ジョブの立ち上がりにやや時間がかかるため開発用エンドポイントを立ち上げておくとDPUが確保されて効率よく開発できる。
立ち上げている間のDPUの料金がかかる。つまりずっとジョブを実行し続けているようなもので結構高くつくので終わったら閉じるようにしたい。&lt;/p&gt;

&lt;p&gt;ローカルやEC2から自分で開発用エンドポイントにsshして&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/dev-endpoint-tutorial-local-notebook.html&#34;&gt;Notebookを立てる&lt;/a&gt;こともできるが、
コンソールから立ち上げたNotebookは最初からつながっていて鍵の登録も必要なくて楽。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh -i private-key-file-path -NTL 9007:169.254.76.1:9007 glue@dev-endpoint-public-dns
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NotebookのインスタンスのIAMロールを作成するとCloudwatch Logsまわりに加えてGlueのDevEndpointとAssetの取得権限が付与されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;Action&amp;quot;: [
    &amp;quot;s3:ListBucket&amp;quot;
  ],
  &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
  &amp;quot;Resource&amp;quot;: [
    &amp;quot;arn:aws:s3:::aws-glue-jes-prod-us-east-1-assets&amp;quot;
  ]
}
{
  &amp;quot;Action&amp;quot;: [
    &amp;quot;s3:GetObject&amp;quot;
  ],
  &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
  &amp;quot;Resource&amp;quot;: [
    &amp;quot;arn:aws:s3:::aws-glue-jes-prod-us-east-1-assets*&amp;quot;
  ]
}
{
  &amp;quot;Action&amp;quot;: [
    &amp;quot;glue:UpdateDevEndpoint&amp;quot;,
    &amp;quot;glue:GetDevEndpoint&amp;quot;,
    &amp;quot;glue:GetDevEndpoints&amp;quot;
  ],
  &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
  &amp;quot;Resource&amp;quot;: [
    &amp;quot;arn:aws:glue:us-east-1:*****:devEndpoint/test*&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たまに立ち上げに失敗したり次のようなエラーで実行できないことがあったが、立ち上げ直したらうまくいった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The code failed because of a fatal error:
	Error sending http request and maximum retry encountered..

Some things to try:
a) Make sure Spark has enough available resources for Jupyter to create a Spark context.
b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.
c) Restart the kernel.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;printデバッグが捗る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
print(output_df.toDF().collect()[0].asDict())
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ジョブのスクリプト&#34;&gt;ジョブのスクリプト&lt;/h2&gt;

&lt;p&gt;GlueはSpark標準のDataFrameを扱うこともできるが、独自にスキーマを柔軟に扱える&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html&#34;&gt;DynamicFrame&lt;/a&gt;というのをサポートしている。DataFrameとは相互に変換できるので、SQL文の実行などDataFrameにしかないAPIを使いたい場合は変換する。
ただ、Sparkの設定を&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html&#34;&gt;変えられない&lt;/a&gt;分、DynamicFrameがうまくやっているところもある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/208/&#34;&gt;Apache SparkのRDD, DataFrame, DataSetとAction, Transformation - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from pyspark.sql.utils import ParseException
data_frame = dynamc_frame.toDF()
data_frame.toDF().createOrReplaceTempView(&#39;t1&#39;)
try:
  data_frame2 = spark.sql(&#39;SELECT * FROM t1&#39;)
except ParseException as e:
    print(str(e).replace(&amp;quot;\\n&amp;quot;, &amp;quot;\n&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入力は為替データのCSV。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ less kawase1.csv
Date,USD,GBP,EUR,CAD,CHF,SEK,DKK,NOK,AUD,NZD
2002/4/1,133.15,189.79,116.12,83.48,79.28,12.87,15.63,15.08,71.14,58.8
...

$ less kawase2.csv
Date,ZAR,BHD,HKD,INR,PHP,SGD,THB,KWD,SAR,AED,MXN,TWD
2002/4/1,11.76,353.65,17.07,2.73,2.61,72.21,3.07,434.14,35.52,36.26,14.81,3.82
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;やることは次の通り。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame-reader.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-reader-from_options&#34;&gt;create_dynamic_frame.from_options()&lt;/a&gt;でS3のCSVを読んでDynamicFrameを生成&lt;/li&gt;
&lt;li&gt;Dateで&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-join&#34;&gt;join()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-apply_mapping&#34;&gt;apply_mapping()&lt;/a&gt;でフィールド名と型をマッピングする&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-map&#34;&gt;map()&lt;/a&gt;でDateをyear, month, dateの3フィールドに分割、各値をUSDとの比にする&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame-writer.html#aws-glue-api-crawler-pyspark-extensions-dynamic-frame-writer-from_options&#34;&gt;create_dynamic_frame.from_options()&lt;/a&gt;でパーティションをyearで&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-programming-etl-partitions.html#aws-glue-programming-etl-partitions-writing&#34;&gt;切って&lt;/a&gt;フォーマットはParquetで書き込む&lt;/li&gt;
&lt;li&gt;クローラの実行を開始する&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;transformation_ctxは後述するジョブのブックマークで使われる一意な識別子。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sys
import datetime
import boto3
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

args = getResolvedOptions(sys.argv, [&amp;quot;JOB_NAME&amp;quot;])

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args[&amp;quot;JOB_NAME&amp;quot;], args)


def split_date(rec):
    date = datetime.datetime.strptime(rec[&amp;quot;Date&amp;quot;], &amp;quot;%Y/%m/%d&amp;quot;)
    rec[&amp;quot;year&amp;quot;] = date.year
    rec[&amp;quot;month&amp;quot;] = date.month
    rec[&amp;quot;day&amp;quot;] = date.day
    return rec


def convert_ratio_usd(rec):
    ret = {}
    for field in rec:
        ret[field] = rec[field]
        if field not in [&amp;quot;year&amp;quot;, &amp;quot;month&amp;quot;, &amp;quot;day&amp;quot;]:
            ret[field] /= rec[&amp;quot;usd&amp;quot;]
    return ret


input_df = glueContext.create_dynamic_frame.from_options(
    transformation_ctx=&amp;quot;source&amp;quot;,
    connection_type=&amp;quot;s3&amp;quot;,
    connection_options={&amp;quot;paths&amp;quot;: [&amp;quot;s3://*****/kawase1.csv&amp;quot;]},
    format=&amp;quot;csv&amp;quot;,
    format_options={&amp;quot;withHeader&amp;quot;: True})
input_df2 = glueContext.create_dynamic_frame.from_options(
    transformation_ctx=&amp;quot;source&amp;quot;,
    connection_type=&amp;quot;s3&amp;quot;,
    connection_options={&amp;quot;paths&amp;quot;: [&amp;quot;s3://*****/kawase2.csv&amp;quot;]},
    format=&amp;quot;csv&amp;quot;,
    format_options={&amp;quot;withHeader&amp;quot;: True})

output_df = input_df.join(
    [&amp;quot;Date&amp;quot;], [&amp;quot;Date&amp;quot;], input_df2, transformation_ctx=&amp;quot;info&amp;quot;).map(
        split_date, transformation_ctx=&amp;quot;split_date&amp;quot;).apply_mapping(
            [(&amp;quot;year&amp;quot;, &amp;quot;smallint&amp;quot;, &amp;quot;year&amp;quot;, &amp;quot;smallint&amp;quot;),
             (&amp;quot;month&amp;quot;, &amp;quot;smallint&amp;quot;, &amp;quot;month&amp;quot;, &amp;quot;smallint&amp;quot;),
             (&amp;quot;day&amp;quot;, &amp;quot;smallint&amp;quot;, &amp;quot;day&amp;quot;, &amp;quot;smallint&amp;quot;),
             (&amp;quot;USD&amp;quot;, &amp;quot;string&amp;quot;, &amp;quot;usd&amp;quot;, &amp;quot;double&amp;quot;),
             (&amp;quot;EUR&amp;quot;, &amp;quot;string&amp;quot;, &amp;quot;eur&amp;quot;, &amp;quot;double&amp;quot;),
             (&amp;quot;AUD&amp;quot;, &amp;quot;string&amp;quot;, &amp;quot;aud&amp;quot;, &amp;quot;double&amp;quot;),
             (&amp;quot;ZAR&amp;quot;, &amp;quot;string&amp;quot;, &amp;quot;zar&amp;quot;, &amp;quot;double&amp;quot;)],
            transformation_ctx=&amp;quot;apply_mapping&amp;quot;).map(
                convert_ratio_usd, transformation_ctx=&amp;quot;convert_ratio_usd&amp;quot;)

glueContext.write_dynamic_frame.from_options(
    frame=output_df,
    connection_type=&amp;quot;s3&amp;quot;,
    connection_options={
        &amp;quot;path&amp;quot;: &amp;quot;s3://*****/target&amp;quot;,
        &amp;quot;partitionKeys&amp;quot;: [&amp;quot;year&amp;quot;],
        &amp;quot;compression&amp;quot;: &amp;quot;gzip&amp;quot;
    },
    format=&amp;quot;parquet&amp;quot;,
    transformation_ctx=&amp;quot;sink&amp;quot;)
job.commit()

glue_client = boto3.client(&#39;glue&#39;, region_name=&#39;us-east-1&#39;)
glue_client.start_crawler(Name=&#39;kawase&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Glueのロールで読める場所にアップロードする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws s3 cp main.py s3://aws-glue-scripts-*****/root/main.py
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ジョブとクローラの作成&#34;&gt;ジョブとクローラの作成&lt;/h2&gt;

&lt;p&gt;ジョブを作成する。デフォルトで10DPU使うようになっているので調整する。1DPUで2つのExecutorが&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-debug-capacity.html#monitor-debug-capacity-visualize&#34;&gt;動く&lt;/a&gt;。
&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-continuations.html&#34;&gt;ブックマーク&lt;/a&gt;を有効にすると以前処理したデータは処理しないようにできるが、残念ながらParquetは対応していないため2回実行すると重複して出力されてしまう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/203-1.png&#34; alt=&#34;ジョブの作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;クローラはデータをクローリングしてデータカタログの指定のデータベースにスキーマやパーティションといったメタデータテーブルを作成する。
以前、LambdaでAthenaのスキーマを管理したりパーティションを切ったりするバッチを作ったが、Glueのデータカタログ上で同じことをやってくれる。
楽だけど現状DPUの設定項目がないのでデータが多くて時間がかかる場合はどうしようもなさそう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/145/&#34;&gt;Athenaのmigrationやpartitionするathena-adminを作った - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ジョブの実行&#34;&gt;ジョブの実行&lt;/h2&gt;

&lt;p&gt;トリガーを設定して定期的に実行することもできるが、今回は手動で実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws glue start-job-run --job-name kawase
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パーティションごとにParquetが出力されている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/203-3.png&#34; alt=&#34;パーティションごとのディレクトリ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;また、クローラの実行が終わるとデータカタログにテーブルが追加される。&lt;/p&gt;

&lt;h2 id=&#34;athenaで参照&#34;&gt;Athenaで参照&lt;/h2&gt;

&lt;p&gt;AthenaをGlueリリース以前から使っていた場合はデータカタログをGlueのものに&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/athena/latest/ug/glue-upgrade.html&#34;&gt;アップグレード&lt;/a&gt;する必要がある。
Athenaのところにリンクが出るので押しとけばIAMロールの更新など大体やってくれる。
これによってDatabaseにGlueのものが出るようになりクエリも実行できるようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/203-4.png&#34; alt=&#34;Athenaからの参照&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>強化学習とDQN(Deep Q-network)</title>
          <link>https://www.sambaiz.net/article/202/</link>
          <pubDate>Tue, 18 Dec 2018 01:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/202/</guid>
          <description>

&lt;p&gt;強化学習というのは将来に得られる報酬を最大化するような行動を学習していくもの。&lt;/p&gt;

&lt;h2 id=&#34;状態価値関数による学習&#34;&gt;状態価値関数による学習&lt;/h2&gt;

&lt;p&gt;状態sのときに取る行動aを決定する方策(Policy)をπ(s)、次の状態s&amp;rsquo;を予測するモデルをP(s,a,s&amp;rsquo;)、直後に得られる即時報酬r_{t+1}を予測するモデルをR(s,a)とすると、将来得られる報酬の期待値である状態価値関数Vπは次の式で再帰的に表すことができ、この形式をベルマン方程式という。
同じ報酬なら早くに得られた方が良いという考えから将来の報酬rは1ステップ遅れるたびに割引率γが掛けられる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/202-1.png&#34; alt=&#34;ベルマン方程式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;どんな状態においても状態価値関数を最大化させる最適方策π*を探すにあたり、定義通り将来の報酬を待つのではなく、即時報酬Rで状態価値関数Vを更新していく。これをTD(Temporal difference)学習という。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/202-2.png&#34; alt=&#34;TD学習&#34; /&gt;&lt;/p&gt;

&lt;p&gt;取り得る状態数が多いと収束するまでの時間が長くなる問題があって、これを価値関数の近似によって解消するのがDQN。&lt;/p&gt;

&lt;h2 id=&#34;dqn-deep-q-network&#34;&gt;DQN (Deep Q-Network)&lt;/h2&gt;

&lt;p&gt;DNNでQ学習を行う。Q学習というのは状態sのときに行動aしたときの報酬の期待値である行動価値関数Qを最大化させるように学習させるもので、
最も良かった行動でQを更新していく。
未知の行動を探索するかどうかはバンディットアルゴリズムのε-greedyによって確率的に決定し、学習が進むにつれて確率は下がっていく。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/202-3.png&#34; alt=&#34;行動価値関数Q&#34; /&gt;&lt;/p&gt;

&lt;p&gt;前もってランダムに行動と結果をサンプリングしておき学習の際に使う、ER(Experience Replay)というテクニックが使われる。
これによって実行回数が減るだけではなく、時系列的な相関を減らし効率的に学習させることができる。&lt;/p&gt;

&lt;p&gt;またmain-networkとは別に、同じ形式のtarget-networkを作ってQ(s&amp;rsquo;=s_{t+1}, a)の値を出すのに使う。
target-networkのパラメータはmain-networkのものを定期的に同期させる以外では更新しないことで学習を安定させることができる。
これをFixed Target Q-Networkという。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/202-4.png&#34; alt=&#34;DQN&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.jnns.org/previous/niss/2000/text/koike2.pdf&#34;&gt;強化学習の基礎&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://book.mynavi.jp/manatee/detail/id=89691&#34;&gt;第14回　深層強化学習DQN（Deep Q-Network）の解説｜Tech Book Zone Manatee&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>生成モデルVAE(Variational Autoencoder)</title>
          <link>https://www.sambaiz.net/article/201/</link>
          <pubDate>Tue, 11 Dec 2018 00:23:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/201/</guid>
          <description>

&lt;p&gt;生成モデルというのはデータの分布をモデリングしてそこから新しいデータを生成するもの。
VAEは入力xに対して何らかの分布を仮定し、例えばガウス分布(正規分布)だとすると平均μと分散σを推論し、
これを&lt;code&gt;z=μ+(σ・ε) (ε~N(0,1))&lt;/code&gt;の潜在変数に変換して生成モデルへの入力とし、その出力の尤度が最大化するように学習させる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/201-4.png&#34; alt=&#34;VAE&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Variational Autoencoderという名前はこの分布を推論して生成する流れがAutoencoderの形式と似ているところから来ている。
Autoencoder(自己符号化器)というのはある入力をエンコードしてデコードしたときに入力と同じものを出力するように学習させたもので、
これによって次元削減された潜在変数zが得られる。&lt;/p&gt;

&lt;p&gt;推論モデルの確率分布をq、生成モデルの確率分布をpとする。対数尤度log{p}を計算したいが潜在変数zが訓練データにないので周辺化する(1)。
これを変換していくと(2)のようになり、第二項のKL情報量は0以上の値になるので第一項のLを最大化することが対数尤度の最大化につながる。
このLをEvidence Lower Bound (ELBO)といい、推論モデルのパラメータφと生成モデルのパラメータθを交互に最適化して
これを最大化させることで尤度の下界を引き上げていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/134/&#34;&gt;自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/201.png&#34; alt=&#34;対数尤度の周辺化とELBO&#34; /&gt;&lt;/p&gt;

&lt;p&gt;生成モデルがベルヌーイ分布、p(z)が標準正規分布とするとELBOは次のようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/201-3.png&#34; alt=&#34;ELBO&#34; /&gt;&lt;/p&gt;

&lt;p&gt;第一項が再生成誤差。第二項によってp(z)とq(z|x)が近づくように学習し正則化され、zの各次元が独立になっていく。
これにβ&amp;gt;1を掛けるとさらに独立性が増し、次元ごとに、人であれば性別や年齢のような、disentangle(もつれを解く)された特徴を持つことができる。これをβ-VAEという。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/212/&#34;&gt;PyTorchでVAEのモデルを実装してMNISTの画像を生成する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;VAEは分布を仮定して尤度によって学習するため、真の分布にはないところの生成データが良くない問題がある。
VAE以外の生成モデルとしてGAN(Generative Adversarial Networks)があって、これはデータの分布を仮定せずより近い分布から良いデータを生成するのを目指す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/210/&#34;&gt;生成モデルGAN(Generative Adversarial Network) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://elix-tech.github.io/ja/2016/07/17/autoencoder.html&#34;&gt;Kerasで学ぶAutoencoder&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1606.05908&#34;&gt;Carl Doersch (2016) Tutorial on Variational Autoencoders&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24&#34;&gt;Variational Autoencoder徹底解説 - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Encoder-Decoder RNNのAttention</title>
          <link>https://www.sambaiz.net/article/200/</link>
          <pubDate>Sat, 01 Dec 2018 23:09:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/200/</guid>
          <description>&lt;p&gt;Encoder-Decoder RNNは入力用のEncoderと出力用のDecoderの2つのLSTMを組み合わせたもので、EncoderのStateはDecoderに繋げる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/200.png&#34; alt=&#34;Encoder-Decoder RNN&#34; /&gt;&lt;/p&gt;

&lt;p&gt;したがって入力データはDecoderに渡されるStateにまとめられることになるが、
出力ごとに入力時系列の重要な部分は異なるため、特定の部分に注目できるようにすると良い結果が期待できる。
次の論文ではAttention Layerを追加することでこれを行い翻訳の精度を向上させている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1508.04025&#34;&gt;Minh-Thang Luong, Hieu Pham, Christopher D. Manning (2015) Effective Approaches to Attention-based Neural Machine Translation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Attention LayerはEncoderの出力とDecoderの対象の出力からどの部分を重要とするかを表すAlign weights a(t)と
Encoderの出力を掛けたものをContext vector c(t)として出力する。
scoreにはそのまま掛けたものや(&lt;code&gt;h_{dec}h_{enc}&lt;/code&gt;)、重みとDecoderの出力のみを掛ける(&lt;code&gt;Wh_{dec}&lt;/code&gt;)といったものが使われる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/200-2.png&#34; alt=&#34;Attention Layer&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/200-3.png&#34; alt=&#34;Align weightsとContext vectorの式&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</title>
          <link>https://www.sambaiz.net/article/199/</link>
          <pubDate>Tue, 27 Nov 2018 09:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/199/</guid>
          <description>

&lt;p&gt;TPU(Tensor Processing Unit)は
Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。
&lt;a href=&#34;https://cloudplatform-jp.googleblog.com/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu.html&#34;&gt;一般的なGPUと比べて15~30倍もの性能が出る&lt;/a&gt;
らしく検索や翻訳などGoogleのサービスでも使われている。&lt;/p&gt;

&lt;p&gt;TPUを使える環境として、無料で使えるJupyter Notebooksの&lt;a href=&#34;https://colab.research.google.com/&#34;&gt;Google Colab&lt;/a&gt;と
GCPの&lt;a href=&#34;https://cloud.google.com/tpu/&#34;&gt;Cloud TPU&lt;/a&gt;がある。ColabのTPUも裏側ではCloud TPUが動いている。
Cloud TPUを直に使うとVMから接続して使うことになるので、TPUの&lt;a href=&#34;https://cloud.google.com/tpu/docs/pricing&#34;&gt;料金&lt;/a&gt;に加えてVMの料金もかかる。&lt;/p&gt;

&lt;h2 id=&#34;モデルのtpu対応&#34;&gt;モデルのTPU対応&lt;/h2&gt;

&lt;p&gt;CNNのモデルを&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimator&#34;&gt;TPUEstimator&lt;/a&gt;でTPUに対応させる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/guide/estimators&#34;&gt;Estimator&lt;/a&gt;はTensorFlowの高レベルAPIで、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#train&#34;&gt;train()&lt;/a&gt;、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate&#34;&gt;evaluate()&lt;/a&gt;、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#predict&#34;&gt;predict()&lt;/a&gt;、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#export_saved_model&#34;&gt;export_saved_model()&lt;/a&gt;
といったモデルの学習から保存まで必要な機能を一通り提供する。&lt;/p&gt;

&lt;p&gt;初めは比較的低レベルのAPIを使おうとしていたが、XLA(Accelerated Linear Algebra)によるコンパイルがうまくいかないなど様々な問題にあたって大変だったので使っておくと良いと思う。
それでもトライアンドエラーの繰り返しで、典型的なものは&lt;a href=&#34;https://cloud.google.com/tpu/docs/troubleshooting&#34;&gt;Troubleshooting&lt;/a&gt;にあるが、ないものは調べるなりしてなんとかやっていくしかない。&lt;/p&gt;

&lt;p&gt;定数などの定義。BATCH_SIZEはCloud TPUのシャード数の8で割り切れる値にする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
from sklearn.model_selection import train_test_split
import tensorflow as tf
import numpy as np
flags = tf.app.flags
flags.DEFINE_boolean(&#39;use_tpu&#39;, True, &#39;use tpu or not&#39;)
tf.app.flags.DEFINE_string(&#39;f&#39;, &#39;&#39;, &#39;kernel&#39;)
FLAGS = flags.FLAGS

EPOCH_NUM = 100
BATCH_SIZE = 800 # must be divisible by number of replicas 8
EVAL_BATCH_SIZE = 800
SHARD_NUM = 8 # A single Cloud TPU has 8 shards.
ITERATION_NUM = 100 # Number of training steps to run on the Cloud TPU before returning control.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;入力データの準備&#34;&gt;入力データの準備&lt;/h3&gt;

&lt;p&gt;入力は関数で渡し、tf.data APIのdatasetを返せばイテレートしてくれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/195/&#34;&gt;TensorFlowのtf.data API - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;batch()でdrop_remainderをTrueにして端数を切り捨てないと、shapeが確定せずコンパイルできない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from google.colab import auth
from googleapiclient.discovery import build
from io import BytesIO

auth.authenticate_user()
bucket = &amp;quot;&amp;lt;bucket_name&amp;gt;&amp;quot;
gcs_service = build(&#39;storage&#39;, &#39;v1&#39;)
train_data = gcs_service.objects().get_media(bucket=bucket, object=&#39;train.csv&#39;).execute()
train = pd.read_csv(BytesIO(train_data))

MODEL_DIR = &#39;gs://{}/model/tpu&#39;.format(bucket)

(x_train, x_valid, y_train, y_valid) = train_test_split(
    train.drop(&#39;label&#39;, axis=1).values.reshape((-1, 28, 28, 1)).astype(np.float32), 
    np.identity(10)[train[&#39;label&#39;]].astype(np.float32), 
    test_size = 0.1, random_state = 100)

def train_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({&#39;x&#39;: x_train}, y_train)) # (features, labels)
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(params[&#39;batch_size&#39;], drop_remainder=True)
    return dataset

def valid_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({&#39;x&#39;: x_valid}, y_valid))
    dataset = dataset.batch(params[&#39;batch_size&#39;], drop_remainder=True)
    return dataset
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入出力するファイルはローカルではなくGCSなどに置く必要があるのでCloud TPUからも読み書きできるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;domain&amp;quot;: &amp;quot;global&amp;quot;,
    &amp;quot;reason&amp;quot;: &amp;quot;forbidden&amp;quot;,
    &amp;quot;message&amp;quot;: &amp;quot;service-******@cloud-tpu.iam.gserviceaccount.com does not have storage.objects.create access to &amp;lt;bucket_name&amp;gt;.&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;!gsutil acl ch -u service-*****@cloud-tpu.iam.gserviceaccount.com:WRITER gs://&amp;lt;bucket_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;モデルの作成&#34;&gt;モデルの作成&lt;/h3&gt;

&lt;p&gt;Estimatorには次のシグネチャのmodel_fnを渡す。
引数のfeaturesとlabelsはinput_fnの返り値で、
modeは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys&#34;&gt;tf.estimator.ModeKeys&lt;/a&gt;の&lt;code&gt;TRAIN&lt;/code&gt;、&lt;code&gt;EVAL&lt;/code&gt;、&lt;code&gt;PREDICT&lt;/code&gt;で、
paramsはEstimator生成時に渡せるパラメータ。
optimizerは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/CrossShardOptimizer&#34;&gt;CrossShardOptimizer&lt;/a&gt;で&lt;a href=&#34;https://www.tensorflow.org/guide/using_tpu#optimizer&#34;&gt;wrapする&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;TPUに対応している&lt;a href=&#34;https://cloud.google.com/tpu/docs/tensorflow-ops&#34;&gt;op&lt;/a&gt;で作る必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def model_fn(features, labels, mode, params):
    def metric_fn(labels, logits):
        return {
            &#39;accuracy&#39;: tf.metrics.accuracy(
                labels=tf.argmax(labels, axis=1), predictions=tf.argmax(logits, axis=1))
         }
    is_training = tf.equal(mode, tf.estimator.ModeKeys.TRAIN)
    conv1 = tf.layers.conv2d(
        inputs=features[&#39;x&#39;],
        filters=32, 
        kernel_size=[5, 5], 
        padding=&amp;quot;same&amp;quot;, 
        activation=tf.nn.relu)
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)
    conv2 = tf.layers.conv2d(
        inputs=pool1, 
        filters=64, 
        kernel_size=[5, 5],
        padding=&amp;quot;same&amp;quot;, 
        activation=tf.nn.relu)
    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
    pool2_flat = tf.layers.flatten(pool2)
    dense = tf.layers.dense(inputs=pool2_flat, units=128, activation=tf.nn.relu)
    dropout = tf.layers.dropout(
        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)
    logits = tf.layers.dense(inputs=dropout, units=10)

    loss = tf.losses.softmax_cross_entropy(
        onehot_labels=labels, logits=logits)
    
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.contrib.tpu.TPUEstimatorSpec(mode, loss=loss, 
                                               eval_metrics=(metric_fn, [labels, logits]))

    optimizer = tf.train.AdamOptimizer(0.01)
    if FLAGS.use_tpu:
        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)

    return tf.contrib.tpu.TPUEstimatorSpec(
        mode=mode,
        loss=loss,
        predictions={
            &#39;pred&#39;: tf.argmax(logits, axis=1)
        },
        train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tpuestimatorの生成&#34;&gt;TPUEstimatorの生成&lt;/h3&gt;

&lt;p&gt;TPUのアドレスが環境変数COLAB_TPU_ADDRに入るのでこれをmasterとする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if FLAGS.use_tpu:
    master = &#39;grpc://&#39; + os.environ[&#39;COLAB_TPU_ADDR&#39;]
    run_config = tf.contrib.tpu.RunConfig(
        master=master,
        session_config=tf.ConfigProto(
            allow_soft_placement=True, log_device_placement=True),
        tpu_config=tf.contrib.tpu.TPUConfig(ITERATION_NUM, SHARD_NUM))
else:
    run_config = tf.contrib.tpu.RunConfig()

classifier = tf.contrib.tpu.TPUEstimator(
    model_fn=model_fn,
    model_dir=MODEL_DIR,
    config=run_config,
    params={},
    train_batch_size=BATCH_SIZE,
    eval_batch_size=EVAL_BATCH_SIZE,
    predict_batch_size=BATCH_SIZE,
    use_tpu=FLAGS.use_tpu)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;学習&#34;&gt;学習&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;for epoch in range(EPOCH_NUM):
  max_steps = len(x_train)*(epoch+1)//BATCH_SIZE
  valid_steps = len(x_valid)//EVAL_BATCH_SIZE
  if FLAGS.use_tpu: 
    max_steps //= SHARD_NUM
  train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_steps)
  eval_spec = tf.estimator.EvalSpec(input_fn=valid_input_fn, steps=valid_steps)
  result = tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
  if result[0] is not None:
    print(&#39;epoch: {}, loss: {} accuracy: {}&#39;.format(epoch+1, result[0][&#39;loss&#39;], result[0][&#39;accuracy&#39;]))
  else:
    print(&#39;epoch: {} is already trained&#39;.format(epoch+1))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;colabでtensorboardを開く&#34;&gt;ColabでTensorBoardを開く&lt;/h3&gt;

&lt;p&gt;このスクリプトを実行するとTensorBoardを立ち上げてngrokで外に開いてくれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/mixuala/colab_utils&#34;&gt;mixuala/colab_utils&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;!git clone https://github.com/mixuala/colab_utils
import os
import colab_utils.tboard

# set paths
ROOT = %pwd
colab_utils.tboard.launch_tensorboard(bin_dir=ROOT, log_dir=MODEL_DIR)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;学習させて実行時間を計測する。計測はセルの頭に&lt;code&gt;%%time&lt;/code&gt;を付けるとできる。&lt;/p&gt;

&lt;h3 id=&#34;cpu&#34;&gt;CPU&lt;/h3&gt;

&lt;p&gt;ベースライン。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 18min 28s, sys: 32.8 s, total: 19min 1s
Wall time: 14min 33s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;gpu&#34;&gt;GPU&lt;/h3&gt;

&lt;p&gt;ランタイムからアクセラレータをGPUに設定。使われるGPUはNVIDIAの&lt;a href=&#34;https://www.nvidia.co.jp/object/tesla-k80-jp.html&#34;&gt;Tesla K80&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.python.client import device_lib
device_lib.list_local_devices()
# ...
# physical_device_desc: &amp;quot;device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 3min 2s, sys: 24.2 s, total: 3min 26s
Wall time: 8min 6s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tpu&#34;&gt;TPU&lt;/h3&gt;

&lt;p&gt;アクセラレータをTPUに変更。
GPUより速くなることを期待したが、むしろCPUよりも遅くなってしまった。その上精度の伸びも遅くて良いところがない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 3min, sys: 23.8 s, total: 3min 24s
Wall time: 15min
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;再チャレンジ&#34;&gt;再チャレンジ&lt;/h2&gt;

&lt;p&gt;エポックの立ち上がりが遅いので学習を切らずに続けて行わせてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def train_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({&#39;x&#39;: x_train}, y_train)) # (features, labels)
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(params[&#39;batch_size&#39;], drop_remainder=True)
    dataset = dataset.repeat(EPOCH_NUM)
    return dataset

epoch = EPOCH_NUM-1
max_steps = len(x_train)*(epoch+1)/BATCH_SIZE
valid_steps = len(x_valid)//EVAL_BATCH_SIZE
if FLAGS.use_tpu: 
  max_steps //= SHARD_NUM
train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_steps)
eval_spec = tf.estimator.EvalSpec(input_fn=valid_input_fn, steps=valid_steps)
result = tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
if result[0] is not None:
  print(&#39;epoch: {}, loss: {} accuracy: {}&#39;.format(epoch+1, result[0][&#39;loss&#39;],  result[0][&#39;accuracy&#39;]))
else:
  print(&#39;epoch: {} is already trained&#39;.format(epoch+1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行したところGPUと同程度には速くなった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# GPU
CPU times: user 40.9 s, sys: 7.8 s, total: 48.7 s
Wall time: 1min 43s

# TPU
CPU times: user 35.2 s, sys: 4.46 s, total: 39.7 s
Wall time: 1min 34s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらにEPOCH_NUMを5から100にして再計測する。&lt;/p&gt;

&lt;h2 id=&#34;結果-1&#34;&gt;結果&lt;/h2&gt;

&lt;h3 id=&#34;gpu-1&#34;&gt;GPU&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 3min 27s, sys: 2min, total: 5min 28s
Wall time: 6min 5s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tpu-1&#34;&gt;TPU&lt;/h3&gt;

&lt;p&gt;エポック数を大幅に増やしたのにも関わらずほとんど実行時間が変わらずとても速い。
CPU時間も変わっていないので演算がTPUで完結していてCPU-TPU間のデータの受け渡しが最小限で済んでいるのかもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 34.5 s, sys: 7.32 s, total: 41.8 s
Wall time: 1min 38s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d&#34;&gt;Google Colab Free GPU Tutorial – Deep Learning Turkey – Medium&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/koshian2/items/fb989cebe0266d1b32fc&#34;&gt;Google ColabのTPUで対GPUの最速に挑戦する - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する</title>
          <link>https://www.sambaiz.net/article/198/</link>
          <pubDate>Wed, 14 Nov 2018 02:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/198/</guid>
          <description>

&lt;h2 id=&#34;batch-normalizationとは&#34;&gt;Batch Normalizationとは&lt;/h2&gt;

&lt;p&gt;Deep Learningでは各層の学習を同時に行うため、前の層の変更によって各層の入力の分布が変わってしまうinternal covariate shiftという現象が起こり、そのためにパラメータの初期化をうまくやる必要があったり、学習率を大きくできず多くのステップを要する。
以下の論文で発表されたBatch Normalization(BN)は各層の入力を正規化して分布を固定することでこれを解決するというもの。
画像認識のコンテスト&lt;a href=&#34;http://image-net.org/challenges/LSVRC/2015/results&#34;&gt;ILSVRC 2015&lt;/a&gt;で1位を取った&lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34;&gt;ResNet(Residual Network)&lt;/a&gt;でも使われている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1502.03167&#34;&gt;Sergey Ioffe, Christian Szegedy (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;具体的にはWx+bと活性化関数の間にBNの層を入れる。μ、σ^2は入力xの平均と分散。
単に正規化するだけでは表現力が下がってしまうのでγとβでスケールやシフトできるようにする。これらの変数は他のパラメータと同様に学習させる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/198.png&#34; alt=&#34;BN層の演算&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;tensorflowでの確認&#34;&gt;TensorFlowでの確認&lt;/h2&gt;

&lt;p&gt;TensorFlowでは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization&#34;&gt;batch_normalization()&lt;/a&gt;がすでに実装されているのでこれを使う。&lt;/p&gt;

&lt;p&gt;以下のCNNで学習率を高めに設定しBNありなしの結果を比較する。学習データはmnist。MonitoredSessionでcostをsummaryとして出力しTensorBoardで見られるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/147/&#34;&gt;TensorBoardでsummaryやグラフを見る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/175/&#34;&gt;TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score

train = pd.read_csv(&#39;./train.csv&#39;)
(x_train, x_valid ,y_train, y_valid) = train_test_split(
    train.drop(&#39;label&#39;, axis=1).values.reshape((-1, 28, 28, 1)), 
    np.identity(10)[train[&#39;label&#39;]], 
    test_size = 0.1, random_state = 100)

print(&amp;quot;data shape: {}, label shape {}&amp;quot;.format(x_train.shape, y_train.shape))

tf.reset_default_graph()

class ConvBnRelu:
    def __init__(self, filters, kernel_size):
        self.filters = filters
        self.kernel_size= kernel_size
        
    def __call__(self, x, use_bn, is_training):
        h = tf.layers.Conv2D(filters=self.filters, kernel_size=self.kernel_size)(x)
        h = tf.cond(
            use_bn,
            true_fn=lambda: tf.layers.batch_normalization(h, training=is_training),
            false_fn=lambda: h
        )
        return tf.nn.relu(h)

is_training = tf.placeholder(tf.bool, shape=())
use_bn = tf.placeholder(tf.bool, shape=())
x = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32)
t = tf.placeholder(tf.float32, [None, 10])

with tf.name_scope(&amp;quot;Conv1&amp;quot;):
    h = ConvBnRelu(filters=32, kernel_size= [3, 3])(x, use_bn, is_training)
    h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h)

with tf.name_scope(&amp;quot;Conv2&amp;quot;):
    h = ConvBnRelu(filters= 64, kernel_size= [3, 3])(h, use_bn, is_training)
    h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h)

h = tf.layers.Flatten()(h)
y = tf.layers.Dense(units=10, activation=tf.nn.softmax)(h)

global_step=tf.train.get_or_create_global_step()
cost = - tf.reduce_mean(tf.reduce_sum(t * tf.log(tf.clip_by_value(y, 1e-10, y)), axis=1))
summary_cost = tf.summary.scalar(&#39;cost&#39;, cost)
optimizer = tf.train.AdamOptimizer(0.01).minimize(cost, global_step=global_step)

EPOCH_NUM = 5
BATCH_SIZE = 100

hooks = [
    tf.train.StopAtStepHook(last_step=EPOCH_NUM*(len(x_train) // BATCH_SIZE))
]

init = tf.global_variables_initializer()

for bn in [False, True]:
    epoch = -1
    print(&amp;quot;--- use binary norm: {} ---&amp;quot;.format(bn))
    with tf.train.MonitoredTrainingSession(
        hooks=hooks, 
        summary_dir=&amp;quot;/home/jovyan/summary&amp;quot;,
        save_summaries_steps=100) as sess:    
        sess.run(init, feed_dict={x: x_valid, t: y_valid, is_training: False, use_bn: bn})
        while not sess.should_stop():
            epoch += 1
            y_pred, cost_valid, _ = sess.run([y, cost, summary_cost], feed_dict={x: x_valid, t: y_valid, is_training: False, use_bn: bn})
            print(&amp;quot;epoch: {:2d}, cost: {:.4f}, accuracy: {:.4f}&amp;quot;.format(
                epoch, cost_valid, accuracy_score(y_pred.argmax(axis=1), y_valid.argmax(axis=1))))
            x_train, y_train = shuffle(x_train, y_train, random_state=100)
            for batch in range(len(x_train) // BATCH_SIZE):
                start = batch * BATCH_SIZE
                end = start + BATCH_SIZE
                sess.run(optimizer, feed_dict={x: x_train[start:end], t: y_train[start:end], is_training: True, use_bn: bn})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BNを行わなかったときの結果。コストを下げられていない。ちなみに学習率を0.01から0.001にしたら下げられるようになった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/198-2.png&#34; alt=&#34;BNしない場合のコスト&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一方、BNを行ったときの結果がこれ。学習率はそのままで順調にコストを下げることができている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/198-3.png&#34; alt=&#34;BNした場合のコスト&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow&#43;numpyでData Augmentationして画像の学習データを増やす</title>
          <link>https://www.sambaiz.net/article/197/</link>
          <pubDate>Sun, 11 Nov 2018 15:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/197/</guid>
          <description>

&lt;p&gt;Data Augmentationは学習データを加工したものを学習データに加えることで数を増やすというもの。
加工したデータには通常元のものと同じラベルが付くことになるが、
例えば画像を反転や回転させても元々のものと同じだと認識されるべきだとしたら妥当だ。
つまり、なんでもすれば良いわけではなくデータセットに応じた、元のデータと同じラベルが付くような加工をする必要があり、
裏を返せばそのような違いがあっても同じものであることをモデルに学習させることができる。&lt;/p&gt;

&lt;p&gt;今回はData Augmentationで行われる加工をTensorFlowやnumpyの関数でおなじみLennaの画像に行う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna.png&#34; alt=&#34;Lenna&#34; /&gt;&lt;/p&gt;

&lt;p&gt;必要なパッケージと画像をimportする。Jupyter Notebooksで実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%matplotlib inline
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
im = Image.open(&amp;quot;lenna.png&amp;quot;, &amp;quot;r&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;flipping&#34;&gt;Flipping&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/flip_left_right&#34;&gt;flip_left_right()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/random_flip_left_right&#34;&gt;random_flip_left_right()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/flip_up_down&#34;&gt;flip_up_down()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/random_flip_up_down&#34;&gt;random_flip_up_down()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;左右と上下の反転。randomは1/2で反転する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fliph = tf.image.flip_left_right(im)
flipv = tf.image.flip_up_down(im)

with tf.Session() as sess:
    results = sess.run([fliph, flipv])
plt.imshow(np.hstack(results))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna2.png&#34; alt=&#34;左右と上下反転したLenna&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;rotating&#34;&gt;Rotating&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/rot90&#34;&gt;rot90()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;反時計周りに90度回転させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rot90 = tf.image.rot90(im)

with tf.Session() as sess:
    results = sess.run([rot90])
plt.imshow(np.hstack(results))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna3.png&#34; alt=&#34;90度回転したLenna&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;cropping&#34;&gt;Cropping&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/central_crop&#34;&gt;central_crop()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/crop_to_bounding_box&#34;&gt;crop_to_bounding_box()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/random_crop&#34;&gt;random_crop()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;中央と一部分の切り取り。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;central_crop = tf.image.central_crop(im, 0.7)
crop_to_box =  tf.image.crop_to_bounding_box(im, 50, 50, 100, 100)
ops = [tf.cast(tf.image.resize_images(op, (200, 200)), tf.uint8) for op in [central_crop, crop_to_box]]
with tf.Session() as sess:
    results = sess.run(ops)
plt.imshow(np.hstack(results))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna4.png&#34; alt=&#34;中央と一部分を切り取ったLenna&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;cutout&#34;&gt;Cutout&lt;/h3&gt;

&lt;p&gt;以下の論文にあるランダムな正方形の領域をマスキングすることで、画像の一部分だけではなくなるべく全体のコンテキストを使わせる手法。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1708.04552&#34;&gt;Terrance DeVries, Graham W. Taylor (2017) Improved Regularization of Convolutional Neural Networks with Cutout&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/187/&#34;&gt;numpyの関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def random_cutout(image, size = 100):
    w = image.shape[0]
    h = image.shape[1]
    mask = np.ones((w, h, 3), np.uint8)
    x = np.random.randint(w)
    y = np.random.randint(h)
    x1 = np.clip(x - size // 2, 0, w)
    x2 = np.clip(x + size // 2, 0, w)
    y1 = np.clip(y - size // 2, 0, h)
    y2 = np.clip(y + size // 2, 0, h)
    mask[x1: x2, y1: y2] = 0
    return im * mask

result = random_cutout(np.array(im))
plt.imshow(result)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna5.png&#34; alt=&#34;CutoutしたLenna&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>FargateでECSを使う</title>
          <link>https://www.sambaiz.net/article/196/</link>
          <pubDate>Fri, 09 Nov 2018 00:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/196/</guid>
          <description>

&lt;p&gt;ECSはAWSのコンテナオーケストレーションサービス。
クラスタは&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/launch_types.html#launch-type-ec2&#34;&gt;EC2上に立てる&lt;/a&gt;こともできるが、その場合Auto Scalingグループの設定や&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/how-to-automate-container-instance-draining-in-amazon-ecs/&#34;&gt;スケールイン時のdrain&lt;/a&gt;などを考慮する必要がある。
&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/launch_types.html#launch-type-fargate&#34;&gt;Fargate&lt;/a&gt;で起動するとサーバーレスで実行でき、バックエンドの管理が必要がなくなる。
&lt;a href=&#34;https://aws.amazon.com/jp/fargate/pricing/&#34;&gt;料金&lt;/a&gt;は割り当てたvCPUとメモリによって、最低1分の1秒単位で課金される。
Lambdaと同じくリソースあたりでいうとオンデマンドのEC2と比較して割高。ただし柔軟にリソースが指定できる分いくらか差は縮まる。&lt;/p&gt;

&lt;p&gt;特にバッチ処理のように常にリソースが必要ないTaskは都度インスタンスを立ち上げるのも面倒なので良いと思う。
Lambdaと比較すると、実行環境を自由に作れるのと実行時間に制限がないというところが良いが、
Taskを作るトリガーは現状cronだけなのでそれ以外のイベントで実行したい場合はLambdaと組み合わせる必要がある。&lt;/p&gt;

&lt;p&gt;AWSにはKubernetesクラスタを立てられるEKSもあるが、こちらはまだFargateに対応していない。
もしかしたら今月末の&lt;a href=&#34;https://reinvent.awsevents.com/&#34;&gt;re:Invent&lt;/a&gt;で何か発表されるかもしれない。&lt;/p&gt;

&lt;h2 id=&#34;clusterの作成&#34;&gt;Clusterの作成&lt;/h2&gt;

&lt;p&gt;まずはClusterを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws ecs create-cluster --cluster-name test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/196.png&#34; alt=&#34;ECSオブジェクト&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;taskの登録&#34;&gt;Taskの登録&lt;/h2&gt;

&lt;p&gt;イメージやポートマッピング、ヘルスチェックや割り当てるリソースといった&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions&#34;&gt;Container definition&lt;/a&gt;
を含む&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task_definition_parameters.html&#34;&gt;Task definition&lt;/a&gt;を書く。
Fargateの場合networkModeはawsvpc固定になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;family&amp;quot;: &amp;quot;test-task&amp;quot;, 
    &amp;quot;networkMode&amp;quot;: &amp;quot;awsvpc&amp;quot;, 
    &amp;quot;containerDefinitions&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;nginx&amp;quot;, 
            &amp;quot;image&amp;quot;: &amp;quot;nginx:1.15&amp;quot;, 
            &amp;quot;portMappings&amp;quot;: [
                {
                    &amp;quot;containerPort&amp;quot;: 80, 
                    &amp;quot;hostPort&amp;quot;: 80, 
                    &amp;quot;protocol&amp;quot;: &amp;quot;tcp&amp;quot;
                }
            ], 
            &amp;quot;essential&amp;quot;: true
        }
    ], 
    &amp;quot;requiresCompatibilities&amp;quot;: [
        &amp;quot;FARGATE&amp;quot;
    ], 
    &amp;quot;cpu&amp;quot;: &amp;quot;256&amp;quot;, 
    &amp;quot;memory&amp;quot;: &amp;quot;512&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Taskを登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws ecs register-task-definition --cli-input-json file://$(pwd)/task.json
$ aws ecs list-task-definitions
    &amp;quot;taskDefinitionArns&amp;quot;: [
        &amp;quot;arn:aws:ecs:ap-northeast-1:*****:task-definition/test-task:1&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;taskを実行&#34;&gt;Taskを実行&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/reference/ecs/run-task.html&#34;&gt;run-task&lt;/a&gt;でTaskを実行できる。
外からアクセスできるようにPublicIPを割り当てている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;cluster&amp;quot;: &amp;quot;test&amp;quot;,
  &amp;quot;taskDefinition&amp;quot;: &amp;quot;test-task:1&amp;quot;,
  &amp;quot;launchType&amp;quot;: &amp;quot;FARGATE&amp;quot;,
  &amp;quot;networkConfiguration&amp;quot;: {
    &amp;quot;awsvpcConfiguration&amp;quot;: {
      &amp;quot;subnets&amp;quot;: [
        &amp;quot;subnet-*****&amp;quot;
      ],
      &amp;quot;securityGroups&amp;quot;: [
        &amp;quot;sg-*****&amp;quot;
      ],
      &amp;quot;assignPublicIp&amp;quot;: &amp;quot;ENABLED&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ aws ecs run-task --cli-input-json file://$(pwd)/run-task.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TaskのNetworkのところにPublicIPが出ていて、アクセスするとWelcome to nginx!の表示が確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/196-2.png&#34; alt=&#34;TaskのNetwork&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;serviceを作成&#34;&gt;Serviceを作成&lt;/h2&gt;

&lt;p&gt;上の方法でTaskを実行することもできるが、
常時動くアプリケーションの場合、何か問題が起きてTaskが終了したら復活してほしい。
それをやるのが&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/service_definition_parameters.html&#34;&gt;Service&lt;/a&gt;で、K8sでいうDeploymentのようなリソース。ELBと紐づけると複数のTaskで負荷分散できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;cluster&amp;quot;: &amp;quot;test&amp;quot;,
    &amp;quot;serviceName&amp;quot;: &amp;quot;test-service&amp;quot;,
    &amp;quot;taskDefinition&amp;quot;: &amp;quot;test-task:1&amp;quot;,
    &amp;quot;desiredCount&amp;quot;: 2,
    &amp;quot;launchType&amp;quot;: &amp;quot;FARGATE&amp;quot;,
    &amp;quot;networkConfiguration&amp;quot;: {
        &amp;quot;awsvpcConfiguration&amp;quot;: {
            &amp;quot;subnets&amp;quot;: [
                &amp;quot;subnet-*****&amp;quot;
            ],
            &amp;quot;securityGroups&amp;quot;: [
                &amp;quot;sg-******&amp;quot;
            ],
            &amp;quot;assignPublicIp&amp;quot;: &amp;quot;ENABLED&amp;quot;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serviceを作成するとdesiredCountの分Taskが立ち上がり、Taskを消すと再びその数になるように立ち上がる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws ecs create-service --cli-input-json file://$(pwd)/service.json
$ aws ecs list-services --cluster test
{
    &amp;quot;serviceArns&amp;quot;: [
        &amp;quot;arn:aws:ecs:ap-northeast-1:*****:service/test-service&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/221/&#34;&gt;ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのtf.data API</title>
          <link>https://www.sambaiz.net/article/195/</link>
          <pubDate>Sat, 03 Nov 2018 18:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/195/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/guide/datasets&#34;&gt;Importing Data  |  TensorFlow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;データを読み込み変換してイテレートする入力パイプラインを作るAPI。
通常、学習にGPU/TPUを使う場合CPU処理の間はアイドル状態となりボトルネックになるが、
パイプライン処理を行うことでCPUとGPU/TPUがなるべくアイドル状態にならないようになり、
&lt;a href=&#34;https://www.tensorflow.org/guide/performance/datasets&#34;&gt;学習時間が短縮される&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;dataset-https-www-tensorflow-org-api-docs-python-tf-data-dataset-の作成&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset&#34;&gt;Dataset&lt;/a&gt;の作成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices&#34;&gt;from_tensor_slices()&lt;/a&gt;でDatasetを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.data.Dataset.from_tensor_slices(
   {&amp;quot;a&amp;quot;: tf.random_uniform([4]),
    &amp;quot;b&amp;quot;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})
print(dataset.output_types) # {&#39;a&#39;: tf.float32, &#39;b&#39;: tf.int32}
print(dataset.output_shapes) # {&#39;a&#39;: TensorShape([]), &#39;b&#39;: TensorShape([Dimension(100)])}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;引数にnumpyのndarrayを渡すとtf.constant()で変換されてグラフに乗る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)))
print(dataset.output_types) # &amp;lt;dtype: &#39;int64&#39;&amp;gt;
print(dataset.output_shapes) # (3,)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;データが1GBを超える場合グラフのシリアライズ上限を超えてしまうことがある。後述するinitializableイテレータの初期化時にndarrayを渡すとこれを避けられる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/data/CsvDataset&#34;&gt;tf.contrib.data.CsvDataset&lt;/a&gt;でCSVからDatasetを作ることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat file1.csv
a,b,c,d
1,2,3,4
2,3,4,5
6,7,8,9
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;filenames = [&amp;quot;file1.csv&amp;quot;]
record_defaults = [tf.float32] * 2 # Two required float columns
dataset = tf.contrib.data.CsvDataset(filenames, record_defaults, header=True, select_cols=[1,3])
print(dataset.output_types) # (tf.float32, tf.float32)
print(dataset.output_shapes) # (TensorShape([]), TensorShape([]))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;前処理&#34;&gt;前処理&lt;/h3&gt;

&lt;p&gt;Datasetは
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map&#34;&gt;map&lt;/a&gt;や
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#flat_map&#34;&gt;flat_map&lt;/a&gt;、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#filter&#34;&gt;filter&lt;/a&gt;で変換でき、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch&#34;&gt;batch&lt;/a&gt;を作ったり
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat&#34;&gt;repeat&lt;/a&gt;したり
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle&#34;&gt;shuffle&lt;/a&gt;できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.data.Dataset.range(5).map(lambda d: d*2) # 0 2 4 6 8
dataset = tf.data.Dataset.from_tensor_slices((np.arange(4).reshape((2,2)))).flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x * 2)) # 0 2 4 6
dataset = tf.data.Dataset.range(5).filter(lambda d: tf.equal(tf.mod(d, 2), 0)) # 0 2 4

dataset = tf.data.Dataset.range(10).batch(4) # [0 1 2 3] [4 5 6 7] [8 9]
dataset = tf.data.Dataset.range(3).repeat(3) # 0 1 2 0 1 2 0 1 2
dataset = tf.data.Dataset.range(5).shuffle(buffer_size=10) # 1 0 3 4 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;iterator-https-www-tensorflow-org-api-docs-python-tf-data-iterator-の作成&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Iterator&#34;&gt;Iterator&lt;/a&gt;の作成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Iterator#get_next&#34;&gt;get_next()&lt;/a&gt;で次の要素が取れる。&lt;/p&gt;

&lt;h3 id=&#34;one-shot&#34;&gt;one-shot&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#make_one_shot_iterator&#34;&gt;make_one_shot_iterator()&lt;/a&gt;で作れるone-shotイテレータはDatasetを一周イテレートする基本的なイテレータ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.data.Dataset.range(100)
iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

with tf.Session() as sess:
    try:
        while True:
            print(sess.run(next_element)) # 0 1 2, ..., 99
    except tf.errors.OutOfRangeError:
        pass
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;initializable&#34;&gt;initializable&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#make_initializable_iterator&#34;&gt;make_initializable_iterator()&lt;/a&gt;で単一Datasetから作れるinitializableイテレータはDatasetのplaceholderを初期化できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;max_value = tf.placeholder(tf.int64, shape=[])
dataset = tf.data.Dataset.range(max_value)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

with tf.Session() as sess:
    sess.run(iterator.initializer, feed_dict={max_value: 10})
    try:
        while True:
            print(sess.run(next_element)) # 0 1 2, ..., 9
    except tf.errors.OutOfRangeError:
        pass
    print(&amp;quot;---&amp;quot;)
    sess.run(iterator.initializer, feed_dict={max_value: 20})
    try:
        while True:
            print(sess.run(next_element)) # 0 1 2, ..., 19
    except tf.errors.OutOfRangeError:
        pass
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;reinitializable&#34;&gt;reinitializable&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Iterator#from_structure&#34;&gt;Iterator.from_structure()&lt;/a&gt;でtypeとshapeから作れるreinitializableイテレータは複数のDatasetで初期化できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;training_dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)))
validation_dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)) * 2)

iterator = tf.data.Iterator.from_structure(training_dataset.output_types,
                                           training_dataset.output_shapes)
next_element = iterator.get_next()
training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

with tf.Session() as sess:
    sess.run(training_init_op)
    try:
        while True:
            print(sess.run(next_element)) # [0 1 2] [3 4 5] [6 7 8]
    except tf.errors.OutOfRangeError:
        pass
    print(&amp;quot;---&amp;quot;)
    sess.run(validation_init_op)
    try:
        while True:
            print(sess.run(next_element)) # [0 2 4] [ 6  8 10] [12 14 16]
    except tf.errors.OutOfRangeError:
        pass
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;feedable&#34;&gt;feedable&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Iterator#from_string_handle&#34;&gt;Iterator.from_string_handle()&lt;/a&gt;でplaceholderとtypeとshapeから作れるfeedableイテレータは
reinitializableと同じく複数のDatasetを切り替えることができるが、
初期化はせずrunごとにDatasetのhandleをplaceholderの値として渡せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;training_dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)))
validation_dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)) * 2)

handle = tf.placeholder(tf.string, shape=[])
iterator = tf.data.Iterator.from_string_handle(
    handle, training_dataset.output_types, training_dataset.output_shapes)
next_element = iterator.get_next()

training_iterator = training_dataset.make_one_shot_iterator()
validation_iterator = validation_dataset.make_one_shot_iterator()

with tf.Session() as sess:
    sess.run(training_init_op)
    training_handle = sess.run(training_iterator.string_handle())
    validation_handle = sess.run(validation_iterator.string_handle())
    try:
        while True:
            print(sess.run(next_element, feed_dict={handle: training_handle})) # [0 1 2] [3 4 5] [6 7 8]
    except tf.errors.OutOfRangeError:
        pass
    try:
        while True:
            print(sess.run(next_element, feed_dict={handle: validation_handle})) # [0 2 4] [ 6  8 10] [12 14 16]
    except tf.errors.OutOfRangeError:
        pass
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>同じ/異なるオリジンのiframeの中からできること</title>
          <link>https://www.sambaiz.net/article/194/</link>
          <pubDate>Wed, 24 Oct 2018 23:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/194/</guid>
          <description>

&lt;p&gt;同じ/異なるオリジンのiframeの中からできることを確認する。同じ&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/Security/Same-origin_policy&#34;&gt;オリジン&lt;/a&gt;というのは
ホストだけではなくプロトコルやポート番号も同じということ。
Web広告では非同期のレンダリングや、CSSやJSのグローバルスコープといったページ全体に及ぶ影響の分離のためによく使われている。&lt;/p&gt;

&lt;h2 id=&#34;検証用ページ&#34;&gt;検証用ページ&lt;/h2&gt;

&lt;p&gt;3つのiframeがあるページを作った。
それぞれabout:blankで動的に書き込むのと、同じオリジンのhtmlを参照しているものと、異なるオリジンのhtmlを参照しているもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;style type=&amp;quot;text/css&amp;quot;&amp;gt;
p{
  width:100px;
  height:100px;
  background:#999;
}
&amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
  &amp;lt;p&amp;gt;parent&amp;lt;/p&amp;gt;
  &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;about:blank&amp;quot; id=&amp;quot;if1&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
    var parentValue = &amp;quot;PARENT&amp;quot;;
    window.addEventListener(&amp;quot;message&amp;quot;, (event) =&amp;gt; {
      console.log(`message from ${event.origin}: ${event.data}`);
    }, false);
  &amp;lt;/script&amp;gt;

  &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;./iframe.html&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;https://*****.ngrok.io/iframe.html&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;./index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1つ目のiframeの中にscriptタグなどを書き込むJS。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.js
const el = document.getElementById(&amp;quot;if1&amp;quot;);
const doc = el.contentDocument;

const p = doc.createElement(&#39;p&#39;);
p.textContent = &amp;quot;child&amp;quot;;
doc.body.appendChild(p);

var scriptTag = doc.createElement(&#39;script&#39;);
const script = `
    var childValue = &amp;quot;CHILD&amp;quot;;
    console.log(location.href + &amp;quot; parentValue: &amp;quot; + window.parent.parentValue);
    window.frameElement.style.width = &#39;400px&#39;;
`;
scriptTag.innerHTML = script;
doc.body.appendChild(scriptTag);
console.log(`${location.href} childValue: ${el.contentWindow.childValue}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;iframeのsrcで参照するhtml。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat iframe.html
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
  &amp;lt;p&amp;gt;child&amp;lt;/p&amp;gt; 
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
    try{
      console.log(`${location.href} parentValue: ${window.parent.parentValue}`);
    } catch (e) {
      console.log(`${location.href} ${e}`);
    }
    window.parent.postMessage(&amp;quot;aaaa&amp;quot;, &amp;quot;*&amp;quot;);
    if (window.frameElement) {
      window.frameElement.style.width = &#39;400px&#39;;
    } else {
      console.log(`${location.href} window.frameElement is ${window.frameElement}`);
    }
  &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行&#34;&gt;実行&lt;/h2&gt;

&lt;p&gt;異なるホストにするためngrokを立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install http-server -g
$ http-server -p 3000
$ ngrok http 3000
$ open http://localhost:3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/194.png&#34; alt=&#34;検証用ページ&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;about:blank parentValue: PARENT
http://localhost:3000/ childValue: CHILD
http://localhost:3000/iframe.html parentValue: PARENT
message from http://localhost:3000: aaaa
https://*****.ngrok.io/iframe.html SecurityError: Blocked a frame with origin &amp;quot;https://*****.ngrok.io&amp;quot; from accessing a cross-origin frame.
https://*****.ngrok.io/iframe.html window.frameElement is null
message from http://localhost:3000: 
message from https://*****.ngrok.io: aaaa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;about:blank&lt;/code&gt;は表示ページと同じオリジンになるので、srcが同じオリジンの場合の挙動と同じでparentの値やiframeを参照して書き換えることもできる。
Web広告の標準規格を定める&lt;a href=&#34;https://www.iab.com/&#34;&gt;IAB&lt;/a&gt;の&lt;a href=&#34;https://www.iab.com/wp-content/uploads/2015/09/rich_media_ajax_best_practices.pdf&#34;&gt;Best Practices for Rich Media Ads&lt;/a&gt;で言及されているFriendly IFrame(FIF)は
about:brankのiframeの中に、対象スクリプトをsrcとしたscriptタグを入れて&lt;code&gt;inDapIF = true&lt;/code&gt;を定義してFIF内で実行されていることを通知するというもの。これによって広告のスクリプトにdocument.write()のようなページの描画に問題を起こし得るコードが含まれていても、iframeで影響を分離しながら
計測や表示領域の拡大縮小などはさせることができる。裏を返せばやろうと思えば何でもできるので悪意のあるスクリプトに対する防衛策にはならない。&lt;/p&gt;

&lt;p&gt;オリジンが異なる場合は値を参照しようとするとブロックされる。
ただしparentのwindow自体は参照できるのでpostMessage()で外側とやりとりすることはできる。
これを利用したのが同じくIABが定めた&lt;a href=&#34;https://www.iab.com/wp-content/uploads/2014/08/SafeFrames_v1.1_final.pdf&#34;&gt;SafeFrame&lt;/a&gt;で、
iframeを異なるオリジンにして直接外側に干渉させず、SafeFrame APIを介して拡大などさせることでセキュアにする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/156/&#34;&gt;ブラウザのwindow間の値渡し - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/nag4/items/de044690dd227865a134&#34;&gt;SafeFrame ver1.1 仕様読解、媒体側の実装例&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goで高速にJSONを扱うライブラリeasyjsonとfastjson</title>
          <link>https://www.sambaiz.net/article/193/</link>
          <pubDate>Wed, 24 Oct 2018 01:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/193/</guid>
          <description>

&lt;h2 id=&#34;easyjson-https-github-com-mailru-easyjson&#34;&gt;&lt;a href=&#34;https://github.com/mailru/easyjson&#34;&gt;easyjson&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;easyjsonは次のようなstructごとのコードを自動生成してReflectionなしで高速にJSON Marshal/Unmarshalできるようにするライブラリ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/mailru/easyjson/...
$ cat struct.go
package a

type Foo struct {
        A string `json:&amp;quot;a,omitempty&amp;quot;`
        B *Bar
}

type Bar struct {
        C []int          `json:&amp;quot;c&amp;quot;`
        D map[string]int `json:&amp;quot;d&amp;quot;`
}

$ easyjson -all struct.go
$ cat struct_easyjson.go
...
func easyjson9f2eff5fEncodeGithubComSambaizBenchjsonA(out *jwriter.Writer, in Foo) {
	out.RawByte(&#39;{&#39;)
	first := true
	_ = first
	if in.A != &amp;quot;&amp;quot; {
		const prefix string = &amp;quot;,\&amp;quot;a\&amp;quot;:&amp;quot;
		if first {
			first = false
			out.RawString(prefix[1:])
		} else {
			out.RawString(prefix)
		}
		out.String(string(in.A))
	}
	{
		const prefix string = &amp;quot;,\&amp;quot;B\&amp;quot;:&amp;quot;
		if first {
			first = false
			out.RawString(prefix[1:])
		} else {
			out.RawString(prefix)
		}
		if in.B == nil {
			out.RawString(&amp;quot;null&amp;quot;)
		} else {
			(*in.B).MarshalEasyJSON(out)
		}
	}
	out.RawByte(&#39;}&#39;)
}
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;標準のencoding/jsonと同じ様に使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x := a.Foo{
    B: &amp;amp;a.Bar{
        C: []int{1, 2, 3},
    },
}
b, err := easyjson.Marshal(x)
if err != nil {
    panic(err)
}
fmt.Println(string(b)) // {&amp;quot;B&amp;quot;:{&amp;quot;c&amp;quot;:[1,2,3],&amp;quot;d&amp;quot;:null}}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fastjson-https-github-com-valyala-fastjson&#34;&gt;&lt;a href=&#34;https://github.com/valyala/fastjson&#34;&gt;fastjson&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;fastjsonはstructを介さず、ParseしてGetIntのような関数で取り出す。
そのため持ち回すとデータ形式が分からなくなるが、ピンポイントで値を取りたい場合や曖昧な型のJSONを扱う際は使いやすいかもしれない。
MarshalToの引数には[]byteを渡せてnilを渡すとallocateされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var p fastjson.Parser
value, err := p.Parse(`{&amp;quot;a&amp;quot;: {&amp;quot;b&amp;quot;: 100, &amp;quot;c&amp;quot;: null}}`)
fmt.Println(value.GetInt(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;)) // 100
fmt.Println(value.GetStringBytes(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;)) // []
fmt.Println(string(value.MarshalTo(nil))) // {&amp;quot;a&amp;quot;:{&amp;quot;b&amp;quot;:100,&amp;quot;c&amp;quot;:null}}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ベンチマーク&#34;&gt;ベンチマーク&lt;/h2&gt;

&lt;p&gt;簡単な例でベンチマークを取ってみる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/47/&#34;&gt;go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;encoding/json&amp;quot;
	&amp;quot;strings&amp;quot;
	&amp;quot;testing&amp;quot;

	&amp;quot;github.com/mailru/easyjson&amp;quot;
	&amp;quot;github.com/sambaiz/benchjson/a&amp;quot;
	&amp;quot;github.com/valyala/fastjson&amp;quot;
)

var target = a.Foo{
	A: strings.Repeat(&amp;quot;ABCD&amp;quot;, 100),
	B: &amp;amp;a.Bar{
		C: []int{1, 2, 3},
		D: map[string]int{
			&amp;quot;AAA&amp;quot;: 100,
			&amp;quot;BBB&amp;quot;: 200,
			&amp;quot;CCC&amp;quot;: 300,
			&amp;quot;DDD&amp;quot;: 400,
		},
	},
}

func targetBytes() []byte {
	dat, err := easyjson.Marshal(target)
	if err != nil {
		panic(err)
	}
	return dat
}

func BenchmarkEncodingJSONMarshal(b *testing.B) {
	for i := 0; i &amp;lt; b.N; i++ {
		_, err := json.Marshal(target)
		if err != nil {
			b.Error(err)
		}
	}
}

func BenchmarkEasyJSONMarshal(b *testing.B) {
	for i := 0; i &amp;lt; b.N; i++ {
		_, err := easyjson.Marshal(target)
		if err != nil {
			b.Error(err)
		}
	}
}

func BenchmarkFastJSONMarshalTo(b *testing.B) {
	dat := targetBytes()
	var p fastjson.Parser
	value, err := p.ParseBytes(dat)
	if err != nil {
		b.Error(err)
	}
	b.ResetTimer()
	for i := 0; i &amp;lt; b.N; i++ {
		value.MarshalTo(nil)
	}
}

func BenchmarkEncodingJSONUnmarshal(b *testing.B) {
	dat := targetBytes()
	v := a.Foo{}
	b.ResetTimer()
	for i := 0; i &amp;lt; b.N; i++ {
		err := json.Unmarshal(dat, &amp;amp;v)
		if err != nil {
			b.Error(err)
		}
	}
}

func BenchmarkEasyJSONUnmarshal(b *testing.B) {
	dat := targetBytes()
	v := a.Foo{}
	b.ResetTimer()
	for i := 0; i &amp;lt; b.N; i++ {
		err := easyjson.Unmarshal(dat, &amp;amp;v)
		if err != nil {
			b.Error(err)
		}
	}
}

func BenchmarkFastJSONParse(b *testing.B) {
	dat := targetBytes()
	var p fastjson.Parser
	b.ResetTimer()
	for i := 0; i &amp;lt; b.N; i++ {
		_, err := p.ParseBytes(dat)
		if err != nil {
			b.Error(err)
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確かにencoding/jsonと比べて格段に速い。適所で使っていきたい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test --bench .
goos: darwin
goarch: amd64
pkg: github.com/sambaiz/benchjson
BenchmarkEncodingJSONMarshal-4     	  300000	      4548 ns/op
BenchmarkEasyJSONMarshal-4         	 1000000	      1829 ns/op
BenchmarkFastJSONMarshalTo-4       	 3000000	       429 ns/op
BenchmarkEncodingJSONUnmarshal-4   	  300000	      5143 ns/op
BenchmarkEasyJSONUnmarshal-4       	 1000000	      1780 ns/op
BenchmarkFastJSONParse-4           	 5000000	       373 ns/op
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MLPと誤差逆伝搬法(Backpropagation)</title>
          <link>https://www.sambaiz.net/article/192/</link>
          <pubDate>Sun, 21 Oct 2018 19:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/192/</guid>
          <description>

&lt;p&gt;MLP(多層パーセプトロン)は入力層と出力層の間に隠れ層を重ねることによって、
ロジスティック回帰(単純パーセプトロン)ではできなかった非線形分離をできるようにしたニューラルネットワークモデル。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/191/&#34;&gt;ロジスティック回帰の尤度と交差エントロピー誤差と勾配降下法 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;入出力が&lt;code&gt;x&lt;/code&gt;、&lt;code&gt;y&lt;/code&gt;、層の数がLでl層目での重みとバイアスを&lt;code&gt;W^(l)&lt;/code&gt;, &lt;code&gt;b^(l)&lt;/code&gt;、活性化関数を&lt;code&gt;f^(l)&lt;/code&gt;、活性化関数適用前後を&lt;code&gt;u^(l)&lt;/code&gt;と&lt;code&gt;h^(l)&lt;/code&gt;とし、入力層を0層目とすると各層での演算は以下の式で表される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/192-1.png&#34; alt=&#34;各層での演算&#34; /&gt;&lt;/p&gt;

&lt;p&gt;活性化関数は非線形で微分可能な関数で、計算速度や勾配消失の面でReLUが最有力。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/133/&#34;&gt;ニューラルネットワークと活性化関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;各層の最適なWとbを探すのにロジスティック回帰と同様に勾配降下法を使うことができる。
誤差関数は分類の場合は交差エントロピーが、回帰の場合は平均二乗誤差(MSE, Mean Squared Error)
または外れ値に引っ張られづらくしたHuber損失などが使われる。&lt;/p&gt;

&lt;p&gt;隠れ層の勾配はそれより後ろの層での演算が影響するので、入力から出力への順伝搬に対して
出力から入力への逆伝播で誤差の情報を前の層に伝播させていく。これを誤差逆伝播法(Backpropagation)という。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/192-2.png&#34; alt=&#34;誤差逆伝播法&#34; /&gt;&lt;/p&gt;

&lt;p&gt;出力から遠くなればなるほど連鎖律が長くなっていくが、途中までは後ろの層と共通になっている。
ということで順伝搬時のhを保存しておき一つ後ろの層のWと誤差δを渡してやれば必要最小限の演算で済み、実行時間を短くすることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/192-3.png&#34; alt=&#34;l層での誤差δを使った逆伝播&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92-%E3%82%A2%E3%82%B9%E3%82%AD%E3%83%BC%E3%83%89%E3%83%AF%E3%83%B3%E3%82%B4-%E9%BB%92%E6%BB%9D-%E7%B4%98%E7%94%9F-ebook/dp/B07GQV1X76&#34;&gt;深層学習&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ロジスティック回帰の尤度と交差エントロピーと勾配降下法</title>
          <link>https://www.sambaiz.net/article/191/</link>
          <pubDate>Sun, 14 Oct 2018 23:28:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/191/</guid>
          <description>

&lt;h2 id=&#34;ロジスティック回帰&#34;&gt;ロジスティック回帰&lt;/h2&gt;

&lt;p&gt;単純パーセプトロンの活性化関数を0/1のステップ関数ではなく0~1のシグモイド関数σにしたモデルで、分類の確率を返すことができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/133/&#34;&gt;ニューラルネットワークと活性化関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;線形分離不可能な場合はうまくいかない。入力と出力の間に隠れ層があるMLPでは非線形分離もできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/192/&#34;&gt;MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;尤度関数と交差エントロピー誤差関数&#34;&gt;尤度関数と交差エントロピー誤差関数&lt;/h2&gt;

&lt;p&gt;尤度(likelihood)関数はXという事象が観察されたときにC=tである尤もらしさを表す関数。
例えば、6面ダイスを2回振って両方1の目が出た(X)ときに1の目が出る確率が1/6&amp;copy;である尤度は(&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;)*(&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;)=1/36となる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-likelihood.png&#34; alt=&#34;尤度関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;学習ではモデルのパラメータw,bを、各入力x(x1,x2,&amp;hellip;,xn)に対して正解であるC=tの尤度の和が最大になるように最適化していく。
通常のロジスティック回帰では二値分類を行うので正解データtは{0,1}とし、&lt;code&gt;P(C=1) = 1-P(C=0)&lt;/code&gt;となる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-l.png&#34; alt=&#34;ロジスティック回帰の尤度関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただ、このままだと積になっていて計算しづらいので、対数を取って和にして、
損失として扱うため負の数にする。これを交差エントロピー誤差関数という。
この値を最小化させるということは尤度を最大化させることになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-e.png&#34; alt=&#34;交差エントロピー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/134/&#34;&gt;自己情報量、エントロピー、KL情報量、交差エントロピー - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;勾配降下法&#34;&gt;勾配降下法&lt;/h2&gt;

&lt;p&gt;誤差をw,bでそれぞれ偏微分したのを引いてパラメータを更新していき、
勾配が0になるような値を探す。&lt;/p&gt;

&lt;p&gt;ηは学習率で正の小さな値にする。
大きすぎると収束しないが、小さすぎても収束に必要なステップ数が増え、さらに局所最適解で止まってしまう可能性が高まるので
最初は大きくして徐々に小さくしていったりする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-gradient.png&#34; alt=&#34;勾配降下法&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ほかに局所最適解で止まるのを避ける手法として、サンプル全体ではなく毎回異なる一部を使う(Minibatch)確率的勾配降下法(SGD: Stochastic Gradient Descent)や、SGDに慣性を追加したMomentumなどがある。&lt;/p&gt;

&lt;h2 id=&#34;多クラスロジスティック回帰&#34;&gt;多クラスロジスティック回帰&lt;/h2&gt;

&lt;p&gt;活性化関数をsoftmax関数にすると多クラス分類できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-softmax.png&#34; alt=&#34;多クラスでの確率&#34; /&gt;&lt;/p&gt;

&lt;p&gt;多クラスの場合の正解データtは{0,1,2,&amp;hellip;}といったようにはせず
正解のindexだけ1でほかは0のone-hot vectorで表し、尤度関数、交差エントロピー誤差関数は以下のようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-le2.png&#34; alt=&#34;多クラスでの尤度関数と交差エントロピー誤差関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;偏微分するとこうなる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-gradient2.png&#34; alt=&#34;交差エントロピー誤差関数の偏微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;あとは同様に勾配降下法でパラメータを更新していく。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3-%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0-TensorFlow%E3%83%BBKeras%E3%81%AB%E3%82%88%E3%82%8B%E6%99%82%E7%B3%BB%E5%88%97%E3%83%87%E3%83%BC%E3%82%BF%E5%87%A6%E7%90%86-%E5%B7%A3%E7%B1%A0-%E6%82%A0%E8%BC%94/dp/4839962510&#34;&gt;詳解 ディープラーニング ~TensorFlow・Kerasによる時系列データ処理~&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesでliveness/readinessProbeのexec commandが実行される流れ</title>
          <link>https://www.sambaiz.net/article/190/</link>
          <pubDate>Sat, 06 Oct 2018 16:32:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/190/</guid>
          <description>&lt;p&gt;Kubernetesの&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/&#34;&gt;liveness/readinessProbe&lt;/a&gt;
はPodが生きているか/リクエストを受けられるかの判定で、
後者はアプリケーションの起動に時間がかかる場合などに使われる。
ヘルスチェックのようなエンドポイントを叩くのはhttpGetでできるが、任意のcommandを実行することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
    httpHeaders:
    - name: X-Custom-Header
      value: Awesome
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Manifestに書かれたProbeは、
各ノードで動いている&lt;a href=&#34;https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/&#34;&gt;kubelet&lt;/a&gt;が
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/kubelet.go#L1983&#34;&gt;Podが追加されたとき&lt;/a&gt;にworkerを
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/prober/prober_manager.go#L157&#34;&gt;作って&lt;/a&gt;
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/prober/prober.go#L147&#34;&gt;runProbe()&lt;/a&gt;で実行させている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if p.Exec != nil {
    glog.V(4).Infof(&amp;quot;Exec-Probe Pod: %v, Container: %v, Command: %v&amp;quot;, pod, container, p.Exec.Command)
    command := kubecontainer.ExpandContainerCommandOnlyStatic(p.Exec.Command, container.Env)
    return pb.exec.Probe(pb.newExecInContainer(container, containerID, command, timeout))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずcommandに含まれる&lt;code&gt;$( )&lt;/code&gt;で囲まれた文字列を
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/third_party/forked/golang/expansion/expand.go#L38&#34;&gt;Expand()&lt;/a&gt;
で存在すればcontainerのenvの値に置き換える。&lt;/p&gt;

&lt;p&gt;その後、
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/kuberuntime/kuberuntime_container.go#L778&#34;&gt;RunInContainer()&lt;/a&gt;で、
コンテナランタイムがK8s標準のCRI(Container Runtime Interface)に対応している場合はその&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/apis/cri/services.go#L50&#34;&gt;API&lt;/a&gt;の、
対応していない場合は~shimパッケージのExecSync()が呼ばれ、コンテナ内でcommandを実行させて結果を受け取り、終了コードが0でなければエラーとする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$( )&lt;/code&gt;でenvの値が使えることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl config use-context docker-for-desktop
$ cat test.yaml
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: &amp;quot;test&amp;quot;
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: &amp;quot;test&amp;quot;
    spec:
      containers:
        - name: &amp;quot;test&amp;quot;
          image: &amp;quot;alpine&amp;quot;
          command: [&amp;quot;top&amp;quot;]
          env:
          - name: TEST
            value: &amp;quot;foobar&amp;quot;
          ports:
          - containerPort: 5000
            name: grpc
          readinessProbe:
            exec:
              command:
              - test
              - $(TEST)
              - =
              - foobar
            initialDelaySeconds: 0
            timeoutSeconds: 1

$ kubectl apply test.yaml
$ kubectl describe pod $(kubectl get pods -l app=test -o jsonpath=&#39;{.items[0].metadata.name}&#39;)
test-85994ddf4d-gpxpq       1/1       Running   0          9s
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLのtime_zoneとgo-sql-driver/mysqlの設定</title>
          <link>https://www.sambaiz.net/article/189/</link>
          <pubDate>Tue, 02 Oct 2018 22:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/189/</guid>
          <description>

&lt;p&gt;MySQLのtime_zoneとgo-sql-driver/mysqlの設定による挙動を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; select version();
    +-----------+
    | version() |
    +-----------+
    | 5.7.21    |
    +-----------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;タイムゾーンがロードされていない場合はロードする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; select count(*) from mysql.time_zone \\G;
*************************** 1. row ***************************
count(*): 0

$ mysql_tzinfo_to_sql /usr/share/zoneinfo/ | mysql -u root mysql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;time_zoneはデフォルト値のSYSTEM。つまりJSTで、my.cnfのdefault-time-zoneで変更できる。
NOW()もJSTの時間を返している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; show variables like &#39;%time_zone%&#39;;
+------------------+--------+
| Variable_name    | Value  |
+------------------+--------+
| system_time_zone | JST    |
| time_zone        | SYSTEM |
+------------------+--------+

&amp;gt; SELECT NOW();
mysql&amp;gt; SELECT NOW() \G;
*************************** 1. row ***************************
NOW(): 2018-10-02 20:26:29
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DATETIMEはそのまま格納され返される。
TIMESTAMPはUTCに変換して格納され、
返すときにtime_zoneに&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/time-zone-support.html&#34;&gt;変換される&lt;/a&gt;。
したがってtime_zoneを変更するとDATETIMEは変わらず、TIMESTAMPは変わる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; CREATE TABLE t (
    dt DATETIME,
    ts TIMESTAMP
);
&amp;gt; INSERT INTO t VALUES (NOW(), NOW());
&amp;gt; select * from t \G;
*************************** 1. row ***************************
dt: 2018-10-02 20:27:13
ts: 2018-10-02 20:27:13

&amp;gt; SET SESSION time_zone = &amp;quot;UTC&amp;quot;;
&amp;gt; select NOW() \G;
*************************** 1. row ***************************
NOW(): 2018-10-02 11:27:56

&amp;gt; select * from t \G;
*************************** 1. row ***************************
dt: 2018-10-02 20:27:13
ts: 2018-10-02 11:27:13
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;go-sql-driver-mysql&#34;&gt;go-sql-driver/mysql&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/go-sql-driver/mysql&#34;&gt;go-sql-driver/mysql&lt;/a&gt;で
Data Source Nameに&lt;a href=&#34;https://github.com/go-sql-driver/mysql#loc&#34;&gt;loc&lt;/a&gt;とtime_zoneを付けて実行してみる。
time.Localの影響を確認するためUTCでもJSTでもない&lt;code&gt;US/Alaska&lt;/code&gt;にしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;database/sql&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;math&amp;quot;
    &amp;quot;time&amp;quot;

    _ &amp;quot;github.com/go-sql-driver/mysql&amp;quot;
)
    
const format = &amp;quot;2006-01-02 15:04:05 Z0700&amp;quot;
    
func main() {
    var err error
    if time.Local, err = time.LoadLocation(&amp;quot;US/Alaska&amp;quot;); err != nil {
        panic(err)
    }
    now := time.Now()
    fmt.Printf(&amp;quot;%15s: %s\n&amp;quot;, &amp;quot;time.Now()&amp;quot;, now.Format(format))
    fmt.Println(&amp;quot;* none&amp;quot;)
    run(now, &amp;quot;root:@/hoge?parseTime=true&amp;quot;)
    fmt.Println(&amp;quot;* loc (mysql&#39;s timezone != Local timezone)&amp;quot;)
    run(now, &amp;quot;root:@/hoge?parseTime=true&amp;amp;loc=Local&amp;quot;)
    fmt.Println(&amp;quot;* loc &amp;amp; time_zone&amp;quot;)
    run(now, &amp;quot;root:@/hoge?parseTime=true&amp;amp;loc=Local&amp;amp;time_zone=%27US%2FAlaska%27&amp;quot;)
}

func run(now time.Time, src string) {
    db, err := sql.Open(&amp;quot;mysql&amp;quot;, src)
    if err != nil {
        panic(err)
    }
    defer db.Close()

    if _, err := db.Exec(&amp;quot;DELETE FROM t&amp;quot;); err != nil {
        panic(err)
    }

    if _, err := db.Exec(&amp;quot;INSERT INTO t VALUES (NOW(), NOW())&amp;quot;); err != nil {
        panic(err)
    }

    if _, err := db.Exec(&amp;quot;INSERT INTO t VALUES (?, ?)&amp;quot;, now, now); err != nil {
        panic(err)
    }

    rows, err := db.Query(&amp;quot;SELECT dt, ts FROM t&amp;quot;)
    if err != nil {
        panic(err)
    }
    i := 0
    title := []string{&amp;quot;mysql NOW()&amp;quot;, &amp;quot;go time.Now()&amp;quot;}
    for rows.Next() {
        var datetime, timestamp time.Time
        if err := rows.Scan(&amp;amp;datetime, &amp;amp;timestamp); err != nil {
            panic(err)
        }
        fmt.Printf(&amp;quot;%15s: %s, %s -&amp;gt; %v\n&amp;quot;,
            title[i],
            datetime.Format(format),
            timestamp.Format(format),
            math.Abs(float64(datetime.Unix()-now.Unix())) &amp;lt; 10,
        )
        i++
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;locはtime.Timeのタイムゾーンで、付けないとUTCになる。
これはMySQLサーバーのtime_zoneには影響せず、NOW()の値はLocalと異なりJSTなので値がおかしくなる。
一方、time.Now()の方はタイムゾーンが考慮されているので値自体は正しい。
time_zoneを付けると&lt;code&gt;SET time_zone&lt;/code&gt;してくれてNOW()の値も正しくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go run main.go
        time.Now(): 2018-10-02 03:43:13 -0800
* none
    mysql NOW(): 2018-10-02 20:43:13 Z, 2018-10-02 20:43:13 Z -&amp;gt; false
    go time.Now(): 2018-10-02 11:43:14 Z, 2018-10-02 11:43:14 Z -&amp;gt; true
* loc (mysql&#39;s timezone != Local timezone)
    mysql NOW(): 2018-10-02 20:43:13 -0800, 2018-10-02 20:43:13 -0800 -&amp;gt; false
    go time.Now(): 2018-10-02 03:43:14 -0800, 2018-10-02 03:43:14 -0800 -&amp;gt; true
* loc &amp;amp; time_zone
    mysql NOW(): 2018-10-02 03:43:13 -0800, 2018-10-02 03:43:13 -0800 -&amp;gt; true
    go time.Now(): 2018-10-02 03:43:14 -0800, 2018-10-02 03:43:14 -0800 -&amp;gt; true
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PythonのType Hintsとmypy</title>
          <link>https://www.sambaiz.net/article/188/</link>
          <pubDate>Sun, 30 Sep 2018 14:13:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/188/</guid>
          <description>

&lt;p&gt;動的型付け言語であるPythonで型アノテーションを書けるようにするための構文。
&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/&#34;&gt;PEP 484&lt;/a&gt;で提案され、Python 3.5で実装された。
実行には影響せず、&lt;a href=&#34;https://github.com/python/mypy&#34;&gt;mypy&lt;/a&gt;のようなツールで静的解析したりするために使われる。&lt;/p&gt;

&lt;p&gt;mypyをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python -m pip install -U mypy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のように引数と返り値に型を書くと、型が誤っている場合にmypyで検知できるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat main.py
def foo(n: int) -&amp;gt; str:
  return str(n)

print(foo(3))
print(foo(&#39;3&#39;))

$ python main.py
3
3

$ mypy main.py
main.py:5: error: Argument 1 to &amp;quot;foo&amp;quot; has incompatible type &amp;quot;str&amp;quot;; expected &amp;quot;int&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、Type Hintsがないライブラリなどのために&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/#stub-files&#34;&gt;Stub&lt;/a&gt;ファイルを別に作って型を書くこともできるようにもなっている。デフォルトではStubがないモジュールはエラーになってしまうので必要に応じて&lt;a href=&#34;https://mypy.readthedocs.io/en/latest/running_mypy.html#ignore-missing-imports&#34;&gt;ignore_missing_import&lt;/a&gt;する。
mypy.iniやsetup.cfgに設定を書くと自動で&lt;a href=&#34;https://mypy.readthedocs.io/en/latest/config_file.html#config-file&#34;&gt;使われる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat main.py
import numpy as np

$ mypy main.py
main.py:1: error: No library stub file for module &#39;numpy&#39;
main.py:1: note: (Stub files are from https://github.com/python/typeshed)

$ vi mypy.ini
[mypy]
[mypy-numpy]
ignore_missing_imports = True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VSCode上でもmypyを有効にすると表示されるようになる。FormatterやLintの設定と併せて有効にしておくとよい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/125/&#34;&gt;PythonのLintとFormatter - sambagiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;python.linting.mypyEnabled&amp;quot;: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/188.png&#34; alt=&#34;VSCodeでの表示&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;callable-https-www-python-org-dev-peps-pep-0484-callable&#34;&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/#callable&#34;&gt;Callable&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Callable[[引数], 返り値]のように書く。引数を&amp;hellip;にすると返り値だけをチェックさせることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from typing import Callable

def foo(f: Callable[[int], None]) -&amp;gt; None:
  f(1)

def bar(f: Callable[..., None]) -&amp;gt; None:
  f(1)

def f1(x: int):
  print(x)

def f2(x: str):
  print(x)

foo(f1) # ok
foo(f2) # error: Argument 1 to &amp;quot;foo&amp;quot; has incompatible type &amp;quot;Callable[[str], Any]&amp;quot;; expected &amp;quot;Callable[[int], None]&amp;quot;
bar(f1) # ok
bar(f2) # ok
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;generics-https-www-python-org-dev-peps-pep-0484-generics&#34;&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/#generics&#34;&gt;Generics&lt;/a&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;from typing import Dict
from typing import TypeVar, Generic

T = TypeVar(&#39;T&#39;)

class Foo(Generic[T]):
  def __init__(self, v: T) -&amp;gt; None:
    self.v = v
  
  def getV(self) -&amp;gt; T:
    return self.v

m: Dict[str, Foo[int]] = {&#39;a&#39;: Foo(1)}
m2: Dict[str, Foo[str]] = {&#39;a&#39;: Foo(&#39;1&#39;)}

def bar(m: Dict[str, Foo[int]], key: str) -&amp;gt; Foo[int]:
  return Foo(m[key]).getV()

def bar2(m: Dict[str, Foo[int]], key: str) -&amp;gt; Foo[str]:
  return Foo(m[key]).getV() # error: Incompatible return value type (got &amp;quot;Foo[int]&amp;quot;, expected &amp;quot;Foo[str]&amp;quot;)

bar(m, &#39;a&#39;)
bar(m2, &#39;a&#39;) # error: Argument 1 to &amp;quot;bar&amp;quot; has incompatible type &amp;quot;Dict[str, Foo[str]]&amp;quot;; expected &amp;quot;Dict[str, Foo[int]]&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TypeVarは&lt;code&gt;TypeVar(&#39;T&#39;, int, float)&lt;/code&gt;のように取り得る型を指定したり、
&lt;code&gt;TypeVar(&#39;T&#39;, bound=Employee)&lt;/code&gt;のようにupper boundを指定する(そのサブクラスが取り得る型)こともできる。
また、取った型はデフォルトでinvariant(非変, そのスーパークラスもサブクラスも許容しない)として扱われるが、
&lt;code&gt;covariant=True&lt;/code&gt;にするとcovariant(共変, サブクラスは許容する)として扱うことができる。&lt;/p&gt;

&lt;h3 id=&#34;union-types-https-www-python-org-dev-peps-pep-0484-union-types&#34;&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/#union-types&#34;&gt;Union types&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;いずれかの型を取るUnion typeも書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from typing import Union, Sequence

def foo(e: Union[int, Sequence[int]]) -&amp;gt; Sequence[int]:
    if isinstance(e, int):
      return [e]
    return e

print(foo(1))
print(foo([1]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Union[T, None]はOptional[T]と同じ。Noneをデフォルト引数にすると自動でOptional[T]として扱われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def foo(e: int = None):
    if e:
      print(e)
foo(1)
foo()
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>numpyの関数</title>
          <link>https://www.sambaiz.net/article/187/</link>
          <pubDate>Sun, 23 Sep 2018 23:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/187/</guid>
          <description>

&lt;h2 id=&#34;ndarrayの生成&#34;&gt;ndarrayの生成&lt;/h2&gt;

&lt;p&gt;ndarrayはnumpyの多次元の配列を表すオブジェクトで、[start:stop:step, &amp;hellip;]の
&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html&#34;&gt;index&lt;/a&gt;でアクセスできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.array([[1, 2, 3, 4], [2, 4, 6, 8]])
print(x[0, 1]) # 2
print(x[0,1:-1]) # [2 3]
print(x[:,2]) # [3 6]
print(x[:,::2]) # [[1 3] [2 6]]
print(x[1,::-1]) # [8 6 4 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html&#34;&gt;array()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.fromiter.html&#34;&gt;fromiter()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;arrayやiteratableオブジェクトからndarrayを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.array([1, 2, 3])) # [1 2 3]

def generate():
    for x in range(3):
        yield x
x = np.fromiter(generate(), dtype=float)
print(x) # [ 0.  1.  2.]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html&#34;&gt;zeros()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html&#34;&gt;ones()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.full.html&#34;&gt;full()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;引数で渡したshapeを特定の値で埋めたndarrayを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.zeros(5)) # [ 0.  0.  0.  0.  0.]
print(np.ones((2,2))) # [[ 1.  1.] [ 1.  1.]]
print(np.full((2, 3), 2)) # [[2 2 2] [2 2 2]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html&#34;&gt;arange()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html&#34;&gt;linspace()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Python built-inのrange()のndarray版と、startからstopまで等間隔なndarrayを生成する関数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.arange(5)) # [0 1 2 3 4]
print(np.linspace(2.0, 3.0, num=5)) # [ 2.    2.25  2.5   2.75  3.  ]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.identity.html&#34;&gt;identity()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html&#34;&gt;eye()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;diagonal(対角)は1,それ以外は0の単位行列を生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.identity(3)) # [[ 1.  0.  0.] [ 0.  1.  0.] [ 0.  0.  1.]]
print(np.eye(3)) # [[ 1.  0.  0.] [ 0.  1.  0.] [ 0.  0.  1.]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.random.html&#34;&gt;random.random()&lt;/a&gt;: &lt;code&gt;[0.0, 1.0)&lt;/code&gt;で連続一様分布&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html&#34;&gt;random.randint()&lt;/a&gt;: &lt;code&gt;[low, high)&lt;/code&gt;で離散一様分布&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.uniform.html&#34;&gt;random.uniform()&lt;/a&gt;: &lt;code&gt;[low, high)&lt;/code&gt;で連続一様分布&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ランダム値のndarrayを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.random.random((2, 2)) # [[ 0.84157926  0.77701369] [ 0.92937916  0.41447905]]
print(np.random.randint(low=5, high=10, size=(2, 2))) # [[9 5] [7 7]]
print(np.random.uniform(low=5, high=10, size=(2,2))) # [[ 9.72222125  6.07259325] [ 7.24174366  9.27801853]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;加工&#34;&gt;加工&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.astype.html&#34;&gt;astype()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;キャストする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.array([1, 2, 2.5]).astype(int)) # [1 2 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html&#34;&gt;reshape()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.flatten.html&#34;&gt;flatten()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;shapeを変更するのと、1次元にする関数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2, 2))
print(x) # [[0 1] [2 3]]
print(x.flatten()) # [0 1 2 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html&#34;&gt;pad()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;paddingする。modeで埋まる値が決まる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from math import ceil
def padding_to(array, width, height):
  return np.pad(array, pad_width=(
        (int((height-array.shape[0])/2), int(ceil((height-array.shape[0])/2))), 
        (int((width-array.shape[1])/2), int(ceil((width-array.shape[1])/2)))), 
                mode=&#39;constant&#39;, constant_values=0)

print(padding_to(np.array([[2, 4], [6, 8]]), 8, 5))
&amp;quot;&amp;quot;&amp;quot;
[[0 0 0 0 0 0 0 0]
 [0 0 0 2 4 0 0 0]
 [0 0 0 6 8 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
&amp;quot;&amp;quot;&amp;quot;

print(np.pad(np.arange(9).reshape(3,3), pad_width=1, mode=&#39;edge&#39;))
&amp;quot;&amp;quot;&amp;quot;
[[0 0 1 2 2]
 [0 0 1 2 2]
 [3 3 4 5 5]
 [6 6 7 8 8]
 [6 6 7 8 8]]
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.diag.html&#34;&gt;diag()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.diagonal.html&#34;&gt;diagonal()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;対角の値を返したり、対角行列にしたりする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(9).reshape((3,3))
print(np.diag(x)) # [0 4 8]
print(np.diag(np.diag(x))) # [[0 0 0] [0 4 0] [0 0 8]]
print(np.diag(np.diag(np.diag(x)))) # [0 4 8]

print(np.diagonal(x)) # [0 4 8]
print(np.diagonal(np.diagonal(x))) # diag requires an array of at least two dimensions
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.sort.html&#34;&gt;sort()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html&#34;&gt;argsort()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argpartition.html&#34;&gt;argpartition()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.permutation.html&#34;&gt;random.permutation()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ソートとシャッフル。argsort()とargpartition()はindexを返す。
argpartition()はkth番目の値で分けるもの(下の例だと4番目に小さいindex 0)で、パーティション内の順序は保証されないが、n番目のindexだけ欲しい場合はargsort()より速い。
random.permutation()はPandasの行をシャッフルするときにも使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/170/&#34;&gt;Pandasの操作 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.random.random((3, 3))
print(np.sort(x)) 
&amp;quot;&amp;quot;&amp;quot;
[[ 0.14366067  0.41558783  0.7584969 ] 
 [ 0.1395897   0.78905376  0.89709119]
 [ 0.3235212   0.82675995  0.95140141]]
&amp;quot;&amp;quot;&amp;quot;

x2 = np.array([3, 1, 2, 1, 4, 5])
print(np.argsort(x2)) # [1 3 2 0 4 5]
print(np.argpartition(x2, 3)) # [3 2 1 0 4 5]

print(np.random.permutation(np.arange(5))) # [3 1 0 4 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html&#34;&gt;repeat()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html&#34;&gt;tile()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html&#34;&gt;unique()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;repeat()は各値を繰り返し、tile()は敷き詰める。unique()はユニークな値にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape(2,2)
print(np.repeat(x, 2)) # [0 0 1 1 2 2 3 3]
print(np.repeat(x, 2, axis=1)) # [[0 0 1 1] [2 2 3 3]]

print(np.tile(x, (3,2)))
&amp;quot;&amp;quot;&amp;quot;
[[0 1 0 1] 
 [2 3 2 3]
 [0 1 0 1]
 [2 3 2 3]
 [0 1 0 1]
 [2 3 2 3]]
&amp;quot;&amp;quot;&amp;quot;

x2 = np.repeat([np.repeat(np.arange(3), 2)], 2, axis=0)
print(x2) #  [[1 1 2 2 3 3] [1 1 2 2 3 3]]
print(np.unique(x2)) # [1 2 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.roll.html&#34;&gt;roll()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ローリングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.roll(np.arange(8).reshape(4, 2), 2, axis=0)) # [[4 5] [6 7] [0 1] [2 3]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.vstack.html&#34;&gt;vstack()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.hstack.html&#34;&gt;hstack()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;縦横に結合する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2, 2))
y = np.identity(2)
print(np.vstack((x, y))) 
&#39;&#39;&#39;
[[ 0.  1.] [ 2.  3.] 
 [ 1.  0.] [ 0.  1.]]
&#39;&#39;&#39;

print(np.hstack((x, y))) 
&#39;&#39;&#39;
[[ 0.  1.  1.  0.] 
 [ 2.  3.  0.  1.]]
&#39;&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.split.html&#34;&gt;split()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_split.html&#34;&gt;array_split()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分割する。array_split()はちょうど分けられなくてもエラーにしない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.split(np.arange(7), 3)) # ValueError: array split does not result in an equal division
print(np.array_split(np.arange(7),3)) # [array([0, 1, 2]), array([3, 4]), array([5, 6])]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html&#34;&gt;meshgrid()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;座標の値からndarrayを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x, y = np.meshgrid(np.linspace(0,1,5), np.linspace(0,1,5))
print(x)
&#39;&#39;&#39;
[[ 0.    0.25  0.5   0.75  1.  ]
 [ 0.    0.25  0.5   0.75  1.  ]
 [ 0.    0.25  0.5   0.75  1.  ]
 [ 0.    0.25  0.5   0.75  1.  ]
 [ 0.    0.25  0.5   0.75  1.  ]]
&#39;&#39;&#39;
print(y)
&#39;&#39;&#39;
[[ 0.    0.    0.    0.    0.  ]
 [ 0.25  0.25  0.25  0.25  0.25]
 [ 0.5   0.5   0.5   0.5   0.5 ]
 [ 0.75  0.75  0.75  0.75  0.75]
 [ 1.    1.    1.    1.    1.  ]]
&#39;&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.unpackbits.html&#34;&gt;unpackbits()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.packbits.html&#34;&gt;packbits()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;uint8のndarrayをバイナリの値に変換するのと、その逆。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.unpackbits(np.array([[8], [23]], dtype=np.uint8), axis=1)
print(x) # [[0 0 0 0 1 0 0 0] [0 0 0 1 0 1 1 1]]
print(np.packbits(x, axis=1)) # [[ 8] [23]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;比較&#34;&gt;比較&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.nonzero.html&#34;&gt;nonzero()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html&#34;&gt;where()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;0でないindexを返す。booleanのndarrayからTrueを抽出するのにも使える。
where()の第1引数は条件式で、第2引数と第3引数を渡すとそれぞれTrueとFalseの場合に置換される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.array([[1,0,0], [0,2,0], [1,1,0]])
print(np.nonzero(x)) # (array([0, 1, 2, 2]), array([0, 1, 0, 1])) =&amp;gt; [0, 0], [1, 1], [2, 0], [2, 1]
print(np.where(x)) # (array([0, 1, 2, 2]), array([0, 1, 0, 1]))
print(x[np.nonzero(x)]) # [1 2 1 1]

print(x &amp;gt; 1) # [[False False False] [False  True False] [False False False]]
print(x[np.nonzero(x &amp;gt; 1)]) # [2]

print(np.where(x == 1, x, 0)) # [[1 0 0] [0 0 0] [1 1 0]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html&#34;&gt;allclose()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_equal.html#numpy.array_equal&#34;&gt;array_equal()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一致する場合はTrueを返す。allclose()は誤差を許容する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [1e10,1e-8]
y = [1.00001e10,1e-9]
print(x == y) # False
print(np.allclose(x, y)) # True
print(np.array_equal(x, y)) # False

o = np.ones(3)
o2 = np.ones(4)
print(o == o2) # comparison failed
print(np.array_equal(o, o2)) # False
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.union1d.html&#34;&gt;union1d()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.intersect1d.html&#34;&gt;intersect1d()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.setdiff1d.html&#34;&gt;setdiff1d()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.setxor1d.html&#34;&gt;setxor1d()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;和、積、差集合と排他的論理和。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [1, 3, 4, 3]
y = [3, 1, 2, 1]
print(np.union1d(x, y)) # [1 2 3 4]
print(np.intersect1d(x, y)) # [1 3]
print(np.setdiff1d(x, y)) # [4]
print(np.setxor1d(x, y)) # [2 4]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.logical_and.html&#34;&gt;logical_and()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.all.html&#34;&gt;all()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.logical_or.html&#34;&gt;logical_or()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.any.html&#34;&gt;any()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.logical_not.html&#34;&gt;logical_not()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.logical_xor.html&#34;&gt;logical_xor()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AND,OR,NOT,XORしたbooleanの値を返す。all()とany()はarrayに対するANDとOR。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [True, False, True]
y = [False, False, True]
print(np.logical_and(x, y)) # [False False  True]
print(np.all([x, y, np.repeat([True], 3)], axis=0)) # [False False  True]
print(np.logical_or(x, y)) # [ True False  True]
print(np.any([x, y, np.repeat([True], 3)], axis=0)) # [ True  True  True]
print(np.logical_not(x)) # [False  True False]
print(np.logical_xor(x, y)) # [ True False False]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html&#34;&gt;bincount()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;正数の出現回数をカウントする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.bincount([0, 1, 2, 1, 2, 6, 1])) # [1 3 2 0 0 0 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;計算&#34;&gt;計算&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.add.html&#34;&gt;add()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html&#34;&gt;dot()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html&#34;&gt;matmul()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;和と内積(a・b)。和は+でも計算できるが、通常のarrayに使うと後ろに結合されてしまうのに注意。
&amp;ldquo;@&amp;ldquo;はmatmul()と同じで数値との積は計算できない。
&amp;ldquo;*&amp;ldquo;は&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.multiply.html&#34;&gt;multiply()&lt;/a&gt;で、要素ごとの積が返る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2, 2))

print([0, 1, 2] + [1, 2, 3]) # [0, 1, 2, 1, 2, 3]
print(x + x) # [[0 2] [4 6]]
print(np.add(x, x)) # [[0 2] [4 6]]

print(np.dot(np.ones((2,2)), np.ones((2,3)))) # [[ 2.  2.  2.] [ 2.  2.  2.]]
print(np.matmul(np.ones((2,2)), np.ones((2,3)))) # [[ 2.  2.  2.] [ 2.  2.  2.]]
print(np.ones((2,2)) @ np.ones((2,3))) # [[ 2.  2.  2.] [ 2.  2.  2.]]
print(np.ones((2,2)) * np.ones((2,3))) # operands could not be broadcast together with shapes (2,2) (2,3) 

print(np.dot(np.ones((2,2)), 2)) # [[ 2.  2.] [ 2.  2.]]
print(np.matmul(np.ones((2,2)), 2)) # Scalar operands are not allowed, use &#39;*&#39; instead
print(np.ones((2,2)) @ 2)  # Scalar operands are not allowed, use &#39;*&#39; instead
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.sqrt.html&#34;&gt;sqrt()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/routines.emath.html&#34;&gt;emath.sqrt()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;平方根を返す。emathの方は複素数が返る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.sqrt([4, 0, -4])) # [  2.   0.  nan]
print(np.emath.sqrt([4, 0, -4])) # [ 2.+0.j  0.+0.j  0.+2.j]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.sin.html&#34;&gt;sin()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.cos.html&#34;&gt;cos()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.tan.html&#34;&gt;tan()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.arcsin.html&#34;&gt;arcsin()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.arccos.html&#34;&gt;arccos()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.arctan.html&#34;&gt;arctan()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;三角関数と逆三角関数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from math import pi
x = np.linspace(-pi, pi, num=5)
print(np.sin(x)) # [ -1.22464680e-16  -1.00000000e+00   0.00000000e+00   1.00000000e+00  1.22464680e-16]
print(np.cos(x)) # [ -1.00000000e+00   6.12323400e-17   1.00000000e+00   6.12323400e-17 -1.00000000e+00]
print(np.tan(x)) # [  1.22464680e-16  -1.63312394e+16   0.00000000e+00   1.63312394e+16 -1.22464680e-16]

x2 = np.linspace(-1, 1, num=5)
print(np.arcsin(x2)) # [-1.57079633 -0.52359878  0.          0.52359878  1.57079633]
print(np.arccos(x2)) # [ 3.14159265  2.0943951   1.57079633  1.04719755  0.        ]
print(np.arctan(x2)) # [-0.78539816 -0.46364761  0.          0.46364761  0.78539816]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html&#34;&gt;exp()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.log.html&#34;&gt;log()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;指数と、eが底の自然対数(ln(x))。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 1, 2]
print(np.exp(x)) # [ 1.10517092  2.71828183  7.3890561 ]
print(np.log(x)) # [-2.30258509  0.          0.69314718]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.clip.html&#34;&gt;clip()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;minより小さな値はminに、maxより大きな値はmaxにする。log()の引数に0が渡るのを避けることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(2)
np.log(x) # RuntimeWarning: divide by zero encountered in log
x2 = np.clip(x, 1e-10, x)
print(x2) # [  1.00000000e-10   1.00000000e+00]
np.log(x2) # ok
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.min.html&#34;&gt;min()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmin.html&#34;&gt;argmin()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.max.html&#34;&gt;max()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html&#34;&gt;argmax()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html&#34;&gt;sum()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html&#34;&gt;mean()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.average.html&#34;&gt;average()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最小、最大、合計、平均。argmin()とargmax()はindexを返し、average()は重みを付けられる。average以外はx.min()のように呼ぶこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2, 2))
print(np.min(x)) # 0 
print(np.max(x)) # 3
print(np.argmax(x)) # 3
print(np.sum(x)) # 6
print(np.mean(x)) # 1.5
print(np.average(x, weights=np.array([[0, 1], [4, 1]]))) # 2.0 &amp;lt;= (1 * 1 + 2 * 4 + 3 * 1) / (1 + 4 + 1) 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.cumsum.html&#34;&gt;cumsum()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.diff.html&#34;&gt;diff()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;累積和と前の値との差。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(9).reshape((3, 3))
print(np.cumsum(x, axis=1)) # [[ 0  1  3] [ 3  7 12] [ 6 13 21]]
print(np.diff(x, axis=1)) # [[1 1] [1 1] [1 1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ceil.html&#34;&gt;ceil()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.floor.html&#34;&gt;floor()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.trunc.html&#34;&gt;trunc()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.absolute.html&#34;&gt;abs()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.copysign.html&#34;&gt;copysign()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;切り上げ、切り捨てと絶対値。floor(-2.5)は-3.0になり、trunc(-2.5)は-2.0になる。
copysign()は第2引数の符号を第1引数にコピーする。
exercisesでは&lt;code&gt;np.copysign(np.ceil(np.abs(Z)), Z)&lt;/code&gt;のようにabsしてから元に戻すために使われていた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.random.uniform(low=-5, high=5, size=(2,2))
print(x) # [[ 2.19861752 -4.22997748] [ 0.15346107  0.62893343]]
print(np.ceil(x)) # [[ 3. -4.] [ 1.  1.]]
print(np.floor(x)) # [[ 2. -5.] [ 0.  0.]]
print(np.trunc(x)) # [[ 2. -4.] [ 0.  0.]]
print(np.abs([-2, 0, 2])) # [2 0 2]
print (np.copysign([1, -2, -1], [-2, 1, -1])) # [-1.  2. -1.]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.det.html&#34;&gt;linalg.det()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;行列式(determinant)を計算する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.linalg.det(np.arange(4).reshape((2, 2)))) # -2.0 &amp;lt;= 0 * 3 - 1 * 2
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html&#34;&gt;percentile()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;パーセンタイルを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.percentile(np.arange(16).reshape((4,4)), 90)) # 13.5
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.convolve.html&#34;&gt;convolve()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1次元の畳み込み。第2引数をずらしながら掛けていく。
畳み込みニューラルネットワークでも使う2次元の畳み込みの関数はnumpyにはないが、scipyの&lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html&#34;&gt;signal.convolve2d()&lt;/a&gt;が使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/6/&#34;&gt;TensorFlow チュートリアル2(Deep MNIST for Experts) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.convolve([3, 6, 9], [0, 1, 0.5])) # [0.  1.  2.5 4.  1.5] &amp;lt;= [(0*3), (0*6+1*3), (0*9+1*6+0.5*3), (1*9+0.5*6), (0.5*9)]

from scipy import signal
print(signal.convolve2d(np.arange(9).reshape((3,3)), np.eye(2)))
&#39;&#39;&#39;
[[  0.   1.   2.   0.]
 [  3.   4.   6.   2.]
 [  6.  10.  12.   5.]
 [  0.   6.   7.   8.]]
&#39;&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;その他&#34;&gt;その他&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.reduce.html&#34;&gt;ufunc.reduce()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;その前の関数でreduceする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2,2))
print(np.add.reduce(x)) # [2 4] &amp;lt;= default axis value is 0
print(np.add.reduce(x, axis=1)) # [1 5]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html&#34;&gt;random.choice()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ランダムに選ぶ。選ばれる確率pを渡すことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(5)
print(np.random.choice(x, 10)) # [3 3 0 4 1 2 0 4 2 1]
print(np.random.choice(x, 10, p=(x / np.sum(x)))) # [3 4 3 4 3 1 3 1 3 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.unravel_index.html&#34;&gt;unravel_index()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;フラットなindexをそのshapeでのindexに変換する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(9).reshape(3,3)
idx = np.unravel_index(5, x.shape)
print(idx) # (1, 2)
print(x[idx]) # 5
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html&#34;&gt;interp()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;線形補間(interpolation)した値を返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(100)
y = np.sin(0.1 * x)
x2 = [10.5, 20.2, 30.4, 60.3, 80.9]
y2 = np.interp(x2, x, y)

import matplotlib.pyplot as plt
plt.plot(x, y)
plt.plot(x2, y2, &#39;o&#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/187.png&#34; alt=&#34;元のグラフと補完補間した点&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>cert-managerで生成した証明書をIstioのGatewayに設定してHTTPS対応する</title>
          <link>https://www.sambaiz.net/article/186/</link>
          <pubDate>Thu, 13 Sep 2018 21:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/186/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/jetstack/cert-manager&#34;&gt;cert-manager&lt;/a&gt;はTLSの証明書を自動で生成し管理するK8sのアドオン。
Istioにも含まれていて、これを使って&lt;a href=&#34;https://letsencrypt.org/&#34;&gt;Let&amp;rsquo;s Encrypt&lt;/a&gt;で証明書を生成しGatewayに設定することでHTTPS対応することができる。&lt;/p&gt;

&lt;p&gt;デフォルトではcert-managerは入らないのでenabled=trueにしてインストールする。
最初に入るLet&amp;rsquo;s EncryptのClusterIssuerはエラーになったので消す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/185/&#34;&gt;IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm install install/kubernetes/helm/istio --name istio --namespace istio-system --set certmanager.enabled=true
$ kubectl delete ClusterIssuer --all
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認用にBookInfoを動かす。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl label namespace default istio-injection=enabled
$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s Encryptで使われている&lt;a href=&#34;https://github.com/ietf-wg-acme/acme&#34;&gt;ACME&lt;/a&gt;プロトコルのドメイン認証(Challenge)には
&lt;code&gt;/.well-known/acme-challenge/{token}&lt;/code&gt;でHTTPレスポンスを返す&lt;a href=&#34;https://github.com/ietf-wg-acme/acme/blob/master/draft-ietf-acme-acme.md#http-challenge&#34;&gt;HTTP Challenge&lt;/a&gt;(http-01)と
DNSのTXTレコードに書き込む&lt;a href=&#34;https://github.com/ietf-wg-acme/acme/blob/master/draft-ietf-acme-acme.md#dns-challenge&#34;&gt;DNS Challenge&lt;/a&gt;(dns-01)がある。
HTTP Challengeは手軽に達成できる一方、CAからアクセスできるようにする必要がある。今回はDNS Challengeでやる。
cert-managerはCloud DNSやRoute53などに&lt;a href=&#34;http://docs.cert-manager.io/en/latest/reference/issuers/acme/dns01.html&#34;&gt;対応&lt;/a&gt;していて、今回はCloudflareを使う。&lt;/p&gt;

&lt;p&gt;DNSに書き込めるようにするためCloudflareのMy ProfileからGlobal API Keyを持ってきてBase64デコードしSecretに入れる。
改行コードが含まれないように&lt;code&gt;-n&lt;/code&gt;を付ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo -n ***** | base64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Secret
metadata:
  name: cloudflare-api-key
  namespace: istio-system
type: Opaque
data:
  api-key: *****
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s EncryptのClusterIssuerと証明書を生成するドメインのCertificateを作成する。
serverのURLは&lt;a href=&#34;https://letsencrypt.status.io/&#34;&gt;Status&lt;/a&gt;のページから確認できる。
本番のURLは&lt;a href=&#34;https://letsencrypt.org/docs/rate-limits/&#34;&gt;レート制限&lt;/a&gt;があるので、まずはFakeの証明書が生成されるstgで試すとよい。&lt;/p&gt;

&lt;p&gt;証明書を書くsecretNameは&lt;code&gt;istio-system&lt;/code&gt;ネームスペースの&lt;code&gt;istio-ingressgateway-certs&lt;/code&gt;にする&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/secure-ingress/#configure-a-tls-ingress-gateway&#34;&gt;必要がある&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: certmanager.k8s.io/v1alpha1
kind: ClusterIssuer
metadata:
  name: letsencrypt-dns01
  namespace: istio-system
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: aaa@example.com
    privateKeySecretRef:
      name: letsencrypt-dns01
    dns01:
      providers:
      - name: cloudflare
        cloudflare:
          email: aaa@example.com
          apiKeySecretRef:
            name: cloudflare-api-key
            key: api-key
---
apiVersion: certmanager.k8s.io/v1alpha1
kind: Certificate
metadata:
  name: xxx-example-com
  namespace: istio-system
spec:
  secretName: istio-ingressgateway-certs
  issuerRef:
    name: letsencrypt-dns01
    kind: ClusterIssuer
  commonName: xxx.example.com
  dnsNames:
  - xxx.example.com
  acme:
    config:
    - dns01:
        provider: cloudflare
      domains:
      - xxx.example.com
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをapplyするとcertmanagerのログが流れ始める。何か間違いがあるとエラーになるのでなんとかする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system logs -f $(kubectl -n istio-system get pods -l app=certmanager -o jsonpath=&#39;{.items[0].metadata.name}&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;証明書と秘密鍵のSecretはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl describe secret istio-ingressgateway-certs -n istio-system
Name:         istio-ingressgateway-certs
Namespace:    istio-system
Labels:       &amp;lt;none&amp;gt;
Annotations:  certmanager.k8s.io/alt-names=xxx.example.com
              certmanager.k8s.io/common-name=xxx.example.com
              certmanager.k8s.io/issuer-kind=ClusterIssuer
              certmanager.k8s.io/issuer-name=letsencrypt-dns01

Type:  kubernetes.io/tls

Data
====
tls.key:  1675 bytes
tls.crt:  3805 bytes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ingressgateway-certs&lt;/code&gt;は自動で&lt;code&gt;/etc/istio/ingressgateway-certs&lt;/code&gt;にマウントされる。
このGatewayをapplyするとHTTPでアクセスした場合はリダイレクトし、HTTPSで正常にアクセスできるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: bookinfo-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - xxx.example.com
    tls:
      httpsRedirect: true
  - port:
      number: 443
      name: https
      protocol: HTTPS
    hosts:
    - xxx.example.com
    tls:
      mode: SIMPLE
      serverCertificate: /etc/istio/ingressgateway-certs/tls.crt
      privateKey: /etc/istio/ingressgateway-certs/tls.key
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する</title>
          <link>https://www.sambaiz.net/article/185/</link>
          <pubDate>Sun, 02 Sep 2018 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/185/</guid>
          <description>

&lt;p&gt;Istioは&lt;a href=&#34;https://www.envoyproxy.io/&#34;&gt;Envoy&lt;/a&gt;というProxyをSidecarとしてPodに入れてトラフィックを通すことでマイクロサービスのRoutingやTelemetryをサービスのコードに手を入れずに行うことができるサービスメッシュ。
もともとEnvoy自体は単体で、コネクションを張りっぱなしのgRPC(HTTP/2)をK8sのServiceのL4ロードバランサーでは分散できない問題の解決方法の一つとして
各PodのIPの一覧を返す&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#headless-services&#34;&gt;Headless Service&lt;/a&gt;と使われていたが、各Manifestに入れたりConfigMapを編集したりする必要があり少し面倒だった。
Istioにするとそれらが省けて、さらに賢いRoutingやモニタリングの仕組みまで付いてくるのでとても便利だ。&lt;/p&gt;

&lt;h2 id=&#34;インストール-https-istio-io-docs-setup-kubernetes-helm-install&#34;&gt;&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/helm-install/&#34;&gt;インストール&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;IstioをダウンロードしてきてHelmでインストールする。Istioには様々なコンポーネントが含まれているが、&lt;a href=&#34;https://github.com/istio/istio/blob/b17b4989699a6d9dc98245c511dc7d544d88e945/install/kubernetes/helm/istio/README.md#configuration&#34;&gt;パラメータ&lt;/a&gt;でインストールするものを選択することができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/122/&#34;&gt;KubernetesのパッケージマネージャーHelmを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今回はデフォルトではfalseになっているGrafana/Jaeger/Kialiをtrueにしてほぼ全て入るようにしている。&lt;/p&gt;

&lt;p&gt;RBACが有効な場合はServiceAccountを作ってcluster-adminあるいは必要なRoleをBindしておく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/160/&#34;&gt;RBACが有効なGKEでHelmを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -L https://git.io/getLatestIstio | sh -
$ cd istio-1.0.1/
# helm init --service-account tiller
$ helm install install/kubernetes/helm/istio --name istio --namespace istio-system --set grafana.enabled=true --set grafana.persist=true --set grafana.storageClassName=standard --set tracing.enabled=true --set kiali.enabled=true
$ kubectl get pod -n istio-system
NAME                                        READY     STATUS    RESTARTS   AGE
grafana-598678cbb-bglbq                     1/1       Running   0          3m
istio-citadel-6f9887d776-tvdg8              1/1       Running   0          3m
istio-egressgateway-84d78d84bf-zpxrq        1/1       Running   0          3m
istio-galley-556f5558f5-hk2r8               1/1       Running   0          3m
istio-ingressgateway-78cccbddbb-gh2xl       1/1       Running   0          3m
istio-pilot-799845f56d-l777d                2/2       Running   0          3m
istio-policy-7666fcd574-nbx8s               2/2       Running   0          3m
istio-sidecar-injector-7b6589c9-m7x77       1/1       Running   0          3m
istio-statsd-prom-bridge-55965ff9c8-s6dmj   1/1       Running   0          3m
istio-telemetry-844c8d6bff-9trcf            2/2       Running   0          3m
istio-tracing-77f9f94b98-g7v6f              1/1       Running   0          3m
kiali-bdf7fdc78-9lpd4                       1/1       Running   0          3m
prometheus-7456f56c96-drhlq                 1/1       Running   0          3m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;default namespaceにラベルを貼って自動でEnvoyが各Podに&lt;a href=&#34;https://github.com/istio/istio/blob/1.0.1/install/kubernetes/helm/istio/templates/sidecar-injector-configmap.yaml#L77&#34;&gt;Injectionされる&lt;/a&gt;ようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get namespace -L istio-injection
NAME           STATUS    AGE       ISTIO-INJECTION
default        Active    27m       
istio-system   Active    16m       
kube-public    Active    27m       
kube-system    Active    27m 

$ kubectl label namespace default istio-injection=enabled
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;併せて&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/init-containers/&#34;&gt;Init Containers&lt;/a&gt;としてInjectionされるistio-initのiptablesで&lt;a href=&#34;https://github.com/istio/istio/blob/1.0.1/tools/deb/istio-iptables.sh#L292&#34;&gt;Envoy以外&lt;/a&gt;のトラフィックが&lt;a href=&#34;https://github.com/istio/istio/blob/1.0.1/tools/deb/istio-iptables.sh#L202&#34;&gt;Envoyのポートに向く&lt;/a&gt;のでサービスのコードでは向き先を変える必要がない。&lt;/p&gt;

&lt;h2 id=&#34;routing&#34;&gt;Routing&lt;/h2&gt;

&lt;h3 id=&#34;pilot-https-istio-io-docs-concepts-traffic-management-pilot-and-envoy&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/traffic-management/#pilot-and-envoy&#34;&gt;Pilot&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;全Envoyを管理するPilotにEnvoy間のトラフィックのルーティングや、リトライやサーキットブレーカーのルールを設定できる。
EnvoyはPilotからサービスディスカバリして他Envoyについて知り、定期的にロードバランシングプールに含まれるインスタンスのヘルスチェックをして失敗数がしきい値を超えたら成功数がしきい値を超えるまでプールから追い出し、ルールに従いトラフィックを制御する。&lt;/p&gt;

&lt;h3 id=&#34;リソース&#34;&gt;リソース&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/reference/config/istio.networking.v1alpha3/#Gateway&#34;&gt;Gateway&lt;/a&gt;: HTTP/TCPロードバランサー。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ingressとは異なりL4-L6のポートやTLSの設定は持つがL7の設定は持たず、VirtualServiceに持つ。
インフラ管理者とサービス開発者が触るであろうリソースが分離されている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/173/&#34;&gt;GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/reference/config/istio.networking.v1alpha3/#VirtualService&#34;&gt;VirtualService&lt;/a&gt;: ルーティングのルール。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/reference/config/istio.networking.v1alpha3/#DestinationRule&#34;&gt;DestinationRule&lt;/a&gt;: ロードバランシングのルール。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;例-https-istio-io-docs-examples-bookinfo&#34;&gt;&lt;a href=&#34;https://istio.io/docs/examples/bookinfo/&#34;&gt;例&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;サンプルアプリケーションBookInfoを動かす。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
$ kubectl get pod
NAME                              READY     STATUS    RESTARTS   AGE
details-v1-7bcdcc4fd6-x92f5       2/2       Running   0          1m
productpage-v1-8584c875d8-jxl68   2/2       Running   0          1m
ratings-v1-54cf9dc8f8-wv9xz       2/2       Running   0          1m
reviews-v1-59cbdd7959-vxf2f       2/2       Running   0          1m
reviews-v2-dccb4cfc9-mc22f        2/2       Running   0          1m
reviews-v3-5465dc97bc-pgvbl       2/2       Running   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GatewayとVirtualServiceを作成して外に開く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/bookinfo-gateway.yaml
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: bookinfo-gateway
spec:
  selector:
    istio: ingressgateway # use istio default controller
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - &amp;quot;*&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: bookinfo
spec:
  hosts:
  - &amp;quot;*&amp;quot;
  gateways:
  - bookinfo-gateway
  http:
  - match:
    - uri:
        exact: /productpage
    - uri:
        exact: /login
    - uri:
        exact: /logout
    - uri:
        prefix: /api/v1/products
    route:
    - destination:
        host: productpage
        port:
          number: 9080

$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml
$ export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.status.loadBalancer.ingress[0].ip}&#39;)
$ export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.spec.ports[?(@.name==&amp;quot;http2&amp;quot;)].port}&#39;)
$ export GATEWAY_URL=http://$INGRESS_HOST:$INGRESS_PORT
$ open $GATEWAY_URL/productpage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-bookinfo.png&#34; alt=&#34;BookInfo&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DestinationRuleを作成する。この時点では各バージョンがラウンドロビンする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/destination-rule-all.yaml
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: productpage
spec:
  host: productpage
  subsets:
  - name: v1
    labels:
      version: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: reviews
spec:
  host: reviews
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
  - name: v3
    labels:
      version: v3
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: ratings
spec:
  host: ratings
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
  - name: v2-mysql
    labels:
      version: v2-mysql
  - name: v2-mysql-vm
    labels:
      version: v2-mysql-vm
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: details
spec:
  host: details
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
---

$ kubectl apply -f samples/bookinfo/networking/destination-rule-all.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VirtualServiceのdestinationでsubsetを指定するとそのバージョンのみに&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/request-routing/&#34;&gt;飛ぶ&lt;/a&gt;ようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/virtual-service-all-v1.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: productpage
spec:
  hosts:
  - productpage
  http:
  - route:
    - destination:
        host: productpage
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
  - reviews
  http:
  - route:
    - destination:
        host: reviews
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ratings
spec:
  hosts:
  - ratings
  http:
  - route:
    - destination:
        host: ratings
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: details
spec:
  hosts:
  - details
  http:
  - route:
    - destination:
        host: details
        subset: v1
---

$ kubectl apply -f samples/bookinfo/networking/virtual-service-all-v1.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VirtualServiceはheaderの中身をみてルーティングさせることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/virtual-service-reviews-test-v2.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
    - reviews
  http:
  - match:
    - headers:
        end-user:
          exact: jason
    route:
    - destination:
        host: reviews
        subset: v2
  - route:
    - destination:
        host: reviews
        subset: v1

$ kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-test-v2.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/fault-injection/&#34;&gt;Fault Injection&lt;/a&gt;して特定条件や割合で意図的に遅延を生じさせたり、エラーコードを返らせたりできる。バグの発見や調査、Chaos Engineeringもできそうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ratings
spec:
  hosts:
  - ratings
  http:
  - match:
    - headers:
        end-user:
          exact: jason
    fault:
      delay:
        percent: 100
        fixedDelay: 7s
    route:
    - destination:
        host: ratings
        subset: v1
  - route:
    - destination:
        host: ratings
        subset: v1

$ kubectl apply -f samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;routeには複数のdestinationを指定できてweightによって飛ばす割合を&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/traffic-shifting/&#34;&gt;変えられる&lt;/a&gt;。
カナリアリリースやA/Bテストが簡単にできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/virtual-service-reviews-50-v3.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
    - reviews
  http:
  - route:
    - destination:
        host: reviews
        subset: v1
      weight: 50
    - destination:
        host: reviews
        subset: v3
      weight: 50

$ kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-50-v3.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;telemetry&#34;&gt;Telemetry&lt;/h2&gt;

&lt;h3 id=&#34;mixer-https-istio-io-docs-concepts-policies-and-telemetry&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/policies-and-telemetry/&#34;&gt;Mixer&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;MixerはポリシーコントロールとTelemetryを行うコンポーネント。
&lt;a href=&#34;https://istio.io/docs/reference/config/policy-and-telemetry/adapters/&#34;&gt;Adapter&lt;/a&gt;によってStackdriverやCloudWatchなど様々なバックエンドに対応している。&lt;/p&gt;

&lt;p&gt;Envoyは前提条件を確認するためリクエストの前と、Telemetryするためリクエストの後にMixerを呼び出す。ただしキャッシュとバッファを持っていて毎回呼び出しはしない。また、Mixerもキャッシュやバッファを持ちバックエンドの呼び出し回数を減らしている。
MixerがSPOFとなり可用性が下がるのではと思われるが、バックエンドの障害をある程度許容できるのに加えて Mixer自身はステートレスで他のバックエンドよりも可用性が高く設計されているためむしろ&lt;a href=&#34;https://istio.io/blog/2017/mixer-spof-myth/&#34;&gt;SLOが向上する&lt;/a&gt;そうだ。&lt;/p&gt;

&lt;h3 id=&#34;リソース-1&#34;&gt;リソース&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/concepts/policies-and-telemetry/#handlers&#34;&gt;Handler(Adapter)&lt;/a&gt;: Mixerからバックエンドへ送る。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/concepts/policies-and-telemetry/#instances&#34;&gt;Instance&lt;/a&gt;: EnvoyからMixerに送られてきたAttributeをAdapterの入力へマッピングする。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/concepts/policies-and-telemetry/#rules&#34;&gt;Rule&lt;/a&gt;: Handlerが特定のInstancesで呼び出されるルール。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;例-https-istio-io-docs-tasks-telemetry-metrics-logs&#34;&gt;&lt;a href=&#34;https://istio.io/docs/tasks/telemetry/metrics-logs/&#34;&gt;例&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;リクエストの2倍の数を値とするmetric instance。&lt;a href=&#34;https://istio.io/docs/reference/config/policy-and-telemetry/expression-language/&#34;&gt;configuration expression language(CEXL)&lt;/a&gt;が使われている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat new_telemetry.yaml 
# Configuration for metric instances
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: metric
metadata:
  name: doublerequestcount
  namespace: istio-system
spec:
  value: &amp;quot;2&amp;quot; # count each request twice
  dimensions:
    reporter: conditional((context.reporter.kind | &amp;quot;inbound&amp;quot;) == &amp;quot;outbound&amp;quot;, &amp;quot;client&amp;quot;, &amp;quot;server&amp;quot;)
    source: source.workload.name | &amp;quot;unknown&amp;quot;
    destination: destination.workload.name | &amp;quot;unknown&amp;quot;
    message: &#39;&amp;quot;twice the fun!&amp;quot;&#39;
  monitored_resource_type: &#39;&amp;quot;UNSPECIFIED&amp;quot;&#39;
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このmetricを受け取るprometheus handler。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Configuration for a Prometheus handler
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: prometheus
metadata:
  name: doublehandler
  namespace: istio-system
spec:
  metrics:
  - name: double_request_count # Prometheus metric name
    instance_name: doublerequestcount.metric.istio-system # Mixer instance name (fully-qualified)
    kind: COUNTER
    label_names:
    - reporter
    - source
    - destination
    - message
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そしてこれらを紐づけるrule。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Rule to send metric instances to a Prometheus handler
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: rule
metadata:
  name: doubleprom
  namespace: istio-system
spec:
  actions:
  - handler: doublehandler.prometheus
    instances:
    - doublerequestcount.metric
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://istio.io/docs/reference/config/policy-and-telemetry/templates/logentry/&#34;&gt;logentry&lt;/a&gt;はログを表すinstance。
あとはそれを標準出力するhandlerとrule。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Configuration for logentry instances
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: logentry
metadata:
  name: newlog
  namespace: istio-system
spec:
  severity: &#39;&amp;quot;warning&amp;quot;&#39;
  timestamp: request.time
  variables:
    source: source.labels[&amp;quot;app&amp;quot;] | source.workload.name | &amp;quot;unknown&amp;quot;
    user: source.user | &amp;quot;unknown&amp;quot;
    destination: destination.labels[&amp;quot;app&amp;quot;] | destination.workload.name | &amp;quot;unknown&amp;quot;
    responseCode: response.code | 0
    responseSize: response.size | 0
    latency: response.duration | &amp;quot;0ms&amp;quot;
  monitored_resource_type: &#39;&amp;quot;UNSPECIFIED&amp;quot;&#39;
---
# Configuration for a stdio handler
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: stdio
metadata:
  name: newhandler
  namespace: istio-system
spec:
 severity_levels:
   warning: 1 # Params.Level.WARNING
 outputAsJson: true
---
# Rule to send logentry instances to a stdio handler
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: rule
metadata:
  name: newlogstdio
  namespace: istio-system
spec:
  match: &amp;quot;true&amp;quot; # match for all requests
  actions:
   - handler: newhandler.stdio
     instances:
     - newlog.logentry
---

$ kubectl apply -f new_telemetry.yaml 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prometheus handlerによってdoublerequestcount metricが届いている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=prometheus -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 9090:9090
$ open http://localhost:9090/graph
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-prometheus.png&#34; alt=&#34;Prometheus&#34; /&gt;&lt;/p&gt;

&lt;p&gt;stdio handlerによってnewlog logentryが出力されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system logs -f $(kubectl -n istio-system get pods -l istio-mixer-type=telemetry -o jsonpath=&#39;{.items[0].metadata.name}&#39;) -c mixer | grep \&amp;quot;instance\&amp;quot;:\&amp;quot;newlog.logentry.istio-system\&amp;quot; 
{&amp;quot;level&amp;quot;:&amp;quot;warn&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2018-09-01T13:53:45.897141Z&amp;quot;,&amp;quot;instance&amp;quot;:&amp;quot;l&amp;quot;,&amp;quot;destination&amp;quot;:&amp;quot;telemetry&amp;quot;,&amp;quot;latency&amp;quot;:&amp;quot;3.817501ms&amp;quot;,&amp;quot;responseCode&amp;quot;:200,&amp;quot;responseSize&amp;quot;:5,&amp;quot;source&amp;quot;:&amp;quot;details&amp;quot;,&amp;quot;user&amp;quot;:&amp;quot;unknown&amp;quot;}
{&amp;quot;level&amp;quot;:&amp;quot;warn&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2018-09-01T13:53:45.899237Z&amp;quot;,&amp;quot;instance&amp;quot;:&amp;quot;newlog.logentry.istio-system&amp;quot;,&amp;quot;destination&amp;quot;:&amp;quot;telemetry&amp;quot;,&amp;quot;latency&amp;quot;:&amp;quot;4.423947ms&amp;quot;,&amp;quot;responseCode&amp;quot;:200,&amp;quot;responseSize&amp;quot;:5,&amp;quot;source&amp;quot;:&amp;quot;productpage&amp;quot;,&amp;quot;user&amp;quot;:&amp;quot;unknown&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;grafana&#34;&gt;Grafana&lt;/h2&gt;

&lt;p&gt;Grafanaを開くと最初からIstioのダッシュボードがいくつか作られている。
Prometheusに送ったmetricをGrafanaで可視化できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=grafana -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 3000:3000
$ open http://localhost:3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-grafana.png&#34; alt=&#34;Grafana&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;jaeger&#34;&gt;Jaeger&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.jaegertracing.io/&#34;&gt;Jaeger&lt;/a&gt;は分散トレーシングツール。
パフォーマンスが問題になったときにどこのサービスがボトルネックになっているかが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl port-forward -n istio-system $(kubectl get pod -n istio-system -l app=jaeger -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 16686:16686
$ open http://localhost:16686
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-jaeger.png&#34; alt=&#34;Jaeger&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;kiali&#34;&gt;Kiali&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.kiali.io/&#34;&gt;Kiali&lt;/a&gt;はサービスメッシュを可視化するツール。v1とv3にリクエストが飛んでいてv2には飛んでいないことが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=kiali -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 20001:20001
$ open http://localhost:20001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-kiali.png&#34; alt=&#34;Kiali&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/wataru420/items/a63a8b205308a93e253c&#34;&gt;kubernetesでgRPCするときにenvoy挟んでみたよ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/why-you-should-care-about-istio-gateways/&#34;&gt;Why You Should Care About Istio Gateways - The New Stack&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>nohupし忘れた時間のかかる処理をdisownしてexit後も実行させ続ける</title>
          <link>https://www.sambaiz.net/article/184/</link>
          <pubDate>Thu, 23 Aug 2018 00:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/184/</guid>
          <description>&lt;p&gt;時間がかかるコマンドを実行する場合、通常は&lt;code&gt;nohup&lt;/code&gt;で実行し
ターミナル終了時に飛ぶ&lt;a href=&#34;https://en.wikipedia.org/wiki/SIGHUP&#34;&gt;SIGHUP(SIGnal Hang UP)&lt;/a&gt;を無視させることで
exitしても実行させ続けることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nohup ./foo &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただnohupを付けずに実行し始めてから思ったより時間がかかるということもある。
その場合は、&lt;code&gt;Ctrl+Z&lt;/code&gt;で一旦停止してから&lt;code&gt;bg&lt;/code&gt;でバックラウンドで実行するようにして&lt;code&gt;disown -h&lt;/code&gt;でSIGHUPが送られないようにできる。
&lt;code&gt;disown&lt;/code&gt;はシェルのジョブテーブルから削除するコマンドで、そのままでもSIGHUPが送られないようにできるが、
-hを付けるとジョブテーブルから削除せずに済む。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ jobs
[1]+  停止                  ./foo

$ bg 1
$ jobs
[1]+  実行中                ./foo

$ disown -h %1
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CircleCI 2.0でDocker imageをbuildしてタグを付けてContainer Registryに上げる</title>
          <link>https://www.sambaiz.net/article/183/</link>
          <pubDate>Wed, 22 Aug 2018 23:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/183/</guid>
          <description>

&lt;blockquote&gt;
&lt;p&gt;(追記: 2019-04-13) 2.1からのOrbを使うと自分でjobを書かなくてもよくなる &lt;a href=&#34;https://www.sambaiz.net/article/217/&#34;&gt;CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;masterにpushしたときと、リリースタグを切ったときにビルドされるようにする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/183-ci.png&#34; alt=&#34;imageとタグ&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: 2
jobs:
  build:
    docker:
      - image: google/cloud-sdk
    environment:
      GCP_PROJECT: &amp;lt;project_name&amp;gt;
      IMAGE_NAME: &amp;lt;image_name&amp;gt;
    steps:
      - checkout
      - setup_remote_docker:
          version: 18.05.0-ce
      - run:
          name: gcloud auth
          command: |
            echo $GCLOUD_SERVICE_KEY | base64 --decode &amp;gt; ${HOME}/gcloud-service-key.json
            gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json
            gcloud --quiet auth configure-docker
      - run:
          name: docker build &amp;amp; push
          command: |
            docker build -t asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} .
            docker tag asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:latest
            if [ -n &amp;quot;${CIRCLE_TAG}&amp;quot; ]; then
              docker tag asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_TAG}
            fi
            docker push asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}

workflows:
  version: 2
  master-build:
    jobs:
      - build:
          filters:
            branches:
              only: master
  release-build:
    jobs:
      - build:
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /^v.*/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;

&lt;p&gt;dockerコマンドを実行できるように&lt;a href=&#34;https://circleci.com/docs/2.0/building-docker-images/&#34;&gt;setup_remote_docker&lt;/a&gt;する。&lt;/p&gt;

&lt;h2 id=&#34;gcpの認証&#34;&gt;GCPの認証&lt;/h2&gt;

&lt;p&gt;Storageのbucketも読み書きできるようにストレージ管理者のService Accountを作成して鍵をJSONでダウンロードし、
base64エンコードしてCircleCIのEnvironment Variablesのところに&lt;code&gt;GCLOUD_SERVICE_KEY&lt;/code&gt;で登録する。
ビルド時にはこれをデコードしてactivate-service-accountする。&lt;/p&gt;

&lt;h2 id=&#34;branchとtagのフィルタ&#34;&gt;branchとtagのフィルタ&lt;/h2&gt;

&lt;p&gt;workflowがなくてもbuildのjobは実行される。
しかし、ブランチのフィルタはjobの方でも設定&lt;a href=&#34;https://circleci.com/docs/2.0/configuration-reference/&#34;&gt;できる&lt;/a&gt;が、タグは設定できないため
workflowを作る必要がある。&lt;/p&gt;

&lt;p&gt;また、tagsを設定しないとタグに反応してビルドが始まらず、branchをignoreしないとタグを切ってないときにも無条件にビルドが走ってしまうので
release-buildではbranchをignoreしている。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KubernetesのCustom Resource Definition(CRD)とCustom Controller</title>
          <link>https://www.sambaiz.net/article/182/</link>
          <pubDate>Thu, 09 Aug 2018 23:59:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/182/</guid>
          <description>

&lt;p&gt;K8sではDeploymentを作成したときにReplicaSetも&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.11.2/pkg/controller/deployment/sync.go#L220&#34;&gt;作成&lt;/a&gt;されるようにしたり、
Load Balancer Serviceを作成したときにGCPなどその環境に応じたLoad Balancerも&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.11.2/pkg/controller/service/service_controller.go#L305&#34;&gt;作成&lt;/a&gt;されるようにしたりするため、Controllerがそれらを監視してAPIを呼んでいる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/173/&#34;&gt;GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Controllerは単なるAPIを呼ぶアプリケーションなので自分でCustom Controllerを作成してDeploymentとしてデプロイすることもできる。
また、監視する対象もpodsやdeploymentsといった標準のAPIだけではなく、
&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#adding-custom-resources&#34;&gt;Custom Resource&lt;/a&gt;
で拡張したものを使うことができる。&lt;/p&gt;

&lt;p&gt;特定のアプリケーションのためのControllerは&lt;a href=&#34;https://coreos.com/blog/introducing-operators.html&#34;&gt;Operator&lt;/a&gt;とも呼ばれる。&lt;/p&gt;

&lt;h2 id=&#34;customresourcedefinition-crd-https-kubernetes-io-docs-tasks-access-kubernetes-api-custom-resources-custom-resource-definitions&#34;&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/&#34;&gt;CustomResourceDefinition(CRD)&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Custom Resourceを定義する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: crontabs.stable.example.com
spec:
  # REST APIで使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;
  group: stable.example.com
  version: v1
  # Namespaced か Cluster
  scope: Namespaced
  names:
    # 複数形 URLに使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;/&amp;lt;plural&amp;gt;
    plural: crontabs
    # 単数形 CLIなどで使われる
    singular: crontab
    # manifestで使う
    kind: CronTab
    shortNames:
    - ct
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f crd.yaml
$ kubectl get crd
NAME                          AGE
crontabs.stable.example.com   8s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;標準のresourceと同様にKindに指定してcreateできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat crontab.yaml
apiVersion: stable.example.com/v1
kind: CronTab
metadata:
  name: test

$ kubectl create -f crontab.yaml
$ kubectl get crontab
NAME      AGE
test      10s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;client&#34;&gt;Client&lt;/h2&gt;

&lt;p&gt;Controllerで使うCustom ResourceのClientを準備する。&lt;/p&gt;

&lt;h3 id=&#34;生成&#34;&gt;生成&lt;/h3&gt;

&lt;p&gt;まず、以下のようにファイルを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tree pkg
pkg
└── apis
    └── mysamplecontroller
        ├── register.go
        └── v1
            ├── doc.go
            ├── register.go
            └── types.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;doc.go&lt;/code&gt;はpackage指定のみ、&lt;code&gt;types.go&lt;/code&gt;にはCustom Resourceのstructを書いて&lt;a href=&#34;https://github.com/kubernetes/code-generator&#34;&gt;code-generator&lt;/a&gt;用のタグを付けている。register.goは&lt;a href=&#34;https://github.com/kubernetes/sample-controller/blob/kubernetes-1.11.1/pkg/apis/samplecontroller/v1alpha1/register.go&#34;&gt;sample&lt;/a&gt;からほとんどコピー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// +k8s:deepcopy-gen=package,register

// +groupName=example.com
package v1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;package v1

import (
	metav1 &amp;quot;k8s.io/apimachinery/pkg/apis/meta/v1&amp;quot;
)

// +genclient
// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object

type SampleResource struct {
	metav1.TypeMeta   `json:&amp;quot;,inline&amp;quot;`
	metav1.ObjectMeta `json:&amp;quot;metadata,omitempty&amp;quot;`

	Spec SampleResourceSpec `json:&amp;quot;spec&amp;quot;`
}

type SampleResourceSpec struct {
	PodImage string `json:&amp;quot;podImage&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;code-generatorを持ってきて&lt;code&gt;generate-groups.sh&lt;/code&gt;を実行すると残りのファイルが生成される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Makefile
.PHONY: codegen
codegen:
	${GOPATH}/src/k8s.io/code-generator/generate-groups.sh &amp;quot;deepcopy,client,informer,lister&amp;quot; \
	github.com/sambaiz/k8s-sample-crd-controller/pkg/client github.com/sambaiz/k8s-sample-crd-controller/pkg/apis \
	mysamplecontroller:v1

$ make codegen
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;zz_generated.deepcopy.go&lt;/code&gt;でCustom Resourceのstructに&lt;code&gt;DeepCopyObject()&lt;/code&gt;関数を追加し、
&lt;a href=&#34;https://github.com/kubernetes/apimachinery/blob/kubernetes-1.11.2/pkg/runtime/interfaces.go#L231&#34;&gt;runtime.Object&lt;/a&gt; interfaceを満たすようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tree pkg
pkg
├── apis
│   └── mysamplecontroller
│       ├── register.go
│       └── v1
│           ├── doc.go
│           ├── register.go
│           ├── types.go
│           └── zz_generated.deepcopy.go
└── client
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;controller&#34;&gt;Controller&lt;/h2&gt;

&lt;p&gt;公式の&lt;a href=&#34;https://github.com/kubernetes/sample-controller&#34;&gt;sample-controller&lt;/a&gt;を見ていく。&lt;/p&gt;

&lt;h3 id=&#34;main-go&#34;&gt;main.go&lt;/h3&gt;

&lt;p&gt;Clientを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
    &amp;quot;k8s.io/client-go/kubernetes&amp;quot;
    clientset &amp;quot;k8s.io/sample-controller/pkg/client/clientset/versioned&amp;quot;
)

cfg, err := clientcmd.BuildConfigFromFlags(masterURL, kubeconfig)
kubeClient, err := kubernetes.NewForConfig(cfg)
exampleClient, err := clientset.NewForConfig(cfg)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にClientからdeploymentsとCustom Resourceであるfoosの&lt;a href=&#34;https://github.com/kubernetes/sample-controller/blob/master/docs/controller-client-go.md#client-go-components&#34;&gt;Informer&lt;/a&gt;を作ってControllerに渡す。Informerは変更があったObjectが入るDeltaFifoQueueを監視して、Event Handlerを呼ぶもの。
ちなみにK8sのAPIを監視してDeltaFifoQueueに入れるのはReflectorがやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
    kubeinformers &amp;quot;k8s.io/client-go/informers&amp;quot;
    informers &amp;quot;k8s.io/sample-controller/pkg/client/informers/externalversions&amp;quot;
)

kubeInformerFactory := kubeinformers.NewSharedInformerFactory(kubeClient, time.Second*30)
exampleInformerFactory := informers.NewSharedInformerFactory(exampleClient, time.Second*30)

controller := NewController(kubeClient, exampleClient,
    kubeInformerFactory.Apps().V1().Deployments(),
    exampleInformerFactory.Samplecontroller().V1alpha1().Foos())

go kubeInformerFactory.Start(stopCh)
go exampleInformerFactory.Start(stopCh)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;controller-go&#34;&gt;controller.go&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;func NewController(
	kubeclientset kubernetes.Interface,
	sampleclientset clientset.Interface,
	deploymentInformer appsinformers.DeploymentInformer,
	fooInformer informers.FooInformer) *Controller {
    ...
    controller := &amp;amp;Controller{
        kubeclientset:     kubeclientset,
        sampleclientset:   sampleclientset,
        deploymentsLister: deploymentInformer.Lister(),
        deploymentsSynced: deploymentInformer.Informer().HasSynced,
        foosLister:        fooInformer.Lister(),
        foosSynced:        fooInformer.Informer().HasSynced,
        workqueue:         workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), &amp;quot;Foos&amp;quot;),
        recorder:          recorder,
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EventHandlerを登録する。fooInformerの方は&amp;rdquo;namespace/name&amp;rdquo;の文字列をControllerのWorkququeに入れる。
deploymentInformerの方は&lt;a href=&#34;https://github.com/kubernetes/apimachinery/blob/kubernetes-1.11.2/pkg/apis/meta/v1/controller_ref.go#L33&#34;&gt;GetControllerOf()&lt;/a&gt;で&lt;a href=&#34;https://github.com/kubernetes/apimachinery/blob/kubernetes-1.11.2/pkg/apis/meta/v1/types.go#L290&#34;&gt;OwnerReference&lt;/a&gt;を見て、それがFooならInformerでObjectを取得し同様の処理を行う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fooInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
    AddFunc: controller.enqueueFoo,
    UpdateFunc: func(old, new interface{}) {
        controller.enqueueFoo(new)
    },
})

deploymentInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
    AddFunc: controller.handleObject,
    UpdateFunc: func(old, new interface{}) {
        newDepl := new.(*appsv1.Deployment)
        oldDepl := old.(*appsv1.Deployment)
        if newDepl.ResourceVersion == oldDepl.ResourceVersion {
            return
        }
        controller.handleObject(new)
    },
    DeleteFunc: controller.handleObject,
})

func (c *Controller) enqueueFoo(obj interface{}) {
	var key string
	var err error
	if key, err = cache.MetaNamespaceKeyFunc(obj); err != nil {
		runtime.HandleError(err)
		return
	}
	c.workqueue.AddRateLimited(key)
}

func (c *Controller) handleObject(obj interface{}) {
	var object metav1.Object
	var ok bool
	if object, ok = obj.(metav1.Object); !ok {
		tombstone, ok := obj.(cache.DeletedFinalStateUnknown)
		if !ok {
			runtime.HandleError(fmt.Errorf(&amp;quot;error decoding object, invalid type&amp;quot;))
			return
		}
		object, ok = tombstone.Obj.(metav1.Object)
		if !ok {
			runtime.HandleError(fmt.Errorf(&amp;quot;error decoding object tombstone, invalid type&amp;quot;))
			return
		}
		glog.V(4).Infof(&amp;quot;Recovered deleted object &#39;%s&#39; from tombstone&amp;quot;, object.GetName())
	}
	glog.V(4).Infof(&amp;quot;Processing object: %s&amp;quot;, object.GetName())
	if ownerRef := metav1.GetControllerOf(object); ownerRef != nil {
		if ownerRef.Kind != &amp;quot;Foo&amp;quot; {
			return
		}

		foo, err := c.foosLister.Foos(object.GetNamespace()).Get(ownerRef.Name)
		if err != nil {
			glog.V(4).Infof(&amp;quot;ignoring orphaned object &#39;%s&#39; of foo &#39;%s&#39;&amp;quot;, object.GetSelfLink(), ownerRef.Name)
			return
		}

		c.enqueueFoo(foo)
		return
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Workqueueから取り出して処理を行う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;obj, shutdown := c.workqueue.Get()
err := func(obj interface{}) error {
    defer c.workqueue.Done(obj)
	if key, ok = obj.(string); !ok {
        c.workqueue.Forget(obj)
        runtime.HandleError(fmt.Errorf(&amp;quot;expected string in workqueue but got %#v&amp;quot;, obj))
        return nil
    }
    if err := c.syncHandler(key); err != nil {
        return fmt.Errorf(&amp;quot;error syncing &#39;%s&#39;: %s&amp;quot;, key, err.Error())
    }
    c.workqueue.Forget(obj)
    glog.Infof(&amp;quot;Successfully synced &#39;%s&#39;&amp;quot;, key)
    return nil
}(obj)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fooを取得し、specのdeploymentNameのdeploymentをclientで生成する。OwnerReferenceを含んでいる。
ここでは省略しているが、既に存在してコントロール下にない場合などのチェックもしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace, name, err := cache.SplitMetaNamespaceKey(key)
foo, err := c.foosLister.Foos(namespace).Get(name)
deploymentName := foo.Spec.DeploymentName
deployment, err := c.deploymentsLister.Deployments(foo.Namespace).Get(deploymentName)
if errors.IsNotFound(err) {
    deployment, err = c.kubeclientset.AppsV1().Deployments(foo.Namespace).Create(newDeployment(foo))
}

func newDeployment(foo *samplev1alpha1.Foo) *appsv1.Deployment {
	labels := map[string]string{
		&amp;quot;app&amp;quot;:        &amp;quot;nginx&amp;quot;,
		&amp;quot;controller&amp;quot;: foo.Name,
	}
	return &amp;amp;appsv1.Deployment{
		ObjectMeta: metav1.ObjectMeta{
			Name:      foo.Spec.DeploymentName,
			Namespace: foo.Namespace,
			OwnerReferences: []metav1.OwnerReference{
				*metav1.NewControllerRef(foo, schema.GroupVersionKind{
					Group:   samplev1alpha1.SchemeGroupVersion.Group,
					Version: samplev1alpha1.SchemeGroupVersion.Version,
					Kind:    &amp;quot;Foo&amp;quot;,
				}),
			},
		},
		Spec: appsv1.DeploymentSpec{
			Replicas: foo.Spec.Replicas,
			Selector: &amp;amp;metav1.LabelSelector{
				MatchLabels: labels,
			},
			Template: corev1.PodTemplateSpec{
				ObjectMeta: metav1.ObjectMeta{
					Labels: labels,
				},
				Spec: corev1.PodSpec{
					Containers: []corev1.Container{
						{
							Name:  &amp;quot;nginx&amp;quot;,
							Image: &amp;quot;nginx:latest&amp;quot;,
						},
					},
				},
			},
		},
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;デプロイ&#34;&gt;デプロイ&lt;/h3&gt;

&lt;p&gt;ローカルで動かすこともできるが、せっかくなのでクラスタにデプロイする。環境はGKE。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Dockerfile
FROM golang:1.10 AS builder
ADD . /go/src/k8s.io/sample-controller
WORKDIR /go/src/k8s.io/sample-controller
RUN CGO_ENABLED=0 go build -o sample-controller .

FROM alpine
WORKDIR /
COPY --from=builder /go/src/k8s.io/sample-controller/sample-controller .
CMD [&amp;quot;/sample-controller&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t asia.gcr.io/*****/sample-controller .
$ gcloud auth configure-docker
$ docker push asia.gcr.io/*****/sample-controller
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RBACが有効になっている場合はAPIを呼ぶため必要なClusterRoleをControllerが動くPodに与える必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=&amp;lt;email&amp;gt;
$ cat role.yaml 
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: sample-controller
rules:
- apiGroups: [&amp;quot;apps&amp;quot;, &amp;quot;samplecontroller.k8s.io&amp;quot;]
  resources: [&amp;quot;*&amp;quot;]
  verbs: [&amp;quot;*&amp;quot;]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sample-controller
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: sample-controller
subjects:
- kind: ServiceAccount
  name: sample-controller
  namespace: default
roleRef:
  kind: ClusterRole
  name: sample-controller
  apiGroup: rbac.authorization.k8s.io

$ kubectl apply -f role.yaml 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初めClusterRoleではなくRoleにしたせいで以下のようなエラーが出て少し悩んだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;k8s.io/sample-controller/pkg/client/informers/externalversions/factory.go:117: Failed to list *v1alpha1.Foo: foos.samplecontroller.k8s.io is forbidden: User &amp;quot;system:serviceaccount:default:sample-controller&amp;quot; cannot list foos.samplecontroller.k8s.io at the cluster scope: Unknown user &amp;quot;system:serviceaccount:default:sample-controller&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作ったServiceAccountをDeploymentのPodSpecに含める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat deployment.yaml
kind: Deployment
metadata:
  name: sample-controller
spec:
  template:
    metadata:
      labels:
        app: sample-controller
    spec:
      serviceAccount: sample-controller
      containers:
      - name: sample-controller
        image: asia.gcr.io/*****/sample-controller

$ kubectl apply -f deployment.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;動作&#34;&gt;動作&lt;/h3&gt;

&lt;p&gt;FooのCRDを作成してcreateするとたしかにdeploymentが作成された。
また、deploymentを削除すると新しいdeploymentが作成され、Fooを削除するとdeploymentも削除されることが確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f artifacts/examples/crd.yaml
$ kubectl create -f artifacts/examples/example-foo.yaml
$ kubectl get foo
NAME          AGE
example-foo   2s

$ kubectl get deployment
NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
example-foo         1         1         1            1           5s
sample-controller   1         1         1            1           1h

$ kubectl delete deployment example-foo
deployment &amp;quot;example-foo&amp;quot; deleted

$ kubectl get deployment
NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
example-foo         1         1         1            1           1s
sample-controller   1         1         1            1           1h

$ kubectl delete foo example-foo
$ kubectl get deployment
No resources found.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/&#34;&gt;Kubernetes Deep Dive: Code Generation for CustomResources – OpenShift Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KubernetesのNetworkPolicy Resource</title>
          <link>https://www.sambaiz.net/article/181/</link>
          <pubDate>Mon, 30 Jul 2018 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/181/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;Network Policies - Kubernetes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PodのトラフィックをラベルやIPアドレスで許可するためのResource。AWSのセキュリティグループやGCPのファイアウォールルールのようなもの。
GKEでは今のところデフォルトでオフになっているので&lt;code&gt;--enable-network-policy&lt;/code&gt;を付けてクラスタを作成する必要がある。&lt;/p&gt;

&lt;p&gt;以前作成したmulti podのアプリケーションで挙動を確認する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/173/&#34;&gt;GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get service
NAME               TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)        AGE
clusterip-app      ClusterIP      10.23.247.54    &amp;lt;none&amp;gt;           80/TCP         48m
loadbalancer-app   LoadBalancer   10.23.244.137   35.224.130.196   80:31508/TCP   48m
nodeport-app       NodePort       10.23.246.215   &amp;lt;none&amp;gt;           80:32181/TCP   48m
...

$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作成するNetworkPolicyは以下の二つで、いずれも対象は&lt;code&gt;app: nodeport-app&lt;/code&gt;のラベルが付いたPod。
一つ目は対象Podへのリクエストを一旦全て拒否する。
二つ目は&lt;code&gt;nodeport-access: &amp;quot;true&amp;quot;&lt;/code&gt;のラベルが付いたPodから対象Podへの8080ポートのリクエストを許可するもの。
今回は設定しないがegressも設定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat networkPolicies.yaml 
---
# Default deny all ingress traffic
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
spec:
  podSelector:
    matchLabels:
      app: nodeport-app
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
spec:
  podSelector:
    matchLabels:
      app: nodeport-app
  ingress:
  - from:
    - podSelector:
        matchLabels:
          nodeport-access: &amp;quot;true&amp;quot;
    ports:
    - port: 8080

$ kubectl apply -f networkPolicies.yaml 
$ kubectl get networkpolicy
NAME                  POD-SELECTOR       AGE
default-deny          app=nodeport-app   5s
test-network-policy   app=nodeport-app   5s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作成後、ラベルが付いていないPodからアクセスできなくなり、ラベルを付けるとアクセスできるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
Get http://nodeport-app: dial tcp 10.23.246.215:80: i/o timeout

$ kubectl label pods loadbalancer-app-6bd554874-**** nodeport-access=true
$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fromにはipBlockやnamespaceSelectorも設定することもでき、複数指定した場合はいずれかの条件を満たすと通る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl delete pod loadbalancer-app-***
$  curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
Get http://nodeport-app: dial tcp 10.23.246.215:80: i/o timeout

$ kubectl label namespaces default aaa=bbb
$ cat networkPolicies.yaml 
...
- from:
    - podSelector:
        matchLabels:
          nodeport-access: &amp;quot;true&amp;quot;
    - namespaceSelector:
        matchLabels:
          aaa: bbb
...

$ kubectl apply -f networkPolicies.yaml 
$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
200
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GCPのCloud Pub/Sub</title>
          <link>https://www.sambaiz.net/article/180/</link>
          <pubDate>Thu, 26 Jul 2018 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/180/</guid>
          <description>&lt;p&gt;スケーラビリティに優れるメッセージングミドルウェア。
データはPullするだけではなくhttpsのエンドポイントにPushすることもでき、Cloud Dataflowを通してBigQueryやCloud MLに繋げることもできる。GAEのTaskQueueのように遅延させる機能は今のところない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/178/&#34;&gt;GAEのTaskQueue - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/pubsub/pricing&#34;&gt;料金&lt;/a&gt;はPublish/Pull/Pushしたデータ容量による。1TB送ると$60くらい。&lt;/p&gt;

&lt;p&gt;Goの&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go&#34;&gt;クライアントライブラリ&lt;/a&gt;で動かしてみる。
まずTopicを作成して50件Publishした後、Subsriptionを作成して、再び50件Publishする。
Publishできるデータは&lt;a href=&#34;https://cloud.google.com/pubsub/docs/publisher#header_1&#34;&gt;10MB未満&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;topic, err := client.CreateTopic(ctx, topicName)
if err != nil {
  panic(err)
}

var wg sync.WaitGroup
for i := 0; i &amp;lt; 50; i++ {
  wg.Add(1)
  go func() {
    if _, err := topic.Publish(ctx, &amp;amp;pubsub.Message{Data: []byte(strconv.Itoa(i))}).Get(ctx); err != nil {
      log.Fatalf(&amp;quot;Publish error: %s&amp;quot;, err.Error())
    } else {
      log.Printf(&amp;quot;Publish successful: %d&amp;quot;, i)
    }
    wg.Done()
  }()
  wg.Wait()
}

log.Printf(&amp;quot;Create Subscription&amp;quot;)
sub := createSubscription(ctx, client, topic, subscriptionName)

for i := 50; i &amp;lt; 100; i++ {
  wg.Add(1)
  go func() {
    if _, err := topic.Publish(ctx, &amp;amp;pubsub.Message{Data: []byte(strconv.Itoa(i))}).Get(ctx); err != nil {
      log.Fatalf(&amp;quot;Publish error: %s&amp;quot;, err.Error())
    } else {
      log.Printf(&amp;quot;Publish successful: %d&amp;quot;, i)
    }
    wg.Done()
  }()
  wg.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2018/07/26 21:42:51 Publish successful: 47
2018/07/26 21:42:51 Publish successful: 48
2018/07/26 21:42:51 Publish successful: 49
2018/07/26 21:42:51 Create Subscription
2018/07/26 21:42:58 Publish successful: 50
2018/07/26 21:42:58 Publish successful: 51
2018/07/26 21:42:58 Publish successful: 52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pull時のHandlerとしてAckを呼ぶackHandlerと、Nackを呼ぶnackHandler、何もしないnothingHandlerを用意した。
AckするとPub/Subからメッセージが消え、Nackまたはタイムアウトするとリトライされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type GotData struct {
	sync.Mutex
	gotData []string
}

var g = GotData{}

func ackHandler(done func()) func(ctx context.Context, m *pubsub.Message) {
	return func(ctx context.Context, m *pubsub.Message) {
		g.Lock()
		g.gotData = append(g.gotData, string(m.Data))
		sort.Slice(g.gotData, func(i, j int) bool {
			return g.gotData[i] &amp;lt; g.gotData[j]
		})
		log.Printf(&amp;quot;ackHandler got message: %s %#v&amp;quot;, m.Data, g.gotData)
		if len(g.gotData) == 50 {
			done()
		}
		g.Unlock()
		m.Ack()
	}
}

func nackHandler(ctx context.Context, m *pubsub.Message) {
	log.Printf(&amp;quot;nackHandler got message: %s&amp;quot;, m.Data)
	m.Nack()
}

func nothingHandler(ctx context.Context, m *pubsub.Message) {
	log.Printf(&amp;quot;nothingHandler got message: %s&amp;quot;, m.Data)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一つのSubscriptionを複数のSubscriberで使うことでメッセージを分散処理することができる。
ただし同じstructを使うとエラーになるのでそれぞれ生成している。&lt;/p&gt;

&lt;p&gt;nothingHandlerではSubscriptionの&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go/blob/f4024bfe9905677af1b3705dc5299b82622933c7/pubsub/subscription.go#L210&#34;&gt;MaxExtension&lt;/a&gt;を&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go/blob/f4024bfe9905677af1b3705dc5299b82622933c7/pubsub/subscription.go#L240&#34;&gt;デフォルト&lt;/a&gt;の10分から10秒にすることでリトライを早めている。&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go/blob/f4024bfe9905677af1b3705dc5299b82622933c7/pubsub/subscription.go#L136&#34;&gt;AckDeadline&lt;/a&gt;というのもあるがPullの場合、結局MaxExtensionまで延長してしまうので意味がないようだ。&lt;/p&gt;

&lt;p&gt;ReceiveSettingsにはほかに&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go/blob/f4024bfe9905677af1b3705dc5299b82622933c7/pubsub/subscription.go#L217&#34;&gt;MaxOutstandingMessages&lt;/a&gt;というのもあり、一度に処理されるメッセージの量を制限することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go func() {
  sub := client.Subscription(subscriptionName)
  if err := sub.Receive(ctx, ackHandler(cancel)); err != nil {
    panic(err)
  }
}()
go func() {
  sub := client.Subscription(subscriptionName)
  if err := sub.Receive(ctx, nackHandler); err != nil {
    panic(err)
  }
}()
go func() {
  sub := client.Subscription(subscriptionName)
  sub.ReceiveSettings.MaxExtension = time.Second * 10
  if err := sub.Receive(ctx, nothingHandler); err != nil {
		panic(err)
  }
}()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;nack/nothingHandlerによっていくつかリトライされた後、ackHandlerにSubscription作成後のメッセージが全て届いた。
データは&lt;a href=&#34;https://cloud.google.com/pubsub/faq#persistent&#34;&gt;7日間&lt;/a&gt;保持される。
メッセージの順序は&lt;a href=&#34;https://cloud.google.com/pubsub/docs/ordering&#34;&gt;保証されず&lt;/a&gt;、今回は1件ずつになっているが重複することがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2018/07/26 21:43:49 nothingHandler got message: 91
2018/07/26 21:44:28 nackHandler got message: 91
2018/07/26 21:44:30 ackHandler got message: 91 []string{&amp;quot;50&amp;quot;, &amp;quot;51&amp;quot;, &amp;quot;52&amp;quot;, &amp;quot;53&amp;quot;, &amp;quot;54&amp;quot;, &amp;quot;55&amp;quot;, &amp;quot;56&amp;quot;, &amp;quot;57&amp;quot;, &amp;quot;58&amp;quot;, &amp;quot;59&amp;quot;, &amp;quot;60&amp;quot;, &amp;quot;61&amp;quot;, &amp;quot;62&amp;quot;, &amp;quot;63&amp;quot;, &amp;quot;64&amp;quot;, &amp;quot;65&amp;quot;, &amp;quot;66&amp;quot;, &amp;quot;67&amp;quot;, &amp;quot;68&amp;quot;, &amp;quot;69&amp;quot;, &amp;quot;70&amp;quot;, &amp;quot;71&amp;quot;, &amp;quot;72&amp;quot;, &amp;quot;73&amp;quot;, &amp;quot;74&amp;quot;, &amp;quot;75&amp;quot;, &amp;quot;76&amp;quot;, &amp;quot;77&amp;quot;, &amp;quot;78&amp;quot;, &amp;quot;79&amp;quot;, &amp;quot;80&amp;quot;, &amp;quot;81&amp;quot;, &amp;quot;82&amp;quot;, &amp;quot;83&amp;quot;, &amp;quot;84&amp;quot;, &amp;quot;85&amp;quot;, &amp;quot;86&amp;quot;, &amp;quot;87&amp;quot;, &amp;quot;88&amp;quot;, &amp;quot;89&amp;quot;, &amp;quot;90&amp;quot;, &amp;quot;91&amp;quot;, &amp;quot;92&amp;quot;, &amp;quot;93&amp;quot;, &amp;quot;94&amp;quot;, &amp;quot;95&amp;quot;, &amp;quot;96&amp;quot;, &amp;quot;97&amp;quot;, &amp;quot;98&amp;quot;, &amp;quot;99&amp;quot;}
2018/07/26 21:44:30 Finished!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;スケールし、複数コンシューマーがそれぞれのタイミングでPullできるログの一時的な貯め先などとしてAWSのKinesis Data Streamsと同じようなユースケースで使われるが、Kinesisでは順序が保証されていたり、シャードの指定やデータの取り出し方といった扱いなど異なる点もある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/67/&#34;&gt;Kinesis Streams/Firehose/Analyticsを試す - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Destributed TensorFlowの流れとSavedModelの出力</title>
          <link>https://www.sambaiz.net/article/179/</link>
          <pubDate>Wed, 25 Jul 2018 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/179/</guid>
          <description>

&lt;h2 id=&#34;distributed-tensorflow-https-www-tensorflow-org-deploy-distributed&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/deploy/distributed&#34;&gt;Distributed TensorFlow&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;クラスタを組んでGraphを分散実行する。&lt;/p&gt;

&lt;p&gt;クラスタは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;master: sessionを作成し、workerを制御する&lt;/li&gt;
&lt;li&gt;worker: 計算を行う&lt;/li&gt;
&lt;li&gt;ps(parameter server): 変数の値を持ち、更新する&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のjobからなり、gRPCの&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/master_service.proto&#34;&gt;Master Service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/worker_service.proto&#34;&gt;Worker Service&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;でやり取りする。&lt;/p&gt;

&lt;h2 id=&#34;tensorflow-serverを立てる&#34;&gt;TensorFlow serverを立てる&lt;/h2&gt;

&lt;p&gt;各jobとURLのmapを&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/ClusterSpec&#34;&gt;ClusterSpec&lt;/a&gt;にして
jobとindexと併せて&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/ServerDef&#34;&gt;ServerDef&lt;/a&gt;を作って
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Server&#34;&gt;Server&lt;/a&gt;を立てる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;master&amp;quot;: [
        &amp;quot;check-tf-config-master-34z8-0:2222&amp;quot;
    ],
    &amp;quot;ps&amp;quot;: [
        &amp;quot;check-tf-config-ps-34z8-0:2222&amp;quot;,
        &amp;quot;check-tf-config-ps-34z8-1:2222&amp;quot;
    ],
    &amp;quot;worker&amp;quot;: [
        &amp;quot;check-tf-config-worker-34z8-0:2222&amp;quot;,
        &amp;quot;check-tf-config-worker-34z8-1:2222&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cluster_spec_object = tf.train.ClusterSpec(cluster_spec)
server_def = tf.train.ServerDef(
    cluster=cluster_spec_object.as_cluster_def(),
    protocol=&amp;quot;grpc&amp;quot;,
    job_name=job_name, # worker, master, ps 
    task_index=0)
server = tf.train.Server(server_def)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;psのjobでは&lt;code&gt;server.join()&lt;/code&gt;して待ち構える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if job_name == &amp;quot;ps&amp;quot;:
    server.join()
else:
    # build model
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;workerにgraphを割り当てる&#34;&gt;WorkerにGraphを割り当てる&lt;/h2&gt;

&lt;p&gt;workerの&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/device&#34;&gt;device&lt;/a&gt;にGraphを割り当てる。
deviceは&lt;code&gt;/job:worker/replica:0/task:0/device:GPU:0&lt;/code&gt;
のような&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/device.py#L130&#34;&gt;フォーマット&lt;/a&gt;で表される。&lt;/p&gt;

&lt;p&gt;Graphの持ち方には一つのGraphの異なる計算箇所をそれぞれのworkerが持つIn-graph replicationと、
それぞれGraphを持つBetween-graph replicationがある。これは後者の例で、&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/replica_device_setter&#34;&gt;replica_device_setter&lt;/a&gt;によってラウンドロビンで各psに変数を配置する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.device(tf.train.replica_device_setter(
    cluster=cluster_spec,
    worker_device=device
)):
    # graph
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;syncreplicasoptimizerのhookを追加&#34;&gt;SyncReplicasOptimizerのhookを追加&lt;/h2&gt;

&lt;p&gt;同期して変数を更新する場合、&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer&#34;&gt;SyncReplicasOptimizer&lt;/a&gt;を使い、make_session_run_hookで作られるhookをMonitoredTrainingSessionに渡す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/175/&#34;&gt;TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;train_op = tf.train.SyncReplicasOptimizer(
    tf.train.AdamOptimizer(self.learning_rate),
    replicas_to_aggregate=self.worker_num,
    total_num_replicas=self.worker_num)

hooks = [
    tf.train.StopAtStepHook(last_step=args.last_step),
    tf.train.CheckpointSaverHook(
        &#39;./ckpt&#39;,
        save_steps=args.save_steps,
        saver=saver),
    train_op.make_session_run_hook(self.is_chief)
]
with tf.train.MonitoredTrainingSession(
    is_chief=is_chief,
    master=master,
    hooks=hooks
) as sess:
    while not sess.should_stop():
    # sess.run()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;savedmodelの出力&#34;&gt;SavedModelの出力&lt;/h2&gt;

&lt;p&gt;実行後、SavedModelを出力する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/172/&#34;&gt;TensorFlowのモデルをsave/loadする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MonitoredTrainingSessionのsessは&lt;code&gt;should_stop()&lt;/code&gt;がtrueになったあとは使えなくなるため、
新しいsessionを作るかhookのendでする必要がある。&lt;/p&gt;

&lt;p&gt;新しいsessionでする例。そのままrestoreするとすでにworkerが終了している場合に、そのdeviceの変数もrestoreしようとして失敗するので
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/import_meta_graph&#34;&gt;import_meta_graph&lt;/a&gt;のclear_devicesをTrueにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
    with tf.Session() as sess:
        ckpt = tf.train.get_checkpoint_state(&amp;quot;ckpt&amp;quot;)
        saver = tf.train.import_meta_graph(
            &#39;{}.meta&#39;.format(ckpt.model_checkpoint_path),
            clear_devices=True)
        saver.restore(sess, ckpt.model_checkpoint_path)
        save.save(sess, &amp;quot;saved&amp;quot;, signature_def_map)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;hookでする例。restoreする必要がなくて良い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class SavedModelBuilderHook(session_run_hook.SessionRunHook):
    def __init__(self, export_dir, signature_def_map, tags):
        self.export_dir = export_dir
        self.signature_def_map = signature_def_map
        self.tags = tags

    def end(self, session):
        session.graph._unsafe_unfinalize()
        builder = tf.saved_model.builder.SavedModelBuilder(self.export_dir)
        builder.add_meta_graph_and_variables(
            session,
            self.tags,
            signature_def_map=self.signature_def_map
        )
        builder.save()
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GAEのTaskQueue</title>
          <link>https://www.sambaiz.net/article/178/</link>
          <pubDate>Sun, 15 Jul 2018 16:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/178/</guid>
          <description>

&lt;p&gt;GCPのマネージドなQueueサービスとしてGAEのTaskQueueがあることを教えてもらったので動かしてみる。
PushQueueとPullQueueがあって、それぞれおおよそAWSのSNSとSQSに相当する。PushQueueの場合はHTTPのリクエストとしてGAEのサービスに投げられる。PullQueueは&lt;a href=&#34;https://cloud.google.com/appengine/docs/standard/python/taskqueue/rest/&#34;&gt;Cloud Tasks API&lt;/a&gt;を使えばGAE外からも使えるらしいがまだalpha。&lt;/p&gt;

&lt;p&gt;設定ファイル&lt;a href=&#34;https://cloud.google.com/appengine/docs/standard/go/config/queueref&#34;&gt;queue.yaml&lt;/a&gt;はこんな感じ。bucket_sizeは最大同時実行数で空いていたらrateで埋められていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;queue:
- name: default
  rate: 10/m
  bucket_size: 5
  retry_parameters:
    min_backoff_seconds: 10
    max_backoff_seconds: 300
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bucket_sizeの最大は500なのでこれ以上の性能が必要な場合は複数のQueueに分けるか
&lt;a href=&#34;https://cloud.google.com/pubsub/&#34;&gt;Cloud Pub/Sub&lt;/a&gt;を使うことになる。ただし、&lt;a href=&#34;https://cloud.google.com/pubsub/faq?hl=ja#duplicates&#34;&gt;At-Least-Once&lt;/a&gt;なのでレコードが重複しても問題ないように作る必要がある。SQSも&lt;a href=&#34;https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html#standard-queues-at-least-once-delivery&#34;&gt;同じ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/180/&#34;&gt;GCPのCloud Pub/Sub - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;アプリケーション&#34;&gt;アプリケーション&lt;/h2&gt;

&lt;p&gt;/にアクセスすると2つのTaskをdefaultのTaskQueueにDelay25秒でPOSTする。
Taskによるリクエストは/workerで受け、30%の確率で500エラーを返すようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;math/rand&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;net/url&amp;quot;
	&amp;quot;strconv&amp;quot;
	&amp;quot;time&amp;quot;

	&amp;quot;google.golang.org/appengine&amp;quot;
	&amp;quot;google.golang.org/appengine/log&amp;quot;
	&amp;quot;google.golang.org/appengine/taskqueue&amp;quot;
)

func main() {
	http.HandleFunc(&amp;quot;/&amp;quot;, handler)
	http.HandleFunc(&amp;quot;/worker&amp;quot;, handlerQueue)
	appengine.Main()
}

func handler(w http.ResponseWriter, r *http.Request) {
	ctx := appengine.NewContext(r)
	// POST body: name=a%26&amp;amp;value=20
	t := taskqueue.NewPOSTTask(&amp;quot;/worker&amp;quot;, map[string][]string{&amp;quot;name&amp;quot;: {&amp;quot;a&amp;amp;&amp;quot;}, &amp;quot;time&amp;quot;: {strconv.FormatInt(time.Now().UnixNano(), 10)}})
	t.Delay = time.Second * 25
	// POST body: name=a&amp;amp;name=b
	t2 := taskqueue.NewPOSTTask(&amp;quot;/worker&amp;quot;, map[string][]string{&amp;quot;name&amp;quot;: {&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;}})
	if _, err := taskqueue.AddMulti(ctx, []*taskqueue.Task{t, t2}, &amp;quot;&amp;quot;); err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	fmt.Fprintln(w, &amp;quot;ok&amp;quot;)
}

func handlerQueue(w http.ResponseWriter, r *http.Request) {
	ctx := appengine.NewContext(r)

	bodyb, err := ioutil.ReadAll(r.Body)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	body := string(bodyb)
	log.Infof(ctx, &amp;quot;%s\n&amp;quot;, body)

	values, err := url.ParseQuery(body)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	log.Infof(ctx, &amp;quot;%#+v\n&amp;quot;, values)
	if rand.Float64() &amp;lt; 0.3 {
		http.Error(w, &amp;quot;random fail&amp;quot;, http.StatusInternalServerError)
		return
	}
	fmt.Fprintln(w, &amp;quot;ok&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デプロイして何度かアクセスする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud app deploy queue.yaml
$ gcloud app deploy
$ gcloud app browse
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TaskがQueueに入り、エラーの場合はリトライしていることが確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/178.png&#34; alt=&#34;PushQueue&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通常Delay経ってETA(Estimate Time of Arrival?)を迎えたものから処理されていくが、bucketやrateが小さい場合リトライが重なって渋滞すると過ぎても処理されず溜まってしまうことがある。リトライ時のDelayはmax_backoff_secondsまでの範囲内でExponential Backoffし、task_retry_limitを指定しないと永遠にリトライし続ける。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/furuyamayuuki/gcp-72165187&#34;&gt;スケーラブル GCP アーキテクチャ&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>WebSocketでの通信内容をWiresharkで見る</title>
          <link>https://www.sambaiz.net/article/177/</link>
          <pubDate>Tue, 10 Jul 2018 23:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/177/</guid>
          <description>

&lt;p&gt;Webで双方向通信するためのプロトコル、WebSocketでの通信内容をWiresharkで見る。&lt;/p&gt;

&lt;h2 id=&#34;アプリケーション&#34;&gt;アプリケーション&lt;/h2&gt;

&lt;h3 id=&#34;サーバー&#34;&gt;サーバー&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io&amp;quot;
	&amp;quot;net/http&amp;quot;

	&amp;quot;golang.org/x/net/websocket&amp;quot;
)

type Payload struct {
	A string
}

func Handler(ws *websocket.Conn) {
	ctx, cancel := context.WithCancel(context.Background())
	go func() {
		var payload Payload
		for {
			err := websocket.JSON.Receive(ws, &amp;amp;payload)
			if err != nil {
				if err == io.EOF {
					fmt.Println(&amp;quot;connection closed&amp;quot;)
				} else {
					fmt.Println(err)
				}
				cancel()
				break
			}
			fmt.Println(payload.A)
		}
	}()
	websocket.JSON.Send(ws, Payload{A: &amp;quot;a&amp;quot;})
	select {
	case &amp;lt;-ctx.Done():
	}
}

func main() {
	http.Handle(&amp;quot;/&amp;quot;, websocket.Handler(Handler))
	http.ListenAndServe(&amp;quot;:12345&amp;quot;, nil)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;クライアント&#34;&gt;クライアント&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
const websocket = new WebSocket(&amp;quot;ws://localhost:12345&amp;quot;);
console.log(websocket)
websocket.onopen = (e) =&amp;gt; { 
    setInterval(() =&amp;gt; {
        console.log(&amp;quot;send&amp;quot;)
        websocket.send(JSON.stringify({A: &amp;quot;あ&amp;quot;.repeat(50)}));
    }, 10000)
};
websocket.onmessage = (e) =&amp;gt; { 
    console.log(`received ${e.data}`);
};
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wireshark-https-www-wireshark-org-のインストール&#34;&gt;&lt;a href=&#34;https://www.wireshark.org/&#34;&gt;Wireshark&lt;/a&gt;のインストール&lt;/h2&gt;

&lt;p&gt;GUIが立ち上がるので&lt;code&gt;tcp.port == 12345&lt;/code&gt;のフィルタで待ち構える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install wireshark --with-qt
$ sudo wireshark
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;通信内容&#34;&gt;通信内容&lt;/h2&gt;

&lt;h3 id=&#34;websocketで通信するまで&#34;&gt;WebSocketで通信するまで&lt;/h3&gt;

&lt;p&gt;まず通常のHTTP通信と同様に3-way handshakeでTCPのコネクションを張った後、
&lt;code&gt;Upgrade: WebSocket&lt;/code&gt;と&lt;code&gt;Connection: Upgrade&lt;/code&gt;を付けたリクエストをサーバーに送ってWebSocketでの通信を要求する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Hypertext Transfer Protocol
    GET / HTTP/1.1\r\n
    Host: localhost:12345\r\n
    Connection: Upgrade\r\n
    Pragma: no-cache\r\n
    Cache-Control: no-cache\r\n
    Upgrade: websocket\r\n
    Sec-WebSocket-Version: 13\r\n
    Sec-WebSocket-Key: vuQHXJAxDEdD9pQ3d7RtOw==\r\n
    Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits\r\n    
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それに対してサーバーはステータスコード101でレスポンスを返す。
送られてきたランダムな&lt;code&gt;Sec-WebSocket-Key&lt;/code&gt;をもとに生成した&lt;code&gt;Sec-WebSocket-Accept&lt;/code&gt;
をヘッダーに付けて、クライアントはこれを見て正しいWebSocketサーバーであることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Hypertext Transfer Protocol
    HTTP/1.1 101 Switching Protocols\r\n
    Upgrade: websocket\r\n
    Connection: Upgrade\r\n
    Sec-WebSocket-Accept: oImbSbalm6WMVbXV5oqmRlHHhWg=\r\n
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;websocketでの通信&#34;&gt;WebSocketでの通信&lt;/h3&gt;

&lt;p&gt;サーバーからクライアントへのデータ。
HTTP/1.1のヘッダーはテキストで記述も多いためデータ量が大きく、毎回それらを送る必要があり効率的ではなかったが、WebSocketではこの場合Payloadを除いた部分が2bytesしかない。&lt;/p&gt;

&lt;p&gt;ちなみにHTTP/2では差分を送るHPACKというフォーマットで圧縮した、バイナリのHEADERSフレームにすることで、この問題を改善している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WebSocket
    1... .... = Fin: True
    .000 .... = Reserved: 0x0
    .... 0001 = Opcode: Text (1)
    0... .... = Mask: False
    .000 1001 = Payload length: 9
    Payload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クライアントからサーバーへのデータ。Payload lengthが125を超えたため拡張されている。
それ以外にMasked payloadが含まれるのでデータ量が少し大きくなっている。これは不正なスクリプトがHTTPリクエストに偽装したデータを送ることでプロキシのキャッシュが汚染されるのを防ぐため。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WebSocket
    1... .... = Fin: True
    .000 .... = Reserved: 0x0
    .... 0001 = Opcode: Text (1)
    1... .... = Mask: True
    .111 1110 = Payload length: 126 Extended Payload Length (16 bits)
    Extended Payload length (16 bits): 158
    Masking-Key: ef17e997
    Masked payload
    Payload
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://plus.google.com/u/0/+TakeshiYoshino/posts/af6Fg972tGQ&#34;&gt;The WebSocket Protocol (RFC 6455) の歴史&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DOMの(next/previous)SiblingとElementSiblingの値</title>
          <link>https://www.sambaiz.net/article/176/</link>
          <pubDate>Wed, 04 Jul 2018 23:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/176/</guid>
          <description>

&lt;p&gt;Siblingは兄弟姉妹という意味&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
&amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt;
&amp;lt;li id=&amp;quot;li2&amp;quot;&amp;gt;2&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;3&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;

&amp;lt;script&amp;gt;
const el = document.querySelector(&amp;quot;li#li2&amp;quot;);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sibling&#34;&gt;Sibling&lt;/h2&gt;

&lt;p&gt;elのpreviousSiblingを取ると&lt;code&gt;&amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt;&lt;/code&gt;になると思いきや、その直前の空白や改行を含むtext nodeが返る。
それらが全くない場合隣のElementが返ることになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const el2 = el.previousSibling;
console.log(`previousSibling: ${el2.nodeName} &amp;quot;${el2.textContent}&amp;quot;`);
/*
#text &amp;quot;
&amp;quot;
*/

const el4 = el.nextSibling;
console.log(`nextSibling: ${el4.nodeName} &amp;quot;${el4.textContent}&amp;quot;`); // LI &amp;quot;3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;elementsibling&#34;&gt;ElementSibling&lt;/h2&gt;

&lt;p&gt;多くの場合で意図した結果が返るのはこっち。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const el3 = el.previousElementSibling;
console.log(`previousElementSibling: ${el3.nodeName} &amp;quot;${el3.textContent}&amp;quot;`); // LI &amp;quot;1&amp;quot;

const el5 = el.nextElementSibling;
console.log(`nextElementSibling: ${el5.nodeName} &amp;quot;${el5.textContent}&amp;quot;`); // LI &amp;quot;3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;firstChildとfirstElementChildなどの関係も同じ。存在を忘れていてひっかかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const el6 = document.querySelector(&amp;quot;ul&amp;quot;).firstChild;
console.log(`firstChild: ${el6.nodeName} &amp;quot;${el6.textContent}&amp;quot;`);
/*
fistChild: #text &amp;quot;
&amp;quot;
*/
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー</title>
          <link>https://www.sambaiz.net/article/175/</link>
          <pubDate>Sun, 01 Jul 2018 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/175/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/MonitoredSession&#34;&gt;MonitoredSession&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;deprecatedになった&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Supervisor&#34;&gt;Supervisor&lt;/a&gt;の後継。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/MonitoredTrainingSession&#34;&gt;MonitoredTrainingSession&lt;/a&gt;で学習用のMonitoredSessionを生成する。
このコンストラクタの引数でcheckpoint_dirを渡すと内部で&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/CheckpointSaverHook&#34;&gt;CheckpointSaverHook&lt;/a&gt;が
&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/monitored_session.py#L396&#34;&gt;追加される&lt;/a&gt;ようになっていて、restoreしたり指定したタイミングでsaveしたりしてくれる。&lt;/p&gt;

&lt;p&gt;なので今回明示的に渡すhooksは
指定したstepに到達したら&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/basic_session_run_hooks.py#L320&#34;&gt;止めてくれる&lt;/a&gt;、&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/StopAtStepHook&#34;&gt;StopAtStepHook&lt;/a&gt;のみ。&lt;/p&gt;

&lt;p&gt;should_stop()がTrueな状態で&lt;code&gt;session.run()&lt;/code&gt;しようとすると&lt;code&gt;Run called even after should_stop requested.&lt;/code&gt;のエラーが出るため、
今回は新しいsessionを作ってAccuracyを返しているが、hookでやった方がrestoreする必要がないので良さそうだ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/179/&#34;&gt;Destributed TensorFlowの流れとSavedModelの出力 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;全体のコードは&lt;a href=&#34;https://gist.github.com/sambaiz/72888520379cff778d6261cd417a3773&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def train(self, learning_rate, variable_default_stddev, bias_default, last_step=800):
  test_images = self.images[:500]
  test_labels = self.labels[:500]
  train_batch = Batch(self.images[500:], self.labels[500:])

  with tf.Graph().as_default():
    global_step=tf.train.get_or_create_global_step()
    g = MNIST_CNN(learning_rate,  variable_default_stddev, bias_default).graph()
    saver = tf.train.Saver()
    savedir = &#39;./ckpt-{}-{}-{}&#39;.format(learning_rate, variable_default_stddev, bias_default)
    hooks = [
      tf.train.StopAtStepHook(last_step=last_step)
    ]
    with tf.train.MonitoredTrainingSession(
      hooks=hooks,
      checkpoint_dir=savedir,
      save_checkpoint_secs = 300,
    ) as sess:
      sess.run(global_step)
      while not sess.should_stop():
        # step = sess.run(global_step)
        images, labels = train_batch.get_next(500)
        sess.run(g[&amp;quot;op&amp;quot;][&amp;quot;train_step&amp;quot;], feed_dict={
          g[&amp;quot;placeholder&amp;quot;][&amp;quot;x&amp;quot;]: list(images), 
          g[&amp;quot;placeholder&amp;quot;][&amp;quot;y&amp;quot;]: list(labels),
        })
    with tf.Session() as sess:
      self._restore(sess, saver, savedir)
      return sess.run(g[&amp;quot;op&amp;quot;][&amp;quot;accuracy&amp;quot;], feed_dict={
        g[&amp;quot;placeholder&amp;quot;][&amp;quot;x&amp;quot;]: list(test_images), 
        g[&amp;quot;placeholder&amp;quot;][&amp;quot;y&amp;quot;]: list(test_labels)
      }), savedir
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;hooksに渡す&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/session_run_hook.py#L103&#34;&gt;SessionRunHook&lt;/a&gt;は以下のメソッドからなる。
&lt;code&gt;before_run()&lt;/code&gt;で返すSessionRunArgsのfeed_dictはrunで渡すfeed_dictとmergeされ、
fetchesはrunするたびに毎回評価される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class MySessionRunHook:
  def __init__(self, feed_dict):
    self.feed_dict = feed_dict
    self.a = tf.placeholder(tf.float32, name=&amp;quot;a&amp;quot;)
      
  def begin(self):
    &amp;quot;&amp;quot;&amp;quot;Called once before using the session.&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;begin&amp;quot;)

  def after_create_session(self, session, coord):
    &amp;quot;&amp;quot;&amp;quot;Called when new TensorFlow session is created.&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;after_create_session&amp;quot;)
      
  def before_run(self, run_context):
    &amp;quot;&amp;quot;&amp;quot;Called before each call to run().&amp;quot;&amp;quot;&amp;quot;
    return SessionRunArgs(fetches={&amp;quot;a&amp;quot;: self.a}, feed_dict=self.feed_dict)
  
  def after_run(self, run_context, run_values):
    &amp;quot;&amp;quot;&amp;quot;Called after each call to run().&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;after_run {} {}&amp;quot;.format(run_values.results[&amp;quot;a&amp;quot;], run_context.session.run(self.a, feed_dict={self.a: 10})))

  def end(self, session):
    &amp;quot;&amp;quot;&amp;quot;Called at the end of session.&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;end&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したがって、hooks内のfetchesにfeedする必要があるものが含まれる場合、
runする対象がfeedする必要がない場合でも&lt;code&gt;You must feed a value for placeholder tensor&lt;/code&gt;のエラーが出ることになる。
また、hooks内とrunの引数のfeed_dictが衝突した場合もエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
  global_step = tf.train.get_or_create_global_step()
  x = tf.placeholder(tf.float32, name=&amp;quot;x&amp;quot;)
  y = tf.placeholder(tf.float32, name=&amp;quot;y&amp;quot;)
  z = x + y
  hook1 = MySessionRunHook({x: 2})
  hook2 = MySessionRunHook({y: 3})
  hooks=[hook1, hook2]
  with tf.train.MonitoredTrainingSession(hooks=hooks) as sess:
    try:
      print(sess.run(global_step))
    except tf.errors.InvalidArgumentError as err:
      print(err) # You must feed a value for placeholder tensor &#39;a_1&#39; with dtype float ...
    print(sess.run([global_step, z], feed_dict={hook1.a: 2, hook2.a: 3})) # [0, 5.0]
    try:
      print(sess.run(y, feed_dict={x: 10}))
    except RuntimeError as err:
      print(err) # Same tensor is fed by a SessionRunHook and user. Conflict(s): [&amp;lt;tf.Tensor &#39;x:0&#39; shape=&amp;lt;unknown&amp;gt; dtype=float32&amp;gt;]     
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上で書いたようにMonitoredTrainingSessionは内部でCheckpointSaverHookを持っていて、
これがfetchesでsummaryを&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/basic_session_run_hooks.py#L689&#34;&gt;返している&lt;/a&gt;ので、一つでもsummaryを入れるとrunするときにそれに必要なfeed_dictを渡さないとエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
  global_step = tf.train.get_or_create_global_step()
  x = tf.placeholder(tf.float32, name=&amp;quot;x&amp;quot;)
  y = tf.placeholder(tf.float32, name=&amp;quot;y&amp;quot;)
  z = x + y
  tf.summary.scalar(&amp;quot;z&amp;quot;, z)
  with tf.train.MonitoredTrainingSession(checkpoint_dir=&amp;quot;./aaa&amp;quot;, save_summaries_steps=1) as sess:
    # ng
    # sess.run(global_step) =&amp;gt; You must feed a value for placeholder tensor &#39;y&#39; with dtype float
    # sess.run(z, feed_dict={x: 10, y:20})
    step, zz = sess.run([global_step, z], feed_dict={x: 10, y:20}) # ok
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GoのgRPC ServerのInterceptor(recovery/auth/zap/prometheus)</title>
          <link>https://www.sambaiz.net/article/174/</link>
          <pubDate>Tue, 26 Jun 2018 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/174/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/grpc/grpc-go&#34;&gt;grpc-go&lt;/a&gt;はInterceptor(Middleware)でhandlerの前後で処理を行うことができる。
UnaryとStreamで&lt;a href=&#34;https://github.com/grpc/grpc-go/blob/master/interceptor.go#L60&#34;&gt;シグネチャ&lt;/a&gt;が異なる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type UnaryServerInterceptor func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (resp interface{}, err error)
type StreamServerInterceptor func(srv interface{}, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func UnaryServerInterceptor(opts ...Option) grpc.UnaryServerInterceptor {
    return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) {
        resp, err := handler(newCtx, req)
        fmt.Println(resp)
        return resp, err
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回は良く使う&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware&#34;&gt;go-grpc-middleware&lt;/a&gt;の&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/tree/master/recovery&#34;&gt;recovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/tree/master/auth&#34;&gt;auth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/tree/master/logging/zap&#34;&gt;zap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-prometheus&#34;&gt;prometehus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Interceptorの挙動を確認する。&lt;/p&gt;

&lt;h2 id=&#34;proto&#34;&gt;proto&lt;/h2&gt;

&lt;p&gt;UnaryなRPCとBidirectional streaming(client, server共にstream)なRPCを一つずつ用意する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat protos/sample/service.proto
syntax = &amp;quot;proto3&amp;quot;;

package sample;

message SampleRequest {
  string sampleInput = 1;
}

message SampleResponse {
  string sampleOutput = 1;
}

service SampleService {
  rpc SampleUnary (SampleRequest) returns (SampleResponse) {}
  rpc SampleStream (stream SampleRequest) returns (stream SampleResponse) {}
}

$ go get -u github.com/golang/protobuf/protoc-gen-go
$ mkdir go
$ protoc --go_out=plugins=grpc:./go --proto_path=./protos protos/*/*.proto
$ ls go/sample
service.pb.go
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;service&#34;&gt;Service&lt;/h2&gt;

&lt;p&gt;Unaryの方でcontextからユーザー名を取り出しているのと、
Streamの方では&amp;rdquo;panic&amp;rdquo;という入力が来たときにpanicになるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type sampleService struct{}

type ctxKey string

var ctxKeyUserName = &amp;quot;userNames&amp;quot;

func (s *sampleService) SampleUnary(ctx context.Context, in *sample.SampleRequest) (*sample.SampleResponse, error) {
	return &amp;amp;sample.SampleResponse{SampleOutput: ctx.Value(ctxKeyUserName).(string)}, nil
}

func (s *sampleService) SampleStream(stream sample.SampleService_SampleStreamServer) error {
	for {
		in, err := stream.Recv()
		if err == io.EOF {
			return nil
		}
		if err != nil {
			return err
		}
		if in.SampleInput == &amp;quot;panic&amp;quot; {
			panic(&amp;quot;received panic&amp;quot;)
		}
		inputRunes := []rune(in.SampleInput)
		for i := 0; i &amp;lt; len(inputRunes); i++ {
			if err := stream.Send(&amp;amp;sample.SampleResponse{
				SampleOutput: string(inputRunes[i]),
			}); err != nil {
				return err
			}
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;server&#34;&gt;Server&lt;/h2&gt;

&lt;p&gt;NewServerでUnary/StreamそれぞれのInterceptorを登録する。
prometheusはさらに&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-prometheus/blob/v1.2.0/server_metrics.go#L63&#34;&gt;EnableHandlingTimeHistogram()&lt;/a&gt;してRegisterしている。&lt;/p&gt;

&lt;p&gt;zapには&lt;a href=&#34;https://github.com/uber-go/zap/blob/v1.8.0/logger.go#L93&#34;&gt;NewProduction()&lt;/a&gt;のloggerをそのまま渡しているのでログはstderrに&lt;a href=&#34;https://github.com/uber-go/zap/blob/7307fae54f855761db01409a36e87fe18ebd8ef4/config.go#L124&#34;&gt;出力される&lt;/a&gt;。
これを&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/blob/91d9dda9fdb0440370fd55356f216a6293cbeb95/logging/zap/grpclogger.go#L15&#34;&gt;ReplaceGrpcLogger()&lt;/a&gt;でも渡しているのでgRPCライブラリ内部のエラーも出る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/104/&#34;&gt;Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io&amp;quot;
	&amp;quot;math&amp;quot;
	&amp;quot;net&amp;quot;
	&amp;quot;net/http&amp;quot;

	&amp;quot;github.com/grpc-ecosystem/go-grpc-middleware&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/go-grpc-middleware/auth&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/go-grpc-middleware/logging/zap&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/go-grpc-middleware/recovery&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/go-grpc-prometheus&amp;quot;
	&amp;quot;github.com/sambaiz/grpc-interceptors/go/sample&amp;quot;
	&amp;quot;github.com/prometheus/client_golang/prometheus/promhttp&amp;quot;
	&amp;quot;go.uber.org/zap&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/codes&amp;quot;
)

func main() {
	zapLogger, err := zap.NewProduction()
	if err != nil {
		panic(err)
	}
	grpc_zap.ReplaceGrpcLogger(zapLogger)
	grpcServer := grpc.NewServer(
		grpc.StreamInterceptor(grpc_middleware.ChainStreamServer(
			grpc_recovery.StreamServerInterceptor(),
			grpc_zap.StreamServerInterceptor(zapLogger),
			grpc_auth.StreamServerInterceptor(auth),
			grpc_prometheus.StreamServerInterceptor,
		)),
		grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer(
			grpc_recovery.UnaryServerInterceptor(),
			grpc_zap.UnaryServerInterceptor(zapLogger),
			grpc_auth.UnaryServerInterceptor(auth),
			grpc_prometheus.UnaryServerInterceptor,
		)),
		grpc.MaxRecvMsgSize(math.MaxInt32))

	grpc_prometheus.EnableHandlingTimeHistogram()
	grpc_prometheus.Register(grpcServer)
	http.Handle(&amp;quot;/metrics&amp;quot;, promhttp.Handler())
	go func() {
		if err := http.ListenAndServe(&amp;quot;:8081&amp;quot;, nil); err != nil {
			panic(err)
		}
	}()

	sample.RegisterSampleServiceServer(grpcServer, &amp;amp;sampleService{})

	port := 8080
	listener, err := net.Listen(&amp;quot;tcp&amp;quot;, fmt.Sprintf(&amp;quot;:%d&amp;quot;, port))
	if err != nil {
		return
	}
	fmt.Printf(&amp;quot;GRPC server started on :%d\n&amp;quot;, port)
	grpcServer.Serve(listener)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;authに渡している関数では&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/blob/v1.0.0/auth/metadata.go#L24&#34;&gt;AuthFromMD()&lt;/a&gt;でmetadataのauthorizationのトークンを取得しユーザー名に変換してcontextに入れている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func auth(ctx context.Context) (context.Context, error) {
	token, err := grpc_auth.AuthFromMD(ctx, &amp;quot;basic&amp;quot;)
	if err != nil {
		return nil, err
	}
	users := map[string]string{
		&amp;quot;aaaaaa&amp;quot;: &amp;quot;sam&amp;quot;,
	}
	userName, ok := users[token]
	if !ok {
		return nil, grpc.Errorf(codes.Unauthenticated, &amp;quot;invalid auth token&amp;quot;)
	}
	newCtx := context.WithValue(ctx, ctxKeyUserName, userName)
	return newCtx, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;client&#34;&gt;Client&lt;/h2&gt;

&lt;p&gt;UnaryとStreamのRPCにそれぞれリクエストを送る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/grpc/grpc-go/blob/v1.13.0/clientconn.go#L325&#34;&gt;WithPerRPCCredentials()&lt;/a&gt;で各RPCでauthorizationがmetadataとして渡るようにしている。
&lt;a href=&#34;https://github.com/grpc/grpc-go/blob/v1.13.0/metadata/metadata.go#L155&#34;&gt;AppendToOutgoingContext&lt;/a&gt;で都度含めることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ctx = metadata.AppendToOutgoingContext(ctx, key, value)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;メトリクスは出していないがprometheusのClientのInterceptorを付けている。
このようにIntercpetorによってはClient用のものも用意されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;fmt&amp;quot;

	&amp;quot;github.com/grpc-ecosystem/go-grpc-prometheus&amp;quot;
	&amp;quot;github.com/sambaiz/grpc-interceptors/go/sample&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
)

type cred struct{}

func (c *cred) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) {
	return map[string]string{
		&amp;quot;authorization&amp;quot;: &amp;quot;basic aaaaaa&amp;quot;,
	}, nil
}

func (c *cred) RequireTransportSecurity() bool {
	return false
}

func main() {
	conn, err := grpc.Dial(
		&amp;quot;localhost:8080&amp;quot;,
		grpc.WithInsecure(),
		grpc.WithPerRPCCredentials(&amp;amp;cred{}),
		grpc.WithUnaryInterceptor(grpc_prometheus.UnaryClientInterceptor),
		grpc.WithStreamInterceptor(grpc_prometheus.StreamClientInterceptor),
	)
	if err != nil {
		panic(err)
	}
	client := sample.NewSampleServiceClient(conn)

	fmt.Println(&amp;quot;- Unary -&amp;quot;)
	unaryResult, err := client.SampleUnary(context.Background(), &amp;amp;sample.SampleRequest{
		SampleInput: &amp;quot;hello&amp;quot;,
	})
	if err != nil {
		panic(err)
	}
	fmt.Println(unaryResult.SampleOutput)
	streamClient, err := client.SampleStream(context.Background())
	if err != nil {
		panic(err)
	}
	defer streamClient.CloseSend()

	fmt.Println(&amp;quot;- Stream -&amp;quot;)
	if err := streamClient.Send(&amp;amp;sample.SampleRequest{
		SampleInput: &amp;quot;he&amp;quot;,
	}); err != nil {
		panic(err)
	}
	if err := streamClient.Send(&amp;amp;sample.SampleRequest{
		SampleInput: &amp;quot;llo&amp;quot;,
	}); err != nil {
		panic(err)
	}
	if err := streamClient.Send(&amp;amp;sample.SampleRequest{
		SampleInput: &amp;quot;panic&amp;quot;,
	}); err != nil {
		panic(err)
	}
	for {
		response, err := streamClient.Recv()
		if err != nil {
			fmt.Println(err)
			break
		} else {
			fmt.Println(response.SampleOutput)
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行結果&#34;&gt;実行結果&lt;/h2&gt;

&lt;p&gt;authによってユーザー名がcontextに入っている。
recoveryがrecoverしているのでpanicしてもサーバーは落ちていない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go run client.go
- Unary -
sam
- Stream -
h
e
l
l
o
rpc error: code = Internal desc = received panic

$ go run main.go
- Unary -
sam
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;zapでログが出ている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GRPC server started on :8080
{&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1530020624.963142,&amp;quot;caller&amp;quot;:&amp;quot;zap/server_interceptors.go:40&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;finished unary call with code OK&amp;quot;,&amp;quot;grpc.start_time&amp;quot;:&amp;quot;2018-06-26T22:43:44+09:00&amp;quot;,&amp;quot;system&amp;quot;:&amp;quot;grpc&amp;quot;,&amp;quot;span.kind&amp;quot;:&amp;quot;server&amp;quot;,&amp;quot;grpc.service&amp;quot;:&amp;quot;sample.SampleService&amp;quot;,&amp;quot;grpc.method&amp;quot;:&amp;quot;SampleUnary&amp;quot;,&amp;quot;grpc.code&amp;quot;:&amp;quot;OK&amp;quot;,&amp;quot;grpc.time_ms&amp;quot;:0.27799999713897705}
{&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1530020624.9652505,&amp;quot;caller&amp;quot;:&amp;quot;zap/grpclogger.go:41&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;transport: loopyWriter.run returning. connection error: desc = \&amp;quot;transport is closing\&amp;quot;&amp;quot;,&amp;quot;system&amp;quot;:&amp;quot;grpc&amp;quot;,&amp;quot;grpc_log&amp;quot;:true}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;prometheusのInterceptorでCounterのメトリクスが追加されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grpc_server_handled_total{grpc_code=&amp;quot;OK&amp;quot;,grpc_method=&amp;quot;SampleUnary&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;unary&amp;quot;} 1
grpc_server_msg_sent_total{grpc_method=&amp;quot;SampleStream&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;bidi_stream&amp;quot;} 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;EnableHandlingTimeHistogram()&lt;/code&gt;でHistogramsのメトリクスも追加されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grpc_server_handling_seconds_bucket{grpc_method=&amp;quot;SampleUnary&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;unary&amp;quot;,le=&amp;quot;0.005&amp;quot;} 1
grpc_server_handling_seconds_bucket{grpc_method=&amp;quot;SampleUnary&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;unary&amp;quot;,le=&amp;quot;0.01&amp;quot;} 1
grpc_server_handling_seconds_bucket{grpc_method=&amp;quot;SampleUnary&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;unary&amp;quot;,le=&amp;quot;0.025&amp;quot;} 1
grpc_server_handling_seconds_sum{grpc_method=&amp;quot;SampleStream&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;bidi_stream&amp;quot;} 271.267611998
grpc_server_handling_seconds_count{grpc_method=&amp;quot;SampleStream&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;bidi_stream&amp;quot;} 1
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress</title>
          <link>https://www.sambaiz.net/article/173/</link>
          <pubDate>Sat, 23 Jun 2018 15:02:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/173/</guid>
          <description>

&lt;h2 id=&#34;疎通確認用アプリケーション&#34;&gt;疎通確認用アプリケーション&lt;/h2&gt;

&lt;p&gt;GETでは200を返し、POSTではURLにGETリクエストを送ってステータスコードを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;encoding/json&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;net/http&amp;quot;
)

type PostBody struct {
	URL string `json:&amp;quot;url&amp;quot;`
}

func handler(w http.ResponseWriter, r *http.Request) {
	if r.Method == http.MethodGet {
		fmt.Fprintln(w, &amp;quot;ok&amp;quot;)
	} else if r.Method == http.MethodPost {
		data, err := ioutil.ReadAll(r.Body)
		if err != nil {
			w.WriteHeader(http.StatusInternalServerError)
			fmt.Fprintln(w, err.Error())
			return
		}
		p := PostBody{}
		if err := json.Unmarshal(data, &amp;amp;p); err != nil {
			w.WriteHeader(http.StatusBadRequest)
			fmt.Fprintln(w, err.Error())
			return
		}

		resp, err := http.DefaultClient.Get(p.URL)
		if err != nil {
			fmt.Fprintln(w, err.Error())
			return
		}
		defer resp.Body.Close()
		fmt.Fprintln(w, resp.StatusCode)
	} else {
		w.WriteHeader(http.StatusMethodNotAllowed)
	}
}

func main() {
	http.HandleFunc(&amp;quot;/&amp;quot;, handler)
	fmt.Println(&amp;quot;Listen on :8080&amp;quot;)
	http.ListenAndServe(&amp;quot;:8080&amp;quot;, nil)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;FROM golang:1.10-alpine3.7 AS build-env
WORKDIR /app
ADD . /app
RUN cd /app &amp;amp;&amp;amp; go build -o goapp

FROM alpine:3.7
RUN apk update &amp;amp;&amp;amp; \
   apk add ca-certificates &amp;amp;&amp;amp; \
   update-ca-certificates &amp;amp;&amp;amp; \
   rm -rf /var/cache/apk/*
WORKDIR /app
COPY --from=build-env /app/goapp /app
EXPOSE 8080
ENTRYPOINT ./goapp
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t asia.gcr.io/*****/network-checker .
$ gcloud docker -- push asia.gcr.io/*****/network-checker
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deploymentとserviceを作成&#34;&gt;DeploymentとServiceを作成&lt;/h2&gt;

&lt;p&gt;ksonnetでマニフェストを生成した。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/171/&#34;&gt;ksonnetでkubernetesのmanifestを環境ごとに生成/applyする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ks init try-service
$ cd try-service
$ ks generate deployed-service clusterip-app --image asia.gcr.io/****/network-checker --type ClusterIP
$ ks generate deployed-service nodeport-app --image asia.gcr.io/l****/network-checker --type NodePort
$ ks generate deployed-service loadbalancer-app --image asia.gcr.io/****/network-checker --type LoadBalancer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;containerPortを8080に変更して、PodがPendingしないようにresourcesを絞る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;containers&amp;quot;: [
  {
     ...
     &amp;quot;resources&amp;quot;: {
        &amp;quot;limits&amp;quot;: {
           &amp;quot;cpu&amp;quot;: params.cpu,
           &amp;quot;memory&amp;quot;: params.memory
        },
        &amp;quot;requests&amp;quot;: {
           &amp;quot;cpu&amp;quot;: params.cpu,
           &amp;quot;memory&amp;quot;: params.memory
        }
     }
  }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ ks apply default
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get service
NAME               TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
clusterip-app      ClusterIP      10.11.253.76    &amp;lt;none&amp;gt;            80/TCP         8m
kubernetes         ClusterIP      10.11.240.1     &amp;lt;none&amp;gt;            443/TCP        3h
loadbalancer-app   LoadBalancer   10.11.250.126   130.211.166.214   80:32627/TCP   8m
nodeport-app       NodePort       10.11.253.190   &amp;lt;none&amp;gt;            80:31233/TCP   8m
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;loadbalancer&#34;&gt;LoadBalancer&lt;/h3&gt;

&lt;p&gt;L4のNetwork Load Balancerが立ち、ヘルスチェックが通っていればEXTERNAL-IPでそのままアクセスできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/173-l4lb.png&#34; alt=&#34;Network Load Balancer&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://clusterip-app&amp;quot;}&#39; http://130.211.166.214/
200

$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://130.211.166.214/
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クラウドごとに異なるクラスタ外のLoadBalancerの操作は&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.11.2/pkg/cloudprovider/cloud.go#L92&#34;&gt;cloudprovider.LoadBalancer&lt;/a&gt; interfaceになっていて、&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.11.2/pkg/controller/service/service_controller.go#L229&#34;&gt;service_controller&lt;/a&gt;に渡すことができるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/182/&#34;&gt;KubernetesのCustom Resource Definition(CRD)とCustom Controller - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;nodeport&#34;&gt;NodePort&lt;/h3&gt;

&lt;p&gt;ファイアウォールルールでGCEのポートが開いていないのでそのままではアクセスできない。開けばNodeのIPとnodePortでアクセスできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/173-firewallrule.png&#34; alt=&#34;ファイアウォールルール&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get node -o wide
NAME                                          STATUS    ROLES     AGE       VERSION         EXTERNAL-IP       OS-IMAGE                             KERNEL-VERSION   CONTAINER-RUNTIME
gke-test-cluster-default-pool-6601d6a8-07gm   Ready     &amp;lt;none&amp;gt;    53m       v1.8.10-gke.0   130.211.190.139   Container-Optimized OS from Google   4.4.111+         docker://17.3.2
gke-test-cluster-default-pool-6601d6a8-6881   Ready     &amp;lt;none&amp;gt;    4h        v1.8.10-gke.0   35.224.204.110    Container-Optimized OS from Google   4.4.111+         docker://17.3.2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://clusterip-app&amp;quot;}&#39; 35.224.204.110:31233
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみにNetworkPolicyを使うとPodのトラフィックを制御できる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/181/&#34;&gt;KubernetesのNetworkPolicy Resource - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ingressを作成&#34;&gt;Ingressを作成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt;はホストやパスで異なるServiceにルーティングしたり、
SSL終端にすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local env = std.extVar(&amp;quot;__ksonnet/environments&amp;quot;);
local params = std.extVar(&amp;quot;__ksonnet/params&amp;quot;).components[&amp;quot;ingress&amp;quot;];
[
  {
    &amp;quot;apiVersion&amp;quot;: &amp;quot;extensions/v1beta1&amp;quot;,
    &amp;quot;kind&amp;quot;: &amp;quot;Ingress&amp;quot;,
    &amp;quot;metadata&amp;quot;: {         
      &amp;quot;name&amp;quot;: params.name,
      &amp;quot;annotations&amp;quot;: {
        &amp;quot;ingress.kubernetes.io/rewrite-target&amp;quot;: &amp;quot;/&amp;quot;
        // &amp;quot;kubernetes.io/ingress.allow-http&amp;quot;: &amp;quot;false&amp;quot;
      }
    },
    &amp;quot;spec&amp;quot;: {
      /*
      &amp;quot;tls: {
        &amp;quot;secretName&amp;quot;: &amp;quot;&amp;quot;
      },
      */
      // default backend
      &amp;quot;backend&amp;quot;: {
        &amp;quot;serviceName&amp;quot;: &amp;quot;nodeport-app&amp;quot;,
        &amp;quot;servicePort&amp;quot;: 81 // fail to reach app
      },
      &amp;quot;rules&amp;quot;: [
        {
          &amp;quot;http&amp;quot;: {
            &amp;quot;paths&amp;quot;: [
              {
                &amp;quot;path&amp;quot;: &amp;quot;/aaa&amp;quot;,
                &amp;quot;backend&amp;quot;: {
                  &amp;quot;serviceName&amp;quot;: &amp;quot;nodeport-app&amp;quot;,
                  &amp;quot;servicePort&amp;quot;: 80
                }
              }
            ]
          }
        }
      ]
    }
  }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ ks apply default -c ingress
$ kubectl get ingress
NAME      HOSTS     ADDRESS         PORTS     AGE
ingress   *         35.241.38.159   80        22m

$ curl 35.241.38.159
default backend - 404

$ curl 35.241.38.159/aaa
ok
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;L7のHTTP Load Balancerが立っている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/173-l7lb.png&#34; alt=&#34;HTTP Load Balancer&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのモデルをsave/loadする</title>
          <link>https://www.sambaiz.net/article/172/</link>
          <pubDate>Fri, 22 Jun 2018 01:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/172/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/saved_model/builder/SavedModelBuilder&#34;&gt;SavedModelBuilder&lt;/a&gt;で
モデルを言語に依存しない&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/saved_model.proto&#34;&gt;SavedModel&lt;/a&gt;のprotobufにして保存できる。
SavedModelには&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Saver&#34;&gt;Saver&lt;/a&gt;によって&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/saved_model/builder_impl.py#L418&#34;&gt;出力&lt;/a&gt;される&lt;a href=&#34;https://www.tensorflow.org/get_started/checkpoints&#34;&gt;Checkpoint&lt;/a&gt;を共有する一つ以上の&lt;a href=&#34;https://www.tensohttps://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directoryrflow.org/api_docs/python/tf/MetaGraphDef&#34;&gt;MetaGraphDef&lt;/a&gt;を&lt;a href=&#34;https://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory&#34;&gt;含む&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf

def build_signature(signature_inputs, signature_outputs):
    return tf.saved_model.signature_def_utils.build_signature_def(
        signature_inputs, signature_outputs,
        tf.saved_model.signature_constants.REGRESS_METHOD_NAME)

def save(sess, export_dir, signature_def_map):
    builder = tf.saved_model.builder.SavedModelBuilder(export_dir)
    builder.add_meta_graph_and_variables(
          sess, [tf.saved_model.tag_constants.SERVING],
          signature_def_map=signature_def_map
    )
    builder.save()

import shutil
import os.path
export_dir = &amp;quot;./saved_model&amp;quot;
if os.path.exists(export_dir):
    shutil.rmtree(export_dir)
    
with tf.Graph().as_default():
    a = tf.placeholder(tf.float32, name=&amp;quot;a&amp;quot;)
    b = tf.placeholder(tf.float32, name=&amp;quot;b&amp;quot;)
    c = tf.add(a, b, name=&amp;quot;c&amp;quot;)

    v = tf.placeholder(tf.float32, name=&amp;quot;v&amp;quot;)
    w = tf.Variable(0.0, name=&amp;quot;w&amp;quot;)
    x = w.assign(tf.add(v, w))
    
    sv = tf.train.Supervisor()
    with sv.managed_session() as sess:
        print(sess.run(c, feed_dict={a: 1, b: 2})) # 3.0
        print(sess.run(x, feed_dict={v: 2})) # 2.0
        print(sess.run(x, feed_dict={v: 3})) # 5.0
        # https://github.com/tensorflow/tensorflow/issues/11549
        sess.graph._unsafe_unfinalize()
        save(sess, export_dir, {
            &amp;quot;add&amp;quot;: build_signature({
                &amp;quot;a&amp;quot;: tf.saved_model.utils.build_tensor_info(a),
                &amp;quot;b&amp;quot;:tf.saved_model.utils.build_tensor_info(b)
            }, {
                &amp;quot;c&amp;quot;: tf.saved_model.utils.build_tensor_info(c)
            }),
             &amp;quot;accumulate&amp;quot;: build_signature({
                &amp;quot;v&amp;quot;: tf.saved_model.utils.build_tensor_info(v),
            }, {
                &amp;quot;x&amp;quot;: tf.saved_model.utils.build_tensor_info(x)
            })
        })
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ ls saved_model/
saved_model.pb  variables
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;loadしてsess.runできる。variableの値も保存されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
    with tf.Session() as sess:
        meta_graph_def = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)
        print(sess.run(
            meta_graph_def.signature_def[&amp;quot;accumulate&amp;quot;].outputs[&amp;quot;x&amp;quot;].name, # Assign:0
            feed_dict={
                meta_graph_def.signature_def[&amp;quot;accumulate&amp;quot;].inputs[&amp;quot;v&amp;quot;].name: 3, # v:0
            }
        )) # 8.0
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ksonnetでkubernetesのmanifestを環境ごとに生成/applyする</title>
          <link>https://www.sambaiz.net/article/171/</link>
          <pubDate>Wed, 20 Jun 2018 01:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/171/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://ksonnet.io/&#34;&gt;ksonnet&lt;/a&gt;はJSONのテンプレートエンジン&lt;a href=&#34;https://jsonnet.org/&#34;&gt;jsonnet&lt;/a&gt;からk8sのmanifestを環境ごとに生成してapplyするツール。&lt;a href=&#34;https://github.com/kubeflow/kubeflow&#34;&gt;kubeflow&lt;/a&gt;でも使われている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install ksonnet/tap/ks
$ ks version
ksonnet version: 0.11.0
jsonnet version: v0.10.0
client-go version:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;init&#34;&gt;init&lt;/h2&gt;

&lt;p&gt;まず&lt;code&gt;ks init&lt;/code&gt;してディレクトリを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl config current-context
minikube

$ ks init kstest
$ cd kstest
$ ls
app.yaml	components	environments	lib		vendor

$ cat app.yaml
apiVersion: 0.1.0
environments:
  default:
    destination:
      namespace: default
      server: https://192.168.99.100:8443
    k8sVersion: v1.10.0
    path: default
kind: ksonnet.io/app
name: kstest
registries:
  incubator:
    gitVersion:
      commitSha: 40285d8a14f1ac5787e405e1023cf0c07f6aa28c
      refSpec: master
    protocol: github
    uri: github.com/ksonnet/parts/tree/master/incubator
version: 0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;prototypeのインストール&#34;&gt;Prototypeのインストール&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;app.yaml&lt;/code&gt;にあるように最初はincubatorというregistryが登録されている。追加する場合は&lt;code&gt;ks registry add&lt;/code&gt;。
&lt;code&gt;ks pkg list&lt;/code&gt;でregistryのpackage一覧を見て、&lt;code&gt;ks pkg install&lt;/code&gt;するとpackageに含まれるいくつかのprototypeを持ってくることができる。
prototypeというのはparameterを足してcomponentになるもと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ks registry add *** github.com/***
$ ks pkg list
REGISTRY  NAME      INSTALLED
========  ====      =========
incubator apache
incubator efk
incubator mariadb
incubator memcached
incubator mongodb
incubator mysql
incubator nginx
incubator node
incubator postgres
incubator redis
incubator tomcat

$ ks pkg install incubator/redis@master
$ ks prototype list
NAME                                  DESCRIPTION
====                                  ===========
...
io.ksonnet.pkg.redis-all-features     A Redis deployment with metrics, ingress, and persistent storage.
io.ksonnet.pkg.redis-persistent       A simple Redis deployment, backed by persistent storage.
io.ksonnet.pkg.redis-stateless        A simple, stateless Redis deployment,

$ ls vendor/incubator/redis/
README.md       examples        parts.yaml      prototypes      redis.libsonnet
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;componentの生成&#34;&gt;Componentの生成&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;ks generate&lt;/code&gt;でprototypeからcomponentを生成する。&lt;code&gt;deployed-service&lt;/code&gt;は最初から入っているprototype。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ks generate deployed-service myapp --image gcr.io/google-samples/hello-app:2.0 --type ClusterIP
$ ks generate redis-stateless redis
$ ls components/
myapp.jsonnet           params.libsonnet        redis.jsonnet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;jsonnetではparamsを参照しているが、environmentごとの設定がなければcomponentsの&lt;code&gt;params.libsonnet&lt;/code&gt;の値になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat components/myapp.jsonnet
local env = std.extVar(&amp;quot;__ksonnet/environments&amp;quot;);
local params = std.extVar(&amp;quot;__ksonnet/params&amp;quot;).components.myapp;
[
   {
      &amp;quot;apiVersion&amp;quot;: &amp;quot;v1&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;Service&amp;quot;,
      &amp;quot;metadata&amp;quot;: {
         &amp;quot;name&amp;quot;: params.name
      },
      &amp;quot;spec&amp;quot;: {
         &amp;quot;ports&amp;quot;: [
            {
               &amp;quot;port&amp;quot;: params.servicePort,
               &amp;quot;targetPort&amp;quot;: params.containerPort
            }
         ],
         &amp;quot;selector&amp;quot;: {
            &amp;quot;app&amp;quot;: params.name
         },
         &amp;quot;type&amp;quot;: params.type
      }
   },
   {
      &amp;quot;apiVersion&amp;quot;: &amp;quot;apps/v1beta2&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;Deployment&amp;quot;,
      &amp;quot;metadata&amp;quot;: {
         &amp;quot;name&amp;quot;: params.name
      },
      &amp;quot;spec&amp;quot;: {
         &amp;quot;replicas&amp;quot;: params.replicas,
         &amp;quot;selector&amp;quot;: {
            &amp;quot;matchLabels&amp;quot;: {
               &amp;quot;app&amp;quot;: params.name
            },
         },
         &amp;quot;template&amp;quot;: {
            &amp;quot;metadata&amp;quot;: {
               &amp;quot;labels&amp;quot;: {
                  &amp;quot;app&amp;quot;: params.name
               }
            },
            &amp;quot;spec&amp;quot;: {
               &amp;quot;containers&amp;quot;: [
                  {
                     &amp;quot;image&amp;quot;: params.image,
                     &amp;quot;name&amp;quot;: params.name,
                     &amp;quot;ports&amp;quot;: [
                     {
                        &amp;quot;containerPort&amp;quot;: params.containerPort
                     }
                     ]
                  }
               ]
            }
         }
      }
   }
]

$ cat components/params.libsonnet
{
  global: {
    // User-defined global parameters; accessible to all component and environments, Ex:
    // replicas: 4,
  },
  components: {
    // Component-level parameters, defined initially from &#39;ks prototype use ...&#39;
    // Each object below should correspond to a component in the components/ directory
    redis: {
      name: &amp;quot;redis&amp;quot;,
      redisPassword: &amp;quot;null&amp;quot;,
    },
    myapp: {
      containerPort: 80,
      image: &amp;quot;gcr.io/google-samples/hello-app:2.0&amp;quot;,
      name: &amp;quot;myapp&amp;quot;,
      replicas: 1,
      servicePort: 80,
      type: &amp;quot;ClusterIP&amp;quot;,
    },
  },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;environmentの追加&#34;&gt;Environmentの追加&lt;/h2&gt;

&lt;p&gt;Environmentごとに向き先を変えて、異なるパラメータでapplyできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ks env add prd -n prd
$ ks env list
NAME    OVERRIDE KUBERNETES-VERSION NAMESPACE SERVER
====    ======== ================== ========= ======
default          v1.10.0            default   https://192.168.99.100:8443
prd              v1.10.0            prd       https://192.168.99.100:8443
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--server&lt;/code&gt;フラグでSERVERを指定できる。対象クラスタのIPは&lt;code&gt;kubectl config view&lt;/code&gt;で分かる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ks param set&lt;/code&gt;でパラメータを設定できる。これがcomponentsの&lt;code&gt;params.libsonnet&lt;/code&gt;のものより優先される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ks param set myapp replicas 2 --env prd
$ cat environments/prd/params.libsonnet
local params = std.extVar(&#39;__ksonnet/params&#39;);
local globals = import &#39;globals.libsonnet&#39;;
local envParams = params + {
  components+: {
    myapp+: {
      replicas: 2,
    },
  },
};

{
  components: {
    [x]: envParams.components[x] + globals
    for x in std.objectFields(envParams.components)
  },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;yamlマニフェストを表示&#34;&gt;yamlマニフェストを表示&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ ks show prd
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: redis
  name: redis
spec:
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - env:
        - name: ALLOW_EMPTY_PASSWORD
          value: &amp;quot;yes&amp;quot;
        image: bitnami/redis:3.2.9-r2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          timeoutSeconds: 5
        name: redis
        ports:
        - containerPort: 6379
          name: redis
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 5
          timeoutSeconds: 1
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
        volumeMounts:
        - mountPath: /bitnami/redis
          name: redis-data
      volumes:
      - name: redis-data
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: redis
  name: redis
spec:
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
---
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: myapp
  type: ClusterIP
---
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - image: gcr.io/google-samples/hello-app:2.0
        name: myapp
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;apply&#34;&gt;apply&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ ks apply default -c myapp
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pandasの操作</title>
          <link>https://www.sambaiz.net/article/170/</link>
          <pubDate>Wed, 13 Jun 2018 23:47:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/170/</guid>
          <description>

&lt;h2 id=&#34;seriesとdataframe&#34;&gt;SeriesとDataframe&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import numpy as np

s = pd.Series([1,3])
print(s[1]) # 3
print(s.values) # [1 3] (ndarray)

dates = pd.date_range(&#39;2014-11-01 10:00&#39;,periods=3, freq=&#39;2H&#39;)
print(dates) 
# DatetimeIndex([&#39;2014-11-01 10:00:00&#39;, &#39;2014-11-01 12:00:00&#39;, &#39;2014-11-01 14:00:00&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;2H&#39;)

datestr = lambda d: pd.to_datetime(d).strftime(&#39;%Y-%m-%d %H:%M&#39;)

df = pd.DataFrame({
    &#39;A&#39; : 1.,
    &#39;B&#39; : pd.Series(range(6),  index=pd.date_range(&#39;2014-11-01 10:00&#39;,periods=6, freq=&#39;H&#39;)),
    &#39;C&#39; : [9, 1, 5],
}, index=dates)

df2 = pd.DataFrame({
    &#39;D&#39; : range(3),
}, index=dates)

print(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |A  |B|C|
|-------------------|---|-|-|
|2014-11-01 10:00:00|1.0|0|9|
|2014-11-01 12:00:00|1.0|2|1|
|2014-11-01 14:00:00|1.0|4|5|
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;indexを指定しないと0始まりの数値になる。&lt;/p&gt;

&lt;h2 id=&#34;取得&#34;&gt;取得&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;print(df[&#39;B&#39;].values) # [0 2 4] (列)
print(df.loc[dates[0]].values) # [ 1.  0.  9.] (行)
print(df[&#39;2014-11-01 11:00:00&#39;:&#39;2014-11-01 13:00:00&#39;].values) # [[ 1.  2.  1.]] (index指定で複数行)
print(len(df[df.C &amp;gt; 3])) # 2 (条件で複数行)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ソート&#34;&gt;ソート&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;print(df.sort_index(
    axis=1, # 行
    ascending=False # 降順
).iloc[0].index.values) # [&#39;C&#39; &#39;B&#39; &#39;A&#39;]
print(list(map(datestr, df.sort_values(by=&#39;C&#39;).iloc[:2].index))) # [&#39;2014-11-01 12:00&#39;, &#39;2014-11-01 14:00&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;takeでランダムに取ってreset_indexで振り直せばシャッフルできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/187/&#34;&gt;numpyの関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(df.take(np.random.permutation(df.index)).reset_index(drop=True))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;結合&#34;&gt;結合&lt;/h2&gt;

&lt;p&gt;indexでjoinする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(df.join(df2, how=&#39;outer&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |A  |B|C|D|
|-------------------|---|-|-|-|
|2014-11-01 10:00:00|1.0|0|9|0|
|2014-11-01 12:00:00|1.0|2|1|1|
|2014-11-01 14:00:00|1.0|4|5|2|
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;値でjoinする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(pd.merge(df, df2, left_on=&#39;C&#39;, right_on=&#39;D&#39;, how=&#39;left&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |A  |B|C|D  |
|-------------------|---|-|-|---|
|2014-11-01 10:00:00|1.0|0|9|NaN|
|2014-11-01 12:00:00|1.0|2|1|1.0|
|2014-11-01 14:00:00|1.0|4|5|NaN|
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集計&#34;&gt;集計&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;print(df.mean().values) # [ 1.  2.  5.]
print(df.apply(
    lambda x: x.max(), 
    axis=0 #  列
).values) # [ 1.  4.  9.] (=df.max())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;groupbyもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df3 = pd.DataFrame({
    &#39;A&#39; : [0, 1, 0, 0, 1],
    &#39;B&#39; : [2, 2, 2, 4, 4],
	&#39;C&#39; : [2, 4, 6, 8, 10]
})
print(df3.groupby([&#39;A&#39;, &#39;B&#39;])[&#39;C&#39;].sum()[0, 2]) # 2 + 6 = 8
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;加工&#34;&gt;加工&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/166/&#34;&gt;KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(df.drop(
    [&#39;A&#39;, &#39;B&#39;],
    axis=1 # 行
)) # 不要なカラムを削除
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |C|
|-------------------|-|
|2014-11-01 10:00:00|9|
|2014-11-01 12:00:00|1|
|2014-11-01 14:00:00|5|
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;df[&#39;D&#39;] = df[&#39;C&#39;].shift(1) # Cを一列ずらしたDを追加
df[&#39;D&#39;] = df[&#39;D&#39;].fillna(df[&#39;D&#39;].mean()).astype(int) # NaNになる1行目はほかの平均で埋める
print(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |A  |B|C|D|
|-------------------|---|-|-|-|
|2014-11-01 10:00:00|1.0|0|9|5|
|2014-11-01 12:00:00|1.0|2|1|9|
|2014-11-01 14:00:00|1.0|4|5|1|
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ファイル入出力&#34;&gt;ファイル入出力&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;df.to_csv(&#39;df.csv&#39;, header=True, index_label=&#39;date&#39;)
&#39;&#39;&#39;
date,A,B,C
2014-11-01 10:00:00,1.0,0,9
2014-11-01 12:00:00,1.0,2,1
2014-11-01 14:00:00,1.0,4,5
&#39;&#39;&#39;
df3 = pd.read_csv(&#39;df.csv&#39;, index_col=0)
print(df3.index.values) # [&#39;2014-11-01 10:00:00&#39; &#39;2014-11-01 12:00:00&#39; &#39;2014-11-01 14:00:00&#39;]
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す</title>
          <link>https://www.sambaiz.net/article/169/</link>
          <pubDate>Sun, 10 Jun 2018 17:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/169/</guid>
          <description>

&lt;p&gt;機械学習の良いハイパーパラメータを探す方法として、scikit-learnにも&lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html&#34;&gt;ある&lt;/a&gt;グリッドサーチがあるが、これは総当たりで試すもので時間がかかる。&lt;/p&gt;

&lt;p&gt;それに対してベイズ最適化は、まず現在の最大値を超える確率や期待値を出力とする獲得関数を決めて、ガウス過程(GP)に従うと仮定する。
ガウス過程は回帰関数の確率モデルで、任意の入力(x1, x2, &amp;hellip; , xn)に対応する出力(y1, y2, &amp;hellip;, yn)がガウス分布(=正規分布)に従うというもの。
これによって予測されるまだ試していない入力での期待値や分散から次に試す値を決めて効率的に探すことができる。&lt;/p&gt;

&lt;p&gt;今回はKaggleのTitanicのチュートリアルを、チューニングなしのランダムフォレストとXGBoostで解いたときの結果と比較して、ベイズ最適化によるハイパーパラメータで精度が向上するか確認する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/166/&#34;&gt;KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/168/&#34;&gt;KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ランダムフォレスト&#34;&gt;ランダムフォレスト&lt;/h2&gt;

&lt;p&gt;Pythonのベイズ最適化のライブラリ、&lt;a href=&#34;https://github.com/fmfn/BayesianOptimization&#34;&gt;BayesianOptimization&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install bayesian-optimization
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html&#34;&gt;RandomForestClassifier&lt;/a&gt;のハイパーパラメータ&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n_estimators: 木の数&lt;/li&gt;
&lt;li&gt;min_samples_split: ノードを分割するのに必要な最小サンプル数&lt;/li&gt;
&lt;li&gt;max_features: 分割するときに考慮する特徴量の割合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の値を探すため、&lt;code&gt;BayesianOptimization&lt;/code&gt;に最大化したい値(精度)とパラメータの範囲を渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from bayes_opt import BayesianOptimization

import pandas as pd

def preprocess(df):
    df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean())
    df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean())
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;)
    df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0)
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int)
    df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1)
    return df

df = preprocess(pd.read_csv(&#39;./train.csv&#39;))
train_x = df.drop(&#39;Survived&#39;, axis=1)
train_y = df.Survived

def randomforest_cv(n_estimators, min_samples_split, max_features):
    val = cross_val_score(
        RandomForestClassifier(
            n_estimators=int(n_estimators),
            min_samples_split=int(min_samples_split),
            max_features=max_features,
            random_state=0
        ),
        train_x, train_y,
        scoring = &#39;accuracy&#39;,
        cv = 3, # 3-fold
        n_jobs = -1 # use all CPUs
    ).mean()
    return val

randomforest_cv_bo = BayesianOptimization(
    randomforest_cv,
    {&#39;n_estimators&#39;: (10, 250),
    &#39;min_samples_split&#39;: (2, 25),
    &#39;max_features&#39;: (0.1, 0.999)}
)

gp_params = {&amp;quot;alpha&amp;quot;: 1e-5}
randomforest_cv_bo.maximize(n_iter=50, **gp_params)
print(randomforest_cv_bo.res[&#39;max&#39;][&#39;max_val&#39;])
print(randomforest_cv_bo.res[&#39;max&#39;][&#39;max_params&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずinit_points回&lt;a href=&#34;https://github.com/fmfn/BayesianOptimization/blob/0.6.0/bayes_opt/bayesian_optimization.py#L84&#34;&gt;ランダムな値で試して&lt;/a&gt;、
それらの結果を起点にベイズ最適化で探していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Initialization
-------------------------------------------------------------------------------------
 Step |   Time |      Value |   max_features |   min_samples_split |   n_estimators | 
    1 | 00m00s |    0.82267 |         0.7470 |             23.8836 |       103.9041 | 
    2 | 00m00s |    0.81818 |         0.2784 |             12.4106 |       188.5984 | 
    3 | 00m00s |    0.82267 |         0.4745 |              9.1743 |        16.8421 | 
    4 | 00m00s |    0.82267 |         0.6617 |              4.7600 |       222.8920 | 
    5 | 00m00s |    0.81033 |         0.3057 |              9.2044 |        42.1871 | 
Bayesian Optimization
-------------------------------------------------------------------------------------
 Step |   Time |      Value |   max_features |   min_samples_split |   n_estimators | 
    6 | 00m08s |    0.82043 |         0.5444 |             24.5978 |       249.8593 | 
    7 | 00m08s |    0.81033 |         0.3853 |             24.8421 |       249.9177 | 
    8 | 00m07s |    0.79012 |         0.8454 |              2.2098 |        10.0838 | 
    9 | 00m05s |    0.81257 |         0.6389 |             24.9582 |        10.1302 | 
...
   54 | 00m13s |    0.82379 |         0.9751 |             24.9576 |        73.5207 | 
   55 | 00m13s |    0.82043 |         0.9698 |             24.9442 |        65.3054 | 
0.82379349046
{&#39;n_estimators&#39;: 73.520665913948847, &#39;min_samples_split&#39;: 24.957568460557685, &#39;max_features&#39;: 0.97511242524537167}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;少し精度がよくなり、性別の影響がかなり強くなった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.810169491525
Sex             0.445553
Fare            0.180365
Pclass          0.162260
Age             0.147300
Embarked        0.037309
SibSp           0.014159
Parch           0.013054
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;xgboost&#34;&gt;XGBoost&lt;/h2&gt;

&lt;p&gt;XGBoostでは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;learning_rate&lt;/li&gt;
&lt;li&gt;max_depth&lt;/li&gt;
&lt;li&gt;subsample&lt;/li&gt;
&lt;li&gt;colsample_bytree&lt;/li&gt;
&lt;li&gt;min_child_weight&lt;/li&gt;
&lt;li&gt;gamma&lt;/li&gt;
&lt;li&gt;alpha&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を探す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import xgboost as xgb
from bayes_opt import BayesianOptimization

df = preprocess(pd.read_csv(&#39;./train.csv&#39;))
train_x = df.drop(&#39;Survived&#39;, axis=1)
train_y = df.Survived
xgtrain = xgb.DMatrix(train_x, label=train_y)

def xgboost_cv(
    learning_rate,
    max_depth,
    subsample,
    colsample_bytree,
    min_child_weight,
    gamma,
    alpha):
    
    params = {}
    params[&#39;learning_rate&#39;] = learning_rate
    # maximum depth of a tree, increase this value will make the model more complex / likely to be overfitting.
    params[&#39;max_depth&#39;] = int(max_depth) 
    #  subsample ratio of the training instance. Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees and this will prevent overfitting.
    params[&#39;subsample&#39;] = subsample
    # subsample ratio of columns when constructing each tree.
    params[&#39;colsample_bytree&#39;] = colsample_bytree 
    # minimum sum of instance weight (hessian) needed in a child. The larger, the more conservative the algorithm will be.
    params[&#39;min_child_weight&#39;] = min_child_weight
    # minimum loss reduction required to make a further partition on a leaf node of the tree. The larger, the more conservative the algorithm will be.
    params[&#39;gamma&#39;] = gamma 
    # L1 regularization term on weights, increase this value will make model more conservative. 
    params[&#39;alpha&#39;] = alpha 
    params[&#39;objective&#39;] = &#39;binary:logistic&#39;

    cv_result = xgb.cv(
        params,
        xgtrain,
        num_boost_round=10, 
        nfold=3,
        seed=0,
        # Validation error needs to decrease at least every &amp;lt;stopping_rounds&amp;gt; round(s) to continue training.
        # callbacks=[xgb.callback.early_stop(20)]
    )

    return 1.0 - cv_result[&#39;test-error-mean&#39;].values[-1]


xgboost_cv_bo = BayesianOptimization(xgboost_cv, 
                             {
                                 &#39;learning_rate&#39;: (0.1, 0.9),
                                 &#39;max_depth&#39;: (5, 15),
                                 &#39;subsample&#39;: (0.5, 1),
                                 &#39;colsample_bytree&#39;: (0.1, 1),
                                 &#39;min_child_weight&#39;: (1, 20),
                                 &#39;gamma&#39;: (0, 10),
                                 &#39;alpha&#39;: (0, 10),
                             })

xgboost_cv_bo.maximize(n_iter=50)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Initialization
---------------------------------------------------------------------------------------------------------------------------------------------
 Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   learning_rate |   max_depth |   min_child_weight |   subsample | 
    1 | 00m00s |    0.77441 |    5.3061 |             0.4302 |    1.1512 |          0.4484 |      8.4632 |            16.3455 |      0.5688 | 
    2 | 00m00s |    0.79349 |    6.5298 |             0.2519 |    8.8275 |          0.8277 |      9.6443 |             8.1207 |      0.5426 | 
    3 | 00m00s |    0.79349 |    0.4152 |             0.7973 |    7.5153 |          0.7173 |      8.2608 |            12.5433 |      0.7952 | 
    4 | 00m00s |    0.76768 |    3.9047 |             0.9619 |    2.0264 |          0.8893 |      9.8001 |            18.0125 |      0.8254 | 
    5 | 00m00s |    0.77217 |    3.0779 |             0.2957 |    3.1872 |          0.4871 |      8.8120 |            10.6444 |      0.6602 | 
Bayesian Optimization
---------------------------------------------------------------------------------------------------------------------------------------------
 Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   learning_rate |   max_depth |   min_child_weight |   subsample | 
    6 | 00m27s |    0.78676 |    8.5373 |             1.0000 |   10.0000 |          0.9000 |      5.0000 |            20.0000 |      0.5000 | 
    7 | 00m38s |    0.76768 |   10.0000 |             1.0000 |   10.0000 |          0.1000 |      5.0000 |             1.0000 |      1.0000 | 
    8 | 00m16s |    0.67901 |    0.2277 |             0.1000 |   10.0000 |          0.1000 |     15.0000 |            19.9844 |      0.5000 | 
    9 | 00m36s |    0.77666 |    0.0000 |             0.1000 |   10.0000 |          0.9000 |      5.0000 |             1.0000 |      0.5000 | 
...

   55 | 00m20s |    0.81818 |    0.3008 |             1.0000 |    2.5199 |          0.9000 |     13.8205 |             3.3037 |      1.0000 | 
0.833894666667
{&#39;learning_rate&#39;: 0.46665290052625796, &#39;max_depth&#39;: 14.985905144970891, &#39;subsample&#39;: 0.96857695798880505, &#39;colsample_bytree&#39;: 0.74722905651892868, &#39;min_child_weight&#39;: 1.1211600650692968, &#39;gamma&#39;: 0.44876616653489076, &#39;alpha&#39;: 0.13669004333540569}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;精度は微増した。元々のパラメータもそう悪くはなかったのかもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.803389830508
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/hoxo_m/ss-77421091&#34;&gt;機械学習のためのベイズ最適化入門&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ism.ac.jp/~daichi/lectures/H26-GaussianProcess/gp-lecture2-daichi.pdf&#34;&gt;ガウス過程の基礎と教師なし学習&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KaggleのTitanicのチュートリアルをXGBoostで解く</title>
          <link>https://www.sambaiz.net/article/168/</link>
          <pubDate>Sat, 02 Jun 2018 18:16:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/168/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://xgboost.readthedocs.io/en/latest/&#34;&gt;XGBoost&lt;/a&gt;は高性能なGradient Boostingのライブラリ。
Boostingというのはアンサンブル学習の種類の一つで、ランダムフォレストのように弱学習器をそれぞれ並列に学習するBaggingに対して、
順番に前回までの結果を受けながら学習し、結果をまとめる際にそれぞれの重みを掛けるもの。
XGBoostではランダムフォレストと同様に決定木を弱学習器とする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/166/&#34;&gt;KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install xgboost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;データの前処理はランダムフォレストと同じようにした。
&lt;a href=&#34;https://github.com/dmlc/xgboost/blob/master/doc/parameter.md#learning-task-parameters&#34;&gt;パラメータ&lt;/a&gt;の
objective(目的関数)には二値分類なので&lt;code&gt;binary:logistic&lt;/code&gt;を指定し、確率が返るのでroundして出力している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def preprocess(df):
    df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean())
    df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean())
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;)
    df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0)
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int)
    df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1)
    return df

def train(df):
    train_x = df.drop(&#39;Survived&#39;, axis=1)
    train_y = df.Survived
    (train_x, test_x ,train_y, test_y) = train_test_split(train_x, train_y, test_size = 0.6, random_state = 42)
    dtrain = xgb.DMatrix(train_x, label=train_y)
    param = {&#39;max_depth&#39;:3, &#39;learning_rate&#39;: 0.6, &#39;objective&#39;:&#39;binary:logistic&#39; }
    num_round = 2
    bst = xgb.train(param, dtrain, num_round)
    preds = bst.predict(xgb.DMatrix(test_x))
    print(accuracy_score(preds.round(), test_y))

    return bst

def predict(bst, df):
    return bst.predict(xgb.DMatrix(df))

df = pd.read_csv(&#39;./train.csv&#39;)
df_test_origin = pd.read_csv(&#39;./test.csv&#39;)
df = preprocess(df)
df_test = preprocess(df_test_origin)
bst = train(df)
answer = predict(bst, df_test).round().astype(int)
submit_data =  pd.Series(answer, name=&#39;Survived&#39;, index=df_test_origin[&#39;PassengerId&#39;])
submit_data.to_csv(&#39;submit2.csv&#39;, header=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;精度は&lt;code&gt;0.78&lt;/code&gt;ほど。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/169.png&#34; alt=&#34;スコアと順位&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/Retrieva_jp/ss-80724064&#34;&gt;ブースティング入門&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Istio v0.7でEnvoy Proxyを付けるまで</title>
          <link>https://www.sambaiz.net/article/167/</link>
          <pubDate>Tue, 29 May 2018 22:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/167/</guid>
          <description>

&lt;blockquote&gt;
&lt;p&gt;追記(2018-09-01) v1.0となりHelmでのインストールも問題なくできるようになった。Istio-AuthがCitadelという&lt;a href=&#34;https://istio.io/about/notes/0.8/&#34;&gt;名前になっていたり&lt;/a&gt;DeprecatedになってるAPIもある&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/185/&#34;&gt;IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;istioとは-https-istio-io-docs-concepts-what-is-istio-overview-html&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html&#34;&gt;Istioとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;マイクロサービス間のネットワークの、ロードバランシングや認証、モニタリングなどを担うサービスメッシュのOSS。
概念は抽象化されていて、Kubernetes以外でもサポートされている。
通信をコントロールするdata-planeのEnvoyと、Envoyを管理するcontrol-planeのPilot, Mixer, Istio-Authからなる。&lt;/p&gt;

&lt;h3 id=&#34;envoy-https-istio-io-docs-concepts-what-is-istio-overview-html-envoy&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html#envoy&#34;&gt;Envoy&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Sidecarとしてデプロイされる、サービスメッシュでの全ての通信を通すプロキシ。
アプリケーションのコードに手を入れる必要がないので言語に縛られない。
&lt;a href=&#34;https://www.cncf.io/&#34;&gt;CNCF&lt;/a&gt;のプロジェクトの一つで、
Istio用に&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/&#34;&gt;オリジナル&lt;/a&gt;から拡張されている。
ロードバランシングやヘルスチェックなどを行い、メトリクスを取る。&lt;/p&gt;

&lt;h3 id=&#34;mixer-https-istio-io-docs-concepts-what-is-istio-overview-html-mixer&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html#mixer&#34;&gt;Mixer&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;サービスメッシュ全体のアクセスコントロールや、Envoyからデータを集めてログに出したりモニタリングしたりする。
プラグインよってAWSやGCPといったインフラバックエンドの差異が吸収される。&lt;/p&gt;

&lt;h3 id=&#34;pilot-https-istio-io-docs-concepts-what-is-istio-overview-html-pilot&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html#pilot&#34;&gt;Pilot&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;サービスディスカバリしてEnvoyのトラフィックを制御する。A/Bテストやカナリアリリースをする場合や、障害に対応して適切にルーティングを行うことができる。&lt;/p&gt;

&lt;h3 id=&#34;istio-auth-https-istio-io-docs-concepts-what-is-istio-overview-html-istio-auth&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html#istio-auth&#34;&gt;Istio-Auth&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;サービスやエンドユーザーの認証を行い、ポリシーに従ってアクセス制御する。&lt;/p&gt;

&lt;h2 id=&#34;istioのインストール-https-istio-io-docs-setup-kubernetes-quick-start-html&#34;&gt;&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/quick-start.html&#34;&gt;Istioのインストール&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ローカルのminikubeに環境を作る。
&lt;code&gt;apiserver.Admission.PluginNames&lt;/code&gt;では立ち上がらなかったので&lt;a href=&#34;https://github.com/kubernetes/minikube/issues/2742&#34;&gt;代わりに&lt;/a&gt;
&lt;code&gt;apiserver.admission-control&lt;/code&gt;を指定している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ minikube version
minikube version: v0.27.0
$ minikube start \
--extra-config=apiserver.admission-control=&amp;quot;NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota&amp;quot; \
--kubernetes-version=v1.9.0
$ kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;istioを持ってきてapplyする。
Helmも用意されていて将来的にそっちで入れるのが推奨になりそうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -L https://git.io/getLatestIstio | sh -
$ cd istio-0.7.1/
$ kubectl apply -f install/kubernetes/istio-auth.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作成されたserviceとpodはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get svc -o name -n istio-system
NAME            TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                             AGE
istio-ingress   LoadBalancer   10.96.175.13     &amp;lt;pending&amp;gt;     80:30562/TCP,443:32026/TCP                                          7m
istio-mixer     ClusterIP      10.98.182.172    &amp;lt;none&amp;gt;        9091/TCP,15004/TCP,9093/TCP,9094/TCP,9102/TCP,9125/UDP,42422/TCP    7m
istio-pilot     ClusterIP      10.102.123.144   &amp;lt;none&amp;gt;        15003/TCP,15005/TCP,15007/TCP,15010/TCP,8080/TCP,9093/TCP,443/TCP   7m

$ kubectl get pod -o name -n istio-system
pods/istio-ca-86f55cc46f-5d6vk
pods/istio-ingress-868d5f978b-k4z5m
pods/istio-mixer-65dc5549d6-lh22q
pods/istio-pilot-657cb5ddf7-g8vc6
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;envoyが自動で付くようする-https-istio-io-docs-setup-kubernetes-sidecar-injection-html-automatic-sidecar-injection&#34;&gt;&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/sidecar-injection.html#automatic-sidecar-injection&#34;&gt;Envoyが自動で付くようする&lt;/a&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;追記(2018-06-30): 0.8.0になってsidecar-injectorはデフォルトで入るようになった&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;istio-sidecar-injector&lt;/code&gt;を入れる。これが&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#mutatingadmissionwebhook-beta-in-1-9&#34;&gt;MutatingAdmissionWebhook&lt;/a&gt;でEnvoyを自動で付け足してくれるらしい。Webhookに証明書が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./install/kubernetes/webhook-create-signed-cert.sh \
--service istio-sidecar-injector \
--namespace istio-system \
--secret sidecar-injector-certs
$ kubectl apply -f install/kubernetes/istio-sidecar-injector-configmap-release.yaml
$ cat install/kubernetes/istio-sidecar-injector.yaml | \
./install/kubernetes/webhook-patch-ca-bundle.sh &amp;gt; \
install/kubernetes/istio-sidecar-injector-with-ca-bundle.yaml
$ kubectl apply -f install/kubernetes/istio-sidecar-injector-with-ca-bundle.yaml
$ kubectl -n istio-system get deployment -listio=sidecar-injector
NAME                     DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
istio-sidecar-injector   1         1         1            0           16s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;default namespaceでEnvoyが付くようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl label namespace default istio-injection=enabled
$ kubectl get namespace -L istio-injection
NAME           STATUS    AGE       ISTIO-INJECTION
default        Active    25m       enabled
istio-system   Active    25m       
kube-public    Active    25m       
kube-system    Active    25m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;付いていることが確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl apply -f samples/sleep/sleep.yaml 
$ kubectl get pod
NAME                     READY     STATUS    RESTARTS   AGE
sleep-776b7bcdcd-z567q   2/2       Running   0          26s

$ kubectl describe pod sleep-776b7bcdcd-z567q
Containers:
  sleep:
    ...
  istio-proxy:
    ...
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
          <link>https://www.sambaiz.net/article/166/</link>
          <pubDate>Tue, 29 May 2018 09:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/166/</guid>
          <description>

&lt;p&gt;ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成し並列に学習するアンサンブル学習のBaggingという種類の手法。
決定木なので特徴量の影響が分かりやすく、単一の決定木と比べて過学習を防ぐことができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/168/&#34;&gt;KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;train.csv&lt;/code&gt;と&lt;code&gt;test.csv&lt;/code&gt;をKaggleから&lt;a href=&#34;https://www.kaggle.com/c/titanic/data&#34;&gt;ダウンロード&lt;/a&gt;する。
csvにはタイタニックの乗客者リストが含まれ、&lt;code&gt;test.csv&lt;/code&gt;には生還したかを表す&lt;code&gt;Survived&lt;/code&gt;が抜けている。
これを予測するのがこのコンペティションの目的だ。&lt;/p&gt;

&lt;p&gt;データのうちFareやAge、Embarkedは入っていないものがあって、これらの欠損値をどう扱うという問題がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df = pd.read_csv(&#39;./train.csv&#39;)
print(len(df))
print(df.isnull().sum())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;891
PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;連続値をとるFareとAgeは平均を取り、Embarkedは欠損値用の値にしてみた。数値化できないものについては除いている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def preprocess(df):
    df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean())
    df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean())
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;)
    df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0)
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int)
    df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1)
    return df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;scikit-learnのの&lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html&#34;&gt;RandomForestClassifier&lt;/a&gt;で学習させる。
デフォルトの木の数は10で、特徴量の数はsqrt(n_features)となっている。
&lt;code&gt;feature_importances_&lt;/code&gt;で各特徴量の重要度を出すことかできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
import numpy as np
import csv

def train(df):
    train_x = df.drop(&#39;Survived&#39;, axis=1)
    train_y = df.Survived
    (train_x, test_x ,train_y, test_y) = train_test_split(train_x, train_y, test_size = 0.33, random_state = 42)

    clf = RandomForestClassifier(random_state=0)
    clf = clf.fit(train_x, train_y)
    pred = clf.predict(test_x)
    print(accuracy_score(pred, test_y))
    
    features = train_x.columns
    importances = clf.feature_importances_
    indices = np.argsort(importances)
    for i in indices[::-1]:
        print(&amp;quot;{:&amp;lt;15} {:f}&amp;quot;.format(features[i], importances[i]))
    return clf

import pandas as pd
df = pd.read_csv(&#39;./train.csv&#39;)
df = preprocess(df)
clf = train(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;精度は8割ほどで、AgeとFareの影響が大きいようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.803389830508
Age             0.267060
Fare            0.262733
Sex             0.224451
Pclass          0.097958
SibSp           0.058860
Parch           0.048173
Embarked        0.040765
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このモデルで予測したSurvivedのcsvを出力してKaggleにアップロードするとスコアと順位が出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df_test_origin = pd.read_csv(&#39;./test.csv&#39;)
df_test = preprocess(df_test_origin)
submit_data =  pd.Series(clf.predict(df_test), name=&#39;Survived&#39;, index=df_test_origin[&#39;PassengerId&#39;])
submit_data.to_csv(&#39;submit.csv&#39;, header=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/166.png&#34; alt=&#34;スコアと順位&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://techblog.gmo-ap.jp/2017/10/02/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AE%E5%AE%9F%E8%B7%B5%E5%85%A5%E9%96%80%E3%83%BCrandom-forest%E3%81%AE%E8%A6%81%E7%B4%84/&#34;&gt;機械学習の実践入門ーRandom Forestの要約 | GMOアドパートナーズグループ TECH BLOG byGMO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.randpy.tokyo/entry/python_random_forest&#34;&gt;【Pythonで決定木 &amp;amp; Random Forest】タイタニックの生存者データを分析してみた - これで無理なら諦めて！世界一やさしいデータ分析教室&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TerraformでGKEクラスタとBigQueryを立てる</title>
          <link>https://www.sambaiz.net/article/165/</link>
          <pubDate>Tue, 29 May 2018 02:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/165/</guid>
          <description>

&lt;p&gt;GKEクラスタからBigQueryを読み書きすることを想定している。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/121/&#34;&gt;TerraformでVPCを管理するmoduleを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/159/&#34;&gt;Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;gke-https-github-com-hashicorp-terraform-guides-tree-master-infrastructure-as-code-k8s-cluster-gke&#34;&gt;&lt;a href=&#34;https://github.com/hashicorp/terraform-guides/tree/master/infrastructure-as-code/k8s-cluster-gke&#34;&gt;GKE&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/google/r/container_cluster.html&#34;&gt;google_container_cluster&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;oauth_scopeにbigqueryを付けている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_container_cluster&amp;quot; &amp;quot;sample&amp;quot; {
  name               = &amp;quot;${var.cluster_name}&amp;quot;
  description        = &amp;quot;sample k8s cluster&amp;quot;
  zone               = &amp;quot;${var.gcp_zone}&amp;quot;
  initial_node_count = &amp;quot;${var.initial_node_count}&amp;quot;

  master_auth {
    username = &amp;quot;${var.master_username}&amp;quot;
    password = &amp;quot;${var.master_password}&amp;quot;
  }

  node_config {
    machine_type = &amp;quot;${var.node_machine_type}&amp;quot;
    disk_size_gb = &amp;quot;${var.node_disk_size}&amp;quot;

    oauth_scopes = [
      &amp;quot;https://www.googleapis.com/auth/compute&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/logging.write&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/monitoring&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/bigquery&amp;quot;,
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;env&amp;quot; {
  description = &amp;quot;system env&amp;quot;
}
variable &amp;quot;gcp_zone&amp;quot; {
  description = &amp;quot;GCP zone, e.g. us-east1-b&amp;quot;
  default = &amp;quot;us-east1-b&amp;quot;
}

variable &amp;quot;cluster_name&amp;quot; {
  description = &amp;quot;Name of the K8s cluster&amp;quot;
}

variable &amp;quot;initial_node_count&amp;quot; {
  description = &amp;quot;Number of worker VMs to initially create&amp;quot;
  default = 1
}

variable &amp;quot;master_username&amp;quot; {
  description = &amp;quot;Username for accessing the Kubernetes master endpoint&amp;quot;
}

variable &amp;quot;master_password&amp;quot; {
  description = &amp;quot;Password for accessing the Kubernetes master endpoint&amp;quot;
}

variable &amp;quot;node_machine_type&amp;quot; {
  description = &amp;quot;GCE machine type&amp;quot;
  default = &amp;quot;n1-standard-1&amp;quot;
}

variable &amp;quot;node_disk_size&amp;quot; {
  description = &amp;quot;Node disk size in GB&amp;quot;
  default = &amp;quot;20&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bigquery&#34;&gt;BigQuery&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/google/r/bigquery_dataset.html&#34;&gt;google_bigquery_dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/google/r/bigquery_table.html&#34;&gt;google_bigquery_table&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_bigquery_dataset&amp;quot; &amp;quot;sample&amp;quot; {
  dataset_id  = &amp;quot;${var.dataset_id}&amp;quot;
  description = &amp;quot;sample dataset&amp;quot;
  location    = &amp;quot;${var.dataset_location}&amp;quot;

  labels {
    env = &amp;quot;${var.env}&amp;quot;
  }
}

resource &amp;quot;google_bigquery_table&amp;quot; &amp;quot;sample&amp;quot; {
  dataset_id = &amp;quot;${google_bigquery_dataset.sample.dataset_id}&amp;quot;
  table_id   = &amp;quot;sample&amp;quot;
  schema     = &amp;quot;${file(&amp;quot;bigquery/sample/schema.json&amp;quot;)}&amp;quot;

  time_partitioning {
    type  = &amp;quot;DAY&amp;quot;
  }

  labels {
    env = &amp;quot;${var.env}&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;env&amp;quot; {
  description = &amp;quot;system env&amp;quot;
}

variable &amp;quot;dataset_id&amp;quot; {
  description = &amp;quot;dataset ID&amp;quot;
}

variable &amp;quot;dataset_location&amp;quot; {
  description = &amp;quot;dataset location one of [US EU]&amp;quot;
  default     = &amp;quot;US&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;schema.json&lt;/code&gt;はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[
    {
        &amp;quot;name&amp;quot;: &amp;quot;foo&amp;quot;,
        &amp;quot;type&amp;quot;: &amp;quot;FLOAT64&amp;quot;,
        &amp;quot;mode&amp;quot;: &amp;quot;NULLABLE&amp;quot;,
        &amp;quot;description&amp;quot;: &amp;quot;foo&amp;quot;
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;呼び出し元&#34;&gt;呼び出し元&lt;/h2&gt;

&lt;p&gt;IAMからサービスアカウントを作成し、credentialをダウンロードする。
backendはgcs。&lt;code&gt;gcloud auth application-default login&lt;/code&gt;で認証しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;google&amp;quot; {
  credentials = &amp;quot;${file(&amp;quot;sample-credentials.json&amp;quot;)}&amp;quot;
  project     = &amp;quot;sample&amp;quot;
}

terraform {
  backend &amp;quot;gcs&amp;quot; {
    bucket = &amp;quot;sample-tfstate&amp;quot;
    prefix = &amp;quot;prd&amp;quot;
  }
}

module &amp;quot;sample-cluster&amp;quot; {
  source             = &amp;quot;./gke&amp;quot;
  gcp_zone           = &amp;quot;us-west1-a&amp;quot;
  env                = &amp;quot;prd&amp;quot;
  cluster_name       = &amp;quot;sample&amp;quot;
  initial_node_count = 1
  master_username    = &amp;quot;master&amp;quot;
  master_password    = &amp;quot;ae9fqAwfGefeweV&amp;quot;
  node_machine_type  = &amp;quot;n1-standard-2&amp;quot;
  node_disk_size     = &amp;quot;20&amp;quot;
}

module &amp;quot;sample-bigquery&amp;quot; {
  source           = &amp;quot;./bigquery/sample&amp;quot;
  env              = &amp;quot;prd&amp;quot;
  dataset_id       = &amp;quot;sample&amp;quot;
  dataset_location = &amp;quot;US&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>カナダのバンクーバーから南へ5都市周ってGoogleI/Oに行ってきた</title>
          <link>https://www.sambaiz.net/article/164/</link>
          <pubDate>Mon, 28 May 2018 23:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/164/</guid>
          <description>

&lt;p&gt;去年と連続でチケットが当たって2回目の参加。
&lt;a href=&#34;https://www.sambaiz.net/article/103&#34;&gt;前回&lt;/a&gt;はニューヨークで大変な目にあったが、
今回はI/OがGWの次の週だったので日程に余裕があり、カナダのバンクーバーから、ビクトリア、アメリカに入ってポートエンジェルス、シアトル、ポートランドと南下していって会場のマウンテンビューを目指すことにした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-1.png&#34; alt=&#34;地図&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;前回と同じ基本的にExpediaで航空券やホテルは取って、各業者のサイトで都市間の移動に使うフェリーやバスや電車を予約して、
あとアメリカのeSTAのようにカナダにもeTAというのがあって申請した。&lt;/p&gt;

&lt;p&gt;前回は空港からマンハッタンのT-mobileのショップにたどり着くまでネット回線がなく、地図すら空港のwifi頼みで大変な思いをした。
今回はカナダも行くので事前にAmazonでカナダも対応しているプランのSIMを&lt;a href=&#34;https://www.amazon.co.jp/%E3%82%A2%E3%83%A1%E3%83%AA%E3%82%AB-T-Mobile-SIM-%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%8D%E3%83%83%E3%83%88%E7%84%A1%E5%88%B6%E9%99%90%E4%BD%BF%E3%81%84%E6%94%BE%E9%A1%8C-%E3%82%A2%E3%83%A1%E3%83%AA%E3%82%AB%E3%83%BB%E3%82%AB%E3%83%8A%E3%83%80%E3%83%BB%E3%83%A1%E3%82%AD%E3%82%B7%E3%82%B3-%E9%80%9A%E8%A9%B1%E3%81%A8SMS%E3%80%81%E3%83%87%E3%83%BC%E3%82%BF%E9%80%9A%E4%BF%A1%E9%AB%98%E9%80%9F%E7%84%A1%E5%88%B6%E9%99%90%E4%BD%BF%E3%81%84%E6%94%BE%E9%A1%8C/dp/B01NBOQ5AP&#34;&gt;購入して&lt;/a&gt;業者にアクティベートしてもらうことにした。&lt;/p&gt;

&lt;p&gt;今回は夜出発だったので時間に余裕があったが、念のため前日から万札を何枚か財布に入れておいた。つまるところ、現金とネットさえあればなんとでもなるのだ。&lt;/p&gt;

&lt;h2 id=&#34;バンクーバー&#34;&gt;バンクーバー&lt;/h2&gt;

&lt;p&gt;空港から出ても怪しい人を見かけないし、駅の人も愛想良く案内してくれる。
アナウンスもはっきりしているので聞き取りやすく券売機のUIもわかりやすい。
駅の券売機で交通ICカードCompassを手に入れれば、電車・バス共に乗ることができる。
Uberは走っていないがバスが発達していて大体事足りる。バス停の標識も比較的低い位置にあって気付きやすい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-3.jpg&#34; alt=&#34;バス停&#34; /&gt;&lt;/p&gt;

&lt;p&gt;バスから降りるとき皆Thank youと言ってるのは良い感じだ。財布を落としたり傘を忘れたりしても皆で教えてくれるし、人が親切で治安が良くて安心感がある。&lt;/p&gt;

&lt;p&gt;アジア系の飲食店が多い。漢字が併記されているのもよく見る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-2.jpg&#34; alt=&#34;フォー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;朝食は&lt;a href=&#34;https://www.jethrosfinegrub.com/&#34;&gt;Jethro&amp;rsquo;s Fine Grub&lt;/a&gt;という店で取った。ダウンタウンからは少し離れてるのに待ちが発生していた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-4.jpg&#34; alt=&#34;カウボーイブレックファスト&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これを食べてからGranville Islandという店が並んでいるところに行ってきた。
Public Marketにはソーセージやお菓子などが売ってたりするんだけど、腹が一向に空かないし、中には座れず外はとても寒かったので何も買わずに帰ってきた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-5.jpg&#34; alt=&#34;Granville Island&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ビクトリア&#34;&gt;ビクトリア&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://bcfconnector.com/&#34;&gt;BC Ferries Connector&lt;/a&gt;というバスがバンクーバーのPublic Central Stationから出ていて、これに乗るとそのままフェリーに乗り込んでビクトリアまで行くことができる。船内のカフェテリアにカナダらしい食べ物プーティンがあったので頼んでみたら思ったより量が多く、15分前ぐらいのアナウンスでバスに戻らないと普通に置いてかれるので、なんとかコーラで流し込んだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-6.jpg&#34; alt=&#34;プーティン&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ビクトリアのダウンタウンに到着後、バスで1時間くらいかけて北へButchers Gardenという庭園に向かった。
ビクトリアには交通ICカードがないので、車内で5ドル払って1日乗車券をもらって乗る。
この時期は色とりどりのチューリップが咲いていて、歩いているだけで良い香りがする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-7.jpg&#34; alt=&#34;Butchers Garden&#34; /&gt;&lt;/p&gt;

&lt;p&gt;そのほかに鹿おどしのある日本庭園や、イタリア庭園もあったりする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-8.jpg&#34; alt=&#34;Butchers Garden&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このためにビクトリアを訪れてもよいぐらい満足度が高かった。&lt;/p&gt;

&lt;p&gt;朝食は&lt;a href=&#34;http://www.thebluefoxcafe.com/&#34;&gt;BlueFox Caffe&lt;/a&gt;という店でEggs Pacificoというサーモンとアボカドのエッグベネディクトを頼んだ。
付け合わせの芋が多いが、とても美味しい。1日1食の日々がしばらく続く。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-9.jpg&#34; alt=&#34;エッグベネディクト&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ポートエンジェルス-オリンピック半島&#34;&gt;ポートエンジェルス(オリンピック半島)&lt;/h2&gt;

&lt;p&gt;ビクトリアの州議事堂の近くから出ている&lt;a href=&#34;https://www.cohoferry.com/&#34;&gt;Black Ball Ferry Line&lt;/a&gt;に乗ってポートエンジェルスに移動する。
予約しても受付でチケットを受け取る必要がある。乗る前に入国審査を受けて、I-94Aという紙をパスポートに貼ってもらった。
料金が6ドルかかる。カードでも払えるがカナダドルでは払えなかった。&lt;/p&gt;

&lt;p&gt;町の自転車屋で電動自転車を借りて、まずはオリンピック国立公園のビジターセンターを目指した。ここで10ドル払うと入園券みたいなののとマップがもらえる。
どこに行くつもりか、と聞かれたので何も考えてないと答えると、比較的近くにあるHurricane Ridgeという所を教えてもらったのでそこを目指すことにした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-10.jpg&#34; alt=&#34;上り坂&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オフシーズンだからか道を工事していて所々コンディションが悪い。しかもずっと上り坂だ。
それでも電動アシストの力を借りて登っていったのだが、途中でまさかの電池切れ。しょうがないので町に引き返してその日は終わり。返すとき顛末を説明したら割り引いてくれた。&lt;/p&gt;

&lt;p&gt;次の日はバスでMarymere fallsという小さな滝のトレッキングコースに行った。散歩みたいなコースですぐ終わってしまったので、
途中の分岐にあったStormKingというコースにも入ってみたら、傾斜が延々と続く山登りコースだった。終盤&lt;code&gt;END OF MAINTAINED TRAIL&lt;/code&gt;の標識よりあとはいろいろ厳しくなり、勇気と気合いでロープをつかみながら登っていくことになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-12.jpg&#34; alt=&#34;ロープ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;頂上からはCrescent Lakeがその名の通り三日月に見える。景色はよいのだけど足場が狭くて立っているだけで怖い。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-11.jpg&#34; alt=&#34;頂上&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;シアトル&#34;&gt;シアトル&lt;/h2&gt;

&lt;p&gt;ポートエンジェルスからバスでシアトルへ。&lt;a href=&#34;https://olympicbuslines.com/&#34;&gt;Olympic Bus Lines&lt;/a&gt;のバスで、クッキーが配られた。&lt;/p&gt;

&lt;p&gt;シアトルのホテルは高かったのでAirBnbを使ってみた。ナンバーロック式の部屋だったので、ホストとはメッセージのやりとりだけで済んだし、親切にも日本語のガイドブックまで用意しておいてくれた。&lt;/p&gt;

&lt;p&gt;まず、交通ICカードOrcaを手に入れようと、駅の自販機にクレジットカードを入れたところ出てこなくなってしまった。駅員はいないので、なんとか引き抜こうと頑張っていたところ、親切な人がペンチを借りてきてくれてなんとか引き抜くことができた。よかった。
ただ、こんな苦労して手に入れたOrcaも2回ぐらいしか使わなかった。というのもバス停が他の標識と混在して分かりづらく、Uberに迎えに来てもらった方が楽だったからだ。相乗りのUber Poolならバスの倍くらいで乗ることができる。&lt;/p&gt;

&lt;p&gt;気を取り直して、Amazonの本部、Day 1に行ってきた。前から予約すれば社内ツアーもあるみたいだけど、今回の目的はこの1階にある、今年オープンしたレジ無しコンビニのAmazon Goだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-13.jpg&#34; alt=&#34;Amazon Go外観&#34; /&gt;&lt;/p&gt;

&lt;p&gt;アプリをインストールし、入り口で画面のQRコードをかざして入れば、あとは好きに商品を取って、そのまま持って行ってもよいというシステム。画像認識などで判別しているらしく、天井にはそれらしい機材がついている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-14.jpg&#34; alt=&#34;Amazon Go店内&#34; /&gt;&lt;/p&gt;

&lt;p&gt;レジがないので、店内は完全に無人化と思いきや、アルコール売り場のところだけIDを確認する人がいた。&lt;/p&gt;

&lt;p&gt;店を出ると数分でアプリにレシートが届く。意識的にややこしい取り方をしたつもりだけど、数も品物も完全に一致していて驚いた。不気味でさえある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-15.png&#34; alt=&#34;Amazon Goレシート&#34; /&gt;&lt;/p&gt;

&lt;p&gt;シアトルはStarbucksの本部もあって、1号店や旗艦店がある。
1号店はPike Place Marketにあって、隣にあるピロシキ屋が美味しかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-16.jpg&#34; alt=&#34;Starbucks 1号店&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Pike Place Marketの近くにFransという高級チョコレートの店があって、1個単位で買って食べることができる。
ウイスキー入りのものを買ってみたが、初めてこの類のもので美味しいと思ったかもしれない。&lt;/p&gt;

&lt;p&gt;夜はマリナーズのホームグラウンド、セーフコ・フィールドでエンゼルス戦の試合を見た。
2時間前から入れるが、球速測定したり、買い食いしたりなどしているとあっという間に時間が過ぎる。
この日(&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;)はちょうどSTAR WARS DAYで、キャラクターの格好をした人がいたり、演出もSTAR WARS仕様になっていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-17.jpg&#34; alt=&#34;セーフコ・フィールド&#34; /&gt;&lt;/p&gt;

&lt;p&gt;イチローはちょうどこの前日に試合への出場をやめてしまったのだけど、大谷が5番DHで出場して大活躍、結果エンゼルスが勝った。&lt;/p&gt;

&lt;h2 id=&#34;ポートランド-オレゴン&#34;&gt;ポートランド(オレゴン)&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.boltbus.com/&#34;&gt;BoltBus&lt;/a&gt;に乗ってポートランドへ。格安バスなんだけど、革のシートにWifi・電源ありとなかなか快適だった。ただ、電車の方が景色がよくておすすめらしい。&lt;/p&gt;

&lt;p&gt;ポートランドでは住んでいる知り合い家族に、地元の美味しい店やBeacon Rockという登れる岩などに連れてってもらった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-18.jpg&#34; alt=&#34;Beacon Rock&#34; /&gt;&lt;/p&gt;

&lt;p&gt;登っている途中に芝犬を連れた人と何人かすれ違った。オレゴンで人気らしい。知り合いもAiduという芝犬を飼っていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-31.jpg&#34; alt=&#34;Aidu&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オレゴンとワシントン州の境のコロンビア川に沿って走っている途中、木が枯れている区間があった。
なんと50000エーカーもの森が少年の火遊びによって燃えたらしい。
単位もスケールも分かりづらいんだけど、大体200km^2で、八王子くらいが丸々燃えたことになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-29.jpg&#34; alt=&#34;枯れた木&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ポートランドのダウンタウンは小さくて、有名な観光スポットがあるわけではないんだけど、&lt;a href=&#34;http://www.powells.com/&#34;&gt;Powell&amp;rsquo;s Books&lt;/a&gt;というとても大きな本屋はどれだけでもいても飽きない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-30.jpg&#34; alt=&#34;Powell&#39;s Books&#34; /&gt;&lt;/p&gt;

&lt;p&gt;宿は&lt;a href=&#34;https://www.mcmenamins.com/kennedy-school&#34;&gt;Kennedy School&lt;/a&gt;という、古い小学校を使ったホテルをとった。
部屋に黒板があってそれらしい雰囲気がある。バーやシアター、温水プールがあって、地元の人も遊びに来ていた。
泊まった日は廊下でオペラ歌手の演奏があって、ホテルで醸造されたビールを片手にそれを聞きながら夜を過ごした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-32.jpg&#34; alt=&#34;Kennedy School&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;coast-starlight&#34;&gt;Coast Starlight&lt;/h2&gt;

&lt;p&gt;ポートランドのUnion StationからAmtrakのCoast Starlightという夜行列車に乗ってサンノゼまで。
この列車自体はシアトルから出てロサンゼルスまで行くんだけど、その一部ですら17時間乗りっぱなしだ。
寝台の個室席もあるんだけど、食事が込みとはいえ多少値が張るためCoachという普通の席を取った。
乗ってみると意外とこれが快適で足が伸ばせるくらい前の座席との間隔があり、背もたれを倒すのも気を使わなくてよく、
普通に寝られる。ただ、停車時はやや寒いような気がしたので、
ポートランドで買った&lt;a href=&#34;https://www.pendleton-usa.com/&#34;&gt;PENDELTON&lt;/a&gt;のブランケットが早速活躍した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-33.jpg&#34; alt=&#34;PENDELTONのブランケット&#34; /&gt;&lt;/p&gt;

&lt;p&gt;列車内には食堂があるが、朝食以外予約が必要で、席まで時間を聞きにくる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-20.jpg&#34; alt=&#34;食堂車からの風景&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただのCoachにはwifiすら通っていないし、そもそも圏外の区間もあったりしたので、本とか持っていってラウンジで読むのがよいと思う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-21.jpg&#34; alt=&#34;ラウンジ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;google-i-o&#34;&gt;Google I/O&lt;/h2&gt;

&lt;p&gt;サンノゼからUberでマウンテンビューのホテルに向かったところ、Expediaで取ったホテルの日程が変更されておらず、
予約がキャンセルされていた。空いてる部屋も当然ない。しょうがないのでスーツケースを引いてI/Oに向かい、ホテルを探す羽目になった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-22.jpg&#34; alt=&#34;Androidとスーツケース&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今年のI/OはGoogle Asistantが店に電話をかけて予約を取ってくれるGoogle Duplex、Android/iOSでアンカーを共有して同じ場所にARオブジェクトを出すCloud Anchors、アプリで機械学習のモデルを使うFirebaseのML Kit、Androidの開発を効率化するAndroid Jetpackなどが発表された。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-28.jpg&#34; alt=&#34;Developers Keynote&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Cloud AnchorsをSandboxで体験してきた。たしかにAndroidとiOS間で共有できているし、精度も速度も良く見える。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-23.jpg&#34; alt=&#34;Cloud Anchrosを使ったゲーム&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Codelabsで軽く動かしてみた。IDでAnchorを共有するのもスムーズだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-24.jpg&#34; alt=&#34;CodelabsでCloud Anchros&#34; /&gt;&lt;/p&gt;

&lt;p&gt;去年行かなかったOffice HourでARのことについて聞いてきた。初歩的な質問にもGooglerが丁寧に答えてくれた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-25.jpg&#34; alt=&#34;Office Hour&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今回のお土産はGoogle Home miniと、Android Things。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-26.jpg&#34; alt=&#34;お土産&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;サンフランシスコ&#34;&gt;サンフランシスコ&lt;/h2&gt;

&lt;p&gt;バリスタの同期のコーヒー屋めぐりに同行させてもらい、効きコーヒーをやってみた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-27.jpg&#34; alt=&#34;利きコーヒー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今回は特に大きな問題もなかった。良かった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Macでの開発環境構築メモ</title>
          <link>https://www.sambaiz.net/article/163/</link>
          <pubDate>Sat, 14 Apr 2018 14:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/163/</guid>
          <description>

&lt;p&gt;新しいMBPを買ったので開発環境の構築でやったことを残しておく&lt;/p&gt;

&lt;h2 id=&#34;設定&#34;&gt;設定&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;アクセシビリティから3本指スクロールを有効にする&lt;/li&gt;
&lt;li&gt;ホットコーナーの左上にLaunchPad、右上にデスクトップを割り当てている&lt;/li&gt;
&lt;li&gt;画面をなるべく広く使うためにDockは左に置いて自動的に隠す&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;bash-profile&#34;&gt;bash_profile&lt;/h2&gt;

&lt;p&gt;パッケージマネージャ以外で持ってきたバイナリは&lt;code&gt;${HOME}/bin&lt;/code&gt;に置くことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;touch ~/.bash_profile
mkdir ${HOME}/bin
echo &amp;quot;export PATH=\$PATH:${HOME}/bin&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;homebrew-https-brew-sh-cask-https-github-com-caskroom-homebrew-cask&#34;&gt;&lt;a href=&#34;https://brew.sh&#34;&gt;HomeBrew&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/caskroom/homebrew-cask&#34;&gt;Cask&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;/usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;
brew tap caskroom/cask
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;一般的なアプリケーション-コマンドのインストール&#34;&gt;一般的なアプリケーション/コマンドのインストール&lt;/h2&gt;

&lt;p&gt;XcodeとUnityとLINEは手動で入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew cask install google-chrome kap visual-studio-code slack kindle
brew install jq gibo mysql wget
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;git&#34;&gt;Git&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;git config --global user.name sambaiz
git config --global user.email godgourd@gmail.com
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker-k8s&#34;&gt;Docker &amp;amp; K8s&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;brew cask install docker virtualbox minikube
brew install docker kubernetes-helm
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fish&#34;&gt;fish&lt;/h2&gt;

&lt;p&gt;bash前提で書かれたスクリプトも多いので、デフォルトシェルにはしない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install fish
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tmux&#34;&gt;tmux&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;~/.tmux.conf&lt;/code&gt;に設定を書く。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/95/&#34;&gt;tmuxのメモ - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install tmux
vi ~/.tmux.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;go&#34;&gt;Go&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/moovweb/gvm&#34;&gt;gvm&lt;/a&gt;でバージョン管理する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/44/&#34;&gt;gvmでGoのバージョン管理 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)
source ${HOME}/.gvm/scripts/gvm
gvm install go1.10 -B
echo &amp;quot;source \${HOME}/.gvm/scripts/gvm&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
echo &amp;quot;gvm use go1.10&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile 
. ~/.bash_profile
go version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/motemen/ghq&#34;&gt;ghq&lt;/a&gt;でリポジトリを管理し、&lt;a href=&#34;https://github.com/peco/peco&#34;&gt;peco&lt;/a&gt;でインクリメンタルサーチして移動したりできるようにする。ghqはデフォルトで&lt;code&gt;~/.ghq&lt;/code&gt;にcloneするが、GOPATHと合わせておくとディレクトリ構造が同じなのでGoのリポジトリをそのまま扱える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get github.com/motemen/ghq
brew install peco
echo &amp;quot;export GHQ_ROOT=\${GOPATH}/src&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
# ghq get git@github.com:sambaiz/puppeteer-lambda-starter-kit.git
# ghq look $(ghq list -p | peco)
echo &#39;alias ghql=&amp;quot;echo \$(ghq list -p | peco)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
# cd `ghql`
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;node-js&#34;&gt;Node.js&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tj/n&#34;&gt;n&lt;/a&gt;でバージョン管理する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/8/&#34;&gt;Node.jsのバージョン管理 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install node yarn
npm install -g n
sudo n stable
node -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serverless frameworkも入れる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install -g serverless
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;python3&#34;&gt;Python3&lt;/h2&gt;

&lt;p&gt;gcloud等がPython2を要求してくるので、aliasは張らない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install python3
python3 --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pip-python2&#34;&gt;pip (python2)&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;wget https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
rm get-pip.py
pip --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;java-scala&#34;&gt;Java &amp;amp; Scala&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;brew cask install java
brew install scala sbt
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;aws-https-docs-aws-amazon-com-ja-jp-cli-latest-userguide-installing-html&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/cli/latest/userguide/installing.html&#34;&gt;AWS&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;pip install awscli --upgrade --user
aws configure --profile ${AWS_PROFILE}
echo &amp;quot;export AWS_DEFAULT_PROFILE=${AWS_PROFILE} &amp;gt;&amp;gt; ~/.bash_profile
echo &amp;quot;PATH=\$PATH:~/Library/Python/2.7/bin&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
. ~/.bash_profile
aws --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gcp-https-cloud-google-com-sdk-docs-quickstart-mac-os-x-kubectl&#34;&gt;&lt;a href=&#34;https://cloud.google.com/sdk/docs/quickstart-mac-os-x&#34;&gt;GCP&lt;/a&gt; &amp;amp; kubectl&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;(
  cd ${HOME}/bin \
  &amp;amp;&amp;amp; sudo wget https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-192.0.0-darwin-x86_64.tar.gz \
  &amp;amp;&amp;amp; sudo tar -zxf google-cloud-sdk-192.0.0-darwin-x86_64.tar.gz \
  &amp;amp;&amp;amp; sudo rm google-cloud-sdk-192.0.0-darwin-x86_64.tar.gz \
  &amp;amp;&amp;amp; sudo ./google-cloud-sdk/install.sh \
  &amp;amp;&amp;amp; sudo ./google-cloud-sdk/bin/gcloud init \
)
. ~/.bash_profile
gcloud --version
sudo gcloud components install kubectl
kubectl version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;protobuf-https-github-com-google-protobuf&#34;&gt;&lt;a href=&#34;https://github.com/google/protobuf&#34;&gt;Protobuf&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;(
  mkdir /tmp/protoc \
  &amp;amp;&amp;amp; cd /tmp/protoc \
  &amp;amp;&amp;amp; wget https://github.com/google/protobuf/releases/download/v3.5.1/protoc-3.5.1-osx-x86_64.zip \
  &amp;amp;&amp;amp; unzip protoc-3.5.1-osx-x86_64.zip \
  &amp;amp;&amp;amp; sudo cp bin/protoc ${HOME}/bin \
  &amp;amp;&amp;amp; rm -r /tmp/protoc
)
. ~/.bash_profile
protoc --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;android&#34;&gt;Android&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;brew cask install android-studio
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動してSDKをインストールしてcliツールのパスを通す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo &amp;quot;export PATH=\$PATH:${HOME}/Library/Android/sdk/platform-tools&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
. ~/.bash_profile
adb --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;key&#34;&gt;Key&lt;/h2&gt;

&lt;p&gt;GitHub等に登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh-keygen -t rsa -b 4096
pbcopy &amp;lt; ~/.ssh/id_rsa.pub
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pythonのasyncioで非同期にリクエストを飛ばす</title>
          <link>https://www.sambaiz.net/article/162/</link>
          <pubDate>Sat, 14 Apr 2018 13:37:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/162/</guid>
          <description>&lt;p&gt;Pythonの&lt;a href=&#34;https://docs.python.org/3/library/asyncio.html&#34;&gt;asyncio&lt;/a&gt;はイベントループを回してシングルスレッドで並行に非同期処理を行う。
マルチスレッドで並列に実行するのが&lt;a href=&#34;https://docs.python.jp/3/library/threading.html&#34;&gt;threading&lt;/a&gt;で、
マルチプロセスで並列に実行するのが&lt;a href=&#34;https://docs.python.jp/3/library/multiprocessing.html&#34;&gt;multiprocessing&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import asyncio

async def sleep(s):
    await asyncio.sleep(s)
    print(s)
    return s

loop = asyncio.get_event_loop()

loop.run_until_complete(sleep(5))

coros = [sleep(3), sleep(2)]
futures = asyncio.gather(*coros)
loop.run_until_complete(futures)
print(futures.result())
loop.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ python main.py
5
2
3
[3, 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.python.org/3.6/library/asyncio-eventloops.html#asyncio.AbstractEventLoopPolicy.get_event_loop&#34;&gt;get_event_loop()&lt;/a&gt;
でイベントループを取得し、
&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#asyncio.gather&#34;&gt;gather()&lt;/a&gt;で処理をまとめたりして、
&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#example-future-with-run-until-complete&#34;&gt;run_until_complete()&lt;/a&gt;で
&lt;a href=&#34;https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future&#34;&gt;Future&lt;/a&gt;の完了を待ち、
結果を取得してイベントループを&lt;code&gt;close()&lt;/code&gt;している。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;async def&lt;/code&gt;を付けた関数は&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#coroutines&#34;&gt;Coroutine&lt;/a&gt;となり、
&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#asyncio.ensure_future&#34;&gt;ensure_future()&lt;/a&gt;でFutureのサブクラスの、イベントループで実行させる&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#task&#34;&gt;Task&lt;/a&gt;にすることができる。
&lt;code&gt;run_until_complete()&lt;/code&gt;はそのままCoroutineを投げても&lt;code&gt;ensure_future()&lt;/code&gt;でwrapしてくれる。&lt;/p&gt;

&lt;p&gt;httpクライアント&lt;a href=&#34;https://github.com/requests/requests&#34;&gt;requests&lt;/a&gt;は&lt;a href=&#34;https://github.com/requests/requests/blob/265ef609d5903151374fba480aa81aafe68126ff/docs/user/advanced.rst#blocking-or-non-blocking&#34;&gt;Blockingする&lt;/a&gt;ようなので、asyncioに対応している&lt;a href=&#34;https://github.com/aio-libs/aiohttp&#34;&gt;aiohttp&lt;/a&gt;を使ってリクエストしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import aiohttp
import asyncio
import async_timeout

async def fetch(session, url):
    print(&amp;quot;{} start&amp;quot;.format(url))
    async with async_timeout.timeout(10):
        async with session.get(url) as response:
            text = await response.text()
            print(&amp;quot;{} done&amp;quot;.format(url))
            return text

async def main():
    async with aiohttp.ClientSession() as session:
        urls = [
          &#39;https://www.youtube.com&#39;,
          &#39;https://www.python.org&#39;,
          &#39;https://www.google.co.jp&#39;,
          &#39;https://www.facebook.com&#39;
        ]
        promises = [fetch(session, u) for u in urls]
        await asyncio.gather(*promises)

if __name__ == &#39;__main__&#39;:
    loop = asyncio.get_event_loop()    
    loop.run_until_complete(main())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;非同期にリクエストが飛び、返り次第処理が実行されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python req.py 
https://www.python.org start
https://www.facebook.com start
https://www.youtube.com start
https://www.google.co.jp start
https://www.python.org done
https://www.google.co.jp done
https://www.facebook.com done
https://www.youtube.com done
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes,Helmで負荷試験ツールLocustを立てる</title>
          <link>https://www.sambaiz.net/article/161/</link>
          <pubDate>Sun, 18 Mar 2018 22:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/161/</guid>
          <description>&lt;p&gt;OSSの負荷試験ツール&lt;a href=&#34;https://locust.io/&#34;&gt;Locust&lt;/a&gt;をK8sクラスタに立てる。
K8sならworkerの増減も簡単だし、HelmのChartもあるので立てるのも楽。&lt;/p&gt;

&lt;p&gt;LocustはPython製で、以下のような&lt;a href=&#34;https://docs.locust.io/en/latest/writing-a-locustfile.html&#34;&gt;コード&lt;/a&gt;で処理を書くことができる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@task(10)&lt;/code&gt;のように括弧の中に数字を書いて実行される割合を偏らせることもできる。
異なるTaskSetに対応するユーザーを複数作ることもできて、こちらもweightで重みを付けられる。
ユーザー数はあとでWeb上から入力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir tasks
$ cat tasks/tasks.py
from locust import HttpLocust, TaskSet, task

class ElbTasks(TaskSet):
  @task
  def task1(self):
    with client.get(&amp;quot;/&amp;quot;, catch_response=True) as response:
    if response.content != &amp;quot;Success&amp;quot;:
        response.failure(&amp;quot;Got wrong response&amp;quot;)

class ElbWarmer(HttpLocust):
  task_set = ElbTasks
  min_wait = 1000
  max_wait = 3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stableに&lt;a href=&#34;https://github.com/kubernetes/charts/tree/master/stable/locust&#34;&gt;Chart&lt;/a&gt;はあるが、今のところtasksの中を書き換えなくてはいけないようなので、forkしてきてtasksの中を書き換え、&lt;code&gt;package&lt;/code&gt; して、&lt;code&gt;helm repo index&lt;/code&gt; でこれを参照する&lt;code&gt;index.yaml&lt;/code&gt;を生成した。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;追記(2020-03-11): 今はConfigmapを自分で作成し &lt;code&gt;--set worker.config.configmapName=***&lt;/code&gt; することでforkしなくてもよく&lt;a href=&#34;https://github.com/helm/charts/commit/0ab53c795720882f3f9630c12f8ecf96ba881638&#34;&gt;なった&lt;/a&gt;
&lt;code&gt;kubectl create configmap locust-worker-configs --from-file tasks/tasks.py&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;$ helm package .
$ helm repo index .
$ ls
index.yaml		locust-0.1.2.tgz		...
$ cat index.yaml
apiVersion: v1
entries:
  locust:
    ...
    urls:
    - locust-0.1.2.tgz
    version: 0.1.2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ helm repo add my-locust &#39;https://raw.githubusercontent.com/sambaiz/charts/my-locust/stable/locust&#39;
$ helm repo list
NAME     	URL                                                                     
stable   	https://kubernetes-charts.storage.googleapis.com
local    	http://127.0.0.1:8879/charts    
my-locust	https://raw.githubusercontent.com/sambaiz/charts/my-locust/stable/locust
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GKEのようなRBACが有効な環境でHelmを使う場合、TillerにServiceAccountを設定しておく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/160/&#34;&gt;RBACが有効なGKEでHelmを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;addしたrepoからinstallする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm install -n my-locust --set master.config.target-host=**** my-locust/locust 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;masterとworker(デフォルトで2つ)が立った。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
my-locust-master-7f7d57f5dc-k966s   1/1       Running   0          1m
my-locust-worker-66cc964748-7ff5w   1/1       Running   0          1m
my-locust-worker-66cc964748-wx5hf   1/1       Running   0          1m
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;port-forwardしてweb-uiにアクセスしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl port-forward $POD_NAME 8089
$ open localhost:8089
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/161.png&#34; alt=&#34;User数と生成速度の設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;実行開始するとRPSなどがリアルタイムで表示される。
1000Users、50spawned/sで始めてみたところ、200Userにも到達せずにリクエスト自体が止まってしまった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/161-2.png&#34; alt=&#34;実行結果&#34; /&gt;&lt;/p&gt;

&lt;p&gt;少なく再設定してもUsersはそのままでよく分からない。
一旦立ち上げ直して100,10で実行してみたら100Userまで行くことは確認できた。&lt;/p&gt;

&lt;p&gt;再び止まるまで上げてみたところ、途中でOOMになっていることが分かった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl describe pod my-locust-worker-****
Containers:
  locust:
    ...
    Last State:     Terminated
      Reason:       OOMKilled
      Exit Code:    137
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;メモリ(割り当て128mi)だけではなく、CPU(割り当て100&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu&#34;&gt;millicores&lt;/a&gt;)もそれなりに使われていて、単純にreplica数を増やせばよさそう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ watch kubectl top node
NAME                                CPU(cores)   MEMORY(bytes)
my-locust-master-7f7d57f5dc-h9mvt   1m           19Mi
my-locust-worker-66cc964748-9dp8n   72m          112Mi
my-locust-worker-66cc964748-h94v9   61m          114Mi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということでworkerを2から5に増やしてみたところUser数を増やしても止まらなくなった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl scale deployment my-locust-worker --replicas=5
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RBACが有効なGKEでHelmを使う</title>
          <link>https://www.sambaiz.net/article/160/</link>
          <pubDate>Sun, 18 Mar 2018 01:04:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/160/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/122/&#34;&gt;k8sのパッケージマネージャーHelmを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm version
Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.8.2&amp;quot;, GitCommit:&amp;quot;a80231648a1473929271764b920a8e346f6de844&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}
Server: &amp;amp;version.Version{SemVer:&amp;quot;v2.8.2&amp;quot;, GitCommit:&amp;quot;a80231648a1473929271764b920a8e346f6de844&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GKEで&lt;code&gt;helm init&lt;/code&gt;して&lt;code&gt;helm install&lt;/code&gt;したところ以下のエラーが返ってきた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: release my-locust failed: namespaces &amp;quot;default&amp;quot; is forbidden: User &amp;quot;system:serviceaccount:kube-system:default&amp;quot; cannot get namespaces in the namespace &amp;quot;default&amp;quot;: Unknown user &amp;quot;system:serviceaccount:kube-system:default&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GKEではデフォルトでK8sのRBAC(Role-Based Access Control)が&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/role-based-access-control&#34;&gt;有効になっている&lt;/a&gt;ため、&lt;a href=&#34;https://github.com/kubernetes/helm/blob/master/docs/rbac.md&#34;&gt;Tillerインスタンスに権限を与える&lt;/a&gt;必要がある。&lt;/p&gt;

&lt;p&gt;ということでTiller用にnamespaceを切って、その中では好きにできる&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/rbac/#role-and-clusterrole&#34;&gt;Role&lt;/a&gt;と、Tillerが使う&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34;&gt;ServiceAccount&lt;/a&gt;を作成し、RoleBindingで紐づける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: tiller-manager
  namespace: tiller-world
rules:
- apiGroups: [&amp;quot;&amp;quot;, &amp;quot;extensions&amp;quot;, &amp;quot;apps&amp;quot;]
  resources: [&amp;quot;*&amp;quot;]
  verbs: [&amp;quot;*&amp;quot;]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: tiller-world
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: tiller-binding
  namespace: tiller-world
subjects:
- kind: ServiceAccount
  name: tiller
  namespace: tiller-world
roleRef:
  kind: Role
  name: tiller-manager
  apiGroup: rbac.authorization.k8s.io
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Roleを追加するため、自分自身にsuper-user相当の&lt;code&gt;cluster-admin&lt;/code&gt;roleをbindする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=&amp;lt;email&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create namespace tiller-world
$ kubectl create -f tiller-rbac.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;helm init&lt;/code&gt;時に作ったServiceAccountを渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm init --tiller-namespace tiller-world --service-account tiller
$ kubectl get deployment -n tiller-world
NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
tiller-deploy   1         1         1            1           1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prometheusをinstallしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm install --name my-prometheus stable/prometheus --tiller-namespace tiller-world --namespace tiller-world
$ kubectl get pods -n tiller-world
NAME                                                           READY     STATUS    RESTARTS   AGE
my-prometheus-prometheus-alertmanager-85f75879db-9r9z2         2/2       Running   0          1m
my-prometheus-prometheus-kube-state-metrics-65dfc57897-95ts7   1/1       Running   0          1m
my-prometheus-prometheus-server-7c98fb8ffb-s7jpq               2/2       Running   0          1m
tiller-deploy-57dbcb6bbc-6srlt                                 1/1       Running   0          2m
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;ただ、実際のところHelmが特定のnamespaceしか触れないのは不便だし、roleをあとから増やすのも面倒なので最初からcluster-adminのRoleを付けておいてもよいかもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る</title>
          <link>https://www.sambaiz.net/article/159/</link>
          <pubDate>Tue, 13 Mar 2018 01:04:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/159/</guid>
          <description>

&lt;p&gt;Logging AgentをNodeレベルの&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;DaemonSet&lt;/a&gt;として動かすのではなく、Podの中に&lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/logging/#using-a-sidecar-container-with-the-logging-agent&#34;&gt;Sidecar Container&lt;/a&gt;として動かす。その分リソースは食うけど、独立した設定で動かせる。&lt;/p&gt;

&lt;h2 id=&#34;アプリケーション&#34;&gt;アプリケーション&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/go-logging-sample&#34;&gt;https://github.com/sambaiz/go-logging-sample&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Goで定期的にログを出すサンプルコードを書いたのでこれを使う。
&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;viper&lt;/a&gt;で設定を持ち、
&lt;a href=&#34;https://github.com/uber-go/zap&#34;&gt;zap&lt;/a&gt;でログを出力する。
あとSIGINTを拾ってSync()してGraceful Shutdownするようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/104/&#34;&gt;Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/develop/develop-images/multistage-build/#name-your-build-stages&#34;&gt;multistage-build&lt;/a&gt;して、GKEで動かすのでContainer Registryに上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t go-logging-sample .
$ docker tag go-logging-sample gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1 
$ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fluentdの設定&#34;&gt;Fluentdの設定&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaizenplatform/fluent-plugin-bigquery&#34;&gt;fluent-plugin-bigquery&lt;/a&gt;プラグインを使う。&lt;/p&gt;

&lt;p&gt;projectとdataset、パーティションの&lt;a href=&#34;https://cloud.google.com/bigquery/docs/creating-partitioned-tables&#34;&gt;日付分割テーブル&lt;/a&gt;に入れる場合は、auto_create_table&lt;a href=&#34;https://github.com/kaizenplatform/fluent-plugin-bigquery#date-partitioned-table-support&#34;&gt;できない&lt;/a&gt;のでtableも作成しておく。&lt;/p&gt;

&lt;p&gt;fluentdの設定は&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/&#34;&gt;ConfigMap&lt;/a&gt;で持つ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
data:
  fluent.conf: |
    &amp;lt;source&amp;gt;
      @type tail
      format json
      path /var/log/app.log
      pos_file /var/log/app.log.pos
      tag bigquery 
    &amp;lt;/source&amp;gt;

    &amp;lt;match bigquery&amp;gt;
      @type bigquery

      method load

      &amp;lt;buffer time&amp;gt;
        @type file
        path /var/log/bigquery.*.buffer
        timekey 1d
        flush_at_shutdown true
      &amp;lt;/buffer&amp;gt;

      auth_method	compute_engine

      project &amp;lt;project-name&amp;gt;
      dataset &amp;lt;dataset-name&amp;gt;
      table &amp;lt;table-name&amp;gt;$%Y%m%d
      fetch_schema true 
      ignore_unknown_values true	  
    &amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プラグイン入りのfluentdイメージもビルドして上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM fluent/fluentd:v1.1-onbuild

RUN apk add --update --virtual .build-deps \
        sudo build-base ruby-dev \

 # cutomize following instruction as you wish
 &amp;amp;&amp;amp; sudo gem install \
        bigdecimal fluent-plugin-bigquery:1.2.0 \

 &amp;amp;&amp;amp; sudo gem sources --clear-all \
 &amp;amp;&amp;amp; apk del .build-deps \
 &amp;amp;&amp;amp; rm -rf /var/cache/apk/* \
           /home/fluent/.gem/ruby/*/cache/*.gem

EXPOSE 24284
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ touch fluent.conf
$ mkdir plugins
$ docker build -t fluentd-bigquery .
$ docker tag fluentd-bigquery gcr.io/&amp;lt;project_id&amp;gt;/fluentd-bigquery:v1 
$ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/fluentd-bigquery
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;podの設定&#34;&gt;Podの設定&lt;/h2&gt;

&lt;p&gt;ConfigMapの&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#add-configmap-data-to-a-volume&#34;&gt;Volume&lt;/a&gt;と、ログが書かれるVolumeを定義し、
これを各コンテナでマウントする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: something-collector
spec:
  containers:
  - name: collector
    image: gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1
    env:
    - name: SAMPLE_LOG_PATH
      value: /var/log/app.log
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  - name: fluentd
    image: gcr.io/&amp;lt;project_id&amp;gt;/fluentd-bigquery:v1
    volumeMounts:
    - name: varlog
      mountPath: /var/log
    - name: config-volume
      mountPath: /fluentd/etc
  volumes:
  - name: varlog
    emptyDir: {}
  - name: config-volume
    configMap:
      name: fluentd-config
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;動かす&#34;&gt;動かす&lt;/h2&gt;

&lt;p&gt;BigQueryの権限が付いたGKEのクラスタにデプロイ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/165/&#34;&gt;TerraformでGKEクラスタとBigQueryを立てる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud container clusters get-credentials &amp;lt;cluster-name&amp;gt; --zone &amp;lt;zone&amp;gt; --project &amp;lt;project-name&amp;gt;
$ kubectl config current-context
gke_***

$ kubectl create -f fluentd-configmap.yaml
$ kubectl create -f something-collector-pod.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;立ち上がらないときは&lt;code&gt;-c&lt;/code&gt;でコンテナのnameを指定してログを見る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl logs something-collector -c fluentd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OptionのUse Legacy SQLのチェックを外して&lt;a href=&#34;https://cloud.google.com/bigquery/docs/reference/standard-sql/migrating-from-legacy-sql&#34;&gt;標準SQL&lt;/a&gt;でBigQueryに入っていることを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT
  *
FROM
  `&amp;lt;dataset-name&amp;gt;.&amp;lt;table-name&amp;gt;` 
WHERE
  _PARTITIONTIME BETWEEN 
  TIMESTAMP_TRUNC(TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 * 24 HOUR),DAY)
  AND 
  TIMESTAMP_TRUNC(CURRENT_TIMESTAMP(),DAY);
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQL InnoDBのロックの挙動</title>
          <link>https://www.sambaiz.net/article/158/</link>
          <pubDate>Sat, 03 Mar 2018 19:44:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/158/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html&#34;&gt;https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;トランザクション分離レベルはデフォルトの&lt;code&gt;REPEATABLE-READ&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation;
+-----------------------+-----------------+
| @@GLOBAL.tx_isolation | @@tx_isolation  |
+-----------------------+-----------------+
| REPEATABLE-READ       | REPEATABLE-READ |
+-----------------------+-----------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;DBを立ち上げてテーブルとレコードを入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat schema_and_data.sql
CREATE TABLE a (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(128) NOT NULL
);

CREATE TABLE b (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    a_id BIGINT UNSIGNED NOT NULL,
    FOREIGN KEY (a_id) REFERENCES a (id)
);

INSERT INTO a (id, name) VALUES (1, &#39;1&#39;);
INSERT INTO a (id, name) VALUES (2, &#39;2&#39;);
INSERT INTO a (id, name) VALUES (3, &#39;3&#39;);
INSERT INTO a (id, name) VALUES (8, &#39;8&#39;);
INSERT INTO a (id, name) VALUES (9, &#39;9&#39;);
INSERT INTO a (id, name) VALUES (10, &#39;10&#39;);

$ cat start.sh
docker rm -f try-mysql-lock
docker run --name try-mysql-lock -p 4306:3306 -e &amp;quot;MYSQL_ALLOW_EMPTY_PASSWORD=yes&amp;quot; -e &amp;quot;MYSQL_DATABASE=try-mysql-lock&amp;quot; -e &amp;quot;TZ=Asia/Tokyo&amp;quot; --health-cmd=&#39;mysqladmin ping --silent&#39; -d mysql:5.6 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
while [[ $(docker inspect --format &amp;quot;{{.State.Health.Status}}&amp;quot; try-mysql-lock) != &amp;quot;healthy&amp;quot; ]]; do printf &amp;quot;.&amp;quot;; sleep 1; done
mysql -u root -h 0.0.0.0 -P 4306 -D try-mysql-lock &amp;lt; schema_and_data.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;共有-shared-ロック&#34;&gt;共有(Shared)ロック&lt;/h2&gt;

&lt;p&gt;その行を他がSELECTしたり共有ロックを取ることは許す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id = 2 LOCK IN SHARE MODE;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; SELECT * FROM a WHERE id = 2 LOCK IN SHARE MODE; -- 他も共有ロックは取れる
&amp;gt; UPDATE a SET name=&#39;b&#39; WHERE id = 3; -- これは通る。ロックは行単位なのでid=2だけロックされている。
&amp;gt; UPDATE a SET name=&#39;a&#39; WHERE id = 2; -- これは止まる
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たしかに1行ロックされている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SHOW ENGINE INNODB STATUS \G;
...
---TRANSACTION 2345, ACTIVE 40 sec
2 lock struct(s), heap size 360, 1 row lock(s)
MySQL thread id 4, OS thread handle 0x7f5de21d8700, query id 147 172.17.0.1 root init
SHOW ENGINE INNODB STATUS
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただのSELECTは分離レベルが&lt;code&gt;SERIALIZABLE&lt;/code&gt;でない限りロックをとらない。
ロックしないと、他のトランザクションのCOMMITで
追加されたデータ(ファントム)を読んでしまったりするかというと、
MySQLの&lt;code&gt;REPEATABLE-READ&lt;/code&gt;ではそうはならず、最初にSELECTしたときのスナップショットを返すようになっている。
ただし、&lt;code&gt;LOCK IN SHARE MODE&lt;/code&gt;や&lt;code&gt;FOR UPDATE&lt;/code&gt;を付けると&lt;code&gt;READ-COMMITED&lt;/code&gt;のように最新の結果を返す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://nippondanji.blogspot.jp/2013/12/innodbrepeatable-readlocking-read.html&#34;&gt;漢(オトコ)のコンピュータ道: InnoDBのREPEATABLE READにおけるLocking Readについての注意点&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;排他-exclusive-ロック&#34;&gt;排他(eXclusive)ロック&lt;/h2&gt;

&lt;p&gt;その行に対して他がロックを取ることを許さない。SELECTできるかは分離レベルにより、&lt;code&gt;REPEATABLE READ&lt;/code&gt;では&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_exclusive_lock&#34;&gt;できる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id = 2 FOR UPDATE;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; SELECT * FROM a WHERE id = 2 FOR UPDATE; -- 止まる。同じ行の排他ロックは取れない
&amp;gt; SELECT * FROM a WHERE id = 2 LOCK IN SHARE MODE; -- 止まる。共有ロックも取れない
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;逆に、共有ロックが取られている行に排他ロックも取れない。
ロックを取る順番によってはDeadlockになる。&lt;/p&gt;

&lt;h2 id=&#34;ギャップロック&#34;&gt;ギャップロック&lt;/h2&gt;

&lt;p&gt;存在しない範囲のindexのレコードを一部でもロックすると、行ではなく範囲がロックされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id &amp;gt; 5 FOR UPDATE;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; INSERT a (id, name) VALUE (6, &#39;a&#39;); -- 止まる。
&amp;gt; INSERT a (id, name) VALUE (4, &#39;a&#39;); -- WHEREには含まれないがこれも止まる。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ギャップロックの場合、同じ範囲を排他ロックできてしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id = 5 FOR UPDATE;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; SELECT * FROM a WHERE id = 5 FOR UPDATE; -- 止まらない
&amp;gt; INSERT a (id, name) VALUE (5, &#39;a&#39;); -- 止まる(Tx1でも同じことをやるとDeadlock)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ネクストキーロック&#34;&gt;ネクストキーロック&lt;/h2&gt;

&lt;p&gt;範囲でロックすると一つ先のキーまでロックされる。
ギャップにファントムを発生させないためのもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id &amp;lt; 6 FOR UPDATE; -- ギャップロック(id=4~7)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; UPDATE a SET name = &#39;b&#39; WHERE id = 8; -- 止まる
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;更新系クエリでかかるロック-https-dev-mysql-com-doc-refman-5-6-ja-innodb-locks-set-html&#34;&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/innodb-locks-set.html&#34;&gt;更新系クエリでかかるロック&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;insert&#34;&gt;INSERT&lt;/h3&gt;

&lt;p&gt;排他ロックがかかる。重複キーエラーになった場合は共有ロックがかかる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; INSERT INTO a (id, name) VALUE (5, &#39;b&#39;); 
&amp;gt; INSERT INTO a (id, name) VALUE (3, &#39;d&#39;); -- 重複キーエラー
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; INSERT INTO a (id, name) VALUE (5, &#39;c&#39;); -- 止まる
&amp;gt; UPDATE a SET name = &#39;e&#39; WHERE id = 3; -- 止まる
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;INSERT IGNORE&lt;/code&gt;しても同じ。そもそもこれは重複キー以外のエラーも無視した結果、変なデータが入ってしまうことがあるため、使わない方がよい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; INSERT INTO a (name) VALUE (NULL);  -- Column &#39;name&#39; cannot be null
&amp;gt; INSERT IGNORE INTO a (name) VALUE (NULL); -- Query OKで空文字が入ってしまう
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;update-delete&#34;&gt;UPDATE, DELETE&lt;/h3&gt;

&lt;p&gt;排他ネクストキーロックがかかる。INSERTでの&lt;code&gt;ON DUPLICATE KEY UPDATE&lt;/code&gt;も同様。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; UPDATE a SET name=&#39;a&#39; WHERE id BETWEEN 8 AND 9; 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; UPDATE a SET name=&#39;a&#39; WHERE id = 9; -- 止まる
&amp;gt; UPDATE a SET name=&#39;a&#39; WHERE id = 10; -- これも止まる
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;外部キー制約&#34;&gt;外部キー制約&lt;/h3&gt;

&lt;p&gt;さらに外部キー制約がかかるレコードを追加/更新/削除すると、参照するレコードも共有ロックされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; INSERT INTO b (a_id) VALUES (1);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; SELECT * FROM a WHERE id = 1 LOCK IN SHARE MODE; -- 通る
&amp;gt; SELECT * FROM a WHERE id = 1 FOR UPDATE; -- 止まる
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる</title>
          <link>https://www.sambaiz.net/article/157/</link>
          <pubDate>Sun, 25 Feb 2018 23:46:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/157/</guid>
          <description>

&lt;p&gt;UserPoolを作成。デフォルト設定はこんな感じ。
必須項目や、確認メールの文面などを自由にカスタマイズでき、
登録時などのタイミングでLambdaを発火させることもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/157.png&#34; alt=&#34;デフォルト設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作成したUserPoolにアプリクライアントを追加する。
ブラウザで使うのでクライアントシークレットはなし。&lt;/p&gt;

&lt;h2 id=&#34;クライアント側&#34;&gt;クライアント側&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/aws/aws-amplify/tree/master/packages/amazon-cognito-identity-js&#34;&gt;amazon-cognito-identity-js&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;依存するjsを持ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/amazon-cognito-identity.min.js
$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/aws-cognito-sdk.min.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sign UpからAPIを呼ぶところまでのボタンを並べた。
SignInすると&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-with-identity-providers.html&#34;&gt;OIDC標準のトークン&lt;/a&gt;がそのページのドメインのLocal Storageに書かれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/136/&#34;&gt;OpenID ConnectのIDトークンの内容と検証 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.idToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.accessToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.refreshToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.clockDrift
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.LastAuthUser
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;APIを呼ぶときはidTokenをAuthorization Headerに乗せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&amp;quot;signUp&amp;quot;&amp;gt;Sign Up&amp;lt;/button&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;label&amp;gt;Code:&amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;code&amp;quot;&amp;gt;&amp;lt;/label&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;button id=&amp;quot;confirm&amp;quot;&amp;gt;Confirm&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;signIn&amp;quot;&amp;gt;Sign In&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;whoAmI&amp;quot;&amp;gt;Who am I?&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;requestAPI&amp;quot;&amp;gt;Request API with token&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;signOut&amp;quot;&amp;gt;Sign Out&amp;lt;/button&amp;gt;

&amp;lt;script src=&amp;quot;aws-cognito-sdk.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;amazon-cognito-identity.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script&amp;gt;
const USER_NAME = &amp;quot;*****&amp;quot;;
const USER_PASSWORD = &amp;quot;*****&amp;quot;;
const USER_EMAIL = &amp;quot;*****&amp;quot;;
class CognitoUserPoolAuth {
  constructor(UserPoolId, clientId, apiEndpoint) {
    const poolData = {
      UserPoolId : UserPoolId,
      ClientId : clientId
    };
    this.userPool = new AmazonCognitoIdentity.CognitoUserPool(poolData);
    this.apiEndpoint = apiEndpoint
  }
  
  signUp(userName, password, email) {
    const attributeList = [];
    if (email) {
      attributeList.push(new AmazonCognitoIdentity.CognitoUserAttribute({
        Name : &#39;email&#39;,
        Value : email
      }));
    }

    return new Promise((resolve, reject) =&amp;gt; {
      this.userPool.signUp(userName, password, attributeList, null, (err, result) =&amp;gt; {
        if (err) {
          return reject(err);
        }
        resolve(result);
      });
    });
  }

  confirmCode(userName, confirmCode) {
    const cognitoUser = this.getCognitoUser(userName);
    return new Promise((resolve, reject) =&amp;gt; {
      cognitoUser.confirmRegistration(confirmCode, true, (err, result) =&amp;gt; {
        if (err) {
          return reject(err);
        }
        resolve(result);
      });
    })
  }

 signIn(userName, password) {
    const authenticationData = {
      Username : userName,
      Password : password,
    };
    const authenticationDetails = new AmazonCognitoIdentity.AuthenticationDetails(authenticationData);
    const cognitoUser = this.getCognitoUser(userName);
    return new Promise((resolve, reject) =&amp;gt; {
      cognitoUser.authenticateUser(authenticationDetails, {
        onSuccess: (result) =&amp;gt; {
          resolve(result.getAccessToken().getJwtToken());
        },

        onFailure: function(err) {
          reject(err);
        },
      });
    });
  }

  signOut() {
    const currentUser = this.currentUser();
    if (!currentUser) return;
    const cognitoUser = this.getCognitoUser(currentUser.username);
    if (!cognitoUser) return;
    cognitoUser.signOut();
  }

  getCognitoUser(userName) {
    const userData = {
      Username : userName,
      Pool : this.userPool
    };
    return new AmazonCognitoIdentity.CognitoUser(userData);
  }

  currentUser() {
    return this.userPool.getCurrentUser()
  }
  
  getJwtToken() {
    return new Promise((resolve, reject) =&amp;gt; {
      const cognitoUser = this.currentUser();
      if (!cognitoUser) {
        return reject(&amp;quot;unauthorized&amp;quot;);
      }
      cognitoUser.getSession((err, result) =&amp;gt; {
        if (err) { 
          return reject(err);
        }
        resolve(result.getIdToken().getJwtToken());
      });
    })
  }

  async requestAPIWithToken() {
    const token = await this.getJwtToken().catch(
      (err) =&amp;gt; {
        console.log(err);
      } 
    );
    const headers = token ? { &#39;Authorization&#39;: token } : {};
    return fetch(this.apiEndpoint, {
      headers: headers
    }).then((response) =&amp;gt; {
      return response.json();
    });
  }
}

// -------------
// Handler
// -------------

const auth = new CognitoUserPoolAuth(
    &amp;quot;&amp;lt;poolID&amp;gt;&amp;quot;, 
    &amp;quot;&amp;lt;clientID&amp;gt;&amp;quot;,
    &amp;quot;https://*****.execute-api.us-east-1.amazonaws.com/dev/secret&amp;quot;
)

document.getElementById(&amp;quot;signUp&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const result = await auth.signUp(USER_NAME, USER_PASSWORD, USER_EMAIL).catch((err) =&amp;gt; {
        if (err.code === &amp;quot;UsernameExistsException&amp;quot;) {
        return Promise.reject(&amp;quot;User name is already used&amp;quot;);
        } else {
        return Promise.reject(err);
        }
    });
    console.log(`signUp successfully`);
}, false);

document.getElementById(&amp;quot;confirm&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const code = document.getElementById(&amp;quot;code&amp;quot;).value;
    const result = await auth.confirmCode(USER_NAME, code);
    console.log(`confirm successfully`);
}, false);

document.getElementById(&amp;quot;signIn&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const result = await auth.signIn(USER_NAME, USER_PASSWORD).catch((err) =&amp;gt; {
        if (err.code === &amp;quot;UserNotConfirmedException&amp;quot;) {
        return Promise.reject(&amp;quot;Confirm your email&amp;quot;);
        } else {
        return Promise.reject(err);
        }
    });
console.log(`signIn successfully`);
}, false);

document.getElementById(&amp;quot;whoAmI&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    console.log(auth.currentUser());
}, false);

document.getElementById(&amp;quot;requestAPI&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    console.log(await auth.requestAPIWithToken());
}, false);

document.getElementById(&amp;quot;signOut&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    auth.signOut();
    console.log(&amp;quot;signout successfully&amp;quot;);
}, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;api側&#34;&gt;API側&lt;/h2&gt;

&lt;p&gt;Serverless FrameworkでCognitoのJWTを認証に使うには
authorizerのarnにUserPoolのARNを入れる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat serverless.yml
service: cognitoapi

provider:
  name: aws
  runtime: nodejs6.10

functions:
  createTodo:
    handler: handler.secret
    events:
      - http:
          path: secret
          cors: true
          method: get
          authorizer:
            arn: ***** # UserPool&#39;s ARN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JWTのpayloadをdecodeして返してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat handler.js
&#39;use strict&#39;;

module.exports.secret = (event, context, callback) =&amp;gt; {
  const payload = JSON.parse(
    new Buffer(
      event.headers.Authorization.split(&amp;quot;.&amp;quot;)[1], 
      &amp;quot;base64&amp;quot;
    ).toString()
  );
  const response = {
    statusCode: 200,
    body: JSON.stringify({
      userInfo: payload
    }),
    headers: {
      &amp;quot;Access-Control-Allow-Origin&amp;quot;: &amp;quot;*&amp;quot;
    },
  };
  callback(null, response);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。Sign Upしたときにコード付きのメールが送られている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/157.gif&#34; alt=&#34;動作&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ブラウザのwindow間の値渡し</title>
          <link>https://www.sambaiz.net/article/156/</link>
          <pubDate>Fri, 23 Feb 2018 02:01:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/156/</guid>
          <description>

&lt;h2 id=&#34;直接windowを参照する&#34;&gt;直接Windowを参照する&lt;/h2&gt;

&lt;p&gt;オリジン(プロトコル+ポート+ホスト)が同じ場合は、親は&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/window.open&#34;&gt;open()&lt;/a&gt;した返り値で、子はwindow.openerで相手のwindowが取れて、直接参照したりDOMを操作したりすることもできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/194/&#34;&gt;同じ/異なるオリジンのiframeの中からできること - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Open window&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;btn2&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
  let win2;
  const button = document.getElementById(&amp;quot;btn&amp;quot;);
  button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    window.foo = &amp;quot;bar from window1&amp;quot;;
    win2 = window.open(&amp;quot;index2.html&amp;quot;);
  }, false);

  const button2 = document.getElementById(&amp;quot;btn2&amp;quot;);
  button2.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    if (win2) {
      win2.close();
    }
  }, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index2.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
  console.log(window.aaa);
  const parentWindow = window.opener;
  const view = document.getElementById(&amp;quot;view&amp;quot;);
  view.textContent = parentWindow.foo; // window1 -&amp;gt; window2

  const button = document.getElementById(&amp;quot;btn&amp;quot;);
  button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    if(!parentWindow) {
      window.close();
    }
    const view = parentWindow.document.getElementById(&amp;quot;view&amp;quot;);
    if (view) {
      view.textContent = &amp;quot;Window2 has been closed by myself&amp;quot;; // window2 -&amp;gt; window1
    }
    window.close();
  }, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認する際は&lt;a href=&#34;https://github.com/cloudhead/node-static&#34;&gt;node-static&lt;/a&gt;などでサーバーを立てる必要がある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-1.gif&#34; alt=&#34;直接Windowを参照する値渡し&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;postmessage-https-developer-mozilla-org-ja-docs-web-api-window-postmessage-を使う&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Window/postMessage&#34;&gt;postMessage()&lt;/a&gt;を使う&lt;/h2&gt;

&lt;p&gt;postMessageで送り、messageのeventで受け取れる。オリジンが異なっていてもよいが、
どこからでも送れてしまうので、ハンドリングする際は&lt;code&gt;event.origin&lt;/code&gt;が意図したものかチェックしなくてはならない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Open window&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;btn2&amp;quot;&amp;gt;Post to window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
const view = document.getElementById(&amp;quot;view&amp;quot;);
const receiveMessage = (event) =&amp;gt; {
  if (event.origin === &amp;quot;http://localhost:8081&amp;quot;) {
    view.textContent = event.data;
  }
}
window.addEventListener(&amp;quot;message&amp;quot;, receiveMessage, false);

let win2;
const button = document.getElementById(&amp;quot;btn&amp;quot;);
button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
  win2 = window.open(&amp;quot;http://localhost:8081/index2.html&amp;quot;);
}, false);

const button2 = document.getElementById(&amp;quot;btn2&amp;quot;);
button2.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
  win2.postMessage(&amp;quot;bar from window1&amp;quot;, &amp;quot;http://localhost:8081&amp;quot;);
}, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index2.html
&amp;lt;script&amp;gt;
const receiveMessage = (event) =&amp;gt; {
  if (event.origin === &amp;quot;http://localhost:8080&amp;quot;) {
    event.source.postMessage(
      `window2 received data: ${event.data}`,
      event.origin
    );
  }
  window.close();
}
window.addEventListener(&amp;quot;message&amp;quot;, receiveMessage, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;別のポートでも値が渡されていることが確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-2.gif&#34; alt=&#34;postMessage()での値渡し&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;reactでpostmessageする&#34;&gt;ReactでpostMessageする&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;componentDidMount()&lt;/code&gt;でaddEventListenerして&lt;code&gt;componentWillUnmount()&lt;/code&gt;でremoveする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.jsx
class App extends React.Component {
  constructor(props) {
    super(props);
    this.state = {value: &#39;&#39;};
    this.handleChange = this.handleChange.bind(this);
    this.handleMessage = this.handleMessage.bind(this);
    this.openWindow = this.openWindow.bind(this);
  }
  componentDidMount() {
    window.addEventListener(&#39;message&#39;, this.handleMessage);
  }
  componentWillUnmount() {
    window.removeEventListener(&#39;message&#39;, this.handleMessage);
  }
  handleMessage(event) {
    if (
      (window.opener &amp;amp;&amp;amp; event.origin === &amp;quot;http://localhost:8080&amp;quot;) ||
      (!window.opener &amp;amp;&amp;amp; event.origin === &amp;quot;http://localhost:8081&amp;quot;)
    ) {
      this.setState({value: event.data});
    }
  }
  handleChange(event) {
    this.setState({value: event.target.value});
    if (this.newWindow) {
      this.newWindow.postMessage(this.state.value, &amp;quot;http://localhost:8081&amp;quot;); // window1 -&amp;gt; window2
    } else if (window.opener) {
      window.opener.postMessage(this.state.value, &amp;quot;http://localhost:8080&amp;quot;); // window2 -&amp;gt; window1
    }
  }
  openWindow(event) {
    this.newWindow = window.open(&#39;http://localhost:8081/index.html&#39;, &#39;_blank&#39;, &#39;width=640, height=480&#39;);
  }
  render() {
    return &amp;lt;div&amp;gt;
      { !window.opener ? &amp;lt;button onClick={this.openWindow}&amp;gt;Open Window&amp;lt;/button&amp;gt; : &amp;lt;div&amp;gt;&amp;lt;/div&amp;gt;}
      &amp;lt;input type=&amp;quot;text&amp;quot; value={this.state.value} onChange={this.handleChange} /&amp;gt;
    &amp;lt;/div&amp;gt;;
  }
}

ReactDOM.render(
  &amp;lt;App /&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;dic id=&amp;quot;root&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script src=&amp;quot;https://unpkg.com/react@16/umd/react.production.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;https://unpkg.com/react-dom@16/umd/react-dom.production.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev @babel/cli @babel/core @babel/preset-react
$ echo &#39;{ &amp;quot;presets&amp;quot;: [&amp;quot;@babel/preset-react&amp;quot;] }&#39; &amp;gt; .babelrc
$ ./node_modules/.bin/babel index.jsx -o index.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-3.gif&#34; alt=&#34;ReactでpostMessage()での値渡し&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Serverless FrameworkでLambdaをデプロイする</title>
          <link>https://www.sambaiz.net/article/155/</link>
          <pubDate>Sun, 11 Feb 2018 23:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/155/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless&#34;&gt;Serverless Framework&lt;/a&gt;でLambda Functionをデプロイする。
Apexが基本的にFunction自体のデプロイしかしないのに対して、こちらはeventの設定なども諸々やってくれて強い。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/140/&#34;&gt;ApexでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g serverless
$ serverless version
1.26.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ApexではFunctionごとにディレクトリが作られたが、Serverlessでは&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/services/#services&#34;&gt;Service&lt;/a&gt;ごとに作られ、
一つのService内で複数のFunctionを定義できる。handlerは同じでも異なっていてもよい。&lt;/p&gt;

&lt;p&gt;Apexの形式の場合、共通の処理をWebpackなどで各Functionに持って来たり、
同じような処理の複数のFunctionを立てる際はコピーする必要があったが、
こちらは必要最小限の変更でそれらを行うことができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless/tree/master/lib/plugins/create/templates&#34;&gt;template&lt;/a&gt;からServiceをcreateする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ serverless create --template aws-nodejs --path testservice
$ ls testservice/
handler.js	serverless.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定ファイル&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/serverless.yml/#serverlessyml-reference&#34;&gt;serverless.yml&lt;/a&gt;
にはLambdaの基本的なもののほかに、VPCやevent、IAM Roleなども書けて、これらはdeploy時に作られるCloudFormationのstackによって管理される。必要なら生のCloudFormationの設定も書ける。&lt;/p&gt;

&lt;p&gt;ApexでもTerraformによって管理することができるが、書くのはこちらの方がはるかに楽。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/144/&#34;&gt;ApexでデプロイしたLambdaのトリガーをTerraformで管理する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat sesrverless.yml
service: testservice

provider:
  name: aws
  profile: foobar
  region: ap-northeast-1
  runtime: nodejs6.10
  memorySize: 512
  timeout: 10
 
functions: 
  hello: 
    handler: handler.hello 
    events:
      - http:
          path: hello/world
          method: get
          cors: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;deployすると&lt;code&gt;{service}-{stage}-{function}&lt;/code&gt;のFunctionが作られる。
今回の場合はtestservice-prd-test。stageをymlでも指定しなかった場合はデフォルト値のdevになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ serverless deploy --stage prd
$ curl https://*****.ap-northeast-1.amazonaws.com/prd/hello/world | jq
{
  &amp;quot;message&amp;quot;: &amp;quot;Go Serverless v1.0! Your function executed successfully!&amp;quot;,
  &amp;quot;input&amp;quot;: {
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;hook&#34;&gt;hook&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless#v1-plugins&#34;&gt;Plugin&lt;/a&gt;で&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/plugins/#lifecycle-events&#34;&gt;Lifecycle Events&lt;/a&gt;を拾えるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppeteer-lambda-starter-kit&lt;/a&gt;は以前からpackage scriptsがあったので、これをServerlessのpackage時に呼ぶことでServerless Framework対応した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev serverless-hooks-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;plugins:
  - serverless-hooks-plugin

custom:
  hooks:
    package:initialize:
      - npm run build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とても便利なのでCloudFormationを使いたくないというわけでなければ、Serverless Frameworkを使っておけばよいと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
          <link>https://www.sambaiz.net/article/154/</link>
          <pubDate>Sun, 11 Feb 2018 19:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/154/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/146/&#34;&gt;TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。
全体のコードは&lt;a href=&#34;https://github.com/sambaiz/my_jupyter_notebook/blob/master/rnn-continuous.ipynb&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;入力&#34;&gt;入力&lt;/h3&gt;

&lt;p&gt;以下の関数によって生成した1次元のデータ列。
これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def make_time_series_data(size):
  data = []
  for i in range(size):
    data.append(sin(random.normalvariate(i,0.1)*0.1))
  return np.reshape(np.array(data, dtype=np.float32), (size,1))

def make_batch(data, batch_size, num_steps, num_dimensions, name=None):
  epoch_size =  data.size // (batch_size*num_steps*num_dimensions)
  data = np.lib.stride_tricks.as_strided(
    data, 
    shape=
      (epoch_size,
        batch_size, 
       num_steps+1,
       num_dimensions),
    strides=(
        4*batch_size*num_steps*num_dimensions, 
        4*num_steps*num_dimensions, 
        4*num_dimensions, 
        4 # bytes
    ), 
    writeable=False
  )
  
  return data[:, :, :-1], data[:, :, 1:]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;モデル&#34;&gt;モデル&lt;/h3&gt;

&lt;p&gt;input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。
lossはMSE(Mean squared error)。Optimizerは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer&#34;&gt;GradientDecentOptimizer&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;チュートリアルでは自力で各time_stepの値を&lt;a href=&#34;https://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/rnn/ptb/ptb_word_lm.py#L141&#34;&gt;入れていた&lt;/a&gt;けど、
今回は&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn&#34;&gt;dynamic_rnn()&lt;/a&gt;に任せている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Model(object):
  def __init__(self, config, is_training=False):
    # config
    self.batch_size = config.batch_size
    self.num_steps = config.num_steps
    self.num_dimensions = config.num_dimensions
    self.keep_prob = config.keep_prob
    self.hidden_size = config.hidden_size
    self.num_layers = config.num_layers
    
    # placeholder
    self.input = tf.placeholder(tf.float32, [None, self.num_steps, self.num_dimensions], name=&amp;quot;input&amp;quot;)
    self.input_strided = tf.placeholder(tf.float32, [self.batch_size, self.num_steps, self.num_dimensions], name=&amp;quot;input_strided&amp;quot;)
    self.lr = tf.placeholder(tf.float32, name=&amp;quot;learning_rate&amp;quot;)
    
    # input layer
    input = tf.reshape(self.input, [-1, self.num_dimensions])
    input_w = tf.get_variable(&amp;quot;input_w&amp;quot;, [self.num_dimensions, self.hidden_size], dtype=tf.float32)
    input_b = tf.get_variable(&amp;quot;input_b&amp;quot;, [self.hidden_size], dtype=tf.float32)
    input = tf.nn.xw_plus_b(input, input_w, input_b)
    input = tf.reshape(input, [self.batch_size, self.num_steps, self.hidden_size])
    
    # LSTM layer
    output, state = self._build_rnn_graph(input, is_training)
    
    # output layer
    output = tf.reshape(output, [-1, self.hidden_size])
    output_w = tf.get_variable(&amp;quot;output_w&amp;quot;, [self.hidden_size, 1], dtype=tf.float32)
    output_b = tf.get_variable(&amp;quot;output_b&amp;quot;, [1], dtype=tf.float32)
    output = tf.nn.xw_plus_b(output, output_w, output_b)
    self.output = tf.reshape(output, [self.batch_size, self.num_steps, 1])
    
    self.cost = tf.reduce_mean(tf.square(self.output[:, -1, :] - self.input_strided[:, -1, :]))
    self.train_op = tf.train.GradientDescentOptimizer(self.lr).minimize(self.cost, global_step=tf.train.get_or_create_global_step())

  def _build_rnn_graph(self, input, is_training):
    def make_cell():
      cell = tf.contrib.rnn.LSTMBlockCell(
        self.hidden_size, forget_bias=0.0)
      if is_training and self.keep_prob &amp;lt; 1:
        cell = tf.contrib.rnn.DropoutWrapper(
          cell, output_keep_prob=self.keep_prob)
      return cell

    cell = tf.contrib.rnn.MultiRNNCell(
      [make_cell() for _ in range(self.num_layers)], state_is_tuple=True)
    initial_state = cell.zero_state(self.batch_size, tf.float32)
    output, state = tf.nn.dynamic_rnn(cell, input, initial_state=initial_state)
    return output, state

  def learn(self, session, input, input_strided, learning_rate):
    fetches = {
      &amp;quot;cost&amp;quot;: self.cost,
      &amp;quot;train_op&amp;quot;: self.train_op
    }
    feed_dict = {
      self.input: input,
      self.input_strided: input_strided,
      self.lr: learning_rate
    }
    vals = session.run(fetches, feed_dict=feed_dict)
    cost = vals[&amp;quot;cost&amp;quot;]
    return cost

  def predict(self, session, input):
    feed_dict = {
      self.input: np.reshape(input, (1, input.shape[0], input.shape[1]))
    }
    return session.run(self.output, feed_dict=feed_dict)[0,-1]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ハイパーパラメータ&#34;&gt;ハイパーパラメータ&lt;/h3&gt;

&lt;p&gt;調整が難しい。&lt;code&gt;max_epoch&lt;/code&gt;は学習率の初期値(&lt;code&gt;learning_rate&lt;/code&gt;)で学習し続けるepochの数なわけなんだけど、
これを大きくして一気にlossを減らしていこうとしたら案外簡単に収束しなくなってしまった。
&lt;code&gt;num_steps&lt;/code&gt;、つまり予測するのに見る数は今回のデータの場合そんなに大きくある必要はなくて、
むしろ大きくすると平たいグラフになって最大値や最小値との誤差が大きくなった。
&lt;code&gt;hidden_size&lt;/code&gt;や&lt;code&gt;num_layers&lt;/code&gt;は増やしても良さそうだけどメモリが足りなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Config(object):
  init_scale = 0.1
  learning_rate = 1.0
  num_layers = 2
  num_steps = 5
  hidden_size = 200
  max_epoch = 3
  batch_size = 3000
  num_dimensions = 1
  keep_prob = 1.0
  lr_decay = 0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;学習結果&#34;&gt;学習結果&lt;/h3&gt;

&lt;p&gt;300000個のデータから学習して予測させたところ
予測値は実際の値と比べて振幅が少なくなってしまった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/154.png&#34; alt=&#34;実際のデータと予測結果のグラフ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>xorm reverseでDBスキーマからGoのstructを生成する</title>
          <link>https://www.sambaiz.net/article/153/</link>
          <pubDate>Sat, 10 Feb 2018 15:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/153/</guid>
          <description>&lt;p&gt;GoのORMの&lt;a href=&#34;https://github.com/go-xorm/xorm&#34;&gt;xorm&lt;/a&gt;にはxorm reverseというDBのスキーマから以下のようなテンプレートに沿ったGoのstructなどを生成する&lt;a href=&#34;https://github.com/go-xorm/cmd&#34;&gt;ツール&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package {{.Model}}

import (
	{{range .Imports}}&amp;quot;{{.}}&amp;quot;{{end}}
)

{{range .Tables}}
type {{Mapper .Name}} struct {
{{$table := .}}
{{range .Columns}}	{{Mapper .Name}}	{{Type .}}
{{end}}
}

{{end}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リポジトリにある&lt;a href=&#34;https://github.com/go-xorm/cmd/tree/master/xorm/templates&#34;&gt;テンプレート&lt;/a&gt;にxorm用テンプレートとgo用のテンプレートが用意されているように、単体で使うこともできる。
また、テンプレートを書く言語としてもGo以外にC++もサポートしている。&lt;/p&gt;

&lt;p&gt;xormのcmdとドライバをインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/go-xorm/cmd/xorm
$ go get github.com/go-sql-driver/mysql
$ xorm
Version:

    0.2.0524
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;様々な型のカラムを含むテーブルで試す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat schema.sql
CREATE TABLE table1 (
  n_tinyint TINYINT,
  n_int INT,
  n_int_unsigned INT UNSIGNED NOT NULL DEFAULT 1,
  n_bigint BIGINT,
  n_float FLOAT,
  n_double DOUBLE,
  d_date DATE,
  d_datetime DATETIME,
  s_char CHAR(64),
  s_varchar VARCHAR(64),
  s_text TEXT,
  s_json JSON,
  b_binary BLOB,
  e_enum ENUM(&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;)
)

$ cat setup.sh
docker run --name mysql-xorm -p 33306:3306 -e &amp;quot;MYSQL_ALLOW_EMPTY_PASSWORD=yes&amp;quot; -e &amp;quot;MYSQL_DATABASE=testdb&amp;quot; 
while [ $(docker inspect --format &amp;quot;{{.State.Health.Status }}&amp;quot; mysql-xorm) != &amp;quot;healthy&amp;quot; ]; do printf &amp;quot;.&amp;quot;; sleep 1; done
mysql -u root -h 0.0.0.0 -P 33306 -D testdb &amp;lt; schema.sql

$ sh setup.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Goのテンプレートをリポジトリから持ってきてxorm reverseを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls xorm-template
config		struct.go.tpl

$ xorm reverse mysql &amp;quot;root:@tcp(0.0.0.0:33306)/testdb&amp;quot; xorm-template
$ cat model/table1.go 
package model

import (
	&amp;quot;time&amp;quot;
)

type Table1 struct {
	NTinyint     int
	NInt         int
	NIntUnsigned int
	NBigint      int64
	NFloat       float32
	NDouble      float64
	DDate        time.Time
	DDatetime    time.Time
	SChar        string
	SVarchar     string
	SText        string
	SJson        string
	BBinary      []byte
	EEnum        string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;概ねうまくいっているが、現状unsignedは無視されてしまう。
これを修正するには依存しているcoreや&lt;a href=&#34;https://github.com/go-xorm/xorm/blob/430fbe866a716bac8e5307d0c5222346f37cf8cf/engine.go#L340&#34;&gt;xorm本体&lt;/a&gt;に手を入れる必要がありそうだ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DatadogのLambda Integrationで気象データを送ってアラートを飛ばす</title>
          <link>https://www.sambaiz.net/article/152/</link>
          <pubDate>Mon, 05 Feb 2018 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/152/</guid>
          <description>&lt;p&gt;最近朝が寒くて布団から出るのがつらい。雨や雪が降っていたら尚更のこと、それならそれで現状を把握する必要がある。
そこで、無料から使える気象API &lt;a href=&#34;http://openweathermap.org/&#34;&gt;OpenWeatherMap&lt;/a&gt;のデータをdatadogに送って、特に寒い日や雨雪が降るような朝にはアラートを飛ばすことにした。&lt;/p&gt;

&lt;p&gt;インスタンスが立っていたらDataDog Agentの&lt;a href=&#34;https://docs.datadoghq.com/ja/guides/dogstatsd/&#34;&gt;DogStatsD&lt;/a&gt;経由で送ることができ、
そうでなければ通常は&lt;a href=&#34;https://docs.datadoghq.com/ja/api/#metrics-post&#34;&gt;API&lt;/a&gt;を呼ぶことになるんだけど、Lambdaでは、AWS Integrationを設定すると有効になる&lt;a href=&#34;https://docs.datadoghq.com/ja/integrations/awslambda/&#34;&gt;Lambda Integration&lt;/a&gt;によって
&lt;code&gt;MONITORING|unix_epoch_timestamp|value|metric_type|my.metric.name|#tag1:value,tag2&lt;/code&gt;のフォーマットでconsole.logするだけでメトリクスが送られるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const axios = require(&#39;axios&#39;);

const CITY = &#39;Shibuya&#39;;
const API_KEY = &#39;*****&#39;;
const WEATHER_API = `http://api.openweathermap.org/data/2.5/weather?q=${CITY}&amp;amp;units=metric&amp;amp;appid=${API_KEY}`;

const METRIC_COUNTER = &#39;counter&#39;;
const METRIC_GAUGE = &#39;gauge&#39;;

const monitor = (metricName, metricType, value, tags) =&amp;gt; {
  const unixEpochTimestamp = Math.floor(new Date().getTime());
  console.log(`MONITORING|${unixEpochTimestamp}|${value}|${metricType}|${metricName}|#${tags.join(&#39;,&#39;)}`);
};

exports.handler = async (event, context, callback) =&amp;gt; {
  const data = (await axios.get(WEATHER_API)).data
  const namePrefix = &#39;livinginfo.weather&#39;
  monitor(`${namePrefix}.temperature`, METRIC_GAUGE, data.main.temp, [])
  monitor(`${namePrefix}.rain`, METRIC_GAUGE, data.rain ? data.rain[&amp;quot;3h&amp;quot;] : 0, []);
  monitor(`${namePrefix}.snow`, METRIC_GAUGE, data.snow ? data.snow[&amp;quot;3h&amp;quot;] : 0, []);
  callback(null, &#39;done&#39;);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;送られた。
あとは0度を下回ったときのThreshold Alertや、前日比で下がったときのChange Alertなどを設定すれば良さそうだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/152.png&#34; alt=&#34;グラフ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ローカルでビルドしたimageをminikubeで使う</title>
          <link>https://www.sambaiz.net/article/151/</link>
          <pubDate>Thu, 01 Feb 2018 22:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/151/</guid>
          <description>&lt;pre&gt;&lt;code&gt;$ minikube version
minikube version: v0.25.0

$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;9&amp;quot;, GitVersion:&amp;quot;v1.9.2&amp;quot;, GitCommit:&amp;quot;5fa2db2bd46ac79e5e00a4e6ed24191080aa463b&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2018-01-18T21:11:08Z&amp;quot;, GoVersion:&amp;quot;go1.9.2&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;}

$ kubectl config current-context
minikube

$ minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;dockerコマンドがminikube VM内で動いているdocker daemonを参照するようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ minikube docker-env
export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
export DOCKER_HOST=&amp;quot;tcp://192.168.99.100:2376&amp;quot;
export DOCKER_CERT_PATH=&amp;quot;/Users/sambaiz/.minikube/certs&amp;quot;

$ eval $(minikube docker-env)
$ docker info --format &#39;{{json .Name}}&#39;
&amp;quot;minikube&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドするDockerfile。nginxが立ち上がるだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;何もタグを付けない(:latest)とcreate時にDockerレジストリからpullしにいって失敗してしまうため、タグ付きでビルドする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t my/myapp:1.0 .
$ docker images my/myapp
my/myapp   1.0   3f8a4339aadd   5 weeks ago   108 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;deploymentとservice。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: my/myapp:1.0
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
 name: my-app
 labels:
   app: my-app
spec:
 type: NodePort
 ports:
 - port: 80
   nodePort: 30001
 selector:
   app: my-app
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f deployment.yml 
$ kubectl create -f service.yml 
$ kubectl get pods
NAME                      READY     STATUS    RESTARTS   AGE
my-app-5f8c46bf95-xjvrg   1/1       Running   0          11s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドしたimageでpodが動いていることを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl $(minikube service my-app --url)
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
...
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Chromeで任意のscriptを読み込まれる前に差し替える</title>
          <link>https://www.sambaiz.net/article/150/</link>
          <pubDate>Thu, 01 Feb 2018 21:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/150/</guid>
          <description>&lt;p&gt;ChromeのDevToolsではSourcesからscriptを書き換えられるようになっているが、
一行目にbreakpointを挟んで更新するとそこで止まるので読み込まれる前に差し替えることができる。
ページの読み込み時に呼ばれるSDKやライブラリの影響範囲を調べたりデバッグしたりするのに便利。&lt;/p&gt;

&lt;p&gt;確認用jsとhtml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;console.log(&amp;quot;original&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&amp;quot;index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;読み込み時に実行されるconsole.logの文章を変えた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/150.gif&#34; alt=&#34;差し替えているところ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す</title>
          <link>https://www.sambaiz.net/article/149/</link>
          <pubDate>Fri, 19 Jan 2018 09:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/149/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/pressly/goose&#34;&gt;Goose&lt;/a&gt;はGo製のDB Migrationツール。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/149.gif&#34; alt=&#34;mergeされるとボタンが出る&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/mysql-migration-slack&#34;&gt;コード&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;こんなリポジトリを作成し、各自ブランチを切ってGoose形式のup/downのSQLを書き、終わったらPullRequestを出す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;goose/
  .keep
.circleci/config.yml
create_test_table.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat create_test_table.sql
-- +goose Up
-- SQL in this section is executed when the migration is applied.
CREATE TABLE testtable (
  id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT,
  n INT NOT NULL,
  c VARCHAR (20) NOT NULL UNIQUE
);

-- +goose Down
-- SQL in this section is executed when the migration is rolled back.
DROP TABLE testtable;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事Approveされ、mergeされるとCircleCIが走り、
SQLをgooseディレクトリの中にバージョンを付けて移し、
SlackにpostMessageするエンドポイントにリクエストを飛ばす。&lt;/p&gt;

&lt;p&gt;ここでバージョンを作成することによって、並列で作業し、レビューなどの関係で適用順が前後しても修正する必要をなくしている。ただ、pushされる前に複数のブランチを連続でmergeする場合うまく動かないのでそれはなんとかする必要がある。&lt;/p&gt;

&lt;p&gt;CircleCI 2.0ではApprovalボタンが出せるんだけど、
アクセスしにいくのがちょっと面倒なのと、周知も兼ねてSlackに出したかったので使っていない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: 2
jobs:
  build:
    docker:
      - image: circleci/golang:1.8
    branches:
      only:
        - master
    steps:
      - checkout
      - run:
          name: Create new version
          command: |
            if [ -e *.sql ]; then
              VERSION=$(ls -U1 goose | wc -l | xargs expr 1 + | xargs printf %05d)
              FILENAME=$(find . -maxdepth 1 -name &amp;quot;*.sql&amp;quot; | head | xargs basename)
              mv ${FILENAME} goose/${VERSION}_${FILENAME}
              git config --global user.email &amp;quot;circleci@example.com&amp;quot;
              git config --global user.name &amp;quot;CircleCI&amp;quot;
              git add .
              git commit -m &amp;quot;version ${VERSION}&amp;quot;
              git push origin master
              COMMIT=$(git rev-parse HEAD)
              curl -H &amp;quot;Authorization: Basic $(echo -n &#39;foobar:dolphins&#39; | base64)&amp;quot; &amp;quot;https://*****/auth/message?version=${VERSION}&amp;amp;filename=${FILENAME}&amp;amp;commit=${COMMIT}&amp;quot;
            fi
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;goose/
  .keep
  00001_create_test_table.sql
.circleci/config.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Migrationボタンが押されると、まずボタンを消してRunning状態とし、
処理が終わったら結果を上書きするようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/148/&#34;&gt;SlackのInteractive messagesでボタンの入力を受け付ける - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;slackMessages.action(&#39;migrate&#39;, (payload, respond) =&amp;gt; {
  let replacement = payload.original_message; 
  delete replacement.attachments[0].actions; 
  replacement.attachments[0].text = `start migration by ${payload.user.name} at ${moment().format()}`;
  replacement.attachments[0].fields = [
    { 
       &amp;quot;title&amp;quot;: &amp;quot;State&amp;quot;,
       &amp;quot;value&amp;quot;: &amp;quot;Running&amp;quot;,
       &amp;quot;short&amp;quot;: false
    } 
  ]; 

  exec(
    // Attention to command injection
    `rm -rf ${repositoryName} &amp;amp;&amp;amp; git clone git@github.com:${repositoryPath}.git &amp;amp;&amp;amp; cd ${repositoryName}/goose &amp;amp;&amp;amp; goose mysql &amp;quot;${mySQLConf}&amp;quot; up`, 
    (err, stdout, stderr) =&amp;gt; {
      replacement.attachments[0].fields = [
        { 
          &amp;quot;title&amp;quot;: &amp;quot;Result&amp;quot;,
          &amp;quot;value&amp;quot;: (err || stderr) ? `${stderr || err}` : &amp;quot;Success&amp;quot;,
          &amp;quot;short&amp;quot;: false
        }
      ];
      respond(replacement);
    }
  );
  
  return replacement;
});
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SlackのInteractive messagesでボタンの入力を受け付ける</title>
          <link>https://www.sambaiz.net/article/148/</link>
          <pubDate>Tue, 16 Jan 2018 21:59:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/148/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://api.slack.com/interactive-messages&#34;&gt;Interactive messages&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/148.gif&#34; alt=&#34;ボタンを押す&#34; /&gt;&lt;/p&gt;

&lt;p&gt;まずはサーバーを用意する。コードは&lt;a href=&#34;https://github.com/sambaiz/node-slack-interactive-messages-sample&#34;&gt;ここ&lt;/a&gt;にあって、
Interactive messagesのハンドリングはSlack公式の&lt;a href=&#34;https://github.com/slackapi/node-slack-interactive-messages&#34;&gt;node-slack-interactive-messages&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.use(&#39;/slack&#39;, slackMessages.expressMiddleware());

slackMessages.action(&#39;question_button&#39;, (payload) =&amp;gt; {
  let replacement = payload.original_message;
  replacement.text =`${payload.user.name} likes ${payload.actions[0].value}`;
  delete replacement.attachments[0].actions;
  return replacement;
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ボタンの表示はattachmentsを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;web.chat.postMessage(channelId, &#39;Question&#39;, {
  attachments: [
    {
      text: &amp;quot;Which buttons do you like?&amp;quot;,
      color: &amp;quot;#f9a41b&amp;quot;,
      callback_id: &amp;quot;question_button&amp;quot;,
      actions: [
        {
          name: &amp;quot;primary_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          style: &amp;quot;primary&amp;quot;,
          text: &amp;quot;Primary&amp;quot;,
          value: &amp;quot;Primary Button&amp;quot;,
        },
        {
          name: &amp;quot;normal_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          text: &amp;quot;Normal&amp;quot;,
          value: &amp;quot;Normal Button&amp;quot;
        },
        {
          name: &amp;quot;danger_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          style: &amp;quot;danger&amp;quot;,
          text: &amp;quot;Danger&amp;quot;,
          value: &amp;quot;Danger Button&amp;quot;,
          confirm: {
            title: &amp;quot;Really?&amp;quot;,
            text: &amp;quot;This is danger&amp;quot;,
            ok_text: &amp;quot;Yes&amp;quot;,
            dismiss_text: &amp;quot;No&amp;quot;
          }
        },
      ]
    }
  ]
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;外に公開する必要があるので、メッセージの送信のエンドポイントはBasic認証をかけてみた。
Interactive messagesのエンドポイントはVerification tokenが一致することを確認している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.use(bodyParser.urlencoded({ extended: false }));
app.all(&#39;/auth/*&#39;, (req, res, next) =&amp;gt; {
  const credentials = auth(req);
  if (!credentials || !check(credentials.name, credentials.pass)) {
    res.status(401).send(&#39;Unauthorized&#39;);
  } else {
    next();
  }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://*****.ngrok.com/auth/message -H &amp;quot;Authorization: Basic $(echo -n &#39;foobar:dolphins&#39; | base64)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://api.slack.com/apps&#34;&gt;Build&lt;/a&gt;からWorkspaceを選択してAppを作成し、
Appに紐づくBot Userを追加後、Install Appすると&lt;code&gt;Bot User OAuth Access Token&lt;/code&gt;
が表示されるので、これで&lt;a href=&#34;https://api.slack.com/methods/chat.postMessage&#34;&gt;postMessage&lt;/a&gt;し、Basic InformationのApp Credentialsにある&lt;code&gt;Verification Token&lt;/code&gt;をInteractive messagesのチェックに使う。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://tech.mercari.com/entry/2017/05/23/095500&#34;&gt;GolangでSlack Interactive Messageを使ったBotを書く - Mercari Engineering Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorBoardでsummaryやグラフを見る</title>
          <link>https://www.sambaiz.net/article/147/</link>
          <pubDate>Sun, 07 Jan 2018 21:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/147/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/146/&#34;&gt;TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;で読んだコードをTensorboardでみてみる。&lt;/p&gt;

&lt;p&gt;8888がJupyter、6006がTensorboard。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コードをuploadするかJupyterからterminalを開いてcloneしてくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# apt-get update
# apt-get install -y git wget
# git clone https://github.com/tensorflow/models.git
# cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logdirを指定して実行し、Tensorboardを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;flags.DEFINE_string(&amp;quot;save_path&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;Model output directory.&amp;quot;)
sv = tf.train.Supervisor(logdir=FLAGS.save_path)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;追記(2018-11-14): Supervisorはdeprecatedなので以下の記事でやっているようにMonitoredTrainingSessionを使うとよい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/198/&#34;&gt;Deep LearningのBatch Normalizationの効果をTensorFlowで確認する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;# tensorboard --logdir=models/tutorials/rnn/ptb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)&lt;/code&gt;による値がリアルタイムに表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard.png&#34; alt=&#34;summaryの推移&#34; /&gt;&lt;/p&gt;

&lt;p&gt;グラフのつながりや、各Operationの入出力やそのshapeを確認できる。
name_scopeで分けておくと見やすい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard3.png&#34; alt=&#34;グラフ全体&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard2.png&#34; alt=&#34;Operationの入出力&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
          <link>https://www.sambaiz.net/article/146/</link>
          <pubDate>Wed, 03 Jan 2018 21:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/146/</guid>
          <description>

&lt;p&gt;TensorflowのRNN(Recurrent Neural Networks)の&lt;a href=&#34;https://www.tensorflow.org/tutorials/recurrent&#34;&gt;チュートリアル&lt;/a&gt;の&lt;a href=&#34;https://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/rnn/ptb/ptb_word_lm.py&#34;&gt;コード&lt;/a&gt;を読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。&lt;/p&gt;

&lt;h2 id=&#34;rnn-lstmとは&#34;&gt;RNN/LSTMとは&lt;/h2&gt;

&lt;p&gt;RNNは入力に対して出力のほかに情報を次のステップに渡すことで時系列データで学習できるようにするネットワーク。
展開すると同じネットワークに単語を一つずつ入れていくように表現できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/146-rnn.png&#34; alt=&#34;RNN&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これを単純にMLPで実装しようとすると逆誤差伝搬する際に過去の層にも伝搬させる(BPTT: Backpropagation through time)必要があり、
時間を遡るほど活性化関数の微分係数が再帰的に繰り返し掛けられるため勾配が消失や爆発しやすくなってしまう。
また、時系列データのうちに発火したいものと発火したくないものが混在している場合、同じ重みにつながっているため更新を打ち消しあってしまう入力/出力重み衝突という問題もある。&lt;/p&gt;

&lt;p&gt;これらを解決するのがLSTM(Long Short Term Memory networks)で、
勾配消失は活性化関数がxで重みが単位行列のニューロンのCEC(Constant Error Carousel)によって常に誤差に掛けられる係数を1にすることで防ぎ、
入力/出力重み衝突は必要な入出力を通したり不必要な情報は忘れさせるために値域(0,1)の値を掛けるinput gate、forget gate、output gateによって回避する。gateは入力と前回の出力によって制御される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/146-lstm.png&#34; alt=&#34;RNN&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TensorflowではいくつかLSTMの実装が用意されていて、&lt;code&gt;CudnnLSTM&lt;/code&gt;や&lt;code&gt;BasicLSTMCell&lt;/code&gt;、&lt;code&gt;LSTMBlockCell&lt;/code&gt;などがある。
&lt;a href=&#34;https://developer.nvidia.com/cudnn&#34;&gt;cuDNN&lt;/a&gt;というのはNVIDIAのCUDAのDNNライブラリのこと。
&lt;code&gt;LSTMBlockCell&lt;/code&gt;はもう少し複雑なLSTMで&lt;code&gt;BasicLSTMCell&lt;/code&gt;よりも速い。&lt;/p&gt;

&lt;h2 id=&#34;動かしてみる&#34;&gt;動かしてみる&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/tensorflow/models.git
$ cd models/tutorials/rnn/ptb/
$ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz
$ tar xvf simple-examples.tgz 
$ python3 -m venv env
$ . ./env/bin/activate
$ pip install numpy tensorflow
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 5534.452 speed: 894 wps
0.104 perplexity: 845.383 speed: 1277 wps
...
0.803 perplexity: 316.808 speed: 1195 wps
0.903 perplexity: 298.087 speed: 1205 wps
Epoch: 1 Train Perplexity: 283.825
Epoch: 1 Valid Perplexity: 182.132
Epoch: 2 Learning rate: 1.000
...
Epoch: 4 Learning rate: 1.000
...
Epoch: 5 Learning rate: 0.500
...
Epoch: 6 Learning rate: 0.250
...
Epoch: 7 Learning rate: 0.125
...
Epoch: 13 Learning rate: 0.002
...
Test Perplexity: 121.759
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;reader&#34;&gt;reader&lt;/h2&gt;

&lt;p&gt;readerにはテストがあったので、これを使って実際にどんな出力をしているか見てみる。&lt;/p&gt;

&lt;h3 id=&#34;ptb-raw-data&#34;&gt;ptb_raw_data&lt;/h3&gt;

&lt;p&gt;単語をIDに変換したものと語彙数が返る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def setUp(self):
  self._string_data = &amp;quot;\n&amp;quot;.join(
    [&amp;quot; hello there i am&amp;quot;,
     &amp;quot; rain as day&amp;quot;,
     &amp;quot; want some cheesy puffs ?&amp;quot;])

def testPtbRawData(self):
  tmpdir = tf.test.get_temp_dir()
  for suffix in &amp;quot;train&amp;quot;, &amp;quot;valid&amp;quot;, &amp;quot;test&amp;quot;:
    filename = os.path.join(tmpdir, &amp;quot;ptb.%s.txt&amp;quot; % suffix)
    with tf.gfile.GFile(filename, &amp;quot;w&amp;quot;) as fh:
    fh.write(self._string_data)
  # Smoke test
  output = reader.ptb_raw_data(tmpdir)
  print(&#39;output: {0}&#39;.format(output))
  # output: (
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # train
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # valid
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # test
  #   12 # vocabulary
  # )
  self.assertEqual(len(output), 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;print(word_to_id)
=&amp;gt; {&#39;?&#39;: 0, &#39;am&amp;lt;eos&amp;gt;&#39;: 1, &#39;as&#39;: 2, &#39;cheesy&#39;: 3, &#39;day&amp;lt;eos&amp;gt;&#39;: 4, &#39;hello&#39;: 5, &#39;i&#39;: 6, &#39;puffs&#39;: 7, &#39;rain&#39;: 8, &#39;some&#39;: 9, &#39;there&#39;: 10, &#39;want&#39;: 11}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ptb-producer&#34;&gt;ptb_producer&lt;/h3&gt;

&lt;p&gt;session.runする度に時系列順に[batch_size, num_steps]のTensorを出力する。
二つ目の返り値は一つ右にずらしたもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def testPtbProducer(self):
  raw_data = [
  # t=0↓  t=1↓
    4, 3, 2, 1, 0, 
    5, 6, 1, 1, 1, 
    1, 0, 3, 4, 1
  ]
  batch_size = 3
  num_steps = 2
  x, y = reader.ptb_producer(raw_data, batch_size, num_steps)
  with self.test_session() as session:
    coord = tf.train.Coordinator()
    tf.train.start_queue_runners(session, coord=coord)
    try:
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[4, 3], [5, 6], [1, 0]])
      self.assertAllEqual(yval, [[3, 2], [6, 1], [0, 3]])
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[2, 1], [1, 1], [3, 4]])
      self.assertAllEqual(yval, [[1, 0], [1, 1], [4, 1]])
    finally:
      coord.request_stop()
      coord.join()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実装はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()
x = tf.strided_slice(data, [0, i * num_steps],
                        [batch_size, (i + 1) * num_steps])
x.set_shape([batch_size, num_steps])
y = tf.strided_slice(data, [0, i * num_steps + 1],
                        [batch_size, (i + 1) * num_steps + 1])
y.set_shape([batch_size, num_steps])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;range_input_producerはその名の通りrangeのように0から値を生成するが、
Threadを調整する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Coordinator&#34;&gt;Coordinator&lt;/a&gt;を生成し、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/start_queue_runners&#34;&gt;start_queue_runners&lt;/a&gt;に渡す必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# example of range_input_producer
with self.test_session() as session:
  i = tf.train.range_input_producer(100, shuffle=False).dequeue()
  coord = tf.train.Coordinator()
  tf.train.start_queue_runners(session, coord=coord)
  try:
    print(session.run(i)) # =&amp;gt; 0
    print(session.run(i)) # =&amp;gt; 1
    print(session.run(i)) # =&amp;gt; 2
  finally:
    coord.request_stop()
    coord.join() # Wait for all the threads to terminate.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;

&lt;h3 id=&#34;入力の準備&#34;&gt;入力の準備&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup&#34;&gt;embedding_lookup&lt;/a&gt;で
embeddingから各stepの単語のものを抽出する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.device(&amp;quot;/cpu:0&amp;quot;):
  embedding = tf.get_variable(
    &amp;quot;embedding&amp;quot;, [vocab_size, size], dtype=data_type())
  # shape=(batch_size, num_steps, size), dtype=float32
  inputs = tf.nn.embedding_lookup(embedding, input_.input_data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;embedding_lookupの挙動はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# example of embedding_lookup
with tf.Session() as session:
  print(session.run(tf.nn.embedding_lookup(
    [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]],
    [[0,1,2], [3,4,5], [6,7,8]]
  ))) 
  # =&amp;gt; [[ 0  2  4]
  #     [ 6  8 10]
  #     [ 1  3  5]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;学習中の場合、過学習を防ぐためkeep_prob残してDropoutし、RNNのグラフを作り始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if is_training and config.keep_prob &amp;lt; 1:
  inputs = tf.nn.dropout(inputs, config.keep_prob)

output, state = self._build_rnn_graph(inputs, config, is_training)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rnnのグラフ&#34;&gt;RNNのグラフ&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;rnn_mode&lt;/code&gt;で実装を選べるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def _build_rnn_graph(self, inputs, config, is_training):
  if config.rnn_mode == CUDNN:
    return self._build_rnn_graph_cudnn(inputs, config, is_training)
  else:
    return self._build_rnn_graph_lstm(inputs, config, is_training)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cellは&lt;code&gt;LSTMBlockCell&lt;/code&gt;をDroopoutWrapperでラップしたもの。
さらにこれをCellの出力が次のCellの入力になる&lt;code&gt;MultiRNNCell&lt;/code&gt;で&lt;code&gt;num_layers&lt;/code&gt;重ねている。&lt;/p&gt;

&lt;p&gt;最初に&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell#zero_state&#34;&gt;zero_state&lt;/a&gt;の
初期状態から&lt;code&gt;num_steps&lt;/code&gt;まわして各stepでのoutputと最後のstateを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def _get_lstm_cell(self, config, is_training):
  if config.rnn_mode == BASIC:
    return tf.contrib.rnn.BasicLSTMCell(
      config.hidden_size, forget_bias=0.0, state_is_tuple=True,
      reuse=not is_training)
  if config.rnn_mode == BLOCK:
    return tf.contrib.rnn.LSTMBlockCell(
      config.hidden_size, forget_bias=0.0)
  raise ValueError(&amp;quot;rnn_mode %s not supported&amp;quot; % config.rnn_mode)

def _build_rnn_graph_lstm(self, inputs, config, is_training):
  def make_cell():
    cell = self._get_lstm_cell(config, is_training)
    if is_training and config.keep_prob &amp;lt; 1:
      cell = tf.contrib.rnn.DropoutWrapper(
        cell, output_keep_prob=config.keep_prob)
    return cell

  cell = tf.contrib.rnn.MultiRNNCell(
    [make_cell() for _ in range(config.num_layers)], state_is_tuple=True)

  self._initial_state = cell.zero_state(config.batch_size, data_type())
  state = self._initial_state

  # [shape=(batch_size, hidden_size) dtype=float32, ...]
  outputs = []
  with tf.variable_scope(&amp;quot;RNN&amp;quot;):
    for time_step in range(self.num_steps):
      if time_step &amp;gt; 0: tf.get_variable_scope().reuse_variables()
      (cell_output, state) = cell(inputs[:, time_step, :], state)
      outputs.append(cell_output)

  # shape=(batch_size * num_steps, hidden_size), dtype=float32
  output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])
  return output, state
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;コスト&#34;&gt;コスト&lt;/h3&gt;

&lt;p&gt;出力層を通したのをlogits(&lt;code&gt;log(p/(1-p)) (0≦p≦1)&lt;/code&gt;)のシーケンスとして扱い、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss&#34;&gt;sequence_loss&lt;/a&gt;で
それぞれ交差エントロピーを求め、その和をコストとする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;output, state = self._build_rnn_graph(inputs, config, is_training)

softmax_w = tf.get_variable(
    &amp;quot;softmax_w&amp;quot;, [size, vocab_size], dtype=data_type())
softmax_b = tf.get_variable(&amp;quot;softmax_b&amp;quot;, [vocab_size], dtype=data_type())
logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)
# shape=(batch_size, num_steps, vocab_size), dtype=float32
logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])

loss = tf.contrib.seq2seq.sequence_loss(
    # logits: [batch_size, sequence_length=num_steps, num_decoder_symbols=vocab_size] and dtype float
    # The logits correspond to the prediction across all classes at each timestep.
    logits,

    # targets: [batch_size, sequence_length=num_steps] and dtype int
    # The target represents the true class at each timestep.
    input_.targets,

    # weights: [batch_size, sequence_length] and dtype float
    # When using weights as masking, set all valid timesteps to 1 and all padded timesteps to 0
    tf.ones([self.batch_size, self.num_steps], dtype=data_type()),

    average_across_timesteps=False,
    average_across_batch=True)

# Update the cost
self._cost = tf.reduce_sum(loss)
self._final_state = state
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;勾配&#34;&gt;勾配&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/trainable_variables&#34;&gt;trainable_variables&lt;/a&gt;で
&lt;code&gt;trainable=True&lt;/code&gt;(つまり_lr以外)のvariableを取得し、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/gradients&#34;&gt;gradients&lt;/a&gt;で各variableに対しての勾配を求め、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/clip_by_global_norm&#34;&gt;clip_by_global_norm&lt;/a&gt;で大きさを抑える。
これはgradient clippingと呼ばれる勾配爆発を防ぐための手法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if not is_training:
    return

self._lr = tf.Variable(0.0, trainable=False)
tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(self._cost, tvars),
                                    config.max_grad_norm)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# example of trainable_variables
with tf.Session() as session:
  a = tf.Variable(10.0, trainable=False)
  b = tf.Variable(20.0)
  c = tf.get_variable(&amp;quot;c&amp;quot;, [2, 2])
  d = tf.get_variable(&amp;quot;d&amp;quot;, [3, 3], trainable=False)
  session.run(tf.global_variables_initializer())
  print(session.run(tf.trainable_variables()))
  # [20.0, array([[ 1.10110056,  0.6373167 ],
  # [ 0.44673324, -0.11995673]], dtype=float32)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# example of gradients &amp;amp; clip_by_global_norm
with tf.Session() as session:
  xs = tf.Variable([10., 20., 30.])
  ys = [xs ** 2 + 123, xs * 5]
  grad = tf.gradients(ys,xs)
  session.run(tf.global_variables_initializer())
  print(session.run(grad)) # [20 + 5, 40 + 5, 60 + 5]

  list_clipped, global_norm = session.run(tf.clip_by_global_norm(grad,2))
  # global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))
  # = sqrt(25 ** 2 + 45 ** 2 + 65 ** 2)
  print(global_norm) # 82.9156

  # t_list[i] * clip_norm / max(global_norm, clip_norm)
  # = [25, 45, 65] * 2 / global_norm
  print(list_clipped) # [0.60302269, 1.08544087, 1.56785905]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;optimize&#34;&gt;Optimize&lt;/h3&gt;

&lt;p&gt;学習率_lrの&lt;code&gt;GradientDescenetOptimizer&lt;/code&gt;でoptimizeする。
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer#apply_gradients&#34;&gt;apply_gradients&lt;/a&gt;するたびに
global_stepがインクリメントされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;optimizer = tf.train.GradientDescentOptimizer(self._lr)
self._train_op = optimizer.apply_gradients(
  zip(grads, tvars),
  global_step=tf.train.get_or_create_global_step())

self._new_lr = tf.placeholder(
  tf.float32, shape=[], name=&amp;quot;new_learning_rate&amp;quot;)
self._lr_update = tf.assign(self._lr, self._new_lr)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;run-epoch&#34;&gt;run_epoch&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;session.run&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fetches = {
  &amp;quot;cost&amp;quot;: model.cost,
  &amp;quot;final_state&amp;quot;: model.final_state,
}
if eval_op is not None:
  fetches[&amp;quot;eval_op&amp;quot;] = eval_op

for step in range(model.input.epoch_size):
  feed_dict = {}
  for i, (c, h) in enumerate(model.initial_state):
    feed_dict[c] = state[i].c
    feed_dict[h] = state[i].h

  vals = session.run(fetches, feed_dict)
  cost = vals[&amp;quot;cost&amp;quot;]
  state = vals[&amp;quot;final_state&amp;quot;]

  costs += cost
  iters += model.input.num_steps

  if verbose and step % (model.input.epoch_size // 10) == 10:
    print(&amp;quot;%.3f perplexity: %.3f speed: %.0f wps&amp;quot; %
      (step * 1.0 / model.input.epoch_size, np.exp(costs / iters),
       iters * model.input.batch_size * max(1, FLAGS.num_gpus) /
       (time.time() - start_time)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;main&#34;&gt;main&lt;/h3&gt;

&lt;p&gt;起点。学習率はmax_epochまで初期値で、それ以後のepochでは指数的に減少させていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Supervisor&#34;&gt;Supervisor&lt;/a&gt;は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Threadを調整する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Coordinator&#34;&gt;Corrdinator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;variableを保存する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Saver&#34;&gt;Saver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;チェックポイントからセッションを再開する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/SessionManager&#34;&gt;SessionManager&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のラッパー。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;追記(2018-07-01): Supervisorはdeprecatedになったので代わりにMonitoredSessionを使うべき。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/175/&#34;&gt;TensorFlowのMonitoredSession - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
  tf.train.import_meta_graph(metagraph)
  for model in models.values():
    model.import_ops()
  sv = tf.train.Supervisor(logdir=FLAGS.save_path)
  config_proto = tf.ConfigProto(allow_soft_placement=soft_placement)
  with sv.managed_session(config=config_proto) as session:
    for i in range(config.max_max_epoch):
      lr_decay = config.lr_decay ** max(i + 1 - config.max_epoch, 0.0)
      m.assign_lr(session, config.learning_rate * lr_decay)

      print(&amp;quot;Epoch: %d Learning rate: %.3f&amp;quot; % (i + 1, session.run(m.lr)))
      train_perplexity = run_epoch(session, m, eval_op=m.train_op,
                                    verbose=True)
      print(&amp;quot;Epoch: %d Train Perplexity: %.3f&amp;quot; % (i + 1, train_perplexity))
      valid_perplexity = run_epoch(session, mvalid)
      print(&amp;quot;Epoch: %d Valid Perplexity: %.3f&amp;quot; % (i + 1, valid_perplexity))

    test_perplexity = run_epoch(session, mtest)
    print(&amp;quot;Test Perplexity: %.3f&amp;quot; % test_perplexity)

    if FLAGS.save_path:
      print(&amp;quot;Saving model to %s.&amp;quot; % FLAGS.save_path)
      sv.saver.save(session, FLAGS.save_path, global_step=sv.global_step)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/154/&#34;&gt;TensorFlow/RNNで連続的な値を取る時系列データを予測する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3-%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0-TensorFlow%E3%83%BBKeras%E3%81%AB%E3%82%88%E3%82%8B%E6%99%82%E7%B3%BB%E5%88%97%E3%83%87%E3%83%BC%E3%82%BF%E5%87%A6%E7%90%86-%E5%B7%A3%E7%B1%A0-%E6%82%A0%E8%BC%94/dp/4839962510&#34;&gt;詳解 ディープラーニング ~TensorFlow・Kerasによる時系列データ処理~&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&#34;&gt;Understanding LSTM Networks &amp;ndash; colah&amp;rsquo;s blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/t_Signull/items/21b82be280b46f467d1b&#34;&gt;わかるLSTM ～ 最近の動向と共に - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://returnn.readthedocs.io/en/latest/tf_lstm_benchmark.html&#34;&gt;TensorFlow LSTM benchmark — RETURNN 1.0-dev documentation&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
          <link>https://www.sambaiz.net/article/145/</link>
          <pubDate>Sun, 24 Dec 2017 23:31:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/145/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/athena-admin&#34;&gt;https://github.com/sambaiz/athena-admin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/athena/pricing/&#34;&gt;料金&lt;/a&gt;はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。
データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだけど都度locationを指定して&lt;code&gt;ADD PARTITION&lt;/code&gt;を実行するのは大変。さらにスキーマを変更するのにも&lt;code&gt;ALTER TABLE ADD COLUMNS&lt;/code&gt;などはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。&lt;/p&gt;

&lt;p&gt;ではどうしようもないかというと&lt;code&gt;MSCK REPAIR TABLE&lt;/code&gt;というのがあって、
これはS3のObjectの&lt;code&gt;dt=YYYY-MM-DD&lt;/code&gt;のようなkey=valueのprefixを認識してパーティションを作るもの。作り直す際もこれ1クエリで終わる。それなら最初からそういう風に置けばよいのではというところだけど、勝手に&lt;code&gt;YYYY/MM/DD/HH&lt;/code&gt;のprefixを付けてしまうFirehoseのようなのもある。&lt;/p&gt;

&lt;p&gt;今回作った&lt;a href=&#34;https://github.com/sambaiz/athena-admin&#34;&gt;athena-admin&lt;/a&gt;は以下のような定義ファイルから、
パーティションのkey=valueのprefixが付くように置き換えたり、変更があったらmigrationする。
このファイルを書き換えるだけで基本的にどうにかなるし、バージョン管理すればテーブル定義の変更を追うことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;general&amp;quot;: {
    &amp;quot;athenaRegion&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;,
    &amp;quot;databaseName&amp;quot;: &amp;quot;aaaa&amp;quot;,
    &amp;quot;saveDefinitionLocation&amp;quot;: &amp;quot;s3://saveDefinitionBucket/aaaa.json&amp;quot;
  },
  &amp;quot;tables&amp;quot;: {
    &amp;quot;sample_data&amp;quot;: {
      &amp;quot;columns&amp;quot;: {
        &amp;quot;user_id&amp;quot;: &amp;quot;int&amp;quot;,
        &amp;quot;value&amp;quot;: {
          &amp;quot;score&amp;quot;: &amp;quot;int&amp;quot;,
          &amp;quot;category&amp;quot;: &amp;quot;string&amp;quot;
        } /* &amp;quot;struct&amp;lt;score:int,category:string&amp;gt;&amp;quot; のように書くこともできる */
      },
      &amp;quot;srcLocation&amp;quot;: &amp;quot;s3://src/location/&amp;quot;,
      &amp;quot;partition&amp;quot;: {
        &amp;quot;prePartitionLocation&amp;quot;: &amp;quot;s3://pre/partition/&amp;quot;, /* optional */
        &amp;quot;regexp&amp;quot;: &amp;quot;(\\d{4})/(\\d{2})/(\\d{2})/&amp;quot;, /* optional */
        &amp;quot;keys&amp;quot;: [
          {
            &amp;quot;name&amp;quot;: &amp;quot;dt&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,
            &amp;quot;format&amp;quot;: &amp;quot;{1}-{2}-{3}&amp;quot;, /* optional */
          }
        ]
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使い方はこんな感じ。使い方によっては&lt;code&gt;migrate()&lt;/code&gt;だけ呼ぶこともあると思う。
&lt;code&gt;replaceObjects()&lt;/code&gt;にはmatchedHandlerというのを渡すこともできて、
UTCからJSTに変換するといったこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install athena-admin
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const AthenaAdmin = require(&#39;athena-admin&#39;).AthenaAdmin;
const dbDef = require(&#39;./sampledatabase.json&#39;);
const admin = new AthenaAdmin(dbDef);
await admin.replaceObjects();
await admin.migrate();
await admin.partition();
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;追記 (2019-01-01): AWS Glueを使っても同じことができる &lt;a href=&#34;https://www.sambaiz.net/article/203/&#34;&gt;AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ApexでデプロイしたLambdaのトリガーをTerraformで管理する</title>
          <link>https://www.sambaiz.net/article/144/</link>
          <pubDate>Sun, 12 Nov 2017 22:23:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/144/</guid>
          <description>

&lt;p&gt;Apexでfunctionをデプロイするとトリガーが登録されないのであとで追加することになる。
これを手作業で行うこともできるのだけど、せっかくなのでアプリケーションと一緒に管理したい。
そんなときのために&lt;code&gt;terraform&lt;/code&gt;コマンドをラップした&lt;a href=&#34;http://apex.run/#managing-infrastructure&#34;&gt;apex infra&lt;/a&gt;が用意されている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/121/&#34;&gt;TerraformでVPCを管理するmoduleを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;functionsと同列にinfrastructureディレクトリを作成してtfファイルを置く。
その下に環境ごとのディレクトリを作成することもできて、その場合は&lt;code&gt;--env&lt;/code&gt;で指定した環境のものが使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- functions
- infrastructure
  main.tf
  variables.tf
  - modules
    - cloudwatch_schedule
      main.tf
      variables.tf
project.json 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;functionをデプロイするとそのARNが変数で取れるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex list --tfvars
apex_function_hello=&amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回設定するトリガーはCloudwatch Eventのスケジューリング。作成するリソースは以下の通り。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/cloudwatch_event_rule.html&#34;&gt;aws_cloudwatch_event_rule&lt;/a&gt;でイベントルール(今回はschedule)を作成&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/cloudwatch_event_target.html&#34;&gt;aws_cloudwatch_event_target&lt;/a&gt;でルールにターゲット(今回はLambda)を設定&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/lambda_permission.html&#34;&gt;aws_lambda_permission&lt;/a&gt;でルールに対象Lambdaをinvokeする権限を付ける&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ cat infrastructure/modules/cloudwatch_schefule/variables.tf
variable &amp;quot;lambda_function_name&amp;quot; {}
variable &amp;quot;lambda_function_arn&amp;quot; {}
variable &amp;quot;schedule_expression&amp;quot; {
    description = &amp;quot;cloudwatch schedule expression e.g. \&amp;quot;cron(0/5 * * * ? *)\&amp;quot;&amp;quot;
}

$ cat infrastructure/modules/cloudwatch_schefule/main.tf
resource &amp;quot;aws_cloudwatch_event_rule&amp;quot; &amp;quot;lambda&amp;quot; {
  name        = &amp;quot;lambda_rule_${var.lambda_function_name}&amp;quot;
  description = &amp;quot;invoke lambda ${var.lambda_function_name}&amp;quot;
  schedule_expression = &amp;quot;${var.schedule_expression}&amp;quot;
}
 
resource &amp;quot;aws_cloudwatch_event_target&amp;quot; &amp;quot;lambda&amp;quot; {
  target_id = &amp;quot;lambda_target_${var.lambda_function_name}&amp;quot;
  rule      = &amp;quot;${aws_cloudwatch_event_rule.lambda.name}&amp;quot;
  arn       = &amp;quot;${var.lambda_function_arn}&amp;quot;
}
 
resource &amp;quot;aws_lambda_permission&amp;quot; &amp;quot;lambda&amp;quot; {
  statement_id  = &amp;quot;AllowExecutionFromCloudWatch&amp;quot;
  action        = &amp;quot;lambda:InvokeFunction&amp;quot;
  function_name = &amp;quot;${aws_cloudwatch_event_target.lambda.arn}&amp;quot;
  principal     = &amp;quot;events.amazonaws.com&amp;quot;
  source_arn    = &amp;quot;${aws_cloudwatch_event_rule.lambda.arn}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat infrastructure/variables.tf 
variable &amp;quot;apex_function_names&amp;quot; {
    type=&amp;quot;map&amp;quot;
}
variable &amp;quot;apex_function_hello&amp;quot; {}

$ cat infrastructure/main.tf
terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;sambaiz-terraform&amp;quot;
    key    = &amp;quot;usetf.tfstate&amp;quot;
    region = &amp;quot;ap-northeast-1&amp;quot;
  }
}

module &amp;quot;hello_trigger&amp;quot; {
  source = &amp;quot;./modules/cloudwatch_schedule&amp;quot;
  lambda_function_name = &amp;quot;${var.apex_function_names[&amp;quot;hello&amp;quot;]}&amp;quot;
  lambda_function_arn = &amp;quot;${var.apex_function_hello}&amp;quot;
  schedule_expression = &amp;quot;cron(0/5 * * * ? *)&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;init&lt;/code&gt;してbackendを初期化してmoduleを準備する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra init
$ ls infrastructure/.terraform/modules/*****
main.tf		variables.tf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;plan&lt;/code&gt;するとこんな感じ。ApexによってfunctionのARNが渡っていることが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra plan
+ module.hello_trigger.aws_cloudwatch_event_rule.lambda
    arn:                 &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    description:         &amp;quot;invoke lambda usetf_hello&amp;quot;
    is_enabled:          &amp;quot;true&amp;quot;
    name:                &amp;quot;lambda_rule_usetf_hello&amp;quot;
    schedule_expression: &amp;quot;cron(0/5 * * * ? *)&amp;quot;

+ module.hello_trigger.aws_cloudwatch_event_target.lambda
    arn:       &amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
    rule:      &amp;quot;lambda_rule_usetf_hello&amp;quot;
    target_id: &amp;quot;lambda_target_usetf_hello&amp;quot;

+ module.hello_trigger.aws_lambda_permission.lambda
    action:        &amp;quot;lambda:InvokeFunction&amp;quot;
    function_name: &amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
    principal:     &amp;quot;events.amazonaws.com&amp;quot;
    source_arn:    &amp;quot;${aws_cloudwatch_event_rule.lambda.arn}&amp;quot;
    statement_id:  &amp;quot;AllowExecutionFromCloudWatch&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apply&lt;/code&gt;するとトリガーが登録される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra apply
$ apex logs hello
...
/aws/lambda/usetf_hello 2017-11-12T13:20:14.561Z	37e75818-c7ac-11e7-a333-111863808b13	processing event:
...
/aws/lambda/usetf_hello 2017-11-12T13:25:15.182Z	eb178941-c7ac-11e7-bde0-998ea9659640 processing event:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://dev.classmethod.jp/cloud/aws/ami-and-snapshot-delete-with-apex-and-terraform/&#34;&gt;ApexとTerraformでCloudWatch EventsによりInvokeされるLambda関数をデプロイする ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>JavaScriptのrequire/importの歴史</title>
          <link>https://www.sambaiz.net/article/143/</link>
          <pubDate>Sat, 11 Nov 2017 20:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/143/</guid>
          <description>

&lt;h2 id=&#34;scriptタグを並べる&#34;&gt;scriptタグを並べる&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;body&amp;gt;
&amp;lt;script src=&amp;quot;a.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;b.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先に書かれた&lt;code&gt;a.js&lt;/code&gt;で定義された内容は&lt;code&gt;b.js&lt;/code&gt;で読むことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat a.js 
const a = &#39;a is defined&#39;;
const divA = document.createElement(&#39;div&#39;);
divA.textContent = (typeof b !== &#39;undefined&#39;) ? b : &#39;b is undefined&#39;;
document.body.appendChild(divA);

$ cat b.js 
const b = &#39;b is defined&#39;;
const divB = document.createElement(&#39;div&#39;);
divB.textContent = (typeof a !== &#39;undefined&#39;) ? a : &#39;a is undefined&#39;;
document.body.appendChild(divB);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;依存が増えてくると順番を考えるのが大変。さらにグローバルな名前空間を汚染してしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b is undefined
a is defined
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;amdとcommonjs&#34;&gt;AMDとCommonJS&lt;/h2&gt;

&lt;p&gt;というのも、かつてのJSにはモジュールを読み込む仕組みがなかった。
そこで考えられたのがAMDやCommonJSというフォーマット。
AMD(Asynchronous module definition)は&lt;a href=&#34;http://requirejs.org/&#34;&gt;RequireJS&lt;/a&gt;によって提供される&lt;code&gt;require()&lt;/code&gt;で動的にscriptタグを埋める。CommonJSはNodeでもおなじみの&lt;code&gt;require()&lt;/code&gt;で、これにWebpackを通して一つのファイルにまとめておく。同じ関数名が使われているが全くの別物。&lt;/p&gt;

&lt;h2 id=&#34;es-modules&#34;&gt;ES Modules&lt;/h2&gt;

&lt;p&gt;今は言語仕様にECMAScript Modulesが追加され、普通に&lt;code&gt;import&lt;/code&gt;でモジュールを読み込めるようになったが、
対応ブラウザがまだ少ないこともあり基本的にはWebpackをかけることになる。
Nodeにも実装されつつあるがStableになるのは&lt;a href=&#34;https://nodejs.org/api/esm.html&#34;&gt;まだ先&lt;/a&gt;のようだ。&lt;/p&gt;

&lt;h2 id=&#34;requirejs-http-requirejs-org&#34;&gt;&lt;a href=&#34;http://requirejs.org/&#34;&gt;RequireJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;define()&lt;/code&gt;でモジュールを定義し、&lt;code&gt;require()&lt;/code&gt;で読み込む。
エントリーポイントは&lt;code&gt;data-main&lt;/code&gt;に指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/b.js
require([&#39;a&#39;], (a) =&amp;gt; {
  const divB = document.createElement(&#39;div&#39;);
  divB.textContent = a.a();
  document.body.appendChild(divB);
});

$ cat src/a.js
define({
  a: () =&amp;gt; &#39;a is defined&#39;
});

$ cat src/index.html
&amp;lt;body&amp;gt;
&amp;lt;script data-main=&amp;quot;b.js&amp;quot; src=&amp;quot;require.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CommonJSのモジュールを読み込もうとするとエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/c.js 
const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

$ cat src/d.js 
exports.d = () =&amp;gt; &#39;d is defined&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Uncaught Error: Module name &amp;quot;d&amp;quot; has not been loaded yet for context: _. Use require([])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RequireJSのNode版、&lt;a href=&#34;https://github.com/requirejs/r.js&#34;&gt;r.js&lt;/a&gt;でCommonJSのモジュールをAMDに変換することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g requirejs
$ r.js -convert src out
$ cat c.js 
define(function (require, exports, module) {const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

});

$ cat d.js 
define(function (require, exports, module) {exports.d = () =&amp;gt; &#39;d is defined&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、Webpackのようにコードを一つのjsファイルにbundleすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ r.js -o baseUrl=out name=b out=bundle.js optimize=none
$ cat bundle.js 
define(&#39;a&#39;,{
  a: () =&amp;gt; &#39;a is defined&#39;
});

define(&#39;d&#39;,[&#39;require&#39;,&#39;exports&#39;,&#39;module&#39;],function (require, exports, module) {exports.d = () =&amp;gt; &#39;d is defined&#39;;


});

define(&#39;c&#39;,[&#39;require&#39;,&#39;exports&#39;,&#39;module&#39;,&#39;d&#39;],function (require, exports, module) {const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

});

require([&#39;a&#39;,&#39;c&#39;], (a,c) =&amp;gt; {
  const divB = document.createElement(&#39;div&#39;);
  divB.textContent = a.a();
  document.body.appendChild(divB);

  const divB2 = document.createElement(&#39;div&#39;);
  divB2.textContent = c.c();
  document.body.appendChild(divB2);
});

define(&amp;quot;b&amp;quot;, function(){});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに&lt;code&gt;optimize=none&lt;/code&gt;を付けているのはES6のコードに対応していないため。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;If the source uses ES2015 or later syntax, please pass &amp;quot;optimize: &#39;none&#39;&amp;quot; to r.js and use an ES2015+ compatible minifier after running r.js. The included UglifyJS only understands ES5 or earlier syntax.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/guybedford/require-css&#34;&gt;guybedford/require-css&lt;/a&gt;を使うと
cssも依存に含めることができ、scriptタグと同様にstyleタグが動的に入る。&lt;/p&gt;

&lt;h2 id=&#34;webpack-https-webpack-js-org&#34;&gt;&lt;a href=&#34;https://webpack.js.org/&#34;&gt;Webpack&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;webpack.config.js&lt;/code&gt;の
&lt;code&gt;entry&lt;/code&gt;にエントリーポイント、
&lt;code&gt;output&lt;/code&gt;に出力場所、
&lt;code&gt;module&lt;/code&gt;にJS以外のファイルをbundleするloader、
&lt;code&gt;plugins&lt;/code&gt;に全体を処理するpluginの
設定を書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev webpack html-webpack-plugin
$ cat webpack.config.js 
const HtmlWebpackPlugin = require(&#39;html-webpack-plugin&#39;);
const webpack = require(&#39;webpack&#39;);
const path = require(&#39;path&#39;);

const config = {
  entry: &#39;./src/main.js&#39;,
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;bundle.js&#39;
  },
  module: {},
  plugins: [
    // new webpack.optimize.UglifyJsPlugin(),
    new HtmlWebpackPlugin({template: &#39;./src/index.html&#39;})
  ]
};

module.exports = config;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ES Modulesの記法を使っている。CommonJSにも対応しているが今はこちらが&lt;a href=&#34;https://webpack.js.org/api/module-methods/&#34;&gt;推奨&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js 
import { bar } from &#39;./foo&#39;;
const div = document.createElement(&#39;div&#39;);
div.textContent = bar();
document.body.appendChild(div);

$ cat src/foo.js 
export function bar() {
  return &#39;bar&#39;;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行するとこんな感じにbundleされる。実際はUglifyJsPluginによってもう少しサイズが小さくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ node_modules/.bin/webpack 
$ cat dist/index.html 
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;Test&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;

$ z$ cat dist/bundle.js 
/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
...
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ([
/* 0 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

&amp;quot;use strict&amp;quot;;
Object.defineProperty(__webpack_exports__, &amp;quot;__esModule&amp;quot;, { value: true });
/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__foo__ = __webpack_require__(1);

const div = document.createElement(&#39;div&#39;);
div.textContent = Object(__WEBPACK_IMPORTED_MODULE_0__foo__[&amp;quot;a&amp;quot; /* bar */])();
document.body.appendChild(div);


/***/ }),
/* 1 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

&amp;quot;use strict&amp;quot;;
/* harmony export (immutable) */ __webpack_exports__[&amp;quot;a&amp;quot;] = bar;
function bar() {
  return &#39;bar&#39;;
};


/***/ })
/******/ ]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/webpack-contrib/css-loader&#34;&gt;css-loader&lt;/a&gt;でCSSをbundleする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev style-loader css-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CSS Moduleを有効にして、ほかの同名のクラスに影響を及ぼさないようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module: {
    rules: [
      {
        test: /\.css$/,
        use: [ 
          &#39;style-loader&#39;, 
          {
            loader: &#39;css-loader&#39;,
            options: {
              modules: true,
            }
          }
        ]
      }
    ]
  },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;importするとCSSに書かれたクラスと変換後の対応が取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js 
import { bar } from &#39;./foo&#39;;
import css from &#39;./style.css&#39;;

const div = document.createElement(&#39;div&#39;);
div.textContent = bar();
div.className = css[&#39;bg&#39;]; /* {&amp;quot;bg&amp;quot;:&amp;quot;_2T2hBh3FkCro4-BOuqaGg5&amp;quot;} */
document.body.appendChild(div);

$ cat src/style.css 
.bg {
  background-color: #22ee22;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じでbundleされている。動的にstyleタグが入るのは同じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat dist/bundle.js | grep &amp;quot;#22ee22&amp;quot;
exports.push([module.i, &amp;quot;._2T2hBh3FkCro4-BOuqaGg5 {\n  background-color: #22ee22;\n}\n&amp;quot;, &amp;quot;&amp;quot;]);
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>圧縮アルゴリズムZopfliとBrotli</title>
          <link>https://www.sambaiz.net/article/142/</link>
          <pubDate>Fri, 03 Nov 2017 15:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/142/</guid>
          <description>

&lt;p&gt;どちらもGoogleが開発した圧縮アルゴリズム。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppetter-lambda-starter-kit&lt;/a&gt;
の&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/issues/2&#34;&gt;issue&lt;/a&gt;に
現在使っているgzipと、Zopfli、Brotliを比較したデータが上がっていたので調べてみた。&lt;/p&gt;

&lt;h2 id=&#34;zopfli-https-github-com-google-zopfli&#34;&gt;&lt;a href=&#34;https://github.com/google/zopfli&#34;&gt;Zopfli&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;出力としてDeflateに対応している。&lt;/p&gt;

&lt;h3 id=&#34;deflate&#34;&gt;Deflate&lt;/h3&gt;

&lt;p&gt;LZ77(実際は改良版のLZSS)とハフマン記号による可逆圧縮アルゴリズム。
zip、zlib、gzip、pngなどで使われていて、これらはヘッダーやフッターが異なる。
LZSSはバイト列を見ていって同じ部分を発見したらそこを参照するように置き換えていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a b c a b c a b c d d d
=&amp;gt; a b c (距離3, 長さ6) d (距離１, 長さ2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このLZSSにあたる部分をZopfliはがんばってやるので圧縮時間が結構かかるがサイズは小さくなるらしい。
展開は通常のDeflate通り。上げてくれたデータを見ても大体そんな感じだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/google/zopfli
$ cd zopfli
$ make zopfli
$ ./zopfli aaaa
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;brotli-https-github-com-google-brotli&#34;&gt;&lt;a href=&#34;https://github.com/google/brotli&#34;&gt;Brotli&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;LZ77、ハフマン記号に加えて2nd order context modelingというのを使って圧縮する
Deflateではない可逆圧縮アルゴリズム。
Safari以外のモダンなブラウザで既に対応しているか対応しているところ。
対応している場合、&lt;code&gt;Accept-Encoding&lt;/code&gt;や&lt;code&gt;Content-Encoding&lt;/code&gt;ヘッダに含まれるのは&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Content-Encoding&#34;&gt;br&lt;/a&gt;。
圧縮率も展開時間もかなり良さそう。&lt;/p&gt;

&lt;p&gt;Nodeにもblotliのライブラリが&lt;a href=&#34;https://github.com/devongovett/brotli.js&#34;&gt;あって&lt;/a&gt;、
圧縮はEmscriptenで&lt;a href=&#34;https://github.com/google/brotli&#34;&gt;本家のC++コード&lt;/a&gt;から変換し、
展開は手で移植しているようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install blotli
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
const brotli = require(&#39;brotli&#39;);
const TARGET = process.env.TARGET;
const MODE = process.env.MODE;

const compress = () =&amp;gt; {
  const target = fs.readFileSync(TARGET);
  const compressed = brotli.compress(target, {
    quality: 11,
  });
  fs.writeFileSync(`${TARGET}.br`, compressed);
};

const decompress = () =&amp;gt; {
  const target = fs.readFileSync(TARGET);
  const decompressed = brotli.decompress(target);
  fs.writeFileSync(`${TARGET.replace(&#39;.br&#39;, &#39;&#39;)}`, decompressed);
};

(async () =&amp;gt; {
    if (MODE === &#39;decompress&#39;) {
        decompress();
    } else {
        compress();
    }
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただ、これで大きなファイルを圧縮しようとすると以下のようなエラーが出て失敗する。
設定を変えてコンパイルするのも面倒なので、圧縮はCLIでやることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ TARGET=headless_shell node compress.js 
Cannot enlarge memory arrays. Either (1) compile with  -s TOTAL_MEMORY=X  with X higher than the current value 318767104, (2) compile with  -s ALLOW_MEMORY_GROWTH=1  which adjusts the size at runtime but prevents some optimizations, (3) set Module.TOTAL_MEMORY to a higher value before the program runs, or if you want malloc to return NULL (0) instead of this abort, compile with  -s ABORTING_MALLOC=0 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リポジトリをcloneしてきてmake installする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/google/brotli.git
$ cd brotli
$ mkdir out &amp;amp;&amp;amp; cd out
$ ../configure-cmake
$ make
$ make test
$ make install
$ brotli --version
brotli 1.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトで最高レベル(11)で圧縮することもあり、かなり時間がかかる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ time brotli headless_shell
$ time brotli headless_shell

real	18m41.814s
user	18m6.485s
sys	0m7.906s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;gzipだと最高レベルで圧縮しても43MBまでのところ、33MBまで圧縮できた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;131M headless_shell
33M  headless_shell.br
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;展開はすぐ。むしろgzipより速い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ time TARGET=aaaa.br MODE=decompress node compress.js

real	0m5.850s
user	0m4.626s
sys	0m1.030s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということで、brotli対応版を出そうとしたが、Lambdaでdecompressしたら&lt;code&gt;JavaScript heap out of memory&lt;/code&gt;になってしまった。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/7shi/deflate&#34;&gt;Deflate&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/jkr_2255/items/f3dfdf08267f2a8b590a&#34;&gt;Zopfliで高圧縮gzip・PNGほか - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Redashでデータを可視化する</title>
          <link>https://www.sambaiz.net/article/141/</link>
          <pubDate>Mon, 23 Oct 2017 23:59:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/141/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/getredash/redash&#34;&gt;Redash&lt;/a&gt;はOSSのデータ可視化ツール。
BIツールのようにパラメータを変えながら指標を探っていくというよりは、分かっている指標を見るのに使うイメージ。
比較的機能が少ない分処理がわかりやすく、
クエリが自動生成されないため時間がかかるものを実行する前にある程度気づけるのが良いと思う。&lt;/p&gt;

&lt;p&gt;docker-composeで立ち上げることもできるけど、
AWSの各リージョンに&lt;a href=&#34;https://redash.io/help-onpremise/setup/setting-up-redash-instance.html&#34;&gt;AMIが用意されている&lt;/a&gt;のでそれで立ち上げる。&lt;/p&gt;

&lt;p&gt;sshで入って以下のようなのを必要に応じて設定する。
メールを送る場合はSESでメールアドレスをVerifyしてやるのが簡単。
GSuiteを使っている場合、OAuthのClientID、Secretを発行しドメインを登録するとそれで認証できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh ubuntu@*****
$ sudo vi /opt/redash/.env
export REDASH_MAIL_SERVER=&amp;quot;email-smtp.us-east-1.amazonaws.com&amp;quot;
export REDASH_MAIL_USE_TLS=&amp;quot;true&amp;quot;
export REDASH_MAIL_USERNAME=&amp;quot;*****&amp;quot;
export REDASH_MAIL_PASSWORD=&amp;quot;*****&amp;quot;
export REDASH_MAIL_DEFAULT_SENDER=&amp;quot;*****&amp;quot; # Email address to send from

export REDASH_GOOGLE_CLIENT_ID=&amp;quot;&amp;quot;
export REDASH_GOOGLE_CLIENT_SECRET=&amp;quot;&amp;quot;

$ cd /opt/redash/current
$ sudo -u redash bin/run ./manage.py org set_google_apps_domains {{domains}}
$ sudo supervisorctl restart all
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTTPS対応するのに&lt;code&gt;/etc/nginx/sites-available/redash&lt;/code&gt;を編集する。crtとkeyの場所は変える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;upstream rd_servers {
  server 127.0.0.1:5000;
}

server {

  server_tokens off;

  listen 80 default;

  access_log /var/log/nginx/rd.access.log;

  gzip on;
  gzip_types *;
  gzip_proxied any;

  location /ping {
    proxy_set_header Host $http_host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_pass       http://rd_servers;
  }
  
  location / {
    return 301 https://$host$request_uri; 
  }
}

server {
  listen 443 ssl;

  # Make sure to set paths to your certificate .pem and .key files.
  ssl on;
  ssl_certificate /path-to/cert.pem; # or crt
  ssl_certificate_key /path-to/cert.key;

  # Specifies that we don&#39;t want to use SSLv2 (insecure) or SSLv3 (exploitable)
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
  # Uses the server&#39;s ciphers rather than the client&#39;s
  ssl_prefer_server_ciphers on;
  # Specifies which ciphers are okay and which are not okay. List taken from https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html
  ssl_ciphers &amp;quot;EECDH+AESGCM:EDH+AESGCM:ECDHE-RSA-AES128-GCM-SHA256:AES256+EECDH:DHE-RSA-AES128-GCM-SHA256:AES256+EDH:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4&amp;quot;;

  access_log /var/log/nginx/redash.access.log;

  gzip on;
  gzip_types *;
  gzip_proxied any;

  location / {
    proxy_set_header Host $http_host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_pass       http://rd_servers;
    proxy_redirect   off;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;諸々のデータはローカルで動いているPostgreSQLに入っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redash-# \d
                       List of relations
 Schema |               Name               |   Type   | Owner  
--------+----------------------------------+----------+--------
 public | access_permissions               | table    | redash
 public | access_permissions_id_seq        | sequence | redash
 public | alembic_version                  | table    | redash
 public | alert_subscriptions              | table    | redash
 public | alert_subscriptions_id_seq       | sequence | redash
 public | alerts                           | table    | redash
 public | alerts_id_seq                    | sequence | redash
 public | api_keys                         | table    | redash
 public | api_keys_id_seq                  | sequence | redash
 public | changes                          | table    | redash
 public | changes_id_seq                   | sequence | redash
 public | dashboards                       | table    | redash
 public | dashboards_id_seq                | sequence | redash
 public | data_source_groups               | table    | redash
 public | data_source_groups_id_seq        | sequence | redash
 public | data_sources                     | table    | redash
 public | data_sources_id_seq              | sequence | redash
 public | events                           | table    | redash
 public | events_id_seq                    | sequence | redash
 public | groups                           | table    | redash
 public | groups_id_seq                    | sequence | redash
 public | notification_destinations        | table    | redash
 public | notification_destinations_id_seq | sequence | redash
 public | organizations                    | table    | redash
 public | organizations_id_seq             | sequence | redash
 public | queries                          | table    | redash
 public | queries_id_seq                   | sequence | redash
 public | query_results                    | table    | redash
 public | query_results_id_seq             | sequence | redash
 public | query_snippets                   | table    | redash
 public | query_snippets_id_seq            | sequence | redash
 public | users                            | table    | redash
 public | users_id_seq                     | sequence | redash
 public | visualizations                   | table    | redash
 public | visualizations_id_seq            | sequence | redash
 public | widgets                          | table    | redash
 public | widgets_id_seq                   | sequence | redash
(37 rows)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なので&lt;a href=&#34;https://redash.io/help-onpremise/misc/backup-your-redash-database-and-restore-it-on-a-different-server.html&#34;&gt;他の環境に移すとき&lt;/a&gt;はこのdumpを取ってリストアする。バックアップを取っておくと良い。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-start.png&#34; alt=&#34;最初の画面&#34; /&gt;&lt;/p&gt;

&lt;p&gt;データソースを登録する。MySQLやRedshift、AthenaやBigQueryのほかにHive、ElasticSearchなども選べる。
今回はMySQL(Amazon RDS)を選択した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-datasource.png&#34; alt=&#34;データソースの登録&#34; /&gt;&lt;/p&gt;

&lt;p&gt;適当なデータをいれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const mysql = require(&#39;mysql&#39;);
const connection = mysql.createConnection({
  host     : &#39;*****&#39;,
  user     : &#39;*****&#39;,
  password : &#39;*****&#39;,
  database : &#39;*****&#39;
});

const query = (connection, query, params) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {
    connection.query(query, params, (error, results, fields) =&amp;gt; {
      if (error) reject(error);
      resolve(results);
    });
  });
};

(async () =&amp;gt; {
  connection.connect();

  await query(connection,
    `DROP TABLE IF EXISTS hoge`
  );

  await query(connection, 
    `CREATE TABLE hoge (
      id int,
      fuga_id int,
      piyo_id int,
      value int,
      created_at datetime
    )`
  );

  for (let i = 0; i &amp;lt; 100; i++) {
    console.log(i);
    await query(connection,
      `INSERT INTO hoge SET ?`,
      {
       id: i, 
       fuga_id: Math.floor(Math.random() * 3), 
       piyo_id: Math.floor(Math.random() * 10),
       value: Math.floor(Math.random() * 100),
       created_at: new Date(),
      }
    );
  };

  connection.end();
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリを登録する。エディタがあってフォーマットもしてくれる。
毎分や特定の時刻に実行するスケジュール機能もあるので、
重いクエリも事前に実行しておいて必要なときにすぐに見られるようにすることができる。
&lt;code&gt;{{name}}&lt;/code&gt;のようにパラメータを入れることもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-query.png&#34; alt=&#34;クエリの登録&#34; /&gt;&lt;/p&gt;

&lt;p&gt;実行して得られたデータからChartを作る。データはCSVでダウンロードもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-visualization.png&#34; alt=&#34;Chart&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このChartをDashboardに貼る。
パラメータがある場合は入力するフォームが出るので、クエリを書かない人に使ってもらうこともできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-dashboard.png&#34; alt=&#34;Dashbord&#34; /&gt;&lt;/p&gt;

&lt;p&gt;あとは簡単なAlertも登録することができて、
飛ばす先はSettingsのALERT DISTINATIONSに
SlackのWebhookなどを設定できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-alert.png&#34; alt=&#34;Alert&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-slack.png&#34; alt=&#34;Slackに飛ぶメッセージ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ApexでLambdaをデプロイする</title>
          <link>https://www.sambaiz.net/article/140/</link>
          <pubDate>Sun, 22 Oct 2017 16:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/140/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/apex/apex&#34;&gt;Apex&lt;/a&gt;でLambdaをデプロイする。
とても簡単に使えるし、変なこともしないので良い感じ。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Serverless Frameworkだとeventの設定までカバーできてより便利。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;インストール。ダウンロードして実行できるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;IAMFullAccess&lt;/li&gt;
&lt;li&gt;AWSLambdaFullAccess&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を付けたIAMのプロファイルを登録しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws configure --profile apex
$ aws configure list --profile apex
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                     apex           manual    --profile
access_key     ****************OVGQ shared-credentials-file    
secret_key     ****************oi5t shared-credentials-file    
    region           ap-northeast-1      config-file    ~/.aws/config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apex init&lt;/code&gt;してnameとdescriptionを入れるとIAMが登録され、
ディレクトリ構造が作られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex init --profile apex
Project name: try-apex
Project description: test  
[+] creating IAM try-apex_lambda_function role
[+] creating IAM try-apex_lambda_logs policy
[+] attaching policy to lambda_function role.
[+] creating ./project.json
[+] creating ./functions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;package.jsonで環境変数などの設定ができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls -R
functions	project.json

./functions:
hello

./functions/hello:
index.js

$ cat project.json 
{
  &amp;quot;name&amp;quot;: &amp;quot;try-apex&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;test&amp;quot;,
  &amp;quot;memory&amp;quot;: 128,
  &amp;quot;timeout&amp;quot;: 5,
  &amp;quot;role&amp;quot;: &amp;quot;arn:aws:iam::524580158183:role/try-apex_lambda_function&amp;quot;,
  &amp;quot;environment&amp;quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apex deploy&lt;/code&gt;するとlambdaが作られる。&lt;code&gt;--dry-run&lt;/code&gt;もできる。
バージョン管理されているので&lt;code&gt;rollback&lt;/code&gt;もできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex deploy hello --profile apex
   • creating function         env= function=hello
   • created alias current     env= function=hello version=1
   • function created          env= function=hello name=try-apex_hello version=1

$ apex list

  hello
    runtime: nodejs6.10
    memory: 128mb
    timeout: 5s
    role: arn:aws:iam::*****:role/try-apex_lambda_function
    handler: index.handle
    arn: arn:aws:lambda:ap-northeast-1:*****:function:try-apex_hello:current
    aliases: current@v1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マネジメントコンソールではここでバージョンが確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/140.png&#34; alt=&#34;バージョンの確認&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;apex invoke&lt;/code&gt;で実行。標準入力でイベントを渡せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex invoke hello
{&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パッケージに含めないファイルは.apexignoreに書く。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsのコードをPrettierでフォーマットしてESLintにかける</title>
          <link>https://www.sambaiz.net/article/139/</link>
          <pubDate>Thu, 19 Oct 2017 00:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/139/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/prettier/prettier&#34;&gt;Prettier&lt;/a&gt;はJSやTSのコードフォーマッタで、
ReactやBabel、Yarnなどの開発にも使われている。&lt;/p&gt;

&lt;p&gt;今回はPrettierでフォーマットしたものを
&lt;code&gt;eslint --fix&lt;/code&gt;する&lt;a href=&#34;https://github.com/prettier/prettier-eslint-cli&#34;&gt;prettier-eslint-cli&lt;/a&gt;を使う。役割が被っているけどPrettierは&lt;code&gt;eslint --fix&lt;/code&gt;よりも強力にフォーマットしてくれるようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git init
$ yarn add --dev eslint eslint-config-google prettier-eslint-cli husky lint-staged
$ cat .eslintrc.js 
module.exports = {
    &amp;quot;extends&amp;quot;: &amp;quot;google&amp;quot;,
    &amp;quot;parserOptions&amp;quot;: {
    	&amp;quot;ecmaVersion&amp;quot;: 2017,
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;対象のコードはこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js
/**
 * hoge function
 */
function hoge() {

  const f = (aaaaaaaaaaaaaaa, bbbbbbbbbb, ccccccccc, dddddddddddd, eeeeeeeeeeeeee) =&amp;gt;
    console.log(&#39;a&#39;);


  f(1, 2, 3, 4, 5);
}


hoge();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prettierのドキュメントでも紹介されているように&lt;a href=&#34;https://github.com/okonet/lint-staged&#34;&gt;lint-staged&lt;/a&gt;を使うとCommit時にフォーマットし、Lintをかけることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;precommit&amp;quot;: &amp;quot;lint-staged&amp;quot;,
    &amp;quot;lint&amp;quot;: &amp;quot;eslint src&amp;quot;,
    &amp;quot;format&amp;quot;: &amp;quot;prettier-eslint --write \&amp;quot;src/**/*.js\&amp;quot;&amp;quot;
  },
  &amp;quot;lint-staged&amp;quot;: {
    &amp;quot;*.js&amp;quot;: [
      &amp;quot;prettier-eslint --write&amp;quot;,
      &amp;quot;eslint&amp;quot;,
      &amp;quot;git add&amp;quot;
    ]
  },
  &amp;quot;devDependencies&amp;quot;: {
    &amp;quot;eslint&amp;quot;: &amp;quot;^4.9.0&amp;quot;,
    &amp;quot;eslint-config-google&amp;quot;: &amp;quot;^0.9.1&amp;quot;,
    &amp;quot;husky&amp;quot;: &amp;quot;^0.14.3&amp;quot;,
    &amp;quot;lint-staged&amp;quot;: &amp;quot;^4.2.3&amp;quot;,
    &amp;quot;prettier-eslint-cli&amp;quot;: &amp;quot;^4.4.0&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ git commit -m &amp;quot;test&amp;quot;
husky &amp;gt; npm run -s precommit (node v8.2.1)

 ✔ Running tasks for *.js
[master e325ea3] test

$ cat src/main.js 
/**
 * hoge function
 */
function hoge() {
  const f = (
    aaaaaaaaaaaaaaa,
    bbbbbbbbbb,
    ccccccccc,
    dddddddddddd,
    eeeeeeeeeeeeee
  ) =&amp;gt; console.log(&#39;a&#39;);

  f(1, 2, 3, 4, 5);
}

hoge();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prettierは&lt;code&gt;eslint --fix&lt;/code&gt;で修正されないmax-lenも良い感じにしてくれる。
なのでESLintのフォーマットに関するところはほとんど修正いらないはず。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git commit -m &amp;quot;test&amp;quot;
husky &amp;gt; npm run -s precommit (node v8.2.1)

 ❯ Running tasks for *.js
   ✖ eslint --fix
     git add
✖ eslint --fix found some errors. Please fix them and try committing again.

***/src/main.js
  5:1  error  Line 5 exceeds the maximum line length of 80  max-len

✖ 1 problem (1 error, 0 warnings)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>確率分布(二項分布/ポアソン分布/正規分布)</title>
          <link>https://www.sambaiz.net/article/138/</link>
          <pubDate>Sun, 15 Oct 2017 01:53:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/138/</guid>
          <description>

&lt;h2 id=&#34;二項分布&#34;&gt;二項分布&lt;/h2&gt;

&lt;p&gt;確率pで起きる事象がn回の試行でx回起きる確率関数の離散的確率分布。記号で書くと&lt;code&gt;B[n,p]&lt;/code&gt;。
期待値は&lt;code&gt;np&lt;/code&gt;で、分散は&lt;code&gt;np(1-p)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-binormal-distribution.png&#34; alt=&#34;二項分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-bi-graph.png&#34; alt=&#34;二項分布のグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ポアソン分布&#34;&gt;ポアソン分布&lt;/h2&gt;

&lt;p&gt;二項分布において、起きる確率pが少なく、試行回数nが多いときに代わりに適用できる確率分布。
具体的にはnが50ぐらいだったら、npが5以下のとき。
試行回数が多いとき、二項分布だとCの部分の計算が困難になってしまうのを解決できる。
期待値も分散も&lt;code&gt;np=μ&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-poisson.png&#34; alt=&#34;ポアソン分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-poisson-graph.png&#34; alt=&#34;ポアソン分布のグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;正規分布&#34;&gt;正規分布&lt;/h2&gt;

&lt;p&gt;正規分布は平均値&lt;code&gt;μ&lt;/code&gt;を最大値とし、左右対称な釣鐘型をしている連続的確率分布。記号で書くと&lt;code&gt;N[μ,σ^2]&lt;/code&gt;。
二項分布のnを大きくしていくと正規分布に近づいていく。
p=0.5であれば、n=10の二項分布&lt;code&gt;B[10,0.5]&lt;/code&gt;でも良い近似が得られる(&lt;code&gt;N[5,2.5]&lt;/code&gt;)。
逆にnが大きな二項分布の近似として正規分布を使うこともできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-normal.png&#34; alt=&#34;正規分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-normal-graph.png&#34; alt=&#34;正規分布のグラプ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;N[0,1]&lt;/code&gt;の正規分布を標準正規分布と呼ぶ。
ある正規分布に従う確率変数xを、標準正規分布に従うzに変換することを標準化変換という。
標準正規分布にすると正規分布表の値を使って計算できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-std.png&#34; alt=&#34;標準化変換&#34; /&gt;&lt;/p&gt;

&lt;p&gt;また、平均&lt;code&gt;μ&lt;/code&gt;、分散&lt;code&gt;σ^2&lt;/code&gt;の任意な分布からn個の標本をとったときの平均は&lt;code&gt;N[μ, σ^2/n]&lt;/code&gt;に従う。
言い換えれば、標本の平均と真の平均の誤差は&lt;code&gt;N[0, σ^2/n]&lt;/code&gt;。これを中心極限定理という。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://ruby.kyoto-wu.ac.jp/~konami/Text/&#34;&gt;統計学入門&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Lpノルムと正則化</title>
          <link>https://www.sambaiz.net/article/137/</link>
          <pubDate>Thu, 12 Oct 2017 23:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/137/</guid>
          <description>

&lt;h2 id=&#34;ノルムとは&#34;&gt;ノルムとは&lt;/h2&gt;

&lt;p&gt;ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;p(av) = |a| p(v)&lt;/code&gt;: スケーラブル&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(u + v) ≦ p(u) + p(v)&lt;/code&gt;: 三角不等式を満たす&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(v) ≧ 0&lt;/code&gt;: 負の値を取らない&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(v) = 0 &amp;lt;=&amp;gt; v=0&lt;/code&gt;: 距離が0 &amp;lt;=&amp;gt; 零ベクトル&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下の式で表されるノルムをLpノルムと呼ぶ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-norm.png&#34; alt=&#34;Lpノルム&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;l1ノルム-マンハッタン距離&#34;&gt;L1ノルム(マンハッタン距離)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-l1norm.png&#34; alt=&#34;L1ノルムの距離1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;絶対値の和。座標軸方向にしか移動できない縛りでの距離。
StreetとAvenueが格子状になっているマンハッタンではタクシーが移動する距離はL1ノルムのようになる。&lt;/p&gt;

&lt;h3 id=&#34;l2ノルム-ユークリッド距離&#34;&gt;L2ノルム(ユークリッド距離)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-l2norm.png&#34; alt=&#34;L2ノルムの距離1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2乗の和の平方根。普通の距離。&lt;/p&gt;

&lt;h2 id=&#34;正則化-regularization&#34;&gt;正則化(regularization)&lt;/h2&gt;

&lt;p&gt;機械学習で過学習を防ぐためのもの。
Lp正則化は重みのLpノルムをp乗してハイパーパラメータΛを掛けたものを正則化項として
素の損失関数に加える。これを最小化するのだから重みがペナルティとしてはたらく。
L1正則化ではΛが大きければいくつかの重みが0になって次元削減できるが、
L2正則化では重みに比例して小さくなるだけ。それぞれLasso回帰、Ridge回帰ともいう。
また、これらを割合で足して使うElasticNetというものもある。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Norm_(mathematics)&#34;&gt;Norm (mathematics) - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tjo.hatenablog.com/entry/2015/03/03/190000&#34;&gt;RでL1 / L2正則化を実践する - 六本木で働くデータサイエンティストのブログ&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OpenID ConnectのIDトークンの内容と検証</title>
          <link>https://www.sambaiz.net/article/136/</link>
          <pubDate>Mon, 09 Oct 2017 20:01:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/136/</guid>
          <description>

&lt;p&gt;OpenID Connectは認可(AuthoriZation)のプロトコルであるOAuth 2.0を正しく認証(AutheNtication)に使うためのプロトコル。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://openid-foundation-japan.github.io/openid-connect-core-1_0.ja.html&#34;&gt;OpenID Connect Core 1.0(日本語訳)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/48/&#34;&gt;OAuth2.0のメモ - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;OpenID ConnectではOAuthのアクセストークンに加えて
Issuer(IdP)によって署名されたJWT(JSON Web Token)形式のIDトークンも返す。
このIDトークンの署名を検証し、含まれるIssuerとクライアントの情報を参照することで
OAuthのImplicit flowでのトークン置き換え攻撃を防ぐことができる。&lt;/p&gt;

&lt;h2 id=&#34;jwt-idトークン&#34;&gt;JWT/IDトークン&lt;/h2&gt;

&lt;p&gt;JWTは&lt;a href=&#34;https://tools.ietf.org/html/rfc7519&#34;&gt;RFC7519&lt;/a&gt;で定義されている、
パーティ間で安全にClaim(エンドユーザーのようなエンティティの情報)を受け渡すための表現方法。
JSONにエンコードしたClaimは、JOSE(Javascript Object Signing and Encryption)のサブセットである&lt;a href=&#34;https://tools.ietf.org/html/rfc7515&#34;&gt;JWS&lt;/a&gt;(JSON Web Signature)のペイロードとして署名を付与されるか、&lt;a href=&#34;https://tools.ietf.org/html/rfc7519&#34;&gt;JWE&lt;/a&gt;(JSON Web Encryption)で暗号化される。
以下のJWTはJWSのもの。&lt;/p&gt;

&lt;p&gt;JWSには&lt;code&gt;(ヘッダ).(ペイロード).(署名)&lt;/code&gt;の文字列で表現されるCompact SerializationとJSONで表現されるJSON Serializationがあるが、JWTではCompact Serializationを使う。&lt;/p&gt;

&lt;p&gt;ヘッダには署名に使うアルゴリズム&lt;code&gt;alg&lt;/code&gt;が含まれる。
JWTを受け取った際、不正なalgになっていないかチェックする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
  &amp;quot;kid&amp;quot;: &amp;quot;5b0924f6f83c719514987954cf66683b370677d4&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ペイロードには以下のようなClaimが含まれる。これ以外のClaimを含めることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;iss&amp;quot;: &amp;quot;https://server.example.com&amp;quot;, # IssuerのIdentifier。httpsのURL
    &amp;quot;sub&amp;quot;: &amp;quot;24400320&amp;quot;, # Subject Identifier。Issuerでユニークなエンドユーザーの識別子。
    &amp;quot;aud&amp;quot;: &amp;quot;s6BhdRkqt3&amp;quot;, # audience。OAuth2.0のclient_id
    &amp;quot;nonce&amp;quot;: &amp;quot;n-0S6_WzA2Mj&amp;quot;, # リクエストで送ったのがそのまま返ってくる。リプレイ攻撃を防ぐため
    &amp;quot;exp&amp;quot;: 1311281970, # IDトークンの有効期限。時間はすべてUNIXエポック秒
    &amp;quot;iat&amp;quot;: 1311280970, # IDトークンの発行時刻
    &amp;quot;auth_time&amp;quot;: 1311280969 # エンドユーザーの認証時刻
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;idトークンを取得する&#34;&gt;IDトークンを取得する&lt;/h2&gt;

&lt;p&gt;Googleの&lt;a href=&#34;https://developers.google.com/identity/protocols/OpenIDConnect&#34;&gt;OAuth 2.0 API&lt;/a&gt;はOpenID Connectに対応している。これのIDトークンを取得する。&lt;/p&gt;

&lt;p&gt;エンドポイント等は&lt;a href=&#34;https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig&#34;&gt;OpenID Connect Discovery 1.0&lt;/a&gt;の
&lt;code&gt;/.well-known/openid-configuration&lt;/code&gt;で取得できるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://accounts.google.com/.well-known/openid-configuration | jq
{
  &amp;quot;issuer&amp;quot;: &amp;quot;https://accounts.google.com&amp;quot;,
  &amp;quot;authorization_endpoint&amp;quot;: &amp;quot;https://accounts.google.com/o/oauth2/v2/auth&amp;quot;,
  &amp;quot;token_endpoint&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v4/token&amp;quot;,
  &amp;quot;userinfo_endpoint&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v3/userinfo&amp;quot;,
  &amp;quot;revocation_endpoint&amp;quot;: &amp;quot;https://accounts.google.com/o/oauth2/revoke&amp;quot;,
  &amp;quot;jwks_uri&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v3/certs&amp;quot;,
  &amp;quot;response_types_supported&amp;quot;: [
    &amp;quot;code&amp;quot;,
    &amp;quot;token&amp;quot;,
    &amp;quot;id_token&amp;quot;,
    &amp;quot;code token&amp;quot;,
    &amp;quot;code id_token&amp;quot;,
    &amp;quot;token id_token&amp;quot;,
    &amp;quot;code token id_token&amp;quot;,
    &amp;quot;none&amp;quot;
  ],
  &amp;quot;subject_types_supported&amp;quot;: [
    &amp;quot;public&amp;quot;
  ],
  &amp;quot;id_token_signing_alg_values_supported&amp;quot;: [
    &amp;quot;RS256&amp;quot;
  ],
  &amp;quot;scopes_supported&amp;quot;: [
    &amp;quot;openid&amp;quot;,
    &amp;quot;email&amp;quot;,
    &amp;quot;profile&amp;quot;
  ],
  &amp;quot;token_endpoint_auth_methods_supported&amp;quot;: [
    &amp;quot;client_secret_post&amp;quot;,
    &amp;quot;client_secret_basic&amp;quot;
  ],
  &amp;quot;claims_supported&amp;quot;: [
    &amp;quot;aud&amp;quot;,
    &amp;quot;email&amp;quot;,
    &amp;quot;email_verified&amp;quot;,
    &amp;quot;exp&amp;quot;,
    &amp;quot;family_name&amp;quot;,
    &amp;quot;given_name&amp;quot;,
    &amp;quot;iat&amp;quot;,
    &amp;quot;iss&amp;quot;,
    &amp;quot;locale&amp;quot;,
    &amp;quot;name&amp;quot;,
    &amp;quot;picture&amp;quot;,
    &amp;quot;sub&amp;quot;
  ],
  &amp;quot;code_challenge_methods_supported&amp;quot;: [
    &amp;quot;plain&amp;quot;,
    &amp;quot;S256&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テスト用にcodeを受け取ってトークンをリクエストするサーバーを書いた。コードは&lt;a href=&#34;https://github.com/sambaiz/openid-connect-test-client&#34;&gt;ここ&lt;/a&gt;。client_idとclient_secretは&lt;a href=&#34;https://console.developers.google.com/&#34;&gt;API Console&lt;/a&gt;で発行できる。&lt;/p&gt;

&lt;p&gt;立ち上げて&lt;code&gt;https://localhost:3000/auth&lt;/code&gt;にアクセスするとリダイレクトし、以下のような情報が出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;code&amp;quot;: {
    &amp;quot;state&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;code&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;authuser&amp;quot;: &amp;quot;0&amp;quot;,
    &amp;quot;session_state&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;prompt&amp;quot;: &amp;quot;none&amp;quot;
  },
  &amp;quot;token&amp;quot;: {
    &amp;quot;access_token&amp;quot;: &amp;quot;*****.*****.*****&amp;quot;
  },
  &amp;quot;id_token_header&amp;quot;: {
    &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
    &amp;quot;kid&amp;quot;: &amp;quot;5b0924f6f83c719514987954cf66683b370677d4&amp;quot;
  },
  &amp;quot;id_token_payload&amp;quot;: {
    &amp;quot;azp&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;aud&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;sub&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;email&amp;quot;: &amp;quot;****@gmail.com&amp;quot;,
    &amp;quot;email_verified&amp;quot;: true,
    &amp;quot;at_hash&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;nonce&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;iss&amp;quot;: &amp;quot;https://accounts.google.com&amp;quot;,
    &amp;quot;iat&amp;quot;: 1506613038,
    &amp;quot;exp&amp;quot;: 1506616638
  },
  &amp;quot;id_token_verify_signature&amp;quot;: &amp;quot;*****&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このIDトークンのiss, audを見て署名も&lt;a href=&#34;https://developers.google.com/identity/protocols/OpenIDConnect#validatinganidtoken&#34;&gt;検証する&lt;/a&gt;ことで、
たしかに発行元と先が正しいことを確認し、expも過ぎていなければ、
subに示されるIDのエンティティとして認証できる。&lt;/p&gt;

&lt;h2 id=&#34;idトークンの署名を検証する&#34;&gt;IDトークンの署名を検証する&lt;/h2&gt;

&lt;p&gt;検証もやってみた。urlは&lt;code&gt;https://localhost:3000/verify?token=****&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;GoogleのIDトークンのalgを見ると、RS256(RSASSA-PKCS1-v1_5 using SHA-256)で署名されていることがわかる。対象となるデータはJWSの&lt;code&gt;(ヘッダ).(ペイロード)&lt;/code&gt;まで。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/135/&#34;&gt;RSA暗号とPEM/DERの構造 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;公開鍵はDiscoveryのjwks_uriで取得でき、1日に1回更新される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://www.googleapis.com/oauth2/v3/certs
{
 &amp;quot;keys&amp;quot;: [
  {
   &amp;quot;kty&amp;quot;: &amp;quot;RSA&amp;quot;,
   &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
   &amp;quot;use&amp;quot;: &amp;quot;sig&amp;quot;,
   &amp;quot;kid&amp;quot;: &amp;quot;23e255c65b234549cc0fe3073bce15e59bd4d4b0&amp;quot;,
   &amp;quot;n&amp;quot;: &amp;quot;w5i-jGiwEyuPewnvR-lFceBRYh4gx91-OFLaJwwr8yCrSVczAgyc1wywFBCsUBDBhHpKSVilqIGG2fIqhdX2_IFJ-OxYvXDmJtYF69kWTafZjFtnAl8EdIqj1X-y31Pm9gYD_rYeLG3CZhNLjIE_y9fk5_MbOOc0Z-br4_wzing6HfERITbAOAfCd8Ri0_tXDqYgi-C1C_gs2HheYEIWqpZ2se8UsGvIg2uePOCV8G3a0fuvh6hgjutspfJ_VH3eeHwYwyYzieq-sDWcyV5qGlnJp9TZlZ9z242WdYHj3C2kudNTUg76p6svbs6cu1ZiZA9WZkaL9d8hWeJ4tLQg3Q&amp;quot;,
   &amp;quot;e&amp;quot;: &amp;quot;AQAB&amp;quot;
  },
  {
   &amp;quot;kty&amp;quot;: &amp;quot;RSA&amp;quot;,
   &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
   &amp;quot;use&amp;quot;: &amp;quot;sig&amp;quot;,
   &amp;quot;kid&amp;quot;: &amp;quot;db15c5e7c1b82b93388459602e4852bfd9b95931&amp;quot;,
   &amp;quot;n&amp;quot;: &amp;quot;lZUcUSL9piIsbwP_Y84683P7-vX_Y9CEvqpeCNpI4p55HFCDnp9xtnvc5mBEOrFP-vwk6sjlkLVbl74d1CR-jKX-z8zPg3T0qQzYWgedAddfQL1zFUyo2BLbCg2JeYDZF6IHv6qfwzM3hgQIMJMa29izyAyZ2T0zhXf5fU311LEKWCdpemQsNj5V4r5Z52vsTuOhm16Xt7LWx_iWb-_VdYxhDYoQ87pZIVaCdnKDwGON0MPoI4eQJdb-ABrcz290mbGJ8kiI4BU_iA98HCc3ifWDe8eatpV9LK54eYansDTMQJXoYZ6a7C-0-Mh1-g6qaxYjpymJXbJjYitiMejYFQ&amp;quot;,
   &amp;quot;e&amp;quot;: &amp;quot;AQAB&amp;quot;
  },
  ...
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;signature,n,eをそれぞれbase64デコードしたのを整数として扱い、&lt;code&gt;m ≡ (signature)^e (mod n)&lt;/code&gt;で複合するとdigestInfoのDERの前に&lt;code&gt;00 01 ff ff .. 00&lt;/code&gt;のパディングがついたものになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;digestInfo ::= SEQUENCE {
     digestAlgorithm DigestAlgorithmIdentifier,
     digest Digest 
}

Digest ::= OCTET STRING
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const digestInfoDERFromSignature = (signature, e, n) =&amp;gt; {
  const signatureHex = Buffer.from(signature, &#39;base64&#39;).toString(&#39;hex&#39;)
  const eHex  = Buffer.from(e, &#39;base64&#39;).toString(&#39;hex&#39;)
  const nHex = Buffer.from(n, &#39;base64&#39;).toString(&#39;hex&#39;)

  const signatureNum = bigInt(signatureHex, 16)
  const eNum = bigInt(eHex, 16)
  const nNum = bigInt(nHex, 16)  

  const m = signatureNum.modPow(eNum, nNum); // c^e (mod n)
  const decrypted = m.toString(16);
  const paddingRemoved = decrypted.replace(/^1f*00/g, &amp;quot;&amp;quot;);
  return paddingRemoved;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この中のdigestと&lt;code&gt;(ヘッダ).(ペイロード)&lt;/code&gt;のsha256 hashが一致することを確認する。
digestは末尾にくるので簡易的にendsWithで比較している。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RSA暗号とPEM/DERの構造</title>
          <link>https://www.sambaiz.net/article/135/</link>
          <pubDate>Sun, 01 Oct 2017 21:02:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/135/</guid>
          <description>

&lt;h2 id=&#34;rsa暗号とは&#34;&gt;RSA暗号とは&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;暗号化: &lt;code&gt;c ≡ m^e (mod n)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;複合: &lt;code&gt;m ≡ c^d (mod n)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;公開鍵がe,nで秘密鍵がd。nはとても大きく近くない素数p,qの積で、
これを公開しても素因数分解できないのがこの暗号の前提になっている。
768bit(10進数で232桁)では既に解読されているので、少なくとも1024bit以上にする。&lt;/p&gt;

&lt;p&gt;eは&lt;a href=&#34;https://en.wikipedia.org/wiki/Euler%27s_totient_function&#34;&gt;Euler totient function&lt;/a&gt;(1~nまでの整数でnと互いに素なものの個数。今回の場合は&lt;code&gt;φ(n)=(p-1)(q-1)&lt;/code&gt;)未満で互いに素な正の整数で、小さすぎても大きすぎてもだめ。&lt;code&gt;2^16 + 1 = 65537&lt;/code&gt;がよく使われる。&lt;/p&gt;

&lt;p&gt;dは&lt;code&gt;ed ≡ 1 (mod φ(n))&lt;/code&gt;を満たすd。&lt;/p&gt;

&lt;h2 id=&#34;例&#34;&gt;例&lt;/h2&gt;

&lt;p&gt;例として(p,q)=(193,709)とするとこんな感じ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n = p * q = 136837&lt;/li&gt;
&lt;li&gt;φ(n) = (p-1)(q-1) = 135936&lt;/li&gt;
&lt;li&gt;e = 65537 &amp;lt; φ(n)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;秘密鍵dは&lt;code&gt;65537*d ≡ 1 (mod 135936)&lt;/code&gt;の式を変形した
&lt;code&gt;65537*d - 135936*x = gcd(65537,135936) = 1&lt;/code&gt;を、拡張されたユークリッドの互除法で解く。
以下のように135936と65537を残しながら展開していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;135936 = 65537 * 2 + 4862 
=&amp;gt; 4862 = 135936 * 1 + 65537 * -2

65537 = 4862 * 13 + 2331 
=&amp;gt; 2331 = 65537 - (135936 * 1 + 65537 * -2) * 13
        = 135936 * -13 + 65537 * 27

4862 = 2331 * 2 + 200 
=&amp;gt; 200 = (135936 * 1 + 65537 * -2) - (135936 * -13 + 65537 * 27) * 2
       = 135936 * 27 + 65537 * -56

2331 = 200 * 11 + 131 
=&amp;gt; 131 = (135936 * -13 + 65537 * 27) - (135936 * 27 + 65537 * -56) * 11
       = 135936 * -310 + 65537 * 643 
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをコードに表したのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const d = (phi,e) =&amp;gt; {
    let history = {[phi]: [1,0], [e]:[0,1]} // [x,y] =&amp;gt; φ * x + e * y
    let x = phi
    let y = e
    while(y &amp;gt; 1){
        const nextY = x % y
        history[x % y] = history[x].map((vx,index) =&amp;gt; vx - history[y][index] * Math.floor(x/y))
        x = y
        y = nextY;
    }
    return history;
}

const phi = (193-1) * (709-1)
const e = 65537
const result = d(phi,e);
console.log(result);
console.log(`1 = ${phi}*${result[1][0]} + ${e}*${result[1][1]}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{ &#39;1&#39;: [ 9503, -19711 ],
  &#39;6&#39;: [ -8519, 17670 ],
  &#39;7&#39;: [ 984, -2041 ],
  &#39;62&#39;: [ -647, 1342 ],
  &#39;69&#39;: [ 337, -699 ],
  &#39;131&#39;: [ -310, 643 ],
  &#39;200&#39;: [ 27, -56 ],
  &#39;2331&#39;: [ -13, 27 ],
  &#39;4862&#39;: [ 1, -2 ],
  &#39;65537&#39;: [ 0, 1 ],
  &#39;135936&#39;: [ 1, 0 ] }
1 = 135936*9503 + 65537*-19711
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;135936*-65537 + 65537*135936 = 0&lt;/code&gt;より
&lt;code&gt;1 = 135936*(9503-65537) + 65537*(-19711 + 135936)&lt;/code&gt;なので
&lt;code&gt;d=116225&lt;/code&gt;。実際&lt;code&gt;(65537*116225) % 135936 = 1&lt;/code&gt;が成り立つ。&lt;/p&gt;

&lt;p&gt;平文が12345とすると、公開鍵で暗号化したのが&lt;code&gt;(12345 ** 65537) % 136837 = 6964&lt;/code&gt;。
これを秘密鍵で複合すると&lt;code&gt;(6964 ** 116225) % 136837 = 12345&lt;/code&gt;のように平文が得られる。&lt;/p&gt;

&lt;h2 id=&#34;鍵ファイルの生成&#34;&gt;鍵ファイルの生成&lt;/h2&gt;

&lt;p&gt;ssh-keygenで生成されるようなPEMファイルを作る。&lt;/p&gt;

&lt;h3 id=&#34;用語&#34;&gt;用語&lt;/h3&gt;

&lt;p&gt;DER(Distinguished Encoding Rules)は
&lt;a href=&#34;https://ja.wikipedia.org/wiki/Abstract_Syntax_Notation_One&#34;&gt;ASN.1(Abstract Syntax Notation One)&lt;/a&gt;記法で定義されたデータを
エンコードするルールの一つ。
&lt;code&gt;1a(INTEGER) 0b(byte) 68 65 6c 6c 6f 20 77 6f 72 6c 64(&amp;quot;hello world&amp;quot;))&lt;/code&gt;
のようなtype-length-valueで表す。&lt;/p&gt;

&lt;p&gt;PEM(Privacy-enhanced Electronic Mail)は
公開鍵のフォーマットの定義&lt;a href=&#34;https://en.wikipedia.org/wiki/X.509&#34;&gt;X.509&lt;/a&gt;で
定められている拡張子で、Base64でエンコードされたDER。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/PKCS&#34;&gt;PKCS(Public-Key Cryptography Standards)&lt;/a&gt;は公開鍵暗号における標準仕様を定めたもの。PKCS#1(&lt;a href=&#34;https://tools.ietf.org/html/rfc2313&#34;&gt;RFC2313&lt;/a&gt;)にはRSA暗号の方式やASN.1表現などが含まれている。&lt;/p&gt;

&lt;p&gt;RFC2313に書かれているASN.1を見ながらPEMの内容を確認する。&lt;/p&gt;

&lt;h3 id=&#34;rsaprivatekey&#34;&gt;RSAPrivateKey&lt;/h3&gt;

&lt;p&gt;n,e,dに加えて生成に使った素数まで含んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RSAPrivateKey ::= SEQUENCE {
     version Version,
     modulus INTEGER, -- n
     publicExponent INTEGER, -- e
     privateExponent INTEGER, -- d
     prime1 INTEGER, -- p
     prime2 INTEGER, -- q
     exponent1 INTEGER, -- d mod (p-1)
     exponent2 INTEGER, -- d mod (q-1)
     coefficient INTEGER -- (inverse of q) mod p }

   Version ::= INTEGER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pemを生成し、Base64デコードしてDERにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa 1024 &amp;gt; secret.pem
$ cat secret.pem 
-----BEGIN RSA PRIVATE KEY-----
(内容)
-----END RSA PRIVATE KEY-----

$ echo (内容) | base64 -D | xxd
00000000: 3082 025c 0201 0002 8181 .... .... .... 
00000080: .... .... .... .... .... ..02 0301 0001
00000090: 0281 80..
00000110: .... ..02 41.. 
00000150: .... .... .... 0241 ....
00000190: .... .... .... .... ..02 40.. 
000001d0: .... .... .... .... .... ..02 41.. ....  
00000210: .... .... .... .... .... .... .... 0240 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;整理するとこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[0000] 30 82 02 5c       
(30-&amp;gt;Type=SEQUENCE 82-&amp;gt;先頭bitが1なのでlengthに使うバイト数(2bytes) 025c-&amp;gt;Length=605bytes)

  [0000] 02 01 00
  (version: 02-&amp;gt;Type=INTEGER, 01-&amp;gt;先頭が0なのでそのままLength=3bytes, Value=0)

  [0000] 02 81 81 .. 
  (modulus: Type=INTEGER, Length=129bytes)

  [0080] 02 03 01 00 01 
  (publicExponent: Type=INTEGER, Length=3bytes, Value=65537)

  [0090] 02 81 80 ..
  (privateExponent: Type=INTEGER, Length=128bytes)

  [0110] 02 41 ..
  (prime1: Type=INTEGER, Length=65bytes)

  [0150] 02 41 .. 
  (prime2: Type=INTEGER, Length=65bytes)

  [0190] 02 40 ..
  (exponent1: Type=INTEGER, Length=64bytes)

  [01d0] 02 41 ..
  (exponent2: Type=INTEGER, Length=65bytes)

  [0210] 02 40 ..
  (coefficient: Type=INTEGER, Length=64bytes)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rsapublickey&#34;&gt;RSAPublicKey&lt;/h3&gt;

&lt;p&gt;nとeだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RSAPublicKey ::= SEQUENCE {
     modulus INTEGER, -- n
     publicExponent INTEGER -- e }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秘密鍵から公開鍵を生成して同様にDERにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl rsa -pubout &amp;lt; secret.pem &amp;gt; public.pem
$ cat public.pem 
-----BEGIN PUBLIC KEY-----
(内容)
-----END PUBLIC KEY-----

$ echo (内容) | base64 -D | xxd
00000000: 3081 9f30 0d06 092a 8648 86f7 0d01 0101
00000010: 0500 0381 8d00 3081 8902 8181 .... ....
00000090: .... .... .... .... .... .... ..02 0301 
000000a0: 0001
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[0000] 30 81 9f
(Type=SEQUENCE, Length=159bytes)
  [0000] 30 0d
  (Type=SEQUENCE, Length=13bytes)
    [0000] 06 09 2a 86 48 86 f7 0d 01 01 01
    (Type=OBJECT IDENTIFIER, Length=9bytes, 
    value=http://www.oid-info.com/get/1.2.840.113549.1.1.1
          最上位ビットは区切りのサイン
          2a ((0)010 1010) =&amp;gt; 40 * 1 + 2 =&amp;gt; 1(iso) 2(member-body)
          86 48 ((1)000 0110 (0)100 1000) =&amp;gt; 840(us)
          86 f7 0d ((1)000 0110 (1)111 0111 (0)000 1101) =&amp;gt; 113549(rsadsi)
          01 ((0)000 0001) =&amp;gt; 1(pkcs)
          01 ((0)000 0001) =&amp;gt; 1(pcks-1)
          01 ((0)000 0001) =&amp;gt; 1(rsaEncryption)

    [0010] 05 00
    (アルゴリズムパラメータ: Type=Null 0byte)

    [0010] 03 81 8d 00 
    (Type=BIT STRING, 141bytes, 最終byteの切り捨て0bit)

      [0010] 30 81 89
      (Type=SEQUENCE, 137bytes)

        [0010] 02 81 81 ..
        (modulus: Type=INTEGER, Length=129bytes)

        [0090] 02 03 01 00 01
        (publicExponent: Type=INTEGER, Length=3bytes, Value=65537)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;digestinfo&#34;&gt;digestInfo&lt;/h3&gt;

&lt;p&gt;署名に使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;digestInfo ::= SEQUENCE {
     digestAlgorithm DigestAlgorithmIdentifier,
     digest Digest 
}

Digest ::= OCTET STRING
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;digestAlgorithmでデータをハッシュ化したものをdigestInfoに詰め、秘密鍵で暗号化したものを署名とし、
公開鍵で複合してdigestと実際のハッシュ値が一致することを確認する。
RSASSA-PKCS1-v1_5では暗号化の前に&lt;code&gt;00 01 ff ff ff .. 00&lt;/code&gt;のパディングを加える。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://people.csail.mit.edu/rivest/Rsapaper.pdf&#34;&gt;A Method for Obtaining Digital Signatures and Public-Key Cryptosystems&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.livedoor.jp/k_urushima/archives/979220.html&#34;&gt;自堕落な技術者の日記 : 図説RSA署名の巻&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bearmini.hatenablog.com/entry/2014/02/05/143510&#34;&gt;RSA 秘密鍵/公開鍵ファイルのフォーマット - bearmini&amp;rsquo;s blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://crypto.stackexchange.com/questions/29115/how-is-oid-2a-86-48-86-f7-0d-parsed-as-1-2-840-113549&#34;&gt;openssl - How is OID 2a 86 48 86 f7 0d parsed as 1.2.840.113549? - Cryptography Stack Exchange&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数</title>
          <link>https://www.sambaiz.net/article/134/</link>
          <pubDate>Mon, 25 Sep 2017 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/134/</guid>
          <description>

&lt;h2 id=&#34;自己情報量&#34;&gt;自己情報量&lt;/h2&gt;

&lt;p&gt;P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-self-information.png&#34; alt=&#34;自己情報量の定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-self-information-graph.png&#34; alt=&#34;自己情報量のグラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;log(P)+log(Q)=log(P*Q)&lt;/code&gt;より加法性がある。
例えば、サイコロで1の目が2回連続で出る(P=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;36&lt;/sub&gt;)情報量(5.16bits)はサイコロで1の目が出る(P=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;)情報量(2.58bits)の2倍と等しい。
確率が高ければ高いほど自己情報量は小さくなり、&lt;code&gt;P(ω)=1&lt;/code&gt;では0bitになる。&lt;/p&gt;

&lt;h2 id=&#34;エントロピー&#34;&gt;エントロピー&lt;/h2&gt;

&lt;p&gt;確率分布Pに従う確率変数Xのエントロピーは以下の式で定義される。情報量の平均。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-entropy.png&#34; alt=&#34;エントロピーの定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これは情報を送る際に必要なビット数の平均の下限になっている。
例えば、Xが1~4の値を(0.8, 0.1, 0.06, 0.04)の確率でとるとする。
4通りなのだからそれぞれ2bits(00, 01, 10, 11)のコードで表すこともできるが、
ほとんど3や4は出ないのだからbit数を偏らせて(0, 10, 110, 111)のコードで表すと
&lt;code&gt;0.8*1 + 0.1*2 + 0.06*3 + 0.04*3 = 1.3bits&lt;/code&gt;まで減らすことができる。
この場合のエントロピーは1.01bitsで、これより小さくすることはできない。&lt;/p&gt;

&lt;h2 id=&#34;カルバック-ライブラー情報量&#34;&gt;カルバック・ライブラー情報量&lt;/h2&gt;

&lt;p&gt;離散確率分布PのQに対するカルバック・ライブラー情報量は以下の式で定義される。連続確率分布では積分する。
Qの自己情報量からPの自己情報量を引いて平均を取ったもので、分布間の距離のように考えることができる。非負の値を取る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-kl.png&#34; alt=&#34;KL情報量の定義&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;交差エントロピー&#34;&gt;交差エントロピー&lt;/h2&gt;

&lt;p&gt;離散確率分布PとQの交差エントロピーは以下の式で定義される。連続確率分布では積分する。
PのエントロピーにPのQに対するKL情報量を足したもの。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-cross-entropy.png&#34; alt=&#34;交差エントロピーの定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これはQの分布に最適化されたコードでPの分布の確率変数の情報を送ってしまった際に必要なビット数の平均の下限になっている。KL情報量が余分な分。機械学習の損失関数に使われる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/191/&#34;&gt;ロジスティック回帰と尤度関数/交差エントロピー誤差と勾配降下法 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Self-information&#34;&gt;Self-information - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&#34;&gt;Kullback–Leibler divergence - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://postd.cc/visual-information-theory-3/&#34;&gt;情報理論を視覚的に理解する (&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;) | コンピュータサイエンス | POSTD&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ニューラルネットワークと活性化関数</title>
          <link>https://www.sambaiz.net/article/133/</link>
          <pubDate>Mon, 18 Sep 2017 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/133/</guid>
          <description>

&lt;p&gt;活性化関数というのは各層での重み掛けバイアス足しのあとに適用する非線形の関数。
これはカーネル法のように空間を変換して線形分離できないデータを線形分離できるようにするはたらきをする。
線形な関数を使うと層を重ねても結局線形のままで、空間もそのまま伸縮するだけなので目的を果たさない。&lt;/p&gt;

&lt;p&gt;バックプロバゲーション(誤差逆伝播法)するために微分できる必要がある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/192/&#34;&gt;MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tensorflowでは以下の活性化関数が&lt;a href=&#34;https://www.tensorflow.org/api_guides/python/nn#Activation_Functions&#34;&gt;用意されている&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;sigmoid-https-www-tensorflow-org-api-docs-python-tf-sigmoid&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/sigmoid&#34;&gt;sigmoid&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-sigmoid.png&#34; alt=&#34;シグモイド関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-sigmoid-f.png&#34; alt=&#34;シグモイド関数の式と微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;値域は(0,1)で&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89&#34;&gt;シグマの語末系ςに似たS字を描く&lt;/a&gt;。
微分係数がそれほど大きくないので何層もこの関数を適用すると、バックプロバゲーションで微分係数を掛けていった結果、勾配が消失する問題がありあまり使われない。値域が(-1,1)で似たグラフを描く&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/tanh&#34;&gt;tanh&lt;/a&gt;(Hyperbolic tangent)もある。&lt;/p&gt;

&lt;h3 id=&#34;softsign-https-www-tensorflow-org-api-docs-python-tf-nn-softsign&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/softsign&#34;&gt;softsign&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softsign.png&#34; alt=&#34;softsign&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softsign-f.png&#34; alt=&#34;softsign関数の式と微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;tanhと比べて漸近線に近づく速度が遅くなっている。
それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。&lt;/p&gt;

&lt;h3 id=&#34;softplus-https-www-tensorflow-org-api-docs-python-tf-nn-softplus&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/softplus&#34;&gt;softplus&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softplus.png&#34; alt=&#34;softplus&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softplus-f.png&#34; alt=&#34;softplus関数の式と微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ReLUに続く。&lt;/p&gt;

&lt;h3 id=&#34;relu-https-www-tensorflow-org-api-docs-python-tf-nn-relu-rectified-linear-unit&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/relu&#34;&gt;ReLU&lt;/a&gt;(Rectified Linear Unit)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-relu.png&#34; alt=&#34;ReLU&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-relu-f.png&#34; alt=&#34;ReLU関数の式と微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;単純だけど最有力。勾配消失も起きにくい。x=0で微分できないが0か1として扱われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def deriv_relu(x):
    return np.where(x &amp;gt; 0, 1, 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;softplusと比べてexpやlogを含まない分高速に計算できるので、
膨大で複雑なデータセットに対して多くの層を用いることができる。&lt;/p&gt;

&lt;p&gt;0以下は等しく0になるため、学習中に落ちてしまうとニューロンが死んでしまう。
これを避けるため0以下のとき&lt;code&gt;y = exp(x) - 1&lt;/code&gt;にする&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/elu&#34;&gt;ELU&lt;/a&gt;(Exponential Linear Unit)
というのもある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-elu.png&#34; alt=&#34;ELU&#34; /&gt;&lt;/p&gt;

&lt;p&gt;比較的起きにくいとはいえ、層を深くすると勾配消失する可能性は高まる。
活性化関数ごとに異なる重みの初期値によってこれを緩和でき、ReLUでは入力次元数によるHe Initializationというのが提案されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rng = np.random.RandomState(1234)
n_in = 10 # 入力次元数
rng.uniform(
    low=-np.sqrt(6/n_in),
    high=+np.sqrt(6/n_in),
    size=5
) # He Initialization
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/towards-data-science/activation-functions-and-its-types-which-is-better-a9a5310cc8f&#34;&gt;Activation functions and it’s types-Which is better?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.orsj.or.jp/archive2/or60-4/or60_4_191.pdf&#34;&gt;最適化から見たディープラーニングの考え方&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf&#34;&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Rectifier_(neural_networks)&#34;&gt;Rectifier (neural networks) - Wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った</title>
          <link>https://www.sambaiz.net/article/132/</link>
          <pubDate>Sun, 10 Sep 2017 23:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/132/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34;&gt;Puppeteer&lt;/a&gt;でHeadless Chromeを動かすコードを
Lambda上で動かすStarter Kitを作った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppeteer-lambda-starter-kit&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;chromeの準備&#34;&gt;Chromeの準備&lt;/h2&gt;

&lt;p&gt;Puppeteerのインストール時に落としてくるChromeをLambda上で動かそうとしても
Lambdaにないshared libraryに依存しているため失敗する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;error while loading shared libraries: libpangocairo-1.0.so.0: cannot open shared object file: No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lambda上でHeadless Chromeを動かす例がないか調べたら&lt;a href=&#34;https://github.com/adieuadieu/serverless-chrome&#34;&gt;serverless-chrome&lt;/a&gt;というのがあって、
Headless用の設定でChromeをビルドしていた。
ほかには&lt;a href=&#34;https://github.com/graphcool/chromeless&#34;&gt;chromeless&lt;/a&gt;というのもあるけど
これはserverless-chromeに
&lt;a href=&#34;https://github.com/graphcool/chromeless/blob/master/serverless/serverless.yml#L46&#34;&gt;依存している&lt;/a&gt;。
最小構成でPuppeteerを使いたかったので、今回はこれらを使わず一から作ることにした。&lt;/p&gt;

&lt;p&gt;serverless-chromeにもビルドしたものが置いてあるが、少しバージョンが古いようだったので最新版でビルドした。
基本的には&lt;a href=&#34;https://github.com/adieuadieu/serverless-chrome/tree/master/chrome&#34;&gt;書いてある&lt;/a&gt;
通りやればうまくいく。他のプロセスとのshared memoryとして/dev/shmを使っているのを、/tmpに&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/blob/master/chrome/buildChrome.sh#L20&#34;&gt;置き換える&lt;/a&gt;
ようにしないと、実行時の&lt;code&gt;page.goto()&lt;/code&gt;で&lt;code&gt;Failed Provisional Load: ***, error_code: -12&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;ビルドしたheadless_shellには問題になった依存は含まれていないようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ldd headless_shell 
	linux-vdso.so.1 =&amp;gt;  (0x00007ffcb6fed000)
	libpthread.so.0 =&amp;gt; /lib64/libpthread.so.0 (0x00007f5f17dbe000)
	libdl.so.2 =&amp;gt; /lib64/libdl.so.2 (0x00007f5f17bba000)
	librt.so.1 =&amp;gt; /lib64/librt.so.1 (0x00007f5f179b1000)
	libnss3.so =&amp;gt; /usr/lib64/libnss3.so (0x00007f5f17692000)
	libnssutil3.so =&amp;gt; /usr/lib64/libnssutil3.so (0x00007f5f17466000)
	libsmime3.so =&amp;gt; /usr/lib64/libsmime3.so (0x00007f5f1723e000)
	libnspr4.so =&amp;gt; /lib64/libnspr4.so (0x00007f5f17001000)
	libexpat.so.1 =&amp;gt; /lib64/libexpat.so.1 (0x00007f5f16dd8000)
	libfontconfig.so.1 =&amp;gt; not found
	libfreetype.so.6 =&amp;gt; /usr/lib64/libfreetype.so.6 (0x00007f5f16b3b000)
	libm.so.6 =&amp;gt; /lib64/libm.so.6 (0x00007f5f16839000)
	libstdc++.so.6 =&amp;gt; /usr/lib64/libstdc++.so.6 (0x00007f5f16533000)
	libgcc_s.so.1 =&amp;gt; /lib64/libgcc_s.so.1 (0x00007f5f1631d000)
	libc.so.6 =&amp;gt; /lib64/libc.so.6 (0x00007f5f15f5b000)
	/lib64/ld-linux-x86-64.so.2 (0x000055ba0af5e000)
	libplc4.so =&amp;gt; /lib64/libplc4.so (0x00007f5f15d55000)
	libplds4.so =&amp;gt; /lib64/libplds4.so (0x00007f5f15b51000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Puppetterで落としてくる普通のChromeは&lt;a href=&#34;http://docs.aws.amazon.com/lambda/latest/dg/limits.html&#34;&gt;Lambdaの制限&lt;/a&gt;の50MBを超えていたが、
ビルドしたものはぎりぎり超えていないのでパッケージに含められるようになった。
PuppeteerのChromeは環境変数&lt;code&gt;PUPPETEER_SKIP_CHROMIUM_DOWNLOAD&lt;/code&gt;を設定することで&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/blob/2817130fe099a7431e98c20ce1f44c6e547d4ca9/docs/api.md#puppeteer&#34;&gt;含めないようにできる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;他のパッケージのサイズによっては50MBを超えてしまうこともあるので、
パッケージに含めず&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/blob/v0.9.0/src/util.js#L62&#34;&gt;S3からダウンロード&lt;/a&gt;できるようにもした。&lt;/p&gt;

&lt;p&gt;いずれの場合も最終的な置き先はLambdaで唯一書き込める&lt;code&gt;/tmp&lt;/code&gt;になる。
この領域は512MBまで使えるので展開してもまだ余裕がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: EROFS: read-only file system, open &#39;node_modules/puppeteer/.local-chromium&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chromeのlaunch時のoption&#34;&gt;ChromeのLaunch時のOption&lt;/h2&gt;

&lt;p&gt;いろいろ試した結果、最低限必要だったのはこのあたり。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;exports.launchOptionForLambda = [
    // error when launch(); No usable sandbox! Update your kernel
    &#39;--no-sandbox&#39;,
    // error when launch(); Failed to load libosmesa.so
    &#39;--disable-gpu&#39;, 
    // freeze when newPage()
    &#39;--single-process&#39;
];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーは分かりづらいものが多く、ときにはエラーすら出ずに止まってしまうこともある。
デバッグの際はdumpioを有効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const browser = await puppeteer.launch({
    ...
    dumpio: !!util.DEBUG,
});  
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;babel&#34;&gt;Babel&lt;/h2&gt;

&lt;p&gt;現在のLambdaのNodeのバージョンはv6.10.3。
&lt;a href=&#34;http://node.green/&#34;&gt;node.green&lt;/a&gt;によるとES2015は99%対応していて、ES2016もべき乗演算子(2 ** 3 = 8)以外は対応しているが、ES2017のasync/awaitは7.6からなので、8系に対応するまではbabelにかける必要がある。
ちなみにPuppeteerは6.4以降で&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/tree/master/utils/node6-transform&#34;&gt;動く&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev babel-cli babel-preset-env
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/babel/babel-preset-env&#34;&gt;babel-preset-env&lt;/a&gt;
.babelrcはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat .babelrc
{
  &amp;quot;presets&amp;quot;: [
    [&amp;quot;env&amp;quot;, {
      &amp;quot;targets&amp;quot;: {
        &amp;quot;node&amp;quot;: &amp;quot;6.10&amp;quot;
      }
    }]
  ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Headless Chromeでファイルをダウンロードする</title>
          <link>https://www.sambaiz.net/article/131/</link>
          <pubDate>Sun, 03 Sep 2017 18:51:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/131/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://chromedevtools.github.io/devtools-protocol/&#34;&gt;Chrome DevTools Protocol&lt;/a&gt;に
Experimentalだけど&lt;a href=&#34;https://chromedevtools.github.io/devtools-protocol/tot/Page#method-setDownloadBehavior&#34;&gt;Page.setDownloadBehavior&lt;/a&gt;
というのがあったので、これを呼んでファイルをダウンロードしてみた。&lt;/p&gt;

&lt;p&gt;今回は公式のDevToolsのNode API、&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34;&gt;Puppeteer&lt;/a&gt;を使うけど、
setDownloadBehaviorを送るAPIはまだ&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/blob/64124df62f4e81999fe1a0ab45c6fb9718a0e413/lib/Page.js#L29&#34;&gt;なく&lt;/a&gt;、直接clientを取ってsendするので他のライブラリでもやることは変わらないと思う。
Puppeteerのインストールの際にChromiumも入る。setDownloadBehaviorは現行Chromeの60では&lt;a href=&#34;https://bugs.chromium.org/p/chromium/issues/detail?id=696481&#34;&gt;対応していない&lt;/a&gt;ようだけど、62が入ったのでなんとかなりそう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add puppeteer
$ find . -name &amp;quot;*chrome*&amp;quot;
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_100_percent.pak
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_200_percent.pak
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、このChromeをLambda上で実行しようとすると失敗する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/132/&#34;&gt;Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ChromeでChromeをダウンロードしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const puppeteer = require(&#39;puppeteer&#39;),
      fs        = require(&#39;fs&#39;);

const headless     = true,
      downloadPath = &#39;./Download&#39;;

(async () =&amp;gt; {
  const browser = await puppeteer.launch({headless: headless});
  
  const page = await browser.newPage();
  await page._client.send(
    &#39;Page.setDownloadBehavior&#39;,
    {behavior : &#39;allow&#39;, downloadPath: downloadPath}
  );

  await page.goto(&#39;https://www.google.co.jp/chrome/browser/desktop/index.html&#39;, {waitUntil: &#39;networkidle&#39;});
  await page.click(&#39;a.download-button&#39;);  /* Chromeをダウンロード         */
  await page.click(&#39;button#eula-accept&#39;); /* 利用規約に同意してインストール */

  await waitDownloadComplete(downloadPath)
        .catch((err) =&amp;gt; console.error(err));
 
  console.log(&#39;finished&#39;);
  browser.close();  
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイルがダウンロードできたかどうかは.crdownloadのありなしで判定している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const waitDownloadComplete = async (path, waitTimeSpanMs = 1000, timeoutMs = 60 * 1000) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {

    const wait = (waitTimeSpanMs, totalWaitTimeMs) =&amp;gt; setTimeout(
      () =&amp;gt; isDownloadComplete(path).then(
        (completed) =&amp;gt; {
          if (completed) { 
            resolve();
          } else {

            const nextTotalTime = totalWaitTimeMs + waitTimeSpanMs;
            if (nextTotalTime &amp;gt;= timeoutMs) {
              reject(&#39;timeout&#39;);
            }

            const nextSpan = Math.min(
              waitTimeSpanMs,
              timeoutMs - nextTotalTime
            );
            wait(nextSpan, nextTotalTime);
          }           
        }
      ).catch(
        (err) =&amp;gt; { reject(err); }
      ),
      waitTimeSpanMs
    );
    
    wait(waitTimeSpanMs, 0);
  }); 
}

const isDownloadComplete = async (path) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {
    fs.readdir(path, (err, files) =&amp;gt; {
      if (err) {
        reject(err);
      } else {
        if (files.length === 0) {
          resolve(false);
          return;
        }
        for(let file of files){

          // .crdownloadがあればダウンロード中のものがある
          if (/.*\.crdownload$/.test(file)) { 
            resolve(false);
            return;
          }
        }
        resolve(true);
      }
    });
  });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Headlessだと何もでてこないのでうまくいったか良くわからないけど、
指定したパスを見にいったらちゃんと保存されていた。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;機能的には近い立ち位置の&lt;a href=&#34;http://www.nightmarejs.org/&#34;&gt;NightmareJS&lt;/a&gt;の方も、
v1の&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;、現行v2の&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;を経て
v3ではHeadless Chromeに&lt;a href=&#34;https://github.com/segmentio/nightmare/issues/1092&#34;&gt;なるかもしれない&lt;/a&gt;。
速いし、ウィンドウがないので&lt;a href=&#34;https://en.wikipedia.org/wiki/Xvfb&#34;&gt;xvfb(X virtual framebuffer)&lt;/a&gt;も&lt;a href=&#34;https://developers.google.com/web/updates/2017/04/headless-chrome&#34;&gt;必要ない&lt;/a&gt;し良さそうなんだけど、
現在のChrome DevTools ProtocolではNightmareの既存APIをサポートできなかったり、
Puppeteerとの住み分けはどうするのって話になっているみたいだ。&lt;/p&gt;

&lt;p&gt;現状Nightmare自体にダウンロード機能は含まれていないが、
Electronの&lt;a href=&#34;https://github.com/electron/electron/blob/master/docs-translations/jp/api/download-item.md&#34;&gt;will-download&lt;/a&gt;イベントを
ハンドリングする
&lt;a href=&#34;https://github.com/rosshinkley/nightmare-download-manager&#34;&gt;nightmare-download-manager&lt;/a&gt;や
&lt;a href=&#34;https://github.com/rosshinkley/nightmare-inline-download&#34;&gt;nightmare-inline-download&lt;/a&gt;
といったライブラリがある。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>floatとdoubleの表現と精度</title>
          <link>https://www.sambaiz.net/article/130/</link>
          <pubDate>Sat, 02 Sep 2017 12:47:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/130/</guid>
          <description>

&lt;p&gt;IEEE754の仕様。記憶が薄れていたのでまとめておく。&lt;/p&gt;

&lt;p&gt;float(32bit)は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1bit: 符号&lt;/li&gt;
&lt;li&gt;8bit: 指数部(exponent)&lt;/li&gt;
&lt;li&gt;23bit: 仮数部(fraction)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;double(64bit)は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1bit: 符号&lt;/li&gt;
&lt;li&gt;11bit: 指数部&lt;/li&gt;
&lt;li&gt;52bit: 仮数部&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;で表される。&lt;/p&gt;

&lt;p&gt;例えば-5.25(2進で-101.01)を表す場合、
&lt;code&gt;-1.0101 * 2^2&lt;/code&gt;のように&lt;code&gt;±1.xxxx * 2^n&lt;/code&gt;の形にして、負なら符号を1に、指数部を正(1~254or2046)にするため
nに127or1023のバイアスを足した数を入れ、仮数部にはxxxxの部分の後ろに0を詰めたのをそのまま入れる。
したがって、-5.25のfloatは&lt;code&gt;1 10000001 01010000000000000000000&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;ただし、指数部が0のときは仮数部xxxxに対して&lt;code&gt;0.xxxx * 2^-126or1022&lt;/code&gt;のように解釈し、
0や指数部で表すことができる数(2^-126or1022)より絶対値が小さい非正規化数を表すことができるようになっている。
また、Infinityはそれぞれ(255or2047,0)、NaNは(255or2047,0以外)で表す。&lt;/p&gt;

&lt;p&gt;精度は仮数部の大きさに依存し、floatが10進で&lt;code&gt;Math.log10(2 ** 23) = 6.92&lt;/code&gt;桁で、doubleが&lt;code&gt;Math.log10(2 ** 52) = 15.65&lt;/code&gt;桁。JavaScriptの数値はdoubleなので
&lt;code&gt;1234567890.1234569&lt;/code&gt;が&lt;code&gt;1234567890.123457&lt;/code&gt;になり16~17桁目で値がおかしくなることが確認できる。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/IEEE_754&#34;&gt;IEEE 754 - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Double-precision_floating-point_format&#34;&gt;Double-precision floating-point format - Wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pythonのインタラクティブな可視化ライブラリBokehでグラフを描く</title>
          <link>https://www.sambaiz.net/article/129/</link>
          <pubDate>Sat, 26 Aug 2017 18:02:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/129/</guid>
          <description>

&lt;p&gt;Pythonの可視化というと&lt;a href=&#34;https://github.com/matplotlib/matplotlib&#34;&gt;matplotlib&lt;/a&gt;や、
そのラッパーの&lt;a href=&#34;https://github.com/mwaskom/seaborn&#34;&gt;seaborn&lt;/a&gt;、
データ解析ライブラリの&lt;a href=&#34;https://github.com/pandas-dev/pandas&#34;&gt;Pandas&lt;/a&gt;にもそういう機能があるけど、
これらが表示するのが静止画なのに対して、&lt;a href=&#34;https://github.com/bokeh/bokeh&#34;&gt;Bokeh&lt;/a&gt;はD3.jsで描画し、
拡大したりスクロールしたり、動的に何か表示することができる。Bokehはカメラのボケ。
似たようなのに&lt;a href=&#34;https://github.com/plotly/plotly.py&#34;&gt;Plotly&lt;/a&gt;というのもあるけど、
こちらはPandasと同じpydata.orgドメインで、スターが多い。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/jupyter/datascience-notebook/&#34;&gt;jupyter/datascience-notebook&lt;/a&gt;イメージにもBokehがインストールされている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d -p 8888:8888 jupyter/datascience-notebook start-notebook.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;簡単なグラフを描く&#34;&gt;簡単なグラフを描く&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;output_notebook&lt;/code&gt;でJupytor Notebokに出力する。ファイルに出力する場合は&lt;code&gt;ouput_file&lt;/code&gt;を呼ぶ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from bokeh.plotting import figure
from bokeh.io import output_notebook, show
output_notebook()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.figure&#34;&gt;figure()&lt;/a&gt;でplotするFigureオブジェクトを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p = figure(
    title=&amp;quot;Hoge&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;,
    y_axis_type=&amp;quot;log&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.line&#34;&gt;line()&lt;/a&gt;で線をつないで&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.circle&#34;&gt;circle()&lt;/a&gt;で円を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
y0 = [i**2 for i in x]
y1 = [10**i for i in x]
y2 = [10**(i**2) for i in x]

p.line(x, x, legend=&amp;quot;y=x&amp;quot;)
p.circle(x, x, legend=&amp;quot;y=x&amp;quot;, fill_color=&amp;quot;white&amp;quot;, size=8)

p.line(x, y0, legend=&amp;quot;y=x^2&amp;quot;, line_width=3)

p.line(x, y1, legend=&amp;quot;y=10^x&amp;quot;, line_color=&amp;quot;red&amp;quot;)
p.circle(x, y1, legend=&amp;quot;y=10^x&amp;quot;, fill_color=&amp;quot;red&amp;quot;, line_color=&amp;quot;red&amp;quot;, size=6)

p.line(x, y2, legend=&amp;quot;y=10^x^2&amp;quot;, line_color=&amp;quot;orange&amp;quot;, line_dash=&amp;quot;4 4&amp;quot;)

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129.png&#34; alt=&#34;折れ線グラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.vbar&#34;&gt;vbar()&lt;/a&gt;で
縦棒を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]

p.vbar(x, top=x, width=0.2, bottom=0, color=&amp;quot;#CAB2D6&amp;quot;)

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-vbar.png&#34; alt=&#34;棒グラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.annular_wedge&#34;&gt;annular_wedge()&lt;/a&gt;で弧を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import math
from collections import namedtuple

Data = namedtuple(&#39;Data&#39;, (&#39;name&#39;, &#39;value&#39;, &#39;color&#39;))
rates = [Data(&amp;quot;A&amp;quot;, 0.6, &amp;quot;#7FC97F&amp;quot;), Data(&amp;quot;B&amp;quot;, 0.4, &amp;quot;#DD1C77&amp;quot;)]

start_angle = 0

for rate in rates:
    p.annular_wedge(
            x=0, 
            y=0,
            inner_radius=0.2, 
            outer_radius=0.5, 
            start_angle=math.pi * 2 * start_angle, 
            end_angle=math.pi * 2 * (start_angle + rate.value),
            color=rate.color,
            legend=rate.name
    )
    start_angle += rate.value

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-c.png&#34; alt=&#34;円グラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;複数のグラフを連動させる&#34;&gt;複数のグラフを連動させる&lt;/h2&gt;

&lt;p&gt;複数のfigureでrangeを合わせると連動する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]

left = figure(
    title=&amp;quot;Left&amp;quot;, 
    width=400,
    y_axis_type=&amp;quot;log&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;
)

right = figure(
    title=&amp;quot;Right&amp;quot;, 
    width=400,
    x_range=left.x_range,
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;
)

left.line(x, x, legend=&amp;quot;y=x&amp;quot;)
right.line(x, x, legend=&amp;quot;y=x&amp;quot;)

p = gridplot([[left, right]])

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129.gif&#34; alt=&#34;連動するグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ホバーで情報を表示する&#34;&gt;ホバーで情報を表示する&lt;/h2&gt;

&lt;p&gt;figureのtoolsにhoverを追加し、sourceに&lt;code&gt;CoulumnDataSource&lt;/code&gt;を渡して、
以下のように&lt;code&gt;select_one(HoverTool)&lt;/code&gt;するとホバーで情報を表示できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import math
from bokeh.models import HoverTool, ColumnDataSource
from collections import namedtuple

p = figure(
    title=&amp;quot;Hoge&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;,
    tools=&amp;quot;hover,save&amp;quot;
)

Data = namedtuple(&#39;Data&#39;, (&#39;name&#39;, &#39;value&#39;, &#39;color&#39;))
rates = [Data(&amp;quot;A&amp;quot;, 0.6, &amp;quot;#7FC97F&amp;quot;), Data(&amp;quot;B&amp;quot;, 0.4, &amp;quot;#DD1C77&amp;quot;)]

start_angle = 0

for rate in rates:
    
    source = ColumnDataSource(
        data=dict(
            value=[rate.value],
        )
    )
    
    p.annular_wedge(
            x=0, 
            y=0,
            inner_radius=0.2, 
            outer_radius=0.5, 
            start_angle=math.pi * 2 * start_angle, 
            end_angle=math.pi * 2 * (start_angle + rate.value),
            color=rate.color,
            legend=rate.name,
            source=source
    )
    start_angle += rate.value

p.select_one(HoverTool).tooltips = [
    (&amp;quot;value&amp;quot;, &amp;quot;@value&amp;quot;)
]

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-c2.png&#34; alt=&#34;Tooltips&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
          <link>https://www.sambaiz.net/article/128/</link>
          <pubDate>Thu, 24 Aug 2017 09:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/128/</guid>
          <description>

&lt;h2 id=&#34;hiveとは-https-cwiki-apache-org-confluence-display-hive-home-home-apachehive&#34;&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/Home#Home-ApacheHive&#34;&gt;Hiveとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Hadoop上で動くデータウェアハウスソフトウェア。
SQLを拡張したHiveQLを書くとデータを処理するMapReduceやSpark、Tezのジョブが生成される。
クエリの実行に時間がかかり、耐障害性があるのでDailyやHourlyのバッチで使われる。&lt;/p&gt;

&lt;p&gt;ちなみにAthenaにも使われている&lt;a href=&#34;https://prestodb.io/&#34;&gt;Presto&lt;/a&gt;
はタスクを並列に実行し、中間データをメモリ上に持つことで数分以内に結果が得られるので
ダッシュボードなどの用途でアドホックに使える。中間データが大きいと&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/top-10-performance-tuning-tips-for-amazon-athena/&#34;&gt;時間がかかったり失敗する&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/5-5-x/topics/impala.html&#34;&gt;Impala&lt;/a&gt;はさらに速いけどメモリの消費が激しいらしい。&lt;/p&gt;

&lt;h2 id=&#34;cloudera-docker-imageを起動する-https-www-cloudera-com-documentation-enterprise-latest-topics-quickstart-docker-container-html&#34;&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/latest/topics/quickstart_docker_container.html&#34;&gt;Cloudera Docker Imageを起動する&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Cloudera Docker Imageには&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html&#34;&gt;CDH&lt;/a&gt;: Clouderaのディストリビューション。Hadoop、Hive、SparkなどのOSSで構成されている。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/latest/topics/cloudera_manager.html&#34;&gt;Cloudera Manager&lt;/a&gt;: CDHクラスタを管理する。無料のExpressと有料のEnterpriseで使える機能に&lt;a href=&#34;https://www.cloudera.com/content/dam/www/static/documents/datasheets/cloudera-enterprise-datasheet.pdf&#34;&gt;差がある&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;が含まれていて、これを起動すると諸々立ち上がる。CDHクラスタを組むのはサポートされていないようなのでテスト用らしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull cloudera/quickstart:latest
$ docker run --hostname=quickstart.cloudera --privileged=true -itd -p 8888 -p 7180 -p 80 cloudera/quickstart /usr/bin/docker-quickstart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;80がチュートリアルで、8888がHadoopのWeb UIの&lt;a href=&#34;https://github.com/cloudera/hue&#34;&gt;Hue&lt;/a&gt;、7180がCloudera Manager。Dockerに割り当てるメモリが2GBだと&lt;code&gt;Failed to contact an active Resource Manager&lt;/code&gt;になってしまったので4GBにした。&lt;/p&gt;

&lt;h2 id=&#34;hiveのテーブルを作成して実行する&#34;&gt;Hiveのテーブルを作成して実行する&lt;/h2&gt;

&lt;p&gt;チュートリアルでは&lt;a href=&#34;http://sqoop.apache.org/&#34;&gt;Sqoop&lt;/a&gt;を使ってDBから取り込んでいるんだけど、
今回はjsonのログのテーブルを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sqoop import-all-tables \
    -m 1 \
    --connect jdbc:mysql://localhost:3306/retail_db \
    --username=retail_dba \
    --password=cloudera \
    --compression-codec=snappy \
    --as-parquetfile \
    --warehouse-dir=/user/hive/warehouse \
    --hive-import
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JSONを扱うにはStringから&lt;code&gt;LATERAL VIEW json_tuple(json_str, &amp;quot;field1&amp;quot;, &amp;quot;field2&amp;quot;) j AS field1, field2&lt;/code&gt;のように実行時にパースする方法と、&lt;a href=&#34;https://github.com/rcongiu/Hive-JSON-Serde&#34;&gt;JSON SerDe&lt;/a&gt;で最初から別カラムにいれる方法があるが、今回はSerDeでやる。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;json_tupleを使う場合、配列はStringになってしまうのでこれをArrayにするには便利なUDF(User-Defined Functions)をまとめた&lt;a href=&#34;https://github.com/klout/brickhouse&#34;&gt;brickhouse&lt;/a&gt;のjson_splitが使える。例えば、&lt;code&gt;SELECT col1 FROM table LATERAL VIEW explode(json_split(&#39;[&amp;quot;a&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;c&amp;quot; ]&#39;)) a as ja&lt;/code&gt;のようにするとArrayになったStringがexplodeしてtableの各列に3種のカラムjaが並ぶ。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;col1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;ja&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;c&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;c&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Arrayが空の場合にexplodeすると消滅してしまうので、LEFT JOINのように残すにはarray(null)に加工してやるとよい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CASE WHEN size(json_split(arr)) &amp;gt; 0 THEN json_split(arr) ELSE array(null) END AS arr
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;JSON SerDeのjarを持ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://www.congiu.net/hive-json-serde/1.3.8/cdh5/json-serde-1.3.8-jar-with-dependencies.jar &amp;gt; /usr/lib/hive/lib/json-serde-1.3.8-jar-with-dependencies.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリはHueから実行できて、初期ユーザー名とパスワードはどちらもcloudera。&lt;/p&gt;

&lt;p&gt;CREATE TABLEはこんな感じ。スキーマ情報はmetastoreに入る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ADD JAR /usr/lib/hive/lib/json-serde-1.3.8-jar-with-dependencies.jar;

CREATE EXTERNAL TABLE jinrou (
        participant ARRAY&amp;lt;STRUCT&amp;lt;user_id:INT,role:STRING,team:STRING&amp;gt;&amp;gt;,
        win_team    STRING,
        ts          STRING
      )
      ROW FORMAT SERDE &#39;org.openx.data.jsonserde.JsonSerDe&#39;
      WITH SERDEPROPERTIES ( &amp;quot;mapping.ts&amp;quot; = &amp;quot;timestamp&amp;quot; )
      LOCATION &#39;/user/cloudera/jinrou&#39;;
      
ADD JAR /usr/lib/hive/lib/hive-contrib.jar;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指定したLOCATIONにログをアップロードする。これもHueからできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;participant&amp;quot;:[{&amp;quot;user_id&amp;quot;:1,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:2,&amp;quot;role&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;wolf&amp;quot;},{&amp;quot;user_id&amp;quot;:3,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:4,&amp;quot;role&amp;quot;:&amp;quot;medium&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:5,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:6,&amp;quot;role&amp;quot;:&amp;quot;fortune-teller&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;}],&amp;quot;win_team&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;timestamp&amp;quot;:&amp;quot;2017-08-21T01:23:45.678+0900&amp;quot;}
{&amp;quot;participant&amp;quot;:[{&amp;quot;user_id&amp;quot;:3,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:4,&amp;quot;role&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;wolf&amp;quot;},{&amp;quot;user_id&amp;quot;:1,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:2,&amp;quot;role&amp;quot;:&amp;quot;medium&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:6,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:5,&amp;quot;role&amp;quot;:&amp;quot;fortune-teller&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;}],&amp;quot;win_team&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;timestamp&amp;quot;:&amp;quot;2017-08-21T02:34:56.789+0900&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SELECT文を実行すると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT user_id, role, SUM(is_win)/COUNT(1) AS wp FROM (
  SELECT 
    par.user_id,
    par.role, 
    CASE WHEN par.role = win_team THEN 1 ELSE 0 END AS is_win
    FROM jinrou
  LATERAL VIEW explode(participant) p AS par
) j GROUP BY user_id, role;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参照できている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;user_id,role,wp
1,villager,0.5
2,medium,0.0
2,wolf,1.0
3,villager,0.5
4,medium,0.0
4,wolf,0.0
5,fortune-teller,0.0
5,villager,0.0
6,fortune-teller,0.0
6,villager,1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テーブルの定義よりjsonのフィールドが多いと無視されて、ないものはNULLになる。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog-jp.treasuredata.com/entry/2014/07/10/150250&#34;&gt;『Prestoとは何か，Prestoで何ができるか』 - トレジャーデータ（Treasure Data）公式ブログ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://recruit.gmo.jp/engineer/jisedai/blog/presto_spark_hive/&#34;&gt;スケールアウト可能なSQLエンジンのベンチマークテスト：Presto vs Spark SQL vs Hive on Tez | GMOインターネット 次世代システム研究室&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CloudflareでカスタムドメインのGitHub PagesにHTTPSでアクセスできるようにする</title>
          <link>https://www.sambaiz.net/article/127/</link>
          <pubDate>Mon, 21 Aug 2017 23:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/127/</guid>
          <description>

&lt;p&gt;このサイトはGitHub Pagesでカスタムドメインsambaiz.netを設定して、
Apex Domain(sambaiz.net)に&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain/&#34;&gt;Aレコード&lt;/a&gt;を登録して運用していたのだけれど、これだとカスタムドメインの証明書を置けないのでHTTPSでアクセスすると警告が出てしまう。
いい加減HTTPだと許されない風潮になってきたのでCloudflareを前に挟んでHTTPSでアクセスできるようにした。
ついでにCNAMEを登録できないApex Domain(sambaiz.net)をやめてwww.sambaiz.netに向ける。&lt;/p&gt;

&lt;h2 id=&#34;dnsの設定をする&#34;&gt;DNSの設定をする&lt;/h2&gt;

&lt;p&gt;Cloudflareでドメインを入れると既存のDNS Recordsを読み込むので必要に応じて修正する。
Cloudflareでは&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/200169056-CNAME-Flattening-RFC-compliant-support-for-CNAME-at-the-root&#34;&gt;CNAME Flattening&lt;/a&gt;によってApex Domainにも設定上ではCNAMEを与えることができ、内部でAレコードに解決してくれる。
そのためApex Domainをそのまま使っても実は問題ないのだけど、今後のために変えておく。
www.sambaiz.netにGitHub PagesのCNAMEを設定し、sambaiz.net(@)にはwww.sambaiz.netをCNAMEとして設定した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/127.png&#34; alt=&#34;DNS設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;あとGitHub Pagesの方のカスタムドメインもwww.sambaiz.netにした。
wwwを設定するとApex Domainでアクセスしたときにリダイレクトするように&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain-and-www-subdomain/&#34;&gt;なっている&lt;/a&gt;ので
既存のリンクが切れたり混在することはない。&lt;/p&gt;

&lt;p&gt;指示された&lt;code&gt;*.ns.cloudflare.com&lt;/code&gt;のようなCloudflareのネームサーバーをドメインに設定する。
さくらの場合、Apex Domainのネームサーバーはゾーン表示ではなくWHOIS情報のところから変更できる。
設定してしばらくするとCloudflareを通してアクセスが飛び警告なくHTTPSでアクセスできるようになる。
証明書は共有のものになっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/127-2.png&#34; alt=&#34;共有証明書&#34; /&gt;&lt;/p&gt;

&lt;p&gt;正常にアクセスできることを確認できたら今HTTPになっている画像やリンクもHTTPSにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ find . -name &#39;.git*&#39; -prune -o -name &#39;public&#39; -prune -o -name &#39;static&#39; -prune -o -type d -o -print | xargs sed -i &amp;quot;&amp;quot; &amp;quot;s/http:\/\/sambaiz.net/https:\/\/www.sambaiz.net/g&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cloudflareの機能&#34;&gt;Cloudflareの機能&lt;/h2&gt;

&lt;p&gt;Cloudflareにはいくつか&lt;a href=&#34;https://www.cloudflare.com/plans/&#34;&gt;プラン&lt;/a&gt;があって、今回はFreeプランにした。&lt;/p&gt;

&lt;h3 id=&#34;analytics&#34;&gt;Analytics&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;キャッシュされている/ないリクエスト数や帯域、それによる節約量&lt;/li&gt;
&lt;li&gt;ブロックした&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/204191238-What-are-the-types-of-Threats-&#34;&gt;脅威&lt;/a&gt;の数&lt;/li&gt;
&lt;li&gt;何人/どこの国からアクセスが来たか&lt;/li&gt;
&lt;li&gt;コンテンツ(HTML/CSS/PNG)ごとのリクエストの割合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;などがわかる。FreeだとWeb TrafficやGeographyが直近24時間より短いスパンで取れない。&lt;/p&gt;

&lt;h3 id=&#34;crypto&#34;&gt;Crypto&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudflare.com/ssl/&#34;&gt;SSL&lt;/a&gt;まわりの設定。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Flexible: クライアントとCloudflareはHTTPS、CloudflareとオリジンサーバーはHTTPで通信する。&lt;/li&gt;
&lt;li&gt;Full: デフォルト。Cloudflareとオリジンサーバーの通信もHTTPSで行うが、証明書の検証は行われない。&lt;/li&gt;
&lt;li&gt;Full(Strict) 証明書の検証も行う。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;から選択する。Business以上のPlanだと共有の証明書ではなく独自のものを上げることもできる。&lt;/p&gt;

&lt;p&gt;HTTPで来たらHTTPSにリダイレクトさせるのと、ブラウザでHTTPをHTTPSに置き換える&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/Security/HTTP_Strict_Transport_Security&#34;&gt;HTTP Strict Transport Security(HSTS)&lt;/a&gt;
の設定もある。
HSTSを設定するときに出るように
将来HTTPSをサポートしなくなった場合、HSTSの期限が残っているブラウザからはアクセスできなくなるので注意。
まあ今後HTTPのみに戻すということは考えにくいのだけど、推奨の有効期限は6ヶ月になっている。
あとNo-Sniff Headerの設定もここにあって、これをオンのままにしておくとContent-Typeがtext/cssでない
styleやJavaScriptのMIME Typeでないscriptのリクエストは&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options&#34;&gt;ブロック&lt;/a&gt;しXSSを防ぐ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Strict-Transport-Security: max-age=15552000
X-Content-Type-Options: nosniff
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;firewall&#34;&gt;Firewall&lt;/h3&gt;

&lt;p&gt;IPアドレスや国でブロックしたりとか。Pro以上のプランだと&lt;a href=&#34;https://www.cloudflare.com/waf/&#34;&gt;Web Application Firewall&lt;/a&gt;を有効にできる。&lt;/p&gt;

&lt;h3 id=&#34;speed&#34;&gt;Speed&lt;/h3&gt;

&lt;p&gt;JS/CSS/HTMLを自動でMinifyしたり、モバイルの場合リダイレクトさせたりできる。
Proプランでは画像を最適化してくれる。&lt;/p&gt;

&lt;h3 id=&#34;caching&#34;&gt;Caching&lt;/h3&gt;

&lt;p&gt;キャッシュをパージしたり、どのレベルでキャッシュするかの設定など。&lt;/p&gt;

&lt;h3 id=&#34;page-rules&#34;&gt;Page Rules&lt;/h3&gt;

&lt;p&gt;URL単位でルールを設定できる。example.com/hoge/*は静的なページなのでHTMLもキャッシュするとか。
3つルールが作れて、5つ追加するのに月5ドル。&lt;/p&gt;

&lt;h3 id=&#34;network&#34;&gt;Network&lt;/h3&gt;

&lt;p&gt;最大アップロードサイズやWebSocketを有効にするかなどの設定。
ユーザーのIPアドレスをTrue-Client-IPに乗せるのはEnterpriseプランが必要。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HDFS(Hadoop Distributed File System)とは</title>
          <link>https://www.sambaiz.net/article/126/</link>
          <pubDate>Mon, 14 Aug 2017 22:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/126/</guid>
          <description>

&lt;h2 id=&#34;hdfsとは&#34;&gt;HDFSとは&lt;/h2&gt;

&lt;p&gt;Hadoopの分散ファイルシステム。
Hadoopの抽象化されたファイルシステム実装の一つで、他の実装にはLocal fileやS3などがある。
データのサイズが大きい場合に特に問題になるディスクI/Oを分散させ、
読み書きする最小の単位であるブロックサイズを大きくしシークのコストを減らすことで
スループットを高めている。
ディスクI/Oがどれくらい遅いかというと、
シークがデータセンター内での往復の通信の20倍(10ms)、
1MBの読み込みが40倍の時間(20ms)&lt;a href=&#34;https://gist.github.com/jboner/2841832&#34;&gt;かかる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;一方、小さなデータに低レイテンシでアクセスするというのは得意でなく、
また、1ファイルあたり150バイトのメタデータがNameNodeのメモリ上に乗っかるため大量のファイルを扱うのは大変。
あとデータは追記しかできない。&lt;/p&gt;

&lt;h3 id=&#34;namenodeとdatanode&#34;&gt;NameNodeとDataNode&lt;/h3&gt;

&lt;p&gt;クラスタの中にはおおよそ2種類のノードがあって、
ブロックがあるいくらかのDataNodeと、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ファイルの階層とメタデータ&lt;/li&gt;
&lt;li&gt;どのDataNodeにそのファイルのブロックがあるか&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の情報が含まれる&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;fsimage(メタデータのスナップショット)&lt;/li&gt;
&lt;li&gt;edit log(fsimageに含まれていない変更ログ)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を保存する、名前空間に単一のNameNodeがある。
もう一つSecondary NameNodeというのがあって、これはedit logが大きくならないよう
定期的にedit logをfsimageにマージするもの。&lt;/p&gt;

&lt;p&gt;NameNodeが機能停止すると読み書きできなくなってしまうので、
新しいNameNodeを立てる必要がある。
その際fsimageにedit logを適用して状態を復元するため
これらのファイルを別のファイルシステムにバックアップなどして失われないようにする。&lt;/p&gt;

&lt;p&gt;巨大なクラスタだとNameNodeを立ち上げるのに30分以上かかることもあるため、
Secondary NameNodeの代わりにStandby NameNodeを立ててHigh Availabilityにすることもできる。
Standby NameNodeはNameNodeと共有ストレージでedit logを共有し、最新の状態がメモリ上に乗っているので
NameNodeが死んだと判断されてから数十秒ほどで切り替えることができる。&lt;/p&gt;

&lt;h2 id=&#34;書き込みと読み込み&#34;&gt;書き込みと読み込み&lt;/h2&gt;

&lt;h3 id=&#34;書き込み&#34;&gt;書き込み&lt;/h3&gt;

&lt;p&gt;ファイルシステムがNameNodeとやりとりして、ファイルが存在しているか、パーミッションがあるかを確認し、問題なければFSDataOutputStreamをクライアントに返す。
書き込むデータはdata queueにまず入って、
どのDataNodeに書き込むかはDataStreamerというのがNameNodeとやりとりして決める。
レプリカの設定数分DataNodeが選ばれ、順に書き込まれるようDataNode間でパイプラインを作る。
正常に書き込まれたDetaNodeからはack packetが返ってくるのでこれはack queryに入れて
全て正しく書き込まれたことが確認できたら消す。
失敗したDataNodeがあったら、そこに中途半端に書き込まれた分を復活したら消すようにして、パイプラインから除き
新しいパイプラインを作る。&lt;/p&gt;

&lt;h3 id=&#34;読み込み&#34;&gt;読み込み&lt;/h3&gt;

&lt;p&gt;ファイルシステムがNameNodeにファイルのブロックがどこにあるかを聞く。
NameNodeは、ブロックがあるDataNodeをクライアントからネットワークトポロジ的に近い順にソートしてアドレスを返す。
ファイルシステムはそのアドレスが含まれたFSDataInputStreamをクライアントに返して、クライアントが順にreadしていく。&lt;/p&gt;

&lt;h2 id=&#34;singlenode-clusterで動かす-http-hadoop-apache-org-docs-current-hadoop-project-dist-hadoop-common-singlecluster-html&#34;&gt;&lt;a href=&#34;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html&#34;&gt;SingleNode Clusterで動かす&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ yum --enablerepo=epel -y install pdsh
$ echo $JAVA_HOME
/usr/lib/jvm/jre
$ wget http://ftp.jaist.ac.jp/pub/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz
$ tar xvzf hadoop-2.7.3.tar.gz 
$ cd hadoop-2.7.3
$ bin/hadoop version
Hadoop 2.7.3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトのファイルシステムをHDFSにしてレプリカを1にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vi etc/hadoop/core-site.xml
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
...
&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;

$ vi etc/hadoop/hdfs-site.xml
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
...
&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hadoopデーモンを起動/終了させるためにsshできるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa
$ cat ~/.ssh/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
$ ssh localhost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs namenode -format
$ sbin/start-dfs.sh
localhost: starting namenode, ...
localhost: starting datanode, ...
0.0.0.0: starting secondarynamenode, ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ディレクトリやファイルを作成して参照する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs dfs -mkdir /home
$ bin/hdfs dfs -mkdir /user/ec2-user
$ echo &#39;aaaaa&#39; &amp;gt; hoge
$ bin/hdfs dfs -put hoge ./
$ bin/hdfs dfs -put hoge ./
put: `hoge&#39;: File exists

$ bin/hdfs dfs -appendToFile hoge hoge
$ bin/hdfs dfs -ls ./
Found 1 items
-rw-r--r--   1 ec2-user supergroup         12 2017-08-14 13:44 hoge

$ bin/hdfs dfs -cat hoge
aaaaa
aaaaa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Filesystem check utilityを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs fsck ./ -files -blocks
Connecting to namenode via http://localhost:50070/fsck?ugi=ec2-user&amp;amp;files=1&amp;amp;blocks=1&amp;amp;path=%2Fuser%2Fec2-user
FSCK started by ec2-user (auth:SIMPLE) from /127.0.0.1 for path /user/ec2-user at Mon Aug 14 13:44:48 UTC 2017
/user/ec2-user &amp;lt;dir&amp;gt;
/user/ec2-user/hoge 12 bytes, 1 block(s):  OK
0. BP-478671077-172.31.3.159-1502715364675:blk_1073741825_1002 len=12 repl=1

Status: HEALTHY
 Total size:	12 B
 Total dirs:	1
 Total files:	1
 Total symlinks:		0
 Total blocks (validated):	1 (avg. block size 12 B)
 Minimally replicated blocks:	1 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	0 (0.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	1
 Average block replication:	1.0
 Corrupt blocks:		0
 Missing replicas:		0 (0.0 %)
 Number of data-nodes:		1
 Number of racks:		1
FSCK ended at Mon Aug 14 13:44:48 UTC 2017 in 2 milliseconds
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://shop.oreilly.com/product/0636920033448.do&#34;&gt;Hadoop: The Definitive Guide, 4th Edition&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.cloudera.com/blog/2014/03/a-guide-to-checkpointing-in-hadoop/&#34;&gt;A Guide to Checkpointing in Hadoop – Cloudera Engineering Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PythonのLintとFormatter</title>
          <link>https://www.sambaiz.net/article/125/</link>
          <pubDate>Fri, 11 Aug 2017 14:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/125/</guid>
          <description>

&lt;h2 id=&#34;yapf-https-github-com-google-yapf&#34;&gt;&lt;a href=&#34;https://github.com/google/yapf&#34;&gt;YAPF&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;スタイルに沿って整形してくれる、Goでいう&lt;code&gt;go fmt&lt;/code&gt;みたいなもの。
デフォルトはPython公式のスタイルガイド&lt;a href=&#34;https://www.python.org/dev/peps/pep-0008/&#34;&gt;PEP8&lt;/a&gt;でフォーマットされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install yapf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VSCodeでPythonを書くときは、
&lt;a href=&#34;https://github.com/DonJayamanne/pythonVSCode/wiki&#34;&gt;Pythonプラグイン&lt;/a&gt;
を入れてこんな設定をWorkspaceのconfigに入れておいて、
保存した時にフォーマットがかかるようにすると快適。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;editor.formatOnSave&amp;quot;: true,
&amp;quot;python.formatting.provider&amp;quot;: &amp;quot;yapf&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lint&#34;&gt;Lint&lt;/h2&gt;

&lt;p&gt;YAPFでフォーマットされた以下のコードにLintをかける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class FizzBuzz:
    def __init__(self, start=0):
        self.num = start

    def __iter__(self):
        return self

    def __next__(self):
        self.num += 1
        if self.num % 15 == 0:
            return &amp;quot;FizzBuzz&amp;quot;
        if self.num % 3 == 0:
            return &amp;quot;Fizz&amp;quot;
        if self.num % 5 == 0:
            return &amp;quot;Buzz&amp;quot;
        return self.num


if __name__ == &amp;quot;__main__&amp;quot;:
    fizzBuzz = FizzBuzz()
    for i in range(100):
        print(next(fizzBuzz))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pylint&#34;&gt;Pylint&lt;/h3&gt;

&lt;p&gt;Pythonプラグインではデフォルトで&lt;a href=&#34;https://github.com/PyCQA/pylint/&#34;&gt;Pylint&lt;/a&gt;が使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install pylint
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必要ならパスをUserのconfigでパスを指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;python.linting.pylintPath&amp;quot;: &amp;quot;***&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コマンドライン上で実行するとこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pylint main.py 
No config file found, using default configuration
************* Module main
C: 22, 0: Final newline missing (missing-final-newline)
C:  1, 0: Missing module docstring (missing-docstring)
C:  1, 0: Missing class docstring (missing-docstring)
R:  1, 0: Too few public methods (0/2) (too-few-public-methods)
C: 20, 4: Invalid constant name &amp;quot;fizzBuzz&amp;quot; (invalid-name)

-----------------------------------
Your code has been rated at 7.22/10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指摘された項目を見ると下の二つは余計かなと感じる。
そんな場合、コメントで&lt;code&gt;# pylint: disable=invalid-name&lt;/code&gt;のように書くか、
設定ファイル&lt;code&gt;pylintrc&lt;/code&gt;のdisableに追加すれば無視できる。
&lt;code&gt;--generate-rc-file&lt;/code&gt;でとても長い設定ファイルが生成される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pylint --generate-rcfile &amp;gt; pylintrc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;10点満点にしたのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot;
FizzBuzz main
&amp;quot;&amp;quot;&amp;quot;

class FizzBuzz: # pylint: disable=too-few-public-methods
    &amp;quot;&amp;quot;&amp;quot;
    FizzBuzz is incrementing a number and
    if the number is divisible by both 3 and 5, output &amp;quot;FizzBuzz&amp;quot;,
    if divisible by 3, &amp;quot;Fizz&amp;quot;,
    if divisible by 5, &amp;quot;Buzz&amp;quot;,
    Otherwise, output the number.
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(self, start=0):
        self.num = start

    def __iter__(self):
        return self

    def __next__(self):
        self.num += 1
        if self.num % 15 == 0:
            return &amp;quot;FizzBuzz&amp;quot;
        if self.num % 3 == 0:
            return &amp;quot;Fizz&amp;quot;
        if self.num % 5 == 0:
            return &amp;quot;Buzz&amp;quot;
        return self.num

if __name__ == &amp;quot;__main__&amp;quot;:
    fizzBuzz = FizzBuzz() # pylint: disable=invalid-name
    for i in range(100):
        print(next(fizzBuzz))
        
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;flake8-https-github-com-pycqa-flake8&#34;&gt;&lt;a href=&#34;https://github.com/PyCQA/flake8&#34;&gt;Flake8&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;他のLintとしてFlake8を使うこともできる。これは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/PyCQA/pyflakes&#34;&gt;PyFlakes&lt;/a&gt;: エラー&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/PyCQA/pycodestyle&#34;&gt;pycodestyle&lt;/a&gt;(元pep8): PEP8&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pycqa/mccabe&#34;&gt;Ned Batchelder&amp;rsquo;s McCabe script&lt;/a&gt;: &lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%BE%AA%E7%92%B0%E7%9A%84%E8%A4%87%E9%9B%91%E5%BA%A6&#34;&gt;循環的複雑度&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のチェッカーを合わせたもの。
&lt;a href=&#34;https://github.com/PyCQA/flake8-docstrings&#34;&gt;docstring&lt;/a&gt;は別に入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install flake8 flake8_docstrings
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VSCodeでの設定はこんな感じ。Pylintと同時に使うこともできなくはない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;python.linting.pylintEnabled&amp;quot;: false
&amp;quot;python.linting.flake8Enabled&amp;quot;: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同じコードにLintをかけてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ flake8 main.py
main.py:1:1: D100 Missing docstring in public module
main.py:1:1: D101 Missing docstring in public class
main.py:2:1: D102 Missing docstring in public method
main.py:5:1: D105 Missing docstring in magic method
main.py:8:1: D105 Missing docstring in magic method
main.py:22:30: W292 no newline at end of file
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;flake8-docstringは&lt;a href=&#34;https://www.python.org/dev/peps/pep-0257/&#34;&gt;PEP257&lt;/a&gt;に忠実にチェックしているのでちょっと厳しめ。&lt;code&gt;# flake8: noqa:D105&lt;/code&gt;のように無視することもできるし、
設定ファイル&lt;code&gt;.flake8&lt;/code&gt;に書くこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[flake8]
ignore = D105
exclude =
    .git,
    __pycache__,
    build,
    dist
max-complexity = 10
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;加えてmypyを使うとType Hintsによる型の整合性をチェックできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/188/&#34;&gt;PythonのType Hintsとmypy - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
          <link>https://www.sambaiz.net/article/124/</link>
          <pubDate>Sun, 06 Aug 2017 23:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/124/</guid>
          <description>

&lt;p&gt;AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリ&lt;a href=&#34;https://github.com/deepmind/sonnet&#34;&gt;Sonnet&lt;/a&gt;を使う。
当初はPython2しか対応していないようだったけど、今は3にも対応している。&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;TensorFlowを使うライブラリはほかにもいくつかあるのだけど、
&lt;a href=&#34;https://github.com/fchollet/keras&#34;&gt;Keras&lt;/a&gt;と比較してみると、
KerasがTensorFlowの部分を完全にラップしているのに対して、
Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。&lt;/p&gt;

&lt;p&gt;SonnetとTensorFlowとPython3入りイメージをDockerHubに&lt;a href=&#34;https://hub.docker.com/r/sambaiz/sonnet/&#34;&gt;上げた&lt;/a&gt;。
Dockerfileは&lt;a href=&#34;https://github.com/sambaiz/docker-sonnet&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;内容は基本的にREADME通りだけど、
configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。
あとは、&lt;a href=&#34;https://github.com/deepmind/sonnet/issues/25&#34;&gt;TensorFlowのビルドに使われているGCCのバージョンが古い&lt;/a&gt;ようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに&lt;code&gt;--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;&lt;/code&gt;を付けている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet
$ docker logs sonnet
...
   Copy/paste this URL into your browser when you connect for the first time,
    to login with a token:
        http://localhost:8888/?token=*****
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sonnet as snt
import tensorflow as tf
snt.resampler(tf.constant([0.]), tf.constant([0.]))
# =&amp;gt; &amp;lt;tf.Tensor &#39;resampler/Resampler:0&#39; shape=(1,) dtype=float32&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mnist&#34;&gt;MNIST&lt;/h2&gt;

&lt;p&gt;TensorFlowのチュートリアルのデータを使って、畳み込みを行わない簡単なMNISTをやってみる。
このデータはtrain、validation、test用に最初から&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/contrib/learn/python/learn/datasets/base.py#L37&#34;&gt;分かれていて&lt;/a&gt;、
それぞれピクセル濃度配列の画像データと、その画像がどの数字なのかを表すone-hot vectorのラベルを&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/contrib/learn/python/learn/datasets/mnist.py#L105&#34;&gt;含んでいる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)
train, validation, test = mnist
print(train.images[0]) # ピクセルの濃度を[0,1]の値で表した配列: [0, 0, ..., 0.41568631  0.6156863, 0.99607849, ...]
print(len(train.images[0])) # 28 * 28 = 784
print(train.labels[0]) # 正解のみ1のone-hot vector: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]
images, labels = mnist.train.next_batch(100)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sonnetではニューラルネットワークの一部をModuleとして表現し、それらをTensorFlowの計算グラフに接続していく。
Moduleはグラフに複数回接続することができ、中の変数は共有される。
素のTensorFlowだと&lt;a href=&#34;https://www.tensorflow.org/programmers_guide/variable_scope&#34;&gt;変数のスコープ&lt;/a&gt;を作って共有するのに
reuse=Trueで&lt;code&gt;tf.variable_scope&lt;/code&gt;して&lt;code&gt;tf.get_variable&lt;/code&gt;したりするけど、そのあたりは抽象化されているので
&lt;code&gt;tf.Variable&lt;/code&gt;を含むような処理はModuleで行う。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/deepmind/sonnet/blob/v1.8/sonnet/python/modules/basic.py&#34;&gt;Linear Module&lt;/a&gt;は
重みの乗算とバイアスの加算をするもの。
これに&lt;code&gt;tf.Sigmoid&lt;/code&gt;のような活性化関数を適用するのを繰り返し、最後に出力層とつなげるとMulti Layer Perceptronを構築できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sonnet as snt
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

FLAGS = tf.flags.FLAGS

tf.flags.DEFINE_integer(&amp;quot;hidden_size&amp;quot;, 100, &amp;quot;Size of hidden layer.&amp;quot;)
tf.flags.DEFINE_integer(&amp;quot;output_size&amp;quot;, 10, &amp;quot;Size of output layer.&amp;quot;)

mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)

x = tf.placeholder(tf.float32, [None, 784])
y_ = tf.placeholder(tf.float32, [None, 10])
lin_to_hidden = snt.Linear(output_size=FLAGS.hidden_size, name=&#39;inp_to_hidden&#39;)
hidden_to_out = snt.Linear(output_size=FLAGS.output_size, name=&#39;hidden_to_out&#39;)
mlp = snt.Sequential([lin_to_hidden, tf.sigmoid, hidden_to_out, tf.nn.softmax])
y = mlp(x)
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(1000):
        images, labels = mnist.train.next_batch(100)
        sess.run(train_step, feed_dict={x: mnist.train.images, y_: mnist.train.labels})
    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
    # =&amp;gt; 0.9307
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;moduleを作る&#34;&gt;Moduleを作る&lt;/h2&gt;

&lt;p&gt;Moduleを作るには&lt;code&gt;snt.AbstractModule&lt;/code&gt;を継承し、
スーパークラスのコンストラクタを呼んで、グラフに接続されるたびに呼ばれる&lt;code&gt;_build&lt;/code&gt;メソッドを実装する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class MyMLP(snt.AbstractModule):
  &amp;quot;&amp;quot;&amp;quot;test mlp module&amp;quot;&amp;quot;&amp;quot;
  def __init__(self, hidden_size, output_size,
               nonlinearity=tf.sigmoid, name=&amp;quot;my_mlp&amp;quot;):
    &amp;quot;&amp;quot;&amp;quot;hidden_size &amp;amp; output_size is required&amp;quot;&amp;quot;&amp;quot;
    super(MyMLP, self).__init__(name=name)
    self._hidden_size = hidden_size
    self._output_size = output_size
    self._nonlinearity = nonlinearity
  
  def _build(self, inputs):
    &amp;quot;&amp;quot;&amp;quot;Compute output Tensor from input Tensor.&amp;quot;&amp;quot;&amp;quot;
    lin_to_hidden = snt.Linear(output_size=self._hidden_size, name=&#39;inp_to_hidden&#39;)
    hidden_to_out = snt.Linear(output_size=self._output_size, name=&#39;hidden_to_out&#39;)
    return snt.Sequential([lin_to_hidden, self._nonlinearity, hidden_to_out, tf.nn.softmax])(inputs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このModuleを使うとこんな感じ。
&lt;a href=&#34;https://github.com/deepmind/sonnet/blob/v1.8/sonnet/examples/dataset_shakespeare.py#L177&#34;&gt;example&lt;/a&gt;のように
データセットもModuleにすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)

mymlp = MyMLP(hidden_size=FLAGS.hidden_size, output_size=FLAGS.output_size)

x = tf.placeholder(tf.float32, [None, 784])
y_ = tf.placeholder(tf.float32, [None, 10])
y = mymlp(x)
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(1000):
        images, labels = mnist.train.next_batch(100)
        sess.run(train_step, feed_dict={x: mnist.train.images, y_: mnist.train.labels})
    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
    # =&amp;gt; 0.9307
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsをTypeScriptで書く</title>
          <link>https://www.sambaiz.net/article/123/</link>
          <pubDate>Sat, 29 Jul 2017 19:34:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/123/</guid>
          <description>

&lt;p&gt;公式の&lt;a href=&#34;https://github.com/Microsoft/TypeScript-Node-Starter&#34;&gt;TypeScript-Node-Starter&lt;/a&gt;から始めてもいいけど、依存が少し余分なので一から作ることにした。&lt;/p&gt;

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/typescript-nodejs-sample&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev typescript tslint tslint-microsoft-contrib jest ts-jest @types/jest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;package-json&#34;&gt;package.json&lt;/h2&gt;

&lt;p&gt;scriptsとテストフレームワーク&lt;a href=&#34;https://facebook.github.io/jest/&#34;&gt;Jest&lt;/a&gt;の設定を追加。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;devDependencies&amp;quot;: {
    ...
    &amp;quot;typescript&amp;quot;: &amp;quot;^2.4.2&amp;quot;
  },
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;start&amp;quot;: &amp;quot;npm run build &amp;amp;&amp;amp; node dist/app.js&amp;quot;,
    &amp;quot;build&amp;quot;: &amp;quot;npm run lint &amp;amp;&amp;amp; tsc&amp;quot;,
    &amp;quot;test&amp;quot;: &amp;quot;jest --forceExit&amp;quot;,
    &amp;quot;lint&amp;quot;: &amp;quot;tslint -c tslint.json -p tsconfig.json --type-check&amp;quot;
  },
  &amp;quot;jest&amp;quot;: {
    &amp;quot;transform&amp;quot;: {
      &amp;quot;^.+\\.ts$&amp;quot;: &amp;quot;./node_modules/ts-jest/preprocessor.js&amp;quot;
    },
    &amp;quot;testRegex&amp;quot;: &amp;quot;/test/.*\\.test\\.(ts|js)$&amp;quot;,
    &amp;quot;moduleFileExtensions&amp;quot;: [
      &amp;quot;ts&amp;quot;,
      &amp;quot;js&amp;quot;
    ],
    &amp;quot;testEnvironment&amp;quot;: &amp;quot;node&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tsconfig-json-https-www-typescriptlang-org-docs-handbook-tsconfig-json-html&#34;&gt;&lt;a href=&#34;https://www.typescriptlang.org/docs/handbook/tsconfig-json.html&#34;&gt;tsconfig.json&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;公式のそのまま。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;compilerOptions&amp;quot;: {
        &amp;quot;module&amp;quot;: &amp;quot;commonjs&amp;quot;,
        &amp;quot;target&amp;quot;: &amp;quot;es6&amp;quot;,
        &amp;quot;noImplicitAny&amp;quot;: true,
        &amp;quot;moduleResolution&amp;quot;: &amp;quot;node&amp;quot;,
        &amp;quot;sourceMap&amp;quot;: true,
        &amp;quot;outDir&amp;quot;: &amp;quot;dist&amp;quot;,
        &amp;quot;baseUrl&amp;quot;: &amp;quot;.&amp;quot;,
        &amp;quot;paths&amp;quot;: {
            &amp;quot;*&amp;quot;: [
                &amp;quot;node_modules/*&amp;quot;,
                &amp;quot;src/types/*&amp;quot;
            ]
        }
    },
    &amp;quot;include&amp;quot;: [
        &amp;quot;src/**/*&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tslint-json-https-palantir-github-io-tslint-usage-tslint-json&#34;&gt;&lt;a href=&#34;https://palantir.github.io/tslint/usage/tslint-json/&#34;&gt;tslint.json&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;MSでも使われているらしいルールを使うことにする。
結構厳しくて&lt;code&gt;console.log&lt;/code&gt;なんかもエラーになるので必要に応じてruleを追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;extends&amp;quot;: &amp;quot;tslint-microsoft-contrib&amp;quot;,
    &amp;quot;rules&amp;quot;: {
        &amp;quot;no-console&amp;quot;: [&amp;quot;&amp;quot;],
        &amp;quot;no-relative-imports&amp;quot;: false,
        &amp;quot;no-http-string&amp;quot;: false,
        &amp;quot;no-backbone-get-set-outside-model&amp;quot;: false
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使うパッケージをインストール&#34;&gt;使うパッケージをインストール&lt;/h2&gt;

&lt;p&gt;本体と型。&lt;/p&gt;

&lt;p&gt;以前は型ファイルを持ってくるのにtsdとかtypingsが使われていたけど
今は&lt;a href=&#34;https://github.com/DefinitelyTyped/DefinitelyTyped&#34;&gt;DefinelyTyped&lt;/a&gt;の内容が
npmの@types/~に&lt;a href=&#34;https://github.com/Microsoft/types-publisher&#34;&gt;上がる&lt;/a&gt;ようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add express
$ yarn add --dev @types/express
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;コードを書く&#34;&gt;コードを書く&lt;/h2&gt;

&lt;p&gt;VSCodeだったらtslintプラグインがあるので入れる。tsとtslintをglobal installする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import * as express from &#39;express&#39;;

/**
 * GET /echo
 * Return a string same as &amp;quot;say&amp;quot; query param.
 */
export function echoApi(req: express.Request, res: express.Response): void {

    const query: { say: string } = &amp;lt;{ say: string }&amp;gt; req.query;
    if (query.say === undefined) {
        res.send(echo(query.say));
    } else {
        res.status(400).send(&#39;&amp;quot;say&amp;quot; query param is required&#39;);
    }
}

/**
 * return a string same as input
 * @param say input (= output)
 */
export function echo(say: string): string {
    return say;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;テストを書く&#34;&gt;テストを書く&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/visionmedia/superagent&#34;&gt;superagent&lt;/a&gt;を使って
HTTPサーバーのテストを行う&lt;a href=&#34;https://github.com/visionmedia/supertest&#34;&gt;supertest&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev supertest @types/supertest
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import * as supertest from &#39;supertest&#39;;
import { app } from &#39;../src/app&#39;;
import { echo } from &#39;../src/echo&#39;;

let request: supertest.SuperTest&amp;lt;supertest.Test&amp;gt;;
beforeAll(() =&amp;gt; {
  request = supertest(app);
});

/**
 * integration test
 */
describe(&#39;GET /echo&#39;, () =&amp;gt; {
  it(&#39;should return a string same as &amp;quot;say&amp;quot; query param&#39;, (): {} =&amp;gt; {
    const say: string = &#39;Aa 1あ&#39;;

    return request
    .get(&#39;/echo&#39;)
    .query({ say: say })
    .expect(200, say);
  });

  it(&#39;is bad request that &amp;quot;say&amp;quot; query param is not given&#39;, (): {} =&amp;gt; {
    return request
    .get(&#39;/echo&#39;)
    .expect(400);
  });
});

/**
 * unit test
 */
describe(&#39;echo&#39;, () =&amp;gt; {
  it(&#39;should return a string same as input&#39;, () =&amp;gt; {
    const say: string = &#39;Aa 1あ&#39;;
    expect(echo(say)).toBe(say);
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;requestしたのをreturnするのを忘れるとテストが無条件で通ってしまうので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm test
...
 PASS  test/echo.test.ts
  GET /echo
    ✓ should return a string same as &amp;quot;say&amp;quot; query param (34ms)
    ✓ is bad request that &amp;quot;say&amp;quot; query param is not given (4ms)
  echo
    ✓ should return a string same as input (1ms)

Test Suites: 1 passed, 1 total
Tests:       3 passed, 3 total
Snapshots:   0 total
Time:        1.601s, estimated 2s
Ran all test suites.
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KubernetesのパッケージマネージャーHelmを使う</title>
          <link>https://www.sambaiz.net/article/122/</link>
          <pubDate>Wed, 26 Jul 2017 01:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/122/</guid>
          <description>&lt;p&gt;Kubernatesが操舵手なのに対して、Helmは舵。
パッケージは&lt;a href=&#34;https://github.com/kubernetes/charts&#34;&gt;Chart&lt;/a&gt;(海図)と呼ばれている。&lt;/p&gt;

&lt;p&gt;ChartにはデフォルトでGoのtemplateで書かれた&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/deployment.yaml&#34;&gt;Manifest&lt;/a&gt;が含まれ、&lt;a href=&#34;https://github.com/helm/charts/blob/master/stable/mysql/values.yaml&#34;&gt;values.yaml&lt;/a&gt;の値を&lt;code&gt;-f values.yaml&lt;/code&gt;や&lt;code&gt;--set key=value&lt;/code&gt;フラグで上書きして適用しインストールすることができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/helm&#34;&gt;Helm&lt;/a&gt;コマンドをインストールする。
今回は&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;minikube&lt;/a&gt;に入れるので立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install kubernetes-helm
$ helm version
Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.5.0&amp;quot;, GitCommit:&amp;quot;012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}

# brew cask install virtualbox minikube
$ minikube version
minikube version: v0.20.0

$ minikube start
Kubectl is now configured to use the cluster.

$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.2&amp;quot;, GitCommit:&amp;quot;922a86cfcd65915a9b2f69f3f193b8907d741d9c&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2017-07-21T19:06:19Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;6&amp;quot;, GitVersion:&amp;quot;v1.6.4&amp;quot;, GitCommit:&amp;quot;d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-06-22T04:31:09Z&amp;quot;, GoVersion:&amp;quot;go1.7.5&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}

$ kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずk8sクラスタ上にHelmの管理サーバーTillerをインストールする必要がある。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;追記(2020-03-11): Helm 3.0からTillerがなくなり &lt;code&gt;helm init&lt;/code&gt; も不要に&lt;a href=&#34;https://helm.sh/blog/helm-3-released/&#34;&gt;なった&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ついでにリポジトリをupdateする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm init
$ ls ~/.helm/
cache		plugins		repository	starters

$ helm repo update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-search&#34;&gt;search&lt;/a&gt;でChartを検索する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm search mysql
NAME                  	VERSION	DESCRIPTION                                       
stable/mysql          	0.2.6  	Fast, reliable, scalable, and easy to use open-...
stable/percona        	0.2.0  	free, fully compatible, enhanced, open source d...
stable/gcloud-sqlproxy	0.1.0  	Google Cloud SQL Proxy                            
stable/mariadb        	0.6.3  	Fast, reliable, scalable, and easy to use open-...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-inspect&#34;&gt;inspect&lt;/a&gt;でChartの情報を見ることができる。
&lt;code&gt;---&lt;/code&gt;の上がChartの情報のChart.yamlで、下がvalues.yaml。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm inspect stable/mysql
description: Fast, reliable, scalable, and easy to use open-source relational database
  system.
engine: gotpl
home: https://www.mysql.com/
icon: https://www.mysql.com/common/logos/logo-mysql-170x115.png
keywords:
- mysql
- database
- sql
maintainers:
- email: viglesias@google.com
  name: Vic Iglesias
name: mysql
sources:
- https://github.com/kubernetes/charts
- https://github.com/docker-library/mysql
version: 0.2.6

---
## mysql image version
## ref: https://hub.docker.com/r/library/mysql/tags/
##
image: &amp;quot;mysql&amp;quot;
imageTag: &amp;quot;5.7.14&amp;quot;

## Specify password for root user
##
## Default: random 10 character string
# mysqlRootPassword: testing

## Create a database user
##
# mysqlUser:
# mysqlPassword:

## Allow unauthenticated access, uncomment to enable
##
# mysqlAllowEmptyPassword: true

## Create a database
##
# mysqlDatabase:

## Specify an imagePullPolicy (Required)
## It&#39;s recommended to change this to &#39;Always&#39; if the image tag is &#39;latest&#39;
## ref: http://kubernetes.io/docs/user-guide/images/#updating-images
##
imagePullPolicy: IfNotPresent

## Persist data to a persitent volume
persistence:
  enabled: true
  ## If defined, volume.beta.kubernetes.io/storage-class: &amp;lt;storageClass&amp;gt;
  ## Default: volume.alpha.kubernetes.io/storage-class: default
  ##
  # storageClass:
  accessMode: ReadWriteOnce
  size: 8Gi

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 256Mi
    cpu: 100m

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mysqlDatabaseの値を渡してinstallしてみる。
パスワードなどをを保持する&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret/&#34;&gt;Secret&lt;/a&gt;、
&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;Persistent Volumes&lt;/a&gt;(PV)を要求する&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;PersistentVolumeClaim&lt;/a&gt;(PVC)と
ServiceとDeploymentが作成された。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{mysqlDatabase: user0db}&#39; &amp;gt; config.yaml
$ helm install -f config.yaml stable/mysql
...
RESOURCES:
==&amp;gt; v1/Secret
NAME                    TYPE    DATA  AGE
pioneering-hydra-mysql  Opaque  2     1s

==&amp;gt; v1/PersistentVolumeClaim
NAME                    STATUS  VOLUME                                    CAPACITY  ACCESSMODES  STORAGECLASS  AGE
pioneering-hydra-mysql  Bound   pvc-9649c097-7088-11e7-8dd5-0800270629d8  8Gi       RWO          standard      1s

==&amp;gt; v1/Service
NAME                    CLUSTER-IP  EXTERNAL-IP  PORT(S)   AGE
pioneering-hydra-mysql  10.0.0.216  &amp;lt;none&amp;gt;       3306/TCP  1s

==&amp;gt; v1beta1/Deployment
NAME                    DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
pioneering-hydra-mysql  1        1        1           0          1s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pods
NAME                                      READY     STATUS    RESTARTS   AGE
pioneering-hydra-mysql-3456603420-0pldk   1/1       Running   0          4m
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/secrets.yaml#L15&#34;&gt;生成された&lt;/a&gt;Secretの値は&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/deployment.yaml#L44&#34;&gt;secretKeyRef&lt;/a&gt;で参照できる。&lt;/p&gt;

&lt;p&gt;PVというのはクラスタにプロビジョニングされる、Podとは独立したライフサイクルを持つVolume。&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#storageclasses&#34;&gt;StorageClass&lt;/a&gt;、ReadWriteOnceのようなアクセスモード、容量を含むPVCでリクエストする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get storageclasses
NAME                 TYPE
standard (default)   k8s.io/minikube-hostpath 
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Secretからrootパスワードを取得し、他のpodから接続できるのとDBが作成されていることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get secret --namespace default pioneering-hydra-mysql -o jsonpath=&amp;quot;{.data.mysql-root-password}&amp;quot; | base64 --decode; echo
******

$ kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il
$ apt-get update &amp;amp;&amp;amp; apt-get install mysql-client -y
$ mysql -h pioneering-hydra-mysql -p
mysql&amp;gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
| user0db            |
+--------------------+
5 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-list&#34;&gt;ls&lt;/a&gt;でインストールしたものを確認でき、
&lt;a href=&#34;https://docs.helm.sh/helm/#helm-delete&#34;&gt;delete&lt;/a&gt;で削除できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm ls
NAME            	REVISION	UPDATED                 	STATUS CHART      	NAMESPACE
pioneering-hydra	1       	Tue Jul 25 00:55:59 2017	DEPLOYEmysql-0.2.6	default  

$ helm delete pioneering-hydra
$ kubectl get secret --namespace default pioneering-hydra-mysql -o jsonpath=&amp;quot;{.data.mysql-root-password}&amp;quot; | base64 --decode; echo
Error from server (NotFound): secrets &amp;quot;pioneering-hydra-mysql&amp;quot; not found
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TerraformでVPCを管理するmoduleを作る</title>
          <link>https://www.sambaiz.net/article/121/</link>
          <pubDate>Sun, 23 Jul 2017 02:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/121/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install terraform
$ terraform -v
Terraform v0.9.11
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;terraformの設定要素&#34;&gt;Terraformの設定要素&lt;/h2&gt;

&lt;h3 id=&#34;provider-https-www-terraform-io-docs-providers-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/index.html&#34;&gt;provider&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;IaaS(e.g. AWS)、PaaS(e.g. Heroku)、SaaS(e.g. CloudFlare)など。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/&#34;&gt;AWS Provider&lt;/a&gt;はこんな感じ。
ここに直接access_keyやsecret_keyを書くこともできるけど、誤って公開されてしまわないように環境変数か
variableで渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;aws&amp;quot; {
  # access_key = &amp;quot;${var.access_key}&amp;quot;
  # secret_key = &amp;quot;${var.secret_key}&amp;quot;
  region = &amp;quot;us-east-1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ export AWS_ACCESS_KEY_ID=&amp;quot;anaccesskey&amp;quot;
$ export AWS_SECRET_ACCESS_KEY=&amp;quot;asecretkey&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;varibale-https-www-terraform-io-docs-configuration-variables-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/variables.html&#34;&gt;varibale&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;CLIでオーバーライドできるパラメーター。typeにはstringのほかにmapやlistを渡すことができ、
何も渡さないとdefault値のものが、それもなければstringになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;key&amp;quot; {
  type    = &amp;quot;string&amp;quot;
  default = &amp;quot;value&amp;quot;
  description = &amp;quot;description&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;値を渡す方法はTF_VAR_をprefixとする環境変数、-var、-var-fileがある。
また、moduleのinputとして渡されることもある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export TF_VAR_somelist=&#39;[&amp;quot;ami-abc123&amp;quot;, &amp;quot;ami-bcd234&amp;quot;]&#39;
$ terraform apply -var foo=bar -var foo=baz
$ terraform apply -var-file=foo.tfvars -var-file=bar.tfvars
$ cat foo.tfvars
foo = &amp;quot;bar&amp;quot;
xyz = &amp;quot;abc&amp;quot;

somelist = [
  &amp;quot;one&amp;quot;,
  &amp;quot;two&amp;quot;,
]

somemap = {
  foo = &amp;quot;bar&amp;quot;
  bax = &amp;quot;qux&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;output-https-www-terraform-io-docs-configuration-outputs-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/outputs.html&#34;&gt;output&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;variableがinputなのに対して、こちらはoutput。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;output &amp;quot;ip&amp;quot; {
  value = &amp;quot;${aws_eip.ip.public_ip}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行した後に取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform apply
...

$ terraform output ip
50.17.232.209
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;resource-https-www-terraform-io-docs-configuration-resources-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/resources.html&#34;&gt;resource&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;物理サーバーやVMのような低レベルのものからDNSレコードのような高レベルのものまで含むインフラのコンポーネント。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_instance&amp;quot; &amp;quot;web&amp;quot; {
  ami           = &amp;quot;ami-408c7f28&amp;quot;
  instance_type = &amp;quot;t1.micro&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;provisioner-https-www-terraform-io-docs-provisioners-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/provisioners/index.html&#34;&gt;provisioner&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;デフォルトでは作成されたときに実行されるコマンド。&lt;code&gt;when = &amp;quot;destroy&amp;quot;&lt;/code&gt;で終了時に実行させることもできる。
on_failureで失敗したときの挙動を設定することができ、デフォルトはコマンド自体が失敗する&amp;rdquo;fail&amp;rdquo;になっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_instance&amp;quot; &amp;quot;web&amp;quot; {
  # ...

  provisioner &amp;quot;local-exec&amp;quot; {
    command = &amp;quot;echo ${self.private_ip_address} &amp;gt; file.txt&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;data-https-www-terraform-io-docs-configuration-data-sources-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/data-sources.html&#34;&gt;data&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;情報を取得する。Terraform以外で作られたリソースのものも取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data &amp;quot;aws_ami&amp;quot; &amp;quot;web&amp;quot; {
  filter {
    name   = &amp;quot;state&amp;quot;
    values = [&amp;quot;available&amp;quot;]
  }

  filter {
    name   = &amp;quot;tag:Component&amp;quot;
    values = [&amp;quot;web&amp;quot;]
  }

  most_recent = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;module-https-www-terraform-io-docs-modules-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/modules/index.html&#34;&gt;module&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;設定をまとめたもの。variableの値を渡すことができ、再利用することができる。
GitHubのurlをsourceに指定することもできる。最初に&lt;code&gt;terraform get&lt;/code&gt;する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module &amp;quot;assets_bucket&amp;quot; {
  source = &amp;quot;./publish_bucket&amp;quot;
  name   = &amp;quot;assets&amp;quot;
}

module &amp;quot;media_bucket&amp;quot; {
  source = &amp;quot;./publish_bucket&amp;quot;
  name   = &amp;quot;media&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# publish_bucket/bucket-and-cloudfront.tf
variable &amp;quot;name&amp;quot; {} # this is the input parameter of the module
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;backend-https-www-terraform-io-docs-backends-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/backends/index.html&#34;&gt;backend&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;0.9.0から&lt;code&gt;terraform remote&lt;/code&gt;の代わりに使われるようになったもの。
管理下のresourceと今の状態を表すtfstateファイルを各自のローカルではなくリモートで一元的に管理する。
オプションではあるけど、applyしたあとにtfstateを上げるのを忘れたりするのを防ぐこともできるため
相当変わった用途でもない限り使わない理由がないと思う。最初に&lt;code&gt;terraform init&lt;/code&gt;する必要がある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/docs/backends/types/s3.html&#34;&gt;S3&lt;/a&gt;に置く場合はこんな感じ。
DynamoDBでロックをかけられる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;mybucket&amp;quot;
    key    = &amp;quot;path/to/my/key&amp;quot;
    region = &amp;quot;us-east-1&amp;quot;
    dynamodb_table = &amp;quot;tflocktable&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;vpcのmoduleを作る&#34;&gt;VPCのmoduleを作る&lt;/h2&gt;

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/terraform-example-vpc&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;community-moduleにも&lt;a href=&#34;https://github.com/terraform-community-modules/tf_aws_vpc&#34;&gt;VPCのモジュール&lt;/a&gt;があるんだけど、今回は自分で作ってみる。&lt;/p&gt;

&lt;p&gt;variableはこんな感じ。同じファイルに書くこともできるが別に分けた方が見やすい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;vpc_name&amp;quot; {
    description = &amp;quot;vpc&#39;s name, e.g. main-vpc&amp;quot;
}

variable &amp;quot;vpc_cidr_block&amp;quot; {
    description = &amp;quot;vpc&#39;s cidr block, e.g. 10.0.0.0/16&amp;quot;
}

variable &amp;quot;public_subnet_cidr_blocks&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;10.0.0.0/24\&amp;quot;, \&amp;quot;10.0.1.0/24\&amp;quot;]&amp;quot;
}

variable &amp;quot;public_subnet_availability_zones&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;ap-northeast-1a\&amp;quot;,\&amp;quot;ap-northeast-1c\&amp;quot;]&amp;quot;
}

variable &amp;quot;private_subnet_cidr_blocks&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;private subnets&#39; cidr blocks, e.g. [\&amp;quot;10.0.2.0/24\&amp;quot;, \&amp;quot;10.0.3.0/24\&amp;quot;]&amp;quot;
}

variable &amp;quot;private_subnet_availability_zones&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;ap-northeast-1a\&amp;quot;,\&amp;quot;ap-northeast-1c\&amp;quot;]&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/vpc.html&#34;&gt;VPC&lt;/a&gt;を作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_vpc&amp;quot; &amp;quot;vpc&amp;quot; {
    cidr_block = &amp;quot;${var.vpc_cidr_block}&amp;quot;
    enable_dns_hostnames = true
    tags {
        Name = &amp;quot;${var.vpc_name}&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にVPCにpublicとprivate用の&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/subnet.html&#34;&gt;サブネット&lt;/a&gt;を、
それぞれcidr_block分作成する。&lt;/p&gt;

&lt;p&gt;vpc_idでvpcのresourceを参照している。したがって、これを実行するためには既にvpcが作られている必要がある。
&lt;code&gt;depends_on&lt;/code&gt;で明示的に依存関係を示すこともできるのだけど、
大抵はそうする必要がなくて&lt;a href=&#34;https://www.terraform.io/intro/getting-started/dependencies.html#implicit-and-explicit-dependencies&#34;&gt;暗黙的な依存関係&lt;/a&gt;をterraformが解決してくれる。
これは&lt;a href=&#34;https://www.terraform.io/docs/commands/graph.html&#34;&gt;terraform graph&lt;/a&gt;で確認できる。&lt;/p&gt;

&lt;p&gt;AZで使われている&lt;a href=&#34;https://www.terraform.io/docs/configuration/interpolation.html#element-list-index-&#34;&gt;element(list, index)&lt;/a&gt;
は要素数以上のindexを渡してもmodの要領で選ぶので数を合わせなくてもよい。&lt;/p&gt;

&lt;p&gt;複数作ったものは&lt;code&gt;aws_subnet.public-subnet.0&lt;/code&gt;のように0から始まるindexで&lt;a href=&#34;https://www.terraform.io/docs/configuration/interpolation.html#attributes-of-other-resources&#34;&gt;参照でき&lt;/a&gt;、
&lt;code&gt;aws_subnet.public-subnet.*.id&lt;/code&gt;のようにすると要素のリストを得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-subnet&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    count = &amp;quot;${length(var.public_subnet_cidr_blocks)}&amp;quot;
    cidr_block = &amp;quot;${var.public_subnet_cidr_blocks[count.index]}&amp;quot;
    availability_zone = &amp;quot;${element(var.public_subnet_availability_zones, count.index)}&amp;quot;
    map_public_ip_on_launch = true
    tags {
        Name = &amp;quot;${var.vpc_name}-public-${element(var.public_subnet_availability_zones, count.index)}&amp;quot;
    }
}

resource &amp;quot;aws_subnet&amp;quot; &amp;quot;private-subnet&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    count = &amp;quot;${length(var.private_subnet_cidr_blocks)}&amp;quot;
    cidr_block = &amp;quot;${var.private_subnet_cidr_blocks[count.index]}&amp;quot;
    availability_zone = &amp;quot;${element(var.private_subnet_availability_zones, count.index)}&amp;quot;
    tags {
        Name = &amp;quot;${var.vpc_name}-private-${element(var.private_subnet_availability_zones, count.index)}&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;public用のサブネットが外と通信できるように&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/internet_gateway.html&#34;&gt;インターネットゲートウェイ&lt;/a&gt;をVPCにアタッチし、
これを登録した&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/route_table.html&#34;&gt;カスタムルートテーブル&lt;/a&gt;
をサブネットに&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/route_table_association.html&#34;&gt;関連付ける&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_internet_gateway&amp;quot; &amp;quot;igw&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    tags {
        Name = &amp;quot;${var.vpc_name}-igw&amp;quot;
    }
}

resource &amp;quot;aws_route_table&amp;quot; &amp;quot;public-route-table&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    route {
        cidr_block = &amp;quot;0.0.0.0/0&amp;quot;
        gateway_id = &amp;quot;${aws_internet_gateway.igw.id}&amp;quot;
    }
    tags {
        Name = &amp;quot;${var.vpc_name}-public-route-table&amp;quot;
    }
}

resource &amp;quot;aws_route_table_association&amp;quot; &amp;quot;route-table-association&amp;quot; {
    count          = &amp;quot;${length(var.public_subnet_cidr_blocks)}&amp;quot;
    subnet_id      = &amp;quot;${element(aws_subnet.public-subnet.*.id, count.index)}&amp;quot;
    route_table_id = &amp;quot;${aws_route_table.public-route-table.id}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;privateのサブネットからはNATして外に出られるようにする。
publicなサブネットにNATする&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-comparison.html&#34;&gt;インスタンス&lt;/a&gt;を立ててもいいけど、&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html&#34;&gt;NATゲートウェイ&lt;/a&gt;を使うと自分でメンテする必要がなくて楽。
&lt;a href=&#34;https://aws.amazon.com/jp/vpc/pricing/&#34;&gt;料金&lt;/a&gt;は時間と通信量による。&lt;/p&gt;

&lt;p&gt;ということで、&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/eip.html&#34;&gt;EIP&lt;/a&gt;を割り当て、
適当なpublicのサブネットに&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/nat_gateway.html&#34;&gt;NATゲートウェイ&lt;/a&gt;を作成する。
ドキュメントに書いてある通り、明示的にigwを依存に入れている。&lt;/p&gt;

&lt;p&gt;NATゲートウェイを&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/main_route_table_assoc.html&#34;&gt;メインルートテーブル&lt;/a&gt;に登録する。
これは&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html#nat-gateway-basics&#34;&gt;AWSのドキュメント&lt;/a&gt;に書いてある通りの構成で、
明示的にルートテーブルと関連付けていないサブネットは
メインルートテーブルに
&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#RouteTables&#34;&gt;関連付けられる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_eip&amp;quot; &amp;quot;nat&amp;quot; {
    vpc = true
}

resource &amp;quot;aws_nat_gateway&amp;quot; &amp;quot;ngw&amp;quot; {
    allocation_id = &amp;quot;${aws_eip.nat.id}&amp;quot;
    subnet_id     = &amp;quot;${aws_subnet.public-subnet.0.id}&amp;quot;
    depends_on = [&amp;quot;aws_internet_gateway.igw&amp;quot;]
}

resource &amp;quot;aws_route_table&amp;quot; &amp;quot;main-route-table&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    route {
        cidr_block = &amp;quot;0.0.0.0/0&amp;quot;
        nat_gateway_id = &amp;quot;${aws_nat_gateway.ngw.id}&amp;quot;
    }
    tags {
        Name = &amp;quot;${var.vpc_name}-main-route-table&amp;quot;
    }
}

resource &amp;quot;aws_main_route_table_association&amp;quot; &amp;quot;main-route-table-association&amp;quot; {
  vpc_id         = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
  route_table_id = &amp;quot;${aws_route_table.main-route-table.id}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行&#34;&gt;実行&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;terraform&amp;quot;
    key    = &amp;quot;terraform.tfstate&amp;quot;
    region = &amp;quot;ap-northeast-1&amp;quot;
  }
}

provider &amp;quot;aws&amp;quot; {
  region = &amp;quot;ap-northeast-1&amp;quot;
}

module &amp;quot;test-vpc&amp;quot; {
  source                            = &amp;quot;./vpc&amp;quot;
  vpc_name                          = &amp;quot;test-vpc&amp;quot;
  vpc_cidr_block                    = &amp;quot;10.0.0.0/16&amp;quot;
  public_subnet_cidr_blocks         = [&amp;quot;10.0.0.0/24&amp;quot;, &amp;quot;10.0.1.0/24&amp;quot;]
  public_subnet_availability_zones  = [&amp;quot;ap-northeast-1a&amp;quot;, &amp;quot;ap-northeast-1c&amp;quot;]
  private_subnet_cidr_blocks        = [&amp;quot;10.0.2.0/24&amp;quot;, &amp;quot;10.0.3.0/24&amp;quot;]
  private_subnet_availability_zones = [&amp;quot;ap-northeast-1a&amp;quot;, &amp;quot;ap-northeast-1c&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;planして問題なければapplyする流れ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform init
$ terraform get
$ terraform plan
+ module.test-vpc.aws_eip.nat
    allocation_id:     &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    association_id:    &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    domain:            &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    instance:          &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface: &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    private_ip:        &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    public_ip:         &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    vpc:               &amp;quot;true&amp;quot;

+ module.test-vpc.aws_internet_gateway.igw
    tags.%:    &amp;quot;1&amp;quot;
    tags.Name: &amp;quot;test-vpc-igw&amp;quot;
    vpc_id:    &amp;quot;${aws_vpc.vpc.id}&amp;quot;

...
Plan: 13 to add, 0 to change, 0 to destroy.

$ terraform apply
...
Apply complete! Resources: 13 added, 0 changed, 0 destroyed.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;applyするとresourceが作成・更新され、tfstateファイルがbackendまたはローカルに出力される。
次回以降はこのtfstateとの差分を取って変更されるので、このファイルがないとまた同じものが作成されてしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;version&amp;quot;: 3,
    &amp;quot;terraform_version&amp;quot;: &amp;quot;0.9.11&amp;quot;,
    &amp;quot;serial&amp;quot;: 1,
    &amp;quot;lineage&amp;quot;: &amp;quot;f97ad997-5a19-4a3d-9921-b553c5f2532b&amp;quot;,
    &amp;quot;modules&amp;quot;: [
        {
            &amp;quot;path&amp;quot;: [
                &amp;quot;root&amp;quot;
            ],
            &amp;quot;outputs&amp;quot;: {},
            &amp;quot;resources&amp;quot;: {},
            &amp;quot;depends_on&amp;quot;: []
        },
        {
            &amp;quot;path&amp;quot;: [
                &amp;quot;root&amp;quot;,
                &amp;quot;test-vpc&amp;quot;
            ],
            &amp;quot;outputs&amp;quot;: {},
            &amp;quot;resources&amp;quot;: {
                &amp;quot;aws_eip.nat&amp;quot;: {
                    &amp;quot;type&amp;quot;: &amp;quot;aws_eip&amp;quot;,
                    &amp;quot;depends_on&amp;quot;: [],
                    &amp;quot;primary&amp;quot;: {
                        &amp;quot;id&amp;quot;: &amp;quot;eipalloc-3046f054&amp;quot;,
                        &amp;quot;attributes&amp;quot;: {
                            &amp;quot;association_id&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;domain&amp;quot;: &amp;quot;vpc&amp;quot;,
                            &amp;quot;id&amp;quot;: &amp;quot;eipalloc-3046f054&amp;quot;,
                            &amp;quot;instance&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;network_interface&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;private_ip&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;public_ip&amp;quot;: &amp;quot;13.114.59.186&amp;quot;,
                            &amp;quot;vpc&amp;quot;: &amp;quot;true&amp;quot;
                        },
                        &amp;quot;meta&amp;quot;: {},
                        &amp;quot;tainted&amp;quot;: false
                    },
                    &amp;quot;deposed&amp;quot;: [],
                    &amp;quot;provider&amp;quot;: &amp;quot;&amp;quot;
                },
                &amp;quot;aws_internet_gateway.igw&amp;quot;: {
                    &amp;quot;type&amp;quot;: &amp;quot;aws_internet_gateway&amp;quot;,
                    &amp;quot;depends_on&amp;quot;: [
                        &amp;quot;aws_vpc.vpc&amp;quot;
                    ],
                    &amp;quot;primary&amp;quot;: {
                        &amp;quot;id&amp;quot;: &amp;quot;igw-d2659bb6&amp;quot;,
                        &amp;quot;attributes&amp;quot;: {
                            &amp;quot;id&amp;quot;: &amp;quot;igw-d2659bb6&amp;quot;,
                            &amp;quot;tags.%&amp;quot;: &amp;quot;1&amp;quot;,
                            &amp;quot;tags.Name&amp;quot;: &amp;quot;test-vpc-igw&amp;quot;,
                            &amp;quot;vpc_id&amp;quot;: &amp;quot;vpc-3cf6a358&amp;quot;
                        },
                        &amp;quot;meta&amp;quot;: {},
                        &amp;quot;tainted&amp;quot;: false
                    },
                    &amp;quot;deposed&amp;quot;: [],
                    &amp;quot;provider&amp;quot;: &amp;quot;&amp;quot;
                },
                ...
            },
            &amp;quot;depends_on&amp;quot;: []
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;planすると変更なしになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan
...
No changes. Infrastructure is up-to-date.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;terafform destroy&lt;/code&gt;で管理下のresourceを消すことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan -destroy
...
Plan: 0 to add, 0 to change, 13 to destroy.

$ terraform destroy
...
Destroy complete! Resources: 13 destroyed.

$ terraform plan
...
Plan: 13 to add, 0 to change, 0 to destroy.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/CkReal/items/1dbbc78888e157a80668&#34;&gt;お金をかけずに、TerraformでAWSのVPC環境を準備する - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensでのUnityアプリケーションのフレームレート</title>
          <link>https://www.sambaiz.net/article/120/</link>
          <pubDate>Sun, 16 Jul 2017 23:32:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/120/</guid>
          <description>

&lt;h2 id=&#34;hololensディスプレイのフレームレート-https-developer-microsoft-com-en-us-windows-mixed-reality-hologram-stability-frame-rate&#34;&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/mixed-reality/hologram_stability#frame_rate&#34;&gt;HoloLensディスプレイのフレームレート&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;HoloLensのディスプレイは60fpsでリフレッシュされるので、アプリケーションもこれに合わせて60fps、
つまり16msごとにOSにイメージを渡せるのがベスト。
ただし、安定して60fpsが実現できないような重いアプリケーションの場合、
変動してしまうよりは下げて安定させる方が良い。&lt;/p&gt;

&lt;p&gt;フレームレートはDevice Portalから確認することができ、キャプチャする際は30fpsに制限される。&lt;/p&gt;

&lt;h2 id=&#34;unityアプリケーションのフレームレート&#34;&gt;Unityアプリケーションのフレームレート&lt;/h2&gt;

&lt;p&gt;Unityでのフレームレートは
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Application-targetFrameRate.html&#34;&gt;Application.targetFrameRate&lt;/a&gt;
で設定できる。デフォルト値は-1で、その場合プラットフォームごとのデフォルト設定が使われる。
何も設定しない状態でHoloLensで動かしたところ60fpsになった。&lt;/p&gt;

&lt;h2 id=&#34;debugビルドでのフレームレートの低下&#34;&gt;Debugビルドでのフレームレートの低下&lt;/h2&gt;

&lt;p&gt;Debugビルドだと&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/4696&#34;&gt;Space Robot Kyle&lt;/a&gt;
だけ描画するだけでもフレームレートが20まで下がってしまった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/119/&#34;&gt;HoloLensで剣振ってみた - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/120-frame.png&#34; alt=&#34;フレームレートの低下&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DebugビルドだったのをRelasseビルドに変えたら60fpsになった。
Relaseビルドではコードの最適化にチェックが入っていたりするんだけど、
その辺りを外してみても特に変わらなかったのでそれではないらしい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensで剣振ってみた</title>
          <link>https://www.sambaiz.net/article/119/</link>
          <pubDate>Sun, 09 Jul 2017 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/119/</guid>
          <description>&lt;p&gt;かつてCardboardでやったようにHoloLensでも剣を振ってみた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/29/&#34;&gt;剣を振るVRゲームを作った - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/119-ss.png&#34; alt=&#34;スクリーンショット&#34; /&gt;&lt;/p&gt;

&lt;p&gt;剣を振ってロボットに当てると爆発する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_gt6ePsqrRc&#34;&gt;動画&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;剣の方は前回と同じくiOSアプリから傾きをBLEで送信している。今回は傘がなかったのでペットボトルにくくりつけた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/119-sword.jpg&#34; alt=&#34;ミニッツメイドソード&#34; /&gt;&lt;/p&gt;

&lt;p&gt;HoloLensのアプリの方はUWPのネイティブプラグインを作った。
Creater&amp;rsquo;s UpdateのAPIがまだ使えなかったので一つ前のAPIを使ってビルドしている。
なお、ペアリングはアプリ内ではなくOSの設定画面から行なっている。
エラーについては原因が分からずハンドリングできていないものもあるけど、つなぎ直すと大抵どうにかなった。
つなぎ直す際はHoloLens側だけではなくiOS側の方の設定も削除する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/105/&#34;&gt;Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ロボットを小さくしているのは近づいても視野角に収まるようにするため。
小さいとどこにいるか分からないので目印を出したほうが良い。
近接武器じゃなきゃ敵に近づかなくてよくなるのでましになるかも。&lt;/p&gt;

&lt;p&gt;上の動画を見れば分かるように、全体的に動きが重くて素でframerateが20ぐらいしか出ていない。
これはReleaseビルドにすると改善された。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/120/&#34;&gt;HoloLensでのUnityアプリケーションのフレームレート - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensのSpartial MappingでNavMeshを生成してランダムにAgentを出現・移動させる</title>
          <link>https://www.sambaiz.net/article/118/</link>
          <pubDate>Sun, 02 Jul 2017 23:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/118/</guid>
          <description>&lt;pre&gt;&lt;code&gt;Unity 5.6.2f1
HoloToolkit v1.5.7.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unity 5.6から動的にNavMeshを生成できるようになったので
HoloLensのSpartial MappingしたものをNavMeshにしてAgentを動かしてみる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/117/&#34;&gt;Unityで動的にNavMeshを生成する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Spartial MappingしたものをNavMeshにするのは以下の記事の&lt;a href=&#34;https://gist.github.com/tarukosu/7bc78c189d8a7de8e94ca3fcfc8f7738#file-spatialmappingnavmesh-cs&#34;&gt;スクリプト&lt;/a&gt;を使った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tarukosu.hatenablog.com/entry/2017/04/23/183546&#34;&gt;HoloLens の空間マップで NavMesh を使ってみる - たるこすの日記&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents&#34;&gt;Unity-Technologies/NavMeshComponents&lt;/a&gt;から
&lt;code&gt;LocalNavMeshBuilder&lt;/code&gt;と&lt;code&gt;NavMeshSourceTag&lt;/code&gt;を持ってきてLocalNavMeshBuilderのObjectを置いておき、
Spartial MappingしたものにNavMeshSourceTagを付けられればExampleと同様にNavMeshにできる。
そこで、このスクリプトではSpatialMappingSourceを取得し、イベントハンドラでNavMeshSourceTagが追加されるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using HoloToolkit.Unity.SpatialMapping;
using UnityEngine;
using HoloToolkit.Unity;

public class SpatialMappingNavMesh : MonoBehaviour
{
    public GameObject SpatialMapping;

    private void Awake()
    {
        var spatialMappingSources = SpatialMapping.GetComponents&amp;lt;SpatialMappingSource&amp;gt;();
        foreach (var source in spatialMappingSources)
        {
            source.SurfaceAdded += SpatialMappingSource_SurfaceAdded;
            source.SurfaceUpdated += SpatialMappingSource_SurfaceUpdated;
        }
    }

    private void SpatialMappingSource_SurfaceAdded(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceObject&amp;gt; e)
    {
        e.Data.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;();
    }

    private void SpatialMappingSource_SurfaceUpdated(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceUpdate&amp;gt; e)
    {
        var navMeshSourceTag = e.Data.New.Object.GetComponent&amp;lt;NavMeshSourceTag&amp;gt;();
        if (navMeshSourceTag == null)
        {
            e.Data.New.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NavMeshのランダムな場所を取得するには、適当なPointを取り、
&lt;a href=&#34;https://docs.unity3d.com/ja/540/ScriptReference/NavMesh.SamplePosition.html&#34;&gt;NavMesh.SamplePosition&lt;/a&gt;で
そこから最も近いNavMeshのPointを取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bool RandomPoint(Vector3 center, float range, out Vector3 result) {
    for (int i = 0; i &amp;lt; 30; i++) {
        Vector3 randomPoint = center + Random.insideUnitSphere * range;
        NavMeshHit hit;
        if (NavMesh.SamplePosition(randomPoint, out hit, 1.0f, NavMesh.AllAreas)) {
            result = hit.position;
            return true;
        }
    }
    result = Vector3.zero;
    return false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;動かすAgentはこんな感じ。こけないようにFreeze Rotationしている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/118.png&#34; alt=&#34;Agentの設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このAgentを出現させて移動させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using UnityEngine;
using UnityEngine.AI;

public class RandomSpawn : MonoBehaviour {

    public GameObject player;
    public GameObject agent;
    public GameObject counter;

    private List&amp;lt;GameObject&amp;gt; spawnedAgents = new List&amp;lt;GameObject&amp;gt;();
    private float interval = 0.0f;

    static int MAX_SPAWN_NUM = 10;
    static float SPAWN_RANGE = 10.0f;

	// Use this for initialization
	void Start () {
        counter.GetComponent&amp;lt;TextMesh&amp;gt;().text = spawnedAgents.Count + &amp;quot;&amp;quot;;
    }

    // Update is called once per frame
    void Update () {

        interval += Time.deltaTime;
        if(interval &amp;gt; 5.0f)
        {
            if (spawnedAgents.Count &amp;lt; MAX_SPAWN_NUM)
            {
                Spawn();
            }
            Move();
            interval = 0.0f;
        }
    }

    void Spawn()
    {
        Vector3 spawnPoint;
        if (GetRandomPosition(player.transform.position, SPAWN_RANGE, out spawnPoint))
        {
            var obj = Instantiate(agent, spawnPoint, Quaternion.identity);
            counter.GetComponent&amp;lt;TextMesh&amp;gt;().text = spawnedAgents.Count + &amp;quot;&amp;quot;;
            spawnedAgents.Add(obj);
        }
    }

    void Move()
    {
        foreach(var agent in spawnedAgents)
        {
            Vector3 next;
            if(GetRandomPosition(agent.transform.position, SPAWN_RANGE, out next)){
                agent.GetComponent&amp;lt;NavMeshAgent&amp;gt;().destination = next;
            }
        }
        
    }

    bool GetRandomPosition(Vector3 center, float range, out Vector3 result)
    {
        for (int i = 0; i &amp;lt; 30; i++)
        {
            Vector3 randomPoint = center + UnityEngine.Random.insideUnitSphere * range;
            NavMeshHit hit;
            if (NavMesh.SamplePosition(randomPoint, out hit, 1.0f, NavMesh.AllAreas))
            {
                result = hit.position;
                return true;
            }
        }
        result = Vector3.zero;
        return false;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと床や壁を認識して移動している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/118.gif&#34; alt=&#34;移動するAgent&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityで動的にNavMeshを生成する</title>
          <link>https://www.sambaiz.net/article/117/</link>
          <pubDate>Sat, 01 Jul 2017 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/117/</guid>
          <description>&lt;p&gt;Unity5.6から動的にNavMeshを生成できるようになった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents&#34;&gt;Unity-Technologies/NavMeshComponents&lt;/a&gt;の
Exampleの2_drop_blankのsceneを開く。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample.png&#34; alt=&#34;Exampleの2_drop_blank&#34; /&gt;&lt;/p&gt;

&lt;p&gt;分断されたCubeの床と、その上に黄色いCylindarと赤いCubeがあって、
クリックしたところに黄色いCylindarが動くんだけど、床がつながっていないのでそのままでは赤いCubeまではたどり着けない。
スペースを押すと目の前に板が出てくるのでこの上を渡って移動することができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample2.png&#34; alt=&#34;スペースを押すと板が出てくる&#34; /&gt;&lt;/p&gt;

&lt;p&gt;板の上がNavMeshとして認識されている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample3.png&#34; alt=&#34;スペースを押すと板が出てくる&#34; /&gt;&lt;/p&gt;

&lt;p&gt;床のCubeと追加される板には&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents/blob/5.6.0b4/Assets/Examples/Scripts/NavMeshSourceTag.cs&#34;&gt;NavMeshSourceTag.cs&lt;/a&gt;が付いていて、staticな&lt;code&gt;m_Meshes&lt;/code&gt;と&lt;code&gt;m_Terrains&lt;/code&gt;にそれぞれ追加している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static List&amp;lt;MeshFilter&amp;gt; m_Meshes = new List&amp;lt;MeshFilter&amp;gt;();
public static List&amp;lt;Terrain&amp;gt; m_Terrains = new List&amp;lt;Terrain&amp;gt;();

void OnEnable()
{
    var m = GetComponent&amp;lt;MeshFilter&amp;gt;();
    if (m != null)
    {
        m_Meshes.Add(m);
    }

    var t = GetComponent&amp;lt;Terrain&amp;gt;();
    if (t != null)
    {
        m_Terrains.Add(t);
    }
}

void OnDisable()
{
    var m = GetComponent&amp;lt;MeshFilter&amp;gt;();
    if (m != null)
    {
        m_Meshes.Remove(m);
    }

    var t = GetComponent&amp;lt;Terrain&amp;gt;();
    if (t != null)
    {
        m_Terrains.Remove(t);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらはCollectメソッドでNavMeshBuildSourceのリストを生成するのに使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void Collect(ref List&amp;lt;NavMeshBuildSource&amp;gt; sources)
{
    sources.Clear();

    for (var i = 0; i &amp;lt; m_Meshes.Count; ++i)
    {
        var mf = m_Meshes[i];
        if (mf == null) continue;

        var m = mf.sharedMesh;
        if (m == null) continue;

        var s = new NavMeshBuildSource();
        s.shape = NavMeshBuildSourceShape.Mesh;
        s.sourceObject = m;
        s.transform = mf.transform.localToWorldMatrix;
        s.area = 0;
        sources.Add(s);
    }

    for (var i = 0; i &amp;lt; m_Terrains.Count; ++i)
    {
       ...
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents/blob/5.6.0b4/Assets/Examples/Scripts/LocalNavMeshBuilder.cs&#34;&gt;LocalNavMeshBuilder.cs&lt;/a&gt;から呼び、&lt;a href=&#34;https://docs.unity3d.com/ScriptReference/AI.NavMeshBuilder.UpdateNavMeshData.html&#34;&gt;NavMeshBuilder.UpdateNavMeshData&lt;/a&gt;に渡してNavMeshDataを更新している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NavMeshData m_NavMesh;
AsyncOperation m_Operation;
NavMeshDataInstance m_Instance;
List&amp;lt;NavMeshBuildSource&amp;gt; m_Sources = new List&amp;lt;NavMeshBuildSource&amp;gt;();

IEnumerator Start()
{
    while (true)
    {
        UpdateNavMesh(true);
        yield return m_Operation;
    }
}

void UpdateNavMesh(bool asyncUpdate = false)
{
    NavMeshSourceTag.Collect(ref m_Sources);
    var defaultBuildSettings = NavMesh.GetSettingsByID(0);
    var bounds = QuantizedBounds();

    if (asyncUpdate)
        m_Operation = NavMeshBuilder.UpdateNavMeshDataAsync(m_NavMesh, defaultBuildSettings, m_Sources, bounds);
    else
        NavMeshBuilder.UpdateNavMeshData(m_NavMesh, defaultBuildSettings, m_Sources, bounds);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Fluentdのout_copyのstoreのエラーは他のstoreに影響する</title>
          <link>https://www.sambaiz.net/article/116/</link>
          <pubDate>Sat, 01 Jul 2017 18:53:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/116/</guid>
          <description>&lt;p&gt;Fluentdの&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/out_copy&#34;&gt;out_copy&lt;/a&gt;プラグインは
一つのeventを複数のoutputに渡すために使われる。
ただ、複数設定した中のstoreでエラーが起きると他のstoreにも影響してしまう。&lt;/p&gt;

&lt;p&gt;例えばこんなの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fileの方で&lt;code&gt;queue size exceeds limit&lt;/code&gt;になるとstdoutも出力されなくなってしまう。&lt;/p&gt;

&lt;p&gt;ちなみに一旦relabelしてもだめ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store&amp;gt;
    @type relabel
    @label @file
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;label @file&amp;gt;
  &amp;lt;match dummy&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/match&amp;gt;
&amp;lt;/label&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ドキュメントでも紹介されている、sonots氏の&lt;a href=&#34;https://github.com/sonots/fluent-plugin-copy_ex&#34;&gt;out_copy_ex&lt;/a&gt;では
storeにignore_errorを付けるとrescueするようになっているので他に巻き込まれなくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-copy_ex
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy_ex

  &amp;lt;store ignore_error&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store ignore_error&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;dummy: {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
[error]:  error_class=Fluent::BufferQueueLimitError error=&amp;quot;queue size exceeds limit&amp;quot;
dummy: {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
[error]:  error_class=Fluent::BufferQueueLimitError error=&amp;quot;queue size exceeds limit&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityの経路探索: NavMeshとAgentとObstacle</title>
          <link>https://www.sambaiz.net/article/115/</link>
          <pubDate>Thu, 29 Jun 2017 00:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/115/</guid>
          <description>

&lt;h2 id=&#34;navmeshと経路探索-https-docs-unity3d-com-jp-540-manual-nav-innerworkings-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-InnerWorkings.html&#34;&gt;NavMeshと経路探索&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;NavMeshというのはエージェントが移動できる面についてのデータ構造で、凸ポリゴンの面と位置関係を含んでいる。
経路探索は2点間を一番近いポリゴンにマッピングし、&lt;a href=&#34;https://ja.wikipedia.org/wiki/A*&#34;&gt;A*アルゴリズム&lt;/a&gt;を用いて行われる。あとからオブジェクトが追加されるなどして道を塞いでしまってもCarvingしてNavMeshに穴をあければ別の経路で移動することができるが、このようなグローバルの経路探索に影響を及ぼす操作は計算にコストがかかるので、各エージェントローカルの衝突回避で済むならそのほうがよい。&lt;/p&gt;

&lt;h2 id=&#34;navmeshをbakeする-https-docs-unity3d-com-jp-540-manual-nav-buildingnavmesh-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-BuildingNavMesh.html&#34;&gt;NavMeshをbakeする&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;こんな感じで床に適当なオブジェクトを置いてみた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-stage.png&#34; alt=&#34;stage&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-stageh.png&#34; alt=&#34;階層&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Window -&amp;gt; Navigation&lt;/code&gt;でBakeするのを選択してNavigation Staticし(StaticになってBakeの対象になる)、
Bakeボタンを押すとこんな感じでBakeされる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-bake.png&#34; alt=&#34;bake&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトの上がNavMeshに含まれていないのはAgent sizeのStep Heightよりも高いため。
段差を移動するときに浮いてしまうのを避けるためにはAdvancedの&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-HeightMesh.html&#34;&gt;Height Mesh&lt;/a&gt;をオンにする。
また、端が含まれていないのはこのAgentの中心が入れる位置を表しているためで、
Agent Radiusを変更すると広がったり狭まったりするのを確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-agentsize.png&#34; alt=&#34;Agent size&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;navmesh-agent-https-docs-unity3d-com-jp-540-manual-nav-createnavmeshagent-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-CreateNavMeshAgent.html&#34;&gt;NavMesh Agent&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Radius0.5, Height2のCylindarを作成し、Nav Mesh Agentを追加する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-navmesh-agent.png&#34; alt=&#34;NavMesh Agent&#34; /&gt;&lt;/p&gt;

&lt;p&gt;で、ゴールにオブジェクトを置いてそこまで移動させてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine.AI;

public GameObject goal;

void Start () {
    var agent = GetComponent&amp;lt;NavMeshAgent&amp;gt;();
    agent.destination = goal.transform.position;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move.gif&#34; alt=&#34;ゴールまでたどり着くNavMesh Agent&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;navmesh-obstacle&#34;&gt;NavMesh Obstacle&lt;/h2&gt;

&lt;p&gt;障害物。上で通った経路上にNavMesh Obstacleを追加したCubeを置いたところうまく避けてゴールまでたどり着いた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move2.gif&#34; alt=&#34;Obstacleを置いた&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただ、完全に道をふさいでしまうと立ち往生してしまうので
Carveにチェックを入れるとCarvingされ、他の経路でゴールまで進むようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move3.gif&#34; alt=&#34;Carvingした&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/117/&#34;&gt;Unityで動的にNavMeshを生成する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityの物理エンジン・衝突: RigidbodyとCollidarとJoint</title>
          <link>https://www.sambaiz.net/article/114/</link>
          <pubDate>Sun, 25 Jun 2017 23:26:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/114/</guid>
          <description>

&lt;h2 id=&#34;rigidbody-https-docs-unity3d-com-ja-current-manual-rigidbodiesoverview-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/RigidbodiesOverview.html&#34;&gt;Rigidbody&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GameObjectを物理特性によって制御し、力の影響を受けるようにする。
&lt;code&gt;Mass(質量)&lt;/code&gt;や&lt;code&gt;Drag(空気抵抗)&lt;/code&gt;、&lt;code&gt;Use Gravity&lt;/code&gt;などのプロパティがある。&lt;/p&gt;

&lt;p&gt;移動させるのに自分でTransformは変更せず力をかけて物理演算に任せる。
&lt;code&gt;Is Kinematic&lt;/code&gt;にチェックを入れると物理エンジンによって移動しないようになるので、
Transformを直接変更する場合は有効にする。
ただし、スクリプトで動的にIs Kinematicを切り替えるのはパフォーマンスが良くない。&lt;/p&gt;

&lt;h2 id=&#34;collidar-https-docs-unity3d-com-ja-current-manual-collidersoverview-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/CollidersOverview.html&#34;&gt;Collidar&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;RigidBodyの物理特性の境界を定義する。衝突させるには両方にCollidarが設定されている必要がある。
RigidBodyなしのCollidarを静的Collidarといって、無効にしたり移動しないことを前提に最適化される。
移動したりするものについてはRigidBodyを付けて、必要ならIs Kinematicを有効にする。&lt;/p&gt;

&lt;p&gt;衝突時には&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionEnter.html&#34;&gt;OnCollisionEnter()&lt;/a&gt;
が呼ばれる。ほかに離れたときの&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionExit.html&#34;&gt;OnCollisionExit()&lt;/a&gt;、
触れている間、毎フレーム呼ばれる&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionStay.html&#34;&gt;OnCollisionStay()&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void OnCollisionEnter(Collision collision)
{
    foreach (ContactPoint contact in collision.contacts)
    {
        if (contact.otherCollider.tag == &amp;quot;Player&amp;quot;)
        {
            Debug.Log(collision.relativeVelocity.magnitude);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Is Trigger&lt;/code&gt;にチェックを入れると物理エンジンには無視されてすり抜け、侵入に対してトリガーイベントが呼ばれる。
OnCollistionと同様に
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerEnter.html&#34;&gt;OnTriggerEnter()&lt;/a&gt;、
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerExit.html&#34;&gt;OnTriggerExit()&lt;/a&gt;、
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerStay.html&#34;&gt;OnTriggerStay()&lt;/a&gt;
がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void OnTriggerEnter(Collider other)
{
    Debug.Log(other.tag);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;joint-https-docs-unity3d-com-ja-current-manual-joints-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/Joints.html&#34;&gt;Joint&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Rigitbodyを他のRigitbodyとつなげるもの。
例えばSprint Jointだとオブジェクト間がばねのように伸縮する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/114-joint.png&#34; alt=&#34;Spring Joint&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする</title>
          <link>https://www.sambaiz.net/article/113/</link>
          <pubDate>Sun, 25 Jun 2017 00:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/113/</guid>
          <description>

&lt;p&gt;デプロイやスループットの調整を簡単にするため、BeanstalkでAggregatorを立ち上げた。&lt;/p&gt;

&lt;h2 id=&#34;負荷分散&#34;&gt;負荷分散&lt;/h2&gt;

&lt;p&gt;TCPの24224(設定による)が通るようにEC2,ELBのSGとリスナーの設定をする必要があって、
ELBのSGのアウトバウンドの設定が見落とされがち。ELBのクロスゾーン分散は有効になっている。&lt;/p&gt;

&lt;p&gt;まず、ELBに3台、それぞれ別のAZ(1b, 1c, 1d)に配置されている状態でログを送り始めるとそれぞれ均等にログが届いた。
その状態から4台(1b * 2, 1c, 1d)にすると、2つのインスタンス(1b, 1c)のみに均等にログが届くようになった。
4台になると(1b, 1c)と(1b, 1d)に分けられてELBのノードがそれらの組に紐づいたということだと思う。
各ノードにはDNSラウンドロビンするようになっている。実際restartすると今度は別の組の方に送られた。&lt;/p&gt;

&lt;p&gt;では、なぜ一度送り始めると同じ方にしか飛ばないかというと、forwardプラグインの&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/out_forward#expirednscache&#34;&gt;expire_dns_cache&lt;/a&gt;がデフォルトでnilになっていて、
heartbeatが届いている間は&lt;a href=&#34;https://github.com/fluent/fluentd/blob/v0.14.18/lib/fluent/plugin/out_forward.rb#L688&#34;&gt;無期限にDNSキャッシュする&lt;/a&gt;ようになっているため。これに0(キャッシュしない)か秒数を指定すると、
その間隔で他の組のインスタンスにもログが届くようになった。
&lt;code&gt;expire_dns_cache&lt;/code&gt;しなくても複数のインスタンスからラウンドロビンされるため全体でいえば分散される。&lt;/p&gt;

&lt;h2 id=&#34;heartbeat&#34;&gt;heartbeat&lt;/h2&gt;

&lt;p&gt;ELB配下のEC2を全て落としても&lt;a href=&#34;https://github.com/fluent/fluentd/blob/v0.14.18/lib/fluent/plugin/out_forward.rb#L665&#34;&gt;heartbeat&lt;/a&gt;に失敗しないため、standyに移行せずELBのバックエンド接続エラーになってログがロストしてしまうようだ。
ログにも出ず、以下のようにactive-standbyの設定をしてもstandbyに移行しない。
全てのインスタンスが同時に落ちるというのは滅多に起きないだろうけど、少なくとも検知できるようにはしておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;server&amp;gt;
    name td1
    host autoscale-td1.us-east-1.elasticbeanstalk.com
    port 24224
&amp;lt;/server&amp;gt;
&amp;lt;server&amp;gt;
    name td2
    host autoscale-td2.us-east-1.elasticbeanstalk.com
    port 24224
    standby
&amp;lt;/server&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;blue-green-deployment&#34;&gt;Blue/Green Deployment&lt;/h2&gt;

&lt;p&gt;Blue-Green Deploymentというのは、2つの系を用意し、activeでない方にデプロイし、
スワップして反映させるもの。ダウンタイムなしで問題が起きた際にもすぐに切り戻すことができる。
スワップして向き先を変えるには&lt;code&gt;expire_dns_cache&lt;/code&gt;を設定する必要がある。&lt;/p&gt;

&lt;h2 id=&#34;auto-scaling&#34;&gt;Auto Scaling&lt;/h2&gt;

&lt;p&gt;増えるのはいいとして減るときに、
送り先で一時的に障害が起きていたりするとバッファをflushできずにログがロストする可能性がある。
それでいうとログの送り元でも同じことが起こりうるんだけど、通常Aggregatorにしか送らないので比較的問題になりにくい。&lt;/p&gt;

&lt;p&gt;これを避けたい場合、Auto Scalingグループの設定で
&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/autoscaling/latest/userguide/as-instance-termination.html#instance-protection&#34;&gt;スケールインから保護&lt;/a&gt;を有効にして
これから立ち上がるインスタンスはスケールインしなくすることができる。
それまでに立ち上がっていたインスタンスには適用されないので注意。&lt;/p&gt;

&lt;p&gt;スケールインしないということは最大の台数で止まってしまうので、
ピークを過ぎたらスワップしてバッファが全て掃けたことを確認してからTerminateすることになる。
これを日常的にやるのは面倒なので、実際は予期しない流量の増加に備えて一応設定しておき、
普段はしきい値にひっかからないような最低台数で待ち構えておくことにするかな。&lt;/p&gt;

&lt;p&gt;あとはヘルスチェックによって潰される可能性はなくもないけど、それはもうやむなし・・・。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/elb-configuration-guide-1&#34;&gt;AWS ELBの社内向け構成ガイドを公開してみる 負荷分散編 – Cross-Zone Routingを踏まえて ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのMecanimでヒューマノイドアニメーションさせる</title>
          <link>https://www.sambaiz.net/article/112/</link>
          <pubDate>Tue, 20 Jun 2017 23:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/112/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/4696&#34;&gt;Space Robot Kyle&lt;/a&gt;を動かす。&lt;/p&gt;

&lt;h2 id=&#34;アバターの作成&#34;&gt;アバターの作成&lt;/h2&gt;

&lt;p&gt;Assetsの&lt;code&gt;Model/Robot Kyle&lt;/code&gt;を選択し、RigのAnimation TypeをHumanoidにすると、
自動的にボーン構造を解析して人型にマッピングしたアバターが設定される。
Configure Avatarで確認すると正しく設定されているようだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-rig.png&#34; alt=&#34;アバター&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;モーションの設定&#34;&gt;モーションの設定&lt;/h2&gt;

&lt;p&gt;KyleのAnimatorのAnimationに設定するAnimation Controllerを作成する。
まずは2つCreate Stateし、それぞれMotionに適当なモーション(今回は&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/36286&#34;&gt;Fighter Pack Bundle FREE&lt;/a&gt;を使った)を設定し、
Make Transitionで相互に結ぶと、オレンジになっているデフォルトステートから交互にモーションする。
ステートには&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/StateMachineBehaviour.html&#34;&gt;StateMachineBehaviour&lt;/a&gt;のScriptを設定することもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-animation.png&#34; alt=&#34;モーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次にParametersでモーションを変化させる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-animation2.png&#34; alt=&#34;分岐したモーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Animatorの左上、parametersタブからBoolのWalkを追加する。
そして片方のTransitionのConditionにWalkがfalse、もう片方にはWalkがtrueを追加すると、
状態によって違うモーションをするようになる。
ちなみに、AnyStateからConditionを設定したTransitionを設定すると、どこのStateからでもそれで遷移させることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-parameters.png&#34; alt=&#34;パラメータ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このParameterはこんな感じに値を設定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Update () {
	GetComponent&amp;lt;Animator&amp;gt; ().SetBool (&amp;quot;Walk&amp;quot;, Random.value &amp;lt; 0.5);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;一部だけモーションさせる&#34;&gt;一部だけモーションさせる&lt;/h2&gt;

&lt;p&gt;人体の一部だけをモーションさせるにはAvatar Maskを使う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-avatar-mask.png&#34; alt=&#34;Avatar Mask&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-avatar-mask-motion.png&#34; alt=&#34;Avatar Maskしたモーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Animationで複数のレイヤーを作成すれば、異なるMaskでそれぞれステートを持たせることができる。&lt;/p&gt;

&lt;h2 id=&#34;animation-override-controller&#34;&gt;Animation Override Controller&lt;/h2&gt;

&lt;p&gt;作ったAnimationを違うモーションで再利用することができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-override.png&#34; alt=&#34;Animator Override Controller&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>NorikraでログをJOINする</title>
          <link>https://www.sambaiz.net/article/111/</link>
          <pubDate>Thu, 15 Jun 2017 00:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/111/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/109/&#34;&gt;NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;適当なログを出すコードを書いた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/lottery-log&#34;&gt;sambaiz/lottery-log&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。
広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// lottery.log
{&amp;quot;ts&amp;quot;:1497453504.6818597,&amp;quot;uid&amp;quot;:&amp;quot;b18c0d98-19b2-4e37-8fc4-6b00a4b728c3&amp;quot;,&amp;quot;prize&amp;quot;:855,&amp;quot;isWin&amp;quot;:true}
// received.log
{&amp;quot;ts&amp;quot;:1497453515.932101,&amp;quot;uid&amp;quot;:&amp;quot;bc4f578f-4a5f-47f1-a4e0-1ef0b43c316e&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリはこんな感じ。一つはlotteryログとreceivedログをuidでJOINするもので、
received_rateの計算にはサブクエリも使っている。
received_rateの計算で分母に小さな値を足しているのはNaNやInfinityにならないようにするため。
receivedログは最大30秒遅れて出力されるため、40秒前までのreceivedログをwin:timeで見ている。
これをtime_batchにしてしまうと期待通りの結果にならないので注意。&lt;/p&gt;

&lt;p&gt;もう一つはJavaの関数でboolを0/1にして平均をとることでisWinがtrueである割合を出している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec norikra norikra-client query add lottery_agg &#39;
SELECT COUNT(*) as received_count, (COUNT(*) / (SELECT COUNT(*) + 0.00001 FROM lottery.win:time_batch(1 sec, 0).std:unique(uid))) as received_rate, AVG(prize) as prize_avg, SUM(prize) as prize_sum FROM lottery.win:time(40 sec).std:unique(uid) as a, received.win:time_batch(1 sec, 0).std:unique(uid) as b WHERE a.uid = b.uid&#39;

$ docker exec norikra norikra-client query add lottery_win_rate &#39;SELECT avg(Boolean.compare(isWin, false)) as win_rate FROM lottery.win:time_batch(1 sec)&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、このクエリの結果をElasticsearchに送って可視化してみたのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type tail
  path /var/log/lottery.log
  pos_file /etc/td-agent/log.pos
  tag event.lottery
  format json
&amp;lt;/source&amp;gt;

&amp;lt;source&amp;gt;
  @type tail
  path /var/log/received.log
  pos_file /etc/td-agent/log.pos
  tag event.received
  format json
&amp;lt;/source&amp;gt;

&amp;lt;match event.*&amp;gt;
  @type   norikra
  norikra localhost:26571
  
  remove_tag_prefix event # event.*の部分が
  target_map_tag    yes   # targetになる

  &amp;lt;default&amp;gt;
    auto_field false 
  &amp;lt;/default&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;source&amp;gt;
  @type   norikra
  norikra localhost:26571
  &amp;lt;fetch&amp;gt;
    method   event
    target   lottery_agg
    tag      string data.lottery_agg
    interval 1m
  &amp;lt;/fetch&amp;gt;
  &amp;lt;fetch&amp;gt;
    method   event
    target   lottery_win_rate
    tag      string data.lottery_win_rate
    interval 1m
  &amp;lt;/fetch&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match data.lottery_agg&amp;gt;
  @type elasticsearch
  host 172.31.5.20
  port 9200
  logstash_prefix lottery
  type_name lottery_agg
  logstash_format true
&amp;lt;/match&amp;gt;

&amp;lt;match data.lottery_win_rate&amp;gt;
  @type elasticsearch
  host 172.31.5.20
  port 9200
  logstash_prefix lottery
  type_name lottery_win_rate
  logstash_format true
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;received_rateを計算するときのウィンドウが1secと小さく、タイミングによってはreceivedの数がlotteryの数を上回ることがあるため1以下で絞っている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/111v.png&#34; alt=&#34;可視化したもの&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>VSでのネイティブプラグインのビルドからUnityでのWSAのビルドまでをバッチでする</title>
          <link>https://www.sambaiz.net/article/110/</link>
          <pubDate>Tue, 13 Jun 2017 00:32:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/110/</guid>
          <description>

&lt;h2 id=&#34;vsでのネイティブプラグインのビルド&#34;&gt;VSでのネイティブプラグインのビルド&lt;/h2&gt;

&lt;p&gt;VSが使っているビルドツール
&lt;a href=&#34;https://docs.microsoft.com/ja-jp/visualstudio/msbuild/msbuild&#34;&gt;MSBuild&lt;/a&gt;を使う。
VSのプロジェクトファイルにはMSBuildのXMLが含まれている。
これ自体はVSに依存していないため、単体で動かすこともできる。&lt;/p&gt;

&lt;p&gt;パスが通ってなかったらパスを通す。管理者権限が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; MSBuild
&#39;MSBuild&#39; は、内部コマンドまたは外部コマンド、
操作可能なプログラムまたはバッチ ファイルとして認識されていません。

&amp;gt;　SETX /M PATH &amp;quot;%PATH%;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\Bin&amp;quot;

成功: 指定した値は保存されました。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;別プロセスから適用されるので立ち上げ直すとパスが通っていることを確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; MSBuild /version
Microsoft (R) Build Engine バージョン 15.1.1012.6693
Copyright (C) Microsoft Corporation.All rights reserved.

15.1.1012.6693
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドして&lt;code&gt;Assets\Plugins&lt;/code&gt;に配置する。これは前作ったBLEのネイティブプラグインのもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/105/&#34;&gt;Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; git clone git@github.com:sambaiz/UnityBLE_UWP.git
&amp;gt; cd UnityBLE_UWP
&amp;gt; MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;quot;x86&amp;quot;
&amp;gt; MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release
&amp;gt; copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA
&amp;gt; copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.dll ..\Assets\Plugins
&amp;gt; cd ..
&amp;gt; rmdir /S /Q UnityBLE_UWP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなエラーが出てきたらmscorlib.dllをインポートできていないのが原因のようで、
restoreしたらうまくいった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;error CS0518: 定義済みの型 &#39;System.Object&#39; は定義、またはインポートされていません
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;unityでのwsaのビルド&#34;&gt;UnityでのWSAのビルド&lt;/h2&gt;

&lt;p&gt;同様にUnityもパスが通ってなかったら通す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; Unity
&#39;Unity&#39; は、内部コマンドまたは外部コマンド、
操作可能なプログラムまたはバッチ ファイルとして認識されていません。

&amp;gt;　SETX /M PATH &amp;quot;%PATH%;C:\Program Files\Unity\Editor&amp;quot;

成功: 指定した値は保存されました。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/BuildPipeline.BuildPlayer.html&#34;&gt;スクリプト&lt;/a&gt;
をAssets/Editorの中に置く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEditor;

public class Build {

    static void PerformBuild()
    {
        string[] scenes = { &amp;quot;Assets/main.unity&amp;quot; };
        BuildPipeline.BuildPlayer(scenes, &amp;quot;build&amp;quot;,
            BuildTarget.WSAPlayer, BuildOptions.None);

    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このstaticメソッドを&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/CommandLineArguments.html&#34;&gt;executeMethod&lt;/a&gt;
で渡してビルドする。Unityを開いたままだと失敗するので閉じる必要がある。&lt;/p&gt;

&lt;p&gt;この例だとbuildディレクトリに出力される。もし出力されなかったらEditorログを見る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; Unity -quit -batchmode -executeMethod Build.PerformBuild
&amp;gt; type C:\Users\(username)\AppData\Local\Unity\Editor\Editor.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;まとめたもの&#34;&gt;まとめたもの&lt;/h2&gt;

&lt;p&gt;ということでこんなバッチをUnityプロジェクトの直下に置いておくことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone git@github.com:sambaiz/UnityBLE_UWP.git
cd UnityBLE_UWP
MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;quot;x86&amp;quot;
MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release
copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA
copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.dll ..\Assets\Plugins
cd ..
rmdir /S /Q UnityBLE_UWP

rmdir /S /Q build
Unity -quit -batchmode -executeMethod Build.PerformBuild
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://sh-yoshida.hatenablog.com/entry/2017/05/27/012755&#34;&gt;MSBuildでコマンドラインからビルドする - 1.21 jigowatts&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
          <link>https://www.sambaiz.net/article/109/</link>
          <pubDate>Sat, 10 Jun 2017 12:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/109/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://norikra.github.io/&#34;&gt;Norikra&lt;/a&gt;はTD社の&lt;a href=&#34;https://github.com/tagomoris&#34;&gt;tagomoris&lt;/a&gt;氏が作った、
スキーマレスのストリーミングデータを処理するOSS。&lt;/p&gt;

&lt;p&gt;モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだけど、
流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。&lt;/p&gt;

&lt;h2 id=&#34;norikraを立ち上げてクエリを実行する&#34;&gt;Norikraを立ち上げてクエリを実行する&lt;/h2&gt;

&lt;p&gt;公式で紹介されているDockerイメージがあったのでこれで動かしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -e &amp;quot;TZ=Asia/Tokyo&amp;quot; -p 26578:26578 -p 26571:26571 -v `pwd`:/var/tmp/norikra:rw -d myfinder/docker-norikra norikra start --stats /var/tmp/norikra/stats.json -l /var/tmp/norikra 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほかの&lt;a href=&#34;https://github.com/norikra/norikra/blob/master/lib/norikra/cli.rb&#34;&gt;オプション&lt;/a&gt;として&lt;code&gt;-Xms&lt;/code&gt;や&lt;code&gt;-Xmx&lt;/code&gt;でJVMのヒープメモリの量を設定したり、Experimentalではあるけど&lt;code&gt;--shutoff&lt;/code&gt;でヒープメモリが一杯になる前に弾いて
OutOfMemoryを防ぐことができる。
また、Norikraのコアエンジンで使われているOSSの
&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%A4%87%E5%90%88%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E5%87%A6%E7%90%86&#34;&gt;CEP&lt;/a&gt;
(Complex event processing)エンジン、
&lt;a href=&#34;http://www.espertech.com/products/esper.php&#34;&gt;Esper&lt;/a&gt;
のパフォーマンスチューニングとして&lt;code&gt;--micro&lt;/code&gt;や&lt;code&gt;--small&lt;/code&gt;などを渡すこともできるけど試していない。&lt;/p&gt;

&lt;p&gt;公式サイトの例に従ってクライアントからデータを入れてクエリを実行してみる。&lt;/p&gt;

&lt;p&gt;まずはtargetをopenする。targetというのはスキーマレスのイベントストリームのこと。
ここで定義したフィールドは必須になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client target open www path:string status:integer referer:string agent:string userid:integer
$ norikra-client target list
TARGET	AUTO_FIELD
www	true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にクエリを追加する。一見普通のSQLのように見えるけど、EsperのクエリであるEPL(Event Processing Language)。
ただしSELECTしか使えないのも含めてクエリにいくらかの制限がある。&lt;/p&gt;

&lt;p&gt;このクエリでは&lt;code&gt;win:time_batch&lt;/code&gt;で10秒のWindowを定義し、eventをgroup byして、その数をeventとして出力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client query add www.toppageviews &#39;SELECT count(*) AS cnt FROM www.win:time_batch(10 sec) WHERE path=&amp;quot;/&amp;quot; AND status=200&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;eventを流す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/login&amp;quot;, &amp;quot;status&amp;quot;:301, &amp;quot;referer&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリの値をfetchする。送るのが遅くてgroup byされなかったけどこんな感じ。
eventがこなかったはじめのWindowは0が出力されるが、それ以降のWindowでは出力されない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client event fetch www.toppageviews
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 20:58:13&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:42:33&amp;quot;,&amp;quot;cnt&amp;quot;:1}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:42:43&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:13&amp;quot;,&amp;quot;cnt&amp;quot;:1}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:23&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:33&amp;quot;,&amp;quot;cnt&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとWeb-uiが用意されていて、クエリを追加したり、targetやクエリの一覧、メモリの使用量やサーバーログなどが取得できる。デフォルトでは26578ポート。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/109-norikra.png&#34; alt=&#34;web-ui&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;クエリ-epl-http-norikra-github-io-query-html&#34;&gt;&lt;a href=&#34;http://norikra.github.io/query.html&#34;&gt;クエリ(EPL)&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;windowなし&#34;&gt;Windowなし&lt;/h3&gt;

&lt;p&gt;上の例では&lt;code&gt;time_batch&lt;/code&gt;でWindowを定義したけど、定義しないクエリを追加してみる。
以下のようなクエリを登録し、再びeventを流してfetchすると流した分が全てとれる。
ただし、このようなクエリはfetchされないと大量のoutput eventが溜まる可能性がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT path, status AS cnt FROM www WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-nowin
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 23:06:12&amp;quot;,&amp;quot;cnt&amp;quot;:200,&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 23:09:10&amp;quot;,&amp;quot;cnt&amp;quot;:200,&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-time-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-time-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-time-batch&#34;&gt;win:time_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;10 sec&lt;/code&gt;のように秒以外にも&lt;code&gt;msec&lt;/code&gt;、&lt;code&gt;min&lt;/code&gt;、&lt;code&gt;hour&lt;/code&gt;、どう使うか想像できないけど&lt;code&gt;year&lt;/code&gt;まで指定でき、
&lt;code&gt;10 minutes 30 seconds&lt;/code&gt;みたいに組み合わせることも&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl_clauses.html#epl-syntax-time-periods&#34;&gt;できる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;また、第二引数にミリ秒を渡すと出力するタイミングを指定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) AS cnt FROM www.win:time_batch(1min, 0L) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-tb-opts
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 00:43:00&amp;quot;,&amp;quot;cnt&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-ext-timed-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-ext-time-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-ext-time-batch&#34;&gt;win:ext_timed_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;来た時間ではなくフィールドのUNIXミリ秒を参照するWindow。時系列順にソートされている必要があって、
tagomoris氏いわく&lt;a href=&#34;https://twitter.com/tagomoris/status/486851407140507648&#34;&gt;おすすめしない&lt;/a&gt;とのこと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) AS cnt FROM www.win:ext_timed_batch(timestamp, 1 min) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3, &amp;quot;timestamp&amp;quot;:1496852100000 }&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3, &amp;quot;timestamp&amp;quot;:1496852200000 }&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-ext_timed
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 01:19:02&amp;quot;,&amp;quot;cnt&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-length-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-length-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-length-batch&#34;&gt;win:length_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;event数のWindow。毎回渡した数ずつ集計できると思いきや、数が集まらなければfetchできず、
それ以上集まったらfetchできるようだ。使いづらいような気がする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT avg(userid) as nosense FROM www.win:length_batch(2) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat

$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat

$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:2}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:42:20&amp;quot;,&amp;quot;nosense&amp;quot;:2.0}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-length-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-length&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-length&#34;&gt;win:length&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;こっちは渡した数スライドして集計するもの。Windowなしのときと同様、大量に溜まる可能性がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT avg(userid) as nosense FROM www.win:length(2) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:5}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:4}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-len
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:11&amp;quot;,&amp;quot;nosense&amp;quot;:3.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:22&amp;quot;,&amp;quot;nosense&amp;quot;:2.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:32&amp;quot;,&amp;quot;nosense&amp;quot;:3.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:45&amp;quot;,&amp;quot;nosense&amp;quot;:4.5}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他にもいろいろあるし、JOINやサブクエリも使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/111/&#34;&gt;NorikraでログをJOINする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;fluentdとやり取りする&#34;&gt;fluentdとやり取りする&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/norikra/fluent-plugin-norikra&#34;&gt;fluent-plugin-norikra&lt;/a&gt;でNorikraサーバーにeventを送り、
eventを受け取ってファイルに出力する。&lt;/p&gt;

&lt;p&gt;c4.large(2コア,メモリ3.75GiB)でDockerでNorikraを立ち上げ、以下の設定でtd-agentを実行した。
&lt;code&gt;auto_field&lt;/code&gt;は来たeventのフィールドを自動でtargetに登録するかの設定で、
true(デフォルト)にするとどんなフィールドが来ているかNorikra上で確認することができる。
falseにしてもクエリで使う分は自動で登録される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag event.dummy
  rate 1000
&amp;lt;/source&amp;gt;
   
&amp;lt;match event.*&amp;gt;
  @type   norikra
  norikra localhost:26571
  
  remove_tag_prefix event # event.*の部分が
  target_map_tag    yes   # targetになる

  &amp;lt;default&amp;gt;
    auto_field false 
  &amp;lt;/default&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;source&amp;gt;
  @type   norikra
  norikra localhost:26571
  &amp;lt;fetch&amp;gt;
    method   event
    # norikra-client query add dummy_count_1sec &#39;SELECT COUNT(*) AS count FROM dummy.win:time_batch(1 sec)&#39;
    target   dummy_count_1sec
    tag      string data.dummy_count_1sec
 #  tag      field FIELDNAME : tag by value with specified field name in output event
    interval 1m
  &amp;lt;/fetch&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match data.*&amp;gt;
  @type file
  path /var/log/td-agent/dummy_count
  time_slice_format %Y%m%d%H
  time_slice_wait 10s
  time_format %Y%m%dT%H%M%S%z
  compress gzip
  symlink_path /var/log/td-agent/dummy_count
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Norikraのスループットは以下の要素が影響する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;number of targets
number of queries
how complex queries are
how complex UDFs are
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、目安としてはこんな感じらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10 queries
2,000 events per seconds
5% usage of 4core CPU
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1target、単純な1クエリなら秒間10000送ってみても問題なかった。
あまり現実的なケースではないけど限界を目指してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail -f dummy_count
20170609T212717+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212718+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212719+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212720+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212721+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212722+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212723+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212724+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212725+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212726+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 8256 root      20   0 1878m 249m  19m S 29.3  6.6   6:46.94 java
 9812 root      20   0  296m  68m 6288 S 20.0  1.8   2:38.08 ruby  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秒間40000送ってみるとカウントがおかしい。
dummyの方の限界かと思ってnorikraを外してみたらおおよそ数が合ったので
Norikraサーバーかやり取りの部分で処理が追いついていないようだ。
一旦rateを下げてみたところ20000あたりを境目にこうなってしまった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail -f dummy_count
20170609T222018+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:31248}
20170609T222019+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:27468}
20170609T222020+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:35309}
20170609T222021+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:31944}
20170609T222022+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:22805}
20170609T222023+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:30716}
20170609T222024+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:33617}
20170609T222025+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:28740}
20170609T222026+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:32058}
20170609T222027+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:27253}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CPUの使用量をみてみると、ほぼ限界まで使用されていた。
fluentdはrubyの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B0%E3%83%AD%E3%83%BC%E3%83%90%E3%83%AB%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%97%E3%83%AA%E3%82%BF%E3%83%AD%E3%83%83%E3%82%AF&#34;&gt;GIL&lt;/a&gt;
(Global Interpreter Lock = GVL(Giant VM Lock))のため同時に&lt;a href=&#34;https://docs.ruby-lang.org/ja/2.3.0/doc/spec=2fthread.html&#34;&gt;1ネイティブスレッドしか動かせず&lt;/a&gt;、1コアしかCPUを使えないが、
jrubyで動くNorikraは残りのコアを使うことができる。
今回はtargetもクエリも一つだし、データ量も小さいためかメモリにはまだ余裕があった。
ログのサイズやウィンドウサイズが大きければメモリを使う量が増えるため、実際のログをしばらく
流してどちらが問題になりそうか確認するべき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
11378 root      20   0  350m 111m 6336 S 96.1  3.0   1:53.03 ruby
8256 root      20   0 1892m 642m  19m S 84.2 17.1  34:36.38 java   
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;HEAP MEMORY USED: 244MB (55.8%), COMMITTED: 437MB, MAX: 437MB
NON-HEAP MEMORY USED: 51MB (23.8%), COMMITTED: 81MB, MAX: 214MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1Gbps、1Mevent/sを超えるような高トラフィックではStormなどのフレームワークを使えとのこと。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでKinesis streamsに送るときの性能確認</title>
          <link>https://www.sambaiz.net/article/108/</link>
          <pubDate>Mon, 05 Jun 2017 23:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/108/</guid>
          <description>

&lt;h2 id=&#34;localでのstreamsとproducerのbenchmark&#34;&gt;localでのstreamsとproducerのbenchmark&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;の
&lt;code&gt;make benchmark&lt;/code&gt;はlocalにDummyServerを&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis/blob/v1.1.3/benchmark/task.rake#L18&#34;&gt;立ち上げて&lt;/a&gt;送っている。&lt;/p&gt;

&lt;p&gt;空でもいいのでroleをつけておく必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/awslabs/aws-fluent-plugin-kinesis.git
$ cd aws-fluent-plugin-kinesis
$ yum install -y ruby-devel gcc
$ echo &#39;gem &amp;quot;io-console&amp;quot;&#39; &amp;gt;&amp;gt; Gemfile
$ make
$ make benchmark
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATEを指定しなければデフォルトで&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis/blob/v1.1.3/benchmark/task.rake#L19&#34;&gt;秒間1000レコード&lt;/a&gt;が送られる設定。
fluentdを起動してから10秒後にプロセスをkillし、そのレコード数などを出力している。&lt;/p&gt;

&lt;p&gt;t2.microでデフォルト(RATE=1000)で実行した結果がこれ。
固める分producerの方はややパフォーマンスが落ちる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 20, raw_records: 9400, records: 9400
bundle exec rake benchmark TYPE=producer
Results: requets: 14, raw_records: 1005, records: 8900
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATE=3000のとき。producerではraw_recordsが1/100、リクエスト数は1/5。
streamsだとシャードを増やしていく必要があるけど、producerの方は当分大丈夫そうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 57, raw_records: 27600, records: 27600
bundle exec rake benchmark TYPE=producer
Results: requets: 12, raw_records: 241, records: 25200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATE=10000のとき。raw_records, requestの圧縮率はさらに上がり、
パフォーマンスの差が大きくなってきている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 177, raw_records: 88000, records: 88000
bundle exec rake benchmark TYPE=producer
Results: requets: 26, raw_records: 385, records: 75000
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実際にkinesis-streamsに送ってみる&#34;&gt;実際にkinesis streamsに送ってみる&lt;/h2&gt;

&lt;p&gt;ap-northeast-1でシャードは3のKinesis streamsにt2.microインスタンス1台から送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1000
&amp;lt;/source&amp;gt;

&amp;lt;source&amp;gt;
  @type monitor_agent
  bind 0.0.0.0
  port 24220
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type kinesis_streams
  region ap-northeast-1
  stream_name test

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秒間3000まではほとんどキューにたまらず送れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:24220/api/plugins.json | jq
{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 0,
      &amp;quot;buffer_total_queued_size&amp;quot;: 17500,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4000にするとそのうちretryが発生してしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
     &amp;quot;buffer_queue_length&amp;quot;: 60,
      &amp;quot;buffer_total_queued_size&amp;quot;: 56544178,
      &amp;quot;retry_count&amp;quot;: 5,
      &amp;quot;retry&amp;quot;: {
        &amp;quot;steps&amp;quot;: 5,
        &amp;quot;next_time&amp;quot;: &amp;quot;2017-06-05 14:05:38 +0000&amp;quot;
      }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たしかにスループットが超過している。スペック通りだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/108.png&#34; alt=&#34;書き込みスループットの超過&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次に30シャードにしてみる。一度にシャード数は倍から半分にしかできないので作り直し。&lt;/p&gt;

&lt;p&gt;これに秒間30000を送ってみると、キューにいくらか溜まった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 7,
      &amp;quot;buffer_total_queued_size&amp;quot;: 7752600,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに倍にして60シャード。これに秒間60000で送ってみる。キューに溜まるものの増え続けはしないのでなんとか送れてそうだ。
td-agentのプロセスがCPUを99%使っているので、このインスタンスではこの辺が限界かもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 15,
      &amp;quot;buffer_total_queued_size&amp;quot;: 16105807,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ついでにus-east-1にも30シャードのStreamsを作成して30000送ってみたところ、キューに溜まる量が格段に増えた。
早くFirehoseやAnalyticsが東京リージョンにも来てほしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 50,
      &amp;quot;buffer_total_queued_size&amp;quot;: 52432436,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>td-agent2.3.5のfluentdが0.14系になってしまっているのでソースからビルドする</title>
          <link>https://www.sambaiz.net/article/107/</link>
          <pubDate>Sun, 04 Jun 2017 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/107/</guid>
          <description>&lt;blockquote&gt;
&lt;p&gt;追記(2016-06-25): 現在は普通に入れても0.12系の2.3.5-1が入るようになっている。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;$ curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh
$ td-agent --version
td-agent 0.14.16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.12系じゃない！？&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yum list installed | grep td-agent
td-agent.x86_64                       2.3.5-0.el2017               @treasuredata
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どうやら2.3.5では0.14系になってしまっているよう。
そのあとにリリースされた2.3.5-1では直ってるみたいだけど、現時点ではrpmリポジトリに上がっていない。&lt;/p&gt;

&lt;p&gt;しょうがないのでソースからビルドすることにした。
いずれにせよ各環境で同じバージョンのビルドに合わせるべきだとは思う。
Beanstalk環境の場合、AMIに固めていたとしても非Beanstalk AMIではyum updateされてしまうので注意が必要だ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/106/&#34;&gt;BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;前UbuntuでやったようにDockerでビルドする。今回はAmazon Linux向け。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/32/&#34;&gt;td-agentをビルドしてfluentdのバージョンを上げる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/sambaiz/docker-td-agent-build-amazon-linux/&#34;&gt;https://hub.docker.com/r/sambaiz/docker-td-agent-build-amazon-linux/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM amazonlinux:2017.03

WORKDIR /tmp

RUN yum -y update &amp;amp;&amp;amp; \
    yum groupinstall -y &amp;quot;Development Tools&amp;quot; &amp;amp;&amp;amp; \
    yum install -y ruby23 ruby23-devel &amp;amp;&amp;amp; \
    gem install bundler io-console &amp;amp;&amp;amp; \
    git clone https://github.com/treasure-data/omnibus-td-agent

WORKDIR /tmp/omnibus-td-agent

RUN bundle install --binstubs &amp;amp;&amp;amp; \
    bin/gem_downloader core_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader plugin_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader ui_gems.rb &amp;amp;&amp;amp; \
    mkdir -p /opt/td-agent /var/cache/omnibus &amp;amp;&amp;amp; \
    bin/omnibus build td-agent2 &amp;amp;&amp;amp; \
    mv ./pkg/*.rpm /
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t amazon-linux-td-agent .
$ docker run --name altd -itd amazon-linux-td-agent sh
$ docker cp altd:/td-agent-2.3.5-1.el2017.x86_64.rpm .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとはこれをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yum install -y redhat-lsb-core
$ rpm -ivh td-agent-2.3.5-1.el2017.x86_64.rpm 
$ td-agent --version
td-agent 0.12.36
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因</title>
          <link>https://www.sambaiz.net/article/106/</link>
          <pubDate>Sun, 04 Jun 2017 23:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/106/</guid>
          <description>

&lt;h2 id=&#34;user-dataとは-http-docs-aws-amazon-com-ja-jp-awsec2-latest-userguide-user-data-html&#34;&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/user-data.html&#34;&gt;User-Dataとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;EC2インスタンス起動時に、シェルスクリプトを走らせたりcloud-initディレクティブを適用できる機能。
コンソールではインスタンスの詳細の設定の、高度な詳細のところから設定できる。&lt;/p&gt;

&lt;h2 id=&#34;beanstalkでのuser-data&#34;&gt;BeanstalkでのUser-Data&lt;/h2&gt;

&lt;p&gt;実はBeanstalkでも使われていて、CloudFormationで設定されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;    /bin/bash /tmp/ebbootstrap.sh &amp;quot;,

...

&amp;quot;Fn::FindInMap&amp;quot;: [
    &amp;quot;AWSEBOptions&amp;quot;,
    &amp;quot;options&amp;quot;,
    &amp;quot;UserDataScript&amp;quot;
]
&amp;quot; &amp;gt; /tmp/ebbootstrap.sh &amp;quot;,

...

&amp;quot;AWSEBOptions&amp;quot;: {
    &amp;quot;options&amp;quot;: {
        &amp;quot;UserDataScript&amp;quot;: &amp;quot;https://s3-ap-northeast-1.amazonaws.com/elasticbeanstalk-env-resources-ap-northeast-1/stalks/eb_node_js_4.0.1.90.2/lib/UserDataScript.sh&amp;quot;,
        &amp;quot;guid&amp;quot;: &amp;quot;f08557fc43ac&amp;quot;,
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このshellの中では、時計を同期させたり、awsebユーザーを作成したりするほかに、
非Beanstalk AMI(is_baked=false)ではyum updateが走るようになっている。
そのため、AMIでのバージョンとBeanstalkで立ち上がったときのバージョンが異なることがあるようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GUID=$7

function update_yum_packages
{
  if is_baked update_yum_packages_$GUID; then
    log yum update has already been done.
  else
    log Updating yum packages.
    yum --exclude=aws-cfn-bootstrap update -y || echo Warning: cannot update yum packages. Continue...
    mark_installed update_yum_packages_$GUID

    # Update system-release RPM package will reset the .repo files
    # Update the mirror list again after yum update
    update_mirror_list

    log Completed updating yum packages. 
  fi
}

function is_baked
{
	if [[ -f /etc/elasticbeanstalk/baking_manifest/$1 ]]; then
    true
	else
    false
	fi
}

function mark_installed
{
    mkdir -p /etc/elasticbeanstalk/baking_manifest/
    echo `date -u` &amp;gt; /etc/elasticbeanstalk/baking_manifest/$1-manifest
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Beanstalk AMIでのログ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /var/log/messages | grep yum
[eb-cfn-init]: yum repo has already been locked to f08557fc43ac.
[eb-cfn-init]: yum update has already been done.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;非Beanstalk AMIでのログ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /var/log/messages | grep yum
[eb-cfn-init]: Completed yum repo version locking.
[eb-cfn-init]: Updating yum packages.
yum[1597]: Updated: *****
...
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unity/UWPでBLEを扱うプラグインを作る</title>
          <link>https://www.sambaiz.net/article/105/</link>
          <pubDate>Sun, 04 Jun 2017 11:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/105/</guid>
          <description>&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/UnityBLE_UWP&#34;&gt;ここ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/aonishi/2013/12/04/unity-on-windows-8-1/&#34;&gt;この動画&lt;/a&gt;の
50:00あたりから説明があるように、
ビルドされたWSAが読むUWPのdllのほかに、
Unityエディタ上から読むための.NET Framework3.5のdllを用意する。
こうすることで実行環境ごとの違いをUnityコード上で気にしなくてもよくなる。&lt;/p&gt;

&lt;p&gt;新しいプロジェクトで&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Visual C# から.NET Framework 3.5にしてクラスライブラリ(.NET Framework)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Visual C# -&amp;gt;　Windows -&amp;gt; ユニバーサルからクラスライブラリ(ユニバーサルWindows)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の2つのプロジェクトを同じソリューションに作成する。
VS2017で.NET Frameworkのクラスライブラリプロジェクトを作成するためには
Visual Studio Installerで.NET Coreのワークロードをインストールする必要がある。
また、これとは別に動作確認用のUWPアプリケーションプロジェクトを作成した。&lt;/p&gt;

&lt;p&gt;UWPの方のプロジェクトにあるClass1.csを削除し、追加 -&amp;gt; 既存の項目から、
もう片方のClass1.csをリンクとして追加して、この共通のcsにUWPのコードを書いていくんだけど、
そのまま書くと当然.NET Frameworkの方でビルドできないので
実装部分を&lt;a href=&#34;https://docs.unity3d.com/Manual/PlatformDependentCompilation.html&#34;&gt;#if WINDOWS_UWP ~ #endif&lt;/a&gt;
で囲む。UWPの方のプロジェクトにはプロパティ -&amp;gt; ビルドの条件付きコンパイルにWINDOWS_UWPが含まれているので有効になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void Start()
{
#if WINDOWS_UWP
    ...
#endif
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;UWPでBLEを扱うのは前書いた通り。
ただし、なぜかXAMLに依存しているようでD3Dビルドすると失敗する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/101&#34;&gt;UWPでBLEデバイスとペアリングして値を取得する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ビルドするとdllができるので.NET Frameworkの方をAssets/Pluginsに置いてInspectorからEditorにだけチェックを入れる。
UWPの方は&lt;a href=&#34;https://docs.unity3d.com/Manual/PluginInspector.html&#34;&gt;Assets/Plugins/WSA&lt;/a&gt;に置くとWSA Playerにだけチェックが入る。&lt;/p&gt;

&lt;p&gt;あとは普通にusingして使うだけ。Edit-&amp;gt;Project Settings-&amp;gt;PlayerからBluetoothのcapabilityを有効にするのを忘れずに。
Package.appxmanifestは上書きされないようなので前にビルドしたやつがあったら一旦消す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityBLE;
  
public class BLE : MonoBehaviour {

    string value = &amp;quot;no connection&amp;quot;;

    public GameObject text;

    private string serviceUUID = &amp;quot;***&amp;quot;;
    private string characteristicUUID = &amp;quot;***&amp;quot;;

    void Start() {
        var ble = new UnityBLE.BLE();
        ble.DeviceAdded += (sender, obj) =&amp;gt; {
            value = &amp;quot;DeviceID: &amp;quot; + obj.DeviceID;
            ble.Listen(obj.DeviceID, serviceUUID, characteristicUUID);
            ble.Stop();
        };
        ble.CharacteristicReceived += (sender, obj) =&amp;gt;
        {
            if (sender == ble)
            {
                if (obj.ex == null)
                {
                    value = Encoding.UTF8.GetString(obj.Value);
                }
                else
                {
                    value = obj.ex.Message;
                }
            }
        };
        ble.Start();
    }

    void Update() {
        text.GetComponent&amp;lt;TextMesh&amp;gt;().text = value;
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる</title>
          <link>https://www.sambaiz.net/article/104/</link>
          <pubDate>Sat, 27 May 2017 16:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/104/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/uber-go/zap&#34;&gt;https://github.com/uber-go/zap&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u go.uber.org/zap
$ go get -u gopkg.in/natefinch/lumberjack.v2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;速さの秘訣&#34;&gt;速さの秘訣&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://techblog.ca-reward.co.jp/2016/06/post-33.html&#34;&gt;Go言語のLogger「zap」は何故高速に構造化されたログを出力する事が出来るのか｜株式会社CAリワード&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;reflectionとallocationの回避。&lt;/p&gt;

&lt;p&gt;一度allocateしたBufferやEncoderは
&lt;a href=&#34;https://golang.org/pkg/sync/#Pool&#34;&gt;sync.Pool&lt;/a&gt;で使い回している。
このPoolはまさにallocateされたアイテムを再利用するためのもので、GCの負担を緩和させることができる。
Poolのアイテムは勝手に削除されることがあり、もし参照しか持っていなかったらそのままdeallocateされる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/uber-go/zap/blob/v1.4.0/buffer/pool.go#L34&#34;&gt;https://github.com/uber-go/zap/blob/v1.4.0/buffer/pool.go#L34&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewPool() Pool {
	return Pool{p: &amp;amp;sync.Pool{
		New: func() interface{} {
			return &amp;amp;Buffer{bs: make([]byte, 0, _size)}
		},
	}}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;

&lt;p&gt;現状ドキュメントが乏しいのでコードから探っていく必要がある。
まずはQuick Startから。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;zap.NewProduction()&lt;/code&gt;は&lt;code&gt;NewProductionConfig().Build(options...)&lt;/code&gt;の&lt;a href=&#34;https://github.com/uber-go/zap/blob/master/logger.go#L87&#34;&gt;ショートカット&lt;/a&gt;。
ConfigをBuildしてLoggerを取得し、InfoやErrorで書く流れ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;logger, _ := zap.NewProduction()
defer logger.Sync()
logger.Info(&amp;quot;Hoge&amp;quot;,
  // Structured context as strongly-typed Field values.
  zap.Int(&amp;quot;attempt&amp;quot;, 3),
  zap.Duration(&amp;quot;backoff&amp;quot;, time.Second),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1495870212.3378785,&amp;quot;caller&amp;quot;:&amp;quot;zap-log/main.go:36&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;Hoge&amp;quot;,&amp;quot;attempt&amp;quot;:3,&amp;quot;backoff&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;NewProductionConfig()&lt;/code&gt;の内容はこんな感じ。ここからOutputPathを書き換えるとファイルに出力されるようにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;config := zap.Config{
    Level:       zap.NewAtomicLevelAt(zap.ErrorLevel),
    Development: false,
    Sampling: &amp;amp;zap.SamplingConfig{
        Initial:    100,
        Thereafter: 100,
    },
    Encoding: &amp;quot;json&amp;quot;,
    EncoderConfig: zapcore.EncoderConfig{
        TimeKey:        &amp;quot;ts&amp;quot;,
        LevelKey:       &amp;quot;level&amp;quot;,
        NameKey:        &amp;quot;logger&amp;quot;,
        CallerKey:      &amp;quot;caller&amp;quot;,
        MessageKey:     &amp;quot;msg&amp;quot;,
        StacktraceKey:  &amp;quot;stacktrace&amp;quot;,
        LineEnding:     zapcore.DefaultLineEnding,
        EncodeLevel:    zapcore.LowercaseLevelEncoder,
        EncodeTime:     zapcore.EpochTimeEncoder,
        EncodeDuration: zapcore.SecondsDurationEncoder,
        EncodeCaller:   zapcore.ShortCallerEncoder,
    },
    OutputPaths:      []string{&amp;quot;stderr&amp;quot;},
    ErrorOutputPaths: []string{&amp;quot;stderr&amp;quot;},
}
config.OutputPaths = []string{&amp;quot;./aaaa.log&amp;quot;}
logger, _ = config.Build()
defer logger.Sync()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Buildの引数にも渡せるOptionというのは&lt;code&gt;apply(logger)&lt;/code&gt;でloggerを操作するインタフェース。
&lt;a href=&#34;https://github.com/uber-go/zap/blob/74ca5ef91c08e5eafb5ab9739df05d66f1b5d8da/options.go#L55&#34;&gt;zap.Fields&lt;/a&gt;は
フィールドを追加するもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;logger = logger.WithOptions(zap.Fields(zap.String(&amp;quot;hoge&amp;quot;, &amp;quot;fuga&amp;quot;)))
defer logger.Sync()
logger.Error(&amp;quot;aaa&amp;quot;,
    zap.String(&amp;quot;eee&amp;quot;, &amp;quot;eee&amp;quot;),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/uber-go/zap/blob/v1.4.0/config.go#L154&#34;&gt;Build&lt;/a&gt;の実装をみると、
中では&lt;code&gt;zapcore.NewCore(enc, sink, cfg.Level)&lt;/code&gt;とOptionを引数として取る&lt;code&gt;New()&lt;/code&gt;でloggerを生成している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;enc, err := cfg.buildEncoder()
if err != nil {
    return nil, err
}

sink, errSink, err := cfg.openSinks()
if err != nil {
    return nil, err
}

log := New(
    zapcore.NewCore(enc, sink, cfg.Level),
    cfg.buildOptions(errSink)...,
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このsinkは&lt;code&gt;io.Writer&lt;/code&gt;をwrapした&lt;a href=&#34;https://github.com/uber-go/zap/blob/179e456766f6ba6d1006f432f90d52ecb6296e84/zapcore/write_syncer.go#L32&#34;&gt;WriteSyncer&lt;/a&gt;
で、&lt;code&gt;AddSync(w io.Writer)&lt;/code&gt;で変換できる。
これに&lt;a href=&#34;https://github.com/natefinch/lumberjack&#34;&gt;lumberjack&lt;/a&gt;を渡してやるとrotateできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;config := zap.NewProductionConfig()
enc := zapcore.NewJSONEncoder(config.EncoderConfig)
sink := zapcore.AddSync(
    &amp;amp;lumberjack.Logger{
        Filename:   &amp;quot;./aaaa.log&amp;quot;,
        MaxSize:    500, // megabytes
        MaxBackups: 3,
        MaxAge:     28, //days
    },
)
logger := zap.New(
    zapcore.NewCore(enc, sink, config.Level),
)
defer logger.Sync()
logger.Error(&amp;quot;aaa&amp;quot;,
    zap.String(&amp;quot;eeef&amp;quot;, &amp;quot;eefe&amp;quot;),
)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>夜のNY郊外を無一文で彷徨い、Google I/OとMaker Faire Bay Areaに行ってきた</title>
          <link>https://www.sambaiz.net/article/103/</link>
          <pubDate>Mon, 22 May 2017 23:44:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/103/</guid>
          <description>

&lt;p&gt;Googleが毎年やっているイベント、Google I/Oのチケットが当たったのでアメリカに行ってきた。
海外に行くのはこれが3回目でアメリカははじめて。一人での海外もはじめて。&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;チケットが当たってからExpediaで航空券やホテルを取った。航空券の流れで保険にも加入した。
アメリカの医療費は相当高いそうなので何かしらの保険に入っておかないと不安だ。&lt;/p&gt;

&lt;p&gt;会期中は会場近辺のサンフランシスコ/マウンテンビューのホテルがとんでもなく値上がりしている模様。
多分通常の倍ぐらいにはなっているので早めに取っておくとよいと思われる。&lt;/p&gt;

&lt;p&gt;GoogleI/Oは週末にかけての3日間だったので、その前の週末から出発し、前半はニューヨークに行くことにして、
マンハッタンに宿を取った。&lt;/p&gt;

&lt;p&gt;アメリカに入国するのには&lt;a href=&#34;https://esta.cbp.dhs.gov/esta/application.html&#34;&gt;ESTA&lt;/a&gt;を申請する必要がある。
申請自体は72時間以内に通るのだけど、パスポート番号が必要がなので持っていなければ先に作っておく必要がある。
ESTAが通っていないと本当に入れないらしい。怖い。&lt;/p&gt;

&lt;p&gt;現地での通信手段はT-mobileの&lt;a href=&#34;https://prepaid-phones.t-mobile.com/prepaid-international-tourist-plan&#34;&gt;Tourist plan&lt;/a&gt;($30プリペイドでSIM+2GB LTE+国内通話+SMS)
を購入することにした。
日本にはsimを送ってくれないので現地で調達する必要がある。モバイルルータはちょっと高いような気がして借りなかった。&lt;/p&gt;

&lt;p&gt;あとは英語力をなんとかしようと付け焼刃でDMM英会話をはじめてみたが、準備期間が短すぎたかなと思う。&lt;/p&gt;

&lt;h2 id=&#34;出国&#34;&gt;出国&lt;/h2&gt;

&lt;p&gt;チェックインの締め切りが出発の1時間前だったので、
余裕を持って2時間前ぐらいには着くはずだったんだけど、こんなときに限って財布を落とすわ成田エクスプレスは突然運休するわで大ピンチ。
日暮里から京急のスカイライナーに乗ってスーツケースをかついで走ってなんとか飛行機には間に合ったが、
両替などする時間はなく、財布に1000円しか入っていない状態で出発することになってしまった。&lt;/p&gt;

&lt;p&gt;距離にして11000km、12時間のフライトの末、ニューヨークのジョン・F・ケネディ国際空港(JFK)に到着。
時差で-13時間になるため出発よりも早い時刻に到着することになって得した気分だ。
ついにアメリカに来た。&lt;/p&gt;

&lt;h2 id=&#34;ニューヨーク&#34;&gt;ニューヨーク&lt;/h2&gt;

&lt;p&gt;当初はニューヨーク観光しつつ、アムトラック(電車)でワシントンD.C.にも行っちゃおうかと考えてチケットまで買っていた。
しかし現実は厳しい。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;現地に到着し、通信手段を調達するためT-mobileのショップに向かおうとしたが、肝心のショップの場所がわからない。
もちろん日本のsimカードはすでに機能停止しているので空港のWifiで調べたところ、そこから一番近いところでも数km離れていることがわかった。
タイムズスクエアの近くにはあるようだったので、まずはなんとかしてホテルに向かうことにしたが、
JFKからマンハッタンまでは直線距離で20km以上離れている。ホテルの送迎サービスはなかった。
それでもGoogle mapに従って、途中free wifiを乗り継いでいけばこのときはなんとかなるかなと思っていた。&lt;/p&gt;

&lt;p&gt;空港から電車で行こうと思っていたところ、うかつにも謎タクシーに誘導されて乗ってしまった。
47ドルでホテルまで行ってくれると思いきや、それはJamaica駅までの料金で、ホテルまでは100ドルという。調べていた相場の倍だ。
傷口を広げないようJamaicaで降ろしてもらうことにした。
乗る前に現金はないからクレジットカードで払う旨を伝えたのだけど、
支払いの段になってクレジットカードの機械が壊れたから現金でと言い出して困った。なにせ1ドルも持っていないのだから。
近くのATMで現金を下ろすよう言われたのでクレジットカードを入れたのだけれど
2枚ともアウト。そこからどうやって払うんだって問いつめられるもののどうしようもない。
結局解放してもらえたが、初っ端からほとんど心が折れてしまって国に帰りたかった。&lt;/p&gt;

&lt;p&gt;それでもなんとかしてホテルにはたどり着かなくてはならないので、LIRRという電車でJamaicaからWoodside駅に向かった。
空港で調べたGoogle mapの経路に出たからそうしたのだけど、
マンハッタンにあるハブ駅、Pensilvania(Penn) stationまで行くほうが行き先表示に出ているので分かりやすかった。
改札はなくて切符は車内で確認される。&lt;/p&gt;

&lt;p&gt;案内の人に聞いて電車に乗ったんだけど、切符の確認の際にこの電車ではないと言われる。
乗り間違えると、引き返すためにホームで割と長く待つことになる。5月も半ばなのに白い息が出るぐらい寒い。
Googleで調べようにも、駅にあるWifiはどうも契約していないと使えなさそうなものしかなかった。
地下鉄にはfree wifiが通っていたが、それも全ての駅で使えるというわけではなさそうだった。&lt;/p&gt;

&lt;p&gt;Woodsideからは地下鉄に乗るのだけれど、この券売機がなぜかクレジットカードのPINをうけつけてくれずチケットを買えなかった。
カードが止まったかと思い、しょうがないので6kmほど歩いてマンハッタンまで向かうことにした。雨が降っていて、寒くて泣きたくなった。
空港でマップのデータを読んでいたのでGPSと合わせればオフラインでも自分の位置はわかるのが唯一の救いだ。
電話もなかったので、道中あったスタバなどのfree wifiを外から使わせてもらって、
家族に連絡をとって日本からクレジットカード会社に問い合わせてもらったが、
本人からの連絡じゃないとだめとのことでどうしようもなかった。&lt;/p&gt;

&lt;p&gt;マンハッタンに行くためにはイースト川を越える必要があったので、
地図上で橋になっているところを順番に見てまわったが、車や電車でないとだめなところばかりで暗雲がただこめる。
あとから調べたら、マンハッタンの南側、ブルックリンとマンハッタン橋は歩いて渡れたらしい。
あの向こうがマンハッタンなのになと沿岸を眺めながら、この時点で夜中の0時を回っていて、野宿の可能性を考え始める。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-manhattan.jpg&#34; alt=&#34;マンハッタンを眺める&#34; /&gt;&lt;/p&gt;

&lt;p&gt;途方に暮れて彷徨っていたところ、歩いていたおじさんとたまたま目が合って、
お金がなくて電車には乗れないんだけど、徒歩でマンハッタンに渡る方法はあるか聞いたら、
なんと地下鉄の駅まで案内してくれて運賃を出してくれた。
お礼するために連絡先を聞こうとしたのにすぐいなくなってしまわれた。命の恩人だ。&lt;/p&gt;

&lt;p&gt;なんとかホテルに到着し、電話を借りてカード会社に連絡したところ、
カードは普通に使える状態で電車の明細はこちらには届いていない、キャッシングは枠がないからできない、
というまさかの事実が発覚した。
カードが使えるとはいえ現金がないと困ることが分かったので、キャッシング枠の審査を急いでもらうよう頼んでみた。&lt;/p&gt;

&lt;p&gt;もはや遠出する気が全くなくなったのでアムトラックのチケットをキャンセルしようと思ったら、システムメンテナンスでできずに諦める。
雨の中歩き回ったのでスーツケースの中の服はほとんどびしょ濡れだった。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;次の日は昼をまわったころ目覚めて、だらだらして風呂に入ってT-mobileのショップに向かってsimを購入。
設定は向こうの人がやってくれるので、言語を英語にしておくとスムーズだ。
念願の通信手段を得て、Google mapがいつでも使えるようになった。つまり無敵。
とはいえ、いまだ現金がないのでマンハッタンの中で過ごすことにした。&lt;/p&gt;

&lt;p&gt;マンハッタンは高いビルが多く、GPSが大きくずれる。縦横のStreetとAvenueに番号が振られているのでそれに従うと動きやすかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-stav.jpg&#34; alt=&#34;StreetとAvenueの表示&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Shake Shackのハンバーガーを食べて、チェルシーマーケットでロブスターを食べた。これでもsmall。
身はぎっしり入っていてレモンをかけて食べるとおいしい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-bigebi.jpg&#34; alt=&#34;チェルシーマーケットのロブスター&#34; /&gt;&lt;/p&gt;

&lt;p&gt;それと、なぜかカードが使えなかった地下鉄に再チャレンジしてみた。
問題になったのはこういう券売機。クレジットカードを抜き差し(dip)してPINを入力する。やっぱり買えない。
いろいろ試して見たところPINを入力せずにENTERだけ押したら買えることがわかった。意味わからん・・・。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-ny-subway-machine.jpg&#34; alt=&#34;NYの地下鉄の券売機&#34; /&gt;&lt;/p&gt;

&lt;p&gt;夜にキャッシングができるようになったのでタクシードライバーに連絡をとって代金を支払って2日目も終わり。
3日目は空港に向かう日なので、これがNY滞在の全て。次来るときはもう少しなんとかしたい。&lt;/p&gt;

&lt;p&gt;到着はJFKだったけど、出発はニューアーク・リバティー空港(EWR)からで、Penn stationからNJ TRANSIT(電車)一本で行ける。
Penn stationは上にも書いたとおりハブ駅で、アムトラック、LIRR、NJ TRANSITの駅が入っている。
ワシントンD.C.に行くときもこの駅から出るはずだった。
最初、画面にTrack(ホーム)が書いてなくてちょっと焦ったが、STATUSがBOARDINGになると表示される。&lt;/p&gt;

&lt;p&gt;EWRの飲食店にはタブレットが置いてあって、そこで注文しカードを通すと注文される。現金は使えない。
最初にboarding passのバーコードをかざすと乗る便の情報が表示されるので乗り遅れる心配がない。乗り遅れるどころか2時間遅延してたけど。
終わったらtabをcloseする。チップの割合も選択できるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-ewr.jpg&#34; alt=&#34;EWRの飲食店のタブレット&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ここから西海岸、サンフランシスコへ。
国内ながら3時間の時差があって、6時間のフライトなのに3時間しか進まない。&lt;/p&gt;

&lt;h2 id=&#34;googlei-o&#34;&gt;GoogleI/O&lt;/h2&gt;

&lt;p&gt;I/Oに参加する同僚2人と合流した。一人でないのは心強い限りだ。&lt;/p&gt;

&lt;p&gt;GoogleI/O自体は3日間なのだけれど、前日に登録ができ、先着順でKeynoteの前の方の席が割り当てられる。
今年の会場は去年と同じマウンテンビューのShoreline Amphitheatreというところで、Googleの近くにある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-shoreline.jpg&#34; alt=&#34;Shoreline Amphitheatre&#34; /&gt;&lt;/p&gt;

&lt;p&gt;サンフランシスコからもサンノゼからもそれなりに離れていて、最寄りの電車の駅も少し離れているので、バスか車で来ることになると思う。
同僚がレンタカーを借りてくれていたのでそれで向かったが、フリーウェイの、特に出口が渋滞して結構時間がかかる。
駐車場が一杯なのではないか心配していたけど、普通の駐車場の他に滅茶苦茶広いオーバーフロー駐車場があるので問題なかった。
どこまで駐車場なのかわからないぐらい広い。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-parking.jpg&#34; alt=&#34;オーバーフロー駐車場&#34; /&gt;&lt;/p&gt;

&lt;p&gt;受付を済ませると首からかけるバッジと、水筒、日焼け止め、Tシャツ、サングラスがもらえた。
会場は基本屋外なのでかなり実用的なセットだ。一方夜は相当寒いので上着を持っていったほうがよい。
バッジはNFCタグになっていて、セッション予約の確認に使われる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-ioset.jpg&#34; alt=&#34;もらったもの&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ついでに近くのGoogleも見にいってきた。ショップがある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-google.jpg&#34; alt=&#34;Google&#34; /&gt;&lt;/p&gt;

&lt;p&gt;その後サンフランシスコ市内の北、フィッシャーマンズワーフのBOUDINという店でパンの器のクラムチャウダーを食べた。
おいしかった。海の方を眺めるとアルカトラズが見える。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-boudin.jpg&#34; alt=&#34;クラムチャウダー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;夜はIntel&amp;rsquo;s Google I/O Day Zero Partyという非公式の前夜祭みたいなのに行ってきた。
I/Oに比べると規模はそんなに大きくはないけど、それでも多くの人が集まっていて、日本勢にも出会った。
飲み放題食べ放題で、IntelやGoogleのテクノロジーに絡んだデモが行われている。
体験したりしてトークンを集めることで賞品と交換でき、アンドロイドのTシャツをもらった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-zero-day.jpg&#34; alt=&#34;アンドロイドのTシャツ&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Keynoteは一番広いアンフィシアターで行われ、内側の椅子エリアと外側の芝のエリアがある。
遅れてしまったため芝エリアしか入れなくて午前中はそこで聞くことしたら、暑いけど寝転がりながら聞くことができるので案外悪くなかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-keynote.jpg&#34; alt=&#34;芝席&#34; /&gt;&lt;/p&gt;

&lt;p&gt;食事は指定の場所で配られているので取っていって適当な場所で食べる。
朝食も含めて食事や飲み物やお菓子は全て提供されるが、朝食は数がそんなに多くないのか、遅い時間に行くとなくなっていることがあった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-food.jpg&#34; alt=&#34;食事のリスト&#34; /&gt;&lt;/p&gt;

&lt;p&gt;午後のDeveloper Keynoteでは主な新機能などがざっくり発表されて、What&amp;rsquo;s newなどのセッションではそれが詳細に説明されたりする形になっている。&lt;/p&gt;

&lt;p&gt;Androidは、GooglePlay Protectや、地味に長いブート時間が2倍速くなったりするAndroid Oが発表された。あと、嬉しそうにもう一つあるよって言い出して
何かなと思ったらKotlin公式サポート。Android勢歓喜。よかったね。&lt;/p&gt;

&lt;p&gt;Daydream(VR)はスマホ不要のStandaloneヘッドセットと、位置トラッキングのWorldSense。
Tango(AR)はGPSに対して、室内で位置を知ることができるVPS(Visual Positioning Service)というのが発表されていた。これを使うと店内でナビできるすごく便利そうなやつだ。
VR/ARは教育分野、&lt;a href=&#34;https://edu.google.com/expeditions/&#34;&gt;Google Expeditions&lt;/a&gt;でも使われているらしい。
ARで教室に火山や竜巻を出したりできる。後のセッションで言っていたのは、どこにでもVRで行って何でもARで見れるだったかな。&lt;/p&gt;

&lt;p&gt;あとはGoogle photoのサジェスト機能や、なんかすごいGoogle lensなどなど。
Keynoteを通して、Googleっていろんなことをやっていて、世界が便利になるイメージが湧いた。&lt;/p&gt;

&lt;p&gt;最後に突然のGoogle Home+GCPクレジット配布の発表。うれしい。
日本での発売も発表されたが、一足早く手に入れることができた。何か作ってみたい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-home.jpg&#34; alt=&#34;Google Home&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Keynoteが終わると並行してセッション、展示やオフィスアワーなどが行われる。
セッションは1時間区切りになっていて、移動の時間が用意されていないように見えるが、
実際は30~40分ほどで終わるので一杯に入れても問題はない。
ただ、一日中ずっとセッションを聞いているというのも疲れるので、
割とみんなその辺りにある椅子や芝生に座ったり寝転がったりしてPCを開いてたり、歓談してたりする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-relax.jpg&#34; alt=&#34;会場風景&#34; /&gt;&lt;/p&gt;

&lt;p&gt;セッションはAR(Tango)/VR(Daydream)、Firebase、Android Thingsなどいろいろな種類のを聞きにいった。
全てのセッションはライブストリーミングされているので日本でも聞けるけど、
現地だと会場の雰囲気を楽しめるのはもちろん、しなかったけどセッションの後やオフィスアワーで質問したりすることができる。
次来るときは質問できるぐらい使い込んでいきたい。&lt;/p&gt;

&lt;p&gt;Firebaseもいくつか機能追加があって、そのうちの一つがPhone number auth。早速ためしてみた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/102/&#34;&gt;io17で発表されたFirebaseのphone number authをwebで試してみた&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AndroidThingsはIoTのためのOS。
Androidのエコシステムに乗れることと、プロトタイプから本番までのスケーリングしやすさ、セキュリティが特長として挙げられていた。
せっかくなのでcodelabsで触ってきた。codelabsでは、Googleのテクノロジーのチュートリアルのコースを質問しながら進められる。
Android端末など必要な機材は用意されているので、それらを持っていなくても問題ない。IoTはなかなかの人気コンテンツで2時間待つことになった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-codelabs.jpg&#34; alt=&#34;IOT codelab&#34; /&gt;&lt;/p&gt;

&lt;p&gt;コースを最後まで終えるとAndroid Things対応のハードウェアセットがもらえた。
codelabsはwebに&lt;a href=&#34;https://codelabs.developers.google.com/io2017&#34;&gt;公開されている&lt;/a&gt;ので家でも試すことができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-iot-omiyage.jpg&#34; alt=&#34;IOTおみやげ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;1,2日目のセッションが終わるとAfter Hourというパーティーがある。
朝から夜まで楽しめる、とても良いイベントだった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-party.jpg&#34; alt=&#34;After Hour&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;maker-faire-bay-area&#34;&gt;Maker Faire Bay Area&lt;/h2&gt;

&lt;p&gt;Google I/Oが終わった翌日、同僚を空港で見送ってSan mateoで行われるMaker Faire Bay Areaにいってきた。&lt;/p&gt;

&lt;p&gt;Maker Faireは、ものづくりが好きな人たちが集まり、作ったものを展示発表したり体験したりするお祭り。
このBay Areaからはじまり、世界中に広がっている。
東京でも行われているんだけど、行ったことがないためこれが初参加。&lt;/p&gt;

&lt;p&gt;空港から会場のSan Mateo Event Centerまではバス(SamTrans)で向かった。
運賃は現金で払うこともできるけど、Clipperという日本のSuicaみたいなやつがあると便利。空港のInformationで買えた。
バスの運賃は2ドルちょっと。&lt;/p&gt;

&lt;p&gt;バス停は柱の上の方にある行き先が書いてある札が目印。待合所があるところもあれば、ただの柱にくっついているところもあってちょっと気づきにくい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-busstop.jpg&#34; alt=&#34;バス停&#34; /&gt;&lt;/p&gt;

&lt;p&gt;乗ったらClipperをピッとやって席に座り、降りたければ黄色い紐を引くとSTOP REQUESTEDされる。
バス停に近づいても特にアナウンスなく通過してしまうのでGPSの位置を注意して見ていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-stop-requested.jpg&#34; alt=&#34;STOP REUESTEDの紐&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;会場はとても広い。何も考えずにうろうろしていたのだけど、あとでマップを見返したら、見てない場所とかがあったりしたので、最初にマップで行く場所に目星をつけておいたほうがよいと思う。
展示のジャンルごとにテントがあって、ほかにはアクティビティやステージ、食べ物の屋台、体験コーナーなどがある。
屋台は基本現金払いだけど、ATMが会場内にもある。
子供連れもたくさんいて、大人子供ともに楽しめるイベントになっていた。&lt;/p&gt;

&lt;p&gt;展示物は、子供が作ったものから、こんなの個人で作れるのかというようなものまで、ジャンルも電子工作からガーデニングまでいろいろ。
日本から出している人もいて、ロボットのところにデイリーポータルZや個人のブースがいくつかあった。&lt;/p&gt;

&lt;p&gt;すごい勢いで燃えながら回転する球。日本だと消防法的にまずそう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-burning.jpg&#34; alt=&#34;燃える球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;自転車をこいで電力を賄うステージ。ステージもいくつかあって、他では化学の実験をやっていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-you-are-the-power.jpg&#34; alt=&#34;YOU ARE THE POWER!&#34; /&gt;&lt;/p&gt;

&lt;p&gt;アクティビティをやるには自己責任的な誓約書にサインしてリストバンドをもらう必要がある。
これは音楽に合わせて対応するところを踏んだり引いたりするゲーム。アクションは5つしかないんだけど、なかなか難しかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-make-act.jpg&#34; alt=&#34;音ゲー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ドローンレースをやっているテントもあった。モニターにはドローン視点の映像が流れていて迫力がある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-drone.jpg&#34; alt=&#34;ドローンレース&#34; /&gt;&lt;/p&gt;

&lt;p&gt;R2D2がいた。もちろん動く。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-r2d2.jpg&#34; alt=&#34;R2D2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;せっかくAndroid Thingsのハードウェアも手に入ったことだし、何か作って出展してみたい。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;これでアメリカでの予定も終わり。
9日間ながら内容が濃い滞在だった。また行きたい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>io17で発表されたFirebaseのphone number authをwebで試してみた</title>
          <link>https://www.sambaiz.net/article/102/</link>
          <pubDate>Wed, 17 May 2017 23:34:00 -0700</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/102/</guid>
          <description>&lt;p&gt;今日のdeveloper keynoteで発表されたphone number authを試してみた。
Firebaseだと他にはPerformance Monitoringも発表されている。
あとSDKをオープンソースにするとか。&lt;/p&gt;

&lt;p&gt;firebase-toolsを最新版にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# npm install -g firebase-tools
$ firebase -V
3.9.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FirebaseUIを使う場合、これも最新版にしないと出てこない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&amp;quot;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;link type=&amp;quot;text/css&amp;quot; rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.css&amp;quot; /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;firebase.auth.PhoneAuthProvider.PROVIDER_ID&lt;/code&gt;がphone number authの
&lt;a href=&#34;https://github.com/firebase/firebaseui-web#starting-the-sign-in-flow&#34;&gt;オプション&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const uiConfig = {
    signInOptions: [
        firebase.auth.PhoneAuthProvider.PROVIDER_ID
    ],
    ...
}

const ui = new firebaseui.auth.AuthUI(firebase.auth());
ui.start(&#39;#firebaseui-auth-container&#39;, uiConfig);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなボタンを押すと&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/102-1.png&#34; alt=&#34;ボタン&#34; /&gt;&lt;/p&gt;

&lt;p&gt;電話番号とCAPTCHAが入り、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/102-2.png&#34; alt=&#34;電話番号とCAPTCHA&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SMSに書かれた番号を入力すると認証される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/102-3.png&#34; alt=&#34;番号入力&#34; /&gt;&lt;/p&gt;

&lt;p&gt;二段階認証のようなものだと思っていたけど、そうではないみたい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UWPでBLEデバイスとペアリングして値を取得する</title>
          <link>https://www.sambaiz.net/article/101/</link>
          <pubDate>Sat, 13 May 2017 10:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/101/</guid>
          <description>

&lt;p&gt;ManifestからBluetoothを許可しておく。&lt;/p&gt;

&lt;h2 id=&#34;bleデバイスを見つける-https-github-com-microsoft-windows-universal-samples-blob-dev-samples-bluetoothleclient-cs-scenario1-discoverserver-xaml-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/Windows-universal-samples/blob/dev/Samples/BluetoothLEClient/cs/Scenario1_DiscoverServer.xaml.cs&#34;&gt;BLEデバイスを見つける&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;CreateWatcher&lt;/code&gt;にBluetooth LEプロトコルの&lt;a href=&#34;https://docs.microsoft.com/ja-jp/windows/uwp/devices-sensors/aep-service-class-ids&#34;&gt;AEP(Association EndPoint)サービスクラスID&lt;/a&gt;と
requestPropaertiesで必要なデバイス情報を渡している。
最後の&lt;code&gt;AssociationEndpoint&lt;/code&gt;は&lt;code&gt;System.Devices.Aep.ProtocolId&lt;/code&gt;のAepと&lt;a href=&#34;https://docs.microsoft.com/ja-jp/windows/uwp/devices-sensors/enumerate-devices-over-a-network&#34;&gt;対応している&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using Windows.Devices.Enumeration;

string[] requestedProperties = { &amp;quot;System.Devices.Aep.DeviceAddress&amp;quot;, &amp;quot;System.Devices.Aep.IsConnected&amp;quot; };

deviceWatcher = DeviceInformation.CreateWatcher(
                        &amp;quot;(System.Devices.Aep.ProtocolId:=\&amp;quot;{bb7bb05e-5972-42b5-94fc-76eaa7084d49}\&amp;quot;)&amp;quot;,
                        requestedProperties,
                        DeviceInformationKind.AssociationEndpoint);

deviceWatcher.Start();
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;deviceWatcher.Added += DeviceWatcher_Added;
deviceWatcher.Removed += DeviceWatcher_Removed;
deviceWatcher.Updated += DeviceWatcher_Updated;
/*
deviceWatcher.EnumerationCompleted += DeviceWatcher_EnumerationCompleted;
deviceWatcher.Stopped += DeviceWatcher_Stopped;
*/

Dictionary&amp;lt;string, DeviceInformation&amp;gt; deviceInfos = new Dictionary&amp;lt;string, DeviceInformation&amp;gt;();

private void DeviceWatcher_Added(DeviceWatcher sender, DeviceInformation deviceInfo)
{

    if (sender == deviceWatcher)
    {
        if (deviceInfo.Name != string.Empty)
        {
            deviceInfos.Add(deviceInfo.Id, deviceInfo);   
        }
    }
}

private void DeviceWatcher_Updated(DeviceWatcher sender, DeviceInformationUpdate deviceInfoUpdate)
{
    if (sender == deviceWatcher)
    {
        deviceInfos[deviceInfoUpdate.id].Update(deviceInfoUpdate);
    }
}

 private void DeviceWatcher_Removed(DeviceWatcher sender, DeviceInformationUpdate deviceInfoUpdate)
{
    if (sender == deviceWatcher)
    {
        deviceInfos.Remove(deviceInfoUpdate.id);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ペアリング&#34;&gt;ペアリング&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;DevicePairingResult result = await deviceInfo.Pairing.PairAsync();
if (result.Status == DevicePairingResultStatus.Paired || result.Status == DevicePairingResultStatus.AlreadyPaired){
    // success
} else{
    // fail
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなウィンドウが出てくる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/101.png&#34; alt=&#34;ペアリング確認&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OSの設定からペアリングすることもできる。&lt;/p&gt;

&lt;h2 id=&#34;serviceのcharacteristicを取得する&#34;&gt;serviceのcharacteristicを取得する&lt;/h2&gt;

&lt;p&gt;ペアリングしたらこんな感じで値を取得できる。
&lt;a href=&#34;https://docs.microsoft.com/en-us/uwp/api/Windows.Devices.Bluetooth.BluetoothLEDevice#Windows_Devices_Bluetooth_BluetoothLEDevice_GetGattServicesForUuidAsync_&#34;&gt;GetGattServicesForUuidAsyc&lt;/a&gt;
などはCreaters Update(15063)から追加されたAPI。
Anniversary Edition(14393)まで&lt;a href=&#34;https://github.com/sambaiz/UnityBLE_UWP/tree/build_For_14393&#34;&gt;対応する場合&lt;/a&gt;
は&lt;code&gt;GetGattService&lt;/code&gt;を使う。いずれにしても最小バージョンをそれ以上にしておく。
deviceの値が取得できない場合はBluetoothが許可されているか確認する。
あと、characteristicが一つも取れない場合、他のアプリケーションからアクセスしていないか注意。
ドキュメントにも書いてあるけど、一つのサービスには一つのアプリケーションしかアクセスできない。
そもそも接続できない場合、一旦お互いの接続設定を消して再ペアリングするとよくなることがある。
ペアリングもできないようだったらBluetoothをオフにしてみるとか。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var device = await BluetoothLEDevice.FromIdAsync(deviceInfo.Id);

var services = await device.GetGattServicesForUuidAsync(serviceUUID);

var characteristics = await services.Services[0].GetCharacteristicsForUuidAsync(characteristicUUID);

characteristics.Characteristics[0].ValueChanged += characteristicChanged;

await characteristics.Characteristics[0].WriteClientCharacteristicConfigurationDescriptorAsync(
    GattClientCharacteristicConfigurationDescriptorValue.Notify
);

void characteristicChanged(
    GattCharacteristic sender,
    GattValueChangedEventArgs eventArgs
){
    byte[] data = new byte[eventArgs.CharacteristicValue.Length];
    Streams.DataReader.FromBuffer(eventArgs.CharacteristicValue).ReadBytes(data);
    var str = System.Text.Encoding.ASCII.GetString(data)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/105&#34;&gt;Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RxJSでObservableを結合する(merge, forkJoin, concat, combineLatest)</title>
          <link>https://www.sambaiz.net/article/100/</link>
          <pubDate>Tue, 09 May 2017 20:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/100/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/85/&#34;&gt;RxJSでRxをはじめる - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;merge-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-merge&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-merge&#34;&gt;merge&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;2つのstreamの両方の値がemitされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.merge(
  stream1,
  stream2
).subscribe(
  data =&amp;gt; console.log(`merge ${data}`),
  err =&amp;gt; console.log(`merge ${err}`)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;forkjoin-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-forkjoin&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-forkJoin&#34;&gt;forkJoin&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;completeしたときの最後の値を配列としてemitする。
非同期で一つ値をemitするようなstreamで、Promise.allのようなことをしたいときはこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.forkJoin(
  stream1,
  stream2
).subscribe(
  data =&amp;gt; console.log(`      forkJoin: ${data}`),
  err =&amp;gt; console.log(`      forkJoin: ${err}`)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;concat-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-concat&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-concat&#34;&gt;concat&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;前のstreamがcompleteしたら次のstreamの値がemitされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.concat(
  stream1,
  stream2
).subscribe(
  data =&amp;gt; console.log(`  concat ${data}`),
  err =&amp;gt; console.log(`  concat ${err}`)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;combinelatest-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-combinelatest&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-combineLatest&#34;&gt;combineLatest&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;stream自体を結合するのではなく値を結合する。
この例だと、stream1でemitされた値がa、stream2で最後にemitされた値がbのとき&lt;code&gt;a+b&lt;/code&gt;をemitする。
combineする値がない場合はemitされない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stream1.combineLatest(stream2, (a, b) =&amp;gt; a + b).subscribe(
  data =&amp;gt; console.log(`    combineLatest ${data}`),
  err =&amp;gt; console.log(`    combineLatest ${err}`)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;同時に実行したときの結果&#34;&gt;同時に実行したときの結果&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;const stream1 = Rx.Observable.interval(100).map(v =&amp;gt; `stream 1-${v+1}`).take(3);
const stream2 = Rx.Observable.interval(100).map(v =&amp;gt; `stream 2-${v+1}`).take(3).delay(150);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/100.png&#34; alt=&#34;stream1とstream2&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;merge stream 1-1
  concat stream 1-1
merge stream 1-2
  concat stream 1-2
merge stream 2-1 &amp;lt;- mergeではstream1はcompleteしていないが、stream2がemitされる
merge stream 1-3
  concat stream 1-3
    combineLatest stream 1-3stream 2-1 &amp;lt;- stream2の値がemitされたのでcombineする
merge stream 2-2
    combineLatest stream 1-3stream 2-2
      forkJoin: stream 1-3,stream 2-3 &amp;lt;- stream1とstream2がcompleteしたのでforkJoinでemitされる
    combineLatest stream 1-3stream 2-3
merge stream 2-3
  concat stream 2-1 &amp;lt;- concatではstream1がcompleteしたので、stream2がemitされる
  concat stream 2-2
  concat stream 2-3
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>angular/material2でフォームを作る</title>
          <link>https://www.sambaiz.net/article/99/</link>
          <pubDate>Sat, 06 May 2017 22:16:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/99/</guid>
          <description>

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99.gif&#34; alt=&#34;フォーム&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/angular4-form&#34;&gt;コード&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;angular-material2-https-github-com-angular-material2-の準備&#34;&gt;&lt;a href=&#34;https://github.com/angular/material2&#34;&gt;angular/material2&lt;/a&gt;の準備&lt;/h2&gt;

&lt;p&gt;現時点で
&lt;a href=&#34;https://github.com/angular/material2/issues/675&#34;&gt;DatePicker&lt;/a&gt;や
&lt;a href=&#34;https://github.com/angular/material2/issues/581&#34;&gt;Table&lt;/a&gt;など
開発中のコンポーネントが多いため足りないものを他のライブラリで補うなどする必要がある。
DatePickerはもう少しで出そう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save @angular/material
$ npm install --save hammerjs # gesture用
$ npm install --save @angular/animations
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Moduleで&lt;code&gt;import &#39;hammerjs&#39;;&lt;/code&gt;して、以下のModuleをimportに加える。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BrowserAnimationsModule&lt;/code&gt;(&lt;code&gt;from &#39;@angular/platform-browser/animations&#39;&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MdButtonModule&lt;/code&gt;など使うもの(&lt;code&gt;from &#39;@angular/material&#39;&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;スタイルとアイコン(md-icon)を追加。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;link href=&amp;quot;../node_modules/@angular/material/prebuilt-themes/indigo-pink.css&amp;quot; rel=&amp;quot;stylesheet&amp;quot;&amp;gt;
&amp;lt;link href=&amp;quot;https://fonts.googleapis.com/icon?family=Material+Icons&amp;quot; rel=&amp;quot;stylesheet&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;フォームを作る-https-angular-io-docs-ts-latest-guide-forms-html&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/forms.html&#34;&gt;フォームを作る&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;とりあえずコンポーネントを作成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g component TodoForm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Formの値をバインドするためのクラスを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export class TodoForm {
  constructor(
    public id: number,
    public title: string,
    public active: boolean,
    public priority?: number,
  ) {  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずは&lt;a href=&#34;https://material.angular.io/components&#34;&gt;material2の&lt;/a&gt;mdInput, mdSelect, mdButtonでフォームを作る。
&lt;code&gt;#todoForm&lt;/code&gt;のように頭についている#は
&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/template-syntax.html#!#ref-vars&#34;&gt;reference variable&lt;/a&gt;で、
titleはrequiredとしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&amp;quot;root&amp;quot;&amp;gt;
  &amp;lt;form (ngSubmit)=&amp;quot;onSubmit()&amp;quot; #todoForm=&amp;quot;ngForm&amp;quot;&amp;gt;

    &amp;lt;div *ngIf=&amp;quot;model.id !== 0&amp;quot; class=&amp;quot;form-item&amp;quot;&amp;gt;
      ID: {{model.id}}
    &amp;lt;/div&amp;gt;

    &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
      &amp;lt;md-input-container&amp;gt;
        &amp;lt;input mdInput name=&amp;quot;title&amp;quot; required placeholder=&amp;quot;やること&amp;quot; 
          [(ngModel)]=&amp;quot;model.title&amp;quot;&amp;gt;
      &amp;lt;/md-input-container&amp;gt;
    &amp;lt;/div&amp;gt;
    
    &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
      &amp;lt;md-select placeholder=&amp;quot;優先度&amp;quot; name=&amp;quot;priority&amp;quot; 
        [(ngModel)]=&amp;quot;model.priority&amp;quot;&amp;gt;
        &amp;lt;md-option [value]=&amp;quot;1&amp;quot;&amp;gt;高&amp;lt;/md-option&amp;gt;
        &amp;lt;md-option [value]=&amp;quot;2&amp;quot;&amp;gt;中&amp;lt;/md-option&amp;gt;
        &amp;lt;md-option [value]=&amp;quot;3&amp;quot;&amp;gt;低&amp;lt;/md-option&amp;gt;        
      &amp;lt;/md-select&amp;gt;
    &amp;lt;/div&amp;gt;

    &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
      &amp;lt;md-slide-toggle name=&amp;quot;active&amp;quot; [(ngModel)]=&amp;quot;model.active&amp;quot;&amp;gt;
        有効にする
      &amp;lt;/md-slide-toggle&amp;gt;
    &amp;lt;/div&amp;gt;

    &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
      &amp;lt;button type=&amp;quot;submit&amp;quot; md-raised-button [disabled]=&amp;quot;!todoForm.form.valid&amp;quot;&amp;gt;
        Submit
      &amp;lt;/button&amp;gt;
    &amp;lt;/div&amp;gt;
    
  &amp;lt;/form&amp;gt;
&amp;lt;/div&amp;gt;

&amp;lt;table&amp;gt;
  &amp;lt;thead&amp;gt;
    &amp;lt;tr&amp;gt;
      &amp;lt;th&amp;gt;ID&amp;lt;/th&amp;gt;
      &amp;lt;th&amp;gt;Title&amp;lt;/th&amp;gt;
      &amp;lt;th&amp;gt;Active&amp;lt;/th&amp;gt;
      &amp;lt;th&amp;gt;Priority&amp;lt;/th&amp;gt;
  &amp;lt;/thead&amp;gt;
  &amp;lt;tbody&amp;gt;
    &amp;lt;tr li *ngFor=&amp;quot;let todo of todos&amp;quot;&amp;gt;
      &amp;lt;td&amp;gt;{{todo.id}}&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;{{todo.title}}&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;{{todo.active}}&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;{{todo.priority}}&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;&amp;lt;button md-button (click)=&amp;quot;onEdit(todo.id)&amp;quot;&amp;gt;編集&amp;lt;/button&amp;gt;&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
  &amp;lt;/tbody&amp;gt;
&amp;lt;/table&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンポーネントはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Component({
  selector: &#39;app-todo-form&#39;,
  templateUrl: &#39;./todo-form.component.html&#39;,
  styleUrls: [&#39;./todo-form.component.css&#39;]
})
export class TodoFormComponent implements OnInit {

  constructor() { }

  todos: TodoForm[] = [];
  model = new TodoForm(0, &amp;quot;&amp;quot;, false);

  ngOnInit() {
  }

  onSubmit() {
    if(this.model.id === 0) {
      this.model.id = this.todos.length + 1;
      this.todos.push(this.model);
    }else{
      this.todos[this.model.id - 1] = this.model;
    }
    this.model = new TodoForm(0, &amp;quot;&amp;quot;, false);
  }

  onEdit(id: number) {
    this.model = Object.assign({}, this.todos[id - 1]);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;autocomplete-https-material-angular-io-components-component-autocomplete&#34;&gt;&lt;a href=&#34;https://material.angular.io/components/component/autocomplete&#34;&gt;AutoComplete&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;次に人を登録するためのtextフォームを作る。これは前もって登録されている人の中からAutoCompleteさせる。&lt;/p&gt;

&lt;p&gt;mdAutocompleteに候補を渡してmdInputのmdAutoCompleteにmdAutoCompleteの参照を渡す。
&lt;a href=&#34;https://angular.io/docs/ts/latest/api/forms/index/FormControl-class.html&#34;&gt;FormControl&lt;/a&gt;を扱うためには&lt;code&gt;@angular/forms&lt;/code&gt;の&lt;code&gt;ReactiveFormsModule&lt;/code&gt;をimportする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
    &amp;lt;md-input-container&amp;gt;
      &amp;lt;input mdInput name=&amp;quot;assignee&amp;quot; required placeholder=&amp;quot;やるひと&amp;quot; 
        [(ngModel)]=&amp;quot;model.assignee&amp;quot;
        [mdAutocomplete]=&amp;quot;autoAssignee&amp;quot;
        [formControl]=&amp;quot;assigneeFormControl&amp;quot;
      &amp;gt;
    &amp;lt;/md-input-container&amp;gt;

    &amp;lt;md-autocomplete #autoAssignee=&amp;quot;mdAutocomplete&amp;quot; [displayWith]=&amp;quot;displayAssignee&amp;quot;&amp;gt;
      &amp;lt;md-option *ngFor=&amp;quot;let p of filteredAssignee | async&amp;quot; [value]=&amp;quot;p&amp;quot;&amp;gt;
          {{ p.name }}
      &amp;lt;/md-option&amp;gt;
    &amp;lt;/md-autocomplete&amp;gt;
  &amp;lt;/div&amp;gt;
  
  &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
    &amp;lt;md-select placeholder=&amp;quot;優先度&amp;quot; name=&amp;quot;priority&amp;quot; 
      [(ngModel)]=&amp;quot;model.priority&amp;quot;&amp;gt;
      &amp;lt;md-option [value]=&amp;quot;1&amp;quot;&amp;gt;高&amp;lt;/md-option&amp;gt;
      &amp;lt;md-option [value]=&amp;quot;2&amp;quot;&amp;gt;中&amp;lt;/md-option&amp;gt;
      &amp;lt;md-option [value]=&amp;quot;3&amp;quot;&amp;gt;低&amp;lt;/md-option&amp;gt;        
    &amp;lt;/md-select&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;people: Person[] = [
  {id: 1, name: &amp;quot;taro&amp;quot;},
  {id: 2, name: &amp;quot;jiro&amp;quot;},
  {id: 3, name: &amp;quot;ichiro&amp;quot;}
];
assigneeFormControl = new FormControl();
filteredAssignee: Observable&amp;lt;Person[]&amp;gt;;

ngOnInit() {
  this.filteredAssignee = this.assigneeFormControl.valueChanges
        .startWith(null)
        .map(val =&amp;gt; val ? this.assigneeFilter(val) : this.people.slice());

  this.assigneeFormControl.asyncValidator
}

assigneeFilter(val: string): Person[] {
  return this.people.filter(p =&amp;gt; new RegExp(`^${val}`, &#39;gi&#39;).test(p.name)); 
}

displayAssignee(person: Person): string {
  return person ? person.name : &#39;&#39;;
}

export class TodoForm {
  constructor(
    public id: number,
    public title: string,
    public active: boolean,
    public priority?: number,
    public assignee?: Person,
  ) {  }
}

interface Person { id: number, name: string };
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;datepicker&#34;&gt;DatePicker&lt;/h2&gt;

&lt;p&gt;最後に目標日を設定するためにDatePickerを用意する。
上にも書いた通り、material2にはまだDatepickerがないので他のライブラリで代用する。
今回はAngular v4に対応していて見た目がシンプルな&lt;a href=&#34;https://github.com/koleary94/Angular-2-Datepicker&#34;&gt;koleary94/Angular-2-Datepicker&lt;/a&gt;を使った。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save angular2-material-datepicker
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
  &amp;lt;material-datepicker placeholder=&amp;quot;終了予定日&amp;quot; [(date)]=&amp;quot;model.deadline&amp;quot;&amp;gt;&amp;lt;/material-datepicker&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CSSのdisplayとposition</title>
          <link>https://www.sambaiz.net/article/98/</link>
          <pubDate>Sat, 06 May 2017 14:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/98/</guid>
          <description>

&lt;h2 id=&#34;display-https-developer-mozilla-org-ja-docs-web-css-display&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/display&#34;&gt;display&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;レンダリングに使うボックスを指定する。&lt;/p&gt;

&lt;h3 id=&#34;outer-display-type&#34;&gt;outer display type&lt;/h3&gt;

&lt;p&gt;pのようなブロックレベル要素やspanのようなインラインレベル要素に関わらず、指定したボックスにレンダリングする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99.png&#34; alt=&#34;outer display type&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:none&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;none&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt;

&amp;lt;div&amp;gt;this is &amp;lt;p style=&amp;quot;display:inline&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline&amp;lt;/p&amp;gt; desu&amp;lt;/div&amp;gt;

&amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt;

&amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;中央寄せ&#34;&gt;中央寄せ&lt;/h3&gt;

&lt;p&gt;中央寄せはblockにwidthを設定して&lt;code&gt;margin auto&lt;/code&gt;するか、
親要素で&lt;code&gt;text-align: center&lt;/code&gt;してinline(-block)にする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-center.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  background-color: #22ee22;
  height: 80px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div style=&amp;quot;margin: 5 auto&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block margin&amp;lt;/div&amp;gt;

&amp;lt;div style=&amp;quot;margin: 5 auto; width: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block margin width&amp;lt;/div&amp;gt;

&amp;lt;div style=&amp;quot;margin: 5 auto; display: inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block margin&amp;lt;/div&amp;gt;

&amp;lt;div style=&amp;quot;text-align: center&amp;quot;&amp;gt;
  
  &amp;lt;div style=&amp;quot;display: inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block align-center&amp;lt;/div&amp;gt;
  
  &amp;lt;div style=&amp;quot;width: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block align-center width&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;flex-https-developer-mozilla-org-ja-docs-web-css-css-flexible-box-layout-using-css-flexible-boxes&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/CSS_Flexible_Box_Layout/Using_CSS_flexible_boxes&#34;&gt;flex&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;displayでflexを指定するとflex containerになる。
&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-flow&#34;&gt;flex-flow&lt;/a&gt;は
表示する方向の&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-direction&#34;&gt;flex-direction&lt;/a&gt;と
折り返しの&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-wrap&#34;&gt;flex-wrap&lt;/a&gt;のショートハンドプロパティ。&lt;/p&gt;

&lt;p&gt;子要素の&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex&#34;&gt;flex&lt;/a&gt;は
伸びるときの倍率の&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-grow&#34;&gt;flex-grow&lt;/a&gt;(default: 0)と
縮むときの倍率の&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-shrink&#34;&gt;flex-shrink&lt;/a&gt;(default: 1)、
初期サイズの&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-basis&#34;&gt;flex-basis&lt;/a&gt;(default: auto)の
ショートハンドプロパティ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-flex.png&#34; alt=&#34;flex&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div&amp;gt;
  this is
  &amp;lt;div style=&amp;quot;display:flex; flex-flow: row wrap&amp;quot;&amp;gt;
    &amp;lt;div style=&amp;quot;flex: auto; margin: 2px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;flex-item1&amp;lt;/div&amp;gt;

    &amp;lt;!-- flex-basis --&amp;gt;
    &amp;lt;div style=&amp;quot;flex: 300px; margin: 2px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;flex-item2&amp;lt;/div&amp;gt;

    &amp;lt;!-- flex-grow | flex-shrink | flex-basis --&amp;gt;
    &amp;lt;div style=&amp;quot;flex: 0 1 30%; margin: 2px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;flex-item3&amp;lt;/div&amp;gt;
  &amp;lt;/div&amp;gt;
  desu
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;position-https-developer-mozilla-org-ja-docs-web-css-position&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/position&#34;&gt;position&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;relative&#34;&gt;relative&lt;/h3&gt;

&lt;p&gt;この設定を考慮せずにすべての要素を配置した後に設定を適用する。
そのため、この例の3つ目のdivの&lt;code&gt;left: 30px&lt;/code&gt;は2つ目のdivの元々の位置から30px右になっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-relative.png&#34; alt=&#34;relative&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  display: inline-block;
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div&amp;gt;
  &amp;lt;div class=&amp;quot;bg&amp;quot;&amp;gt;aaa&amp;lt;/div&amp;gt;
  &amp;lt;div style=&amp;quot;position: relative; top: 30px; left: 30px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;bbb&amp;lt;/div&amp;gt;
  &amp;lt;div style=&amp;quot;position: relative; left: 30px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;ccc&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;absolute&#34;&gt;absolute&lt;/h3&gt;

&lt;p&gt;絶対位置で指定する。位置指定された祖先要素の相対的な位置になる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-absolute.png&#34; alt=&#34;absolute&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  display: inline-block;
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div&amp;gt;
  &amp;lt;div class=&amp;quot;bg&amp;quot;&amp;gt;aaa&amp;lt;/div&amp;gt;
  &amp;lt;div style=&amp;quot;position: relative; top: 50px&amp;quot;&amp;gt;
    &amp;lt;div style=&amp;quot;background-color: #eeeeee&amp;quot;&amp;gt;relative top 50px&amp;lt;/div&amp;gt;
    &amp;lt;div style=&amp;quot;position: absolute; top: 50px; left: 300px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;top 50px; left: 300px&amp;lt;/div&amp;gt;
    &amp;lt;div style=&amp;quot;position: absolute; left: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;left 100px&amp;lt;/div&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;fixed&#34;&gt;fixed&lt;/h3&gt;

&lt;p&gt;ビューポートに対して絶対的な位置を指定する。この例では2つ目のfixedなdivはスクロールしてもビューポートに対して位置が固定される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-fixed.png&#34; alt=&#34;fixed&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  display: inline-block;
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div style=&amp;quot;height: 3000px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;aaa&amp;lt;/div&amp;gt;
&amp;lt;div style=&amp;quot;position: fixed; top: 50px; left: 300px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;top 50px; left: 300px&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AngularのRouter</title>
          <link>https://www.sambaiz.net/article/97/</link>
          <pubDate>Sun, 30 Apr 2017 22:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/97/</guid>
          <description>

&lt;pre&gt;&lt;code&gt;@angular/core&amp;quot;: 4.1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/40/&#34;&gt;Angular2とangular-cliでTODOを作る - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;angular-cli&lt;/code&gt;は&lt;code&gt;@angular/cli&lt;/code&gt;に&lt;a href=&#34;https://github.com/angular/angular-cli/commit/601f9b38f8ce53052d623a4b8a2dc5bb30f9eee1&#34;&gt;変更された&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;routingを行うのでnewで&lt;code&gt;--routing&lt;/code&gt;オプションを付けている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g @angular/cli
$ ng -v
@angular/cli: 1.0.1

$ ng new angular4-routing --routing
$ cd angular4-routing/
$ cat package.json | grep @angular/core
    &amp;quot;@angular/core&amp;quot;: &amp;quot;^4.0.0&amp;quot;,

$ ng serve
** NG Live Development Server is running on http://localhost:4200 **     
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--routing&lt;/code&gt;を付けたので&lt;code&gt;app-routing.module.ts&lt;/code&gt;が作成され、&lt;code&gt;app.module.ts&lt;/code&gt;にAppRoutingModuleが追加される。
&lt;code&gt;index.html&lt;/code&gt;のheadにはpushStateのroutingが働くように
&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base&#34;&gt;base&lt;/a&gt;要素が
&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#base-href&#34;&gt;追加されている&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { NgModule } from &#39;@angular/core&#39;;
import { Routes, RouterModule } from &#39;@angular/router&#39;;

const routes: Routes = [
  {
    path: &#39;&#39;,
    children: []
  }
];

@NgModule({
  imports: [RouterModule.forRoot(routes)],
  exports: [RouterModule]
})
export class AppRoutingModule { }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、&lt;code&gt;app.component.html&lt;/code&gt;に&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#router-outlet&#34;&gt;router-outlet&lt;/a&gt;が置かれていてroutingによるComponentはこの下に描画される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;h1&amp;gt;
  {{title}}
&amp;lt;/h1&amp;gt;
&amp;lt;router-outlet&amp;gt;&amp;lt;/router-outlet&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;動的に追加されるコンポーネントのstyleは&lt;code&gt;@HostBinding&lt;/code&gt;で設定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export class TodoMainComponent implements OnInit {

  @HostBinding(&#39;style.width&#39;)   width = &#39;100%&#39;;

  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ルーティング定義-https-angular-io-docs-ts-latest-guide-router-html-route-config&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#route-config&#34;&gt;ルーティング定義&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;children&lt;/code&gt;で&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#child-routing-component&#34;&gt;child route&lt;/a&gt;を設定しているが、
これは親コンポーネントの&lt;code&gt;router-outlet&lt;/code&gt;の下に描画される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g component todo/todo-main
$ ng g component todo/todo-list
$ ng g component todo/todo-item
$ ng g component not-found
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import { NgModule } from &#39;@angular/core&#39;;
import { Routes, RouterModule } from &#39;@angular/router&#39;;

import { TodoMainComponent } from &#39;./todo/todo-main/todo-main.component&#39;
import { TodoListComponent } from &#39;./todo/todo-list/todo-list.component&#39;
import { TodoItemComponent } from &#39;./todo/todo-item/todo-item.component&#39;
import { NotFoundComponent } from &#39;./not-found/not-found.component&#39;

const routes: Routes = [
  {
    path: &#39;todo&#39;,
    component: TodoMainComponent,
    children: [
          {
            path: &#39;:id&#39;,
            component: TodoItemComponent
          },
          {
            path: &#39;&#39;,
            component: TodoListComponent
          }
    ]
  },
  {
    path: &#39;**&#39;,
    component: NotFoundComponent,
  }
];

@NgModule({
  imports: [RouterModule.forRoot(routes)],
  exports: [RouterModule]
})
export class AppRoutingModule { }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;
  todo-main works!
&amp;lt;/p&amp;gt;
&amp;lt;router-outlet&amp;gt;&amp;lt;/router-outlet&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで &lt;a href=&#34;http://localhost:4200/todo&#34;&gt;http://localhost:4200/todo&lt;/a&gt; にアクセスすると、&lt;code&gt;TodoMainComponent&lt;/code&gt;と&lt;code&gt;TodoListComponent&lt;/code&gt;が表示される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app works!

todo-main works!

todo-list works!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;パラメータの取得-https-angular-io-docs-ts-latest-guide-router-html-route-parameters-activated-route&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#route-parameters-activated-route&#34;&gt;パラメータの取得&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;ActivatedRoute&lt;/code&gt;をDIしてObservableなparamsをSubscribeする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component, OnInit, HostBinding } from &#39;@angular/core&#39;;
import { Router, ActivatedRoute, Params } from &#39;@angular/router&#39;;

@Component({
  selector: &#39;app-todo-item&#39;,
  templateUrl: &#39;./todo-item.component.html&#39;,
  styleUrls: [&#39;./todo-item.component.css&#39;]
})
export class TodoItemComponent implements OnInit {

  id: number;

  constructor(
    private route: ActivatedRoute,
  ) { }

  ngOnInit() {  
    this.route.params.subscribe(
      (params: Params) =&amp;gt; this.id = +params[&#39;id&#39;]
    );
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;
  todo-item ({{id}}) works!
&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;遷移&#34;&gt;遷移&lt;/h2&gt;

&lt;p&gt;タグなら&lt;code&gt;&amp;lt;a routerLink&amp;gt;&lt;/code&gt;を、コードなら&lt;code&gt;Router.navigate&lt;/code&gt;を使って遷移できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;
  todo-item ({{id}}) works!
  &amp;lt;button (click)=&amp;quot;onClickNext()&amp;quot;&amp;gt;Next&amp;lt;/button&amp;gt;
  &amp;lt;a routerLink=&amp;quot;/todo&amp;quot;&amp;gt;todos&amp;lt;/a&amp;gt;
&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
export class TodoItemComponent implements OnInit {

  constructor(
    private route: ActivatedRoute,
    private router: Router
  ) { }

  ...

  onClickNext() {
    if(typeof this.id !== &#39;undefined&#39;){
      this.router.navigate([`/todo/${this.id+1}`, {hoge: &amp;quot;fuga&amp;quot;}]);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;navigateでhogeという適当なパラメータを付けているが、呼ぶと&lt;code&gt;http://localhost:4200/todo/10;hoge=fuga&lt;/code&gt;のように
クエリパラメータが&lt;code&gt;?, &amp;amp;&lt;/code&gt;ではなく&lt;code&gt;;&lt;/code&gt;で区切られたURLに遷移する。
これをmatrix URL notationといって、&lt;a href=&#34;https://www.w3.org/DesignIssues/MatrixURIs.html&#34;&gt;結構由緒正しい&lt;/a&gt;ものらしい。&lt;/p&gt;

&lt;h2 id=&#34;guard-https-angular-io-docs-ts-latest-guide-router-html-guards&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#guards&#34;&gt;Guard&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;routeの遷移時に何かするためのもの。
具体的にはログインしているかどうかをチェックしたりとか、
遷移する前にデータを一時保存したりとかそういうのに使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g guard auth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/api/router/index/CanActivate-interface.html&#34;&gt;canActivate()&lt;/a&gt;
はrouteに遷移するときに呼ばれ、trueを返すとそのまま続行され、falseを返すと中断される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Injectable } from &#39;@angular/core&#39;;
import { CanActivate, ActivatedRouteSnapshot, RouterStateSnapshot } from &#39;@angular/router&#39;;
import { Observable } from &#39;rxjs/Observable&#39;;

@Injectable()
export class AuthGuard implements CanActivate {
  canActivate(
    next: ActivatedRouteSnapshot,
    state: RouterStateSnapshot): Observable&amp;lt;boolean&amp;gt; | Promise&amp;lt;boolean&amp;gt; | boolean {
    console.log(`canActivate(): ${state.url}`);
    return true;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;AppModuleのprovidersにAuthGuardを入れて、routesにも&lt;code&gt;canActivate&lt;/code&gt;としてAuthGuardを設定すると呼ばれるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { AuthGuard } from &#39;./auth.guard&#39;

const routes: Routes = [
  {
    path: &#39;todo&#39;,
    component: TodoMainComponent,
    canActivate: [AuthGuard],
    children: [
          {
            path: &#39;:id&#39;,
            component: TodoItemComponent
          },
          {
            path: &#39;&#39;,
            component: TodoListComponent
          }
    ]
  },
  {
    path: &#39;**&#39;,
    component: NotFoundComponent,
  }
];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この設定だと上で追加したNextボタンを押してchild routeに遷移したときには呼ばれない。
&lt;code&gt;canActivateChild()&lt;/code&gt;にするとchild routeに遷移したときにも呼ばれるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;canActivateChild(route: ActivatedRouteSnapshot, state: RouterStateSnapshot): Observable&amp;lt;boolean&amp;gt; | Promise&amp;lt;boolean&amp;gt; | boolean {
  return this.canActivate(route, state);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
    path: &#39;todo&#39;,
    component: TodoMainComponent,
    canActivateChild: [AuthGuard],
    children: [
          {
            path: &#39;:id&#39;,
            component: TodoItemComponent
          },
          {
            path: &#39;&#39;,
            component: TodoListComponent
          }
    ]
} 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらの他には&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/api/router/index/CanDeactivate-interface.html&#34;&gt;canDeactivate()&lt;/a&gt;: 今のrouteから離れるとき&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/api/router/index/Resolve-interface.html&#34;&gt;resolve()&lt;/a&gt;: コンポーネントを表示する前。pre-fetchのため。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/api/router/index/CanLoad-interface.html&#34;&gt;canLoad()&lt;/a&gt;: &lt;code&gt;loadChildren&lt;/code&gt;で指定したModuleを&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#lazy-loading-route-config&#34;&gt;lazy load&lt;/a&gt;
するとき。ドキュメントではAdminModuleに対して、認証されていなかったらロードしないようにしている。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のGuardがある。&lt;/p&gt;

&lt;h2 id=&#34;アニメーション-https-angular-io-docs-ts-latest-guide-router-html-route-animation&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#route-animation&#34;&gt;アニメーション&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;app.module.ts&lt;/code&gt;に&lt;code&gt;BrowserAnimationsModule&lt;/code&gt;を追加。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save @angular/animations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import { BrowserAnimationsModule } from &#39;@angular/platform-browser/animations&#39;;

@NgModule({
  ...
  imports: [
    ...
    BrowserAnimationsModule
  ],
  ...
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;animations.ts&lt;/code&gt;を作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { animate, AnimationEntryMetadata, state, style, transition, trigger } from &#39;@angular/core&#39;;

// Component transition animations
export const slideInDownAnimation: AnimationEntryMetadata =
  trigger(&#39;routeAnimation&#39;, [
    state(&#39;*&#39;,
      style({
        opacity: 1,
        transform: &#39;translateX(0)&#39;
      })
    ),
    transition(&#39;:enter&#39;, [
      style({
        opacity: 0,
        transform: &#39;translateX(-100%)&#39;
      }),
      animate(&#39;0.2s ease-in&#39;)
    ]),
    transition(&#39;:leave&#39;, [
      animate(&#39;0.5s ease-out&#39;, style({
        opacity: 0,
        transform: &#39;translateY(100%)&#39;
      }))
    ])
  ]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを@Componentのanimationsに入れて&lt;code&gt;@HostBinding&lt;/code&gt;でanimationのトリガー(routeAnimation)を発火させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component, OnInit, HostBinding } from &#39;@angular/core&#39;;
import { Router, ActivatedRoute, Params } from &#39;@angular/router&#39;;
import { slideInDownAnimation } from &#39;../../animations&#39;;

@Component({
  selector: &#39;app-todo-item&#39;,
  templateUrl: &#39;./todo-item.component.html&#39;,
  styleUrls: [&#39;./todo-item.component.css&#39;],
  animations: [ slideInDownAnimation ]
})
export class TodoItemComponent implements OnInit {

  @HostBinding(&#39;@routeAnimation&#39;) routeAnimation = true;
  @HostBinding(&#39;style.display&#39;)   display = &#39;block&#39;;
  @HostBinding(&#39;style.position&#39;)  position = &#39;absolute&#39;;

  id: number;

  constructor(
    private route: ActivatedRoute,
    private router: Router
  ) { }

  ngOnInit() {  
    this.route.params.subscribe(
      (params: Params) =&amp;gt; this.id = +params[&#39;id&#39;]
    );
  }

  onClickNext() {
    this.router.navigate([&#39;/todo&#39;, {id: this.id + 1, hoge: &amp;quot;fuga&amp;quot;}])
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じにアニメーションする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/97.gif&#34; alt=&#34;アニメーション&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsのStream API</title>
          <link>https://www.sambaiz.net/article/96/</link>
          <pubDate>Sat, 22 Apr 2017 19:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/96/</guid>
          <description>

&lt;h2 id=&#34;stream-apiとは-https-nodejs-org-docs-v7-9-0-api-stream-html&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html&#34;&gt;Stream APIとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;NodeでStreamデータを扱うためのもの。
例えばサイズが大きいファイルの入出力をStreamとして扱うことでバッファを最小限にできる。&lt;/p&gt;

&lt;p&gt;Streamは&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/events.html&#34;&gt;EventEmitter&lt;/a&gt;で、
Readable streamやWritable stream、ReadableとWritableを合わせたDuplex streamと
Readしたものを加工してWriteするTransform streamの種類があり、
それぞれ特定の関数が&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_api_for_stream_implementers&#34;&gt;実装&lt;/a&gt;されている必要がある。&lt;/p&gt;

&lt;h2 id=&#34;readable-stream-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-readable-streams&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_readable_streams&#34;&gt;Readable stream&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Readable streamには&lt;code&gt;flowing&lt;/code&gt;と&lt;code&gt;paused&lt;/code&gt;の
&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_two_modes&#34;&gt;二つのモード&lt;/a&gt;がある。
最初は&lt;code&gt;paused&lt;/code&gt;モードで、readableになってからread()することで読むことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;sample.txt&#39;);
var i = 0;
readable.on(&#39;readable&#39;, () =&amp;gt; {
  let chunk;
  while (null !== (chunk = readable.read(10))) {
    console.log(`${i++}: ${chunk}`);
  }
});
dable.on(&#39;end&#39;, () =&amp;gt; {
  console.log(&#39;end&#39;);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat sample.txt
abcdefghijklmnopqrstuvwxyz
1234567890
あいうえお

$ node main.js
0: abcdefghij
1: klmnopqrst
2: uvwxyz
123
3: 4567890
あい
4: うえお

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;dataのイベントハンドラーを追加するか、後で書くpipeを使うと&lt;code&gt;flowing&lt;/code&gt;モードになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;sample.txt&#39;);
var i = 0;
readable.on(&#39;data&#39;, (chunk) =&amp;gt; {
  console.log(`${i++}: ${chunk}`);
});
readable.on(&#39;end&#39;, () =&amp;gt; {
  console.log(&#39;end&#39;);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0: abcdefghijklmnopqrstuvwxyz
1234567890
あいうえお

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーハンドリングはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;error.txt&#39;);
readable.on(&#39;data&#39;, (chunk) =&amp;gt; {
  console.log(`${i++}: ${chunk}`);
});
readable.on(&#39;error&#39;, (error) =&amp;gt; {
  console.log(error);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ node main.js
{ Error: ENOENT: no such file or directory, open &#39;error.txt&#39;
    at Error (native) errno: -2, code: &#39;ENOENT&#39;, syscall: &#39;open&#39;, path: &#39;error.txt&#39; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;実装-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-implementing-a-readable-stream&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_implementing_a_readable_stream&#34;&gt;実装&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;実装する関数は&lt;code&gt;_read&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const Readable = require(&#39;stream&#39;).Readable;

class Random extends Readable {
  constructor(opt) {
    super(opt); 
  }
  
  _read() {
    
    // error handling
    // if(err){ 
    //   this.emit(&#39;error&#39;, err)
    //   return
    // }
    
    this.push(Math.random()+&#39;&#39;);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;writable-stream-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-class-stream-writable&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_class_stream_writable&#34;&gt;Writable stream&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;output.txtに出力するWritable stream。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let writable = fs.createWriteStream(&#39;output.txt&#39;)

writable.write(&#39;hoge\n&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat output.txt
hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入力の流量が多く、Writable streamのバッファが&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_constructor_new_stream_writable_options&#34;&gt;highWaterMark&lt;/a&gt;を超えてしまうと、write()はfalseを返す。そのまま書き込み続けるとメモリを食いつぶしてしまうので、
全てのバッファが捌けて&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_event_drain&#34;&gt;drain&lt;/a&gt;イベントが発行されるまで書き込みを止めてback-pressureとする必要がある。
ただし、pipeを使う場合このあたりはやってくれるので、あまり気にすることはない。&lt;/p&gt;

&lt;h3 id=&#34;実装-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-implementing-a-writable-stream&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_implementing_a_writable_stream&#34;&gt;実装&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;実装する関数は&lt;code&gt;_write&lt;/code&gt;と、バッファされているchunkをまとめて扱うなら&lt;code&gt;_writev&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const Writable = require(&#39;stream&#39;).Writable;

class DummyWritable extends Writable {
  constructor(opt) {
    super(opt);
  }

  _write(chunk, encoding, callback) {
    const chunkStr = chunk.toString()
    if (chunkStr == &#39;this is error&#39;) {
      callback(new Error(&#39;chunk is invalid&#39;));
    } else {
      console.log(chunkStr);
      callback();
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pipe-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-readable-pipe-destination-options&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_readable_pipe_destination_options&#34;&gt;pipe&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Readable streamをWritable streamとつなげる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;sample.txt&#39;);
let writable = fs.createWriteStream(&#39;output.txt&#39;);
readable.pipe(writable);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat output.txt
abcdefghijklmnopqrstuvwxyz
1234567890
あいうえお
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意すべきなのは、pipeしたものをまとめてエラーハンドリングすることはできないこと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;error.txt&#39;);
let writable = fs.createWriteStream(&#39;output.txt&#39;);
let piped = readable.pipe(writable);

piped.on(&#39;error&#39;, (error) =&amp;gt; {
  console.log(error);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;events.js:160
      throw er; // Unhandled &#39;error&#39; event
      ^

Error: ENOENT: no such file or directory, open &#39;error.txt&#39;
    at Error (native)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;面倒だけど、毎度エラーハンドリングする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;error.txt&#39;);
let writable = fs.createWriteStream(&#39;output.txt&#39;);
const errorHandling = (err) =&amp;gt; { console.log(err) }
let piped = readable.on(&#39;error&#39;, errorHandling).pipe(writable);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pipeを組み合わせると、こんな風にcsvをfetchして加工し、文字コードを変えて出力するといったこともStreamでできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fetch = require(&#39;node-fetch&#39;);
const Iconv = require(&#39;iconv&#39;).Iconv;
const iconv = new Iconv(&#39;UTF-8&#39;, &#39;SHIFT_JIS//IGNORE&#39;);
const csv = require(&#39;csv&#39;);
const fs = require(&#39;fs&#39;);

const errorHandling = (err) =&amp;gt; { console.log(err); };

const outputFile = fs.createWriteStream(&#39;output.csv&#39;);

fetch(&#39;http://example.com/test.csv&#39;).then((res) =&amp;gt; {

  res.body
  .pipe(csv.parse({columns : true}))
  .on(&#39;error&#39;, errorHandling)
  .pipe(csv.transform(function(record){
    if(record[&#39;hoge&#39;] &amp;lt; 100000){
      return null;
    }
    return record;
  }))
  .on(&#39;error&#39;, errorHandling)
  .pipe(csv.stringify({header: true}))
  .on(&#39;error&#39;, errorHandling)
  .pipe(iconv)
  .on(&#39;error&#39;, errorHandling)
  .pipe(outputFile)
  .on(&#39;error&#39;, errorHandling);

}).then(() =&amp;gt; console.log(&amp;quot;done&amp;quot;)).catch((err) =&amp;gt; console.log(err));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pipeではないけど、readlineのcreateInterfaceに入力と出力のStreamを渡すと、
行ごとに処理することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
const readline = require(&#39;readline&#39;);

let readable = fs.createReadStream(&#39;sample.txt&#39;);
const rl = readline.createInterface({
  input: readable,
  output: process.stdout
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;abcdefghijklmnopqrstuvwxyz
1234567890
あいうえお
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rxjsで扱う&#34;&gt;RxJSで扱う&lt;/h2&gt;

&lt;p&gt;StreamはEventEmitterなのでRxJSのfromEvent()でObservableとして扱うこともできる。ただし&lt;a href=&#34;https://github.com/ReactiveX/rxjs&#34;&gt;v5&lt;/a&gt;にはpipeがない(v4には&lt;a href=&#34;https://github.com/Reactive-Extensions/RxJS/blob/8fa95ac884181fb6cbff8ce7c1d669ffb190f5e4/src/core/linq/observable/pipe.js#L6&#34;&gt;ある&lt;/a&gt;)ので、pipeする場合は自分でSubscribeしてwriteする必要がありそう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/85/&#34;&gt;RxJSでRxをはじめる - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
const Rx = require(&#39;rxjs/Rx&#39;);
const writable = fs.createWriteStream(&#39;output.txt&#39;)

Rx.Observable.fromEvent(process.stdin, &#39;data&#39;)
.map((v) =&amp;gt; `- ${v}`)
.subscribe((v) =&amp;gt; write(v));

function write(v){
  // TODO: back-pressure
  writable.write(v);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ node main.js 
aiueo
kakikukeko
^C

$ cat output.txt 
- aiueo
- kakikukeko
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>tmuxのメモ</title>
          <link>https://www.sambaiz.net/article/95/</link>
          <pubDate>Fri, 21 Apr 2017 00:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/95/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://tmux.github.io/&#34;&gt;https://tmux.github.io/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;セッションを立ち上げてその中で複数のウィンドウやペインからコマンドを実行できるやつ。
サーバーでの作業中にネットワークが切断されてしまってもセッションをattachすることで再開することができる。
ローカル環境でもコマンドキーでのウィンドウ作成やペインの分割、
複数のサーバーにsshで入って調査するようなときにペインの同時入力は便利。
もちろんターミナルを閉じてしまっても再開できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install tmux
$ tmux
$ tmux ls
$ tmux a # sessionをattachする
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bind key(デフォルトで&lt;code&gt;Ctrl + b&lt;/code&gt;)を入れてからコマンドキーを入れる。よく使うもの。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;c: 新しいウインドウをCreateする&lt;/li&gt;
&lt;li&gt;d: 今のクライアントをDetachする&lt;/li&gt;
&lt;li&gt;n: Nextウィンドウに移動する&lt;/li&gt;
&lt;li&gt;p: Previousウィンドウに戻る&lt;/li&gt;
&lt;li&gt;w: Windowを一覧表示して選択する&lt;/li&gt;
&lt;li&gt;x: ペインを削除する&lt;/li&gt;
&lt;li&gt;,: ウィンドウの名前を変更する&lt;/li&gt;
&lt;li&gt;z: ウィンドウ一杯にペインをzoomする/解除&lt;/li&gt;
&lt;li&gt;[: ペイン内をスクロールできるようになる。qで解除&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;~/.tmux.conf&lt;/code&gt;はこんな感じにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# bind keyをC-tに変更してC-bを解除
set -g prefix C-t
unbind C-b

# Vimのキーバインドでペインを移動する
bind h select-pane -L
bind j select-pane -D
bind k select-pane -U
bind l select-pane -R

# - でペインを横に分割する(縦に切る)
bind - split-window -h

# | でペインを縦に分割する(横に切る)
bind | split-window -v

# 同時入力
bind s set-window-option synchronize-panes on
bind S set-window-option synchronize-panes off
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Firebaseをwebで使う(Hosting, Authentication, Realtime Database, Storage)</title>
          <link>https://www.sambaiz.net/article/94/</link>
          <pubDate>Sun, 16 Apr 2017 20:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/94/</guid>
          <description>

&lt;h2 id=&#34;firebase-https-firebase-google-com-hl-ja-とは&#34;&gt;&lt;a href=&#34;https://firebase.google.com/?hl=ja&#34;&gt;Firebase&lt;/a&gt;とは&lt;/h2&gt;

&lt;p&gt;GoogleのmBaaS。Android/iOSアプリの開発に使う認証、データストア、クラッシュレポート、分析、通知、広告などなど全部入りサービス。
今年のGoogleI/Oでも&lt;a href=&#34;https://events.google.com/io/schedule/?section=may-19&#34;&gt;毎時間のように&lt;/a&gt;
Firebaseのセッションがあって大分推している印象。&lt;/p&gt;

&lt;p&gt;基本的にはアプリで使うのだけれど、webで使える機能も結構ある。今回は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Hosting&lt;/li&gt;
&lt;li&gt;Authentication&lt;/li&gt;
&lt;li&gt;Realtime Database&lt;/li&gt;
&lt;li&gt;Storage&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を使ってみる。&lt;/p&gt;

&lt;h2 id=&#34;料金-https-firebase-google-com-pricing&#34;&gt;&lt;a href=&#34;https://firebase.google.com/pricing/&#34;&gt;料金&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;プランは無料のSPARKと25ドル/月のFLAME、従量課金のBLAZEがある。
試す分にはSPARKで十分だけど、Realtime Databaseの同時接続数が100なので注意。&lt;/p&gt;

&lt;h2 id=&#34;セットアップ-https-firebase-google-com-docs-web-setup&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/web/setup&#34;&gt;セットアップ&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://firebase.google.com/docs/cli/&#34;&gt;firebase-cli&lt;/a&gt;をインストール、ログインして初期化する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g firebase-tools
$ firebase login
$ mkdir firebase-chat &amp;amp;&amp;amp; cd firebase-chat
$ firebase init
...
? What Firebase CLI features do you want to setup for this folder? 
❯◉ Database: Deploy Firebase Realtime Database Rules
 ◉ Functions: Configure and deploy Cloud Functions
 ◉ Hosting: Configure and deploy Firebase Hosting sites

? What Firebase project do you want to associate as default? *****

? What file should be used for Database Rules? database.rules.json

? Do you want to install dependencies with npm now? Yes

? What do you want to use as your public directory? public

? Configure as a single-page app (rewrite all urls to /index.html)? Yes

✔  Firebase initialization complete!

$ ls
database.rules.json	firebase.json		functions		public
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;firebase.jsonはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat firebase.json
{
  &amp;quot;database&amp;quot;: {
    &amp;quot;rules&amp;quot;: &amp;quot;database.rules.json&amp;quot;
  },
  &amp;quot;hosting&amp;quot;: {
    &amp;quot;public&amp;quot;: &amp;quot;public&amp;quot;,
    &amp;quot;rewrites&amp;quot;: [
      {
        &amp;quot;source&amp;quot;: &amp;quot;**&amp;quot;,
        &amp;quot;destination&amp;quot;: &amp;quot;/index.html&amp;quot;
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ローカルでサーバーを立ち上げて確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ firebase serve
Server listening at: http://localhost:5000

$ curl http://localhost:5000 # Firebase SDK loaded with auth, database, messaging, storage
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;hosting-https-firebase-google-com-docs-hosting-hl-ja&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/hosting/?hl=ja&#34;&gt;Hosting&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;静的サイトのホスティング。もちろん独自ドメインも使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ firebase deploy --only hosting
...
✔  Deploy complete!

Project Console: https://console.firebase.google.com/project/*****/overview
Hosting URL: https://*****.firebaseapp.com
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;authentication-https-firebase-google-com-docs-auth&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/auth/&#34;&gt;Authentication&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ユーザー認証。Googleだけではなく、TwitterやFacebook、Githubといったプロバイダや、メールとパスワードでの認証が用意されていて、
コンソールから有効にする必要がある。&lt;/p&gt;

&lt;p&gt;実装はFirebase SDKで自分でやるか、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const provider = new firebase.auth.GoogleAuthProvider();
firebase.auth().signInWithPopup(provider).then((result) =&amp;gt; {
    console.log(`sign in successfully. ${result.user.displayName}`)
}).catch((error) =&amp;gt; {
    console.log(`fail to sign in. ${error.message}`)
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/firebase/FirebaseUI-Web&#34;&gt;FirebaseUI Auth&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script defer src=&amp;quot;https://cdn.firebase.com/libs/firebaseui/1.0.1/firebaseui.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;link type=&amp;quot;text/css&amp;quot; rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://cdn.firebase.com/libs/firebaseui/1.0.1/firebaseui.css&amp;quot; /&amp;gt;

&amp;lt;div id=&amp;quot;firebaseui-auth-container&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;// FirebaseUI config.
var uiConfig = {
  signInOptions: [
    // Leave the lines as is for the providers you want to offer your users.
    firebase.auth.GoogleAuthProvider.PROVIDER_ID
  ],
  callbacks: {
    signInSuccess: function(currentUser, credential, redirectUrl) {
      // リダイレクトさせない
      return false;
    }
  },
  // Terms of service url.
  tosUrl: &#39;&amp;lt;your-tos-url&amp;gt;&#39;
};

// Initialize the FirebaseUI Widget using Firebase.
var ui = new firebaseui.auth.AuthUI(firebase.auth());
// The start method will wait until the DOM is loaded.
ui.start(&#39;#firebaseui-auth-container&#39;, uiConfig);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じにボタンが並ぶ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/93-firebase-authentication.png&#34; alt=&#34;Firebase authentication&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;onAuthStateChanged()&lt;/code&gt;でsign in/outをハンドリングでき、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;firebase.auth().onAuthStateChanged((user) =&amp;gt; {
    if (user) {
      console.log(`${user.displayName} sign in`);
    } else {
      console.log(&#39;sign out&#39;);
    }
  }, (error) =&amp;gt; {
    console.log(error);
  }
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;currentUserでsign inしてるユーザーを取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if(firebase.auth().currentUser){
  console.log(firebase.auth().currentUser.displayName);
}else{
  // need to sign in
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;realtime-database-https-firebase-google-com-docs-database&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/database/&#34;&gt;Realtime Database&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;NoSQLなデータベース。直接読み書きするのではなく、
ローカルにデータを保存してリアルタイムに同期するため一時的にオフライン状態になっても読み書きできる。&lt;/p&gt;

&lt;h3 id=&#34;読み書き-https-firebase-google-com-docs-database-web-read-and-write&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/database/web/read-and-write&#34;&gt;読み書き&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;データベースへの書き込みと更新。refで&lt;code&gt;users/1&lt;/code&gt;のように参照を取って操作する。
&lt;a href=&#34;https://firebase.google.com/docs/reference/js/firebase.database.Reference?hl=ja#push&#34;&gt;push()&lt;/a&gt;で
&lt;code&gt;hoge/-Khp36CCygw5AI6G8L1B&lt;/code&gt;のようなユニークなキーを発行することができ、これは時系列にソートされるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const database = firebase.database();

for(let i = 0; i &amp;lt; 10; i++){
    
    const newHogeRef = database.ref(&#39;hoge&#39;).push();
    console.log(`newHogeRef: ${newHogeRef.toString()}`);
    
    newHogeRef.set({
        idx: i,
        aaa: &amp;quot;bbb123&amp;quot;,
    });

    newHogeRef.update({
        aaa: &amp;quot;bbb456&amp;quot;,
        eee: &amp;quot;fff&amp;quot;
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;newHogeRef: https://test-3a363.firebaseio.com/hoge/-Khp36CCygw5AI6G8L1B
newHogeRef: https://test-3a363.firebaseio.com/hoge/-Khp36CLyJ9BQVefW-l5
newHogeRef: https://test-3a363.firebaseio.com/hoge/-Khp36CMs9-jJoKUUgr0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://firebase.google.com/docs/reference/js/firebase.database.Reference?hl=ja#on&#34;&gt;on()&lt;/a&gt;で
value eventを拾うと、
呼んだときとデータに変更があったときに&lt;a href=&#34;https://firebase.google.com/docs/reference/js/firebase.database.DataSnapshot?hl=ja&#34;&gt;snapshot&lt;/a&gt;が取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;database.ref(&amp;quot;hoge&amp;quot;).orderByKey().limitToLast(3).on(&amp;quot;value&amp;quot;, (snapshot) =&amp;gt; {
    snapshot.forEach((data) =&amp;gt; console.log(data.val()));
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
Object {aaa: &amp;quot;bbb456&amp;quot;, eee: &amp;quot;fff&amp;quot;, idx: 7}
Object {aaa: &amp;quot;bbb456&amp;quot;, eee: &amp;quot;fff&amp;quot;, idx: 8}
Object {aaa: &amp;quot;bbb456&amp;quot;, eee: &amp;quot;fff&amp;quot;, idx: 9}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;アクセス権限-バリデーション-https-firebase-google-com-docs-database-security-securing-data&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/database/security/securing-data&#34;&gt;アクセス権限・バリデーション&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;firebase.jsonで指定しているdatabase ruleファイル(database.rules.json)でルールを設定する。
デフォルトで認証していれば読み書きできる設定になっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;rules&amp;quot;: {
    &amp;quot;.read&amp;quot;: &amp;quot;auth != null&amp;quot;,
    &amp;quot;.write&amp;quot;: &amp;quot;auth != null&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;read/writeだけではなくバリデーションの設定もこんな感じでできる。
これは&lt;code&gt;users/${ユーザーのuid}&lt;/code&gt;への読み書きを本人のみができるようにするもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;rules&amp;quot;: {
    &amp;quot;users&amp;quot;: {
      &amp;quot;$uid&amp;quot;: {
        &amp;quot;.read&amp;quot;: &amp;quot;$uid === auth.uid&amp;quot;,
        &amp;quot;.write&amp;quot;: &amp;quot;$uid === auth.uid&amp;quot;,
        &amp;quot;.validate&amp;quot;: &amp;quot;newData.hasChildren([&#39;age&#39;, &#39;name&#39;]) &amp;amp;&amp;amp; newData.child(&#39;age&#39;).isNumber() &amp;amp;&amp;amp; newData.child(&#39;age&#39;).val() &amp;gt;= 0 &amp;amp;&amp;amp; newData.child(&#39;age&#39;).val() &amp;lt; 200 &amp;amp;&amp;amp; newData.child(&#39;name&#39;).isString() &amp;amp;&amp;amp; newData.child(&#39;name&#39;).val().length &amp;lt; 50&amp;quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ firebase deploy --only database
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上の設定を適用したデータベースに読み書きしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const uid = firebase.auth().currentUser.uid;

database.ref(`users/${uid}`).set({
    age: 20,
    name: &amp;quot;taro&amp;quot;
});

// ok: Object {age: 20, name: &amp;quot;taro&amp;quot;}
database.ref(`users/${uid}`).on(&amp;quot;value&amp;quot;, (snapshot) =&amp;gt; {
    console.log(snapshot.val()); // Object {age: 20, name: &amp;quot;taro&amp;quot;}
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のような不正なデータや不正なキーに書き込もうとすると
&lt;code&gt;PERMISSION_DENIED: Permission denied&lt;/code&gt;になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// ageがおかしい
database.ref(`users/${uid}`).set({
    age: &amp;quot;aaaa&amp;quot;,
    name: &amp;quot;jiro&amp;quot;
});

// 本人じゃない
database.ref(`users/hogehoge`).set({
    age: 20,
    name: &amp;quot;jiro&amp;quot;
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、さっきまでアクセスできていたhogeにもアクセスできなくなっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// PERMISSION_DENIED: Permission denied
database.ref(&amp;quot;hoge&amp;quot;).orderByKey().limitToLast(3).on(&amp;quot;value&amp;quot;, (snapshot) =&amp;gt; {
    snapshot.forEach((data) =&amp;gt; console.log(data.val()));
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを解決するためにrulesのルートに&lt;code&gt;auth != null&lt;/code&gt;の設定を入れてしまうと、
&lt;a href=&#34;https://firebase.google.com/docs/database/security/securing-data#read_and_write_rules_cascade&#34;&gt;浅い階層のルールが深い階層のルールより優先される&lt;/a&gt;
ためusersのread/writeの設定が無効になってしまうので注意。ただしvalidateはそれぞれの階層でチェックされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;rules&amp;quot;: {
    &amp;quot;.read&amp;quot;: &amp;quot;auth != null&amp;quot;,
    &amp;quot;.write&amp;quot;: &amp;quot;auth != null&amp;quot;,
    &amp;quot;users&amp;quot;: {
      &amp;quot;$uid&amp;quot;: {
        &amp;quot;.read&amp;quot;: &amp;quot;$uid === auth.uid&amp;quot;,
        &amp;quot;.write&amp;quot;: &amp;quot;$uid === auth.uid&amp;quot;,
        &amp;quot;.validate&amp;quot;: &amp;quot;newData.hasChildren([&#39;age&#39;, &#39;name&#39;]) &amp;amp;&amp;amp; newData.child(&#39;age&#39;).isNumber() &amp;amp;&amp;amp; newData.child(&#39;age&#39;).val() &amp;gt;= 0 &amp;amp;&amp;amp; newData.child(&#39;age&#39;).val() &amp;lt; 200 &amp;amp;&amp;amp; newData.child(&#39;name&#39;).isString() &amp;amp;&amp;amp; newData.child(&#39;name&#39;).val().length &amp;lt; 50&amp;quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;storage-https-firebase-google-com-docs-storage&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/storage/&#34;&gt;Storage&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;画像などを保存しておくために使う。
Realtime Databaseと同様、
ネットワーク品質が良くない環境でも使えるように、処理が中断されても途中から処理を再開するようになっている。
裏側ではGoogle Cloud Storageが使われている。&lt;/p&gt;

&lt;h3 id=&#34;アップロード-https-firebase-google-com-docs-storage-web-upload-files&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/storage/web/upload-files&#34;&gt;アップロード&lt;/a&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;input type=&amp;quot;file&amp;quot; id=&amp;quot;file-upload&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const storage = firebase.storage();

const inputFile = document.getElementById(&#39;file-upload&#39;);

inputFile.addEventListener(&#39;change&#39;, (e) =&amp;gt; {
  const files = e.target.files;
  const user = firebase.auth().currentUser;
  if(user){
    const ref = storage.ref(`images/${user.uid}`);
    const uploadTask = ref.put(files[0]);
  }
}, false);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;中断、再開、キャンセル。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;uploadTask.pause();
uploadTask.resume();
uploadTask.cancel();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アップロードの状態はstage_changed eventで確認し、完了するとダウンロードURLを取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;uploadTask.on(&#39;state_changed&#39;, (snapshot) =&amp;gt; {

  const progress = (snapshot.bytesTransferred / snapshot.totalBytes) * 100;
  console.log(&#39;Upload is &#39; + progress + &#39;% done&#39;);

  switch (snapshot.state) {
    case firebase.storage.TaskState.PAUSED: // or &#39;paused&#39;
      console.log(&#39;Upload is paused&#39;);
      break;
    case firebase.storage.TaskState.RUNNING: // or &#39;running&#39;
      console.log(&#39;Upload is running&#39;);
      break;
  }
}, (error) =&amp;gt; {
  // Handle unsuccessful uploads
  console.log(error);
}, () =&amp;gt; {
  // Handle successful uploads on complete
  // For instance, get the download URL: https://firebasestorage.googleapis.com/...
  console.log(uploadTask.snapshot.downloadURL);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;アクセス制限-バリデーション-https-firebase-google-com-docs-storage-security-hl-ja&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/storage/security/?hl=ja&#34;&gt;アクセス制限・バリデーション&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Realtime Databaseと同様にアクセス制限やバリデーションをかけることができる。
設定はコンソールから。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/93-firebase-storage-rule.png&#34; alt=&#34;Storageのルール&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service firebase.storage {
  match /b/*****.appspot.com/o {
    match /images/{imageId} {
      // Only allow uploads of any image file that&#39;s less than 5MB
      allow write: if request.resource.size &amp;lt; 5 * 1024 * 1024
                   &amp;amp;&amp;amp; request.resource.contentType.matches(&#39;image/.*&#39;)
                   &amp;amp;&amp;amp; request.auth != null;
      allow read: if request.auth != null;             
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ダウンロード-https-firebase-google-com-docs-storage-web-download-files&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/storage/web/download-files&#34;&gt;ダウンロード&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;getDownloadURL()&lt;/code&gt;でURLを取得する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;img id=&amp;quot;myimg&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const ref = storage.ref(`images/${user.uid}`).getDownloadURL().then((url) =&amp;gt; {
  
  const img = document.getElementById(&#39;myimg&#39;);
  img.src = url;

}).catch((error) =&amp;gt; {

  switch (error.code) {
    case &#39;storage/object-not-found&#39;:
      console.log(&amp;quot;not found&amp;quot;);
      break;

    default:
      console.log(error);
  }
});;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLのALTER TABLEのメモ</title>
          <link>https://www.sambaiz.net/article/93/</link>
          <pubDate>Sat, 15 Apr 2017 19:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/93/</guid>
          <description>&lt;p&gt;しばらく書かないとどういう構文だったか忘れてしまう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/alter-table.html&#34;&gt;MySQL :: MySQL 5.6 リファレンスマニュアル :: 13.1.7 ALTER TABLE 構文&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE t0 (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    c1 VARCHAR(30),
    c2 VARCHAR(30)
);
CREATE TABLE t2 (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ALTER TABLE t0 RENAME t1;
ALTER TABLE t1
  ADD COLUMN t2_id BIGINT UNSIGNED AFTER id,
  ADD COLUMN c3 INTEGER NOT NULL AFTER t2_id,
  MODIFY COLUMN c1 VARCHAR(30) NOT NULL,
  DROP COLUMN c2,
  ADD INDEX (c3),
  ADD FOREIGN KEY (t2_id) REFERENCES t2(id) ON UPDATE RESTRICT ON DELETE RESTRICT
;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SHOW CREATE TABLE t1 \G;
*************************** 1. row ***************************
       Table: t1
Create Table: CREATE TABLE `t1` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `t2_id` bigint(20) unsigned DEFAULT NULL,
  `c3` int(11) NOT NULL,
  `c1` varchar(30) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `c3` (`c3`),
  KEY `t2_id` (`t2_id`),
  CONSTRAINT `t1_ibfk_1` FOREIGN KEY (`t2_id`) REFERENCES `t2` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE=InnoDB DEFAULT CHARSET=utf8
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ALTER TABLE t1
  DROP INDEX c3,
  DROP FOREIGN KEY t1_ibfk_1,
  DROP INDEX t2_id
;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SHOW CREATE TABLE t1 \G
*************************** 1. row ***************************
       Table: t1
Create Table: CREATE TABLE `t1` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `t2_id` bigint(20) unsigned DEFAULT NULL,
  `c3` int(11) NOT NULL,
  `c1` varchar(30) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityのパーティクル設定(Shuriken)</title>
          <link>https://www.sambaiz.net/article/92/</link>
          <pubDate>Thu, 13 Apr 2017 17:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/92/</guid>
          <description>

&lt;p&gt;Unityには&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/class-ParticleSystem.html&#34;&gt;Shuriken&lt;/a&gt;というパーティクルシステムがある。&lt;/p&gt;

&lt;p&gt;Sphereを置いてParticle Systemを追加すると、Particleが出始める。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-1.png&#34; alt=&#34;Particleの初期状態&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;モジュール&#34;&gt;モジュール&lt;/h2&gt;

&lt;p&gt;設定項目が多いためモジュールに分かれている。ひとまずデフォルトで有効になっている&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(メインモジュール)&lt;/li&gt;
&lt;li&gt;Emission&lt;/li&gt;
&lt;li&gt;Shape&lt;/li&gt;
&lt;li&gt;Renderer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;について見ていく。&lt;/p&gt;

&lt;h3 id=&#34;メインモジュール-https-docs-unity3d-com-550-documentation-manual-partsysmainmodule-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/PartSysMainModule.html&#34;&gt;メインモジュール&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Duration: 5&lt;/li&gt;
&lt;li&gt;Looping: true&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;デフォルトだとLoopingにチェックが入っているのでずっと出ているが、チェックを外すとDurationで止まる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Delay: 0&lt;/li&gt;
&lt;li&gt;Play On Awake: true&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PlayOnAwakeがtrueでStartDelayが0なので実行してからすぐにParticleが出始める。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Lifetime: 5&lt;/li&gt;
&lt;li&gt;Max Particles: 1000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;StartLifetimeはParticleが消えるまでの時間。ただしMaxParticlesに達したら消される。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Speed: 5&lt;/li&gt;
&lt;li&gt;Simulation Speed: 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;StartSpeedはParticleの初速で、上げると勢い良く飛んでいく。
SimulationSpeedを上げるとParticleが出るのも含めて全体のスピードが上がる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Size: 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleの初期サイズ。小さくすると塵みたいになる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Rotation: 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleの初期角度。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Gravity Modifier: 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;重力値。0だと無重力。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Simulation Space: Local&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleをlocal座標かworld座標で動かすか。
Localだとオブジェクトが移動したときに一緒に移動する。Worldだと置いてかれる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Scaling Mode: Local&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ParticleのScale。LocalだとそのオブジェクトのScaleだけを見る。Hierarchyだと親も考慮したScale。Shapeだと開始位置だけ。&lt;/p&gt;

&lt;h3 id=&#34;emissionモジュール-https-docs-unity3d-com-550-documentation-manual-partsysemissionmodule-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/PartSysEmissionModule.html&#34;&gt;Emissionモジュール&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Rate over time: 10&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;単位時間あたりにParticleを出す数。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Rate over Distance: 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;オブジェクトが移動するときにParticleを出す数。Simulation SpaceがWorldのときのみ有効。&lt;/p&gt;

&lt;h3 id=&#34;shapeモジュール-https-docs-unity3d-com-550-documentation-manual-partsysshapemodule-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/PartSysShapeModule.html&#34;&gt;Shapeモジュール&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Shape: Corn&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleを出す形。Cornだと特定方向に向けた円錐状に出る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-shape-corn.png&#34; alt=&#34;ShapeがCorn&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Spehreで全方向に出したり、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-shape-sphere.png&#34; alt=&#34;ShapeがSphere&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hemisphereで片側だけ出したり、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-shape-hemisphere.png&#34; alt=&#34;ShapeがHemisphere&#34; /&gt;&lt;/p&gt;

&lt;p&gt;EdgeでY方向に直線上に出したりすることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-shape-edge.png&#34; alt=&#34;ShapeがEdge&#34; /&gt;&lt;/p&gt;

&lt;p&gt;そのほかのパラメータはShapeに応じて設定する。&lt;/p&gt;

&lt;h3 id=&#34;rendererモジュール-https-docs-unity3d-com-550-documentation-manual-partsysrenderermodule-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/PartSysRendererModule.html&#34;&gt;Rendererモジュール&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Render Mode: Billboard&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleがどのようにレンダリングされるか。Billboardは常にカメラに向くようにレンダリングされる。&lt;/p&gt;

&lt;p&gt;Stretched Billboardにするとカメラの方向に向きながら、&lt;a href=&#34;https://en.wikipedia.org/wiki/Squash_and_stretch&#34;&gt;stretch and squash&lt;/a&gt;させる。つまり速度を強調するように変形させる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-stretched-billboard.png&#34; alt=&#34;Render ModeがStretched Billboard&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Material: None&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleのmaterial。これにDefault-Particleを指定するとこうなる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-default-particle.png&#34; alt=&#34;MaterialがDefault Particle&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;afterburner&#34;&gt;AfterBurner&lt;/h2&gt;

&lt;p&gt;Standard AssetsにあるAfterBurnerの設定を見てみる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-after-burner.png&#34; alt=&#34;AfterBurner&#34; /&gt;&lt;/p&gt;

&lt;p&gt;中央の濃い部分と、そのまわりの薄い部分の2つの設定を組み合わせている。
Explosionとかは9個組み合わせているので比較的シンプル。&lt;/p&gt;

&lt;p&gt;濃い部分ではEmissionのRate over Timeを80にすることで続いているように見えるようにして、
Size over LifetimeモジュールのSizeを徐々に小さくすることによって尾の方にかけて細くなるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-after-burner-size.png&#34; alt=&#34;AfterBurnerのSize over Lifetime&#34; /&gt;&lt;/p&gt;

&lt;p&gt;さらにColor over LifetimeモジュールのColorで両端のAlphaを0、Location 6.0%のAlphaを30に設定することで、
素早くフェードインし、徐々にフェードアウトするようにしている。&lt;/p&gt;

&lt;p&gt;また、Start SizeをRandom Between Two Constantsの(1.2, 1.4)に設定することで多少揺らいでいるように見せている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-after-burner-gradient.png&#34; alt=&#34;AfterBurnerのSize over Lifetime&#34; /&gt;&lt;/p&gt;

&lt;p&gt;薄い部分ではEmissionのRate over Timeを60、ColorのLocation 6.0%のAlphaを8に設定して薄く見せている。
あとはSize over Lifetimeを設定し、Start SizeはRandom Between Two Constantsの(4,6)と大きく設定してある。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>godocのメモ</title>
          <link>https://www.sambaiz.net/article/91/</link>
          <pubDate>Wed, 05 Apr 2017 22:11:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/91/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/tools/cmd/godoc&#34;&gt;https://godoc.org/golang.org/x/tools/cmd/godoc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;コメントからドキュメントを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ godoc cmd/fmt Printf
func Printf(format string, a ...interface{}) (n int, err error)
    Printf formats according to a format specifier and writes to standard
    output. It returns the number of bytes written and any write error
    encountered.

$ godoc -src cmd/fmt Printf
// Printf formats according to a format specifier and writes to standard output.
// It returns the number of bytes written and any write error encountered.
func Printf(format string, a ...interface{}) (n int, err error) {
    return Fprintf(os.Stdout, format, a...)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;記述対象の要素の名前から始まる、完全な文として&lt;a href=&#34;https://blog.golang.org/godoc-documenting-go-code&#34;&gt;コメントを書く&lt;/a&gt;。
インデントすれば整形した文になり、&lt;code&gt;Bug(ユーザー名):&lt;/code&gt;から始めればバグセクションにまとめられる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// foo bar package
package foo

import &amp;quot;fmt&amp;quot;

// Hoge returns &amp;quot;HOGE (input num)&amp;quot; string.
//   Hoge
//   Fuga
//   Piyo
// BUG(sambaiz): when passed 2, it panic.
func Hoge(num int) string {
	if num == 2 {
		panic(&amp;quot;AAAAAAAAHHHH&amp;quot;)
	}
	return fuga(&amp;quot;HOGE&amp;quot;, num)
}

// returns &amp;quot;(keyword) (num)&amp;quot; string
func fuga(keyword string, num int) string {
	return fmt.Sprintf(&amp;quot;%s %d&amp;quot;, keyword, num)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/testing/#hdr-Examples&#34;&gt;例&lt;/a&gt;を&lt;code&gt;ExampleXXX&lt;/code&gt;のような関数に書いておくと、これもドキュメントに追加される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package foo

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;testing&amp;quot;
)

func TestHoge(t *testing.T){
	...
}

func ExampleHoge() {
	fmt.Println(Hoge(1))
	// Output: HOGE 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Webサーバーを立ち上げてブラウザで確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ godoc -http=:6060 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じでfooパッケージのドキュメントが表示される。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:6060/pkg/github.com/sambaiz/godoctest/foo/&#34;&gt;http://localhost:6060/pkg/github.com/sambaiz/godoctest/foo/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/91_godoc.png&#34; alt=&#34;godoc&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Nightmareでブラウザでの操作を自動化する</title>
          <link>https://www.sambaiz.net/article/90/</link>
          <pubDate>Wed, 29 Mar 2017 23:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/90/</guid>
          <description>&lt;p&gt;最近、&lt;a href=&#34;http://postwash.net/&#34;&gt;POSTWASH&lt;/a&gt;という洗濯代行サービスを使っている。
専用のカバンに詰めて集荷にきた人に渡すと、きれいに畳まれた洗濯ものが届く便利なサービスだ。
注文時にはWebのフォームから集荷、配達時間や支払い方法などを選ぶ必要があるんだけど、毎週のことなのでこれを自動化してみる。&lt;/p&gt;

&lt;p&gt;ブラウザの操作を自動化するのに&lt;a href=&#34;https://github.com/segmentio/nightmare&#34;&gt;Nightmare&lt;/a&gt;を使う。
&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;を使っていて、&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PahntomJS&lt;/a&gt;より2倍くらい速く、簡潔に書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install nightmare
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Nightmare()&lt;/code&gt;の引数に&lt;code&gt;show: true&lt;/code&gt;を渡すとウィンドウが開いて実行し始める。
これで確認画面までいくのであとは注文ボタンを押すだけ。
ウィンドウが閉じないように最後に&lt;code&gt;nightmare.end()&lt;/code&gt;を呼んでいない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const co = require(&#39;co&#39;);
const moment = require(&#39;moment&#39;)
const jst = +9
const Nightmare = require(&#39;nightmare&#39;);		
const nightmare = Nightmare({ 
  show: true,
  waitTimeout: 3000,
  gotoTimeout: 3000
});
const loginID = process.env.LOGIN_ID;
const loginPassword = process.env.LOGIN_PASSWORD;

moment.locale(&#39;ja&#39;);
const now = moment().utcOffset(jst)
const dayAfterTomorrow = now.add(2, &#39;days&#39;).format(&amp;quot;YYYY年M月D日(ddd)&amp;quot;);
const nextWeek = now.add(7, &#39;days&#39;).format(&amp;quot;YYYY年M月D日(ddd)&amp;quot;)
console.log(`${dayAfterTomorrow}~${nextWeek}`);

// IDとパスワードを入れてログイン
const login = () =&amp;gt; nightmare
  .goto(&#39;https://sv359.xserver.jp/~postwash/postwash.net/accounts/&#39;)
  .type(&#39;#loginid&#39;, loginID)
  .insert(&#39;#loginpw&#39;, loginPassword) // .insert() is faster than .type() but does not trigger the keyboard events.
  .click(&#39;#submit&#39;)
  .wait(&#39;#yokoso&#39;)
  .evaluate(() =&amp;gt; document.querySelector(&#39;#yokoso h5&#39;).textContent);

// 注文フォームを埋めていく
const order = () =&amp;gt; nightmare
  .goto(&#39;https://sv359.xserver.jp/~postwash/postwash.net/mypage/order.html&#39;)
  .wait(&#39;#item\\[4\\]&#39;)
  .check(&#39;#item\\[4\\]&#39;)
  .insert(&#39;#itemnum\\[4\\]&#39;, &#39;1&#39;)
  .select(&#39;#pickup_date_request&#39;, dayAfterTomorrow)
  .select(&#39;#pickup_time_request&#39;, &#39;午前中（8時～12時）&#39;)
  .wait(500) // #delivery_date_request が切り替わってしまうので少し待つ
  .select(&#39;#delivery_date_request&#39;, nextWeek)
  .select(&#39;#delivery_time_request&#39;, &#39;午前中（8時～12時）&#39;)
  .select(&#39;#payment&#39;, &#39;代金引換&#39;)
  .check(&#39;#agreement&#39;)
  .click(&#39;#submit&#39;)

co(function *(){
    yield login().then(
        (result) =&amp;gt; console.log(result), // ようこそ
        (err) =&amp;gt; console.log(err)
    );
    yield order();
    // yield nightmare.end();
});
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsでの文字コードの変換</title>
          <link>https://www.sambaiz.net/article/89/</link>
          <pubDate>Tue, 28 Mar 2017 21:36:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/89/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/bnoordhuis/node-iconv&#34;&gt;node-iconv&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install iconv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SHIFT_JISからUTF-8への変換はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const Iconv  = require(&#39;iconv&#39;).Iconv;

const before = new Buffer([
    0x8b, 0x8d, 
    0x8e, 0x4d, 
    0x26,
    0x82, 0xb2,
    0x94, 0xd1
]);

const iconv = new Iconv(&#39;SHIFT_JIS&#39;, &#39;UTF-8&#39;);
console.log(`before: ${before.toString(&#39;hex&#39;)} ${before.toString()}`)
const after = iconv.convert(before);
console.log(`after:  ${after.toString(&#39;hex&#39;)} ${after.toString()}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;before: 8b8d8e4d2682b294d1 ���M&amp;amp;����
after:  e7899be79abf26e38194e9a3af 牛皿&amp;amp;ご飯
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文字コードによっては変換後に表せないことがある。
例えば、UTF-8からSHIFT_JISへの変換でサロゲートペア🍚を渡すと変換できず、エラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;throw errnoException(&#39;EILSEQ&#39;, &#39;Illegal character sequence.&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;//IGNORE&lt;/code&gt;を&lt;a href=&#34;https://www.npmjs.com/package/iconv#dealing-with-untranslatable-characters&#34;&gt;付ける&lt;/a&gt;ことで
そのような文字があった場合でもエラーにしないようにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const Iconv  = require(&#39;iconv&#39;).Iconv;

const before = &amp;quot;牛皿&amp;amp;🍚&amp;quot;;

const iconv = new Iconv(&#39;UTF-8&#39;, &#39;SHIFT_JIS//IGNORE&#39;);
console.log(`before: ${new Buffer(before).toString(&#39;hex&#39;)} ${before.toString()}`)
const conv = iconv.convert(before);
const iconv2 = new Iconv(&#39;SHIFT_JIS&#39;, &#39;UTF-8&#39;);
const after = iconv2.convert(conv);
console.log(`after:  ${after.toString(&#39;hex&#39;)} ${after.toString()}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;変換できないものは無視される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;before: e7899be79abf26f09f8d9a 牛皿&amp;amp;🍚
after:  e7899be79abf26 牛皿&amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lambdaでは&#34;&gt;Lambdaでは&lt;/h2&gt;

&lt;p&gt;Lambdaではインストールされているiconvコマンドを使うことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return new Promise((resolve, reject) =&amp;gt; {
    let filePath = &amp;quot;/tmp/shiftjis&amp;quot;;
    fs.writeFileSync(filePath, shiftjis);
    var exec = require(&#39;child_process&#39;).exec;
    var cmd = `iconv -c -f sjis -t utf-8 ${filePath}`;
    var child = exec(cmd, (err, stdout, stderr) =&amp;gt; {
      if (err) reject(err);
      else resolve(stdout);
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bokukoko.info/entry/2015/08/30/AWS_Lambda%E5%86%85%E3%81%A7%E6%96%87%E5%AD%97%E3%82%B3%E3%83%BC%E3%83%89%E3%82%92%E5%A4%89%E6%8F%9B%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95&#34;&gt;AWS Lambda内で文字コードを変換する方法 - ボクココ&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensのSharing</title>
          <link>https://www.sambaiz.net/article/88/</link>
          <pubDate>Sat, 25 Mar 2017 22:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/88/</guid>
          <description>

&lt;ul&gt;
&lt;li&gt;HoloToolkit-Unity v1.5.5.0&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サーバー&#34;&gt;サーバー&lt;/h2&gt;

&lt;p&gt;SharingService.exeを
&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/tree/v1.5.5.0/External/HoloToolkit/Sharing/Server&#34;&gt;ここ&lt;/a&gt;
からとってきて実行する。開発に使っているHoloToolkitと同じリリースバージョンのものを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SharingService.exe -local
...
SharingService: Listening for session list connections on port 20602 of all network devices of the local machine.
SharingService: Local IP addresses are:
SharingService:         xxx.xxx.xxx.xxx
SharingService: Created Session &amp;quot;Default&amp;quot; with ID 0 on port 20601
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今日のTokyo Hololens Meetup Vol.2の開発者セッションで、
ちょうどSharingの話があったのだけれど、残念ながら先着順で出遅れて聞けなかった。&lt;/p&gt;

&lt;p&gt;Tweetを見る限りだとカスタマイズできず、スケーリングできないSharingService.exeは使わずに
&lt;a href=&#34;https://github.com/neuecc/MagicOnion&#34;&gt;MagicOnion&lt;/a&gt;というのを自前で作ったらしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://togetter.com/li/1094037&#34;&gt;Tokyo Hololens MeetuUp Vol.2 Session5 #HoloLensJP #TMCN - Togetterまとめ&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;クライアント-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing&#34;&gt;クライアント&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Assets/HoloToolkit/Sharing/Tests&lt;/code&gt;のSceneで試してみる。&lt;/p&gt;

&lt;p&gt;以下のcapabilitiesを設定し、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SpatialPerception&lt;/li&gt;
&lt;li&gt;InternetClient&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SharingのServer Addressを設定してビルド。ほかにはこんな設定がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Scripts/SharingStage.cs#L15&#34;&gt;Client Role&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Primary: 直接セッションサーバーに接続し、セッションを管理する&lt;/li&gt;
&lt;li&gt;Secondary: Primaryクライアントに接続して、セッション管理は任せる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Server Address&lt;/li&gt;
&lt;li&gt;Port&lt;/li&gt;
&lt;li&gt;Auto Discover Server&lt;/li&gt;
&lt;li&gt;Session Name&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;起動して以下のようなエラーが出たらSharingService.exeがHoloToolkitのバージョンと合っていない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;List Server Handshake Failed: Invalid schema version.
Expected: 17, got 15
Please sync to latest XTools
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接続と離脱のメッセージはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SharingService: User UnknownUser at address xxx.xxx.xxx.xxx joined session Default
SharingService: User UnknownUser left session Default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2つ以上クライアントを立ち上げると、他のクライアントの、球からの相対的な頭の位置にCubeが映った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/88-sharing.jpg&#34; alt=&#34;他のクライアントの頭の位置にCubeがある&#34; /&gt;&lt;/p&gt;

&lt;p&gt;が、球の場所が空間に対して同期されない・・・。&lt;/p&gt;

&lt;p&gt;原因を探るために、
TestsのSceneと同様に、SharingのPrefabにCustomMessage.csを、
適当なGameObjectにImportExportAnchorManager.csとRemoteHeadManager.csと
目印になるオブジェクトを追加し、
ImportExportAnchorManager.csにこんな感じのを追加してcurrentStateを表示してみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public GameObject statusText;
private void Update()
{
    statusText.GetComponent&amp;lt;TextMesh&amp;gt;().text = currentState.ToString();
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果、起動してからまだReady状態になっていなかったことが分かった。
少し待ってみるといろんな状態を経て、Ready状態になると、
目印のオブジェクトが物理的に同じところに移動し、頭の位置も正しいところに移動した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/88-sharing2.png&#34; alt=&#34;Sharingしている状態&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;なにをやっているか見ていく。&lt;/p&gt;

&lt;p&gt;まずは拾えるevent。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/83/&#34;&gt;C#のdelegateとevent - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;sharingsessiontracker-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-scripts-sharingsessiontracker-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Scripts/SharingSessionTracker.cs&#34;&gt;SharingSessionTracker&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;public event EventHandler&lt;SessionJoinedEventArgs&gt; SessionJoined;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ユーザーがセッションに入ったとき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class SessionJoinedEventArgs : EventArgs
{
    public User joiningUser;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;public event EventHandler&lt;SessionLeftEventArgs&gt; SessionLeft;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;セッションから出たとき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class SessionLeftEventArgs : EventArgs
{
    public long exitingUserId;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sharingstage-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-scripts-sharingstage-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Scripts/SharingStage.cs&#34;&gt;SharingStage&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;public event EventHandler SharingManagerConnected;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SharingManagerが接続されたとき。ArgsはEmpty。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;connectedEvent(this, EventArgs.Empty);
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;これらのeventをsubscribeしているTestsの中のコード。&lt;/p&gt;

&lt;h2 id=&#34;custommessages-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-tests-custommessages-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Tests/CustomMessages.cs&#34;&gt;CustomMessages&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;データを送受信するところ。&lt;/p&gt;

&lt;h3 id=&#34;初期化-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-tests-custommessages-cs-l57&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Tests/CustomMessages.cs#L57&#34;&gt;初期化&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;SharingManagerが接続されたら初期化がはじまる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Start()
{
    SharingStage.Instance.SharingManagerConnected += SharingManagerConnected;
}

private void SharingManagerConnected(object sender, EventArgs e)
{
    InitializeMessageHandlers();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず、ServerとのConnectionを取得し、Messageを受信したときのeventをsubscribeしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SharingStage sharingStage = SharingStage.Instance;
serverConnection = sharingStage.Manager.GetServerConnection();
connectionAdapter = new NetworkConnectionAdapter();
connectionAdapter.MessageReceivedCallback += OnMessageReceived;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それから自分自身のユーザーIDも保存してある。これはMessageを送るときに使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;localUserID = SharingStage.Instance.Manager.GetLocalUser().GetID();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後に&lt;code&gt;MessageHandlers&lt;/code&gt;にnullを詰めて終わり。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (byte index = (byte)TestMessageID.HeadTransform; index &amp;lt; (byte)TestMessageID.Max; index++)
{
    if (MessageHandlers.ContainsKey((TestMessageID)index) == false)
    {
        MessageHandlers.Add((TestMessageID)index, null);
    }

    serverConnection.AddListener(index, connectionAdapter);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後からこういう風にhandlerを設定している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CustomMessages.Instance.MessageHandlers[CustomMessages.TestMessageID.HeadTransform] = this.UpdateHeadTransform;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;受信&#34;&gt;受信&lt;/h3&gt;

&lt;p&gt;messageTypeに対応したhandlerに渡す。初期状態では全てnullなので何もしない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void OnMessageReceived(NetworkConnection connection, NetworkInMessage msg)
{
    byte messageType = msg.ReadByte();
    MessageCallback messageHandler = MessageHandlers[(TestMessageID)messageType];
    if (messageHandler != null)
    {
        messageHandler(msg);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;送信&#34;&gt;送信&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;CustomMessages.Instance.SendStageTransform(transform.localPosition, transform.localRotation);
CustomMessages.Instance.SendHeadTransform(headPosition, headRotation);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じにBroadcastしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void SendHeadTransform(Vector3 position, Quaternion rotation)
{
    // If we are connected to a session, broadcast our head info
    if (serverConnection != null &amp;amp;&amp;amp; serverConnection.IsConnected())
    {
        // Create an outgoing network message to contain all the info we want to send
        NetworkOutMessage msg = CreateMessage((byte)TestMessageID.HeadTransform);

        AppendTransform(msg, position, rotation);

        // Send the message as a broadcast, which will cause the server to forward it to all other users in the session.
        serverConnection.Broadcast(
            msg,
            MessagePriority.Immediate,
            MessageReliability.UnreliableSequenced,
            MessageChannel.Avatar);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;importexportanchormanager-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-tests-importexportanchormanager-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Tests/ImportExportAnchorManager.cs&#34;&gt;ImportExportAnchorManager&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;オブジェクトのpositionを物理的に固定する&lt;a href=&#34;https://docs.unity3d.com/ScriptReference/VR.WSA.WorldAnchor.html&#34;&gt;WorldAnchor&lt;/a&gt;を共有する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;currentState&lt;/code&gt;は最初&lt;code&gt;AnchorStore_Initializing&lt;/code&gt;で、
&lt;code&gt;anchorStore&lt;/code&gt;が取得できたら&lt;code&gt;AnchorStore_Initialized&lt;/code&gt;になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private ImportExportState currentState = ImportExportState.Start;

// インスタンスがロードされたときに呼ばれる。コンストラクターの代わり
protected override void Awake()
{
    base.Awake();
    Debug.Log(&amp;quot;Import Export Manager starting&amp;quot;);
    // We need to get our local anchor store started up.
    currentState = ImportExportState.AnchorStore_Initializing;
    WorldAnchorStore.GetAsync(AnchorStoreReady);
}

private void AnchorStoreReady(WorldAnchorStore store)
{
    anchorStore = store;
    currentState = ImportExportState.AnchorStore_Initialized;
}

private void Start()
{
    SharingStage.Instance.SharingManagerConnected += SharingManagerConnected;
    SharingSessionTracker.Instance.SessionJoined += Instance_SessionJoined;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SharingManagerが接続されたら、RoomManagerのインスタンスを取得して、
Anchorのダウンロードとアップロードしたときのeventをsubscribeしている。&lt;/p&gt;

&lt;p&gt;Uploaded時は&lt;code&gt;currentState&lt;/code&gt;を&lt;code&gt;Ready&lt;/code&gt;にし、
Downloaded時は&lt;code&gt;rawAnchorData&lt;/code&gt;に保存し、&lt;code&gt;currentState&lt;/code&gt;を&lt;code&gt;DataReady&lt;/code&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void SharingManagerConnected(object sender, EventArgs e)
{
    // Setup the room manager callbacks.
    roomManager = SharingStage.Instance.Manager.GetRoomManager();
    roomManagerCallbacks = new RoomManagerAdapter();

    roomManagerCallbacks.AnchorsDownloadedEvent += RoomManagerCallbacks_AnchorsDownloaded;
    roomManagerCallbacks.AnchorUploadedEvent += RoomManagerCallbacks_AnchorUploaded;
    roomManager.AddListener(roomManagerCallbacks);
}

private void RoomManagerCallbacks_AnchorUploaded(bool successful, XString failureReason)
{
    if (successful)
    {
        currentState = ImportExportState.Ready;
    }
    else
    {
        Debug.Log(&amp;quot;Upload failed &amp;quot; + failureReason);
        currentState = ImportExportState.Failed;
    }
}

private byte[] rawAnchorData = null;

private void RoomManagerCallbacks_AnchorsDownloaded(bool successful, AnchorDownloadRequest request, XString failureReason)
{
    // If we downloaded anchor data successfully we should import the data.
    if (successful)
    {
        int datasize = request.GetDataSize();
        Debug.Log(datasize + &amp;quot; bytes &amp;quot;);
        rawAnchorData = new byte[datasize];

        request.GetData(rawAnchorData, datasize);
        currentState = ImportExportState.DataReady;
    }
    else
    {
        // If we failed, we can ask for the data again.
        Debug.Log(&amp;quot;Anchor DL failed &amp;quot; + failureReason);
        MakeAnchorDataRequest();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SessionJoin時には、&lt;code&gt;sharingServiceReady&lt;/code&gt;をtrueにする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;InitRoomApi()&lt;/code&gt;では&lt;code&gt;currentRoom&lt;/code&gt;にJoin(あるいは新しく作る)し、Roomを代入している。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;currentState&lt;/code&gt;は新しくRoomを作った場合&lt;code&gt;InitialAnchorRequired&lt;/code&gt;で、すでにあるRoomに入った場合&lt;code&gt;RoomApiInitialized&lt;/code&gt;になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private bool sharingServiceReady = false;
private Room currentRoom;

private void Instance_SessionJoined(object sender, SharingSessionTracker.SessionJoinedEventArgs e)
{
    SharingSessionTracker.Instance.SessionJoined -= Instance_SessionJoined;

    // ほかの処理が落ち着くまで5秒待って実行する
    Invoke(&amp;quot;MarkSharingServiceReady&amp;quot;, 5);
}

private void MarkSharingServiceReady()
{
    sharingServiceReady = true;

#if UNITY_EDITOR || UNITY_STANDALONE
    InitRoomApi();
#endif
}

private void InitRoomApi()
{
    if (roomManager.GetRoomCount() == 0)
    {
        if (LocalUserHasLowestUserId())
        {
            Debug.Log(&amp;quot;Creating room &amp;quot;);            
            currentRoom = roomManager.CreateRoom(new XString(&amp;quot;DefaultRoom&amp;quot;), roomID, false);
            currentState = ImportExportState.InitialAnchorRequired;
        }
    }
    else
    {
        Debug.Log(&amp;quot;Joining room &amp;quot;);
        currentRoom = roomManager.GetRoom(0);
        roomManager.JoinRoom(currentRoom);
        currentState = ImportExportState.RoomApiInitialized;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Update。ここで&lt;code&gt;currentState&lt;/code&gt;を見ている。ここまでの&lt;code&gt;currentState&lt;/code&gt;をまとめると、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AnchorStore_Initializing: 初期状態&lt;/li&gt;
&lt;li&gt;AnchorStore_Initialized: AnchorStore取得完了&lt;/li&gt;
&lt;li&gt;InitialAnchorRequired: 新しくRoomを作った(のでWorldAnchorを生成する)&lt;/li&gt;
&lt;li&gt;RoomApiInitialized: すでにあるRoomに入った&lt;/li&gt;
&lt;li&gt;Ready: Upload完了&lt;/li&gt;
&lt;li&gt;DataReady: Download完了&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void Update()
{
    switch (currentState)
    {
        case ImportExportState.AnchorStore_Initialized:
            if (sharingServiceReady)
            {
                InitRoomApi();
            }
            break;
        case ImportExportState.RoomApiInitialized:
            StartAnchorProcess();
            break;
        case ImportExportState.DataReady:
            // DataReady is set when the anchor download completes.
            currentState = ImportExportState.Importing;
            WorldAnchorTransferBatch.ImportAsync(rawAnchorData, ImportComplete);
            break;
        case ImportExportState.InitialAnchorRequired:
            currentState = ImportExportState.CreatingInitialAnchor;
            CreateAnchorLocally();
            break;
        case ImportExportState.ReadyToExportInitialAnchor:
            // We&#39;ve created an anchor locally and it is ready to export.
            currentState = ImportExportState.UploadingInitialAnchor;
            Export();
            break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Roomを新しく作ったならWorldAnchorを作成する必要がある。
&lt;a href=&#34;https://docs.unity3d.com/ScriptReference/VR.WSA.WorldAnchor-isLocated.html&#34;&gt;isLocated&lt;/a&gt;がtrueになったら
&lt;code&gt;OnTrackingChanged_InitialAnchor&lt;/code&gt;にし、AnchorをUploadする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void CreateAnchorLocally()
{
    WorldAnchor anchor = GetComponent&amp;lt;WorldAnchor&amp;gt;();
    if (anchor == null)
    {
        anchor = gameObject.AddComponent&amp;lt;WorldAnchor&amp;gt;();
    }

    if (anchor.isLocated)
    {
        currentState = ImportExportState.ReadyToExportInitialAnchor;
    }
    else
    {
        anchor.OnTrackingChanged += Anchor_OnTrackingChanged_InitialAnchor;
    }
}

private void Anchor_OnTrackingChanged_InitialAnchor(WorldAnchor self, bool located)
{
    if (located)
    {
        Debug.Log(&amp;quot;Found anchor, ready to export&amp;quot;);
        currentState = ImportExportState.ReadyToExportInitialAnchor;
    }
    else
    {
        Debug.Log(&amp;quot;Failed to locate local anchor (super bad!)&amp;quot;);
        currentState = ImportExportState.Failed;
    }

    self.OnTrackingChanged -= Anchor_OnTrackingChanged_InitialAnchor;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;anchorStore&lt;/code&gt;に保存して、SerializeしてUploadする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void Export()
{
    WorldAnchor anchor = GetComponent&amp;lt;WorldAnchor&amp;gt;();

    string guidString = Guid.NewGuid().ToString();
    exportingAnchorName = guidString;

    // Save the anchor to our local anchor store.
    if (anchorStore.Save(exportingAnchorName, anchor))
    {
        sharedAnchorInterface = new WorldAnchorTransferBatch();
        sharedAnchorInterface.AddWorldAnchor(guidString, anchor);
        WorldAnchorTransferBatch.ExportAsync(sharedAnchorInterface, WriteBuffer, ExportComplete);
    }
    else
    {
        Debug.Log(&amp;quot;This anchor didn&#39;t work, trying again&amp;quot;);
        currentState = ImportExportState.InitialAnchorRequired;
    }
}

public void ExportComplete(SerializationCompletionReason status)
{
    if (status == SerializationCompletionReason.Succeeded &amp;amp;&amp;amp; exportingAnchorBytes.Count &amp;gt; minTrustworthySerializedAnchorDataSize)
    {
        Debug.Log(&amp;quot;Uploading anchor: &amp;quot; + exportingAnchorName);
        roomManager.UploadAnchor(
            currentRoom,
            new XString(exportingAnchorName),
            exportingAnchorBytes.ToArray(),
            exportingAnchorBytes.Count);
    }
    else
    {
        Debug.Log(&amp;quot;This anchor didn&#39;t work, trying again&amp;quot;);
        currentState = ImportExportState.InitialAnchorRequired;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もしすでにあるRoomにJoinしている(&lt;code&gt;RoomApiInitialized&lt;/code&gt;)なら、Anchorをダウンロードし始め、&lt;code&gt;DataRequested&lt;/code&gt;になる。
ダウンロードしたら&lt;code&gt;DataReady&lt;/code&gt;になって、AnchorデータをImportする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void StartAnchorProcess()
{
    // First, are there any anchors in this room?
    int anchorCount = currentRoom.GetAnchorCount();

    // If there are anchors, we should attach to the first one.
    if (anchorCount &amp;gt; 0)
    {
        // Extract the name of the anchor.
        XString storedAnchorString = currentRoom.GetAnchorName(0);
        string storedAnchorName = storedAnchorString.GetString();

        // Attempt to attach to the anchor in our local anchor store.
        if (AttachToCachedAnchor(storedAnchorName) == false)
        {
            MakeAnchorDataRequest();
        }
    }
}

private void MakeAnchorDataRequest()
{
    if (roomManager.DownloadAnchor(currentRoom, currentRoom.GetAnchorName(0)))
    {
        currentState = ImportExportState.DataRequested;
    }
    else
    {
        Debug.Log(&amp;quot;Couldn&#39;t make the download request.&amp;quot;);
        currentState = ImportExportState.Failed;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Import完了したら&lt;code&gt;anchorStore&lt;/code&gt;に保存し、&lt;code&gt;Ready&lt;/code&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void ImportComplete(SerializationCompletionReason status, WorldAnchorTransferBatch wat)
{
    if (status == SerializationCompletionReason.Succeeded &amp;amp;&amp;amp; wat.GetAllIds().Length &amp;gt; 0)
    {
        Debug.Log(&amp;quot;Import complete&amp;quot;);

        string first = wat.GetAllIds()[0];
        Debug.Log(&amp;quot;Anchor name: &amp;quot; + first);

        WorldAnchor anchor = wat.LockObject(first, gameObject);
        anchorStore.Save(first, anchor);
        currentState = ImportExportState.Ready;
    }
    else
    {
        Debug.Log(&amp;quot;Import fail&amp;quot;);
        currentState = ImportExportState.DataReady;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;remoteheadmanager-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-tests-remoteheadmanager-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Tests/RemoteHeadManager.cs&#34;&gt;RemoteHeadManager&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;他のユーザーの頭の位置にオブジェクトを表示させる。&lt;/p&gt;

&lt;p&gt;受信時のhandlerを設定し、eventをsubscribeする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Start()
{
    CustomMessages.Instance.MessageHandlers[CustomMessages.TestMessageID.HeadTransform] = this.UpdateHeadTransform;

    SharingSessionTracker.Instance.SessionJoined += Instance_SessionJoined;
    SharingSessionTracker.Instance.SessionLeft += Instance_SessionLeft;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;joinしたのが自分自身じゃないかチェック。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void Instance_SessionJoined(object sender, SharingSessionTracker.SessionJoinedEventArgs e)
{
    if (e.joiningUser.GetID() != SharingStage.Instance.Manager.GetLocalUser().GetID())
    {
        GetRemoteHeadInfo(e.joiningUser.GetID());
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;remoteHeads&lt;/code&gt;になければ、HeadObjectを作成し、追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public RemoteHeadInfo GetRemoteHeadInfo(long userID)
{
    RemoteHeadInfo headInfo;

    // Get the head info if its already in the list, otherwise add it
    if (!this.remoteHeads.TryGetValue(userID, out headInfo))
    {
        headInfo = new RemoteHeadInfo();
        headInfo.UserID = userID;
        headInfo.HeadObject = CreateRemoteHead();

        this.remoteHeads.Add(userID, headInfo);
    }

    return headInfo;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sessionから離れたときはオブジェクトを削除し、remoteHeadsから取り除く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void Instance_SessionLeft(object sender, SharingSessionTracker.SessionLeftEventArgs e)
{
    if (e.exitingUserId != SharingStage.Instance.Manager.GetLocalUser().GetID())
    {
        RemoveRemoteHead(this.remoteHeads[e.exitingUserId].HeadObject);
        this.remoteHeads.Remove(e.exitingUserId);
    }
}

void RemoveRemoteHead(GameObject remoteHeadObject)
{
    DestroyImmediate(remoteHeadObject);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;受信時のhandlerではMessageからpositionとquarternionを取得し、オブジェクトの位置を動かしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void UpdateHeadTransform(NetworkInMessage msg)
{
    // Parse the message
    long userID = msg.ReadInt64();

    Vector3 headPos = CustomMessages.Instance.ReadVector3(msg);

    Quaternion headRot = CustomMessages.Instance.ReadQuaternion(msg);

    RemoteHeadInfo headInfo = GetRemoteHeadInfo(userID);
    headInfo.HeadObject.transform.localPosition = headPos;
    headInfo.HeadObject.transform.localRotation = headRot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自分の頭の位置はUpdate()で送信している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Update()
{
    // Grab the current head transform and broadcast it to all the other users in the session
    Transform headTransform = Camera.main.transform;

    // Transform the head position and rotation from world space into local space
    Vector3 headPosition = this.transform.InverseTransformPoint(headTransform.position);
    Quaternion headRotation = Quaternion.Inverse(this.transform.rotation) * headTransform.rotation;

    CustomMessages.Instance.SendHeadTransform(headPosition, headRotation);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ライセンス&#34;&gt;ライセンス&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;MIT License

Copyright (c) 2016 Microsoft Corporation

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &amp;quot;Software&amp;quot;), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED &amp;quot;AS IS&amp;quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unixのパイプをmkfifo()で作ってdup2()で標準出力にコピーして書き込む</title>
          <link>https://www.sambaiz.net/article/87/</link>
          <pubDate>Fri, 24 Mar 2017 22:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/87/</guid>
          <description>

&lt;h2 id=&#34;パイプとは&#34;&gt;パイプとは&lt;/h2&gt;

&lt;p&gt;Unixでプロセス間通信するためのもの。シェルで使う&lt;code&gt;|&lt;/code&gt;は無名パイプ。
&lt;code&gt;mkfifo()&lt;/code&gt;システムコールで名前付きパイプを作成でき、これを読み書きすることで任意のプロセス間でやりとりできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkfifo hoge
$ ls -lh
$ prw-r--r-- ... 0B ... hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常のファイルと同様に読み書きすることができ、読み書きどちらかを行おうとすると待つことになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo hoge &amp;amp; # 読まれるまで待つ
$ cat hoge
aaaaa
[1]+  Done                    echo &amp;quot;aaaaa&amp;quot; &amp;gt; hoge

$ cat hoge &amp;amp; # 書かれるまで待つ
$ echo &amp;quot;bbbbb&amp;quot; &amp;gt; hoge
bbbbb
[1]+  Done                    cat hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイルディスクリプタをコピーするシステムコール&lt;code&gt;dup2()&lt;/code&gt;でopenしたパイプを標準出力(1)にコピーしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;

int main(){
  int fd = open(&amp;quot;./hoge&amp;quot;, O_WRONLY);
  if(fd &amp;lt; 0){
    printf(&amp;quot;fail to open\n&amp;quot;);
    return 1;
  }

  printf(&amp;quot;OPEN %d \n&amp;quot;, fd);

  if(dup2(fd, 1) &amp;lt; 0){
    printf(&amp;quot;fail to dup2\n&amp;quot;);
    return 2;
  }

  printf(&amp;quot;WRITE\n&amp;quot;); // これがどこに書き込まれるか

  close(fd);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後のprintfの内容は標準出力ではなく、パイプに書き込まれていることがわかる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./a.out &amp;amp;
$ echo &amp;quot;read `cat hoge` from pipe&amp;quot;
OPEN 3 
read WRITE from pipe
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%83%97_(%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF)#.E3.83.97.E3.83.AD.E3.82.B0.E3.83.A9.E3.83.A0.E3.81.AB.E3.82.88.E3.82.8B.E3.83.91.E3.82.A4.E3.83.97.E3.81.AE.E4.BD.9C.E6.88.90&#34;&gt;パイプ (コンピュータ) - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/richmikan@github/items/bb660a58690ac01ec295&#34;&gt;mkfifoコマンドって使ってますか？ - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/stc1988/items/9354204d3c2ff210512b&#34;&gt;リダイレクトの挙動 - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CuratorでElasticsearchの古いindexを削除する</title>
          <link>https://www.sambaiz.net/article/86/</link>
          <pubDate>Wed, 22 Mar 2017 00:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/86/</guid>
          <description>

&lt;h2 id=&#34;curatorとは-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-index-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html&#34;&gt;Curatorとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;indexやsnapshotを管理するのに使えるツール。&lt;/p&gt;

&lt;h2 id=&#34;インストール-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-installation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/installation.html&#34;&gt;インストール&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;インストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/yum.repos.d/curator.repo
[curator-4]
name=CentOS/RHEL 7 repository for Elasticsearch Curator 4.x packages
baseurl=http://packages.elastic.co/curator/4/centos/7
gpgcheck=1
gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch
enabled=1

$ yum install -y elasticsearch-curator
$ curator --version
curator, version 4.2.6
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;config-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-configfile-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/configfile.html&#34;&gt;config&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;configファイルを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;client:
  hosts:
    - 127.0.0.1
  port: 9200

logging:
  loglevel: INFO
  logfile:
  logformat: default
  blacklist: [&#39;elasticsearch&#39;, &#39;urllib3&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;action-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-actions-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/actions.html&#34;&gt;action&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;今回はindexを削除するので&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/ex_delete_indices.html&#34;&gt;delete_indices&lt;/a&gt;。
対象は&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/filters.html&#34;&gt;filter&lt;/a&gt;で指定する。
logstash formatだとhogehoge-2017.01.01のようなindex名になるので&lt;code&gt;%Y.%m.%d&lt;/code&gt;。&lt;code&gt;okder than 3 days&lt;/code&gt;のものを削除する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;actions:
  1:
    action: delete_indices
    description: &amp;gt;-
      3日前より古いhogehoge-* indexを消す
    filters:
    - filtertype: pattern
      kind: prefix
      value: hogehoge-
    - filtertype: age
      source: name
      direction: older
      timestring: &#39;%Y.%m.%d&#39;
      unit: days
      unit_count: 3
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-command-line-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/command-line.html&#34;&gt;実行&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;configとactionファイルを指定して実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curator --config curator_config.yml curator_action.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;毎日00:05に実行するようにしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ crontab -l
5 0 * * * curator --config curator_config.yml curator_action.yml
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RxJSでRxをはじめる</title>
          <link>https://www.sambaiz.net/article/85/</link>
          <pubDate>Sat, 18 Mar 2017 21:36:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/85/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/ReactiveX/rxjs&#34;&gt;https://github.com/ReactiveX/rxjs&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;rx-reactivex-とは-http-reactivex-io-intro-html&#34;&gt;&lt;a href=&#34;http://reactivex.io/intro.html&#34;&gt;Rx(ReactiveX)とは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;非同期処理をうまく扱えるようにするライブラリ。いろんな言語で実装されている。
非同期処理の結果はObservableなStreamに流される。
ObservableはIteratableのように扱うことができる。&lt;/p&gt;

&lt;p&gt;Rxは&lt;a href=&#34;https://en.wikipedia.org/wiki/Observer_pattern&#34;&gt;Observer pattern&lt;/a&gt;
を拡張したもの。
Observer patternというのは、Subjectが、Observeしている全てのObserverに対して通知を送るデザインパターン。
C#などのeventのそれ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/83/&#34;&gt;C#のdelegateとevent - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;試してみる&#34;&gt;試してみる&lt;/h2&gt;

&lt;p&gt;inputのkeyupイベントのObservableを作成し、それを&lt;code&gt;subscribe()&lt;/code&gt;して出力している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;script src=&amp;quot;https://cdnjs.cloudflare.com/ajax/libs/rxjs/5.0.1/Rx.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;

&amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;input&amp;quot; /&amp;gt;

&amp;lt;script&amp;gt;

const inputForm = document.querySelector(&#39;#input&#39;);

const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;);

keyups.subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; console.log(err)
);

&amp;lt;/script&amp;gt;

&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入力するとこんなのが出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;KeyboardEvent {isTrusted: true, key: &amp;quot;a&amp;quot;, code: &amp;quot;KeyA&amp;quot;, location: 0, ctrlKey: false…}
KeyboardEvent {isTrusted: true, key: &amp;quot;b&amp;quot;, code: &amp;quot;KeyB&amp;quot;, location: 0, ctrlKey: false…}
KeyboardEvent {isTrusted: true, key: &amp;quot;c&amp;quot;, code: &amp;quot;KeyC&amp;quot;, location: 0, ctrlKey: false…}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;observable-http-reactivex-io-rxjs-class-es6-observable-js-observable-html&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html&#34;&gt;Observable&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;create-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-create&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-create&#34;&gt;create&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;next()&lt;/code&gt;でObservableに値をemitし、&lt;code&gt;complete()&lt;/code&gt;で終了させる。
&lt;code&gt;error()&lt;/code&gt;でエラーをemitするとそれ以後の値はemitされない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.create(function (observer) {
    observer.next(&amp;quot;AAAAA&amp;quot;);
    observer.next(&amp;quot;BBBBB&amp;quot;);
    observer.next(&amp;quot;CCCCC&amp;quot;);
    observer.complete();
}).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;AAAA
BBBB
CCCC
completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;from-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-from&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-from&#34;&gt;from&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;配列などのIteratableをObservableに変換する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.from([1,2,3]).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1
2
3
completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;fromevent-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-fromevent&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-fromEvent&#34;&gt;fromEvent&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;上で使ったやつ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.fromEvent(document.querySelector(&#39;#input&#39;), &#39;keyup&#39;).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;KeyboardEvent {isTrusted: true, key: &amp;quot;a&amp;quot;, code: &amp;quot;KeyA&amp;quot;, location: 0, ctrlKey: false…}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;frompromise-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-frompromise&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-fromPromise&#34;&gt;fromPromise&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;PromiseもObservableに変換できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.fromPromise(Promise.resolve(&amp;quot;ok&amp;quot;)).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ok
completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;interval-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-interval&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-interval&#34;&gt;interval&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;一定時間ごとにemitし続ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.interval(1000).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0
1
2
3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/100/&#34;&gt;RxJSでObservableを結合する(merge, forkJoin, concat, combineLatest) - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;operator-http-reactivex-io-rxjs-manual-overview-html-operators&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/manual/overview.html#operators&#34;&gt;Operator&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Observableのメソッド。新しいObservableを作って返す。&lt;/p&gt;

&lt;p&gt;上で試したkeyupのObservableにいろいろやってみる。&lt;/p&gt;

&lt;h3 id=&#34;pluck-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-pluck&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-pluck&#34;&gt;pluck&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;nestされたプロパティを指定する。この例だと&lt;code&gt;.target.value&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;)
  .pluck(&#39;target&#39;, &#39;value&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;h
ho
hog
hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;filter-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-filter&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-filter&#34;&gt;filter&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;フィルタリングする。この例だと長さが2より大きいものだけがemitされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;)
  .pluck(&#39;target&#39;, &#39;value&#39;)
  .filter(text =&amp;gt; text.length &amp;gt; 2 );
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;hog
hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;map-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-map&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-map&#34;&gt;map&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;map。この例だと&lt;code&gt;value: ${text}&lt;/code&gt;のフォーマットでemitされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;)
  .pluck(&#39;target&#39;, &#39;value&#39;)
  .filter(text =&amp;gt; text.length &amp;gt; 2 )
  .map(text =&amp;gt; `value: ${text}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;value: hog
value: hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;reduce-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-reduce&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-reduce&#34;&gt;reduce&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;reduce。emitされるのはcompleteされたときなので、&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-takeUntil&#34;&gt;takeUntil()&lt;/a&gt;で
渡したObservableが何かemitしたときにcompleteさせるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;)
  .takeUntil(Rx.Observable.interval(5000))
  .pluck(&#39;target&#39;, &#39;value&#39;)
  .filter(text =&amp;gt; text.length &amp;gt; 2 )
  .map(text =&amp;gt; `value: ${text}`)
  .reduce((acc, curr) =&amp;gt; `${acc} ${curr}`, &amp;quot;&amp;quot;);

keyups.subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; console.log(err),
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; value: aaa value: aaaa value: aaaaa value: aaaaaa value: aaaaaaa value: aaaaaaaa value: aaaaaaaaa value: aaaaaaaaaa value: aaaaaaaaaaa
 completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;subject-http-reactivex-io-documentation-subject-html&#34;&gt;&lt;a href=&#34;http://reactivex.io/documentation/subject.html&#34;&gt;Subject&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Observerでもあり、Observableでもあるブリッジのようなもの。&lt;/p&gt;

&lt;p&gt;これまでのObservableはSubscribeされるまでemitしない&amp;rdquo;Cold&amp;rdquo;なものだったが、
SubjectはそんなObservableをSubscribeし、それをトリガーにemitするので、
&amp;ldquo;Cold&amp;rdquo;なObservableを常にemitし得る&amp;rdquo;Hot&amp;rdquo;なものに変えることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// ColdなObservable
const cold = Rx.Observable.from([1,2,3]);

// Coldだと、いつから、何回読んでも同じ値が得られる

// 1, 2, 3, completed
cold.subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);

// 1, 2, 3, completed
cold.subscribe(
  data =&amp;gt; console.log(data), 
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;publish-subject&#34;&gt;(Publish)Subject&lt;/h3&gt;

&lt;p&gt;Subscribeした時点からemitされたアイテムをemitする。それまでにemitされたアイテムはしない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const subject = new Rx.Subject(); 

subject.subscribe(
  data =&amp;gt; console.log(`1: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;1: completed&amp;quot;)
);

subject.next(&amp;quot;AAA&amp;quot;) // 1: AAA

subject.subscribe(
  data =&amp;gt; console.log(`2: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;2: completed&amp;quot;)
);

subject.next(&amp;quot;BBB&amp;quot;); 

subject.complete(); 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1: AAA
1: BBB
2: BBB
1: completed
2: completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;asyncsubject&#34;&gt;AsyncSubject&lt;/h3&gt;

&lt;p&gt;complete時に最後にemitされた値だけをemitする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const subject = new Rx.AsyncSubject();

subject.subscribe(
  data =&amp;gt; console.log(`1: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;1: completed&amp;quot;)
);

subject.next(&amp;quot;AAA&amp;quot;); 
subject.next(&amp;quot;BBB&amp;quot;);

subject.complete();

subject.subscribe(
  data =&amp;gt; console.log(`2: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;2: completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1: BBB
1: completed
2: BBB
2: completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;behaviorsubject&#34;&gt;BehaviorSubject&lt;/h3&gt;

&lt;p&gt;Subscribeしたとき、最近のアイテムをemitする。あとはSubjectと同じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const subject = new Rx.BehaviorSubject(&amp;quot;ZZZ&amp;quot;)

subject.subscribe(
  data =&amp;gt; console.log(`1: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;1: completed&amp;quot;)
);

subject.next(&amp;quot;AAA&amp;quot;);
subject.next(&amp;quot;BBB&amp;quot;);

subject.subscribe(
  data =&amp;gt; console.log(`2: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;2: completed&amp;quot;)
);

subject.next(&amp;quot;CCC&amp;quot;); 

subject.complete(); 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1: ZZZ
1: AAA
1: BBB
2: BBB
1: CCC
2: CCC
1: completed
2: completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;replaysubject&#34;&gt;ReplaySubject&lt;/h3&gt;

&lt;p&gt;いつSubscribeしてもbufferにある全てのアイテムをemitする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const subject = new Rx.ReplaySubject(2) // buffer size = 2

subject.subscribe(
  data =&amp;gt; console.log(`1: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;1: completed&amp;quot;)
);

subject.next(&amp;quot;AAA&amp;quot;);
subject.next(&amp;quot;BBB&amp;quot;);
subject.next(&amp;quot;CCC&amp;quot;);
subject.next(&amp;quot;DDD&amp;quot;);

subject.subscribe(
  data =&amp;gt; console.log(`2: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;2: completed&amp;quot;)
);

subject.complete(); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;buffer size = 2 なので2がSubscribeしたときにはAAAとBBBはもうない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1: AAA
1: BBB
1: CCC
1: DDD
2: CCC
2: DDD
1: completed
2: completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/wilfrem/tech-rxjs&#34;&gt;歌舞伎座tech発表資料 RxJSの中を追う&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ</title>
          <link>https://www.sambaiz.net/article/84/</link>
          <pubDate>Wed, 15 Mar 2017 23:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/84/</guid>
          <description>

&lt;h2 id=&#34;kpl-kinesis-producer-library-とは&#34;&gt;KPL(Kinesis Producer Library)とは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-kpl.html&#34;&gt;Developing Amazon Kinesis Streams Producers Using the Amazon Kinesis Producer Library - Amazon Kinesis Streams&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kinesisに送るとき、自動リトライしてくれたり、レコードをまとめてスループットを向上してくれたりするアプリケーション。Protobufを使っている。
普通に送るとどんなに小さくてもシャード*1000レコード/秒しか最大でPUTできないのを、KPLを使ってまとめることで増やすことができる。&lt;/p&gt;

&lt;h2 id=&#34;fluentdで送る&#34;&gt;fluentdで送る&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;で&lt;code&gt;kinesis_producer&lt;/code&gt;を指定するとKPLを使って送信する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;kinesis_producer&amp;gt;&lt;/code&gt;の中にKPLの設定を書くことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;kinesis_producer&amp;gt;
    record_max_buffered_time 10
&amp;lt;/kinesis_producer&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L239&#34;&gt;record_max_bufferd_time&lt;/a&gt;
はバッファされたレコードが送られるまでの最大時間(ms)。デフォルトは100ms。この時間が経つか、他のリミットに当たったらレコードは送られる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L30&#34;&gt;AggregationMaxCount&lt;/a&gt;: 一つのレコードにまとめる最大レコード数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L44&#34;&gt;AggregationMaxSize&lt;/a&gt;: まとめたレコードの最大バイト数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L54&#34;&gt;CollectionMaxCount&lt;/a&gt;: PutRecordsで送る最大アイテム数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L67&#34;&gt;CollectionMaxSize&lt;/a&gt;: PutRecordsで送るデータ量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CloudWatchに送る&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L158&#34;&gt;metrics_level&lt;/a&gt;はデフォルトでdetailedになっていて、
コンソールのメトリクスからstream名で検索すると
&lt;code&gt;KinesisProducerLibrary&lt;/code&gt;に&lt;code&gt;UserRecordsPerKinesisRecord&lt;/code&gt;や、&lt;code&gt;UserRecordsDataPut&lt;/code&gt;、&lt;code&gt;BufferingTime&lt;/code&gt;、&lt;code&gt;RequestTime&lt;/code&gt;などいろいろ表示される。&lt;/p&gt;

&lt;p&gt;とりあえず試しにこんな設定で送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match hoge.log&amp;gt;
  @type kinesis_producer
  region ap-northeast-1
  stream_name teststream
  include_time_key true

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lambdaで読む&#34;&gt;Lambdaで読む&lt;/h2&gt;

&lt;p&gt;まとめられたレコードを&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation&#34;&gt;kinesis-aggregation&lt;/a&gt;で分解して読む。
今回は&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation/tree/master/node&#34;&gt;Node.js&lt;/a&gt;でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save aws-kinesis-agg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意する必要があるのは&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation/issues/16&#34;&gt;ドキュメントの情報が古く&lt;/a&gt;て、
関数の引数が足りないこと。第二引数のcomputeChecksumsが抜けているので気付かないと一つずつずれていくことになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;use strict&#39;;

const agg = require(&#39;aws-kinesis-agg&#39;);

exports.handler = (event, context, callback) =&amp;gt; {
    Promise.all(
        event.Records.map(
            (record) =&amp;gt; deaggregate(record)
        )
    ).then(
        (records) =&amp;gt; {
            // LambdaのNode.jsはまだ4.3なのでSpread operatorが使えない・・・
            // const message = `${[].concat(...records).length} came in`; 
            let sumCount = 0;
            records.forEach((r) =&amp;gt; sumCount += r.length);
            const message = `${records.length} aggregated records and ${sumCount} records come in`; 
            console.log(message);
            callback(null, message);
        },
        (err) =&amp;gt; callback(err)
    );
};

function deaggregate(record){
    return new Promise((resolve, reject) =&amp;gt; {
        agg.deaggregateSync(record.kinesis, true, (err, userRecords) =&amp;gt; {
            if (err) {
                reject(err);
            } else {
                resolve(userRecords);
            }
        });
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;175レコードが10レコードにまとめられた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10 aggregated records and 175 records come in
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/high-throughput-messaging-system-with-kinesis-kpl-fluentd-lambda/&#34;&gt;Kinesis Producer Library(KPL)とfluentdとLambdaを連携してKinesisのスループットを上げる ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>C#のdelegateとevent</title>
          <link>https://www.sambaiz.net/article/83/</link>
          <pubDate>Sun, 12 Mar 2017 21:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/83/</guid>
          <description>

&lt;h2 id=&#34;delegate-https-msdn-microsoft-com-ja-jp-library-900fyy8e-aspx&#34;&gt;&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/900fyy8e.aspx&#34;&gt;delegate&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;カプセル化するためのdelegate(移譲)メソッドに使う型。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Converter{

	private static double defaultConvert(double num){
		return num;
	}

	public delegate double Convert(double num);
	public Convert convert = defaultConvert;

	public double run(double num){
		return convert (num);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;匿名メソッドやラムダ式を渡すこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var conv = new Converter ();

print (conv.run (2)); // 2

// 匿名メソッドの例
conv.convert = delegate(double input)
{
    return input + 1;
};
print (conv.run (2)); // 2 + 1 = 3

// ラムダ式の例
conv.convert = s =&amp;gt; s * s;
print (conv.run(2)); // 2 * 2 = 4
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;event-https-msdn-microsoft-com-ja-jp-library-8627sbea-aspx&#34;&gt;&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/8627sbea.aspx&#34;&gt;event&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;宣言元でしか呼べないマルチキャストデリゲート。&lt;code&gt;+=&lt;/code&gt;でsubscribeして&lt;code&gt;-=&lt;/code&gt;で解除する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public delegate void RunEventHandler(double num);
public event RunEventHandler RunEvent;

public double run(double num){
    if (RunEvent != null) {
        RunEvent (num);
    }
    return convert (num);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;subscribeしたものは全て呼ばれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void runHook(double num){
    print(&amp;quot;b: &amp;quot; +  num);
}

var conv = new Converter ();
conv.RunEvent += s =&amp;gt; print (&amp;quot;a: &amp;quot; +  s); // Subscribe a
conv.run (2); // a: 2

conv.RunEvent += runHook; // Subscribe b
conv.run (3); // a: 3, b: 3

conv.RunEvent -= runHook; // Unsubscribe b
conv.run (4); // a: 4

// error
// conv.RunEvent (); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.NET Frameworkのクラスライブラリの全てのイベントでは
&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/db0etb8x.aspx&#34;&gt;EventHandler&lt;TEventArgs&gt;&lt;/a&gt;を使っていて、
ユーザー定義のコードでもこのパターンを使うのが&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/w369ty8x.aspx&#34;&gt;推奨されている&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public delegate void EventHandler&amp;lt;TEventArgs&amp;gt;(
	object sender,
	TEventArgs e
)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのMaterial</title>
          <link>https://www.sambaiz.net/article/82/</link>
          <pubDate>Sat, 11 Mar 2017 20:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/82/</guid>
          <description>

&lt;h2 id=&#34;materialとshaderとtexture-https-docs-unity3d-com-550-documentation-manual-shaders-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/Shaders.html&#34;&gt;MaterialとShaderとTexture&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Materialは表面がどのようにレダリングされるかを定義するもの。
Shaderを指定し、Textureなどのパラメーターを設定する。&lt;/p&gt;

&lt;p&gt;Shaderは光と、Materialの設定から、ピクセルの色を計算するスクリプト。
大体&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/shader-StandardShader.html&#34;&gt;Standard Shader&lt;/a&gt;
で事足りるらしい。&lt;/p&gt;

&lt;p&gt;Textureはビットマップイメージ。色(Albedo)だけではなく、反射率や粗さなど、いろんな要素に使える。&lt;/p&gt;

&lt;h2 id=&#34;standard-shader&#34;&gt;Standard Shader&lt;/h2&gt;

&lt;h3 id=&#34;rendering-mode-https-docs-unity3d-com-manual-standardshadermaterialparameterrenderingmode-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/Manual/StandardShaderMaterialParameterRenderingMode.html&#34;&gt;Rendering Mode&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Albedoは(255, 255, 255, 255)で、テクスチャにはDefault Particleを指定している。
透明度はテクスチャのアルファチャンネルとAlbedoのアルファ値に基づく。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-defaultparticle.png&#34; alt=&#34;Default Particle&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Opaque: デフォルト。すべて不透明。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-opaque.png&#34; alt=&#34;Opaque&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CutOut: 閾値を境に、完全に透明か、不透明になる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Alpha Cutoffを0.1にした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-cutout.png&#34; alt=&#34;CutOut&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Transparent: 透明度が適用される。現実世界の透明なマテリアルのように、反射のハイライトは完全に表示される。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-transparent.png&#34; alt=&#34;Transparent&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fade: ハイライトにも透明度を適用する。フェードイン/アウトしたいときに使う。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-fade.png&#34; alt=&#34;Fade&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;metallic&#34;&gt;Metallic&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/StandardShaderMaterialCharts.html&#34;&gt;マテリアルチャート&lt;/a&gt;をもとにAlbedoとMetallicとSmoothnessを設定する。&lt;/p&gt;

&lt;p&gt;これは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Albedo: (255, 255, 255, 255)&lt;/li&gt;
&lt;li&gt;Metallic: 1&lt;/li&gt;
&lt;li&gt;Smoothness: 0.68&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を設定している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-metal.png&#34; alt=&#34;Metallic&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのUI</title>
          <link>https://www.sambaiz.net/article/81/</link>
          <pubDate>Wed, 08 Mar 2017 16:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/81/</guid>
          <description>

&lt;h2 id=&#34;canvas-https-docs-unity3d-com-ja-540-scriptreference-canvas-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/540/ScriptReference/Canvas.html&#34;&gt;Canvas&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;UI要素を配置するための領域。&lt;/p&gt;

&lt;h3 id=&#34;rendermode-https-docs-unity3d-com-jp-540-manual-uicanvas-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/UICanvas.html&#34;&gt;renderMode&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Overlay: スクリーンに対してオーバーレイするように表示&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Camera: Cameraから指定した距離(planeDistance)離れた前方に表示&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;World Space 他のオブジェクトと同じように表示&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;canvas-scaler-https-docs-unity3d-com-jp-540-manual-script-canvasscaler-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/script-CanvasScaler.html&#34;&gt;Canvas Scaler&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;UI Scale Mode (World Space以外)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Constant Pixel Size: 画面サイズに関わらず同じピクセル数にする&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Scale With Screen Size: 画面サイズでスケールさせる&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Constant Physical Size 解像度や画面サイズによらず物理的に同じサイズにする&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dynami Pixels Per Unit (World Spaceのみ): Textなどの動的に生成されたビットマップの解像度&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1と3でそれぞれこんな感じになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/81-ppu1.png&#34; alt=&#34;Dynamic Pixels Per Unitが1のとき&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/81-ppu3.png&#34; alt=&#34;Dynamic Pixels Per Unitが3のとき&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;autolayout-https-docs-unity3d-com-ja-540-manual-comp-uiautolayout-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/comp-UIAutoLayout.html&#34;&gt;AutoLayout&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/script-VerticalLayoutGroup.html&#34;&gt;Vertical Layout Group&lt;/a&gt;や
&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/script-GridLayoutGroup.html&#34;&gt;Grid Layout Group&lt;/a&gt;
など。これらのComponentを追加すると子要素のTransform(の一部)が自動で設定される。&lt;/p&gt;

&lt;h3 id=&#34;content-size-fitter-https-docs-unity3d-com-ja-540-manual-script-contentsizefitter-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/script-ContentSizeFitter.html&#34;&gt;Content Size Fitter&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Layout Component要素に合うように自動で調整される。&lt;/p&gt;

&lt;h2 id=&#34;レイアウトを作る-https-docs-unity3d-com-jp-540-manual-uibasiclayout-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/UIBasicLayout.html&#34;&gt;レイアウトを作る&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;RectTool(ツールバーボタンの一番右の四角いやつ)を選択して、Pivot, Localにするとよい。
Canvasにいろいろ置いていって、Anchorを選んでRect Transformを設定していく。
あとはPrefabにしてInstantiateするなりして表示する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine.UI;

public GameObject dialogWindow;
var obj = Instantiate(obj, new Vector3(0, 0, 200), Quaternion.identity);

var hogeText = obj.transform.Find(&amp;quot;panel/hoge&amp;quot;).gameObject.GetComponent&amp;lt;Text&amp;gt;();
hogeText.text = &amp;quot;fuga&amp;quot;;

var fugaButton = obj.transform.Find(&amp;quot;panel/fuga&amp;quot;).gameObject.GetComponent&amp;lt;Button&amp;gt;();
fugaButton.onClick.AddListener (() =&amp;gt; {
    Debug.Log (&amp;quot;onClick&amp;quot;);
});
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのTransform</title>
          <link>https://www.sambaiz.net/article/80/</link>
          <pubDate>Tue, 07 Mar 2017 02:11:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/80/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/current/ScriptReference/Transform.html&#34;&gt;https://docs.unity3d.com/jp/current/ScriptReference/Transform.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトの位置、スケール、回転を保持する。親子関係を持つ。&lt;/p&gt;

&lt;h2 id=&#34;position&#34;&gt;Position&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-position.html&#34;&gt;position&lt;/a&gt;がワールド空間の、
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-localPosition.html&#34;&gt;localPosition&lt;/a&gt;
が親から見た相対的なローカル空間の位置。localPositionの1unitはscaleに依存する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.position = new Vector3(0, 0, 0);
transform.localPosition = new Vector3(0, 0, 0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;徐々に移動するには&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.Translate.html&#34;&gt;Translate()&lt;/a&gt;を使う。
最後の引数はデフォルトで&lt;code&gt;Space.Self&lt;/code&gt;になっていて、&lt;code&gt;Space.World&lt;/code&gt;を指定するとワールド座標を基準にする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Time-deltaTime.html&#34;&gt;Time.deltaTime&lt;/a&gt;は最後のフレームを完了するのにかかった秒数。
なのでフレームレートにかかわらず同じ速度で移動させることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.Translate(0, Time.deltaTime, 0, Space.World);
transform.Translate(Vector3.up * Time.deltaTime, Space.World); // 軸に沿って移動
transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform); // 最後の引数のローカル座標を基準にする
transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;scale&#34;&gt;Scale&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-localScale.html&#34;&gt;localScale&lt;/a&gt;
はローカル空間のスケール。ワールド空間のScaleはない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.localScale = new Vector3(0.1f, 1f, 1f);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rotation&#34;&gt;Rotation&lt;/h2&gt;

&lt;p&gt;ワールド空間の
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-rotation.html&#34;&gt;rotation&lt;/a&gt;と
ローカル空間の
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-localRotation.html&#34;&gt;localRoation&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Unityは&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Quaternion.html&#34;&gt;Quarternion&lt;/a&gt;(四元数)で回転を持っている。
実際はQuarternionそのものを自分で計算することはなく、
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Quaternion.LookRotation.html&#34;&gt;Quaternion.LookRotation()&lt;/a&gt;や
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Quaternion.Euler.html&#34;&gt;Quaternion.Euler()&lt;/a&gt;などを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Vector3 relativePos;
transform.rotation = Quaternion.LookRotation(relativePos); // そのPointを向くように回転
transform.localRotation = Quaternion.Euler(0, 30, 0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Transformを向くように回転する場合は
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.LookAt.html&#34;&gt;LookAt()&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Transform target;
transform.LookAt(target);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;徐々に回転させるには&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.Rotate.html&#34;&gt;Rotate()&lt;/a&gt;を使う。
最後の引数はデフォルトで&lt;code&gt;Space.Self&lt;/code&gt;で、&lt;code&gt;Space.World&lt;/code&gt;を指定すると回転の軸がワールドの軸になる。指定するのは角度。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.Rotate(0, Time.deltaTime, 0, Space.World);
transform.Rotate(Vector3.up, Time.deltaTime, Space.World);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ワールド座標のあるPointを中心として回転させる場合は
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.RotateAround.html&#34;&gt;RotateAround()&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.RotateAround(Vector3.zero, Vector3.up, 20 * Time.deltaTime);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;parent-https-docs-unity3d-com-jp-current-scriptreference-transform-parent-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/current/ScriptReference/Transform-parent.html&#34;&gt;parent&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;親を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var fuga = GameObject.CreatePrimitive (PrimitiveType.Cube);
fuga.transform.parent = hoge.transform;
fuga.transform.parent = null; // detach
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;find-https-docs-unity3d-com-jp-540-scriptreference-transform-find-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.Find.html&#34;&gt;Find&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;子の名前で検索する。
FindChildもあるけどドキュメントに書いてないので使わない方がよさそう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var child = transform.Find(&amp;quot;hoge/fuga&amp;quot;)
if(child != null){
    child.gameObject
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Moment.jsでNode.jsのDateを任意のフォーマットの文字列にする</title>
          <link>https://www.sambaiz.net/article/79/</link>
          <pubDate>Mon, 06 Mar 2017 20:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/79/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://momentjs.com/&#34;&gt;Moment.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;相対時間(&lt;code&gt;5 years ago&lt;/code&gt;)を出したり、日付の計算(&lt;code&gt;add(3, &#39;days&#39;)&lt;/code&gt;)もできる便利なライブラリ。
ブラウザでも使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install moment
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const moment = require(&#39;moment&#39;)
const jst = +9
let now = moment().utcOffset(jst).format(&amp;quot;YYYY-MM-DD HH:mm:ss.SSSZ&amp;quot;);
console.log(now);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ TZ=Africa/Ouagadougou node main.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mutableなのでadd()などの操作で元の値が変わってしまうのに注意。
変わると困る場合clone()する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let now2 = moment();
let now3 = now2.clone();
console.log(now2);
console.log(now2.add(1, &#39;days&#39;));
console.log(now2);
console.log(now3);
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityと.NETとMono</title>
          <link>https://www.sambaiz.net/article/78/</link>
          <pubDate>Sun, 05 Mar 2017 18:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/78/</guid>
          <description>

&lt;p&gt;.NETとかよくわからなかったのでまとめてみた。&lt;/p&gt;

&lt;h2 id=&#34;net-framework&#34;&gt;.NET Framework&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/.NET_Framework&#34;&gt;.NET Framework - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Microsoftが開発したアプリケーション開発、実行環境。&lt;/p&gt;

&lt;p&gt;各言語のコンパイラによって言語、環境によらない共通の中間言語(CIL, Common Intermediate Language)バイナリ(exeやdll)に変換し、
実行時に共通言語基盤(CLI, Common Language Infrastructure)の仮想実行システム(VES)が環境依存の機械語を動的に生成(JIT, Just in time)する。
CLIの仕様はECMAで標準化されていて、Microsoftが実装したCLIが共通言語ランタイム(CLR)。Windowsでしか動かない。&lt;/p&gt;

&lt;h2 id=&#34;net-core&#34;&gt;.NET Core&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/magazine/mt694084.aspx&#34;&gt;.NET Core - .NET Core による .NET のクロスプラットフォームへの移行&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Microsoft/dotnet&#34;&gt;Microsoft/dotnet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;オープンソースで、クロスプラットフォームに対応した.NET。CoreCLRはWindowsだけではなくMacやLinuxでも動く。
.NET Frameworkと共通のAPIもあるが、GUIまわりでどちらかにしかないAPIが存在する。&lt;/p&gt;

&lt;h2 id=&#34;mono-http-www-mono-project-com&#34;&gt;&lt;a href=&#34;http://www.mono-project.com/&#34;&gt;Mono&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;オープンソースで、クロスプラットフォームな.NET Framework互換ソフトウェア。C#のコンパイラとCLIが実装されている。
Unityはこれを使っているが、バージョンが古くて使えないライブラリがある。&lt;/p&gt;

&lt;h2 id=&#34;net-coreでhello-world&#34;&gt;.NET CoreでHello World&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/net/core#macos&#34;&gt;インストール手順&lt;/a&gt;に沿って
&lt;code&gt;dotnet&lt;/code&gt;コマンドを使えるようにする。&lt;/p&gt;

&lt;p&gt;Hello Worldまで。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ dotnet console -o hwapp
$ cd hwapp
$ ls
Program.cs	hwapp.csproj

$ dotnet restore
$ ls
Program.cs	hwapp.csproj	obj

$ ls obj
hwapp.csproj.nuget.g.props	project.assets.json
hwapp.csproj.nuget.g.targets

# dotnet build
$ dotnet run
Hello World!

$ dotnet bin/Debug/netcoreapp1.1/hwapp.dll 
Hello World!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;特に.NET CoreにしかないAPIも使っていないのでmono(.NET Framework)ででも実行できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Program.cs 
using System;

namespace hwapp
{
    class Program
    {
        static void Main(string[] args)
        {
            Console.WriteLine(&amp;quot;Hello World!&amp;quot;);
        }
    }
}

$ mono bin/Debug/netcoreapp1.1/hwapp.dll 
Hello World!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/AimingStudy/unitynet&#34;&gt;Unityと.NET&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Elasticsearchで期間ごとの集計値を出す</title>
          <link>https://www.sambaiz.net/article/77/</link>
          <pubDate>Sun, 05 Mar 2017 01:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/77/</guid>
          <description>

&lt;p&gt;Bucket(SQLでいうGROUP BY)にまとめて(Bucket Aggreagtion)、集計(Metric Aggregation)する。&lt;/p&gt;

&lt;p&gt;使うデータは&lt;a href=&#34;https://www.sambaiz.net/article/76/&#34;&gt;作ったツール&lt;/a&gt;で生成したこんなの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bucket-aggregations-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-bucket-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket.html&#34;&gt;Bucket Aggregations&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;date-range-aggregation-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-bucket-daterange-aggregation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket-daterange-aggregation.html&#34;&gt;Date Range Aggregation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;date_range&lt;/code&gt;で期間のBucketを作る。この例だと今から10分前の00秒~今の分の00秒まで。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d&#39;
{
    &amp;quot;aggs&amp;quot;: {
        &amp;quot;range_10minutes&amp;quot;: {
            &amp;quot;date_range&amp;quot;: {
                &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;,
                &amp;quot;format&amp;quot;: &amp;quot;HH-mm-ssZ&amp;quot;,
                &amp;quot;ranges&amp;quot;: [                               
                    { &amp;quot;to&amp;quot;: &amp;quot;now/m&amp;quot;, &amp;quot;from&amp;quot;: &amp;quot;now-10m/m&amp;quot; }
                ]
            }
        }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;range_10minutes&amp;quot;: {
    &amp;quot;buckets&amp;quot;: [
      {
        &amp;quot;key&amp;quot;: &amp;quot;15-17+0000-15-27+0000&amp;quot;,
        &amp;quot;from&amp;quot;: 1488640620000,
        &amp;quot;from_as_string&amp;quot;: &amp;quot;15-17+0000&amp;quot;,
        &amp;quot;to&amp;quot;: 1488641220000,
        &amp;quot;to_as_string&amp;quot;: &amp;quot;15-27+0000&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 600
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;date-histogram-aggregation-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-bucket-datehistogram-aggregation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket-datehistogram-aggregation.html&#34;&gt;Date Histogram Aggregation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;date_histogram&lt;/code&gt;で日付の間隔でBucketを作る。この例だと1分ごとにBucketが作られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d&#39;
{
    &amp;quot;aggs&amp;quot;: {   
        &amp;quot;histogram_1minute&amp;quot;: {                  
            &amp;quot;date_histogram&amp;quot;: {
                &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;,
                &amp;quot;interval&amp;quot;: &amp;quot;1m&amp;quot;
            }
        }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;histogram_1minute&amp;quot;: {
    &amp;quot;buckets&amp;quot;: [
      ...
      {
        &amp;quot;key_as_string&amp;quot;: &amp;quot;1488640560&amp;quot;,
        &amp;quot;key&amp;quot;: 1488640560000,
        &amp;quot;doc_count&amp;quot;: 60
      },
      {
        &amp;quot;key_as_string&amp;quot;: &amp;quot;1488640620&amp;quot;,
        &amp;quot;key&amp;quot;: 1488640620000,
        &amp;quot;doc_count&amp;quot;: 31
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;terms-aggregation-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-bucket-terms-aggregation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket-terms-aggregation.html&#34;&gt;Terms Aggregation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;terms&lt;/code&gt;で値ごとにBucketを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d&#39;
{
    &amp;quot;aggs&amp;quot;: {   
        &amp;quot;os_names&amp;quot;:{                  
            &amp;quot;terms&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;os_name&amp;quot; }
        }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;os_names&amp;quot;: {
    &amp;quot;doc_count_error_upper_bound&amp;quot;: 0,
    &amp;quot;sum_other_doc_count&amp;quot;: 0,
    &amp;quot;buckets&amp;quot;: [
      {
        &amp;quot;key&amp;quot;: &amp;quot;windows&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 458
      },
      {
        &amp;quot;key&amp;quot;: &amp;quot;android&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 456
      },
      {
        &amp;quot;key&amp;quot;: &amp;quot;mac&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 455
      },
      {
        &amp;quot;key&amp;quot;: &amp;quot;linux&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 447
      },
      {
        &amp;quot;key&amp;quot;: &amp;quot;ios&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 404
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;metrics-aggregations-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-metrics-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-metrics.html&#34;&gt;Metrics Aggregations&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;avg-aggregation-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-metrics-avg-aggregation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-metrics-avg-aggregation.html&#34;&gt;Avg Aggregation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;avg&lt;/code&gt;で平均を出す。&lt;code&gt;max&lt;/code&gt;、&lt;code&gt;min&lt;/code&gt;、&lt;code&gt;sum&lt;/code&gt;も同様。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d &#39;
{
    &amp;quot;aggs&amp;quot;: {      
        &amp;quot;avg_score&amp;quot;: { &amp;quot;avg&amp;quot;: { &amp;quot;field&amp;quot; : &amp;quot;score&amp;quot; } }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;avg_score&amp;quot;: {
    &amp;quot;value&amp;quot;: 50.34639639639639
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集計する&#34;&gt;集計する&lt;/h2&gt;

&lt;p&gt;aggsを組み合わせて集計する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d&#39;
{             
    &amp;quot;aggs&amp;quot;: {
        &amp;quot;range&amp;quot;: {
            &amp;quot;date_range&amp;quot;: {
                &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;,
                &amp;quot;format&amp;quot;: &amp;quot;HH-mm-ssZ&amp;quot;,
                &amp;quot;ranges&amp;quot;: [                               
                    { &amp;quot;to&amp;quot;: &amp;quot;now/m&amp;quot;, &amp;quot;from&amp;quot;: &amp;quot;now-10m/m&amp;quot; }
                ]
            },
            &amp;quot;aggs&amp;quot;: {
                &amp;quot;histogram&amp;quot;: {                  
                    &amp;quot;date_histogram&amp;quot;: {
                        &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;,
                        &amp;quot;interval&amp;quot;: &amp;quot;1m&amp;quot;
                    },
                    &amp;quot;aggs&amp;quot;: {
                        &amp;quot;os_names&amp;quot;:{
                            &amp;quot;terms&amp;quot;: { &amp;quot;field&amp;quot; : &amp;quot;os_name&amp;quot; },
                            &amp;quot;aggs&amp;quot;: {
                                &amp;quot;avg_score&amp;quot;: { &amp;quot;avg&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;score&amp;quot; }}
                            }
                        }
                    }
                }
            }
        }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;range&amp;quot;: {
    &amp;quot;buckets&amp;quot;: [
      {
        &amp;quot;key&amp;quot;: &amp;quot;15-55-00+0000-16-05-00+0000&amp;quot;,
        &amp;quot;from&amp;quot;: 1488642900000,
        &amp;quot;from_as_string&amp;quot;: &amp;quot;15-55-00+0000&amp;quot;,
        &amp;quot;to&amp;quot;: 1488643500000,
        &amp;quot;to_as_string&amp;quot;: &amp;quot;16-05-00+0000&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 25,
        &amp;quot;histogram&amp;quot;: {
          &amp;quot;buckets&amp;quot;: [
            {
              &amp;quot;key_as_string&amp;quot;: &amp;quot;1488643440&amp;quot;,
              &amp;quot;key&amp;quot;: 1488643440000,
              &amp;quot;doc_count&amp;quot;: 25,
              &amp;quot;os_names&amp;quot;: {
                &amp;quot;doc_count_error_upper_bound&amp;quot;: 0,
                &amp;quot;sum_other_doc_count&amp;quot;: 0,
                &amp;quot;buckets&amp;quot;: [
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;linux&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 9,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 41.44444444444444
                    }
                  },
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;ios&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 5,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 63.6
                    }
                  },
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;mac&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 5,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 53.6
                    }
                  },
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;android&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 4,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 41.25
                    }
                  },
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;windows&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 2,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 67
                    }
                  }
                ]
              }
            }
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>一定間隔でjsonデータを作って送り続けるCLIツールを作った</title>
          <link>https://www.sambaiz.net/article/76/</link>
          <pubDate>Sat, 04 Mar 2017 23:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/76/</guid>
          <description>&lt;p&gt;Elasticsearchにリアルタイムなテストデータを投入するために、一定間隔でjsonを作って送り続けるCLIツールを作った。Go製。
&lt;a href=&#34;https://github.com/urfave/cli&#34;&gt;urfave/cli&lt;/a&gt;を使った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/sendjson&#34;&gt;sambaiz/sendjson&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;こんなindexにデータを入れてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;http://localhost:9200/hoge&#39; -d&#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;test_type&amp;quot;: { 
      &amp;quot;_all&amp;quot;:       { &amp;quot;enabled&amp;quot;: false  }, 
      &amp;quot;properties&amp;quot;: { 
        &amp;quot;os_name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; },
        &amp;quot;score&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;byte&amp;quot; },
        &amp;quot;@timestamp&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;epoch_second&amp;quot; }
      }
    }
  }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じでキーに対してtypeと入る値を定義するとそれっぽいデータができて送られていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go install github.com/sambaiz/sendjson
$ sendjson --interval 0.5s --duration 10s --url http://localhost:9200/hoge/test_type &#39;
{
    &amp;quot;os_name&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;or&amp;quot;: [&amp;quot;windows&amp;quot;, &amp;quot;mac&amp;quot;, &amp;quot;linux&amp;quot;, &amp;quot;ios&amp;quot;, &amp;quot;android&amp;quot;]},
    &amp;quot;score&amp;quot;:  {&amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;, &amp;quot;min&amp;quot;: 0, &amp;quot;max&amp;quot;: 100},
    &amp;quot;@timestamp&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;time&amp;quot;, &amp;quot;time_format&amp;quot;: &amp;quot;unix_epoch&amp;quot;}
}&#39;

{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82}
{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:9}
{&amp;quot;@timestamp&amp;quot;:1488635131,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:73}
{&amp;quot;@timestamp&amp;quot;:1488635131,&amp;quot;os_name&amp;quot;:&amp;quot;ios&amp;quot;,&amp;quot;score&amp;quot;:50}
{&amp;quot;@timestamp&amp;quot;:1488635132,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:69}
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと入っていることを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:9200/hoge/_search | jq
{
  &amp;quot;took&amp;quot;: 2,
  &amp;quot;timed_out&amp;quot;: false,
  &amp;quot;_shards&amp;quot;: {
    &amp;quot;total&amp;quot;: 5,
    &amp;quot;successful&amp;quot;: 5,
    &amp;quot;failed&amp;quot;: 0
  },
  &amp;quot;hits&amp;quot;: {
    &amp;quot;total&amp;quot;: 29,
    &amp;quot;max_score&amp;quot;: 1,
    &amp;quot;hits&amp;quot;: [
      {
        &amp;quot;_index&amp;quot;: &amp;quot;hoge&amp;quot;,
        &amp;quot;_type&amp;quot;: &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot;: &amp;quot;AVqZpCjjFTc9Q_rmmMn7&amp;quot;,
        &amp;quot;_score&amp;quot;: 1,
        &amp;quot;_source&amp;quot;: {
          &amp;quot;@timestamp&amp;quot;: 1488636356,
          &amp;quot;os_name&amp;quot;: &amp;quot;android&amp;quot;,
          &amp;quot;score&amp;quot;: 38
        }
      },
      {
        &amp;quot;_index&amp;quot;: &amp;quot;hoge&amp;quot;,
        &amp;quot;_type&amp;quot;: &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot;: &amp;quot;AVqZpE-kFTc9Q_rmmMoN&amp;quot;,
        &amp;quot;_score&amp;quot;: 1,
        &amp;quot;_source&amp;quot;: {
          &amp;quot;@timestamp&amp;quot;: 1488636366,
          &amp;quot;os_name&amp;quot;: &amp;quot;android&amp;quot;,
          &amp;quot;score&amp;quot;: 87
        }
      },
      ...
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>H2OでHTTPS-&gt;HTTPのリバースプロキシを立てる</title>
          <link>https://www.sambaiz.net/article/75/</link>
          <pubDate>Thu, 02 Mar 2017 20:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/75/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://qiita.com/cubicdaiya/items/235777dc401ec419b14e&#34;&gt;良くチューニングされたNginxと同じくらい速い&lt;/a&gt;と
評判のHTTP/2サーバー&lt;a href=&#34;https://h2o.examp1e.net/&#34;&gt;H2O&lt;/a&gt;でリバースプロキシを立ててみる。
HTTP/2だけではなく1.xにも対応しているので古い環境などでも大丈夫。&lt;/p&gt;

&lt;p&gt;設定は
&lt;a href=&#34;https://github.com/h2o/h2o/wiki/Reverse-Proxy&#34;&gt;Reverse Proxy&lt;/a&gt;と
&lt;a href=&#34;https://github.com/h2o/h2o/wiki/redirect-HTTP-to-HTTPS&#34;&gt;HTTP to HTTPS&lt;/a&gt;の
サンプルをもとにして書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hosts:
  &amp;quot;*&amp;quot;:
    listen:
      port: 443
      ssl:
        certificate-file: /etc/h2o/oreore.crt
        key-file:         /etc/h2o/server.key
    paths:
      &amp;quot;/&amp;quot;:
        proxy.reverse.url: http://127.0.0.1:3000/

access-log: /dev/stdout
error-log: /dev/stderr
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とりあえずオレオレ証明書で試してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa 2048 &amp;gt; server.key # private key
$ openssl req -new -key server.key &amp;gt; server.csr # certificate signing request 
$ openssl x509 -days 365000 -req -signkey server.key &amp;lt; server.csr &amp;gt; oreore.crt # oreore certificate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerで動かす。&lt;a href=&#34;https://github.com/lkwg82/h2o.docker&#34;&gt;lkwg82/h2o.docker&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vi h2o.conf
$ docker run -v $(pwd):/etc/h2o --net=host --name h2o --restart=always -itd lkwg82/h2o-http2-server
$ curl --insecure https://127.0.0.1 # -&amp;gt; :3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chromeでアクセスして、Developer ToolsのNetworkで右クリックでProtocolにチェックを入れてh2と表示されていたら
HTTP/2で通信している。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goroutineの数をworkerで抑制する</title>
          <link>https://www.sambaiz.net/article/74/</link>
          <pubDate>Mon, 27 Feb 2017 23:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/74/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/61/&#34;&gt;Goのnet/httpとKeep-Alive - sambaiz.net&lt;/a&gt;でやったように、
あるエンドポイントに連続してGoroutineでリクエストを投げると、リクエスト数を増やしたときにタイムアウトが頻発するようになった。&lt;/p&gt;

&lt;p&gt;まず、2000リクエストを投げてみた結果。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[RESULT] request: 2000, ok: 2000, ng: 0, time(ms) 138
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一応全部捌けてはいるけど、おおよそ同時にリクエストを送っているのにタイムアウト(100ms)時間を超えてしまっている。これをさらに3000に増やしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[RESULT] request: 3000, ok: 13, ng: 2987, time(ms) 372
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほぼ全滅してしまった・・・。時間もおかしいのでGoroutineでの処理に遅延が発生しているようだ。
そこで、都度Goroutineを生成してリクエストを投げるのではなく、
一定数のWorkerに処理させることで、同時に作られるGoroutineの数を抑制する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Req struct {
	Okch chan int
	Ngch chan int
}

func startWorker(ctx context.Context, num int) (requestch chan *Req) {

	requestch = make(chan *Req)

	for i := 0; i &amp;lt; num; i++ {
		go func() {
			for {
				select {
				case req := &amp;lt;-requestch:
					request(req.Okch, req.Ngch)
				case &amp;lt;-ctx.Done():
					return
				}
			}
		}()
	}

	return
}

func main(){
    ...
    ctx, cancel := context.WithCancel(context.Background())
	defer cancel()
	requestch := startWorker(ctx, 1000)

    requestch &amp;lt;- req
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果、すべてのリクエストをタイムアウトせずに送れるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[RESULT] request: 3000, ok: 3000, ng: 0, time(ms) 157
[RESULT] request: 5000, ok: 5000, ng: 0, time(ms) 239
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上のコードではWorkerを作るにあたって単純にWorkerの数分goroutineを生成して共通のチャネルに入ってきたものを読んで処理させているが、
以下の記事のようにDispatcherを用意してWorkerPool(chan chan Job)からWorkerのjobChannel(chan Job)を取り出して送る方法も紹介されていたので
これとも比較してみた。今回は入力するチャネルだけ分けて終了方法はStartで渡したcontextに一任しているので上の方法とさほど変わらず、むしろ冗長に見えるが、
実際はWorkerそれぞれがquitするチャネルなどを持っていて、独立して終了させることができるため、Workerの数を動的にコントロールしやすいのが特長だと思う。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://marcio.io/2015/07/handling-1-million-requests-per-minute-with-golang/&#34;&gt;Handling 1 Million Requests per Minute with Go  · marcio.io&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Dispatcher struct{
	Requestch chan *Req
	workerPool chan chan *Req
	workerNum int
}

func NewDispatcher(workerNum int) *Dispatcher{
	return &amp;amp;Dispatcher{
		Requestch: make(chan *Req),
		workerPool: make(chan chan *Req, workerNum),
		workerNum: workerNum,
	}
}


func (d *Dispatcher) Start(ctx context.Context) error{
	poolLength := len(d.workerPool)
	if poolLength != 0{
		return errors.New(&amp;quot;already started&amp;quot;)
	}
	for i := 0; i &amp;lt; d.workerNum; i++{
		startWorker(ctx, 1, d.workerPool)
	}

	go d.dispatch(ctx)

	return nil
}

func (d *Dispatcher) dispatch(ctx context.Context){
	for{
		select{
		case req := &amp;lt;- d.Requestch:
            // workerPoolからchanを取り出しreqを入れる
			worker := &amp;lt;- d.workerPool
			worker &amp;lt;- req
		case &amp;lt;-ctx.Done():
			return 
		}
	}
}

func startWorker(ctx context.Context, num int, workerPool chan chan *Req) {

	requestch := make(chan *Req)

	for i := 0; i &amp;lt; num; i++ {
		go func() {
			for {
                // workerPoolにchanを入れる(終わったらまだ戻る)
				workerPool &amp;lt;- requestch
				select {
				case req := &amp;lt;-requestch:
					request(req.Okch, req.Ngch)
				case &amp;lt;-ctx.Done():
					return
				}
			}
		}()
	}

	return
}

func main(){
    ...
    dispatcher := NewDispatcher(1000)
	if err := dispatcher.Start(ctx); err != nil{
		panic(err)
	}

    dispatcher.requestch &amp;lt;- req
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほとんど変わらず。WorkerPoolからチャネルを取り出す分、わずかに遅いかな。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[RESULT] request: 3000, ok: 3000, ng: 0, time(ms) 169
[RESULT] request: 5000, ok: 5000, ng: 0, time(ms) 246
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
          <link>https://www.sambaiz.net/article/73/</link>
          <pubDate>Sun, 26 Feb 2017 18:56:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/73/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;でKinesis Streamsに送り、Lambdaで読んでS3に保存する。
要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。&lt;/p&gt;

&lt;h2 id=&#34;fluentdで送る&#34;&gt;fluentdで送る&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-kinesis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;try_flush_interval&lt;/code&gt;と&lt;code&gt;queued_chunk_flush_interval&lt;/code&gt;はドキュメントには載っていないが、
以下のページによるとそれぞれqueueに次のchunkがないときとあるときのflushする間隔。
いずれもデフォルトは1だが、これを減らすことでもっと頻繁に吐き出されるようになるらしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sonots/fluentd-scr/blob/master/02_out_forward_buffered.md&#34;&gt;Fluentd の out_forward と BufferedOutput&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;あとシャードに振り分けるための&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis#partition_key&#34;&gt;partition_key&lt;/a&gt;
を指定できる。デフォルトはランダム。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type tail
  path /var/log/td-agent/hoge.log
  pos_file /etc/td-agent/log.pos
  tag hoge.log
  format json

  time_key timestamp
  # 2017-01-01T01:01:01+0900
  time_format %Y-%m-%dT%H:%M:%S%z
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type kinesis_streams
  region ap-northeast-1
  stream_name teststream
  include_time_key true

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;いくつか送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in `seq 1 1000`
do
  echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;, &amp;quot;timestamp&amp;quot;: &amp;quot;2017-01-01T01:01:01+0900&amp;quot;}&#39; &amp;gt;&amp;gt; /var/log/td-agent/hoge.log
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kinesisのシャードが足りないと詰まってしまうので注意。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/84/&#34;&gt;FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;lambdaで読む&#34;&gt;Lambdaで読む&lt;/h2&gt;

&lt;p&gt;Lambdaのトリガーの設定でKinesisを選ぶと、バッチサイズや開始位置を設定できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/73-lambda-kinesis.png&#34; alt=&#34;トリガーの設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;コードはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;use strict&#39;;

const zlib = require(&#39;zlib&#39;);
const aws = require(&#39;aws-sdk&#39;);
const s3 = new aws.S3({ apiVersion: &#39;2006-03-01&#39; });
const BUCKET_NAME = process.env.BUCKET_NAME; // 環境変数で設定する

exports.handler = (event, context, callback) =&amp;gt; {

    const data = event.Records.map((record) =&amp;gt; new Buffer(record.kinesis.data, &#39;base64&#39;).toString()).join(&amp;quot;\n&amp;quot;);
    const key = new Date().toISOString();
    
    putS3(key, data, true).then(
        (data) =&amp;gt; callback(null, `Successfully processed ${event.Records.length} records.`),
        (err) =&amp;gt; callback(err, null)
    );
};

function putS3(key, data, gzip){    
    return new Promise((resolve, reject) =&amp;gt; {
        
        const params = {
            Bucket: BUCKET_NAME,
            Key: key
        };

        if(gzip){
            params.Body = zlib.gzipSync(data);
            params.ContentEncoding = &amp;quot;gzip&amp;quot;;
        }else{
            params.Body = data;
        }
        
        s3.putObject(params, (err, data) =&amp;gt; {
            if (err) reject(err);
            else resolve(data);
        });
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;トリガーを有効にするとイベントが発火してS3に保存されるようになった。&lt;/p&gt;

&lt;p&gt;ただ、Kinesisをイベントトリガーにして都度出力すると、1ファイルのサイズが非常に小さくなってしまう。
なんとかして都度出力しないようにするか、あるいは時間トリガーで実行するか、いずれにしてもどこまで読んだか記録しておかなくちゃいけないのでちょっと面倒だ。バッファリングしてくれるFirehoseが早く日本にも来て欲しい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AWSのAssumeRole</title>
          <link>https://www.sambaiz.net/article/72/</link>
          <pubDate>Sat, 25 Feb 2017 20:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/72/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/id_credentials_temp.html&#34;&gt;AWS Security Token Service&lt;/a&gt;による、
RoleArn(&lt;code&gt;arn:aws:iam::&amp;lt;account id&amp;gt;:role/&amp;lt;role name&amp;gt;&lt;/code&gt;)から一時的なCredentialを取得する仕組み。
前もって発行したAPIキーとは違い、有効期限が存在するため続けて呼ぶ場合は失効する前に再発行する必要がある。&lt;/p&gt;

&lt;p&gt;ではRoleArnを知っていたら誰でも取得できるかというと、もちろんそうではなく、
ロールの信頼関係、&lt;code&gt;&amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;&lt;/code&gt;のPrincipalのところで信頼する対象を設定する。
例えば、&lt;code&gt;Service&lt;/code&gt;で&lt;code&gt;ec2.amazonaws.com&lt;/code&gt;を指定してEC2がAssumeRoleするのを許可したり、
&lt;code&gt;AWS&lt;/code&gt;で(他の)アカウントやユーザーを指定してそのAPIキーでこのRoleのCredentialを取得できるようにしたりといった感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Principal&amp;quot;: {
        &amp;quot;Service&amp;quot;: &amp;quot;ec2.amazonaws.com&amp;quot;
      },
      &amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EC2にロールを設定すると、実はそのロールについてAssumeRoleして自動でCredentialを取得している。
EC2にロールを設定するにはロールとは別に
&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html&#34;&gt;インスタンスプロファイルを作成&lt;/a&gt;
する必要があるが、コンソールでEC2のサービスロールを作ると同名のインスタンスプロファイルが自動で作成される。
さらに、AssumeRoleのServiceとして&lt;code&gt;ec2.amazonaws.com&lt;/code&gt;が追加されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://169.254.169.254/latest/meta-data/iam/info
{
  &amp;quot;Code&amp;quot; : &amp;quot;Success&amp;quot;,
  &amp;quot;LastUpdated&amp;quot; : &amp;quot;2017-02-25T10:56:33Z&amp;quot;,
  &amp;quot;InstanceProfileArn&amp;quot; : &amp;quot;arn:aws:iam::*****:instance-profile/assume_role_test&amp;quot;,
  &amp;quot;InstanceProfileId&amp;quot; : &amp;quot;*****&amp;quot;
}

$ curl http://169.254.169.254/latest/meta-data/iam/security-credentials/assume_role_test
{
  &amp;quot;Code&amp;quot; : &amp;quot;Success&amp;quot;,
  &amp;quot;LastUpdated&amp;quot; : &amp;quot;2017-02-25T10:56:23Z&amp;quot;,
  &amp;quot;Type&amp;quot; : &amp;quot;AWS-HMAC&amp;quot;,
  &amp;quot;AccessKeyId&amp;quot; : &amp;quot;*****&amp;quot;,
  &amp;quot;SecretAccessKey&amp;quot; : &amp;quot;*****&amp;quot;,
  &amp;quot;Token&amp;quot; : &amp;quot;*****&amp;quot;,
  &amp;quot;Expiration&amp;quot; : &amp;quot;2017-02-25T17:26:07Z&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/iam-role-and-assumerole/&#34;&gt;IAMロール徹底理解 〜 AssumeRoleの正体 ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/id_credentials_temp_use-resources.html&#34;&gt;一時的なセキュリティ認証情報を使用して AWS リソースへのアクセスをリクエストする - AWS Identity and Access Management&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ElasticsearchのCircuit Breaker</title>
          <link>https://www.sambaiz.net/article/71/</link>
          <pubDate>Fri, 24 Feb 2017 21:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/71/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/52/&#34;&gt;ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。
表示されたエラーはこういうの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;root_cause&amp;quot;: [
    {
        &amp;quot;type&amp;quot;: &amp;quot;circuit_breaking_exception&amp;quot;,
        &amp;quot;reason&amp;quot;: &amp;quot;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;quot;,
        &amp;quot;bytes_wanted&amp;quot;: 10464007168,
        &amp;quot;bytes_limit&amp;quot;: 8998512230
    }
],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは1リクエストの集計などで使うメモリ量がしきい値をこえて
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/circuit-breaker.html&#34;&gt;Circuit Breaker&lt;/a&gt;が発動したということ。
メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。&lt;/p&gt;

&lt;p&gt;情報は&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/cluster-nodes-stats.html&#34;&gt;stats&lt;/a&gt;のapiでも取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request
{
  &amp;quot;limit_size_in_bytes&amp;quot;: 8998512230,
  &amp;quot;limit_size&amp;quot;: &amp;quot;8.3gb&amp;quot;,
  &amp;quot;estimated_size_in_bytes&amp;quot;: 10348347504,
  &amp;quot;estimated_size&amp;quot;: &amp;quot;9.6gb&amp;quot;,
  &amp;quot;overhead&amp;quot;: 1,
  &amp;quot;tripped&amp;quot;: 470
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回ひっかかったのは&lt;code&gt;indices.breaker.request.limit&lt;/code&gt;。デフォルトではJVMのヒープメモリの60%になっているが、
これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{
    &amp;quot;persistent&amp;quot; : {
        &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;,
        &amp;quot;indices.breaker.total.limit&amp;quot;: &amp;quot;80%&amp;quot;
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{
    &amp;quot;persistent&amp;quot; : {
        &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;,
        &amp;quot;indices.breaker.total.limit&amp;quot;: &amp;quot;80%&amp;quot;
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必要なメモリ量を上回ったのでひとまずは返せるようになった。
これは一時しのぎで、定常的に大量にメモリが必要なリクエストを処理する必要があるなら、そもそもメモリが足りないので増やさなければならない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request
{
  &amp;quot;limit_size_in_bytes&amp;quot;: 11998016307,
  &amp;quot;limit_size&amp;quot;: &amp;quot;11.1gb&amp;quot;,
  &amp;quot;estimated_size_in_bytes&amp;quot;: 10473078896,
  &amp;quot;estimated_size&amp;quot;: &amp;quot;9.7gb&amp;quot;,
  &amp;quot;overhead&amp;quot;: 1,
  &amp;quot;tripped&amp;quot;: 470
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>crontabのメモ</title>
          <link>https://www.sambaiz.net/article/70/</link>
          <pubDate>Fri, 24 Feb 2017 21:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/70/</guid>
          <description>

&lt;p&gt;各ユーザーごとのcron設定。&lt;code&gt;crontab -e&lt;/code&gt;でも編集できるけど、間違えて&lt;code&gt;-r&lt;/code&gt;にすると全部消えてしまうのでこういう風に一旦取り出してから編集すると安全。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ crontab -l &amp;gt; ~/crontab
$ echo &amp;quot;*/1 * * * * /hoge/fuga.sh&amp;quot; &amp;gt;&amp;gt; ~/crontab
$ crontab &amp;lt; ~/crontab
$ crontab -l
*/1 * * * * /hoge/fuga.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://vividcode.hatenablog.com/entry/man-cron-and-crontab&#34;&gt;cron 設定ファイル (crontab ファイル) の置き場所と書式について - ひだまりソケットは壊れない&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Cookieのメモ</title>
          <link>https://www.sambaiz.net/article/69/</link>
          <pubDate>Wed, 22 Feb 2017 20:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/69/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies&#34;&gt;https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;レスポンスに&lt;code&gt;Set-Cookie&lt;/code&gt;ヘッダーが含まれていればブラウザはcookieに保存する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;HTTP/1.0 200 OK
Content-type: text/html
Set-Cookie: yummy_cookie=choco
Set-Cookie: tasty_cookie=strawberry
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リクエスト時には&lt;code&gt;Cookie&lt;/code&gt;ヘッダーにcookieを入れて送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GET /sample_page.html HTTP/1.1
Host: www.example.org
Cookie: yummy_cookie=choco; tasty_cookie=strawberry
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CookieにExpire(ある期間まで有効)またはMax-Age(特定の期間の間有効)を設定するとPermanent cookieとなる。
いずれも設定しなかった場合Session cookieとなり、ブラウザを閉じると削除されることになっているが、
ブラウザのセッション復元機能が有効になっていれば永続化される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Secureを付けるとHTTPSでのみ送られる。
また、HttpOnlyはjsから&lt;code&gt;document.cookie&lt;/code&gt;などでアクセスすることができなくなる。
サイトにXSSの脆弱性があるとき、cookieが盗まれてしまうのを防ぐことができるので問題なければ設定するべき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Domainを指定するとそのドメインとサブドメインへのリクエストのときに送られる。しないとそのドメインだけ。Pathも指定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Domain=example.com; Path=/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リクエストが飛び、&lt;code&gt;Set-Cookie&lt;/code&gt;ヘッダーを受け取ればCookieに書かれるので、アクセスしたサイトのドメイン以外のCookieが書かれることがある。
このようなCookieを3rd party cookieといって、広告のトラッキングによく使われるが、
Safariなどのデフォルト設定では書き込めなくなっている。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ELBのスケーリングとsurge queue</title>
          <link>https://www.sambaiz.net/article/68/</link>
          <pubDate>Tue, 21 Feb 2017 19:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/68/</guid>
          <description>

&lt;p&gt;バックエンドだけではなくELB自体もスケーリングし、内部node数はdigで調べることができる。
このnode数は自分ではコントロールできず、基本的に意識することはない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ dig ****.ap-northeast-1.elb.amazonaws.com

;; ANSWER SECTION:
*****.elb.amazonaws.com. 60 IN A xxx.xxx.xxx.xxx
*****.elb.amazonaws.com. 60 IN A yyy.yyy.yyy.yyy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;nodeが増えるのにはある程度時間がかかるので、
アクセスが急増(5分間で50%以上のトラフィック増加が&lt;a href=&#34;http://aws.typepad.com/sajp/2015/05/aws-black-belt-elb.html&#34;&gt;目安&lt;/a&gt;)
したら捌ききれず、503を返すことがある。
前もって多量のアクセスが来ることが分かっていて、
&lt;a href=&#34;https://aws.amazon.com/jp/premiumsupport/signup/&#34;&gt;AWSサポート&lt;/a&gt;がBusiness以上なら
pre-warming申請することでnodeが増えた状態で待ち構えられる。&lt;/p&gt;

&lt;p&gt;バックエンドのアプリケーションがリクエストを処理できない場合、ELBのsurge queueに溜まっていく。
この数はCloudWatchのSurgeQueueLength(キュー長の急増)メトリクスで確認できる。
また、SurgeQueueLengthの最大値1024を超えるとリクエストは拒否され、その数はSpoiloverCount(過剰数)メトリクスに出る。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/elb-and-cloudwatch-metrics-in-depth/&#34;&gt;ELBの挙動とCloudWatchメトリクスの読み方を徹底的に理解する ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/premiumsupport/knowledge-center/elb-latency-troubleshooting/&#34;&gt;Elastic Load Balancing でのレイテンシーのトラブルシューティング&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kinesis Streams/Firehose/Analyticsを試す</title>
          <link>https://www.sambaiz.net/article/67/</link>
          <pubDate>Mon, 20 Feb 2017 21:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/67/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/&#34;&gt;https://aws.amazon.com/jp/kinesis/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;リアルタイムのストリーミングデータを扱うサービス群。
いまのところTokyoリージョンではKinesis Streamsしか使えない。&lt;/p&gt;

&lt;h3 id=&#34;kinesis-firehose-https-aws-amazon-com-jp-kinesis-firehose&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/&#34;&gt;Kinesis Firehose&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;AWSのデータストアに送るストリーム。自分でデータを読む処理を書かなくてよく、スケーリングも勝手にやってくれるので簡単に使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/faqs/&#34;&gt;https://aws.amazon.com/jp/kinesis/firehose/faqs/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: 送信先とは何ですか?
送信先はデータが配信されるデータストアです。Amazon Kinesis Firehose では、
現在送信先として Amazon S3、Amazon Redshift、Amazon Elasticsearch Service がサポートされています。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/pricing/&#34;&gt;料金&lt;/a&gt;は取り込まれたデータ量による。
一見そんなに高くならないように見えるが、5KB単位で切り上げられるのでレコードのサイズが小さくて数が多い場合に注意が必要。&lt;/p&gt;

&lt;p&gt;今回はS3に送ってみる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-create-firehose.png&#34; alt=&#34;firehose作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;圧縮方法を設定したり、Lambdaを噛ませたりすることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-create-firehose2.png&#34; alt=&#34;firehose作成2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;StatusがActiveになったら&lt;a href=&#34;http://docs.aws.amazon.com/firehose/latest/dev/writing-with-agents.html&#34;&gt;Kinesis Agent&lt;/a&gt;で送ってみる。
CloudWatchとFirehoseにPutする権限が必要。Firehoseはkinesis:ではなくfirehose:なので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install –y aws-kinesis-agent
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/etc/aws-kinesis/agent.json&lt;/code&gt;を編集する。リージョンごとのエンドポイントは
&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/general/latest/gr/rande.html#fh_region&#34;&gt;ここ&lt;/a&gt;
にある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;awsAccessKeyId&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;awsSecretAccessKey&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;firehose.endpoint&amp;quot;: &amp;quot;https://firehose.us-east-1.amazonaws.com&amp;quot;, 
    &amp;quot;flows&amp;quot;: [
        {
            &amp;quot;filePattern&amp;quot;: &amp;quot;/tmp/hoge.log&amp;quot;, 
            &amp;quot;deliveryStream&amp;quot;: &amp;quot;hogefugastream&amp;quot;
        }
    ] 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service aws-kinesis-agent start
$ sudo chkconfig aws-kinesis-agent on
$ echo &amp;quot;aaa&amp;quot; &amp;gt;&amp;gt; /tmp/hoge.log
$ tail /var/log/aws-kinesis-agent/aws-kinesis-agent.log
com.amazon.kinesis.streaming.agent.Agent [INFO] Agent: Progress: 2 records parsed (168 bytes), 
and 2 records sent successfully to destinations. Uptime: 300044ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;S3に保存されているのを確認。&lt;/p&gt;

&lt;h3 id=&#34;kinesis-streams-https-aws-amazon-com-jp-kinesis-streams&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/streams/&#34;&gt;Kinesis Streams&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;用途を制限しないストリーム。データは保持期間の間、何度でも読むことができるので、
とりあえず必要なだけシャードを増やしてデータを入れておけばどうにかなる。
データを扱う側はそれぞれ独立に必要なタイミングで必要なだけpullするため、スケールするにあたってその先は別に考えることができ、
高負荷なシステムのlog aggregatorとして使われる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/streams/pricing/&#34;&gt;料金&lt;/a&gt;は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;時間単位のシャード速度： 1シャードは最大1000件/秒の1MB/秒の入力と2MB/秒の出力能力がある。&lt;/li&gt;
&lt;li&gt;PUTペイロードユニット: 追加する25KBのチャンクの数。5KBでも1チャンク。&lt;/li&gt;
&lt;li&gt;データ保持期間: デフォルトで24時間。7日まで延長可能。シャード時間ごとに課金。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;による。&lt;/p&gt;

&lt;p&gt;ストリーム作成時はシャード数を入れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-create-streams.png&#34; alt=&#34;streams作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Firehoseと同じくKinesis Agentで送ってみる。
エンドポイントは&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/general/latest/gr/rande.html#ak_region&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;awsAccessKeyId&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;awsSecretAccessKey&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;kinesis.endpoint&amp;quot;: &amp;quot;https://kinesis.us-east-1.amazonaws.com&amp;quot;, 
    &amp;quot;flows&amp;quot;: [
        {
            &amp;quot;filePattern&amp;quot;: &amp;quot;/tmp/hoge.log&amp;quot;, 
            &amp;quot;kinesisStream&amp;quot;: &amp;quot;fugafugastream&amp;quot;
        }
    ] 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;aws-cliでデータを&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/streams/latest/dev/fundamental-stream.html#get-records&#34;&gt;取得する&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;まず、シャードイテレーターを取得する。有効時間は300秒。
&lt;a href=&#34;http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax&#34;&gt;TRIM_HORIZON&lt;/a&gt;
で最も古い方からデータを取得していく。SequenceNumberを指定して途中から読むこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws kinesis get-shard-iterator --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON --stream-name fugafugastream
{
    &amp;quot;ShardIterator&amp;quot;: &amp;quot;AAAAAAAAAAFjKI0neNqY2N5HzGljYFCzoFqpQsdncdC6xE+ylnqvZpmusNfyViY3hBSS8WQXa67gvtkF0f2eKzxQ/Fd7SXZG8Inkb8l1UDF5t+jHgErA28gVSWyT4uYxTzzbnhm9AhcbztyQrjqehYcjEfpWIz5XmhY9K3Kjp0Crygy+OYNSS5PoQFcB1PZ7xMFE8zLTxJXLv1ANRu0Q+1m/JFxKQ3WS&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このシャードイテレータを使ってget-recordsする。データはBase64で入っているのでデコードして確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws kinesis get-records --shard-iterator AAAAAAAAAAFjKI0neNqY2N5HzGljYFCzoFqpQsdncdC6xE+ylnqvZpmusNfyViY3hBSS8WQXa67gvtkF0f2eKzxQ/Fd7SXZG8Inkb8l1UDF5t+jHgErA28gVSWyT4uYxTzzbnhm9AhcbztyQrjqehYcjEfpWIz5XmhY9K3Kjp0Crygy+OYNSS5PoQFcB1PZ7xMFE8zLTxJXLv1ANRu0Q+1m/JFxKQ3WS
{
    &amp;quot;Records&amp;quot;: [
        {
            &amp;quot;Data&amp;quot;: &amp;quot;YWFhCg==&amp;quot;, 
            &amp;quot;PartitionKey&amp;quot;: &amp;quot;999679.8130737302&amp;quot;, 
            &amp;quot;ApproximateArrivalTimestamp&amp;quot;: 1487082145.518, 
            &amp;quot;SequenceNumber&amp;quot;: &amp;quot;49570460043263608661463102123405561406360875697772167170&amp;quot;
        }, 
        ...
    ], 
    &amp;quot;NextShardIterator&amp;quot;: &amp;quot;AAAAAAAAAAE08GRdLF1d76L1wCyLIiuAgpSEkKZSkUEO0VdUt3EOfdm1oOSXA1Xc4+tJPkSmB8g5NaQqDPRS/67u5IXermTUiAj6g2lgvDCGCqWFcYMAxIwIKZjKluCPQjL9kRaUqfVAaElRoKjp4Gv7JmuBDjKpxsbF2yk4uJJDAcevqH/VVkala8UbdhTweGyFgf9VhP/ljzXlrqkZ8wbD0eFwtZ3x&amp;quot;, 
    &amp;quot;MillisBehindLatest&amp;quot;: 0
}

$ echo &amp;quot;YWFhCg==&amp;quot; | base64 -d
aaa
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kinesis-analytics-https-aws-amazon-com-jp-kinesis-analytics&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/analytics/&#34;&gt;Kinesis Analytics&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;SourceとなるKinesis Streamsか、Firehoseを指定し、SQLを実行できる。そして必要なら次のストリームに入れることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-create-analytics.png&#34; alt=&#34;analytics作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今回はSourceとしてjsonで株価のデータが入っているDemo streamを使う。
いくつかSQLテンプレートが用意されていて、その中のContinuous Filterを選択。
Streamに入ってきたものをTECHで絞って出力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- ** Continuous Filter ** 
-- Performs a continuous filter based on a WHERE condition.
--          .----------.   .----------.   .----------.              
--          |  SOURCE  |   |  INSERT  |   |  DESTIN. |              
-- Source--&amp;gt;|  STREAM  |--&amp;gt;| &amp;amp; SELECT |--&amp;gt;|  STREAM  |--&amp;gt;Destination
--          |          |   |  (PUMP)  |   |          |              
--          &#39;----------&#39;   &#39;----------&#39;   &#39;----------&#39;               
-- STREAM (in-application): a continuously updated entity that you can SELECT from and INSERT into like a TABLE
-- PUMP: an entity used to continuously &#39;SELECT ... FROM&#39; a source STREAM, and INSERT SQL results into an output STREAM
-- Create output stream, which can be used to send to a destination
CREATE OR REPLACE STREAM &amp;quot;DESTINATION_SQL_STREAM&amp;quot; (ticker_symbol VARCHAR(4), sector VARCHAR(12), change REAL, price REAL);
-- Create pump to insert into output 
CREATE OR REPLACE PUMP &amp;quot;STREAM_PUMP&amp;quot; AS INSERT INTO &amp;quot;DESTINATION_SQL_STREAM&amp;quot;
-- Select all columns from source stream
SELECT STREAM ticker_symbol, sector, change, price
FROM &amp;quot;SOURCE_SQL_STREAM_001&amp;quot;
-- LIKE compares a string to a string pattern (_ matches all char, % matches substring)
-- SIMILAR TO compares string to a regex, may use ESCAPE
WHERE sector SIMILAR TO &#39;%TECH%&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-run-analytics.png&#34; alt=&#34;analytics実行&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する</title>
          <link>https://www.sambaiz.net/article/66/</link>
          <pubDate>Sun, 19 Feb 2017 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/66/</guid>
          <description>

&lt;h2 id=&#34;fluentdのmonitor-agent-http-docs-fluentd-org-v0-12-articles-monitoring&#34;&gt;&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/monitoring&#34;&gt;fluentdのmonitor_agent&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;メトリクスをjsonで返すAPIを提供する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type monitor_agent
  bind 0.0.0.0
  port 24220
&amp;lt;/source&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:24220/api/plugins.json | jq
{
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d8c250&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;forward&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;forward&amp;quot;,
        &amp;quot;port&amp;quot;: &amp;quot;24222&amp;quot;,
        &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: false,
      &amp;quot;retry_count&amp;quot;: null
    },
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d894c4&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;monitor_agent&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;monitor_agent&amp;quot;,
        &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot;,
        &amp;quot;port&amp;quot;: &amp;quot;24220&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: false,
      &amp;quot;retry_count&amp;quot;: null
    },
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590dc1f2c&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;file&amp;quot;,
        &amp;quot;path&amp;quot;: &amp;quot;/var/log/td-agent/hoge.log&amp;quot;,
        &amp;quot;buffer_path&amp;quot;: &amp;quot;/var/log/td-agent/hoge.log.*&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: true,
      &amp;quot;buffer_queue_length&amp;quot;: 0,
      &amp;quot;buffer_total_queued_size&amp;quot;: 0,
      &amp;quot;retry_count&amp;quot;: 0
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをもとにStackdriverで異常を検知できるようにする。&lt;/p&gt;

&lt;h2 id=&#34;google-stackdriver-https-cloud-google-com-stackdriver&#34;&gt;&lt;a href=&#34;https://cloud.google.com/stackdriver/&#34;&gt;Google Stackdriver&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GoogleがStackdriverを買収して改造したもの。GCPだけではなくAWSのリソースも監視できる。
まだBeta。&lt;/p&gt;

&lt;h2 id=&#34;ec2インスタンスを監視する-https-cloud-google-com-monitoring-quickstart-aws-configure-sd-acct&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/quickstart-aws#configure-sd-acct&#34;&gt;EC2インスタンスを監視する&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GCPのメニューのSTACKDRIVER -&amp;gt; モニタリングで、プロジェクトを指定してStackdriverアカウントを作成する。&lt;/p&gt;

&lt;p&gt;今回はEC2で動いているfluentdを監視するので指示に従ってクロスアカウントアクセスのロールを作成、
Role ARNを入力してAWSアカウントと接続すると、
StackdriverのResouces-&amp;gt;InstancesでCPUの使用率などは確認できるが、
EC2にAgentを入れると詳細な情報を取得できる。&lt;/p&gt;

&lt;p&gt;GCPのメニューのサービスアカウントから接続したAWSアカウントを選択し、
Project-&amp;gt;編集者とLogging-&amp;gt;ログ書き込みロールのサービスアカウントを作成する。
新しい秘密鍵の提供にチェックを入れて、JSONのキーをダウンロードする。
これをEC2の&lt;code&gt;/etc/google/auth/application_default_credentials.json&lt;/code&gt;に置いて
&lt;code&gt;chown root:root&lt;/code&gt;、&lt;code&gt;chmod 400&lt;/code&gt;する。&lt;/p&gt;

&lt;p&gt;Monitoring AgentとLogging Agentをインストールし、
&lt;code&gt;stackdriver-collectd&lt;/code&gt;と&lt;code&gt;google-fluentd&lt;/code&gt;のプロセスがあれば正常。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -O https://repo.stackdriver.com/stack-install.sh
sudo bash stack-install.sh --write-gcm

curl -sSO https://dl.google.com/cloudagents/install-logging-agent.sh
sudo bash install-logging-agent.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;メモリの使用量やTCPコネクション数などがとれていることを確認する。
Googleのドキュメントには見つからなかったけど、
旧Stackdriverと同様、&lt;code&gt;stackdriver_monitor: false&lt;/code&gt;のタグを付けると
&lt;a href=&#34;https://support.stackdriver.com/customer/portal/articles/1491785-collecting-data-from-specific-resources-only&#34;&gt;監視対象から外れる&lt;/a&gt;
っぽい。&lt;/p&gt;

&lt;h2 id=&#34;カスタムメトリクスを送る-https-cloud-google-com-monitoring-custom-metrics&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/&#34;&gt;カスタムメトリクスを送る&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;MetricDescriptorを作成し、これにTimeSeriesデータを書き込んでいく。&lt;/p&gt;

&lt;h3 id=&#34;metricdescriptorの作成-https-cloud-google-com-monitoring-custom-metrics-creating-metrics-monitoring-create-metric-protocol&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#monitoring-create-metric-protocol&#34;&gt;MetricDescriptorの作成&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors&#34;&gt;MetricDescriptor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;typeは&lt;code&gt;custom.googleapis.com/&lt;/code&gt;
から&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#custom_metric_names&#34;&gt;始める&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors#MetricKind&#34;&gt;metricKind&lt;/a&gt;
にはGAUGEのほかに変化量をとるDELTA、累積するCUMULATIVEを指定できる。&lt;/p&gt;

&lt;p&gt;labelはフィルタリングのためのもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;fluentd buffer_queue_length&amp;quot;,
  &amp;quot;displayName&amp;quot;: &amp;quot;fluentd-buffer_queue_length&amp;quot;,
  &amp;quot;type&amp;quot;: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
  &amp;quot;metricKind&amp;quot;: &amp;quot;GAUGE&amp;quot;,
  &amp;quot;valueType&amp;quot;: &amp;quot;INT64&amp;quot;,
  &amp;quot;labels&amp;quot;: [
    {
      &amp;quot;key&amp;quot;: &amp;quot;plugin_type&amp;quot;,
      &amp;quot;valueType&amp;quot;: &amp;quot;STRING&amp;quot;,
      &amp;quot;description&amp;quot;: &amp;quot;The type of the plugin&amp;quot;
    },
  ],
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをGoで登録する。&lt;/p&gt;

&lt;p&gt;gcpのほうのprojectでProject-&amp;gt;編集者のサービスアカウントを作成してパスを
環境変数&lt;code&gt;GOOGLE_APPLICATION_CREDENTIALS&lt;/code&gt;に入れて
&lt;a href=&#34;https://developers.google.com/identity/protocols/application-default-credentials&#34;&gt;Default Credential&lt;/a&gt;
にする。&lt;/p&gt;

&lt;p&gt;必要なパッケージをgo get。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get google.golang.org/api/monitoring/v3
$ go get golang.org/x/oauth2/google
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		panic(err)
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		panic(err)
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/*****&amp;quot;

		requestBody = &amp;amp;monitoring.MetricDescriptor{
			Description: &amp;quot;fluentd buffer_queue_length&amp;quot;,
			DisplayName: &amp;quot;fluentd-buffer_queue_length&amp;quot;,
			Type:        &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
			MetricKind:  &amp;quot;GAUGE&amp;quot;,
			ValueType:   &amp;quot;INT64&amp;quot;,
			Labels: []*monitoring.LabelDescriptor{
				&amp;amp;monitoring.LabelDescriptor{
					Key:         &amp;quot;plugin_type&amp;quot;,
					ValueType:   &amp;quot;STRING&amp;quot;,
					Description: &amp;quot;The type of the plugin&amp;quot;,
				},
			},
		}
	)

	response, err := client.Projects.MetricDescriptors.Create(name, requestBody).Context(ctx).Do()
	if err != nil {
		panic(err)
	}

	fmt.Println(&amp;quot;done&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;登録されたことをlistで確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;response, err := client.Projects.MetricDescriptors.List(name).Context(ctx).Do()
if err != nil {
  panic(err)
}

for _, v := range response.MetricDescriptors {
  fmt.Println(v.DisplayName)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;API Request Count
Agent Memory Usage
Stream Space Used
...
fluentd-buffer_queue_length
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;timeseriesの書き込み-https-cloud-google-com-monitoring-custom-metrics-creating-metrics-monitoring-write-timeseries-protocol&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#monitoring-write-timeseries-protocol&#34;&gt;TimeSeriesの書き込み&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/TimeSeries&#34;&gt;TimeSeries&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;metricのtypeはMetricDescriptorのtypeと対応する。
pointsのendTimeはRFC3339のUTC文字列で渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
 &amp;quot;timeSeries&amp;quot;: [
  {
   &amp;quot;metric&amp;quot;: {
    &amp;quot;type&amp;quot;: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
    &amp;quot;labels&amp;quot;: {
     &amp;quot;plugin_type&amp;quot;: &amp;quot;file&amp;quot;
    }
   },
   &amp;quot;resource&amp;quot;: {
    &amp;quot;type&amp;quot;: &amp;quot;aws_ec2_instance&amp;quot;,
    &amp;quot;labels&amp;quot;: {
     &amp;quot;project_id&amp;quot;: &amp;quot;*****&amp;quot;,
     &amp;quot;instance_id&amp;quot;: &amp;quot;*****&amp;quot;,
     &amp;quot;region&amp;quot;: &amp;quot;aws:ap-northeast-1&amp;quot;,
     &amp;quot;aws_account&amp;quot;: &amp;quot;*****&amp;quot;
    }
   },
   &amp;quot;points&amp;quot;: [
    {
     &amp;quot;interval&amp;quot;: {
      &amp;quot;endTime&amp;quot;: &amp;quot;2016-06-01T10:00:00-04:00&amp;quot;
     },
     &amp;quot;value&amp;quot;: {
      &amp;quot;int64Value&amp;quot;: 0
     }
    }
   ]
  }
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;resourceのtypeは
&lt;a href=&#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/monitoredResourceDescriptors/list#MonitoredResourceDescriptor&#34;&gt;MonitoredResourceDescriptor&lt;/a&gt;
と対応していて、
&lt;a href=&#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/monitoredResourceDescriptors/list&#34;&gt;list&lt;/a&gt;で確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
 &amp;quot;resourceDescriptors&amp;quot;: [
   {
   &amp;quot;type&amp;quot;: &amp;quot;aws_ec2_instance&amp;quot;,
   &amp;quot;displayName&amp;quot;: &amp;quot;Amazon EC2 Instance&amp;quot;,
   &amp;quot;description&amp;quot;: &amp;quot;A VM instance in Amazon EC2.&amp;quot;,
   &amp;quot;labels&amp;quot;: [
    {
     &amp;quot;key&amp;quot;: &amp;quot;project_id&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The identifier of the GCP project under which data is stored for the AWS account specified in the aws_account label (e.g., my-project).&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;instance_id&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The VM instance identifier assigned by AWS.&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;region&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The AWS region in which the VM is running. Supported AWS region values are listed by service at http://docs.aws.amazon.com/general/latest/gr/rande.html. The value supplied for this label must be prefixed with &#39;aws:&#39; (for example, &#39;aws:us-east-1&#39; is a valid value while &#39;us-east-1&#39; is not).&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;aws_account&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The AWS account number under which the VM is running.&amp;quot;
    }
   ]
  },
  ...
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;書くコード。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func writeFluentdBufferQueueLength() error {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		return err
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		return err
	}

	now := time.Now().UTC().Format(time.RFC3339)

	resource := &amp;amp;monitoring.MonitoredResource{
		Type: &amp;quot;aws_ec2_instance&amp;quot;,
		Labels: map[string]string{
			&amp;quot;project_id&amp;quot;:  &amp;quot;*****&amp;quot;,
			&amp;quot;instance_id&amp;quot;: &amp;quot;*****&amp;quot;,
			&amp;quot;region&amp;quot;:      &amp;quot;aws:ap-northeast-1&amp;quot;,
			&amp;quot;aws_account&amp;quot;: &amp;quot;*****&amp;quot;,
		},
	}

	metrics, err := fetchFluentdMetrics()
	if err != nil {
		return err
	}

	timeSeries := []*monitoring.TimeSeries{}

	for _, v := range metrics.Plugins {
		if v.OutputPlugin {

			fmt.Printf(&amp;quot;send %s\n&amp;quot;, v.Type)

			timeSeries = append(
				timeSeries,
				&amp;amp;monitoring.TimeSeries{
					Metric: &amp;amp;monitoring.Metric{
						Type: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
						Labels: map[string]string{
							&amp;quot;plugin_type&amp;quot;: v.Type,
						},
					},
					Resource: resource,
					Points: []*monitoring.Point{
						&amp;amp;monitoring.Point{
							Interval: &amp;amp;monitoring.TimeInterval{
								EndTime: now,
							},
							Value: &amp;amp;monitoring.TypedValue{
								Int64Value: int64p(v.BufferQueueLength),
							},
						},
					},
				},
			)
		}
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/try-stackdriver-159110&amp;quot;

		requestBody = &amp;amp;monitoring.CreateTimeSeriesRequest{
			TimeSeries: timeSeries,
		}
	)

	_, err = client.Projects.TimeSeries.Create(name, requestBody).Context(ctx).Do()
	if err != nil {
		return err
	}

	fmt.Println(&amp;quot;done&amp;quot;)

	return nil
}

const fluentdMonitorEndpoint = &amp;quot;http://localhost:24220/api/plugins.json&amp;quot;

type fluentdMetrics struct {
	Plugins []fluentdMetricsPlugin `json:&amp;quot;plugins&amp;quot;`
}
type fluentdMetricsPlugin struct {
	Type              string `json:&amp;quot;type&amp;quot;`
	OutputPlugin      bool   `json:&amp;quot;output_plugin&amp;quot;`
	BufferQueueLength int64  `json:&amp;quot;buffer_queue_length&amp;quot;`
}

// monitor_agentからfluentdのメトリクスを取得する
func fetchFluentdMetrics() (*fluentdMetrics, error) {

	resp, err := http.Get(fluentdMonitorEndpoint)
	if err != nil {
		return nil, err
	}

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}

	var ret fluentdMetrics

	if err := json.Unmarshal(body, &amp;amp;ret); err != nil {
		return nil, err
	}

	return &amp;amp;ret, nil
}

// int64 -&amp;gt; *int64
func int64p(n int64) *int64 {
	return &amp;amp;n
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;a href=&#34;https://github.com/jasonlvhit/gocron&#34;&gt;gocron&lt;/a&gt;などで定期的に実行させる。&lt;/p&gt;

&lt;p&gt;読むコード。確認用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func readFluentdBufferQueueLength() error {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		return err
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		return err
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/*****&amp;quot;
	)

	start := time.Now().Add(time.Hour * -3).UTC().Format(time.RFC3339)
	now := time.Now().UTC().Format(time.RFC3339)

	filter := &amp;quot;metric.type = \&amp;quot;custom.googleapis.com/fluentd/buffer_queue_length\&amp;quot;&amp;quot;
	resp, err := client.Projects.TimeSeries.List(name).
		IntervalStartTime(start).
		IntervalEndTime(now).
		Filter(filter).Context(ctx).Do()
	if err != nil {
		return err
	}

	for _, v := range resp.TimeSeries {
		fmt.Println(v.Metric.Type)
		for _, p := range v.Points {
			fmt.Println(*(p.Value.Int64Value))
		}
	}

	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと届いていれば
Resource-&amp;gt;Metrics Explorerでもcustom/fluentd/buffer_queue_lengthを確認できる。&lt;/p&gt;

&lt;p&gt;これでAlertを設定できるようになった。TargetのResource TypeはCustom Metrics。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/66.png&#34; alt=&#34;Alertの設定&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのselectの中断処理(close, context)</title>
          <link>https://www.sambaiz.net/article/65/</link>
          <pubDate>Thu, 16 Feb 2017 20:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/65/</guid>
          <description>

&lt;h2 id=&#34;close-chan&#34;&gt;close(chan)&lt;/h2&gt;

&lt;p&gt;closeしたチャネルを読むとゼロ値になるので、selectで待っているやつにまとめて送れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	done := make(chan bool)

	wg := new(sync.WaitGroup)

	waitTillDone(wg, done)
	waitTillDone(wg, done)

    // こんなことしなくていい
	// done &amp;lt;- true
	// done &amp;lt;- true

	close(done)

	wg.Wait()
}

func waitTillDone(wg *sync.WaitGroup, done &amp;lt;-chan bool) {
	wg.Add(1)
	go func() {
		select {
		case v := &amp;lt;-done:
			fmt.Println(v) // false (ゼロ値)
			wg.Done()
		}
	}()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;context-https-godoc-org-golang-org-x-net-context&#34;&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/net/context&#34;&gt;context&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;key-valueの値を渡せるほかにキャンセルやタイムアウトの仕組みをもつ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ctx := context.Background() // empty context
ctx, cancel = context.WithCancel(ctx)
ctx, cancel = context.WithDeadline(ctx, time.Now().Add(time.Second * 10))
ctx, cancel = context.WithTimeout(ctx, time.Second * 10)
ctx = context.WithValue(ctx, key, value)
ctx.Value(key).(Data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さっきdoneで待ってたところを&lt;code&gt;ctx.Done()&lt;/code&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	finished := make(chan interface{})
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel() // キャンセルしないとリークする

	go func() {
		if err := f1(ctx); err != nil {
			fmt.Printf(&amp;quot;main: %s\n&amp;quot;, err)
		} else {
			fmt.Println(&amp;quot;ok&amp;quot;)
		}
		close(finished)
	}()

	fmt.Println(&amp;quot;I will cancel!&amp;quot;)
	cancel()

	select {
	case &amp;lt;-finished:
		fmt.Println(&amp;quot;finished&amp;quot;)
	}
}

func f1(ctx context.Context) error {
	f2(ctx)
	select {
	case &amp;lt;-ctx.Done():
		fmt.Printf(&amp;quot;f1: %s\n&amp;quot;, ctx.Err())
		return ctx.Err()
	}
}

func f2(ctx context.Context) error {
	select {
	case &amp;lt;-ctx.Done():
		fmt.Printf(&amp;quot;f2: %s\n&amp;quot;, ctx.Err())
		return ctx.Err()
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;I will cancel!
f2: context canceled
f1: context canceled
main: context canceled
finished
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、key-valueを受けわたすために使う場合は
type-safeにするために
NewContextで値を詰めて、FromContextで値を取り出すということがコメントに書いてある。
また、Contextはctxという名前で第一引数として渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type User struct {
	name string
}

type key int

var userKey key = 0

func NewContext(ctx context.Context, u *User) context.Context {
	return context.WithValue(ctx, userKey, u)
}

func FromContext(ctx context.Context) (*User, bool) {
	u, ok := ctx.Value(userKey).(*User)
	return u, ok
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/pipelines&#34;&gt;Go Concurrency Patterns: Pipelines and cancellation - The Go Blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://deeeet.com/writing/2016/07/22/context/&#34;&gt;Go1.7のcontextパッケージ | SOTA&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentd自身のログを拾う</title>
          <link>https://www.sambaiz.net/article/64/</link>
          <pubDate>Tue, 14 Feb 2017 21:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/64/</guid>
          <description>

&lt;p&gt;fluentdは自身のログも&lt;code&gt;fluent.error&lt;/code&gt;のようなタグでイベントとして流す。&lt;/p&gt;

&lt;p&gt;バッファを0にして意図的にエラーを発生させてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

# throw away
&amp;lt;match fluent.info&amp;gt;
  @type null
&amp;lt;/match&amp;gt;

&amp;lt;match fluent.**&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;

# error!
&amp;lt;match **&amp;gt;
  @type file
  path /var/log/td-agent/hoge.log
  buffer_chunk_limit 0
  buffer_queue_limit 0
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;すると、こんなのがtd-agent.logに出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fluent.error: {&amp;quot;error&amp;quot;:&amp;quot;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;quot;,&amp;quot;error_class&amp;quot;:&amp;quot;Fluent::BufferQueueLimitError&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただ、これだとaggregatorに集めたときにどのサーバーのfluentdに問題が発生してるのか分からない。
そこでホスト名を追加する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/55/&#34;&gt;fluentdのrecord_transformerでログを加工する - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;filter fluent.**&amp;gt;
  @type record_transformer
  enable_ruby

  &amp;lt;record&amp;gt;
    hostname &amp;quot;#{Socket.gethostname}&amp;quot;
    tag ${tag}
  &amp;lt;/record&amp;gt;
&amp;lt;/filter&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;fluent.error: {&amp;quot;error&amp;quot;:&amp;quot;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;quot;,&amp;quot;error_class&amp;quot;:&amp;quot;Fluent::BufferQueueLimitError&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;quot;,
&amp;quot;hostname&amp;quot;:&amp;quot;*****&amp;quot;,&amp;quot;tag&amp;quot;:&amp;quot;fluent.error&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://chopl.in/post/2013/04/27/fluentd_internal_log/&#34;&gt;fluentd自身のログにまつわるノウハウ - still deeper&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GoでDynamoDBを使う</title>
          <link>https://www.sambaiz.net/article/63/</link>
          <pubDate>Sun, 12 Feb 2017 23:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/63/</guid>
          <description>

&lt;h2 id=&#34;テーブルを作成する&#34;&gt;テーブルを作成する&lt;/h2&gt;

&lt;h3 id=&#34;プライマリキー&#34;&gt;プライマリキー&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/GuidelinesForTables.html&#34;&gt;テーブルの操作のガイドライン - Amazon DynamoDB&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;プライマリキーとしてパーティションキー(ハッシュキー)とオプションのソートキー(レンジキー)を設定する。
DynamoDBはこのパーティションキーに基づいて、複数のパーティションに分散して保存する。
テーブルにプロビジョニングされたスループット性能はパーティション間で均等に使われるので、
ソートキーを設定する場合にこれを最大限に活用するためには、
あるパーティションにリクエストが集中しないよう、パーティションキーに特定の値ばかり集中しないようなフィールドを
選ぶ必要がある。&lt;/p&gt;

&lt;h3 id=&#34;セカンダリインデックス&#34;&gt;セカンダリインデックス&lt;/h3&gt;

&lt;p&gt;パーティションキーのグローバルセカンダリインデックス(GSI)と
ソートキーのローカルセカンダリインデックス(LSI)がある。
射影されるフィールドを選択でき、ここに含まれないフィールドは返さない。
ただし、すべてをインデックスに書き込むのはコストが高いのでなるべく絞る。&lt;/p&gt;

&lt;h3 id=&#34;キャパシティユニット-http-docs-aws-amazon-com-ja-jp-amazondynamodb-latest-developerguide-limits-html-limits-capacity-units-provisioned-throughpu&#34;&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/Limits.html#limits-capacity-units-provisioned-throughpu&#34;&gt;キャパシティユニット&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1読み込みキャパシティユニット: 4kbを超えないデータを1秒に1~2回(整合性による)読み込める&lt;/li&gt;
&lt;li&gt;1書き込みキャパシティユニット: 1kbを超えないデータを1秒に1回書き込める&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ユニットに応じて1時間あたりで&lt;a href=&#34;https://aws.amazon.com/jp/dynamodb/pricing/&#34;&gt;課金&lt;/a&gt;される。&lt;/p&gt;

&lt;p&gt;未使用のキャパシティがある場合、最大5分保持して&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/GuidelinesForTables.html#GuidelinesForTables.Bursting&#34;&gt;バーストに備えてくれる&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;読み書きする&#34;&gt;読み書きする&lt;/h2&gt;

&lt;p&gt;aws-sdk-goを直接使ってもいいけど、簡単に扱えるラッパー
&lt;a href=&#34;https://github.com/guregu/dynamo&#34;&gt;guregu/dynamo&lt;/a&gt;
を使うことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Data struct {
	ID   int64 `dynamo:&amp;quot;id&amp;quot;`
	Name string
	Age  int
}

db := dynamo.New(session.New(), &amp;amp;aws.Config{Region: aws.String(&amp;quot;ap-northeast-1&amp;quot;)})
table := db.Table(&amp;quot;testtable&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;create-update&#34;&gt;Create &amp;amp; Update&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;d := Data{ID: 1, Name: &amp;quot;hogefuga&amp;quot;, Age: 123}
if err := table.Put(d).Run(); err != nil {
    return err
}

if err := table.Update(&amp;quot;id&amp;quot;, 1).Set(&amp;quot;name&amp;quot;, &amp;quot;fugafuga&amp;quot;).Run(); err != nil {
    return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get&#34;&gt;Get&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;var data Data
// 結果整合性がある読み込み(1秒に2回/ユニット)　.Consistent(true)で強い整合性のある読み込み(1秒に1回/ユニット)にできる
if err := table.Get(&amp;quot;id&amp;quot;, 1).One(&amp;amp;data); err != nil {
    return err
}
fmt.Println(data)

if err := table.Get(&amp;quot;id&amp;quot;, 2).One(&amp;amp;data); err != nil {
    return err // dynamo: no item found
}
fmt.Println(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/AmazonWebServicesJapan/20150805-aws-blackbeltdynamodb&#34;&gt;AWS Black Belt Tech シリーズ 2015 - Amazon DynamoDB&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Elasticsearchのmapping</title>
          <link>https://www.sambaiz.net/article/62/</link>
          <pubDate>Thu, 09 Feb 2017 21:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/62/</guid>
          <description>

&lt;p&gt;Dynamic mappingがあるので、自分で設定しなくてもデータは入るけど、
自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。
バージョンは5.2。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: 0 
}
&#39;

$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot;
}
&#39;

{
  &amp;quot;error&amp;quot; : {
    &amp;quot;root_cause&amp;quot; : [
      {
        &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;,
        &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;
      }
    ],
    &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;,
    &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;,
    &amp;quot;caused_by&amp;quot; : {
      &amp;quot;type&amp;quot; : &amp;quot;number_format_exception&amp;quot;,
      &amp;quot;reason&amp;quot; : &amp;quot;For input string: \&amp;quot;sambaiz\&amp;quot;&amp;quot;
    }
  },
  &amp;quot;status&amp;quot; : 400
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mapping-parameters-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-params-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-params.html&#34;&gt;Mapping parameters&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;index-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-index-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-index.html&#34;&gt;index&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;falseにするとindexしない。クエリで必要ないものはfalseにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;index&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;store-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-store-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-store.html&#34;&gt;store&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;デフォルトでフィールドはindexされるがstoreはされず、metaの&lt;code&gt;_source&lt;/code&gt;としてオリジナルのJSONがstoreされている。
サイズの大きなフィールドがあるなど、選んでstoreする場合はtrueにする。stored_fieldsで必要なものだけとってくることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;store&amp;quot;: true }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;meta-fields-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-fields-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-fields.html&#34;&gt;Meta fields&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;all-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-all-field-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-all-field.html&#34;&gt;_all&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;全てのフィールドをスペースでつなげた一つの文字列にしてanalyzeし、indexする。storeはされない。&lt;/p&gt;

&lt;p&gt;フィールドの区別なく検索できたりするけどindexするのにコストがかかるので必要ないならfalseにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;_all&amp;quot;: { &amp;quot;enabled&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;source-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-source-field-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-source-field.html&#34;&gt;_source&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;オリジナルのJSONを含み、indexはされずstoreされる。&lt;/p&gt;

&lt;p&gt;無効にするとストレージを節約できるが、
まずは&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/index-modules.html#index-codec&#34;&gt;compression level&lt;/a&gt;を上げてみる。
無効にするとupdateやreindexができなくなったりするので有効のままにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;_source&amp;quot;: { &amp;quot;enabled&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;analysis-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-analysis-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analysis.html&#34;&gt;analysis&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;textをどのようにanalyzeするか。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analyzer-anatomy.html&#34;&gt;Analyzer&lt;/a&gt;は
Character filtersで文字列を加工してTokenizerでトークンに分割してからToken filtersでトークンを取り除いたり変更したりするもの。
自分でこれらを組み合わせて&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analysis-custom-analyzer.html&#34;&gt;定義する&lt;/a&gt;こともできる。&lt;/p&gt;

&lt;p&gt;日本語のAnalyzerとして&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/plugins/5.2/analysis-kuromoji.html&#34;&gt;kuromoji&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/elasticsearch-plugin install analysis-kuromoji
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;kuromoji&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XGET &#39;localhost:9200/_analyze?pretty&#39; -d &#39;
{
  &amp;quot;analyzer&amp;quot; : &amp;quot;kuromoji&amp;quot;,
  &amp;quot;text&amp;quot; : &amp;quot;Character filtersで文字列を加工します&amp;quot;
}&#39;

{
  &amp;quot;tokens&amp;quot; : [
    {
      &amp;quot;token&amp;quot; : &amp;quot;character&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 0,
      &amp;quot;end_offset&amp;quot; : 9,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 0
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;filters&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 10,
      &amp;quot;end_offset&amp;quot; : 17,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 1
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;文字&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 18,
      &amp;quot;end_offset&amp;quot; : 20,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 3
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;列&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 20,
      &amp;quot;end_offset&amp;quot; : 21,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 4
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;加工&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 22,
      &amp;quot;end_offset&amp;quot; : 24,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 6
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;datatype-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-types-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-types.html&#34;&gt;datatype&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;文字列-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-string-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/string.html&#34;&gt;文字列&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;5.Xからstringは廃止され
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/text.html&#34;&gt;text&lt;/a&gt;と
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/keyword.html&#34;&gt;keyword&lt;/a&gt;になった。&lt;/p&gt;

&lt;p&gt;textはメールの文章のようなfull-textの値で、ある単語がそれぞれの文章に含まれるかということを調べることができる。
メールアドレスのようなデータの場合はkeywordを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;email&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;数値-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-number-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/number.html&#34;&gt;数値&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;long(64bit), integer(32bit), short(16bit, ~32767), byte(8bit, ~127), double, floatとか。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;age&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;short&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;日付-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-date-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/date.html&#34;&gt;日付&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;date&amp;quot;: {
  &amp;quot;type&amp;quot;:   &amp;quot;date&amp;quot;,
  &amp;quot;format&amp;quot;: &amp;quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;boolean-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-boolean-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/boolean.html&#34;&gt;Boolean&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;success&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;object-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-object-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/object.html&#34;&gt;Object&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;propertiesの中に書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: {
  &amp;quot;properties&amp;quot;: {
    &amp;quot;fuga&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;nested-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-nested-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/nested.html&#34;&gt;nested&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;objectの配列。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: {
  &amp;quot;type&amp;quot;: &amp;quot;nested&amp;quot;
  &amp;quot;properties&amp;quot;: {
    &amp;quot;fuga&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: [{&amp;quot;fuga&amp;quot;: true}]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;登録&#34;&gt;登録&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/test_index?pretty&#39; -d&#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;test_type&amp;quot;: { 
      &amp;quot;_all&amp;quot;:       { &amp;quot;enabled&amp;quot;: false  }, 
      &amp;quot;properties&amp;quot;: { 
        &amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;, &amp;quot;store&amp;quot;: true },
        &amp;quot;description&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;kuromoji&amp;quot; },
        &amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;index&amp;quot;: false }
      }
    }
  }
}
&#39;

$ curl -XPOST &#39;localhost:9200/test_index/test_type?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot;,
    &amp;quot;description&amp;quot;: &amp;quot;青い海&amp;quot;,
    &amp;quot;memo&amp;quot;: &amp;quot;白い空&amp;quot;
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logstashのようにindex名に日付が付いているような場合は
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/indices-templates.html&#34;&gt;indices-template&lt;/a&gt;で設定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_template/hogefuga-template -d &#39;
{
  &amp;quot;template&amp;quot; : &amp;quot;hogefuga-*&amp;quot;,
  &amp;quot;mappings&amp;quot; : {
    ...
  }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;取得&#34;&gt;取得&lt;/h2&gt;

&lt;p&gt;まずはデータが入っていることを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/test_index/test_type/_search?pretty&#39;
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVodMAubr8EtIroFs0eP&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;name&amp;quot; : &amp;quot;sambaiz&amp;quot;,
          &amp;quot;description&amp;quot; : &amp;quot;青い海&amp;quot;,
          &amp;quot;memo&amp;quot; : &amp;quot;白い空&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stored_fieldsを付けてリクエスト。_sourceが含まれず、storeがtrueなnameだけが返ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/test_index/_search?pretty&amp;amp;stored_fields=name,description,memo&#39;
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVodMAubr8EtIroFs0eP&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;fields&amp;quot; : {
          &amp;quot;name&amp;quot; : [
            &amp;quot;sambaiz&amp;quot;
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリを付けてリクエスト。indexされてないmemoではひっかからない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_index/test_type/_search?pretty&#39; -d &#39;
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;query_string&amp;quot;:{
      &amp;quot;default_field&amp;quot; : &amp;quot;description&amp;quot;,
      &amp;quot;query&amp;quot;: &amp;quot;青い海&amp;quot;
    }
  }
}&#39;

{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_index/test_type/_search?pretty&#39; -d &#39;
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;query_string&amp;quot;:{
      &amp;quot;default_field&amp;quot; : &amp;quot;memo&amp;quot;,
      &amp;quot;query&amp;quot;: &amp;quot;白い空&amp;quot;
    }
  }
}&#39;

{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 0,
    &amp;quot;max_score&amp;quot; : null,
    &amp;quot;hits&amp;quot; : [ ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing/&#34;&gt;Elasticsearchのインデキシングに関するパフォーマンス検討 - @johtaniの日記 2nd&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのnet/httpとKeep-Alive</title>
          <link>https://www.sambaiz.net/article/61/</link>
          <pubDate>Tue, 07 Feb 2017 22:42:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/61/</guid>
          <description>

&lt;p&gt;Keep-AliveするとTCPコネクションを使い回し、名前解決やコネクション(3 way handshake)を毎回行わなくてよくなる。
Goの&lt;code&gt;net/http&lt;/code&gt;ではデフォルトでKeep-Aliveが
&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L129&#34;&gt;有効になっている&lt;/a&gt;が、
全体と同一ホストでそれぞれKeep-Aliveするコネクション数が制限される。
これらの値は&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36&#34;&gt;Client&lt;/a&gt;のTransportが持っていて、
これがnullだと&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/transport.go#L39&#34;&gt;DefaultTransport&lt;/a&gt;が参照されるので、意識しなければこの値が使われる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L143&#34;&gt;MaxIdleConns&lt;/a&gt;: DefaultTransportでは&lt;a href=&#34;https://github.com/golang/go/blob/master/src/net/http/transport.go#L46&#34;&gt;100になっている&lt;/a&gt;。0にすると無制限。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L148&#34;&gt;MaxIdleConnsPerHost&lt;/a&gt;: &lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L54&#34;&gt;デフォルト値は2&lt;/a&gt;。0にするとデフォルト値が使われる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;同一のホストに同時にたくさんリクエストする場合、2だとほとんど意味を持たない。これを増やして比較してみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;time&amp;quot;
)

var client = http.Client{
	Timeout: time.Millisecond * 100,
}

const TOTAL_REQUEST_NUM = 3000
const TARGET_URL = &amp;quot;*****&amp;quot;

func main() {

	http.DefaultTransport.(*http.Transport).MaxIdleConns = 0
	http.DefaultTransport.(*http.Transport).MaxIdleConnsPerHost = 3000

	okChan := make(chan int, TOTAL_REQUEST_NUM)
	ngChan := make(chan int, TOTAL_REQUEST_NUM)

	var okCount = 0
	var ngCount = 0

	// connect and keep-alive
	for i := 0; i &amp;lt; TOTAL_REQUEST_NUM; i++ {
		go request(okChan, ngChan)
	}

	for {
		select {
		case &amp;lt;-okChan:
			okCount++
		case &amp;lt;-ngChan:
			ngCount++
		}

		if okCount+ngCount == TOTAL_REQUEST_NUM {
			break
		}
	}

	okCount = 0
	ngCount = 0

	startNs := time.Now().UnixNano()

	for i := 0; i &amp;lt; TOTAL_REQUEST_NUM; i++ {
		go request(okChan, ngChan)
	}

	for {
		select {
		case &amp;lt;-okChan:
			okCount++
		case &amp;lt;-ngChan:
			ngCount++
		}

		if okCount+ngCount == TOTAL_REQUEST_NUM {
			break
		}
	}

	endNs := time.Now().UnixNano()

	fmt.Printf(&amp;quot;[RESULT] request: %d, ok: %d, ng: %d, time(ms) %d\n&amp;quot;,
		TOTAL_REQUEST_NUM, okCount, ngCount, (endNs-startNs)/(1000*1000))
}

func request(okch chan int, ngch chan int) {
	req, err := http.NewRequest(&amp;quot;GET&amp;quot;, TARGET_URL, nil)
	if err != nil {
		panic(err.Error())
	}

	resp, err := client.Do(req)
	if err != nil {
		fmt.Println(err.Error())
		ngch &amp;lt;- 1
		return
	}
	defer resp.Body.Close()

	_, err = ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Println(err.Error())
		ngch &amp;lt;- 1
		return
	}

	okch &amp;lt;- 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;デフォルト設定: &lt;code&gt;[RESULT] request: 3000, ok: 530, ng: 2470, time(ms) 173&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;MaxIdleConnsPerHostを3000に: &lt;code&gt;[RESULT] request: 3000, ok: 3000, ng: 0, time(ms) 88&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;全てのリクエストが時間内に捌けるようになったので効果があったようだ。&lt;/p&gt;

&lt;p&gt;ただ、このコードのようにgoroutineを無尽蔵に生成すると、限界を超えたときにタイムアウトが頻発してしまうので注意。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/74&#34;&gt;Goroutineの数をworkerで抑制する - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ちなみに、&lt;a href=&#34;https://github.com/tcnksm/go-httpstat&#34;&gt;tcnksm/go-httpstat&lt;/a&gt;でnet/http/httptraceすると各処理にかかっている時間が分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;req, err := http.NewRequest(&amp;quot;GET&amp;quot;, TARGET_URL, nil)
if err != nil {
	panic(err.Error())
}

result := new(httpstat.Result)
ctx := httpstat.WithHTTPStat(req.Context(), result)
req = req.WithContext(ctx)

resp, err := client.Do(req)
if err != nil {
	fmt.Println(err.Error())
	ngch &amp;lt;- 1
	return
}
defer resp.Body.Close()

_, err = ioutil.ReadAll(resp.Body)
if err != nil {
	fmt.Println(err.Error())
	ngch &amp;lt;- 1
	return
}

result.End(time.Now())
fmt.Printf(&amp;quot;%+v\n&amp;quot;, result)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Start Transfer:   85 ms
Total:            86 ms

DNS lookup:           0 ms
TCP connection:       0 ms
TLS handshake:        0 ms
Server processing:   64 ms
Content transfer:     1 ms

Name Lookup:       0 ms
Connect:           0 ms
Pre Transfer:      0 ms
Start Transfer:   64 ms
Total:            65 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://shogo82148.github.io/blog/2017/01/14/re-golang-dns-cache/&#34;&gt;Re:golang の http.Client を速くする - Shogo&amp;rsquo;s Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>iftopでネットワークの帯域を見る</title>
          <link>https://www.sambaiz.net/article/60/</link>
          <pubDate>Tue, 07 Feb 2017 20:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/60/</guid>
          <description>&lt;pre&gt;&lt;code&gt;$ yum install --enablerepo=epel iftop
$ iftop -f &amp;quot;not dst net 10.0.0.0/8&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;-i eth0&lt;/code&gt;のようにしてインタフェースを指定し、&lt;code&gt;-f&lt;/code&gt;でフィルタをかけられる。フィルタの詳細は&lt;code&gt;man pcap-filter&lt;/code&gt;で。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                          12.5Kb                     25.0Kb                     37.5Kb                     50.0Kb		62.5Kb
└─────────────────────────┴──────────────────────────┴──────────────────────────┴──────────────────────────┴──────────────────────────
ip-172-31-9-9.ap-northeast-1.compute.internal         =&amp;gt; 61-121-217-66.dh-connect.net                          1.72Kb  6.57Kb  2.40Kb
                                                      &amp;lt;=                                                        416b   2.13Kb   702b
...
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
TX:             cum:   22.6KB   peak:   13.2Kb                                                        rates:   1.22Kb  1.27Kb  2.46Kb
RX:                    6.63KB           5.03Kb                                                                  208b    330b    748b
TOTAL:                 29.2KB           18.2Kb                                                                 1.42Kb  1.59Kb  3.19Kb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;左から2, 10, 40秒間の平均kbps。TXが送信量、RXが受信量で、cumが総量、peakが最大。&lt;/p&gt;

&lt;p&gt;実行中に&lt;code&gt;S&lt;/code&gt;でソースのポートを&lt;code&gt;D&lt;/code&gt;でディスティネーションのポートが表示される。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>vmstatのメモ</title>
          <link>https://www.sambaiz.net/article/59/</link>
          <pubDate>Mon, 06 Feb 2017 22:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/59/</guid>
          <description>

&lt;pre&gt;&lt;code&gt;$ vmstat 間隔(秒)
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 118588  80388 2516284    0    0     2    77  141   85  1  0 98  0  0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;procs&#34;&gt;procs&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;r: 実行待ちプロセス数。CPUの処理が追いついていない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;b: 割り込み不可能なスリープ中のプロセス数。I/O待ちらしい。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;memory&#34;&gt;memory&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;swpd: バーチャルメモリの使用量。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;free: 空きメモリ量。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;buff: バッファに使われてるメモリ量。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cache: キャッシュに使われているメモリ量。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;swap&#34;&gt;swap&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;si: 秒あたりのスワップイン量。メモリが足りていない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;so: 秒あたりのスワップアウト量。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;io&#34;&gt;io&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;bi: 秒あたりのブロックデバイスから受け取ったブロック数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;bo: 秒あたりのブロックデバイスに送ったブロック数。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;system&#34;&gt;system&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;in: 秒あたりの割り込み回数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cs: 秒あたりの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B3%E3%83%B3%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%82%B9%E3%82%A4%E3%83%83%E3%83%81&#34;&gt;コンテキストスイッチ&lt;/a&gt;の回数。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cpu&#34;&gt;cpu&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;us: カーネル以外のコードでかかっている時間。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;sy: カーネルコードでかかっている時間。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;id: アイドルタイム。0だとCPUが全力で仕事中。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;wa: IO待ち時間。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;st: 要求したがCPUリソースを割り当ててもらえなかった時間。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://orebibou.com/2015/07/vmstat%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7%E8%A6%9A%E3%81%88%E3%81%A6%E3%81%8A%E3%81%8D%E3%81%9F%E3%81%84%E4%BD%BF%E3%81%84%E6%96%B98%E5%80%8B/&#34;&gt;vmstatコマンドで覚えておきたい使い方8個(+1個) | 俺的備忘録 〜なんかいろいろ〜&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.oracle.com/yappri/entry/vmstat&#34;&gt;vmstat コマンドの読み方 (やっぱり Sun がスキ！)&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>EC2のインスタンスストア</title>
          <link>https://www.sambaiz.net/article/58/</link>
          <pubDate>Mon, 06 Feb 2017 21:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/58/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/InstanceStorage.html&#34;&gt;http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/InstanceStorage.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;EC2ではインスタンスタイプによってはEBSに加えてインスタンスストアが使える。しかも追加料金なし。
対象はストレージが&amp;rdquo;EBSのみ&amp;rdquo;でないもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/ec2/instance-types/&#34;&gt;https://aws.amazon.com/jp/ec2/instance-types/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;インスタンスストアはインスタンスが停止したり、障害が起きると消える一時ストレージ。再起動では消えない。
ホストに物理的にアタッチされているので、バッファやキャッシュなどの頻繁に読み書きされ、消えてもいいデータに最適。
他のインスタンスにアタッチすることはできない。容量や性能もインスタンスタイプに依存する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/add-instance-store-volumes.html&#34;&gt;インスタンスストアボリュームの追加&lt;/a&gt;は
インスタンスの起動時に、新しいボリュームを追加し、ボリュームタイプをインスタンスストアにすることで行うことができる。&lt;/p&gt;

&lt;p&gt;今回はSSDストレージ1 x 4のm3.mediumで試す。これは4gbのボリュームが一つ追加できるという意味。&lt;/p&gt;

&lt;p&gt;まずはインスタンスストアを追加してないインスタンス。
lsblkというのはlist block devicesの略。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ df -h
ファイルシス   サイズ  使用  残り 使用% マウント位置
/dev/xvda1       7.8G  1.2G  6.6G   15% /
...
$ dd if=/dev/zero of=hoge bs=1M count=1000
$ ls -sh
合計 1001M
1001M hoge

$ df -h
ファイルシス   サイズ  使用  残り 使用% マウント位置
/dev/xvda1       7.8G  2.2G  5.6G   28% /
...

$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk 
└─xvda1 202:1    0   8G  0 part /
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それに対してインスタンスストア(/dev/xvdb)を追加したインスタンス。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ df -h
ファイルシス   サイズ  使用  残り 使用% マウント位置
/dev/xvda1       7.8G  1.2G  6.6G   15% /
/dev/xvdb        4.0G   73M  3.7G    2% /media/ephemeral0

$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk 
└─xvda1 202:1    0   8G  0 part /
xvdb    202:16   0   4G  0 disk /media/ephemeral0

$ dd if=/dev/zero of=/media/ephemeral0/hoge bs=1M count=1000
$ df -h
ファイルシス   サイズ  使用  残り 使用% マウント位置
/dev/xvda1       7.8G  1.2G  6.6G   15% /
/dev/xvdb        4.0G  1.1G  2.7G   29% /media/ephemeral0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/imaifactory/ephemeral-ssd&#34;&gt;EC2のストレージどう使う? -Instance Storageを理解して高速IOを上手に活用!-&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensでGaze, Click, Hold, Voiceイベントを拾う</title>
          <link>https://www.sambaiz.net/article/57/</link>
          <pubDate>Sun, 05 Feb 2017 20:01:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/57/</guid>
          <description>

&lt;p&gt;こんなの。SparitalMappingを有効にしているので球が床で止まっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/57.png&#34; alt=&#34;こんなの&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://youtu.be/wQLn_SO9Ics&#34;&gt;動画&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity&#34;&gt;HoloToolKit&lt;/a&gt;
のインタフェースを実装することでイベントを拾えるようになっている。&lt;/p&gt;

&lt;h2 id=&#34;ifocusable&#34;&gt;IFocusable&lt;/h2&gt;

&lt;p&gt;Gazeしたとき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void OnFocusEnter（）
{
    gazing = true;
}

public void OnFocusExit()
{
    gazing = false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;iinputclickhandler&#34;&gt;IInputClickHandler&lt;/h2&gt;

&lt;p&gt;クリックしたとき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void OnInputClicked(InputEventData eventData)
{
    if (!clicked)
    {
        clicked = true;
        clickedRotationFrame = 0;
    }
    countUp();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;iholdhandler&#34;&gt;IHoldHandler&lt;/h2&gt;

&lt;p&gt;Hold(指を下げたまま維持する)したとき。
指を上げたときがCompletedで、Objectを外れたときCanceledになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void OnHoldStarted(HoldEventData eventData)
{
    holding = true;
    clicked = true;
}

public void OnHoldCompleted(HoldEventData eventData)
{
    holding = false;
}

public void OnHoldCanceled(HoldEventData eventData)
{
    holding = false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ispeechhandler&#34;&gt;ISpeechHandler&lt;/h2&gt;

&lt;p&gt;声の入力。
InspectorからSpeech Input Source(Script)を追加して反応するキーワードを設定して使う。
MicrophoneのCapabilitiesが必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void OnSpeechKeywordRecognized(SpeechKeywordRecognizedEventData eventData)
{
    switch (eventData.RecognizedText)
    {
        case &amp;quot;reset&amp;quot;:
            count = 0;
            num.GetComponent&amp;lt;TextMesh&amp;gt;().text = count.ToString();
            break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;全体。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using HoloToolkit.Unity.InputModule;
using UnityEngine;

public class CounterCube : MonoBehaviour, IFocusable, IInputClickHandler, IHoldHandler, ISpeechHandler
{
    // rotate ANIMATION_FRAME * ANIMATION_PER_FRAME degrees
    private const int ANIMATION_FRAME = 30;
    private const float ANIMATION_ROTATE_PER_FRAME = 60f / ANIMATION_FRAME;

    public GameObject cube;
    public GameObject num;

    private int count = 0;

    private bool gazing = false;
    private bool clicked = false;
    private int clickedRotationFrame = 0;
    private bool holding = false;
	
	// Update is called once per frame
	void Update ()
    {
        if(clicked)
        {
            if(clickedRotationFrame &amp;lt; ANIMATION_FRAME)
            {
                clickedRotationFrame++;
                cube.transform.localRotation = Quaternion.Euler(clickedRotationFrame * ANIMATION_ROTATE_PER_FRAME, clickedRotationFrame * ANIMATION_ROTATE_PER_FRAME, 0);
            }
            else if (holding)
            {
                // continue to count up
                clickedRotationFrame = 0;
                countUp();
            }
            else
            {
                clicked = false;
            }

        }

        if (holding)
        {
            cube.GetComponent&amp;lt;Renderer&amp;gt;().material.color = Color.green;
        }
        else if (gazing)
        {
            cube.GetComponent&amp;lt;Renderer&amp;gt;().material.color = Color.blue;
        }
        else
        {
            cube.GetComponent&amp;lt;Renderer&amp;gt;().material.color = Color.gray;
        }
    }

    public void OnFocusEnter()
    {
        gazing = true;
    }

    public void OnFocusExit()
    {
        gazing = false;
    }

    public void OnInputClicked(InputEventData eventData)
    {
        if (!clicked)
        {
            clicked = true;
            clickedRotationFrame = 0;
        }
        countUp();
    }

    public void OnHoldStarted(HoldEventData eventData)
    {
        holding = true;
        clicked = true;
    }

    public void OnHoldCompleted(HoldEventData eventData)
    {
        holding = false;
    }

    public void OnHoldCanceled(HoldEventData eventData)
    {
        holding = false;
    }

    private void countUp()
    {
        num.GetComponent&amp;lt;TextMesh&amp;gt;().text = (++count).ToString();
        var sphere = GameObject.CreatePrimitive(PrimitiveType.Sphere);
        sphere.transform.position = transform.position;
        sphere.transform.localScale = Vector3.one * 0.1f;
        sphere.AddComponent&amp;lt;Rigidbody&amp;gt;();
    }

    public void OnSpeechKeywordRecognized(SpeechKeywordRecognizedEventData eventData)
    {
        switch (eventData.RecognizedText)
        {
            case &amp;quot;reset&amp;quot;:
                count = 0;
                num.GetComponent&amp;lt;TextMesh&amp;gt;().text = count.ToString();
                break;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensの開発を始める</title>
          <link>https://www.sambaiz.net/article/56/</link>
          <pubDate>Sat, 04 Feb 2017 21:28:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/56/</guid>
          <description>

&lt;h2 id=&#34;hololensでのアプリケーション&#34;&gt;HoloLensでのアプリケーション&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/app_model&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/app_model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ある点を見るGazeと指で選択するGesture、声で入力するVoiceで操作する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/hololens_shell_overview&#34;&gt;HoloLens shell&lt;/a&gt;
では壁などにタイルを配置することでアプリケーションが起動する。&lt;/p&gt;

&lt;p&gt;一度に動くアプリケーションは一つ。
他にアクティブなアプリケーションがあれば中断され、タイルは最後の状態のスクリーンショットになる。
タイルを削除するとプロセスが終了する。&lt;/p&gt;

&lt;p&gt;Viewには空間全体を使うHolographic Viewと、通常のウィンドウのような2D Viewがある。&lt;/p&gt;

&lt;h2 id=&#34;開発を始める&#34;&gt;開発を始める&lt;/h2&gt;

&lt;p&gt;Unityを使ってHolographic Viewのアプリケーションを開発する。&lt;/p&gt;

&lt;p&gt;必要なツールをインストールする。エミュレーターは空きメモリが2GB以上ないと立ち上がらない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/install_the_tools&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/install_the_tools&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;チュートリアル&#34;&gt;チュートリアル&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/holograms_100&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/holograms_100&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;QualityのところでWindows Storeのマークがなかったら、
UnityのFile-&amp;gt;Build SettingsからWindows Storeモジュールをダウンロードする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/holograms_101e&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/holograms_101e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;エミュレーターはWASDキーで移動してカーソルキーで向きを変え、エンターキーで選択できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/56-hololens.PNG&#34; alt=&#34;エミュレーターで実行した画面&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;エミュレーターで動かしてみる&#34;&gt;エミュレーターで動かしてみる&lt;/h2&gt;

&lt;p&gt;UnityProjectを作成してHolograms 100のように設定していく。&lt;/p&gt;

&lt;p&gt;まずはCamera。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Position: (0,0,0)&lt;/li&gt;
&lt;li&gt;Clear Flags: Solid Color&lt;/li&gt;
&lt;li&gt;Background: (0,0,0,0)&lt;/li&gt;
&lt;li&gt;Clipping Planes Near: 0.85&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;とりあえず動くことを確認するため適当なオブジェクトを置いてビルドしてみる。&lt;/p&gt;

&lt;p&gt;Edit-&amp;gt;Project Settings-&amp;gt;QualityでWindows StoreをFastestにする。&lt;/p&gt;

&lt;p&gt;Build Settings-&amp;gt;Windows Storeで&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SDK: Universal: 10&lt;/li&gt;
&lt;li&gt;Target device: HoloLens&lt;/li&gt;
&lt;li&gt;UWP Build Type: D3D&lt;/li&gt;
&lt;li&gt;Unity C# Projectにチェック&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;にする。&lt;/p&gt;

&lt;p&gt;BuildSettingsにあるPlayer Settingsボタンを押して
Other SettingsのVirtual Reality Supportedにチェックを入れ、
SDKsにWindows Holographicが出るのを確認する。&lt;/p&gt;

&lt;p&gt;あとはBuild SettingsでAdd Open ScenesしてBuild。適当なディレクトリを作って選ぶとUWPのVSプロジェクトができるので
上のところでRelease,x86,HoloLens Emulatrorにしてデバッグメニューからデバッグなしで開始する。
エミュレーターが立ち上がって置いたオブジェクトが見えたらうまくいっている。&lt;/p&gt;

&lt;h3 id=&#34;uwp-ユニバーサル-windows-プラットフォーム-とは-https-docs-microsoft-com-ja-jp-windows-uwp-get-started-universal-application-platform-guide&#34;&gt;&lt;a href=&#34;https://docs.microsoft.com/ja-jp/windows/uwp/get-started/universal-application-platform-guide&#34;&gt;UWP(ユニバーサル Windows プラットフォーム)とは&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Windows 8でWindowsランタイム(WinRT)として導入された、
PCだけではなく、タブレット、Xbox、HoloLensなど、様々なWindowsデバイス共通のアプリプラットフォーム。&lt;/p&gt;

&lt;p&gt;PCではデスクトップデバイスファミリ、タブレットではモバイルデバイスファミリといったような、デバイスファミリに基づいたOSが実行される。
UWPアプリでは、共通のWinRT APIだけではなく各デバイスファミリ固有のAPIも呼び出すこともでき、
アプリのターゲットとするデバイスファミリを選択することができる。&lt;/p&gt;

&lt;h2 id=&#34;holotoolkitを使う&#34;&gt;HoloToolKitを使う&lt;/h2&gt;

&lt;p&gt;実装やビルドを楽にするやつ。上のような初期設定はやらなくていい。&lt;/p&gt;

&lt;h3 id=&#34;準備&#34;&gt;準備&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/master/GettingStarted.md&#34;&gt;https://github.com/Microsoft/HoloToolkit-Unity/blob/master/GettingStarted.md&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/releases&#34;&gt;ここ&lt;/a&gt;からunitypackageをダウンロードして
UnityのAssetsメニューからインポートする。&lt;/p&gt;

&lt;p&gt;HoloToolKitメニューができるのでConfigureする。&lt;/p&gt;

&lt;p&gt;Main CameraとDirectional Lightを消して
&lt;code&gt;HoloToolkit/Input/Prefabs/HoloLensCamera.prefab&lt;/code&gt;と、
&lt;code&gt;HoloToolkit/Input/Prefabs/Cursor/DefaultCursor.prefab&lt;/code&gt;を置く。&lt;/p&gt;

&lt;p&gt;Create Emptyして&amp;rdquo;Managers&amp;rdquo;にリネームし、この中に
&lt;code&gt;HoloToolkit/Input/Prefabs/InputManager.prefab&lt;/code&gt;を入れる。&lt;/p&gt;

&lt;p&gt;Managersの中にUI -&amp;gt; EventSystemを作成する。&lt;/p&gt;

&lt;p&gt;SparitalMappingする場合は、
&lt;code&gt;HoloToolkit/SpartialMapping/Prefabs/SpartialMapping.prefab&lt;/code&gt;をMangersに入れて
Editor -&amp;gt;　Project Settings -&amp;gt;　PlayerのPublishing Settingsから
SpartialPerceptionにチェックを入れる。&lt;/p&gt;

&lt;p&gt;HoloToolkitメニューからBuild Window -&amp;gt; Build Visual Studio SLNで
ビルドし、Open SLNでVisual Studioが立ち上がる。
ビルドの際にクラッシュしたらWindows Storeモジュールが入っているか確認する。&lt;/p&gt;

&lt;h2 id=&#34;実機での実行&#34;&gt;実機での実行&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/Using_Visual_Studio.html#deploying_an_app_over_wi-fi&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/Using_Visual_Studio.html#deploying_an_app_over_wi-fi&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Visual StudioでDeviceをHoloLens EmulatorからRemote Deviceに変更する。
HoloLensのIPアドレスはSettings -&amp;gt; Network &amp;amp; Internet -&amp;gt; Advanced Optionで確認して、
認証モードはユニバーサルにしてデバッグなしで開始する。&lt;/p&gt;

&lt;p&gt;PINコードを要求されるので、Settings -&amp;gt;Update &amp;amp; Security -&amp;gt; For developersから
Developer modeをonにし、その下のPaired devicesで表示されるPINコードを入力する。&lt;/p&gt;

&lt;h2 id=&#34;スクリーンショットの撮り方&#34;&gt;スクリーンショットの撮り方&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/using_mixed_reality_capture&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/using_mixed_reality_capture&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;カメラで撮れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/56-hololens2.jpg&#34; alt=&#34;実機で実行した画面&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;windows-device-portal&#34;&gt;Windows Device Portal&lt;/h2&gt;

&lt;p&gt;PCのブラウザからいろいろできるツール。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/Using_the_Windows_Device_Portal.html#mixed_reality_capture&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/Using_the_Windows_Device_Portal.html#mixed_reality_capture&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Settings -&amp;gt;Update &amp;amp; Security -&amp;gt; For developersからDevice Portalをonにすると
&lt;a href=&#34;https://HoloLensのIPアドレス&#34;&gt;https://HoloLensのIPアドレス&lt;/a&gt;
でアクセスできる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのrecord_transformerでログを加工する</title>
          <link>https://www.sambaiz.net/article/55/</link>
          <pubDate>Fri, 03 Feb 2017 21:14:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/55/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/filter_record_transformer&#34;&gt;http://docs.fluentd.org/v0.12/articles/filter_record_transformer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;追加したり、編集したり、削除したりできるフィルタ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;filter hoge.log&amp;gt;
  @type record_transformer
  enable_ruby
  auto_typecast true
  remove_keys b,d

  &amp;lt;record&amp;gt;
    what_is_tag ${tag}
    what_is_a ${record[&amp;quot;a&amp;quot;]}
    what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1}
  &amp;lt;/record&amp;gt;
&amp;lt;/filter&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この例だとタグを値に持つ&amp;rdquo;what_is_tag&amp;rdquo;、aを値に持つ&amp;rdquo;what_is_a&amp;rdquo;、b.cの値に1を足す&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;が追加され、
bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。&lt;/p&gt;

&lt;p&gt;auto_typecastをtrueにしないと&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;の値がstringになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: 1}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ tail /var/log/td-agent/td-agent.log
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーが起きるとnullになるが、それ以外の処理はされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: &amp;quot;error!&amp;quot;}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ tail /var/log/td-agent/td-agent.log
[warn]: failed to expand `record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1` error_class=TypeError error=&amp;quot;no implicit conversion of Fixnum into String&amp;quot;
...
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:null}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;フィルタ適用前と後をそれぞれoutputしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match hoge.log&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;
 
  &amp;lt;store&amp;gt;
    @type relabel
    @label @fuga
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;label @fuga&amp;gt;
  &amp;lt;filter hoge.log&amp;gt;
    @type record_transformer
    enable_ruby
    auto_typecast true
    remove_keys b,d
  
    &amp;lt;record&amp;gt;
      what_is_tag ${tag}
      what_is_a ${record[&amp;quot;a&amp;quot;]}
      what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1}
    &amp;lt;/record&amp;gt;
  &amp;lt;/filter&amp;gt;

  &amp;lt;match hoge.log&amp;gt;
    @type stdout
  &amp;lt;/match&amp;gt;
&amp;lt;/label&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;b&amp;quot;:{&amp;quot;c&amp;quot;:1},&amp;quot;d&amp;quot;:&amp;quot;fuga&amp;quot;}
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでElasticsearchに送る</title>
          <link>https://www.sambaiz.net/article/54/</link>
          <pubDate>Wed, 01 Feb 2017 21:51:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/54/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/uken/fluent-plugin-elasticsearch&#34;&gt;uken/fluent-plugin-elasticsearch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;必要なものをいれていく。Amazon LinuxのAMIから。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Failed to build gem native extension.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ yum install -y ruby-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;serverengine requires Ruby version &amp;gt;= 2.1.0.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/rbenv/rbenv&#34;&gt;rbenv&lt;/a&gt;でバージョンを上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv
$ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src
$ echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
$ ~/.rbenv/bin/rbenv init
$ echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
$ source ~/.bash_profile
$ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ rbenv -v
rbenv 1.1.0-2-g4f8925a
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Ruby install aborted due to missing extensions&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ yum install -y openssl-devel readline-devel zlib-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ rbenv install -l
1.8.5-p113
1.8.5-p114
1.8.5-p115
...

$ rbenv install 2.4.0
$ rbenv global 2.4.0
$ ruby -v
ruby 2.4.0p0 (2016-12-24 revision 57164) [x86_64-linux]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;td-agent.confはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type elasticsearch
  host *****
  port 9200
  index_name test_index
  type_name test_type
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ curl *****:9200/test_index/test_type/_search?pretty
{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVn5puy79PEDL_x5e_u3&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;a&amp;quot; : &amp;quot;b&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logstash formatでも入れてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type elasticsearch
  host *****
  port 9200
  logstash_format true
  logstash_prefix aaaa
  type_name test_type
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ curl *****:9200/aaaa-2017.02.02/_search?pretty
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;aaaa-2017.02.02&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVn_FyQP7q9Gyu5HC4Mq&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;a&amp;quot; : &amp;quot;b&amp;quot;,
          &amp;quot;@timestamp&amp;quot; : &amp;quot;2017-02-02T22:49:33+09:00&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;forwardと同じく
&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/buffer-plugin-overview&#34;&gt;Buffered Output plugin&lt;/a&gt;を
&lt;a href=&#34;https://github.com/uken/fluent-plugin-elasticsearch#buffered-output-options&#34;&gt;継承しているので&lt;/a&gt;
buffer_typeのデフォルトはmemory。必要ならfileにする。いずれにせよスパイクなどでbuffer_queue_limitを超えないように余裕をもっておく。
また、buffer_chunk_limitがElasticsearchのhttp.max_content_length(デフォルト100mb)を超えないようにする。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのnet/http.Client.Doの内部実装をたどったメモ</title>
          <link>https://www.sambaiz.net/article/53/</link>
          <pubDate>Mon, 30 Jan 2017 20:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/53/</guid>
          <description>

&lt;pre&gt;&lt;code&gt;package main

import (
        &amp;quot;fmt&amp;quot;
        &amp;quot;net/http&amp;quot;
        &amp;quot;io/ioutil&amp;quot;
)

var client = http.Client{}

func main() {

        req, err := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;http://example.com&amp;quot;, nil)
        if err != nil{
                panic(err)
        }

        resp, err := client.Do(req)
        if err != nil{
                panic(err)
        }
        defer resp.Body.Close()

        body, err := ioutil.ReadAll(resp.Body)
        if err != nil{
                panic(err)
        }

        fmt.Println(string(body))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;client&#34;&gt;Client&lt;/h3&gt;

&lt;p&gt;TransportがTCPコネクションをキャッシュするのでClientは使い回すべき。複数のgoroutineでコンカレントに使っても大丈夫。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Client struct {

        // nilならDefaultTransportが使われる        
    	Transport RoundTripper

        // nilなら10回で止まる
        CheckRedirect func(req *Request, via []*Request) error

        // nilならcookieは無視される
        Jar CookieJar

        Timeout time.Duration
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MaxIdleConnsとは別に、ホストごとの制限がある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/61/&#34;&gt;Goのnet/httpとKeep-Alive - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L39&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L39&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var DefaultTransport RoundTripper = &amp;amp;Transport{
	Proxy: ProxyFromEnvironment,
	DialContext: (&amp;amp;net.Dialer{
		Timeout:   30 * time.Second,
		KeepAlive: 30 * time.Second,
		DualStack: true,
	}).DialContext,
	MaxIdleConns:          100,
	IdleConnTimeout:       90 * time.Second,
	TLSHandshakeTimeout:   10 * time.Second,
	ExpectContinueTimeout: 1 * time.Second,
}

const DefaultMaxIdleConnsPerHost = 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;request&#34;&gt;Request&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/request.go#L690&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/request.go#L690&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewRequest(method, urlStr string, body io.Reader) (*Request, error) {
    ...
    
    u, err := url.Parse(urlStr)
    
    ...
    
    rc, ok := body.(io.ReadCloser)
    req := &amp;amp;Request{
            Method:     method,
            URL:        u,
            Proto:      &amp;quot;HTTP/1.1&amp;quot;,
            ProtoMajor: 1,
            ProtoMinor: 1,
            Header:     make(Header),
            Body:       rc,
            Host:       u.Host,
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;do&#34;&gt;Do&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L181&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L181&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Requestを渡してResponseを受け取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) Do(req *Request) (*Response, error) {
    method := valueOrDefault(req.Method, &amp;quot;GET&amp;quot;)
    if method == &amp;quot;GET&amp;quot; || method == &amp;quot;HEAD&amp;quot; {
        return c.doFollowingRedirects(req, shouldRedirectGet)
    }
    if method == &amp;quot;POST&amp;quot; || method == &amp;quot;PUT&amp;quot; {
        return c.doFollowingRedirects(req, shouldRedirectPost)
    }
    return c.send(req, c.deadline())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dofollowingredirects&#34;&gt;doFollowingRedirects&lt;/h3&gt;

&lt;p&gt;リクエストを送り、リダイレクトする場合はして、そうでない場合はレスポンスを返す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L440&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L440&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) doFollowingRedirects(req *Request, shouldRedirect func(int) bool) (*Response, error) {
    ...

    for{

        ...
        
        if resp, err = c.send(req, deadline); err != nil {
            if !deadline.IsZero() &amp;amp;&amp;amp; !time.Now().Before(deadline) {
                err = &amp;amp;httpError{
                    err:     err.Error() + &amp;quot; (Client.Timeout exceeded while awaiting headers)&amp;quot;,
                    timeout: true,
                }
            }
            return nil, uerr(err)
        }

        if !shouldRedirect(resp.StatusCode) {
            return resp, nil
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;send&#34;&gt;send&lt;/h3&gt;

&lt;p&gt;ClientのTransportのRoundTripを呼ぶ。ここからはTransport(RoundTripper)の仕事。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L140&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L140&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) send(req *Request, deadline time.Time) (*Response, error) {
    
    ...
    
    resp, err := send(req, c.transport(), deadline)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L208&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L208&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func send(ireq *Request, rt RoundTripper, deadline time.Time) (*Response, error) {
   
    ...
    
    resp, err := rt.RoundTrip(req)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;roundtrip&#34;&gt;RoundTrip&lt;/h3&gt;

&lt;p&gt;チャネルを通して接続先とやりとりする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L319&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L319&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (t *Transport) RoundTrip(req *Request) (*Response, error) {
    
    ...
    
    treq := &amp;amp;transportRequest{Request: req, trace: trace}
    
    ...
	
    cm, err := t.connectMethodForRequest(treq)
    pconn, err := t.getConn(treq, cm)
   
    ...
    
    resp, err = pconn.roundTrip(treq)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;writeとreadを同時に行っているのはサーバーがbodyのすべてを読む前にレスポンスを返すときのため。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L1823&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L1823&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (pc *persistConn) roundTrip(req *transportRequest) (resp *Response, err error) {
    
    ...
    
    pc.writech &amp;lt;- writeRequest{req, writeErrCh, continueCh} // pc.writeLoopで読まれる

    resc := make(chan responseAndError)
	pc.reqch &amp;lt;- requestAndChan{ // pc.readLoopで読まれる
		req:        req.Request,
		ch:         resc,
		addedGzip:  requestedGzip,
		continueCh: continueCh,
		callerGone: gone,
	}
    var re responseAndError
    
    ...
    
    case re = &amp;lt;-resc: // pc.readLoopで書き込まれる
		re.err = pc.mapRoundTripErrorFromReadLoop(req.Request, startBytesWritten, re.err)
		break WaitResponse
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pconn-getconn-dialconn&#34;&gt;pconn.getConn/dialConn&lt;/h3&gt;

&lt;p&gt;接続し、チャネルを読むループ(readLoop, writeLoop)を回す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L865&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L865&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (t *Transport) getConn(treq *transportRequest, cm connectMethod) (*persistConn, error) {
    ...
    type dialRes struct {
		pc  *persistConn
		err error
	}
    dialc := make(chan dialRes)
    
    ...
    
    go func() {
		pc, err := t.dialConn(ctx, cm)
		dialc &amp;lt;- dialRes{pc, err}
	}()
    
    ...
    
    select {
	case v := &amp;lt;-dialc:
        if v.pc != nil {
            
            ...
			
            return v.pc, nil
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L967&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L967&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (t *Transport) dialConn(ctx context.Context, cm connectMethod) (*persistConn, error) {
    pconn := &amp;amp;persistConn{
		t:             t,
		cacheKey:      cm.key(),
		reqch:         make(chan requestAndChan, 1), // roundTripで書かれて、readLoopで読まれる
		writech:       make(chan writeRequest, 1), // roundTripで書かれて、writeLoopで読まれる
		closech:       make(chan struct{}),
		writeErrCh:    make(chan error, 1),
		writeLoopDone: make(chan struct{}),
	}

    ...
    
    conn, err := t.dial(ctx, &amp;quot;tcp&amp;quot;, cm.addr())
	pconn.conn = conn
    
    ...
    
    go pconn.readLoop()
	go pconn.writeLoop()
	return pconn, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ライセンス&#34;&gt;ライセンス&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;Copyright (c) 2009 The Go Authors. All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

   * Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.
   * Redistributions in binary form must reproduce the above
copyright notice, this list of conditions and the following disclaimer
in the documentation and/or other materials provided with the
distribution.
   * Neither the name of Google Inc. nor the names of its
contributors may be used to endorse or promote products derived from
this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
&amp;quot;AS IS&amp;quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
          <link>https://www.sambaiz.net/article/52/</link>
          <pubDate>Sun, 29 Jan 2017 17:08:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/52/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;vm.max_map_count
(&lt;a href=&#34;http://www.atmarkit.co.jp/flinux/special/proctune/proctune02b.html&#34;&gt;バーチャルメモリにマッピングできる最大ページ数&lt;/a&gt;)
を262144以上にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sysctl vm.max_map_count
$ grep vm.max_map_count /etc/sysctl.conf
vm.max_map_count=262144
# sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-cap-add=IPC_LOCK&lt;/code&gt;でLock memory(スワップアウトしないようにする)を
&lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&#34;&gt;許可&lt;/a&gt;する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。
ただし、物理RAMの50%以下で、&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#compressed_oops&#34;&gt;32GB近辺の境界を超えないようにする&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p ~/do/elasticsearch/data
$ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \
--name elasticsearch \
-p 9200:9200 \
-e xpack.security.enabled=false \
-e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;quot;-Xms28g -Xmx28g&amp;quot; \
--cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \
--restart=always \
docker.elastic.co/elasticsearch/elasticsearch:5.1.2

$ docker volume ls
local               elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;問題なく起動しているか確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200 | jq
{
  &amp;quot;name&amp;quot;: &amp;quot;eqIkJ48&amp;quot;,
  &amp;quot;cluster_name&amp;quot;: &amp;quot;docker-cluster&amp;quot;,
  &amp;quot;cluster_uuid&amp;quot;: &amp;quot;Lsu_C7wORS6G-0m9PJ9sFQ&amp;quot;,
  &amp;quot;version&amp;quot;: {
    &amp;quot;number&amp;quot;: &amp;quot;5.1.2&amp;quot;,
    &amp;quot;build_hash&amp;quot;: &amp;quot;c8c4c16&amp;quot;,
    &amp;quot;build_date&amp;quot;: &amp;quot;2017-01-11T20:18:39.146Z&amp;quot;,
    &amp;quot;build_snapshot&amp;quot;: false,
    &amp;quot;lucene_version&amp;quot;: &amp;quot;6.3.0&amp;quot;
  },
  &amp;quot;tagline&amp;quot;: &amp;quot;You Know, for Search&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html&#34;&gt;dynamic mapping&lt;/a&gt;
を無効にする場合&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/_template/template_all?pretty&#39; -d&#39;
{
  &amp;quot;template&amp;quot;: &amp;quot;*&amp;quot;,
  &amp;quot;order&amp;quot;:0,
  &amp;quot;settings&amp;quot;: {
    &amp;quot;index.mapper.dynamic&amp;quot;: false 
  }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kuromojiを入れる場合&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec -it ***** bin/elasticsearch-plugin install analysis-kuromoji
$ docker restart  *****
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;grafanaで可視化する&#34;&gt;Grafanaで可視化する&lt;/h2&gt;

&lt;p&gt;前は&lt;a href=&#34;https://www.sambaiz.net/article/19/&#34;&gt;InfluxDBとつなげた&lt;/a&gt;が、Elasticsearchにも対応している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p /var/lib/grafana/plugins
$ docker run -itd --restart=always -p 3000:3000 -v grafana:/var/lib/grafana grafana/grafana
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.grafana.org/datasources/elasticsearch/&#34;&gt;http://docs.grafana.org/datasources/elasticsearch/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;admin/adminでログインして、data sourceを追加する。AccessはProxyにする。&lt;/p&gt;

&lt;p&gt;適当にデータを入れて表示してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/test_index?pretty&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;test_type&amp;quot;: { 
      &amp;quot;_all&amp;quot;:       { &amp;quot;enabled&amp;quot;: false  }, 
      &amp;quot;properties&amp;quot;: { 
        &amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot; },
        &amp;quot;age&amp;quot;:    { &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;  },
        &amp;quot;timestamp&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;epoch_millis&amp;quot; }
      }
    }
  }
}
&#39;

$ curl &#39;localhost:9200/_cat/indices?format=json&amp;amp;pretty&#39;
[
  {
    &amp;quot;health&amp;quot; : &amp;quot;yellow&amp;quot;,
    &amp;quot;status&amp;quot; : &amp;quot;open&amp;quot;,
    &amp;quot;index&amp;quot; : &amp;quot;test_index&amp;quot;,
    &amp;quot;uuid&amp;quot; : &amp;quot;kVbt2V-rS2m6vhplIkMKNg&amp;quot;,
    &amp;quot;pri&amp;quot; : &amp;quot;5&amp;quot;,
    &amp;quot;rep&amp;quot; : &amp;quot;1&amp;quot;,
    &amp;quot;docs.count&amp;quot; : &amp;quot;0&amp;quot;,
    &amp;quot;docs.deleted&amp;quot; : &amp;quot;0&amp;quot;,
    &amp;quot;store.size&amp;quot; : &amp;quot;260b&amp;quot;,
    &amp;quot;pri.store.size&amp;quot; : &amp;quot;260b&amp;quot;
  },
  ...
]

$ curl -XPOST &#39;localhost:9200/test_index/test_type?pretty&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;hoge fuga&amp;quot;,
    &amp;quot;age&amp;quot;: 24,
    &amp;quot;timestamp&amp;quot;: 1485676393044
}
&#39;

$ curl &#39;localhost:9200/test_index/test_type/_search?pretty&#39;
{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVnpOGrseo3fDHi0SK-P&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;name&amp;quot; : &amp;quot;hoge fuga&amp;quot;,
          &amp;quot;age&amp;quot; : 24,
          &amp;quot;timestamp&amp;quot; : 1485676393044
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/52.png&#34; alt=&#34;表示してみた&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのforward</title>
          <link>https://www.sambaiz.net/article/51/</link>
          <pubDate>Wed, 25 Jan 2017 22:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/51/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/high-availability#network-topology&#34;&gt;td-agent間でログをやりとりするとき&lt;/a&gt;
に使われるforwardについて。内部では&lt;a href=&#34;http://docs.fluentd.org/articles/in_forward#protocol&#34;&gt;MessagePackを使っている&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;forward-input&#34;&gt;forward input&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/in_forward&#34;&gt;http://docs.fluentd.org/articles/in_forward&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;受け取る側。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/etc/init.d/td-agent restart&lt;/code&gt;してfluent-catで送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat -h xx.xx.xx.xx test.tag
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/var/log/td-agent/td-agent.log&lt;/code&gt;に出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test.tag: {&amp;quot;hoge&amp;quot;:&amp;quot;fuga&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;forward-output&#34;&gt;forward output&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward&#34;&gt;http://docs.fluentd.org/articles/out_forward&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/buffer-plugin-overview&#34;&gt;http://docs.fluentd.org/articles/buffer-plugin-overview&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;送る側。&lt;/p&gt;

&lt;p&gt;ポートはデフォルトで24224で、イベントの送信にTCPを、heartbeatにUDP(heartbeat_typeで変えられる)を使う。&lt;/p&gt;

&lt;p&gt;flush_intervalははデフォルトで&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#flushinterval&#34;&gt;60秒&lt;/a&gt;。
確認のときは短くしておくと分かりやすい。
buffer_queueの一番上のチャンクがこの時間経過するか、サイズがbuffer_chunk_limitを超えると、一番下のチャンクが書き込まれ、新しいチャンクがpushされる。
chunkの数がbuffer_queue_limitに到達してしまうと新しいイベントは破棄されてしまうので
リソースを圧迫(buffer_chunk_limit * buffer_queue_limit)しない程度に十分大きな数にしておき、
スパイクや障害時に備えておく。
buffer_typeはデフォルトがmemory。fileだと&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#flushatshutdown&#34;&gt;flush_at_shutdownのデフォルトがfalse&lt;/a&gt;なので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type forward

  flush_interval 1s

  buffer_type file
  buffer_path /var/log/td-agent/forward-buf
  flush_at_shutdown true
  buffer_chunk_limit 256m

  &amp;lt;server&amp;gt;
    name log_server
    host xx.xx.xx.xx
    port 24224
  &amp;lt;/server&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;冗長化&#34;&gt;冗長化&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#ltservergt-at-least-one-is-required&#34;&gt;server&lt;/a&gt;は複数書くことができ、
それぞれにweight(デフォルトは60)を設定したり、
&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#standby&#34;&gt;standby&lt;/a&gt;を付けることでActive-Standbyの構成にすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type forward

  ...

  &amp;lt;server&amp;gt;
    name log_server
    host xx.xx.xx.xx
    port 24224
    weight 60
  &amp;lt;/server&amp;gt;

  &amp;lt;server&amp;gt;
    name log_server2
    host yy.yy.yy.yy
    port 24224
    weight 60
  &amp;lt;/server&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;片方のサーバーをtd-agentをstopしてstartしてみるとこんなログが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;detached forwarding server &#39;log_server2&#39; host=&amp;quot;yy.yy.yy.yy&amp;quot; port=24224 phi=16.06814271743242 phi_threshold=16
recovered forwarding server &#39;log_server2&#39; host=&amp;quot;yy.yy.yy.yy&amp;quot; port=24224
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみにtd-agentはrootで動かしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/sysconfig/td-agent 
TD_AGENT_USER=root
TD_AGENT_GROUP=root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/113/&#34;&gt;fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのinterface/structの埋め込み</title>
          <link>https://www.sambaiz.net/article/50/</link>
          <pubDate>Wed, 18 Jan 2017 01:39:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/50/</guid>
          <description>

&lt;p&gt;Goには継承が存在しない。その代わりstructを埋め込み、委譲することができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/doc/effective_go.html#embedding&#34;&gt;https://golang.org/doc/effective_go.html#embedding&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;挙動&#34;&gt;挙動&lt;/h2&gt;

&lt;h3 id=&#34;interfaceにinterfaceを埋め込む&#34;&gt;interfaceにinterfaceを埋め込む&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;type I interface {
	Hoge()
}

type J interface {
	Fuga()
}

type K interface {
	I
	J
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インタフェースKはIとJを合わせたものになる。IとJに重複する関数がある場合はエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type L struct {
}

func (l L) Hoge() {
	fmt.Println(&amp;quot;hoge&amp;quot;)
}
func (l L) Fuga() {
	fmt.Println(&amp;quot;fuga&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;var k K
k = L{}
k.Hoge()
k.Fuga()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;structにinterfaceを埋め込む&#34;&gt;structにinterfaceを埋め込む&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;type K interface {
	Hoge()
	Fuga()
}

type M struct {
	K
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;埋め込むと&lt;code&gt;m.Hoge()&lt;/code&gt;のように透過的にKを扱うことができるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m := M{L{}}
m.Hoge()
// m.K.Hoge() これでも呼べる
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;埋め込まないとこうなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type M struct {
	k K
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;m := M{L{}}
m.k.Hoge()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;structにstructを埋め込む&#34;&gt;structにstructを埋め込む&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;type A struct {
	name string
}

type B struct {
	A
}

func (a A) hoge() {
	fmt.Println(&amp;quot;hoge&amp;quot;, a.name)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上と同様、&lt;code&gt;b.name&lt;/code&gt;や、&lt;code&gt;b.hoge()&lt;/code&gt;のように扱える。
Aの関数も呼べて一見継承しているように見えるが、実際はAへの委譲となる。なのでhogeのレシーバーはA。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b := B{}
b.name = &amp;quot;a&amp;quot;
// b = B{A{name: &amp;quot;a&amp;quot;}} 
b.hoge()
// b.A.hoge()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、Bにもhogeを実装すると、&lt;code&gt;b.hoge()&lt;/code&gt;でこちらが呼ばれることになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b B) hoge() {
	fmt.Println(&amp;quot;fuga&amp;quot;, b.name)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;b := B{}
b.name = &amp;quot;piyo&amp;quot;
b.hoge() // =&amp;gt; fuga piyo
b.A.hoge() // =&amp;gt; hoge piyo
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;継承との違い&#34;&gt;継承との違い&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;type A struct {
	name string
}

type B struct {
	A
}

func (a A) hoge() {
	fmt.Println(&amp;quot;hoge&amp;quot;, a.name)
}

func (a A) fuga() {
	a.hoge()
}

// override?
func (b B) hoge() {
	fmt.Println(&amp;quot;fuga&amp;quot;, b.name)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もし、BがAを継承しているとするとb.fuga()内でhoge()を呼ぶと、オーバーライドした、Bをレシーバーとするhoge()が呼ばれ、&amp;rdquo;fuga&amp;rdquo;が出力されるはずだ。
しかし、fuga()のレシーバーはAなので、呼ばれるのはAをレシーバーとする方のhoge()となり、&amp;rdquo;hoge&amp;rdquo;が出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b := B{}
b.name = &amp;quot;piyo&amp;quot;
b.fuga() // =&amp;gt; hoge piyo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、type Aの変数にBを代入することもできない。&lt;/p&gt;

&lt;h2 id=&#34;用途を探る&#34;&gt;用途を探る&lt;/h2&gt;

&lt;h3 id=&#34;interfaceのデフォルト実装&#34;&gt;interfaceのデフォルト実装&lt;/h3&gt;

&lt;p&gt;interfaceのデフォルトの実装を用意したstructを埋めることで、各structでは差分だけを実装すればいいようにできる。
ただデフォルト実装が他のデフォルト実装の関数を呼んでいる場合、呼び先の関数だけ実装しても元々の関数の動作は変わらないので注意。
レシーバーを意識する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Student interface {
	Plus(x int, y int) int
	Minus(x int, y int) int
}

type defaultStudent struct{}

func (defaultStudent) Plus(x int, y int) int {
	return x + y
}

func (defaultStudent) Minus(x int, y int) int {
	return x - y
}

type BadStudent struct {
	defaultStudent
}

func (BadStudent) Minus(x int, y int) int {
	return 0
}

type GeniusStudent struct {
	defaultStudent
}

func (GeniusStudent) Plus(x int, y int) int {
	if ans, err := strconv.Atoi(fmt.Sprintf(&amp;quot;%d%d&amp;quot;, x, y)); err != nil {
		fmt.Errorf(&amp;quot;genius student fails to %d + %d&amp;quot;, x, y)
		return 0
	} else {
		return ans
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;publicな機能の追加&#34;&gt;Publicな機能の追加&lt;/h3&gt;

&lt;p&gt;Publicな関数を提供するstructを埋め込み、それを直接外からも呼べるようにする。&lt;/p&gt;

&lt;p&gt;試しに、&lt;code&gt;sync.RWMutex()&lt;/code&gt;を埋め込んでみた。これはゼロ値でロックしていない状態なので初期化する必要はない。
一見良さそうに見えるが、この例だとLockとUnlockは内側でのみ呼ぶことを想定していて、外からうっかり呼んでしまうとおかしなことになってしまうだめな例。まあでもこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Twin struct {
	num     int
	sameNum int
	sync.RWMutex
}

func (l *Twin) Set(n int) {
	l.Lock()
	l.num = n
	l.sameNum = n
	l.Unlock()
}

func (l *Twin) Check() (ok bool) {
	l.RLock()
	ok = l.num == l.sameNum
	l.RUnlock()
	return
}

func main() {

	twin := new(Twin)

	for i := 0; i &amp;lt; 1000; i++ {
		go twin.Set(i)
		if !twin.Check() {
			panic(&amp;quot;broken&amp;quot;)
		}
	}

	fmt.Println(&amp;quot;success&amp;quot;)

	twin.Unlock() // panic!
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;privateな共通処理をまとめる&#34;&gt;Privateな共通処理をまとめる&lt;/h3&gt;

&lt;p&gt;privateな共通処理を埋め込むことでDRYに書けるように試みる。&lt;/p&gt;

&lt;p&gt;まず、状態を持たないような処理の場合。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (defaultStudent) hoge() bool {
	return true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これはパッケージが適切に切られていれば&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func hoge() bool {
	return true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と変わらず、埋め込む必要はないと思う。埋め込むとレシーバーから補完が効いて探しやすいかもしれないけれど。&lt;/p&gt;

&lt;p&gt;一方、状態を持つような処理の場合。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (n defaultStudent) counter() int {
    n.counter += 1
    return n.counter
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは埋め込むか、明示的にフィールドを持つかのどちらかになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type BadStudent struct {
	defaultStudent
}

or 

type BadStudent struct {
	d defaultStudent
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回の場合、defaultStudentにPublicなデフォルト実装があってそれを使うので埋め込んだ方が自然なような気もするけど、
そうでなければ埋め込まない方が移譲していることが分かりやすいと思う。せいぜい数文字増えるだけだし。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/sonatard/items/2b4b70694fd680f6297c&#34;&gt;オブジェクト指向言語としてGolangをやろうとするとハマる点を整理してみる - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのpanicとrecover</title>
          <link>https://www.sambaiz.net/article/49/</link>
          <pubDate>Tue, 17 Jan 2017 23:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/49/</guid>
          <description>

&lt;h2 id=&#34;panic&#34;&gt;panic&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/builtin/#panic&#34;&gt;https://golang.org/pkg/builtin/#panic&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;panicは現在のgoroutineの通常の実行を停止する組み込み関数。
&lt;a href=&#34;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/runtime/panic.go#L26&#34;&gt;index out of range&lt;/a&gt;や
&lt;a href=&#34;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/runtime/panic.go#L61&#34;&gt;invalid memory address or nil pointer dereference&lt;/a&gt;
のときなどでも呼ばれる。&lt;/p&gt;

&lt;p&gt;deferを実行して呼び出し元に戻り、panicの実行-&amp;gt;deferの実行-&amp;gt;呼び出し元に戻る、を繰り返して
最後まで戻ったらプログラムを終了し、panicに渡した引数と共にエラーをレポートする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	a()
}

func a() {
	defer fmt.Println(&amp;quot;a&amp;quot;)
	b()
	fmt.Println(&amp;quot;a2&amp;quot;)
}

func b() {
	defer fmt.Println(&amp;quot;b1&amp;quot;)
	panic(&amp;quot;b2&amp;quot;)
	defer fmt.Println(&amp;quot;b3&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;b1
a
panic: b2

goroutine 1 [running]:
panic(0x89840, 0xc42000a2c0)
	/*****/libexec/src/runtime/panic.go:500 +0x1a1
main.b()
	/*****/main.go:19 +0x107
main.a()
	/*****/main.go:13 +0xce
main.main()
	/*****/main.go:8 +0x14
exit status 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;recover&#34;&gt;recover&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/builtin/#recover&#34;&gt;https://golang.org/pkg/builtin/#recover&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;deferで呼ぶことによってpanicを停止させることができる組み込み関数。
panicの引数に渡した値を取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	fmt.Println(a())
	fmt.Println(&amp;quot;main&amp;quot;)
}

func a() (ret string) {
	defer func() {
		if err := recover(); err != nil {
			fmt.Println(&amp;quot;recover -&amp;gt;&amp;quot;, err)
			ret = &amp;quot;panicked&amp;quot;
		}
	}()
	b()
	fmt.Println(&amp;quot;a2&amp;quot;)
	return &amp;quot;ok&amp;quot;
}

func b() {
	defer fmt.Println(&amp;quot;b1&amp;quot;)
	panic(&amp;quot;b2&amp;quot;)
	defer fmt.Println(&amp;quot;b3&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;b1
recover -&amp;gt; b2
panicked
main
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常はpanicもrecoverもあまり使わず、errorを返すことでハンドリングする。&lt;/p&gt;

&lt;p&gt;ではどんな時に使われるかというと、例えばWebフレームワーク&lt;a href=&#34;https://github.com/labstack/echo&#34;&gt;echo&lt;/a&gt;のRecover middlewareは
panicをrecoverしてinternal server errorとしてレスポンスを返すようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/labstack/echo/blob/a96c564fc34b3fcbc5a1a67eeb9402243cdac6b2/middleware/recover.go#L66&#34;&gt;https://github.com/labstack/echo/blob/a96c564fc34b3fcbc5a1a67eeb9402243cdac6b2/middleware/recover.go#L66&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/labstack/echo/blob/54fb1015c1a51aed1c8e5ef6bf9e643b1a079acb/context.go#L525&#34;&gt;https://github.com/labstack/echo/blob/54fb1015c1a51aed1c8e5ef6bf9e643b1a079acb/context.go#L525&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/labstack/echo/blob/b2c623b07dd1362011f2677147ffbbe48ea3b178/echo.go#L284&#34;&gt;https://github.com/labstack/echo/blob/b2c623b07dd1362011f2677147ffbbe48ea3b178/echo.go#L284&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
        // Echo instance
        e := echo.New()

        // Middleware
        e.Use(middleware.Logger())
        e.Use(middleware.Recover())

        // Route =&amp;gt; handler
        e.GET(&amp;quot;/&amp;quot;, func(c echo.Context) error {
                panic(&amp;quot;fail&amp;quot;)
                return c.String(http.StatusOK, &amp;quot;Hello, World!\n&amp;quot;)
        })

        // Start server
        e.Logger.Fatal(e.Start(&amp;quot;:1323&amp;quot;))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;message&amp;quot;:&amp;quot;Internal Server Error&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ではRecover middlewareを使わなかったらアプリケーションが終了するかというと、
net/httpのserveでもrecoverしてるのでここでひっかかる(レスポンスは返らない)。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/net/http/server.go#L2625&#34;&gt;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/net/http/server.go#L2625&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/net/http/server.go#L1718&#34;&gt;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/net/http/server.go#L1718&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo: http: panic serving [::1]:53992: AA
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/defer-panic-and-recover&#34;&gt;Defer, Panic, and Recover - The Go Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OAuth2.0のメモ</title>
          <link>https://www.sambaiz.net/article/48/</link>
          <pubDate>Sun, 08 Jan 2017 02:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/48/</guid>
          <description>

&lt;h2 id=&#34;認可-authorization-と認証-authentication&#34;&gt;認可(Authorization)と認証(Authentication)&lt;/h2&gt;

&lt;p&gt;それぞれAuthZ、AuthNとも書かれる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;認可: リソースへのアクセスを許可する&lt;/li&gt;
&lt;li&gt;認証: ユーザーが何者かを検証する&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;oauth-2-0&#34;&gt;OAuth 2.0&lt;/h2&gt;

&lt;p&gt;認可のプロトコル。
それによってアクセスできるようになったリソースの情報をもとに認証を行ったりすることもあるが、
以下に示すImplicit Flowでそれをやると他のサービスのトークンで他人に成りすませてしまう問題があるため、
認証する場合はOAuth 2.0ベースの認証プロトコルのOpenID Connectを使うべき。
その場合もトークンを取得するまでの流れはほとんどOAuth 2.0通りなのでフローを理解しておいて無駄はない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/136/&#34;&gt;OpenID ConnectのIDトークンの内容と検証 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;authorization-code-flow&#34;&gt;Authorization Code Flow&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/48_authcode.png&#34; alt=&#34;シーケンス図&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OAuthクライアントがアプリケーションサーバーのときのフロー。&lt;/p&gt;

&lt;p&gt;まずユーザーがOAuth認可ページで認可する。
このリクエストには&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;client_id&lt;/li&gt;
&lt;li&gt;redirect_uri&lt;/li&gt;
&lt;li&gt;scope: アクセスできるリソースの種類&lt;/li&gt;
&lt;li&gt;response_type=code: 認可コードが返される&lt;/li&gt;
&lt;li&gt;state: CSRFを防ぐためのランダムで一意な文字列。アプリケーションサーバーが保持して、前後で一致するかチェックする&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;が含まれる。&lt;/p&gt;

&lt;p&gt;認可されると認可コードとstateを付けてredirect_uri(&lt;a href=&#34;https://tools.ietf.org/html/rfc6749#section-3.1.2.2&#34;&gt;事前に登録しておく&lt;/a&gt;)にリダイレクトするので、
アプリケーションサーバーは認可コードをアクセストークンに交換する。
この際、client_idとclient_secretも送る。&lt;/p&gt;

&lt;p&gt;オプションでリフレッシュトークンを含み、これを使うと期限が切れたとき新しいアクセストークンを取得できる。&lt;/p&gt;

&lt;p&gt;アクセストークンは通常Bearer Token(Authorization: Bearer ***)としてリクエストに含まれる。&lt;/p&gt;

&lt;h3 id=&#34;implicit-flow&#34;&gt;Implicit Flow&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/48_implicit.png&#34; alt=&#34;シーケンス図&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OAuthクライアントがアプリなどでclient_secretの機密性を保てない場合のフロー。&lt;/p&gt;

&lt;p&gt;認可コードは不要なので&lt;code&gt;response_type=token&lt;/code&gt;でリクエストし、アクセストークンをブラウザで取得する。
リフレッシュトークンは含まない。
他のサービスで発行された他人のトークンを使うことでなりすませてしまうので、
そのトークンがどのサービスに対して発行されたかを確認する術が特に用意されているのでなければ
認証に使ってはいけない。OpenID Connectでは署名されたIDトークンに発行されたサービスの情報が含まれている。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873115580/&#34;&gt;O&amp;rsquo;Reilly Japan - OAuth 2.0をはじめよう&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://oauth.jp/blog/2014/05/07/covert-redirect-in-implicit-flow/&#34;&gt;Implicit Flow では Covert Redirect で Token 漏れるね - OAuth.jp&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる</title>
          <link>https://www.sambaiz.net/article/47/</link>
          <pubDate>Wed, 04 Jan 2017 23:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/47/</guid>
          <description>&lt;p&gt;この関数のベンチマークを取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package cal

import (
	&amp;quot;math/big&amp;quot;
)

var cache = map[int]*big.Int{}

func resetCache() {
	cache = map[int]*big.Int{}
}

func Fibonacci(n int) *big.Int {

	if c := cache[n]; c != nil {
		return c
	}

	ret := new(big.Int)
	before := big.NewInt(1)
	for i := 1; i &amp;lt; n; i++ {
		tmp := new(big.Int).Add(ret, before)
		before = ret
		ret = tmp
		cache[i] = ret
	}
	cache[n] = ret
	return ret
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;引数にtesting.Bを取る、Benchmarkから始まる関数を書いて、b.N回ループさせる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package cal

import (
	&amp;quot;math/big&amp;quot;
	&amp;quot;testing&amp;quot;
)

func TestFibonacci(t *testing.T) {
	if f := Fibonacci(10); f.String() != big.NewInt(34).String() {
		t.Errorf(&amp;quot;%d != %d (expected)&amp;quot;, f, big.NewInt(34))
	}
}

func BenchmarkFibonacci(b *testing.B) {
	for i := 0; i &amp;lt; b.N; i++ {
		b.StopTimer()
		resetCache()
		b.StartTimer()
		Fibonacci(100)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;code&gt;go test -bench&lt;/code&gt;で実行するとベンチマークが取れる。さらに&lt;code&gt;-benchmem&lt;/code&gt;を付けるとメモリアロケーションの情報も出る。
また、&lt;code&gt;-cpuprofile&lt;/code&gt;でCPUのプロファイルを出力し、pprofに渡すことでどの部分で時間がかかっているかを調べることができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/cmd/go/#hdr-Description_of_testing_flags&#34;&gt;https://golang.org/cmd/go/#hdr-Description_of_testing_flags&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench Fibonacci -benchmem -o pprof/test.bin  -cpuprofile pprof/cpu.out ./cal
BenchmarkFibonacci-4   	   50000	     32788 ns/op	   13344 B/op	     211 allocs/op
PASS
ok  	github.com/sambaiz/try-pprof/cal	3.406s

$ go tool pprof --text pprof/test.bin pprof/cpu.out
3.80s of 3.83s total (99.22%)
Dropped 17 nodes (cum &amp;lt;= 0.02s)
      flat  flat%   sum%        cum   cum%
     2.31s 60.31% 60.31%      2.31s 60.31%  runtime.mach_semaphore_signal
     0.38s  9.92% 70.23%      0.38s  9.92%  runtime.mach_semaphore_timedwait
     0.32s  8.36% 78.59%      0.32s  8.36%  runtime.mach_semaphore_wait
     0.27s  7.05% 85.64%      0.27s  7.05%  runtime.usleep
     0.14s  3.66% 89.30%      0.14s  3.66%  runtime.deductSweepCredit
     0.09s  2.35% 91.64%      0.28s  7.31%  runtime.mallocgc
     0.04s  1.04% 92.69%      0.14s  3.66%  runtime.mapassign1
     0.04s  1.04% 93.73%      0.05s  1.31%  runtime.updatememstats
     0.03s  0.78% 94.52%      0.13s  3.39%  math/big.nat.add
     0.03s  0.78% 95.30%      0.03s  0.78%  runtime.aeshash64
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;graphvizをインストールすることでsvgのグラフを出すこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install graphviz
$ go tool pprof --svg pprof/test.bin pprof/cpu.out &amp;gt; pprof/test.svg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/47.png&#34; alt=&#34;svgで出力したもの&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/238/&#34;&gt;Goのnet/http/pprofでCPUやMemoryをprofileする流れと内部実装 - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>汎用シリアライズ方法(MessagePack/Protocol Buffers/FlatBuffers)</title>
          <link>https://www.sambaiz.net/article/46/</link>
          <pubDate>Fri, 30 Dec 2016 18:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/46/</guid>
          <description>

&lt;h2 id=&#34;messagepack-http-msgpack-org-とは&#34;&gt;&lt;a href=&#34;http://msgpack.org/&#34;&gt;MessagePack&lt;/a&gt;とは&lt;/h2&gt;

&lt;p&gt;JSONのように使うことができ、速くてサイズが小さい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;compact&amp;quot;:true,&amp;quot;スキーマ&amp;quot;:{&amp;quot;number&amp;quot;: 999, &amp;quot;string&amp;quot;: &amp;quot;aaa&amp;quot;}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;のjson(61bytes)をMessagePack(45bytes)に変換したのがこれ。見やすいように改行している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;82 
a7 63 6f 6d 70 61 63 74 c3 
ac e3 82 b9 e3 82 ad e3 83 bc e3 83 9e 
   82 
   a6 6e 75 6d 62 65 72 cd 03 e7 
   a6 73 74 72 69 6e 67 a3 61 61 61
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一行目の&lt;code&gt;82&lt;/code&gt;は&lt;a href=&#34;https://github.com/msgpack/msgpack/blob/master/spec.md#map-format-family&#34;&gt;要素数2のfixmap(要素数15まで)&lt;/a&gt;を表す。&lt;/p&gt;

&lt;p&gt;二行目の&lt;code&gt;a7&lt;/code&gt;が&lt;a href=&#34;https://github.com/msgpack/msgpack/blob/master/spec.md#str-format-family&#34;&gt;7バイトのfixstr(31bytesまで)&lt;/a&gt;で、
&lt;code&gt;63 6f 6d 70 61 63 74&lt;/code&gt;が&amp;rdquo;compact&amp;rdquo;。&lt;code&gt;c3&lt;/code&gt;は&lt;a href=&#34;https://github.com/msgpack/msgpack/blob/master/spec.md#bool-format-family&#34;&gt;true&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;三行目の&lt;code&gt;ac&lt;/code&gt;は12バイトのfixstrで、&lt;code&gt;e3 82 b9 e3 82 ad e3 83 bc e3 83 9e&lt;/code&gt;が&amp;rdquo;スキーマ&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;四行目はこれのvalueで、要素数2のfixmap(&lt;code&gt;82&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;五行目は6バイトのfixstr(&lt;code&gt;a6&lt;/code&gt;)、&amp;rdquo;number&amp;rdquo;(&lt;code&gt;6e 75 6d 62 65 72&lt;/code&gt;)、
&lt;code&gt;cd&lt;/code&gt;が&lt;a href=&#34;https://github.com/msgpack/msgpack/blob/master/spec.md#int-format-family&#34;&gt;uint16&lt;/a&gt;で、999(&lt;code&gt;03 e7&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;六行目は6バイトのfixstr(&lt;code&gt;a6&lt;/code&gt;)、&amp;rdquo;string&amp;rdquo;(&lt;code&gt;73 74 72 69 6e 67&lt;/code&gt;)、3バイトのfixstr(&lt;code&gt;a3&lt;/code&gt;)、&amp;rdquo;aaa&amp;rdquo;(&lt;code&gt;61 61 61&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;と、こんな感じで分かりやすいバイナリになっている。文字列が多いとあまりサイズが変わらない。&lt;/p&gt;

&lt;h3 id=&#34;使い方&#34;&gt;使い方&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/ugorji/go/codec
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mh := codec.MsgpackHandle{RawToString: true}
origin := serialize.Data{
	Title: &amp;quot;aaaa&amp;quot;,
}

func MessagePackEncode(mh codec.MsgpackHandle, origin Data) []byte {
	var encoded []byte

	enc := codec.NewEncoderBytes(&amp;amp;encoded, &amp;amp;mh)
	if err := enc.Encode(&amp;amp;origin); err != nil {
		panic(err)
	}

	return encoded
}

func MessagePackDecode(mh codec.MsgpackHandle, bytes []byte) Data {
	var decoded Data

	dec := codec.NewDecoderBytes(bytes, &amp;amp;mh)
	if err := dec.Decode(&amp;amp;decoded); err != nil {
		panic(err)
	}

	return decoded
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;protocol-buffers-https-developers-google-com-protocol-buffers-とは&#34;&gt;&lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol Buffers&lt;/a&gt;とは&lt;/h2&gt;

&lt;p&gt;Googleのシリアライズライブラリ。gRPCでも使われる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/12/&#34;&gt;Googleが作ったRPCフレームワークgRPCを使ってみた&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;message typeを&lt;code&gt;proto&lt;/code&gt;ファイルで定義する(proto3)。このファイルから各言語のコードを生成することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;syntax = &amp;quot;proto3&amp;quot;;

message SearchResponse {
  repeated Result results = 1;
}

message Result {
  string url = 1;
  string title = 2;
  repeated string snippets = 3;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それぞれのmessage typeには名前と型を持つユニークな数値のフィールドが含まれる。一度割り当てた数値のtypeは変更しないようにする。
&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#assigning-tags&#34;&gt;(Assigning Tags)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;repeated&lt;/code&gt;は0以上の任意の個数で、順番は保存される。
&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#specifying-field-rules&#34;&gt;(Specifying Field Rules)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;新しいコードがフィールドを追加してメッセージを送ると、古いコードは未知のフィールドを無視する。
逆に、古いコードがメッセージを送ると、
新しいコードの新しいフィールドには&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#default&#34;&gt;デフォルト値&lt;/a&gt;が入る。
&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#updating&#34;&gt;(Updating A Message Type)&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;使い方-1&#34;&gt;使い方&lt;/h3&gt;

&lt;p&gt;protoファイル。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;syntax = &amp;quot;proto3&amp;quot;;

message Data {
  string title = 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;goのコードを生成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install protobuf
$ protoc --version
libprotoc 3.1.0

$ go get github.com/golang/protobuf/protoc-gen-go

$ mkdir -p build/gen 
$ protoc --proto_path=proto --go_out=data proto/data.proto
$ ls data
data.pb.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;生成されたコード。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Code generated by protoc-gen-go.
// source: data.proto
// DO NOT EDIT!

/*
Package data is a generated protocol buffer package.

It is generated from these files:
	data.proto

It has these top-level messages:
	Data
*/
package data

import proto &amp;quot;github.com/golang/protobuf/proto&amp;quot;
import fmt &amp;quot;fmt&amp;quot;
import math &amp;quot;math&amp;quot;

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

type Data struct {
	Title string `protobuf:&amp;quot;bytes,1,opt,name=title&amp;quot; json:&amp;quot;title,omitempty&amp;quot;`
}

func (m *Data) Reset()                    { *m = Data{} }
func (m *Data) String() string            { return proto.CompactTextString(m) }
func (*Data) ProtoMessage()               {}
func (*Data) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }

func init() {
	proto.RegisterType((*Data)(nil), &amp;quot;Data&amp;quot;)
}

func init() { proto.RegisterFile(&amp;quot;data.proto&amp;quot;, fileDescriptor0) }

var fileDescriptor0 = []byte{
	// 67 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x09, 0x6e, 0x88, 0x02, 0xff, 0xe2, 0xe2, 0x4a, 0x49, 0x2c, 0x49,
	0xd4, 0x2b, 0x28, 0xca, 0x2f, 0xc9, 0x57, 0x92, 0xe1, 0x62, 0x71, 0x49, 0x2c, 0x49, 0x14, 0x12,
	0xe1, 0x62, 0x2d, 0xc9, 0x2c, 0xc9, 0x49, 0x95, 0x60, 0x54, 0x60, 0xd4, 0xe0, 0x0c, 0x82, 0x70,
	0x92, 0xd8, 0xc0, 0x8a, 0x8c, 0x01, 0x01, 0x00, 0x00, 0xff, 0xff, 0xf5, 0x0d, 0xbe, 0x9b, 0x32,
	0x00, 0x00, 0x00,
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/golang/protobuf/proto
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func ProtoBufEncode(origin data.Data) []byte {
	encoded, err := proto.Marshal(&amp;amp;origin)
	if err != nil {
		panic(err)
	}

	return encoded
}

func ProtoBufDecode(bytes []byte) data.Data {
	var decoded data.Data
	if err := proto.Unmarshal(bytes, &amp;amp;decoded); err != nil {
		panic(err)
	}

	return decoded
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;flatbuffers-http-google-github-io-flatbuffers&#34;&gt;&lt;a href=&#34;http://google.github.io/flatbuffers/&#34;&gt;FlatBuffers&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Googleの、ゲームなどパフォーマンスを要求するアプリケーションのためのシリアライズライブラリ。
データにアクセスする前にparseやunpackする必要がなく、オブジェクトごとのメモリ割り当てが必要。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;proto&lt;/code&gt;の代わりにこんな&lt;code&gt;schema&lt;/code&gt;ファイルを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace MyGame.Sample;
enum Color:byte { Red = 0, Green, Blue = 2 }
union Equipment { Weapon } // Optionally add more tables.
struct Vec3 {
  x:float;
  y:float;
  z:float;
}
table Monster {
  pos:Vec3; // Struct.
  mana:short = 150;
  hp:short = 100;
  name:string;
  friendly:bool = false (deprecated);
  inventory:[ubyte];  // Vector of scalars.
  color:Color = Blue; // Enum.
  weapons:[Weapon];   // Vector of tables.
  equipped:Equipment; // Union.
}
table Weapon {
  name:string;
  damage:short;
}
root_type Monster;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使い方-2&#34;&gt;使い方&lt;/h3&gt;

&lt;p&gt;schemaファイル。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace dataf;

table Data {
    title:string;
}

root_type Data;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;goのコードを生成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install flatbuffers

$ flatc --go fbs/dataf.fbs
$ ls dataf/
data.go

$ go get github.com/google/flatbuffers/go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;生成されたコード。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// automatically generated by the FlatBuffers compiler, do not modify

package dataf

import (
	flatbuffers &amp;quot;github.com/google/flatbuffers/go&amp;quot;
)

type data struct {
	_tab flatbuffers.Table
}

func GetRootAsdata(buf []byte, offset flatbuffers.UOffsetT) *data {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &amp;amp;data{}
	x.Init(buf, n+offset)
	return x
}

func (rcv *data) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *data) Title() []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.ByteVector(o + rcv._tab.Pos)
	}
	return nil
}

func dataStart(builder *flatbuffers.Builder) {
	builder.StartObject(1)
}
func dataAddTitle(builder *flatbuffers.Builder, title flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(title), 0)
}
func dataEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://rwinslow.com/posts/use-flatbuffers-in-golang/&#34;&gt;Tutorial: Use FlatBuffers in Go · Robert Winslow&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GoogleのkvsライブラリLevelDBを使う</title>
          <link>https://www.sambaiz.net/article/45/</link>
          <pubDate>Sat, 24 Dec 2016 21:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/45/</guid>
          <description>

&lt;h2 id=&#34;leveldbとは&#34;&gt;LevelDBとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/google/leveldb&#34;&gt;https://github.com/google/leveldb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Googleが作った高速なkey-valueストレージライブラリ。&lt;/p&gt;

&lt;p&gt;ChromeのIndexedDBや&lt;a href=&#34;https://prometheus.io/docs/operating/storage/&#34;&gt;prometheus&lt;/a&gt;などで使われている。&lt;/p&gt;

&lt;h3 id=&#34;特徴-https-github-com-google-leveldb-features&#34;&gt;&lt;a href=&#34;https://github.com/google/leveldb#features&#34;&gt;特徴&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Keyと任意のバイト配列のValue&lt;/li&gt;
&lt;li&gt;データはKeyでソートされる。ソートのための比較関数はオーバーライドできる。&lt;/li&gt;
&lt;li&gt;基本的な操作はPut, Get, Delete。&lt;/li&gt;
&lt;li&gt;複数の変更を一つのatomicなバッチで行える&lt;/li&gt;
&lt;li&gt;一環したデータのビューを取得するために、一時的なスナップショットを作成できる&lt;/li&gt;
&lt;li&gt;データを前にも後ろにもイテレーションできる&lt;/li&gt;
&lt;li&gt;データは&lt;a href=&#34;http://google.github.io/snappy/&#34;&gt;Snappy compression library&lt;/a&gt;で自動で圧縮される。&lt;/li&gt;
&lt;li&gt;ファイルシステムの操作など外部のアクティビティを仮想的なインタフェースを通して行うので、OSとのやりとりをカスタマイズできる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;制限-https-github-com-google-leveldb-limitations&#34;&gt;&lt;a href=&#34;https://github.com/google/leveldb#limitations&#34;&gt;制限&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;SQLデータベースではない。リレーショナルなデータモデルは持てないし、SQLやインデックスにも対応していない。&lt;/li&gt;
&lt;li&gt;一度に一つのプロセスしかDBにアクセスできない。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;キャッシュ-https-rawgit-com-google-leveldb-master-doc-index-html&#34;&gt;&lt;a href=&#34;https://rawgit.com/google/leveldb/master/doc/index.html&#34;&gt;キャッシュ&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;DBはファイルシステムのディレクトリに対応する名前を持ち、内容はそのディレクトリに保存される。&lt;/li&gt;
&lt;li&gt;各ファイルには圧縮したブロックが保存され、良く使うものについては非圧縮のブロックがキャッシュされる。&lt;/li&gt;
&lt;li&gt;ソートして隣接するキーは通常、同じブロックに配置される。ディスク転送とキャッシュはブロック単位。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;フィルタ&#34;&gt;フィルタ&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Getの際、不要なデータを読まなくていいようにフィルタ(Bloom Filter)を用いることができる。&lt;/li&gt;
&lt;li&gt;独自の比較関数(末尾のスペースを無視するなど)を使う場合、Bloom Filterを使うことができないことがあるので、その場合は独自のフィルタが必要。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;レベル-https-rawgit-com-google-leveldb-master-doc-impl-html&#34;&gt;&lt;a href=&#34;https://rawgit.com/google/leveldb/master/doc/impl.html&#34;&gt;レベル&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;最近の更新はログファイルに保存される。これが決められたサイズ(デフォルトでは約4MB)に達すると、sorted table(sst)に変換され、新しいログファイルが生成される。&lt;/li&gt;
&lt;li&gt;現在のログファイルのコピーがメモリ(memtable)にも乗って読み取りで参照される。&lt;/li&gt;
&lt;li&gt;sstはキーによってソートされたエントリーを保存する。エントリーはキーの値か、削除マーカー。&lt;/li&gt;
&lt;li&gt;sstはレベルによってまとめられる。ログファイルから変換されると、特別なyoungレベル(level-0とも呼ばれる)に配置される。&lt;/li&gt;
&lt;li&gt;youngファイルの数があるしきい値(現在4つ)を超えると全てのyoungファイルを全てのlevel-1ファイルとマージし、新しいlevel-1ファイルを生成する(2MBごとに1ファイル)。&lt;/li&gt;
&lt;li&gt;youngレベルのファイルにはキーが重複していることがある。しかし、他のレベルでは重複しないキーの範囲がある。&lt;/li&gt;
&lt;li&gt;level-L(L&amp;gt;=1)のファイルの合計サイズが&lt;code&gt;10^L MB&lt;/code&gt;を超えたとき、level-Lのファイルと、level-(L+1)の全てのファイルをマージし、新しいlevel-(L+1)ファイルを生成する。&lt;/li&gt;
&lt;li&gt;これによって、バルク読み込み/書き込みのみを使い、コストが高いシークを最小限にして、youngレベルから大きいレベルに更新を徐々にマイグレーションすることができる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;動かしてみる&#34;&gt;動かしてみる&lt;/h2&gt;

&lt;p&gt;LevelDBのgo実装。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/syndtr/goleveldb&#34;&gt;syndtr/goleveldb&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/syndtr/goleveldb/leveldb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずDBを開く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// open
db, err := leveldb.OpenFile(&amp;quot;/Users/sambaiz/leveldb&amp;quot;, nil)
defer db.Close()
if err != nil {
    panic(err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;普通に5個(key0~4)、バッチで5個(key5~9)のデータを入れて、そのうち一つを消す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// put
for i := 0; i &amp;lt; 5; i++ {
    if err = db.Put([]byte(fmt.Sprintf(&amp;quot;key%d&amp;quot;, i)), []byte(fmt.Sprintf(&amp;quot;value%d&amp;quot;, i)), nil); err != nil {
        panic(err)
    }
}

// batch
batch := new(leveldb.Batch)
for i := 5; i &amp;lt; 10; i++ {
    batch.Put([]byte(fmt.Sprintf(&amp;quot;key%d&amp;quot;, i)), []byte(fmt.Sprintf(&amp;quot;value%d&amp;quot;, i)))
}
if err = db.Write(batch, nil); err != nil{
    panic(err)
}

// delete
if err = db.Delete([]byte(&amp;quot;key2&amp;quot;), nil); err != nil {
    panic(err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この時点でこんなファイルが生成され、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls
000001.log	CURRENT		LOCK		LOG		MANIFEST-000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;000001.logの中身はこんな感じになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ od -c 000001.log 
0000000    Z 221   @ 300 031  \0 001 001  \0  \0  \0  \0  \0  \0  \0 001
0000020   \0  \0  \0 001 004   k   e   y   0 006   v   a   l   u   e   0
0000040    o 037   = 373 031  \0 001 002  \0  \0  \0  \0  \0  \0  \0 001
0000060   \0  \0  \0 001 004   k   e   y   1 006   v   a   l   u   e   1
0000100  256 343   &amp;gt; 311 031  \0 001 003  \0  \0  \0  \0  \0  \0  \0 001
0000120   \0  \0  \0 001 004   k   e   y   2 006   v   a   l   u   e   2
0000140    = 006 330 341 031  \0 001 004  \0  \0  \0  \0  \0  \0  \0 001
0000160   \0  \0  \0 001 004   k   e   y   3 006   v   a   l   u   e   3
0000200  002 005   4 016 031  \0 001 005  \0  \0  \0  \0  \0  \0  \0 001
0000220   \0  \0  \0 001 004   k   e   y   4 006   v   a   l   u   e   4
0000240    d 240 344   {   M  \0 001 006  \0  \0  \0  \0  \0  \0  \0 005
0000260   \0  \0  \0 001 004   k   e   y   5 006   v   a   l   u   e   5
0000300  001 004   k   e   y   6 006   v   a   l   u   e   6 001 004   k
0000320    e   y   7 006   v   a   l   u   e   7 001 004   k   e   y   8
0000340  006   v   a   l   u   e   8 001 004   k   e   y   9 006   v   a
0000360    l   u   e   9   ! 233 277 371 022  \0 001  \v  \0  \0  \0  \0
0000400   \0  \0  \0 001  \0  \0  \0  \0 004   k   e   y   2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;取得するにはkeyを指定して&lt;code&gt;Get()&lt;/code&gt;したり、Iteratorを使う。
IteratorはSeekしたり、StartやLimitを設定したり、Prefixを指定して取ってくることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// get
fmt.Println(&amp;quot;-- get --&amp;quot;)
for i := 0; i &amp;lt; 10; i++ {
    var data []byte
    if data, err = db.Get([]byte(fmt.Sprintf(&amp;quot;key%d&amp;quot;, i)), nil); err != nil {
        fmt.Printf(&amp;quot;key%d: %s\n&amp;quot;, i, err.Error())
    } else {
        fmt.Printf(&amp;quot;key%d: %s\n&amp;quot;, i, string(data))
    }
}

// iterate
fmt.Println(&amp;quot;-- iterate --&amp;quot;)
iter := db.NewIterator(nil, nil)
for iter.Next() {
    key := iter.Key()
    value := iter.Value()
    fmt.Printf(&amp;quot;%s: %s\n&amp;quot;, string(key), string(value))
}
iter.Release()
if err = iter.Error(); err != nil {
    panic(err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- get --
key0: value0
key1: value1
key2: leveldb: not found
key3: value3
key4: value4
key5: value5
key6: value6
key7: value7
key8: value8
key9: value9
-- iterate --
key0: value0
key1: value1
key3: value3
key4: value4
key5: value5
key6: value6
key7: value7
key8: value8
key9: value9
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>gvmでGoのバージョン管理</title>
          <link>https://www.sambaiz.net/article/44/</link>
          <pubDate>Tue, 20 Dec 2016 20:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/44/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/moovweb/gvm&#34;&gt;moovweb/gvm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;必要なものはREADMEを見て入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)
$ source ${HOME}/.gvm/scripts/gvm
$ gvm install go1.7 -B
$ gvm use go1.7
$ go version
go version go1.7 linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;$GOPATH&lt;/code&gt;と&lt;code&gt;$GOROOT&lt;/code&gt;が書き変わる(&lt;code&gt;${HOME}/.gvm/pkgsets/go1.7/global/&lt;/code&gt;)ので注意。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>複数EC2インスタンスを立ち上げてvegetaで負荷試験する</title>
          <link>https://www.sambaiz.net/article/43/</link>
          <pubDate>Sun, 18 Dec 2016 20:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/43/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/tsenart/vegeta&#34;&gt;vegeta&lt;/a&gt;で負荷をかける。&lt;/p&gt;

&lt;h2 id=&#34;インスタンスを立ち上げるスクリプト&#34;&gt;インスタンスを立ち上げるスクリプト&lt;/h2&gt;

&lt;p&gt;コードはここ。 &lt;a href=&#34;https://github.com/sambaiz/loadtest&#34;&gt;sambaiz/loadtest&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;まずキーペアを作成し、EC2インスタンスを立ち上げて、全てのインスタンスが使えるようになるまで待つ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;aws ec2 create-key-pair --key-name LoadTestKeyPare --query &#39;KeyMaterial&#39; --output text &amp;gt; LoadTestKeyPare.pem
chmod 400 LoadTestKeyPare.pem
aws ec2 run-instances --image-id $AMI_ID --count $INSTANCE_NUM --instance-type t2.micro --key-name LoadTestKeyPare --security-group-ids $SECURITY_GROUP_IDS --subnet-id $SUBNET_ID
...
aws ec2 wait instance-status-ok --instance-ids $INSTANCE_IDS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このAMIは事前にPackerでつくったもの。vegetaをインストールしてファイルディスクリプタの上限を増やしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;aws_access_key&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;aws_secret_key&amp;quot;: &amp;quot;&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;,
    &amp;quot;access_key&amp;quot;: &amp;quot;{{user `aws_access_key`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `aws_secret_key`}}&amp;quot;,
    &amp;quot;region&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;,
    &amp;quot;source_ami&amp;quot;: &amp;quot;ami-0c11b26d&amp;quot;,
    &amp;quot;instance_type&amp;quot;: &amp;quot;t2.micro&amp;quot;,
    &amp;quot;ssh_username&amp;quot;: &amp;quot;ec2-user&amp;quot;,
    &amp;quot;ami_name&amp;quot;: &amp;quot;loadtest {{timestamp}}&amp;quot;
  }],
  &amp;quot;provisioners&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
    &amp;quot;inline&amp;quot;: [
      &amp;quot;wget https://github.com/tsenart/vegeta/releases/download/v6.1.1/vegeta-v6.1.1-linux-amd64.tar.gz&amp;quot;,
      &amp;quot;sudo tar xzf vegeta-v6.1.1-linux-amd64.tar.gz -C /usr/local/bin/&amp;quot;,
      &amp;quot;sudo sh -c \&amp;quot;echo &#39;* hard nofile 65536&#39; &amp;gt;&amp;gt; /etc/security/limits.conf\&amp;quot;&amp;quot;,
      &amp;quot;sudo sh -c \&amp;quot;echo &#39;* soft nofile 65536&#39; &amp;gt;&amp;gt; /etc/security/limits.conf\&amp;quot;&amp;quot;
    ]
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;立ち上がったインスタンスに対して&lt;a href=&#34;https://code.google.com/p/pdsh/&#34;&gt;pdsh&lt;/a&gt;で
各マシンでvegetaを実行させ($VEGETA_CMD)、結果のファイルを集めてreportのinputsで指定すると
まとめてレポートを出力してくれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pdsh -l ec2-user -w `echo &amp;quot;$PUBLIC_DNS_NAMES&amp;quot; |  paste -d, -s -` &amp;quot;$VEGETA_CMD &amp;gt; result.bin&amp;quot;

for machine in $PUBLIC_DNS_NAMES; do
  scp -i ./LoadTestKeyPare.pem -oStrictHostKeyChecking=no ec2-user@$machine:~/result.bin $machine
done

vegeta report -inputs=`echo $PUBLIC_DNS_NAMES |  paste -d, -s -`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;終わったら後片付けをする。trapでCtrl+C等での終了時もインスタンスが残らないようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cleanup() {
  echo &amp;quot;---- Clean up ----&amp;quot;
  aws ec2 terminate-instances --instance-ids $INSTANCE_IDS
  aws ec2 delete-key-pair --key-name LoadTestKeyPare
  rm -f LoadTestKeyPare.pem
  rm $PUBLIC_DNS_NAMES
}
trap cleanup EXIT SIGHUP SIGINT SIGQUIT SIGTERM
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行する&#34;&gt;実行する&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ brew install awscli pdsh jq vegeta packer
$ aws configure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じのスクリプト(sample/sample.sh)から実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash

export INSTANCE_NUM=3

export AMI_ID=ami-*****
export SECURITY_GROUP_IDS=sg-*****
export SUBNET_ID=subnet-*****

export RESOURCES_DIR=res

# https://github.com/tsenart/vegeta#attack
export VEGETA_CMD=&#39;vegeta attack -targets=res/targets.txt -rate=1000 -duration=10s&#39;

sh run.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sample/res/targets.txt&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GET http://example.com/

POST http://example.com/
@res/post.json
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;何も指定しないとこんな感じ(-reporter=text)。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Requests      [total, rate]            10000, 1000.10
Duration      [total, attack, wait]    10.011642793s, 9.998999835s, 12.642958ms
Latencies     [mean, 50, 95, 99, max]  14.781775ms, 4.262304ms, 68.475899ms, 97.492882ms, 1.096072997s
Bytes In      [total, mean]            15285000, 1528.50
Bytes Out     [total, mean]            110000, 11.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:10000  
Error Set:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他にもjsonだったり、plotを指定するとレイテンシのグラフのhtmlが出力される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/43_plot.jpg&#34; alt=&#34;グラフ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SSHポートフォワーディングとnetstatのメモ</title>
          <link>https://www.sambaiz.net/article/42/</link>
          <pubDate>Sat, 17 Dec 2016 12:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/42/</guid>
          <description>

&lt;h2 id=&#34;sshポートフォワーディング&#34;&gt;SSHポートフォワーディング&lt;/h2&gt;

&lt;p&gt;ローカルの8080ポートを、example.comを通したexample2.comの80ポートに向ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh hoge@example.com -Nf -L 8080:example2.com:80 
$ curl localhost:8080 # =&amp;gt; example2.com:80
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-N&lt;/code&gt;: リモートでコマンドを実行しない&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-f&lt;/code&gt;: バックグラウンドで実行&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;netstat&#34;&gt;netstat&lt;/h2&gt;

&lt;p&gt;ネットワークの状態を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ netstat -ant
Proto Recv-Q Send-Q Local Address               Foreign Address             State      
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN 
...
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-a&lt;/code&gt;: non-listening(TCPではESTABLISHED状態)しているソケットだけではなく、listeningしている情報も出す&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-n&lt;/code&gt;: 数値のアドレスで表示する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-t&lt;/code&gt;: TCPで制限&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ファイルディスクリプタの上限を増やす</title>
          <link>https://www.sambaiz.net/article/41/</link>
          <pubDate>Thu, 08 Dec 2016 21:36:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/41/</guid>
          <description>

&lt;h2 id=&#34;ファイルディスクリプタとは&#34;&gt;ファイルディスクリプタとは&lt;/h2&gt;

&lt;p&gt;プロセスの外部とやりとりするための識別子。POSIXではint型で、0がstdin、1がstdout、2がstderrといったもの。
ファイルやデバイスに対するopen()や、
ネットワーク(INETドメインソケット)やホスト内(UNIXドメインソケット)で
通信するためのソケットを生成するsocket()などのシステムコールで生成される。&lt;/p&gt;

&lt;h2 id=&#34;ファイルディスクリプタの上限&#34;&gt;ファイルディスクリプタの上限&lt;/h2&gt;

&lt;p&gt;一つのプロセスがリソースを食いつぶさないように
使えるファイルディスクリプタの上限が決まっていて、&lt;code&gt;ulimit -n&lt;/code&gt;で確認できる。デフォルトは大体1024。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ulimit -n
1024
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;各プロセスの上限と使っているファイルディスクリプタはこれで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /proc/&amp;lt;プロセスID&amp;gt;/limits
...
Max open files            1024                 4096                 files     
...

$ ls -l /proc/&amp;lt;プロセスID&amp;gt;/fd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webサーバーのように同時にたくさん通信したりすると上限に達してしまい、&lt;code&gt;Too many open files&lt;/code&gt;になってしまうので増やす必要がある。&lt;/p&gt;

&lt;h3 id=&#34;etc-security-limits-conf-で変更する&#34;&gt;&lt;code&gt;/etc/security/limits.conf&lt;/code&gt;で変更する&lt;/h3&gt;

&lt;p&gt;PAM認証時(ログインするときなど)に適用されるので、サーバーの起動時に立ち上がったデーモンには使えない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/pam.d/sshd
...
session    required     pam_limits.so
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;全てのユーザー(&lt;code&gt;*&lt;/code&gt;)のプロセスが使える
ファイルディスクリプタ(nofile)のsoft(ユーザーが設定できる)とhard(rootが設定できる)上限を共に64000にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;* hard nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf
$ echo &amp;quot;* soft nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf
$ ulimit -n
64000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ulimit-n-で変更する&#34;&gt;&lt;code&gt;ulimit -n&lt;/code&gt;で変更する&lt;/h3&gt;

&lt;p&gt;シェルと、起動したプロセスで有効。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ulimit -n 64000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dockerコンテナでは&#34;&gt;dockerコンテナでは&lt;/h3&gt;

&lt;p&gt;run時に&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/run/#/set-ulimits-in-container---ulimit&#34;&gt;ulimitオプション&lt;/a&gt;で
&lt;code&gt;--ulimit nofile=11111&lt;/code&gt;のように指定することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -itd --ulimit nofile=11111 ubuntu
$ docker exec -it &amp;lt;id&amp;gt; /bin/bash -c &amp;quot;ulimit -n&amp;quot;
11111
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://open-groove.net/linux/memo-etcsecuritylimits-conf/&#34;&gt;/etc/security/limits.confに関するメモ | OpenGroove&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://staffblog.yumemi.jp/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%82%BF%E6%95%B0%E3%81%AE%E4%B8%8A%E9%99%90%E5%A4%89%E6%9B%B4%E3%81%A8limits-conf%E3%81%AE%E7%BD%A0-2/&#34;&gt;ファイルディスクリプタ数の上限変更とlimits.confの罠&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.koikikukan.com/archives/2013/03/14-005555.php&#34;&gt;Linuxのファイルディスクリプタ数を変更・確認する方法: 小粋空間&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/ファイル記述子&#34;&gt;ファイル記述子 - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/kuni-nakaji/items/d11219e4ad7c74ece748&#34;&gt;調べなきゃ寝れない！と調べたら余計に寝れなくなったソケットの話 - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Angular2とangular-cliでTODOを作る</title>
          <link>https://www.sambaiz.net/article/40/</link>
          <pubDate>Mon, 05 Dec 2016 00:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/40/</guid>
          <description>

&lt;p&gt;コード: &lt;a href=&#34;https://github.com/sambaiz/angular2-todo&#34;&gt;https://github.com/sambaiz/angular2-todo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/40.gif&#34; alt=&#34;動いているところ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;アプリケーションの作成と立ち上げ&#34;&gt;アプリケーションの作成と立ち上げ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/angular/angular-cli&#34;&gt;angular-cli&lt;/a&gt;をインストールしてサーバーを立ち上げるまで。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install angular-cli -g
$ ng -v
angular-cli: 1.0.0-beta.21
node: 5.12.0
os: darwin x64

$ ng new mytodo
$ cd mytodo
$ ng server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4200/&#34;&gt;http://localhost:4200/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;新しいコンポーネントを作る&#34;&gt;新しいコンポーネントを作る&lt;/h2&gt;

&lt;p&gt;新しいコンポーネントを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g component todo-list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでtodo-listディレクトリにコンポーネントクラスとテンプレートとCSS、テストとindexが出力される。&lt;/p&gt;

&lt;p&gt;また、app.module.ts(BootstrapするRoot Module)にも追加されている。
NgModuleのdeclartionsなどに入っているものは、各Componentで指定しなくても使えるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { BrowserModule } from &#39;@angular/platform-browser&#39;;
import { NgModule } from &#39;@angular/core&#39;;
import { FormsModule } from &#39;@angular/forms&#39;;
import { HttpModule } from &#39;@angular/http&#39;;

import { AppComponent } from &#39;./app.component&#39;;
import { TodoListComponent } from &#39;./todo-list/todo-list.component&#39;;

@NgModule({
  declarations: [
    AppComponent,
    TodoListComponent
  ],
  imports: [
    BrowserModule,
    FormsModule,
    HttpModule
  ],
  providers: [],
  bootstrap: [AppComponent]
})
export class AppModule { }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なので、この状態でAppComponentのtemplateに追加するだけでTodoListComponentが表示される。
このapp-todo-listというのはコンポーネントのselectorと対応している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;h1&amp;gt;
  {{title}}
&amp;lt;/h1&amp;gt;
&amp;lt;app-todo-list&amp;gt;&amp;lt;/app-todo-list&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;@Component({
  selector: &#39;app-todo-list&#39;,
  templateUrl: &#39;./todo-list.component.html&#39;,
  styleUrls: [&#39;./todo-list.component.css&#39;]
})
export class TodoListComponent {
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;todoリストを表示する&#34;&gt;TODOリストを表示する&lt;/h2&gt;

&lt;p&gt;TODOリストを入力として受け取って表示するコンポーネントを作る。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@Input&lt;/code&gt;で入力を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component, OnInit, Input } from &#39;@angular/core&#39;;

@Component({
  selector: &#39;app-todo-list&#39;,
  templateUrl: &#39;./todo-list.component.html&#39;,
  styleUrls: [&#39;./todo-list.component.css&#39;]
})
export class TodoListComponent implements OnInit {

  @Input() todos: string[] = [];

  constructor() { }

  ngOnInit() {
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;渡すときは&lt;code&gt;[@Inputの変数名]=&amp;quot;値&amp;quot;&lt;/code&gt;。分かりやすいように変数名を変えてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;app-todo-list [todos]=&amp;quot;todos_&amp;quot;&amp;gt;&amp;lt;/app-todo-list&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import { Component } from &#39;@angular/core&#39;;

@Component({
  selector: &#39;app-root&#39;,
  templateUrl: &#39;./app.component.html&#39;,
  styleUrls: [&#39;./app.component.css&#39;]
})
export class AppComponent {
  title = &#39;app works!&#39;;
  todos_ = [&amp;quot;朝起きる&amp;quot;, &amp;quot;昼ご飯を食べる&amp;quot;, &amp;quot;夜ご飯を食べる&amp;quot;, &amp;quot;寝る&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;todosは&lt;code&gt;*ngFor&lt;/code&gt;でループさせて表示させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
  &amp;lt;li
    *ngFor=&amp;quot;let todo of todos&amp;quot;
  &amp;gt;
  {{todo}}
  &amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、出力する/しないを制御する&lt;code&gt;*ngIf&lt;/code&gt;もあって、
これらの頭に付いている
&lt;code&gt;*&lt;/code&gt;はStructural directivesの&lt;a href=&#34;https://angular.io/docs/dart/latest/guide/structural-directives.html#!#asterisk&#34;&gt;糖衣構文&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Directiveは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;コンポーネント&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://angular.io/docs/dart/latest/guide/structural-directives.html&#34;&gt;Structual directives&lt;/a&gt; (DOM elementを追加したり削除したりする)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://angular.io/docs/dart/latest/guide/attribute-directives.html&#34;&gt;Attribute directives&lt;/a&gt; (Dom elementの見た目や挙動を変える)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の3種類ある。&lt;/p&gt;

&lt;h2 id=&#34;todoを登録する&#34;&gt;TODOを登録する&lt;/h2&gt;

&lt;p&gt;登録する用のコンポーネントを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g component todo-form
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今度は&lt;code&gt;@Output&lt;/code&gt;で出力する方。
onCreateTodoでEventEmitterのnextに次の状態を渡してイベントを発火させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iimport { Component, OnInit, Output, EventEmitter } from &#39;@angular/core&#39;;

@Component({
  selector: &#39;app-todo-form&#39;,
  templateUrl: &#39;./todo-form.component.html&#39;,
  styleUrls: [&#39;./todo-form.component.css&#39;]
})
export class TodoFormComponent implements OnInit {

  @Output() createTodo = new EventEmitter();

  newTodo = &amp;quot;&amp;quot;;

  constructor() { }

  ngOnInit() {
  }

  onCreateTodo() {
    if(this.newTodo !== &amp;quot;&amp;quot;) this.createTodo.next(this.newTodo);
    this.newTodo = &amp;quot;&amp;quot;;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;フォームでは&lt;code&gt;(ngSubmit)&lt;/code&gt;でonsubmitイベント時にonCreateTodoが呼ばれるようにしている。
また、&lt;code&gt;[(ngModel)]=&amp;quot;newTodo&amp;quot;&lt;/code&gt;でnewTodoを
&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/template-syntax.html#!#ngModel&#34;&gt;Two-way binding&lt;/a&gt;して
フォームと変数の値を同期させる。これにはFormsModuleが必要で、既にRoot Moduleに含まれている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div&amp;gt;
  &amp;lt;form (ngSubmit)=&amp;quot;onCreateTodo()&amp;quot;&amp;gt;
    &amp;lt;input
      type=&amp;quot;text&amp;quot;
      name=&amp;quot;todo&amp;quot;
      [(ngModel)]=&amp;quot;newTodo&amp;quot;
    &amp;gt;
    &amp;lt;button
      type=&amp;quot;submit&amp;quot;
    &amp;gt;
    登録
    &amp;lt;/button&amp;gt;
  &amp;lt;/form&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;@Output&lt;/code&gt;はこんな感じでハンドリングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;app-todo-form (createTodo)=&amp;quot;onCreateTodo($event)&amp;quot;&amp;gt;&amp;lt;/app-todo-form&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;登録イベントが起きたらtodos_に追加していく。これでリストの方も更新される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component } from &#39;@angular/core&#39;;

@Component({
  selector: &#39;app-root&#39;,
  templateUrl: &#39;./app.component.html&#39;,
  styleUrls: [&#39;./app.component.css&#39;]
})
export class AppComponent {
  title = &#39;app works!&#39;;
  todos_ = [&amp;quot;朝起きる&amp;quot;, &amp;quot;昼ご飯を食べる&amp;quot;, &amp;quot;夜ご飯を食べる&amp;quot;, &amp;quot;寝る&amp;quot;]

  onCreateTodo(todo) {
    this.todos_.push(todo);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;apiを叩くサービスを作る&#34;&gt;APIを叩くサービスを作る&lt;/h2&gt;

&lt;p&gt;データを保存して取得する簡易的なAPIを用意した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var express = require(&#39;express&#39;)
var bodyParser = require(&#39;body-parser&#39;)
var app = express()
app.use(bodyParser());

data = []

app.get(&#39;/&#39;, function (req, res) {
  res.send(data)
})

app.post(&#39;/&#39;, function (req, res) {
  data.push(req.body)
  res.send(req.body)
})

app.listen(3000, function () {
  console.log(&#39;listening on port 3000&#39;)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir services
$ ng g service services/todo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サービスクラスとテストができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/server-communication.html&#34;&gt;HTTP Client - ts - GUIDE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Angularで用意されているHTTPクライアントは&lt;a href=&#34;https://github.com/ReactiveX/RxJS&#34;&gt;RxJS&lt;/a&gt;のObservableな値を返す。
これを扱うために&lt;code&gt;import &#39;rxjs/Rx&#39;&lt;/code&gt;するとサイズがとても大きくなってしまうので必要なものだけをimportする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import &#39;rxjs/add/operator/map&#39;;
import &#39;rxjs/add/operator/catch&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンストラクタのhttpはAngularによって
providerから&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/dependency-injection.html&#34;&gt;DI&lt;/a&gt;される。
Root Moduleのprovidersは空になっているが、HttpModuleで提供されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iimport { Injectable } from &#39;@angular/core&#39;;
import { Http, Response, Headers, RequestOptions } from &#39;@angular/http&#39;;
import { Observable }     from &#39;rxjs/Observable&#39;;

@Injectable()
export class TodoService {
  private apiUrl = &#39;http://localhost:3000&#39;;

  constructor(private http: Http) { }

  getTodos (): Observable&amp;lt;string[]&amp;gt; {
    return this.http.get(this.apiUrl)
                    .map(this.extractData)
                    .catch(this.handleError);
  }

  addTodo (todo: string): Observable&amp;lt;string&amp;gt; {
    let headers = new Headers({ &#39;Content-Type&#39;: &#39;application/json&#39; });
    let options = new RequestOptions({ headers: headers });

    return this.http.post(this.apiUrl, { todo }, options)
                    .map(this.extractData)
                    .catch(this.handleError);
  }

  private extractData(res: Response) {
    let body = res.json();
    return body || { };
  }

  private handleError (error: Response | any) {
    // In a real world app, we might use a remote logging infrastructure
    let errMsg: string;
    if (error instanceof Response) {
      const body = error.json() || &#39;&#39;;
      const err = body.error || JSON.stringify(body);
      errMsg = `${error.status} - ${error.statusText || &#39;&#39;} ${err}`;
    } else {
      errMsg = error.message ? error.message : error.toString();
    }
    console.error(errMsg);
    return Observable.throw(errMsg);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このサービスがDIされるようにprovidersに追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { BrowserModule } from &#39;@angular/platform-browser&#39;;
import { NgModule } from &#39;@angular/core&#39;;
import { FormsModule } from &#39;@angular/forms&#39;;
import { HttpModule } from &#39;@angular/http&#39;;

import { AppComponent } from &#39;./app.component&#39;;
import { TodoListComponent } from &#39;./todo-list/todo-list.component&#39;;
import { TodoFormComponent } from &#39;./todo-form/todo-form.component&#39;;

import { TodoService } from &#39;./services/todo.service&#39;;

// RxJS
import &#39;rxjs/add/operator/map&#39;;
import &#39;rxjs/add/operator/catch&#39;;

@NgModule({
  declarations: [
    AppComponent,
    TodoListComponent,
    TodoFormComponent
  ],
  imports: [
    BrowserModule,
    FormsModule,
    HttpModule
  ],
  providers: [TodoService],
  bootstrap: [AppComponent]
})
export class AppModule { }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サービスを使うようにする。ngOnInitはコンポーネントのプロパティが初期化されたあと一度だけ呼ばれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/lifecycle-hooks.html&#34;&gt;Lifecycle Hooks - ts - GUIDE&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component, OnInit } from &#39;@angular/core&#39;;
import { TodoService } from &#39;./services/todo.service&#39;;

@Component({
  selector: &#39;app-root&#39;,
  templateUrl: &#39;./app.component.html&#39;,
  styleUrls: [&#39;./app.component.css&#39;]
})
export class AppComponent implements OnInit {
  title = &#39;app works!&#39;;
  todos_: string[] = []

  constructor(private todoService: TodoService) { }

  ngOnInit() {
    this.todoService.getTodos().subscribe(
                       todos =&amp;gt; this.todos_ = todos.map((t) =&amp;gt; t[&amp;quot;todo&amp;quot;]),
                       error =&amp;gt; this.todos_ = [&amp;quot;&amp;lt;error&amp;gt;&amp;quot;]);
  }

  onCreateTodo(todo: string) {
    this.todoService.addTodo(todo).subscribe(
                       todo =&amp;gt; this.todos_.push(todo[&amp;quot;todo&amp;quot;]),
                       error =&amp;gt; this.todos_ = [&amp;quot;&amp;lt;error&amp;gt;&amp;quot;]);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テストは気が向いたら書く。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OpenVPNサーバーPritunlをDockerで動かす</title>
          <link>https://www.sambaiz.net/article/39/</link>
          <pubDate>Fri, 02 Dec 2016 21:05:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/39/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://pritunl.com/&#34;&gt;Pritunl&lt;/a&gt;でVPNサーバーを立てる。&lt;/p&gt;

&lt;p&gt;Dockerfileはこんな感じ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/sambaiz/pritunl/&#34;&gt;https://hub.docker.com/r/sambaiz/pritunl/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM mongo:3.4

# https://docs.pritunl.com/docs/installation
RUN echo &#39;deb http://repo.pritunl.com/stable/apt jessie main&#39; &amp;gt; /etc/apt/sources.list.d/pritunl.list &amp;amp;&amp;amp; \
    apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 7568D9BB55FF9E5287D586017AE645C0CF8E292A &amp;amp;&amp;amp; \
    apt-get --assume-yes update &amp;amp;&amp;amp; \
    apt-get --assume-yes upgrade &amp;amp;&amp;amp; \
    apt-get --assume-yes install pritunl iptables

EXPOSE 80 443 12345/udp

CMD mongod --fork --logpath /data/db/mongod.log &amp;amp;&amp;amp; echo &#39;Setup Key:&#39; `pritunl setup-key` &amp;amp;&amp;amp; pritunl start
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -itd -p 80:80 -p 443:443 -p 12345:12345/udp --privileged sambaiz/pritunl
$ docker logs &amp;lt;id&amp;gt;
...
Setup Key: ***********
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--privileged&lt;/code&gt;を付けているのはStart Server時にこれで失敗しないように。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CalledProcessError: Command &#39;[&#39;sysctl&#39;, &#39;-w&#39;, &#39;net.ipv4.ip_forward=1&#39;]&#39; returned non-zero exit status 255
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;httpsでアクセスして、Setup Keyを入力すると初期設定が始まり、ログイン画面になる。
初期パスワードは&lt;code&gt;pritunl/pritunl&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;あとは、OrganizationとUser、Server(ポートはudpの12345にする)を登録し、ServerにOrganizationを紐付け、
ServerにRouteを追加して、アクセスしたいCIDRを入力したらStart Serverする。
ovpnファイルをダウンロードできる24時間有効のリンクを発行でき、これでクライアントに設定すると
RouteにVPNを通してアクセスできるようになる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>aws-sdk-goでs3にput/get</title>
          <link>https://www.sambaiz.net/article/38/</link>
          <pubDate>Wed, 30 Nov 2016 20:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/38/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/aws/aws-sdk-go&#34;&gt;aws-sdk-go&lt;/a&gt;でS3にputしてgetする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;bytes&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws/session&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/service/s3&amp;quot;
)

const REGION = &amp;quot;ap-northeast-1&amp;quot;
const BUCKET_NAME = &amp;quot;faweijojio4f3e4&amp;quot;

func main() {

	sess, err := session.NewSession(aws.NewConfig().WithRegion(REGION))
	if err != nil {
		fmt.Println(err.Error())
		return
	}

	svc := s3.New(sess)

	// put
	data := []byte(&amp;quot;BBBBBB&amp;quot;)
	key := &amp;quot;AAA.txt&amp;quot;

	params := &amp;amp;s3.PutObjectInput{
		Bucket:        aws.String(BUCKET_NAME),
		Key:           aws.String(key),
		Body:          bytes.NewReader(data),
		ContentLength: aws.Int64(int64(len(data))),
		ContentType:   aws.String(&amp;quot;text/plain&amp;quot;),
	}
	if _, err = svc.PutObject(params); err != nil {
		fmt.Println(err.Error())
		return
	}

	// bucket list
	keys := []string{}
	err = svc.ListObjectsPages(&amp;amp;s3.ListObjectsInput{
		Bucket: aws.String(BUCKET_NAME),
	}, func(p *s3.ListObjectsOutput, last bool) (shouldContinue bool) {
		for _, obj := range p.Contents {
			keys = append(keys, *obj.Key)
			fmt.Println(*obj.Key)
		}
		return true
	})

	if err != nil {
		fmt.Println(err.Error())
		return
	}

	// get
	resp, err2 := svc.GetObject(&amp;amp;s3.GetObjectInput{
		Bucket: aws.String(BUCKET_NAME),
		Key:    aws.String(keys[0]),
	})
	if err2 != nil {
		fmt.Println(err2.Error())
		return
	}

	buf := new(bytes.Buffer)
	buf.ReadFrom(resp.Body)
	fmt.Println(keys[0] + &amp;quot; -&amp;gt; &amp;quot; + buf.String())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ AWS_ACCESS_KEY_ID=**** AWS_SECRET_ACCESS_KEY=**** go run main.go
AAA.txt
bbbb.txt
AAA.txt -&amp;gt; BBBBBB
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goでstructをリフレクションしてcsvを出力する</title>
          <link>https://www.sambaiz.net/article/37/</link>
          <pubDate>Mon, 28 Nov 2016 21:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/37/</guid>
          <description>&lt;p&gt;こんなstructとデータがあったら、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Result struct{
 Name string `col:&amp;quot;who&amp;quot;`
 Point int
}

x := Result{&amp;quot;sam&amp;quot;, 100}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;フィールド名と、値、タグはrefrectで取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x := Result{&amp;quot;sam&amp;quot;, 100}
v := reflect.ValueOf(x)
fmt.Println(v.Type().Field(0).Name) // -&amp;gt; Name
fmt.Println(v.Type().Field(1).Name) // -&amp;gt; Point
fmt.Println(v.Field(0).Interface()) // -&amp;gt; sam
fmt.Println(v.Field(1).Interface()) // -&amp;gt; 100
fmt.Println(v.Type().Field(0).Tag.Get(&amp;quot;col&amp;quot;)) // -&amp;gt; who
fmt.Println(v.Type().Field(1).Tag.Get(&amp;quot;col&amp;quot;)) // -&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらをencoding/csvで書く。&lt;/p&gt;

&lt;p&gt;ただ、引数を&lt;code&gt;[]interface{}&lt;/code&gt;にすると&lt;a href=&#34;https://golang.org/doc/faq#convert_slice_of_interface&#34;&gt;interface{}のスライスしか渡せない&lt;/a&gt;ので、
一旦&lt;code&gt;interface{}&lt;/code&gt;で受け取ってスライスにする。このときにもrefrectを使っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;encoding/csv&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;reflect&amp;quot;
	&amp;quot;strings&amp;quot;
)

type Result struct {
	Name  string `col:&amp;quot;who&amp;quot;`
	Point int
	Age   int `col:&amp;quot;-&amp;quot;` // ignore
}

const COLTAG = &amp;quot;col&amp;quot;

func main() {

	x := []Result{Result{&amp;quot;sam&amp;quot;, 100, 24}, Result{&amp;quot;tom&amp;quot;, 0, 100025}}

	file, err := os.OpenFile(&amp;quot;aaaa.csv&amp;quot;, os.O_WRONLY|os.O_CREATE, 0600)
	if err != nil {
		panic(err)
	}
	defer file.Close()

	WriteCSV(file, x)
}

// Convert interface{} to []interface{}
func toSlice(src interface{}) []interface{} {

	ret := []interface{}{}

	if v := reflect.ValueOf(src); v.Kind() == reflect.Slice {
		for i := 0; i &amp;lt; v.Len(); i++ {
			ret = append(ret, v.Index(i).Interface())
		}
	} else {
		ret = append(ret, v.Interface())
	}

	return ret
}

// Generate csv rows including header from interface{} slice or object
func genRows(src interface{}) [][]string {

	sl := toSlice(src)
	rows := make([][]string, 1)
	ignoreColIndex := map[int]bool{}

	for n, d := range sl {
		rows = append(rows, []string{})
		v := reflect.ValueOf(d)

		for i := 0; i &amp;lt; v.NumField(); i++ {
			if n == 0 {
				// Header
				colName := v.Type().Field(i).Tag.Get(COLTAG)
				if colName == &amp;quot;&amp;quot; {
					colName = strings.ToLower(v.Type().Field(i).Name)
				} else if colName == &amp;quot;-&amp;quot; {
					ignoreColIndex[i] = true
					continue
				}
				rows[0] = append(rows[0], colName)
			}

			if !ignoreColIndex[i] {
				rows[len(rows)-1] = append(rows[len(rows)-1], fmt.Sprint(v.Field(i).Interface()))
			}
		}
	}
	return rows
}

// Write csv file to path
func WriteCSV(file *os.File, data interface{}) {
	rows := genRows(data)

	writer := csv.NewWriter(file)
	for _, row := range rows {
		writer.Write(row)
	}
	writer.Flush()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;who,point
sam,100
tom,0
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>WebVRを動かす</title>
          <link>https://www.sambaiz.net/article/36/</link>
          <pubDate>Wed, 16 Nov 2016 00:46:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/36/</guid>
          <description>

&lt;h3 id=&#34;webvrとは&#34;&gt;WebVRとは&lt;/h3&gt;

&lt;p&gt;Webブラウザ上でVRアプリケーションを動かすためのAPI。
ヘッドマウントディスプレイの動きを3D空間上の動きに変換してくれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/WebVR_API&#34;&gt;WebVR API - Web API インターフェイス | MDN&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ただし、まだほとんどのブラウザがVR APIをサポートしていないので、
実際は&lt;a href=&#34;https://github.com/googlevr/webvr-polyfill&#34;&gt;Polyfill&lt;/a&gt;で動かすことになる。&lt;/p&gt;

&lt;h3 id=&#34;動かしてみる&#34;&gt;動かしてみる&lt;/h3&gt;

&lt;p&gt;まず、&lt;a href=&#34;https://github.com/borismus/webvr-boilerplate&#34;&gt;webvr-boilerplate&lt;/a&gt;を動かしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm init
$ npm install node-static
$ git clone https://github.com/borismus/webvr-boilerplate.git
$ cd webvr-boilerplate/ &amp;amp;&amp;amp; npm install &amp;amp; cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;var static = require(&#39;node-static&#39;);

var fileServer = new static.Server(&#39;./webvr-boilerplate&#39;);

require(&#39;http&#39;).createServer(function (request, response) {
    request.addListener(&#39;end&#39;, function () {
        fileServer.serve(request, response);
    }).resume();
}).listen(8080);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:8080&#34;&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;を見ると箱が回っているのが映る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/36_webvr1.png&#34; alt=&#34;箱が回っている&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただ、start_modeに3を指定してVRモードにしようとしたところ、&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:8080/index.html?start_mode=3&#34;&gt;http://localhost:8080/index.html?start_mode=3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PCのChromeから見ると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;base.js:191 Uncaught (in promise) Error: VRDisplay is not capable of presenting
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;というエラーが出てしまった。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Only enable VR mode if there&amp;rsquo;s a VR device attached or we are running the polyfill on mobile&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;と書いてあったので、Android端末から見てみたところ
Cardboardのマークが出てきて、それを押したら二眼の表示になった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/36_vrview.png&#34; alt=&#34;二眼で映っている&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;描画&#34;&gt;描画&lt;/h3&gt;

&lt;p&gt;webvr-boilerplateでは、描画に&lt;a href=&#34;https://threejs.org/&#34;&gt;Three.js&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;まずシーンやカメラを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var scene = new THREE.Scene();
var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、cameraをTHREE.VRControlsに渡す。この中でVR APIを呼んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var controls = new THREE.VRControls(camera);
controls.standing = true;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをupdateしていくことでVRデバイスにcameraが連動するようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;controls.update();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自分でVR APIを呼んでいるところもあって、
&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Navigator/getVRDisplays&#34;&gt;Navigator.getVRDisplays()&lt;/a&gt;で
VRDisplayを取得し、
&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/VRDevice/requestAnimationFrame&#34;&gt;VRDisplay.requestAnimationFrame()&lt;/a&gt;で、VRDisplayのリフレッシュレートでアニメーションさせるコールバックが呼ばれるようにしている。
このコールバックの中で&lt;code&gt;controls.update()&lt;/code&gt;を呼んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function setupStage() {
  navigator.getVRDisplays().then(function(displays) {
    if (displays.length &amp;gt; 0) {
      vrDisplay = displays[0];
      if (vrDisplay.stageParameters) {
        setStageDimensions(vrDisplay.stageParameters);
      }
      vrDisplay.requestAnimationFrame(animate);
    }
  });
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>JVMのヒープ領域とFull GC</title>
          <link>https://www.sambaiz.net/article/35/</link>
          <pubDate>Mon, 14 Nov 2016 23:46:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/35/</guid>
          <description>

&lt;h3 id=&#34;ヒープ領域&#34;&gt;ヒープ領域&lt;/h3&gt;

&lt;p&gt;ヒープ領域というのはメモリ上の動的に確保する領域のこと。
JVMでは、ヒープ領域のNew領域とOld領域、非ヒープ領域のPermanent領域が存在する(した)。&lt;/p&gt;

&lt;h3 id=&#34;permanent領域&#34;&gt;Permanent領域&lt;/h3&gt;

&lt;p&gt;ロードしたクラスやメソッドが入る。
Java8版のHotspotVM(OracleのJVM)ではMetaspace領域となり、ネイティブメモリに乗るようになったらしい。&lt;/p&gt;

&lt;h3 id=&#34;new領域&#34;&gt;New領域&lt;/h3&gt;

&lt;p&gt;New領域の中はさらに分かれている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Eden領域: オブジェクトが作られて最初に配置される。&lt;/li&gt;
&lt;li&gt;To領域(Survivor領域1): Edenが一杯になると、EdenとFromから送られる。&lt;/li&gt;
&lt;li&gt;From領域(Survivor領域0): Edenが一杯になると、Toから送られる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Edenが一杯になったときに不要なオブジェクトは破棄、必要なものは領域を移動させるのがScavenge GC。
つまり、Edenが一杯になるたびにToに飛んだオブジェクトはFromと往復し続ける。
ただし、MaxTenuringThresholdの回数を超えるとOld領域に送られることになる。&lt;/p&gt;

&lt;h3 id=&#34;old領域&#34;&gt;Old領域&lt;/h3&gt;

&lt;p&gt;Old領域も一杯になったらどうしようもないのでFull GCが走る。
Full GCでは全ての領域のオブジェクトをチェックして不要なものを探す。
これに集中するので他のことはできなくなり、時間もかかる。
Full GCばかり起きていたらまともに動かないので、
Old領域にまで行かないようにオブジェクトの寿命を短くするか、
ヒープ領域の大きさ(&lt;code&gt;-Xms&lt;/code&gt;, &lt;code&gt;-Xmx&lt;/code&gt;)を変えたりしてなるべく起きないようにしたい。&lt;/p&gt;

&lt;h3 id=&#34;どれくらいfull-gcしているかどうか&#34;&gt;どれくらいFull GCしているかどうか&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;-Xloggc&lt;/code&gt;でGCのログが出せる。&lt;code&gt;-XX:+UseGCLogFileRotation&lt;/code&gt;でローテーションしたりもできる。
あと手軽に&lt;code&gt;jps&lt;/code&gt;からの&lt;code&gt;jstat -gc &amp;lt;pid&amp;gt;&lt;/code&gt;、あるいはグラフで可視化できるようなやつでヒープ領域の状態を確認する。
&lt;code&gt;jstat&lt;/code&gt;の結果の意味は&lt;a href=&#34;https://docs.oracle.com/javase/jp/8/docs/technotes/tools/windows/jstat.html&#34;&gt;ここ&lt;/a&gt;に書いてある。
例えばFGCがフルGCイベントの数。&lt;/p&gt;

&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://d.hatena.ne.jp/ogin_s57/20120623/1340463194&#34;&gt;JVMとGCのしくみ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://equj65.net/tech/java8hotspot/&#34;&gt;Java8のHotSpotVMからPermanent領域が消えた理由とその影響 | ギークを目指して&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/i_matsui/items/aabbdaa169c6ae51ecb3&#34;&gt;Java開発の性能改善！ その２ GCログの解析とHeepの設定&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>API BlueprintでAPI仕様を書く</title>
          <link>https://www.sambaiz.net/article/34/</link>
          <pubDate>Thu, 10 Nov 2016 00:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/34/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://apiblueprint.org/&#34;&gt;API Blueprint&lt;/a&gt;というのはAPIの仕様を書くための言語で、
これを元にHTMLのドキュメントにしたり、モックサーバーを立てたりする&lt;a href=&#34;https://apiblueprint.org/tools.html&#34;&gt;ツール&lt;/a&gt;がある。&lt;/p&gt;

&lt;p&gt;最初にMetadataとして、API Blueprintのバージョンを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FORMAT: 1A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;基本的にはMarkdownのように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# テストAPI
テスト
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;頭にGroupと書くとグループができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Group echo
やまびこ
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;終わりに&lt;code&gt;[]&lt;/code&gt;で囲んでリソースを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## echo [/echo]
やっほー
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アクション。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;### echo [POST]
叫ぶ

+ say (string) - 発声
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リクエスト例とレスポンス例はこんな感じ。&lt;a href=&#34;https://apiblueprint.org/documentation/advanced-tutorial.html#json-schema&#34;&gt;JSON Schemaを書くこともできる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+ Request (application/json)

    {
        &amp;quot;say&amp;quot;: &amp;quot;yahho&amp;quot;
    }

+ Response 200 (application/json)

  + Headers

    Hoge: Fuga

  + Body

    {
        &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;全体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FORMAT: 1A

# テストAPI
テスト

# Group echo
やまびこ

## echo [/echo]
やっほー

### echo [POST]
叫ぶ

+ say (string) - 発声

+ Request (application/json)

    {
        &amp;quot;say&amp;quot;: &amp;quot;yahho&amp;quot;
    }

+ Response 200 (application/json)

  + Headers

    Hoge: Fuga

  + Body

    {
        &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを使って、&lt;a href=&#34;https://github.com/danielgtaylor/aglio&#34;&gt;aglio&lt;/a&gt;でHTMLにしたり、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g aglio
$ aglio -i test.apib -o test.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/34_api_html.png&#34; alt=&#34;HTMLに出力したもの&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/localmed/api-mock&#34;&gt;api-mock&lt;/a&gt;でモックを立てたりすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g api-mock
$ api-mock --version
api-mock v0.3.2

$ api-mock test.apib
info:    Enabled Cross-Origin-Resource-Sharing (CORS)
info:    	Allow-Origin: *
info:    	Allow-Methods: GET, PUT, POST, PATCH, DELETE, TRACE, OPTIONS
info:    	Allow-Headers: Origin, X-Requested-With, Content-Type, Accept, Authorization, Referer, Prefer
info:    Listening on port 3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただnode v6でインストールしたらprotagonistのところで失敗してしまったので、5.12.0に下げて実行した。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/8/&#34;&gt;nでNode.jsのバージョン管理&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ n 5.12.0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X POST -H &amp;quot;Content-Type: application/json&amp;quot; -d &#39;{&amp;quot;say&amp;quot;: &amp;quot;ho&amp;quot;}&#39; &amp;quot;http://localhost:3000/echo&amp;quot;
{
    &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>logrotateでログをローテーションする</title>
          <link>https://www.sambaiz.net/article/33/</link>
          <pubDate>Wed, 09 Nov 2016 22:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/33/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/Sirupsen/logrus&#34;&gt;logrus&lt;/a&gt;がローテーションする仕組みを持っていなかったので、
READMEに書いてあったlogrotateを使う。/etc/logrotate.dの中に設定ファイルを入れて、cronで回して使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM ubuntu:14.04

ADD logrotate /etc/logrotate.d/app
RUN echo &amp;quot;/usr/sbin/logrotate /etc/logrotate.conf&amp;quot; &amp;gt; /etc/cron.daily/logrotate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定ファイル(logrotate)はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/var/log/app.log {
  daily
  rotate 4
  missingok
  delaycompress
  dateext
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;daily&lt;/code&gt;で1日に1回、&lt;code&gt;rotate 4&lt;/code&gt;で過去4日分残し、
&lt;code&gt;missingok&lt;/code&gt;でファイルがなくてもエラーにせず、&lt;code&gt;delaycompress&lt;/code&gt;で圧縮するのをローテーションした次の回にして、
&lt;code&gt;dateext&lt;/code&gt;でローテーションしたファイルの末尾を数字ではなく日付にする。&lt;/p&gt;

&lt;p&gt;実際に動かして確かめる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logrotate&lt;/code&gt;を実行すると、&lt;code&gt;/var/lib/logrotate/status&lt;/code&gt;に過去に見た時間が入る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;aaaaa&amp;quot; &amp;gt; /var/log/app.log
$ logrotate /etc/logrotate.conf
$ cat /var/lib/logrotate/status
logrotate state -- version 2
...
&amp;quot;/var/log/app.log&amp;quot; 2016-11-9-11:0:0
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;強制的にローテーションさせてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;aaaa&amp;quot; &amp;gt; /var/log/app.log
$ logrotate -f /etc/logrotate.conf
$ ls /var/log | grep app
app.log
app.log-20161109

$ cat /var/log/app.log-20161109
aaaaa
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>td-agentをビルドしてfluentdのバージョンを上げる</title>
          <link>https://www.sambaiz.net/article/32/</link>
          <pubDate>Sun, 06 Nov 2016 11:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/32/</guid>
          <description>&lt;pre&gt;&lt;code&gt;$td-agent --version
td-agent 0.12.26
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;td-agentって書いてあるけど、これがfluentdのバージョンらしい。&lt;/p&gt;

&lt;p&gt;fluentdはv0.14から&lt;a href=&#34;http://www.fluentd.org/blog/fluentd-v0.14.0-has-been-released&#34;&gt;ナノ秒で時間を持つようになった。&lt;/a&gt;
ただ、現行のtd-agent(v2.3.2)は上の通り古いバージョンを使っている。
0.14になる&lt;a href=&#34;https://github.com/treasure-data/omnibus-td-agent/tree/td-agent-3&#34;&gt;td-agent-3&lt;/a&gt;はまだリリースされていないので、
自分でfluentdを&lt;a href=&#34;https://github.com/fluent/fluentd/releases/tag/v0.14.8&#34;&gt;v0.14.8&lt;/a&gt;に上げてビルドすることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM ubuntu:14.04

WORKDIR /tmp

RUN apt-get update &amp;amp;&amp;amp; \
    apt-get install -y git software-properties-common build-essential curl &amp;amp;&amp;amp; \
    add-apt-repository -y ppa:brightbox/ruby-ng &amp;amp;&amp;amp; \
    apt-get update &amp;amp;&amp;amp; \
    apt-get install -y ruby2.3 ruby2.3-dev &amp;amp;&amp;amp; \
    gem install bundler &amp;amp;&amp;amp; \
    git clone https://github.com/treasure-data/omnibus-td-agent

WORKDIR /tmp/omnibus-td-agent

RUN sed -ie &amp;quot;s/^default_version.*$/default_version &#39;3d1dd53f31d1fe49508f230a71a2b4c2ceb20f47&#39;/&amp;quot; config/software/fluentd.rb &amp;amp;&amp;amp; \
    sed -ie &amp;quot;s/^license_file.*$/license_file &#39;LICENSE&#39;/&amp;quot; config/projects/td-agent2.rb &amp;amp;&amp;amp; \
    bundle install --binstubs &amp;amp;&amp;amp; \
    bin/gem_downloader core_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader plugin_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader ui_gems.rb &amp;amp;&amp;amp; \
    git config --global user.email &amp;quot;root@example.com&amp;quot; &amp;amp;&amp;amp; \
    mkdir -p /opt/td-agent /var/cache/omnibus &amp;amp;&amp;amp; \
    bin/omnibus build td-agent2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;config/projects/td-agent2.rb&lt;/code&gt;を書き換えているのは、ビルド時に&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/var/lib/gems/2.3.0/gems/omnibus-5.5.0/lib/omnibus/licensing.rb:223:in `read&#39;: No such file or directory @ rb_sysopen - /tmp/omnibus-td-agent/https://raw.githubusercontent.com/treasure-data/omnibus-td-agent/master/LICENSE (Errno::ENOENT)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなエラーが出たため。&lt;a href=&#34;https://github.com/chef/omnibus/blob/v5.5.0/lib/omnibus/licensing.rb#L223&#34;&gt;licensing.rb&lt;/a&gt;を見てみたところ、相対パスを想定しているようだった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;g++: internal compiler error: Killed (program cc1plus)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;が出たらメモリが足りないかもしれない。&lt;/p&gt;

&lt;p&gt;ビルドが成功したらpkgにdebが出来ている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker cp &amp;lt;Container ID&amp;gt;:/tmp/omnibus-td-agent/pkg/td-agent_2.3.3-0_amd64.deb .
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ dpkg -i td-agent_2.3.3-0_amd64.deb
$ td-agent --version
td-agent 0.14.8
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>d3.jsで折れ線グラフを書くコードを読む</title>
          <link>https://www.sambaiz.net/article/31/</link>
          <pubDate>Thu, 03 Nov 2016 00:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/31/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://bl.ocks.org/mbostock/3883245&#34;&gt;http://bl.ocks.org/mbostock/3883245&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CSSと&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;

.axis--x path {
  display: none;
}

.line {
  fill: none;
  stroke: steelblue;
  stroke-width: 1.5px;
}

&amp;lt;/style&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;グラフを書くsvgとd3.js。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;svg width=&amp;quot;960&amp;quot; height=&amp;quot;500&amp;quot;&amp;gt;&amp;lt;/svg&amp;gt;
&amp;lt;script src=&amp;quot;https://d3js.org/d3.v4.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;var svg = d3.select(&amp;quot;svg&amp;quot;),
    margin = {top: 20, right: 20, bottom: 30, left: 50},
    width = +svg.attr(&amp;quot;width&amp;quot;) - margin.left - margin.right,
    height = +svg.attr(&amp;quot;height&amp;quot;) - margin.top - margin.bottom,
    g = svg.append(&amp;quot;g&amp;quot;).attr(&amp;quot;transform&amp;quot;, &amp;quot;translate(&amp;quot; + margin.left + &amp;quot;,&amp;quot; + margin.top + &amp;quot;)&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;d3.select&lt;/code&gt;でsvg要素を選択。widthとheightを取得したり、中にg(グループ)を入れてtransformでmarginを作っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;svg width=&amp;quot;960&amp;quot; height=&amp;quot;500&amp;quot;&amp;gt;&amp;lt;g transform=&amp;quot;translate(50,20)&amp;quot;&amp;gt;&amp;lt;/g&amp;gt;&amp;lt;/svg&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;svg.attr&lt;/code&gt;の前に+を付けるとnullの場合でも数値として扱える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; +null
0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;var parseTime = d3.timeParse(&amp;quot;%d-%b-%y&amp;quot;);

var x = d3.scaleTime()
    .rangeRound([0, width]);

var y = d3.scaleLinear()
    .rangeRound([height, 0]);

var line = d3.line()
    .x(function(d) { return x(d.date); })
    .y(function(d) { return y(d.close); });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;d3.scaleTime()&lt;/code&gt;や&lt;code&gt;d3.scaleLinear()&lt;/code&gt;は&lt;code&gt;domain&lt;/code&gt;で値域を指定し、&lt;code&gt;range&lt;/code&gt;の範囲にマッピングさせる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; d3.scaleLinear().rangeRound([0, 100]).domain([0, 66525])(33262)
50
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;d3.line()&lt;/code&gt;で点を結ぶ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; d3.line()
  .x(function(d) { return d.a; })
  .y(function(d) { return d.b; })([{a: 10, b: 20},{a: 20, b:10}])
M10,20L20,10
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;d3.tsv(&amp;quot;data.tsv&amp;quot;, function(d) {
  d.date = parseTime(d.date);
  d.close = +d.close;
  return d;
}, function(error, data) {
  if (error) throw error;

  x.domain(d3.extent(data, function(d) { return d.date; }));
  y.domain(d3.extent(data, function(d) { return d.close; }));

  g.append(&amp;quot;g&amp;quot;)
      .attr(&amp;quot;class&amp;quot;, &amp;quot;axis axis--x&amp;quot;)
      .attr(&amp;quot;transform&amp;quot;, &amp;quot;translate(0,&amp;quot; + height + &amp;quot;)&amp;quot;)
      .call(d3.axisBottom(x));

  g.append(&amp;quot;g&amp;quot;)
      .attr(&amp;quot;class&amp;quot;, &amp;quot;axis axis--y&amp;quot;)
      .call(d3.axisLeft(y))
    .append(&amp;quot;text&amp;quot;)
      .attr(&amp;quot;fill&amp;quot;, &amp;quot;#000&amp;quot;)
      .attr(&amp;quot;transform&amp;quot;, &amp;quot;rotate(-90)&amp;quot;)
      .attr(&amp;quot;y&amp;quot;, 6)
      .attr(&amp;quot;dy&amp;quot;, &amp;quot;0.71em&amp;quot;)
      .style(&amp;quot;text-anchor&amp;quot;, &amp;quot;end&amp;quot;)
      .text(&amp;quot;Price ($)&amp;quot;);

  g.append(&amp;quot;path&amp;quot;)
      .datum(data)
      .attr(&amp;quot;class&amp;quot;, &amp;quot;line&amp;quot;)
      .attr(&amp;quot;d&amp;quot;, line);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;tsvを読んで加工した後、&lt;code&gt;d3.extent&lt;/code&gt;で[最小値, 最大値]の配列を作ってdomainに渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;console.log(d3.extent([4, 1, 2, 4, 9, 3], function(d){ return d }))
[1, 9]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あと縦軸と横軸を書いてパスを書く。&lt;/p&gt;

&lt;p&gt;`&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>mp4をエンコードしてMPEG-DASHにして再生する</title>
          <link>https://www.sambaiz.net/article/30/</link>
          <pubDate>Sun, 30 Oct 2016 23:51:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/30/</guid>
          <description>

&lt;h2 id=&#34;mpeg-dashとは&#34;&gt;MPEG-DASHとは&lt;/h2&gt;

&lt;p&gt;HTTPで動画をストリーミングするための規格。似たようなのにAppleの独自規格であるHLSなどがある。&lt;/p&gt;

&lt;p&gt;サーバーはMPD(Media Presentation Description)ファイルと、セグメントに分けられた動画や音声ファイルを持っていて、
クライアントはMPDファイルをリクエストし、この内容をもとにセグメントをリクエストしていく。&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ffmpeg.org/ffmpeg.html&#34;&gt;ffmpeg&lt;/a&gt;と
&lt;a href=&#34;https://gpac.wp.mines-telecom.fr/mp4box/&#34;&gt;MP4Box&lt;/a&gt;を使うので、これらを実行できるようにする。
Docker上で実行することもできて、その場合は以下のようにエイリアスを付けると便利。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ alias ffmpeg=&#39;docker run --rm -v `pwd`:/tmp/workdir jrottenberg/ffmpeg&#39;
$ alias MP4Box=&#39;docker run --rm -v `pwd`:/work sambaiz/mp4box&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;エンコード&#34;&gt;エンコード&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ffmpeg -i input.mp4 -vcodec libx264 -vb 448k -r 30 -x264opts no-scenecut -g 15 -acodec libfaac -ac 2 -ab 128k -frag_duration 5000000 -movflags empty_moov output.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;オプションの意味は多分こんな感じ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-vcodec libx264&lt;/code&gt;: 動画を&lt;a href=&#34;https://ja.wikipedia.org/wiki/H.264&#34;&gt;H.264&lt;/a&gt;にエンコードする&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-vb 448k&lt;/code&gt;: 動画のビットレート(bps)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-r 30&lt;/code&gt;: 動画のフレームレート(fps)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-x264opts no-scenecut&lt;/code&gt;: キーフレームの間隔を動画の内容によらず固定にする&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-g 15&lt;/code&gt;: キープレームの間隔。フレームレート(&lt;code&gt;-r&lt;/code&gt;) * フラグメントの時間(&lt;code&gt;-frag_duration&lt;/code&gt;) / キーフレームの間隔(&lt;code&gt;-g&lt;/code&gt;)が整数になるようにする。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-acodec libfaac&lt;/code&gt;: 音声を&lt;a href=&#34;https://ja.wikipedia.org/wiki/AAC&#34;&gt;AAC&lt;/a&gt;にエンコードする&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ac 2&lt;/code&gt;: 音声チャンネル数2(ステレオ)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ab 128k&lt;/code&gt;: 音声のビットレート(bps)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-frag_duration 5000000&lt;/code&gt;: フラグメント(セグメント)の時間(μs)。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-movflags empty_moov&lt;/code&gt;: 頭にmdat atom(データが含まれる)なしで、moov atom(メタ情報が含まれている)を書き始めるらしい。これにしないとMP4Boxに入れるときに失敗した。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ MP4Box -info -v input.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
[iso file] Current top box start before parsing 0
[iso file] Read Box type ftyp size 24 start 0
[iso file] Current top box start before parsing 24
[iso file] Read Box type free size 8 start 24
[iso file] Current top box start before parsing 32
[iso file] Read Box type mdat size 5216803 start 32 &amp;lt;--
[iso file] Current top box start before parsing 5216835
[iso file] Read Box type moov size 13332 start 5216835 &amp;lt;--
...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ MP4Box -info -v output.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[iso file] Current top box start before parsing 0
[iso file] Read Box type ftyp size 36 start 0
[iso file] Current top box start before parsing 36
[iso file] Read Box type moov size 1186 start 36 &amp;lt;--
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mpeg-dashにする&#34;&gt;MPEG-DASHにする&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ MP4Box -dash 5000 output.mp4
$ ls
input.mp4 output.mp4 output_dash.mpd output_dashinit.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;-dash&lt;/code&gt;はセグメントの時間。ただ、このmpdだと&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Multiplexed representations are intentionally not supported, as they are not compliant with the DASH-AVC/264 guidelines
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と出てしまい再生できない。中を見てみると、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Representation id=&amp;quot;1&amp;quot; mimeType=&amp;quot;video/mp4&amp;quot; codecs=&amp;quot;avc1.64000d,mp4a.40.2&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;240&amp;quot; frameRate=&amp;quot;30&amp;quot; sar=&amp;quot;1:1&amp;quot; audioSamplingRate=&amp;quot;44100&amp;quot; startWithSAP=&amp;quot;1&amp;quot; bandwidth=&amp;quot;564201&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;となっていて、動画と音声が一つのRepresentationになっているのがまずそうだったので、動画と音声を分けて実行した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ MP4Box -dash 5000 output.mp4#video output.mp4#audio
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果、できたmpdがこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;!-- MPD file Generated with GPAC version 0.6.1-rev14-g8eb0297-master  at 2016-10-30T14:47:02.962Z--&amp;gt;
&amp;lt;MPD xmlns=&amp;quot;urn:mpeg:dash:schema:mpd:2011&amp;quot; minBufferTime=&amp;quot;PT1.500S&amp;quot; type=&amp;quot;static&amp;quot; mediaPresentationDuration=&amp;quot;PT0H0M21.545S&amp;quot; maxSegmentDuration=&amp;quot;PT0H0M10.000S&amp;quot; profiles=&amp;quot;urn:mpeg:dash:profile:full:2011&amp;quot;&amp;gt;
 &amp;lt;ProgramInformation moreInformationURL=&amp;quot;http://gpac.sourceforge.net&amp;quot;&amp;gt;
  &amp;lt;Title&amp;gt;output_dash.mpd generated by GPAC&amp;lt;/Title&amp;gt;
 &amp;lt;/ProgramInformation&amp;gt;

 &amp;lt;Period duration=&amp;quot;PT0H0M21.545S&amp;quot;&amp;gt;
  &amp;lt;AdaptationSet segmentAlignment=&amp;quot;true&amp;quot; maxWidth=&amp;quot;320&amp;quot; maxHeight=&amp;quot;240&amp;quot; maxFrameRate=&amp;quot;30&amp;quot; par=&amp;quot;4:3&amp;quot; lang=&amp;quot;eng&amp;quot;&amp;gt;
   &amp;lt;Representation id=&amp;quot;1&amp;quot; mimeType=&amp;quot;video/mp4&amp;quot; codecs=&amp;quot;avc3.64000d&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;240&amp;quot; frameRate=&amp;quot;30&amp;quot; sar=&amp;quot;1:1&amp;quot; startWithSAP=&amp;quot;1&amp;quot; bandwidth=&amp;quot;437781&amp;quot;&amp;gt;
    &amp;lt;BaseURL&amp;gt;output_track1_dashinit.mp4&amp;lt;/BaseURL&amp;gt;
    &amp;lt;SegmentList timescale=&amp;quot;15360&amp;quot; duration=&amp;quot;153600&amp;quot;&amp;gt;
     &amp;lt;Initialization range=&amp;quot;0-1128&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;1129-556172&amp;quot; indexRange=&amp;quot;1129-1172&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;556173-1134265&amp;quot; indexRange=&amp;quot;556173-556216&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;1134266-1172888&amp;quot; indexRange=&amp;quot;1134266-1134309&amp;quot;/&amp;gt;
    &amp;lt;/SegmentList&amp;gt;
   &amp;lt;/Representation&amp;gt;
  &amp;lt;/AdaptationSet&amp;gt;
  &amp;lt;AdaptationSet segmentAlignment=&amp;quot;true&amp;quot; lang=&amp;quot;eng&amp;quot;&amp;gt;
   &amp;lt;Representation id=&amp;quot;2&amp;quot; mimeType=&amp;quot;audio/mp4&amp;quot; codecs=&amp;quot;mp4a.40.2&amp;quot; audioSamplingRate=&amp;quot;44100&amp;quot; startWithSAP=&amp;quot;1&amp;quot; bandwidth=&amp;quot;129622&amp;quot;&amp;gt;
    &amp;lt;AudioChannelConfiguration schemeIdUri=&amp;quot;urn:mpeg:dash:23003:3:audio_channel_configuration:2011&amp;quot; value=&amp;quot;2&amp;quot;/&amp;gt;
    &amp;lt;BaseURL&amp;gt;output_track2_dashinit.mp4&amp;lt;/BaseURL&amp;gt;
    &amp;lt;SegmentList timescale=&amp;quot;44100&amp;quot; duration=&amp;quot;441000&amp;quot;&amp;gt;
     &amp;lt;Initialization range=&amp;quot;0-1060&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;1061-163674&amp;quot; indexRange=&amp;quot;1061-1104&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;163675-326023&amp;quot; indexRange=&amp;quot;163675-163718&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;326024-349091&amp;quot; indexRange=&amp;quot;326024-326067&amp;quot;/&amp;gt;
    &amp;lt;/SegmentList&amp;gt;
   &amp;lt;/Representation&amp;gt;
  &amp;lt;/AdaptationSet&amp;gt;
 &amp;lt;/Period&amp;gt;
&amp;lt;/MPD&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;再生する&#34;&gt;再生する&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Dash-Industry-Forum/dash.js&#34;&gt;dash.js&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
     &amp;lt;script src=&amp;quot;http://cdn.dashjs.org/latest/dash.all.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
     &amp;lt;style&amp;gt;
         video {
             width: 640px;
             height: 360px;
          }
     &amp;lt;/style&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
     &amp;lt;div&amp;gt;
         &amp;lt;video data-dashjs-player autoplay src=&amp;quot;http://localhost:8080/output_dash.mpd&amp;quot; controls&amp;gt;&amp;lt;/video&amp;gt;
     &amp;lt;/div&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ローカルでサーバーを立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var static = require(&#39;node-static&#39;);

var fileServer = new static.Server(&#39;./public&#39;);

require(&#39;http&#39;).createServer(function (request, response) {
    request.addListener(&#39;end&#39;, function () {
        fileServer.serve(request, response);
    }).resume();
}).listen(8080);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.jstage.jst.go.jp/article/itej/67/2/67_109/_pdf&#34;&gt;次世代動画配信技術「MPEG-DASH」技術概要と標準化・関連技術動向&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/tomoyukilabs/items/c4eb7a829baac880797c&#34;&gt;FFmpegでHTML5 readyな動画ファイルを作成 (MP4, WebM) - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://yebisupress.dac.co.jp/2015/11/04/profile%EF%BC%9Fatom%EF%BC%9Fmp4%E3%81%AE%E3%82%88%E3%81%8F%E3%82%8F%E3%81%8B%E3%82%89%E3%81%AA%E3%81%84%E3%81%82%E3%82%8C%E3%81%93%E3%82%8C%EF%BC%88atom%E7%B7%A8/&#34;&gt;profile？atom？mp4のよくわからないあれこれ（atom編)&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>剣を振るVRゲームを作った</title>
          <link>https://www.sambaiz.net/article/29/</link>
          <pubDate>Sun, 30 Oct 2016 19:05:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/29/</guid>
          <description>

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/29_game.png&#34; alt=&#34;ゲーム画像&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Tlonh7D5UzY&#34;&gt;プレイ動画&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://vr.google.com/intl/ja_jp/cardboard/&#34;&gt;Cardboard&lt;/a&gt;にAndroidを入れて、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/29_card.jpg&#34; alt=&#34;Cardboard&#34; /&gt;&lt;/p&gt;

&lt;p&gt;iPhoneをくくりつけた傘を動かすと、画面の剣も動くのでこれで敵を倒すゲーム。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/29_sword.jpg&#34; alt=&#34;iPhoneをくくりつけた傘&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;h3 id=&#34;剣-ios&#34;&gt;剣(iOS)&lt;/h3&gt;

&lt;p&gt;剣にくくりつけたiPhoneの傾きの値をUnity(Android)に送信している。
iOSはClassic Bluetoothを自由に使えないので、Androidと通信する場合はBLEを使う。
BLEは通常だと20byteしか一度に送れないので、これを超えないよう注意する必要がある。&lt;/p&gt;

&lt;p&gt;BLEで通信するところは&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/26&#34;&gt;iOS端末をBLEのPeripheralにする&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;で作ったので、端末の傾きを取得して送るだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import UIKit
import CoreMotion

class Motion{

    let peripheral: BLEPeripheral
    let accelHandler:CMDeviceMotionHandler
    let manager = CMMotionManager()

    public init(peripheral :BLEPeripheral, label :UILabel){
        self.peripheral = peripheral

        accelHandler = {
            (data: CMDeviceMotion?, error: Error?) -&amp;gt; Void in
            let str = String(format: &amp;quot;%.1f %.1f %.1f&amp;quot;,
                             arguments: [data!.attitude.pitch * 180 / M_PI,
                                         data!.attitude.roll * 180 / M_PI,
                                         data!.attitude.yaw * 180 / M_PI]
                )
            let res = peripheral.update(str.data(using: String.Encoding.utf8))
            label.text = str + &amp;quot; &amp;quot; + String(res)
        }
    }

    func start(){
        if manager.isDeviceMotionAvailable {
            manager.deviceMotionUpdateInterval = 1 / 12;
            manager.startDeviceMotionUpdates(to: OperationQueue.current!, withHandler: accelHandler)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ゲーム-unity-android&#34;&gt;ゲーム(Unity &amp;amp; Android)&lt;/h3&gt;

&lt;p&gt;オライリーから&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873117577/&#34;&gt;UnityによるVRアプリケーション開発――作りながら学ぶバーチャルリアリティ入門&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;という本が出ていたので買った。Unityの初歩的なところやBlenderとかも説明があるのでおすすめ。
とりあえず&lt;a href=&#34;https://developers.google.com/vr/unity/&#34;&gt;GoogleのSDK&lt;/a&gt;をimportして、
Prefabの&lt;code&gt;GvrViewerMain&lt;/code&gt;を置くと二眼のそれっぽい感じになる。&lt;/p&gt;

&lt;p&gt;スコアとかゲームオーバーの状態と処理。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine;
using UnityEngine.UI;
using System.Collections;

public class Game : MonoBehaviour {

	public static int score = 0;
	public static bool gameOver = false;
	public static bool killed = false;

	public Text gameOverText;
	public Text scoreText;
	public GameObject enemy;

	void Start () {
		gameOverText.enabled = false;
	}

	void Update () {
		scoreText.text = &amp;quot;Score: &amp;quot; + score;
		if (gameOver) gameOverText.enabled = true;
		if (killed) {
			nextLevel ();
			killed = false;
		}
	}

	public void nextLevel(){
		var old = enemy;
		var x = Random.Range (-10, 10);
		enemy = (GameObject) Instantiate (
			enemy, new Vector3(x, 0, Mathf.Sqrt(10 * 10 - x * x)), Quaternion.Euler(0, 0, 0));
		Destroy (old);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;敵の当たり判定。剣に当たったら爆発して次のが出てくる。
体(見えないCapsule Colliderを設定している)に当たるとゲームオーバー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine;
using UnityEngine.UI;
using System.Collections;

public class MonsterHit : MonoBehaviour {

	public GameObject killEffect;

	void OnCollisionEnter(Collision collision) {
		switch (collision.gameObject.name) {
		case &amp;quot;sword&amp;quot;:
			if (!Game.gameOver) {
				Game.score += 1;
				Instantiate (killEffect, transform.position, transform.rotation);
				Game.killed = true;
			}
			break;

		case &amp;quot;Body&amp;quot;:
			Game.gameOver = true;
			break;
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;敵を動かす。スコアが上がるとスピードも上がる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine;
using System.Collections;

public class MonsterMove : MonoBehaviour {

	private float moveRate;

	void Start () {
		moveRate = 0.0f;
	}

	void Update () {
		transform.position = Vector3.Lerp (transform.position, new Vector3 (0, 0, -1.5f), moveRate);
		moveRate += 0.0001f * (Game.score + 1);
		transform.LookAt (new Vector3 (0, 0, -1.5f));
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;センサーの値を受け取って、剣を動かす。ここで使っているネイティブライブラリは前作ったもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/27&#34;&gt;UnityでAndroidのBLEを使うネイティブプラグインを作る&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine;
using System.Collections;

public class SwordMotion : MonoBehaviour {

	private AndroidJavaObject ble;
	private Quaternion q;

	void Start () {
		ble = new AndroidJavaObject (&amp;quot;net.sambaiz.unity_ble.BLE&amp;quot;, this.gameObject.name, &amp;quot;received&amp;quot;);
		q = Quaternion.Euler (0, 0, 0);
	}

	void Update () {
		transform.rotation = q;
	}

	void received(string message){
		var motionData = message.Split (&#39; &#39;); // pitch roll yaw
		q = Quaternion.Euler (
				90 - float.Parse (motionData [0]),
				float.Parse (motionData [1]),
				0) ;
	}

	void OnApplicationPause (bool pauseStatus)
	{
		if (ble != null) {
			if (pauseStatus) {
				ble.Call (&amp;quot;onPause&amp;quot;);
			} else {
				ble.Call (&amp;quot;onActive&amp;quot;);
			}
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>gcloudのアカウント切り替えとkubectlのcontext変更</title>
          <link>https://www.sambaiz.net/article/28/</link>
          <pubDate>Tue, 25 Oct 2016 20:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/28/</guid>
          <description>

&lt;p&gt;いつも迷うのでまとめた。&lt;/p&gt;

&lt;h2 id=&#34;gcloudのアカウント一覧と切り替え&#34;&gt;gcloudのアカウント一覧と切り替え&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud auth list
$ gcloud config set account `ACCOUNT`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;configにprojectなども設定している場合はconfig自体を作成して切り替えた方が楽。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud config configurations create &amp;lt;name&amp;gt;
$ gcloud config configurations activate &amp;lt;name&amp;gt;
$ gcloud config list
...
Your active configuration is: [&amp;lt;name&amp;gt;]

$ gcloud config set account &amp;lt;accout&amp;gt;
$ gcloud config set project &amp;lt;project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubectlのcontext変更&#34;&gt;kubectlのcontext変更&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl config current-context
$ kubectl config view # contexts
$ kubectl config use-context minikube
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityでAndroidのBLEを使うネイティブプラグインを作る</title>
          <link>https://www.sambaiz.net/article/27/</link>
          <pubDate>Sun, 23 Oct 2016 20:39:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/27/</guid>
          <description>

&lt;p&gt;UnityからBLEを使うためのネイティブプラグインを作る。&lt;/p&gt;

&lt;h2 id=&#34;android側&#34;&gt;Android側&lt;/h2&gt;

&lt;p&gt;まず、Activityなしのプロジェクトを作って、New ModuleからAndroid Libraryを選択。
これらのパッケージ名がUnityで使うものと被らないようにする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/Applications/Unity/PlaybackEngines/AndroidPlayer/Variations/mono/Release/Classes/classes.jar&lt;/code&gt;
をModuleの方のlibsに置く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import com.unity3d.player.UnityPlayer;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このjarは元々のやつとかぶってしまうので除外(build.gradleに追加)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;android.libraryVariants.all { variant -&amp;gt;
    variant.outputs.each { output -&amp;gt;
        output.packageLibrary.exclude(&#39;libs/classes.jar&#39;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Activiyは&lt;code&gt;UnityPlayer.currentActivity&lt;/code&gt;で取得でき、
Unity側のメソッドを呼ぶのも
&lt;code&gt;UnityPlayer.UnitySendMessage(mGameObjName, mCallBackName, new String(characteristic.getValue()));&lt;/code&gt;
のようにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class BLE {

    private final static String TAG = BLE.class.getSimpleName();
    private static final int REQUEST_ENABLE_BT = 1;
    private static final int MY_PERMISSION_RESPONSE = 2;

    private static final String PERIPHERAL_LOCAL_NAME = &amp;quot;my-ble&amp;quot;;
    private static final UUID PERIPHERAL_SERIVCE_UUID = UUID.fromString(&amp;quot;BF9CB85F-620C-4A67-BDD2-1A64213F74CA&amp;quot;);
    private static final UUID PERIPHERAL_CHARACTERISTIC_UUID = UUID.fromString(&amp;quot;5F83E23F-BCA1-42B3-B6F2-EA82BE46A93D&amp;quot;);
    private static final UUID CLIENT_CHARACTERISTIC_CONFIG = UUID.fromString(&amp;quot;00002902-0000-1000-8000-00805f9b34fb&amp;quot;);

    private String mGameObjName;
    private String mCallBackName;

    private BluetoothAdapter mBluetoothAdapter;
    private BluetoothGatt mBluetoothGatt;
    private BluetoothGattCharacteristic mCharacteristic;
    private Handler mHandler;

    // Stops scanning after 30 seconds.
    private static final long SCAN_PERIOD = 30000;

    public BLE(String gameObjName, String callBackName) {

        this.mGameObjName = gameObjName;
        this.mCallBackName = callBackName;

        mHandler = new Handler();

        if (!UnityPlayer.currentActivity.getPackageManager().hasSystemFeature(PackageManager.FEATURE_BLUETOOTH_LE)) {
            Toast.makeText(UnityPlayer.currentActivity, &amp;quot;BLEをサポートしていません&amp;quot;, Toast.LENGTH_SHORT).show();
            UnityPlayer.currentActivity.finish();
            return;
        }

        final BluetoothManager bluetoothManager =
                (BluetoothManager) UnityPlayer.currentActivity.getSystemService(Context.BLUETOOTH_SERVICE);
        mBluetoothAdapter = bluetoothManager.getAdapter();

        if (mBluetoothAdapter == null) {
            Toast.makeText(UnityPlayer.currentActivity, &amp;quot;Bluetoothをサポートしていません&amp;quot;, Toast.LENGTH_SHORT).show();
            UnityPlayer.currentActivity.finish();
            return;
        }

        onActive();
    }

    public void onActive() {
        Log.d(TAG, &amp;quot;onActive&amp;quot;);
        if (!mBluetoothAdapter.isEnabled()) {
            Intent enableBtIntent = new Intent(BluetoothAdapter.ACTION_REQUEST_ENABLE);
            UnityPlayer.currentActivity.startActivityForResult(enableBtIntent, REQUEST_ENABLE_BT);
        }

        scanLeDevice(true);
    }

    public void onPause() {
        Log.d(TAG, &amp;quot;onPause&amp;quot;);
        scanLeDevice(false);

        if(mCharacteristic != null){
            mBluetoothGatt.setCharacteristicNotification(
                    mCharacteristic,
                    false
            );
        }

        if(mBluetoothGatt != null) {
            mBluetoothGatt.close();
            mBluetoothGatt = null;
        }
    }

    private void scanLeDevice(final boolean enable) {
        if (enable) {
            mHandler.postDelayed(new Runnable() {
                @Override
                public void run() {
                    mBluetoothAdapter.stopLeScan(mLeScanCallback);
                }
            }, SCAN_PERIOD);

            mBluetoothAdapter.startLeScan(mLeScanCallback);
        } else {
            mBluetoothAdapter.stopLeScan(mLeScanCallback);
        }
    }

    private BluetoothAdapter.LeScanCallback mLeScanCallback =
            new BluetoothAdapter.LeScanCallback() {

                @Override
                public void onLeScan(final BluetoothDevice device, int rssi, byte[] scanRecord) {
                    if(PERIPHERAL_LOCAL_NAME.equals(device.getName())){
                        scanLeDevice(false);
                        connect(device);
                    }
                }
            };

    private boolean connect(BluetoothDevice device) {
        if (mBluetoothAdapter == null) {
            Log.w(TAG, &amp;quot;BluetoothAdapter not initialized or unspecified address.&amp;quot;);
            return false;
        }

        // Previously connected device.  Try to reconnect.
        if (mBluetoothGatt != null) {
            Log.d(TAG, &amp;quot;Trying to use an existing mBluetoothGatt for connection.&amp;quot;);
            if (mBluetoothGatt.connect()) {
                return true;
            } else {
                return false;
            }
        }

        mBluetoothGatt = device.connectGatt(UnityPlayer.currentActivity, false, mGattCallback);
        Log.d(TAG, &amp;quot;Trying to create a new connection.&amp;quot;);
        return true;
    }


    private final BluetoothGattCallback mGattCallback = new BluetoothGattCallback() {
        @Override
        public void onConnectionStateChange(BluetoothGatt gatt, int status, int newState) {
            if (newState == BluetoothProfile.STATE_CONNECTED) {

                scanLeDevice(false);
                Log.i(TAG, &amp;quot;Connected to GATT server.&amp;quot;);
                gatt.discoverServices();

            } else if (newState == BluetoothProfile.STATE_DISCONNECTED) {
                Log.i(TAG, &amp;quot;Disconnected from GATT server.&amp;quot;);
            } else{
                Log.i(TAG, &amp;quot;onConnectionStateChange:&amp;quot; + newState);
            }
        }

        @Override
        public void onServicesDiscovered(BluetoothGatt gatt, int status) {
            if (status == BluetoothGatt.GATT_SUCCESS) {
                mCharacteristic = gatt.getService(PERIPHERAL_SERIVCE_UUID).
                        getCharacteristic(PERIPHERAL_CHARACTERISTIC_UUID);

                gatt.setCharacteristicNotification(
                        mCharacteristic,
                        true
                );
                BluetoothGattDescriptor descriptor = mCharacteristic.getDescriptor(CLIENT_CHARACTERISTIC_CONFIG);
                descriptor.setValue(BluetoothGattDescriptor.ENABLE_NOTIFICATION_VALUE);
                mBluetoothGatt.writeDescriptor(descriptor);
            } else {
                Log.w(TAG, &amp;quot;onServicesDiscovered received: &amp;quot; + status);
            }
        }

        @Override
        public void onCharacteristicChanged(BluetoothGatt gatt,
                                            BluetoothGattCharacteristic characteristic) {
            UnityPlayer.UnitySendMessage(mGameObjName, mCallBackName, new String(characteristic.getValue()));
        }
    };

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Manifestに追加した分。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;uses-feature android:name=&amp;quot;android.hardware.bluetooth_le&amp;quot; android:required=&amp;quot;true&amp;quot;/&amp;gt;

&amp;lt;uses-permission android:name=&amp;quot;android.permission.BLUETOOTH&amp;quot; /&amp;gt;
&amp;lt;uses-permission android:name=&amp;quot;android.permission.BLUETOOTH_ADMIN&amp;quot; /&amp;gt;
&amp;lt;uses-permission android:name=&amp;quot;android.permission.ACCESS_COARSE_LOCATION&amp;quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できたらaarを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./gradlew assembleRelease
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;build/outputs/aar/*-release.aar&lt;/code&gt;をUnityの&lt;code&gt;Assets/Plugins/Android/libs&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;あと、依存aarはこの中に含まれないようなのでそれもまとめてコピーする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;task copyLibs(type: Copy) {
    from configurations.compile
    into &#39;build/outputs/aar&#39;
    exclude { details -&amp;gt; details.file.name.endsWith(&amp;quot;.jar&amp;quot;) }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Manifetstのmergeに失敗したのでSDKVersionを合わせる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;compileSdkVersion 22

defaultConfig {
    minSdkVersion 19
    targetSdkVersion 22
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;unity側&#34;&gt;Unity側&lt;/h2&gt;

&lt;p&gt;こんな感じでインスタンスを作り、
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/AndroidJavaObject.Call.html&#34;&gt;メソッドを呼べる&lt;/a&gt;。
ただし、unity editor上では&lt;code&gt;Init&#39;d AndroidJavaClass with null ptr!&lt;/code&gt;のエラーが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;plugin = new AndroidJavaObject(&amp;quot;net.sambaiz.unity_ble.BLE&amp;quot;, this.gameObject.name, &amp;quot;received&amp;quot;);

void received(string message){
	Debug.Log (&amp;quot;BLE:&amp;quot; + message);
}

void OnApplicationPause (bool pauseStatus)
{
	if (pauseStatus) {
		plugin.Call (&amp;quot;onPause&amp;quot;);
	} else {
		plugin.Call (&amp;quot;onActive&amp;quot;);
	}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>iOS端末をBLEのPeripheralにする</title>
          <link>https://www.sambaiz.net/article/26/</link>
          <pubDate>Sun, 23 Oct 2016 01:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/26/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://developer.apple.com/jp/documentation/CoreBluetoothPG.pdf&#34;&gt;CoreBluetoothプログラミングガイド&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;流れ&#34;&gt;流れ&lt;/h2&gt;

&lt;p&gt;まず、CoreBluetooth.frameworkを追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import CoreBluetooth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CBPeripheralManagerを生成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;peripheralManager = CBPeripheralManager(delegate: self, queue: nil)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stateが変化したらdelegateメソッドが呼ばれるので&lt;code&gt;.poweredOn&lt;/code&gt;であることを確認できれば
Managerの準備は完了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public func peripheralManagerDidUpdateState(_ peripheral: CBPeripheralManager){        
    switch (peripheral.state){
    case .poweredOn:
        print(&amp;quot;PeripheralManager state is ok&amp;quot;)
        ready = true

    default:
        print(&amp;quot;PeripheralManager state is ng:&amp;quot;, peripheral.state)
        ready = false
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Characteristicを作成。&lt;code&gt;CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify)&lt;/code&gt;で、
Centralが読みにくることも、通知を受け取ることもできるようにし、&lt;code&gt;CBAttributePermissions.readable&lt;/code&gt;でreadのみ許可する。
このvalueをnilにしておかないと、キャッシュされあとで変更できなくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;characteristic = CBMutableCharacteristic(
    type: CHARACTERISTIC_UUID,
    properties: CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify),
    value:nil,
    permissions:CBAttributePermissions.readable)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このCharacteristicのServiceを作成し、Managerに登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let service = CBMutableService(type: SERVICE_UUID, primary: true)
service.characteristics = [characteristic]
peripheralManager!.add(service)
ready = true         
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;public func peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?){
    if(error != nil){
        print(&amp;quot;Add Service error:&amp;quot;, error)
    }else{
        print(&amp;quot;Add Service ok&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ServiceをAdvertiseする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;peripheral.startAdvertising([
    CBAdvertisementDataLocalNameKey: LOCAL_NAME,
    CBAdvertisementDataServiceUUIDsKey: [SERVICE_UUID]
    ])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;public func peripheralManagerDidStartAdvertising(_ peripheral: CBPeripheralManager, error: Error?){
    if(error != nil){
        print(&amp;quot;Start Advertising error:&amp;quot;, error)
    }else{
        print(&amp;quot;Start Advertising ok&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通知要求してきたCentralに向けて通知する。&lt;code&gt;onSubscribedCentrals: nil&lt;/code&gt;で全てのCentralに送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;peripheralManager!.updateValue(d, for: characteristic, onSubscribedCentrals: nil)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;読みにきたときのdelegateメソッド。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public func peripheralManager(_ peripheral: CBPeripheralManager, didReceiveRead request: CBATTRequest){
    if (request.characteristic.uuid.isEqual(self.characteristic.uuid)) {
        if let value = self.characteristic.value{
            if (request.offset &amp;gt; value.count) {
                peripheral.respond(to: request, withResult: CBATTError.invalidOffset)
                print(&amp;quot;Read fail: invalid offset&amp;quot;)
                return;
            }
        }

        request.value = self.characteristic.value?.subdata(
            in: Range(uncheckedBounds: (request.offset, (self.characteristic.value?.count)! - request.offset))
        )
        peripheral.respond(to: request, withResult: CBATTError.success)
        print(&amp;quot;Read success&amp;quot;)
    }else{
        print(&amp;quot;Read fail: wrong characteristic uuid:&amp;quot;, request.characteristic.uuid)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;全体&#34;&gt;全体&lt;/h2&gt;

&lt;p&gt;エラーハンドリングは適当だけど、とりあえず動くものができた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import CoreBluetooth

class BLEPeripheral : NSObject, CBPeripheralManagerDelegate {

    let CHARACTERISTIC_UUID = CBUUID(string:&amp;quot;5F83E23F-BCA1-42B3-B6F2-EA82BE46A93D&amp;quot;)
    let SERVICE_UUID = CBUUID(string:&amp;quot;BF9CB85F-620C-4A67-BDD2-1A64213F74CA&amp;quot;)
    let LOCAL_NAME = &amp;quot;my-ble&amp;quot;

    private var peripheralManager : CBPeripheralManager?
    private var characteristic: CBMutableCharacteristic
    private var ready = false

    public override init(){
        characteristic = CBMutableCharacteristic(
            type: CHARACTERISTIC_UUID,
            properties: CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify),
            value:nil,
            permissions:CBAttributePermissions.readable)

        super.init()

        peripheralManager = CBPeripheralManager(delegate: self, queue: nil)
    }

    public func update(_ data: Data?) -&amp;gt; Bool {
        if(ready){
            if let d = data{
                characteristic.value = d
                return peripheralManager!.updateValue(d, for: characteristic, onSubscribedCentrals: nil)
            }else{
                print(&amp;quot;data is null&amp;quot;)
            }
        }else{
            print(&amp;quot;not ready&amp;quot;)
        }
        return false
    }



    /*
     CBPeripheralManagerDelegate
    */

    public func peripheralManagerDidUpdateState(_ peripheral: CBPeripheralManager){        
        switch (peripheral.state){
        case .poweredOn:
            print(&amp;quot;PeripheralManager state is ok&amp;quot;)

            let service = CBMutableService(type: SERVICE_UUID, primary: true)
            service.characteristics = [characteristic]
            peripheralManager!.add(service)
            ready = true

        default:
            print(&amp;quot;PeripheralManager state is ng:&amp;quot;, peripheral.state)
            ready = false
        }
    }

    public func peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?){
        if(error != nil){
            print(&amp;quot;Add Service error:&amp;quot;, error)
        }else{
            print(&amp;quot;Add Service ok&amp;quot;)
            peripheral.startAdvertising([
                CBAdvertisementDataLocalNameKey: LOCAL_NAME,
                CBAdvertisementDataServiceUUIDsKey: [SERVICE_UUID]
                ])
        }
    }

    public func peripheralManagerDidStartAdvertising(_ peripheral: CBPeripheralManager, error: Error?){
        if(error != nil){
            print(&amp;quot;Start Advertising error:&amp;quot;, error)
        }else{
            print(&amp;quot;Start Advertising ok&amp;quot;)
        }
    }

    public func peripheralManager(_ peripheral: CBPeripheralManager, didReceiveRead request: CBATTRequest){
        var value: Data?
        switch request.characteristic.uuid {
        case characteristic.uuid:
            value = characteristic.value

        default: break
        }

        if let v = value{
            if (request.offset &amp;gt; v.count) {
                peripheral.respond(to: request, withResult: CBATTError.invalidOffset)
                print(&amp;quot;Read fail: invalid offset&amp;quot;)
                return;
            }

            request.value = v.subdata(
                in: Range(uncheckedBounds: (request.offset, v.count - request.offset))
            )
            peripheral.respond(to: request, withResult: CBATTError.success)
            print(&amp;quot;Read success&amp;quot;)
        }else{
            print(&amp;quot;Read fail: wrong characteristic uuid:&amp;quot;, request.characteristic.uuid)
        }
    }

    public func peripheralManager(_ peripheral: CBPeripheralManager, central: CBCentral, didSubscribeTo characteristic: CBCharacteristic){
        print(&amp;quot;Subscribe to&amp;quot;, characteristic.uuid)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;現在の時間を1秒ごとに更新して通知がくることを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;timer = Timer.scheduledTimer(timeInterval: 1.0, target: self, selector: #selector(self.update), userInfo: nil, repeats: true)
timer!.fire()

public func update(){
    let now = String(format: &amp;quot;%.0f&amp;quot;, arguments: [Date().timeIntervalSince1970])
    peripheral.update(now.data(using: String.Encoding.utf8))
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>android-BluetoothLeGattを読む</title>
          <link>https://www.sambaiz.net/article/25/</link>
          <pubDate>Fri, 21 Oct 2016 14:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/25/</guid>
          <description>

&lt;p&gt;BLEのサンプルコード。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/googlesamples/android-BluetoothLeGatt&#34;&gt;https://github.com/googlesamples/android-BluetoothLeGatt&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;devicescanactivity&#34;&gt;DeviceScanActivity&lt;/h2&gt;

&lt;p&gt;BLEをサポートしているかチェックする。
&lt;a href=&#34;https://www.sambaiz.net/article/23&#34;&gt;BluetoothChat&lt;/a&gt;ではBluetoothAdapterを取得するのに
&lt;code&gt;BluetoothAdapter.getDefaultAdapter()&lt;/code&gt;のようにしていたが、
BLEをサポートしているような新しいバージョンでは、BluetoothManagerの&lt;code&gt;getAdapter()&lt;/code&gt;を使うらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    getActionBar().setTitle(R.string.title_devices);
    mHandler = new Handler();

    // Use this check to determine whether BLE is supported on the device.  Then you can
    // selectively disable BLE-related features.
    if (!getPackageManager().hasSystemFeature(PackageManager.FEATURE_BLUETOOTH_LE)) {
        Toast.makeText(this, R.string.ble_not_supported, Toast.LENGTH_SHORT).show();
        finish();
    }

    // Initializes a Bluetooth adapter.  For API level 18 and above, get a reference to
    // BluetoothAdapter through BluetoothManager.
    final BluetoothManager bluetoothManager =
            (BluetoothManager) getSystemService(Context.BLUETOOTH_SERVICE);
    mBluetoothAdapter = bluetoothManager.getAdapter();

    // Checks if Bluetooth is supported on the device.
    if (mBluetoothAdapter == null) {
        Toast.makeText(this, R.string.error_bluetooth_not_supported, Toast.LENGTH_SHORT).show();
        finish();
        return;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BluetoothChatと同様にBluetoothを有効にさせるのと、scanの開始。
&lt;code&gt;mBluetoothAdapter.startLeScan(mLeScanCallback)&lt;/code&gt;で
見つかったらcallbackの&lt;code&gt;onLeScan&lt;/code&gt;が呼ばれるのでデバイスリストに追加していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onResume() {
    super.onResume();

    // Ensures Bluetooth is enabled on the device.  If Bluetooth is not currently enabled,
    // fire an intent to display a dialog asking the user to grant permission to enable it.
    if (!mBluetoothAdapter.isEnabled()) {
        if (!mBluetoothAdapter.isEnabled()) {
            Intent enableBtIntent = new Intent(BluetoothAdapter.ACTION_REQUEST_ENABLE);
            startActivityForResult(enableBtIntent, REQUEST_ENABLE_BT);
        }
    }

    // Initializes list view adapter.
    mLeDeviceListAdapter = new LeDeviceListAdapter();
    setListAdapter(mLeDeviceListAdapter);
    scanLeDevice(true);
}

private void scanLeDevice(final boolean enable) {
    if (enable) {
        // Stops scanning after a pre-defined scan period.
        mHandler.postDelayed(new Runnable() {
            @Override
            public void run() {
                mScanning = false;
                mBluetoothAdapter.stopLeScan(mLeScanCallback);
                invalidateOptionsMenu();
            }
        }, SCAN_PERIOD);

        mScanning = true;
        mBluetoothAdapter.startLeScan(mLeScanCallback);
    } else {
        mScanning = false;
        mBluetoothAdapter.stopLeScan(mLeScanCallback);
    }
    invalidateOptionsMenu();
}

private BluetoothAdapter.LeScanCallback mLeScanCallback =
            new BluetoothAdapter.LeScanCallback() {
    @Override
    public void onLeScan(final BluetoothDevice device, int rssi, byte[] scanRecord) {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mLeDeviceListAdapter.addDevice(device);
                mLeDeviceListAdapter.notifyDataSetChanged();
            }
        });
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pause時はscanを止め、Listをクリアする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onPause() {
    super.onPause();
    scanLeDevice(false);
    mLeDeviceListAdapter.clear();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リストが選択されたら、scanを止め、そのデバイスの情報を渡してDeviceControlActivityを始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onListItemClick(ListView l, View v, int position, long id) {
    final BluetoothDevice device = mLeDeviceListAdapter.getDevice(position);
    if (device == null) return;
    final Intent intent = new Intent(this, DeviceControlActivity.class);
    intent.putExtra(DeviceControlActivity.EXTRAS_DEVICE_NAME, device.getName());
    intent.putExtra(DeviceControlActivity.EXTRAS_DEVICE_ADDRESS, device.getAddress());
    if (mScanning) {
        mBluetoothAdapter.stopLeScan(mLeScanCallback);
        mScanning = false;
    }
    startActivity(intent);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;devicecontrolactivity&#34;&gt;DeviceControlActivity&lt;/h2&gt;

&lt;p&gt;bindServiceでBluetoothLeServiceにServiceConnectionをバインドする。
Serviceと接続したらServiceConnectionの&lt;code&gt;onServiceConnected&lt;/code&gt;が呼ばれるので、
LocalBinderの&lt;code&gt;getService&lt;/code&gt;で取得し、初期化して対象のデバイスにconnectする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.android.com/guide/components/services.html?hl=ja&#34;&gt;Service&lt;/a&gt;は、
開始したコンポーネントや、ユーザーの操作に関係なく、バックグラウンドで動く。
サーバー/クライアントでいうサーバーで、複数のクライアントが同時にバインドでき、
その場合バインドしているクライアントが存在しなくなったら破棄される。
ホストプロセスのメインスレッドで実行される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.gatt_services_characteristics);

    final Intent intent = getIntent();
    mDeviceName = intent.getStringExtra(EXTRAS_DEVICE_NAME);
    mDeviceAddress = intent.getStringExtra(EXTRAS_DEVICE_ADDRESS);

    // Sets up UI references.
    ((TextView) findViewById(R.id.device_address)).setText(mDeviceAddress);
    mGattServicesList = (ExpandableListView) findViewById(R.id.gatt_services_list);
    mGattServicesList.setOnChildClickListener(servicesListClickListner);
    mConnectionState = (TextView) findViewById(R.id.connection_state);
    mDataField = (TextView) findViewById(R.id.data_value);

    getActionBar().setTitle(mDeviceName);
    getActionBar().setDisplayHomeAsUpEnabled(true);
    Intent gattServiceIntent = new Intent(this, BluetoothLeService.class);
    bindService(gattServiceIntent, mServiceConnection, BIND_AUTO_CREATE);
}

private final ServiceConnection mServiceConnection = new ServiceConnection() {

    @Override
    public void onServiceConnected(ComponentName componentName, IBinder service) {
        mBluetoothLeService = ((BluetoothLeService.LocalBinder) service).getService();
        if (!mBluetoothLeService.initialize()) {
            Log.e(TAG, &amp;quot;Unable to initialize Bluetooth&amp;quot;);
            finish();
        }
        // Automatically connects to the device upon successful start-up initialization.
        mBluetoothLeService.connect(mDeviceAddress);
    }

    @Override
    public void onServiceDisconnected(ComponentName componentName) {
        mBluetoothLeService = null;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BroadcastReceiverを登録して、対象デバイスに繋ぎに行く。
GATTのService(AndroidのServiceとは違うもの)やCharacteristicが見つかったら表示する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.bluetooth.com/specifications/gatt&#34;&gt;GATT(Generic Attribute Profile)&lt;/a&gt;
というのは、BLEで通信するときに使う階層化されたデータ構造の定義。
ProfileにはいくつかのServiceが含まれ、ServiceにはいくつかのCharacteristic、または他のServiceが含まれる。
Characteristicというのが値。ServiceやCharacteristicはUUIDで識別することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onResume() {
    super.onResume();
    registerReceiver(mGattUpdateReceiver, makeGattUpdateIntentFilter());
    if (mBluetoothLeService != null) {
        final boolean result = mBluetoothLeService.connect(mDeviceAddress);
        Log.d(TAG, &amp;quot;Connect request result=&amp;quot; + result);
    }
}

private final BroadcastReceiver mGattUpdateReceiver = new BroadcastReceiver() {
    @Override
    public void onReceive(Context context, Intent intent) {
        final String action = intent.getAction();
        if (BluetoothLeService.ACTION_GATT_CONNECTED.equals(action)) {
            mConnected = true;
            updateConnectionState(R.string.connected);
            invalidateOptionsMenu();
        } else if (BluetoothLeService.ACTION_GATT_DISCONNECTED.equals(action)) {
            mConnected = false;
            updateConnectionState(R.string.disconnected);
            invalidateOptionsMenu();
            clearUI();
        } else if (BluetoothLeService.ACTION_GATT_SERVICES_DISCOVERED.equals(action)) {
            // Show all the supported services and characteristics on the user interface.
            displayGattServices(mBluetoothLeService.getSupportedGattServices());
        } else if (BluetoothLeService.ACTION_DATA_AVAILABLE.equals(action)) {
            displayData(intent.getStringExtra(BluetoothLeService.EXTRA_DATA));
        }
    }
};

private static IntentFilter makeGattUpdateIntentFilter() {
    final IntentFilter intentFilter = new IntentFilter();
    intentFilter.addAction(BluetoothLeService.ACTION_GATT_CONNECTED);
    intentFilter.addAction(BluetoothLeService.ACTION_GATT_DISCONNECTED);
    intentFilter.addAction(BluetoothLeService.ACTION_GATT_SERVICES_DISCOVERED);
    intentFilter.addAction(BluetoothLeService.ACTION_DATA_AVAILABLE);
    return intentFilter;
}

private void displayGattServices(List&amp;lt;BluetoothGattService&amp;gt; gattServices) {
    if (gattServices == null) return;
    String uuid = null;
    String unknownServiceString = getResources().getString(R.string.unknown_service);
    String unknownCharaString = getResources().getString(R.string.unknown_characteristic);
    ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt; gattServiceData = new ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt;();
    ArrayList&amp;lt;ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt;&amp;gt; gattCharacteristicData
            = new ArrayList&amp;lt;ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt;&amp;gt;();
    mGattCharacteristics = new ArrayList&amp;lt;ArrayList&amp;lt;BluetoothGattCharacteristic&amp;gt;&amp;gt;();

    // Loops through available GATT Services.
    for (BluetoothGattService gattService : gattServices) {
        HashMap&amp;lt;String, String&amp;gt; currentServiceData = new HashMap&amp;lt;String, String&amp;gt;();
        uuid = gattService.getUuid().toString();
        currentServiceData.put(
                LIST_NAME, SampleGattAttributes.lookup(uuid, unknownServiceString));
        currentServiceData.put(LIST_UUID, uuid);
        gattServiceData.add(currentServiceData);

        ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt; gattCharacteristicGroupData =
                new ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt;();
        List&amp;lt;BluetoothGattCharacteristic&amp;gt; gattCharacteristics =
                gattService.getCharacteristics();
        ArrayList&amp;lt;BluetoothGattCharacteristic&amp;gt; charas =
                new ArrayList&amp;lt;BluetoothGattCharacteristic&amp;gt;();

        // Loops through available Characteristics.
        for (BluetoothGattCharacteristic gattCharacteristic : gattCharacteristics) {
            charas.add(gattCharacteristic);
            HashMap&amp;lt;String, String&amp;gt; currentCharaData = new HashMap&amp;lt;String, String&amp;gt;();
            uuid = gattCharacteristic.getUuid().toString();
            currentCharaData.put(
                    LIST_NAME, SampleGattAttributes.lookup(uuid, unknownCharaString));
            currentCharaData.put(LIST_UUID, uuid);
            gattCharacteristicGroupData.add(currentCharaData);
        }
        mGattCharacteristics.add(charas);
        gattCharacteristicData.add(gattCharacteristicGroupData);
    }

    SimpleExpandableListAdapter gattServiceAdapter = new SimpleExpandableListAdapter(
            this,
            gattServiceData,
            android.R.layout.simple_expandable_list_item_2,
            new String[] {LIST_NAME, LIST_UUID},
            new int[] { android.R.id.text1, android.R.id.text2 },
            gattCharacteristicData,
            android.R.layout.simple_expandable_list_item_2,
            new String[] {LIST_NAME, LIST_UUID},
            new int[] { android.R.id.text1, android.R.id.text2 }
    );
    mGattServicesList.setAdapter(gattServiceAdapter);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;BluetoothGattCharacteristic.PROPERTY_READ&lt;/code&gt;と
&lt;code&gt;BluetoothGattCharacteristic.PROPERTY_NOTIFY&lt;/code&gt;は
それぞれCharacteristicが読めることと、値が変化したときにPeripheralから通知が受けられることを表している。&lt;/p&gt;

&lt;p&gt;PeripheralというのはiBeaconのように、Advertising(見つかるようにする)し、接続される方。
それに対して接続する方をCentralという。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private final ExpandableListView.OnChildClickListener servicesListClickListner =
  new ExpandableListView.OnChildClickListener() {
      @Override
      public boolean onChildClick(ExpandableListView parent, View v, int groupPosition,
                                  int childPosition, long id) {
          if (mGattCharacteristics != null) {
              final BluetoothGattCharacteristic characteristic =
                      mGattCharacteristics.get(groupPosition).get(childPosition);
              final int charaProp = characteristic.getProperties();
              if ((charaProp | BluetoothGattCharacteristic.PROPERTY_READ) &amp;gt; 0) {
                  // If there is an active notification on a characteristic, clear
                  // it first so it doesn&#39;t update the data field on the user interface.
                  if (mNotifyCharacteristic != null) {
                      mBluetoothLeService.setCharacteristicNotification(
                              mNotifyCharacteristic, false);
                      mNotifyCharacteristic = null;
                  }
                  mBluetoothLeService.readCharacteristic(characteristic);
              }
              if ((charaProp | BluetoothGattCharacteristic.PROPERTY_NOTIFY) &amp;gt; 0) {
                  mNotifyCharacteristic = characteristic;
                  mBluetoothLeService.setCharacteristicNotification(
                          characteristic, true);
              }
              return true;
          }
          return false;
      }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BroadcastReceiverを外すのと、サービスのバインドをやめる処理。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onPause() {
    super.onPause();
    unregisterReceiver(mGattUpdateReceiver);
}

@Override
protected void onDestroy() {
    super.onDestroy();
    unbindService(mServiceConnection);
    mBluetoothLeService = null;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bluetoothleservice&#34;&gt;BluetoothLeService&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.android.com/reference/android/os/Binder.html&#34;&gt;Binder&lt;/a&gt;というのは
プロセス間通信(IPC; Inter-Process Communication)するためのもの。&lt;/p&gt;

&lt;p&gt;全てのクライアントのバインドが外れると&lt;code&gt;onUnbind&lt;/code&gt;が呼ばれるので、close処理をする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class LocalBinder extends Binder {
    BluetoothLeService getService() {
        return BluetoothLeService.this;
    }
}

@Override
public IBinder onBind(Intent intent) {
    return mBinder;
}

@Override
public boolean onUnbind(Intent intent) {
    // After using a given device, you should make sure that BluetoothGatt.close() is called
    // such that resources are cleaned up properly.  In this particular example, close() is
    // invoked when the UI is disconnected from the Service.
    close();
    return super.onUnbind(intent);
}

private final IBinder mBinder = new LocalBinder();

public void close() {
    if (mBluetoothGatt == null) {
        return;
    }
    mBluetoothGatt.close();
    mBluetoothGatt = null;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初期化処理。BluetoothAdapterを取得する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public boolean initialize() {
    // For API level 18 and above, get a reference to BluetoothAdapter through
    // BluetoothManager.
    if (mBluetoothManager == null) {
        mBluetoothManager = (BluetoothManager) getSystemService(Context.BLUETOOTH_SERVICE);
        if (mBluetoothManager == null) {
            Log.e(TAG, &amp;quot;Unable to initialize BluetoothManager.&amp;quot;);
            return false;
        }
    }

    mBluetoothAdapter = mBluetoothManager.getAdapter();
    if (mBluetoothAdapter == null) {
        Log.e(TAG, &amp;quot;Unable to obtain a BluetoothAdapter.&amp;quot;);
        return false;
    }

    return true;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;既に接続したことがあれば、そのBluetoothGattで再接続し、そうでなければ&lt;code&gt;connectGatt&lt;/code&gt;する。
callbackでは必要に応じてIntentをブロードキャストする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public boolean connect(final String address) {
    if (mBluetoothAdapter == null || address == null) {
        Log.w(TAG, &amp;quot;BluetoothAdapter not initialized or unspecified address.&amp;quot;);
        return false;
    }

    // Previously connected device.  Try to reconnect.
    if (mBluetoothDeviceAddress != null &amp;amp;&amp;amp; address.equals(mBluetoothDeviceAddress)
            &amp;amp;&amp;amp; mBluetoothGatt != null) {
        Log.d(TAG, &amp;quot;Trying to use an existing mBluetoothGatt for connection.&amp;quot;);
        if (mBluetoothGatt.connect()) {
            mConnectionState = STATE_CONNECTING;
            return true;
        } else {
            return false;
        }
    }

    final BluetoothDevice device = mBluetoothAdapter.getRemoteDevice(address);
    if (device == null) {
        Log.w(TAG, &amp;quot;Device not found.  Unable to connect.&amp;quot;);
        return false;
    }
    // We want to directly connect to the device, so we are setting the autoConnect
    // parameter to false.
    mBluetoothGatt = device.connectGatt(this, false, mGattCallback);
    Log.d(TAG, &amp;quot;Trying to create a new connection.&amp;quot;);
    mBluetoothDeviceAddress = address;
    mConnectionState = STATE_CONNECTING;
    return true;
}

private final BluetoothGattCallback mGattCallback = new BluetoothGattCallback() {
    @Override
    public void onConnectionStateChange(BluetoothGatt gatt, int status, int newState) {
        String intentAction;
        if (newState == BluetoothProfile.STATE_CONNECTED) {
            intentAction = ACTION_GATT_CONNECTED;
            mConnectionState = STATE_CONNECTED;
            broadcastUpdate(intentAction);
            Log.i(TAG, &amp;quot;Connected to GATT server.&amp;quot;);
            // Attempts to discover services after successful connection.
            Log.i(TAG, &amp;quot;Attempting to start service discovery:&amp;quot; +
                    mBluetoothGatt.discoverServices());

        } else if (newState == BluetoothProfile.STATE_DISCONNECTED) {
            intentAction = ACTION_GATT_DISCONNECTED;
            mConnectionState = STATE_DISCONNECTED;
            Log.i(TAG, &amp;quot;Disconnected from GATT server.&amp;quot;);
            broadcastUpdate(intentAction);
        }
    }

    @Override
    public void onServicesDiscovered(BluetoothGatt gatt, int status) {
        if (status == BluetoothGatt.GATT_SUCCESS) {
            broadcastUpdate(ACTION_GATT_SERVICES_DISCOVERED);
        } else {
            Log.w(TAG, &amp;quot;onServicesDiscovered received: &amp;quot; + status);
        }
    }

    @Override
    public void onCharacteristicRead(BluetoothGatt gatt,
                                     BluetoothGattCharacteristic characteristic,
                                     int status) {
        if (status == BluetoothGatt.GATT_SUCCESS) {
            broadcastUpdate(ACTION_DATA_AVAILABLE, characteristic);
        }
    }

    @Override
    public void onCharacteristicChanged(BluetoothGatt gatt,
                                        BluetoothGattCharacteristic characteristic) {
        broadcastUpdate(ACTION_DATA_AVAILABLE, characteristic);
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;private void broadcastUpdate(final String action) {
    final Intent intent = new Intent(action);
    sendBroadcast(intent);
}

private void broadcastUpdate(final String action,
                             final BluetoothGattCharacteristic characteristic) {
    final Intent intent = new Intent(action);

    // This is special handling for the Heart Rate Measurement profile.  Data parsing is
    // carried out as per profile specifications:
    // http://developer.bluetooth.org/gatt/characteristics/Pages/CharacteristicViewer.aspx?u=org.bluetooth.characteristic.heart_rate_measurement.xml
    if (UUID_HEART_RATE_MEASUREMENT.equals(characteristic.getUuid())) {
        int flag = characteristic.getProperties();
        int format = -1;
        if ((flag &amp;amp; 0x01) != 0) {
            format = BluetoothGattCharacteristic.FORMAT_UINT16;
            Log.d(TAG, &amp;quot;Heart rate format UINT16.&amp;quot;);
        } else {
            format = BluetoothGattCharacteristic.FORMAT_UINT8;
            Log.d(TAG, &amp;quot;Heart rate format UINT8.&amp;quot;);
        }
        final int heartRate = characteristic.getIntValue(format, 1);
        Log.d(TAG, String.format(&amp;quot;Received heart rate: %d&amp;quot;, heartRate));
        intent.putExtra(EXTRA_DATA, String.valueOf(heartRate));
    } else {
        // For all other profiles, writes the data formatted in HEX.
        final byte[] data = characteristic.getValue();
        if (data != null &amp;amp;&amp;amp; data.length &amp;gt; 0) {
            final StringBuilder stringBuilder = new StringBuilder(data.length);
            for(byte byteChar : data)
                stringBuilder.append(String.format(&amp;quot;%02X &amp;quot;, byteChar));
            intent.putExtra(EXTRA_DATA, new String(data) + &amp;quot;\n&amp;quot; + stringBuilder.toString());
        }
    }
    sendBroadcast(intent);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;切断する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void disconnect() {
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(TAG, &amp;quot;BluetoothAdapter not initialized&amp;quot;);
        return;
    }
    mBluetoothGatt.disconnect();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Characteristicを読む。結果は&lt;code&gt;BluetoothGattCallback#onCharacteristicRead&lt;/code&gt;で受け取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void readCharacteristic(BluetoothGattCharacteristic characteristic) {
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(TAG, &amp;quot;BluetoothAdapter not initialized&amp;quot;);
        return;
    }
    mBluetoothGatt.readCharacteristic(characteristic);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Characteristicの通知を設定。
Descriptorというのは、Characteristicの値を説明するもので、通知を受け取れるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void setCharacteristicNotification(BluetoothGattCharacteristic characteristic,
                                          boolean enabled) {
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(TAG, &amp;quot;BluetoothAdapter not initialized&amp;quot;);
        return;
    }
    mBluetoothGatt.setCharacteristicNotification(characteristic, enabled);

    // This is specific to Heart Rate Measurement.
    if (UUID_HEART_RATE_MEASUREMENT.equals(characteristic.getUuid())) {
        BluetoothGattDescriptor descriptor = characteristic.getDescriptor(
                UUID.fromString(SampleGattAttributes.CLIENT_CHARACTERISTIC_CONFIG));
        descriptor.setValue(BluetoothGattDescriptor.ENABLE_NOTIFICATION_VALUE);
        mBluetoothGatt.writeDescriptor(descriptor);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GATTのサービスのリストを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public List&amp;lt;BluetoothGattService&amp;gt; getSupportedGattServices() {
    if (mBluetoothGatt == null) return null;

    return mBluetoothGatt.getServices();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;android-6-0以降の端末で動かす&#34;&gt;Android 6.0以降の端末で動かす&lt;/h2&gt;

&lt;p&gt;Android6.0以降ではscanに位置情報のパーミッションが必要になったため、手を入れる必要がある。
&lt;a href=&#34;https://github.com/googlesamples/android-BluetoothLeGatt/pull/20&#34;&gt;プルリク&lt;/a&gt;は出てるのでそのうち入るかも。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;uses-permission android:name=&amp;quot;android.permission.ACCESS_COARSE_LOCATION&amp;quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SDK Versionが23以上だったら、さらにリクエストする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if (ContextCompat.checkSelfPermission(this, Manifest.permission.ACCESS_COARSE_LOCATION)
        != PackageManager.PERMISSION_GRANTED) {
    Log.w(&amp;quot;BleActivity&amp;quot;, &amp;quot;Location access not granted!&amp;quot;);
    ActivityCompat.requestPermissions(this,
            new String[]{Manifest.permission.ACCESS_COARSE_LOCATION},
            MY_PERMISSION_RESPONSE);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PackerでAMIを作る</title>
          <link>https://www.sambaiz.net/article/24/</link>
          <pubDate>Tue, 18 Oct 2016 22:37:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/24/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.packer.io/&#34;&gt;https://www.packer.io/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;いろんなプラットフォームのイメージを作ることができるツール。
これでfluentdのログサーバーのAMIを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install packer # mac
$ packer -v
0.10.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定ファイルはこんな感じ。&lt;code&gt;variables&lt;/code&gt;の値は&lt;code&gt;{{user ... }}&lt;/code&gt;のところで使われる。
&lt;code&gt;builders&lt;/code&gt;に作るイメージの情報を書いて、&lt;code&gt;provisioners&lt;/code&gt;で環境を作る。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;provisioners&lt;/code&gt;にはchefやansibleなども指定できるが、
継ぎ足し継ぎ足しで秘伝のタレ化したAMIも最初は、コマンドいくつか実行するだけなのでとりあえず手作業で作った、後でなんとかするなんてものもあったりして、
そういうものは無理にchefなどで始めず、手軽にshellでpacker buildするといいと思う。
手作業よりも楽だしソースが別にあるので使われていないAMIを消すのも簡単。&lt;/p&gt;

&lt;p&gt;fileではpermissionがないところに置くことができないので、一旦置いてshellで移動する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;aws_access_key&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;aws_secret_key&amp;quot;: &amp;quot;&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;,
    &amp;quot;access_key&amp;quot;: &amp;quot;{{user `aws_access_key`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `aws_secret_key`}}&amp;quot;,
    &amp;quot;region&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;,
    &amp;quot;source_ami&amp;quot;: &amp;quot;ami-1a15c77b&amp;quot;,
    &amp;quot;instance_type&amp;quot;: &amp;quot;t2.small&amp;quot;,
    &amp;quot;ssh_username&amp;quot;: &amp;quot;ec2-user&amp;quot;,
    &amp;quot;ami_name&amp;quot;: &amp;quot;fluentd-logserver {{timestamp}}&amp;quot;
  }],
  &amp;quot;provisioners&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
    &amp;quot;source&amp;quot;: &amp;quot;td-agent.conf&amp;quot;,
    &amp;quot;destination&amp;quot;: &amp;quot;/home/ec2-user/td-agent.conf&amp;quot;
  },
  {
    &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
    &amp;quot;inline&amp;quot;: [
      &amp;quot;curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh&amp;quot;,
      &amp;quot;sudo mv /home/ec2-user/td-agent.conf /etc/td-agent/td-agent.conf&amp;quot;,
      &amp;quot;sudo /etc/init.d/td-agent restart&amp;quot;
    ]
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ packer validate fluentd-logserver.json
Template validated successfully.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;buildのとき&lt;code&gt;-var&lt;/code&gt;でvariablesを渡すことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ packer build \
    -var &#39;aws_access_key=YOUR ACCESS KEY&#39; \
    -var &#39;aws_secret_key=YOUR SECRET KEY&#39; \
    fluentd-logserver.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行すると実際にインスタンスを立ち上げ、AMIを作成し始める。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>android-bluetoothChatを読む</title>
          <link>https://www.sambaiz.net/article/23/</link>
          <pubDate>Sat, 15 Oct 2016 14:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/23/</guid>
          <description>

&lt;p&gt;Classic Bluetoothのサンプルコード。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/googlesamples/android-BluetoothChat&#34;&gt;https://github.com/googlesamples/android-BluetoothChat&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;mainactivity&#34;&gt;MainActivity&lt;/h2&gt;

&lt;p&gt;まず、MainActivity。&lt;/p&gt;

&lt;p&gt;Fragmentのcommitや、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    if (savedInstanceState == null) {
        FragmentTransaction transaction = getSupportFragmentManager().beginTransaction();
        BluetoothChatFragment fragment = new BluetoothChatFragment();
        transaction.replace(R.id.sample_content_fragment, fragment);
        transaction.commit();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;オプションメニューの設定をしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 最初だけ呼ばれる
@Override
public boolean onCreateOptionsMenu(Menu menu) {
    getMenuInflater().inflate(R.menu.main, menu);
    return true;
}

// 表示される度に呼ばれる
@Override
public boolean onPrepareOptionsMenu(Menu menu) {
    MenuItem logToggle = menu.findItem(R.id.menu_toggle_log);
    logToggle.setVisible(findViewById(R.id.sample_output) instanceof ViewAnimator);
    logToggle.setTitle(mLogShown ? R.string.sample_hide_log : R.string.sample_show_log);

    return super.onPrepareOptionsMenu(menu);
}

@Override
public boolean onOptionsItemSelected(MenuItem item) {
    switch(item.getItemId()) {
        case R.id.menu_toggle_log:
            mLogShown = !mLogShown;
            ViewAnimator output = (ViewAnimator) findViewById(R.id.sample_output);
            if (mLogShown) {
                output.setDisplayedChild(1);
            } else {
                output.setDisplayedChild(0);
            }　
            // メニューを再作成する(onCreateOptionsMenu, onPrepareOptionsMenuが呼ばれる)
            supportInvalidateOptionsMenu();
            return true;
    }
    return super.onOptionsItemSelected(item);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bluetoothchatfragment&#34;&gt;BluetoothChatFragment&lt;/h2&gt;

&lt;p&gt;onCreateではBluetoothAdapterを取得して、Bluetoothが使えるかどうかを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setHasOptionsMenu(true);
    // Get local Bluetooth adapter
    mBluetoothAdapter = BluetoothAdapter.getDefaultAdapter();

    // If the adapter is null, then Bluetooth is not supported
    if (mBluetoothAdapter == null) {
        FragmentActivity activity = getActivity();
        Toast.makeText(activity, &amp;quot;Bluetooth is not available&amp;quot;, Toast.LENGTH_LONG).show();
        activity.finish();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;onStartではもしBluetoothが有効でなければ有効にするよう要求し、有効になったらsetupする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onStart() {
    super.onStart();
    // If BT is not on, request that it be enabled.
    // setupChat() will then be called during onActivityResult
    if (!mBluetoothAdapter.isEnabled()) {
        Intent enableIntent = new Intent(BluetoothAdapter.ACTION_REQUEST_ENABLE);
        startActivityForResult(enableIntent, REQUEST_ENABLE_BT);
        // Otherwise, setup the chat session
    } else if (mChatService == null) {
        setupChat();
    }
}

public void onActivityResult(int requestCode, int resultCode, Intent data) {
    switch (requestCode) {
        case REQUEST_CONNECT_DEVICE_SECURE:
            // When DeviceListActivity returns with a device to connect
            if (resultCode == Activity.RESULT_OK) {
                connectDevice(data, true);
            }
            break;
        case REQUEST_CONNECT_DEVICE_INSECURE:
            // When DeviceListActivity returns with a device to connect
            if (resultCode == Activity.RESULT_OK) {
                connectDevice(data, false);
            }
            break;
        case REQUEST_ENABLE_BT:
            // When the request to enable Bluetooth returns
            if (resultCode == Activity.RESULT_OK) {
                // Bluetooth is now enabled, so set up a chat session
                setupChat();
            } else {
                // User did not enable Bluetooth or an error occurred
                Log.d(TAG, &amp;quot;BT not enabled&amp;quot;);
                Toast.makeText(getActivity(), R.string.bt_not_enabled_leaving,
                        Toast.LENGTH_SHORT).show();
                getActivity().finish();
            }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;onActivityResultではDeviceListActivityで、接続する端末を選択した結果もハンドリングしていて、connectDeviceを呼ぶ。
アドレスからmBluetoothAdapter.getRemoteDevice(address)でdeviceを取得して、これをサービスに渡して接続する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void connectDevice(Intent data, boolean secure) {
    // Get the device MAC address
    String address = data.getExtras()
            .getString(DeviceListActivity.EXTRA_DEVICE_ADDRESS);
    // Get the BluetoothDevice object
    BluetoothDevice device = mBluetoothAdapter.getRemoteDevice(address);
    // Attempt to connect to the device
    mChatService.connect(device, secure);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serviceのstartとstop。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onDestroy() {
    super.onDestroy();
    if (mChatService != null) {
        mChatService.stop();
    }
}

@Override
public void onResume() {
    super.onResume();

    // Performing this check in onResume() covers the case in which BT was
    // not enabled during onStart(), so we were paused to enable it...
    // onResume() will be called when ACTION_REQUEST_ENABLE activity returns.
    if (mChatService != null) {
        // Only if the state is STATE_NONE, do we know that we haven&#39;t started already
        if (mChatService.getState() == BluetoothChatService.STATE_NONE) {
            // Start the Bluetooth chat services
            mChatService.start();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;viewまわり。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container,
                         @Nullable Bundle savedInstanceState) {
    return inflater.inflate(R.layout.fragment_bluetooth_chat, container, false);
}

@Override
public void onViewCreated(View view, @Nullable Bundle savedInstanceState) {
    mConversationView = (ListView) view.findViewById(R.id.in);
    mOutEditText = (EditText) view.findViewById(R.id.edit_text_out);
    mSendButton = (Button) view.findViewById(R.id.button_send);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;setupChatでは会話用リストにAdapterをセットしたり、入力欄やボタンにリスナーを登録するほかに、ChatServiceを初期化する。
初期化する際に第二引数として渡すmHandlerでは、Serviceからのメッセージにより処理を行う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void setupChat() {
    Log.d(TAG, &amp;quot;setupChat()&amp;quot;);

    // Initialize the array adapter for the conversation thread
    mConversationArrayAdapter = new ArrayAdapter&amp;lt;String&amp;gt;(getActivity(), R.layout.message);

    mConversationView.setAdapter(mConversationArrayAdapter);

    // Initialize the compose field with a listener for the return key
    mOutEditText.setOnEditorActionListener(mWriteListener);

    // Initialize the send button with a listener that for click events
    mSendButton.setOnClickListener(new View.OnClickListener() {
        public void onClick(View v) {
            // Send a message using content of the edit text widget
            View view = getView();
            if (null != view) {
                TextView textView = (TextView) view.findViewById(R.id.edit_text_out);
                String message = textView.getText().toString();
                sendMessage(message);
            }
        }
    });

    // Initialize the BluetoothChatService to perform bluetooth connections
    mChatService = new BluetoothChatService(getActivity(), mHandler);

    // Initialize the buffer for outgoing messages
    mOutStringBuffer = new StringBuffer(&amp;quot;&amp;quot;);
}

private TextView.OnEditorActionListener mWriteListener = new TextView.OnEditorActionListener() {
  public boolean onEditorAction(TextView view, int actionId, KeyEvent event) {
      // If the action is a key-up event on the return key, send the message
      if (actionId == EditorInfo.IME_NULL &amp;amp;&amp;amp; event.getAction() == KeyEvent.ACTION_UP) {
          String message = view.getText().toString();
          sendMessage(message);
      }
      return true;
  }
};

private final Handler mHandler = new Handler() {
    @Override
    public void handleMessage(Message msg) {
        FragmentActivity activity = getActivity();
        switch (msg.what) {
            case Constants.MESSAGE_STATE_CHANGE:
                switch (msg.arg1) {
                    case BluetoothChatService.STATE_CONNECTED:
                        setStatus(getString(R.string.title_connected_to, mConnectedDeviceName));
                        mConversationArrayAdapter.clear();
                        break;
                    case BluetoothChatService.STATE_CONNECTING:
                        setStatus(R.string.title_connecting);
                        break;
                    case BluetoothChatService.STATE_LISTEN:
                    case BluetoothChatService.STATE_NONE:
                        setStatus(R.string.title_not_connected);
                        break;
                }
                break;
            case Constants.MESSAGE_WRITE:
                byte[] writeBuf = (byte[]) msg.obj;
                // construct a string from the buffer
                String writeMessage = new String(writeBuf);
                mConversationArrayAdapter.add(&amp;quot;Me:  &amp;quot; + writeMessage);
                break;
            case Constants.MESSAGE_READ:
                byte[] readBuf = (byte[]) msg.obj;
                // construct a string from the valid bytes in the buffer
                String readMessage = new String(readBuf, 0, msg.arg1);
                mConversationArrayAdapter.add(mConnectedDeviceName + &amp;quot;:  &amp;quot; + readMessage);
                break;
            case Constants.MESSAGE_DEVICE_NAME:
                // save the connected device&#39;s name
                mConnectedDeviceName = msg.getData().getString(Constants.DEVICE_NAME);
                if (null != activity) {
                    Toast.makeText(activity, &amp;quot;Connected to &amp;quot;
                            + mConnectedDeviceName, Toast.LENGTH_SHORT).show();
                }
                break;
            case Constants.MESSAGE_TOAST:
                if (null != activity) {
                    Toast.makeText(activity, msg.getData().getString(Constants.TOAST),
                            Toast.LENGTH_SHORT).show();
                }
                break;
        }
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デバイスを検出可能にするのと、DeviceListActivityを始めるメニュー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onCreateOptionsMenu(Menu menu, MenuInflater inflater) {
    inflater.inflate(R.menu.bluetooth_chat, menu);
}

@Override
public boolean onOptionsItemSelected(MenuItem item) {
    switch (item.getItemId()) {
        case R.id.secure_connect_scan: {
            // Launch the DeviceListActivity to see devices and do scan
            Intent serverIntent = new Intent(getActivity(), DeviceListActivity.class);
            startActivityForResult(serverIntent, REQUEST_CONNECT_DEVICE_SECURE);
            return true;
        }
        case R.id.insecure_connect_scan: {
            // Launch the DeviceListActivity to see devices and do scan
            Intent serverIntent = new Intent(getActivity(), DeviceListActivity.class);
            startActivityForResult(serverIntent, REQUEST_CONNECT_DEVICE_INSECURE);
            return true;
        }
        case R.id.discoverable: {
            // Ensure this device is discoverable by others
            ensureDiscoverable();
            return true;
        }
    }
    return false;
}

private void ensureDiscoverable() {
    if (mBluetoothAdapter.getScanMode() !=
            BluetoothAdapter.SCAN_MODE_CONNECTABLE_DISCOVERABLE) {
        Intent discoverableIntent = new Intent(BluetoothAdapter.ACTION_REQUEST_DISCOVERABLE);
        discoverableIntent.putExtra(BluetoothAdapter.EXTRA_DISCOVERABLE_DURATION, 300);
        startActivity(discoverableIntent);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bluetoothchatservice&#34;&gt;BluetoothChatService&lt;/h2&gt;

&lt;p&gt;初期stateはSTATE_NONE。
setStateしたときにobtainMessageでstateが変わったときの処理をhandlerに行わせる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public BluetoothChatService(Context context, Handler handler) {
    mAdapter = BluetoothAdapter.getDefaultAdapter();
    mState = STATE_NONE;
    mHandler = handler;
}

private synchronized void setState(int state) {
    Log.d(TAG, &amp;quot;setState() &amp;quot; + mState + &amp;quot; -&amp;gt; &amp;quot; + state);
    mState = state;

    // Give the new state to the Handler so the UI Activity can update
    mHandler.obtainMessage(Constants.MESSAGE_STATE_CHANGE, state, -1).sendToTarget();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接続しようとしている、した、される処理はそれぞれ別スレッドで行われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public synchronized void start() {
    Log.d(TAG, &amp;quot;start&amp;quot;);

    // Cancel any thread attempting to make a connection
    if (mConnectThread != null) {
        mConnectThread.cancel();
        mConnectThread = null;
    }

    // Cancel any thread currently running a connection
    if (mConnectedThread != null) {
        mConnectedThread.cancel();
        mConnectedThread = null;
    }

    setState(STATE_LISTEN);

    // Start the thread to listen on a BluetoothServerSocket
    if (mSecureAcceptThread == null) {
        mSecureAcceptThread = new AcceptThread(true);
        mSecureAcceptThread.start();
    }
    if (mInsecureAcceptThread == null) {
        mInsecureAcceptThread = new AcceptThread(false);
        mInsecureAcceptThread.start();
    }
}

public synchronized void stop() {
    Log.d(TAG, &amp;quot;stop&amp;quot;);

    if (mConnectThread != null) {
        mConnectThread.cancel();
        mConnectThread = null;
    }

    if (mConnectedThread != null) {
        mConnectedThread.cancel();
        mConnectedThread = null;
    }

    if (mSecureAcceptThread != null) {
        mSecureAcceptThread.cancel();
        mSecureAcceptThread = null;
    }

    if (mInsecureAcceptThread != null) {
        mInsecureAcceptThread.cancel();
        mInsecureAcceptThread = null;
    }
    setState(STATE_NONE);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず、接続するためのConnectThread。コンストラクタでつなげるdeviceからsocketを作成し、
runで接続する。接続できたらconnectedを呼び、ConnectedThreadを始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private class ConnectThread extends Thread {
    private final BluetoothSocket mmSocket;
    private final BluetoothDevice mmDevice;
    private String mSocketType;

    public ConnectThread(BluetoothDevice device, boolean secure) {
        mmDevice = device;
        BluetoothSocket tmp = null;
        mSocketType = secure ? &amp;quot;Secure&amp;quot; : &amp;quot;Insecure&amp;quot;;

        // Get a BluetoothSocket for a connection with the
        // given BluetoothDevice
        try {
            if (secure) {
                tmp = device.createRfcommSocketToServiceRecord(
                        MY_UUID_SECURE);
            } else {
                tmp = device.createInsecureRfcommSocketToServiceRecord(
                        MY_UUID_INSECURE);
            }
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;Socket Type: &amp;quot; + mSocketType + &amp;quot;create() failed&amp;quot;, e);
        }
        mmSocket = tmp;
    }

    public void run() {
        Log.i(TAG, &amp;quot;BEGIN mConnectThread SocketType:&amp;quot; + mSocketType);
        setName(&amp;quot;ConnectThread&amp;quot; + mSocketType);

        // Always cancel discovery because it will slow down a connection
        mAdapter.cancelDiscovery();

        // Make a connection to the BluetoothSocket
        try {
            // This is a blocking call and will only return on a
            // successful connection or an exception
            mmSocket.connect();
        } catch (IOException e) {
            // Close the socket
            try {
                mmSocket.close();
            } catch (IOException e2) {
                Log.e(TAG, &amp;quot;unable to close() &amp;quot; + mSocketType +
                        &amp;quot; socket during connection failure&amp;quot;, e2);
            }
            connectionFailed();
            return;
        }

        // Reset the ConnectThread because we&#39;re done
        synchronized (BluetoothChatService.this) {
            mConnectThread = null;
        }

        // Start the connected thread
        connected(mmSocket, mmDevice, mSocketType);
    }

    public void cancel() {
        try {
            mmSocket.close();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;close() of connect &amp;quot; + mSocketType + &amp;quot; socket failed&amp;quot;, e);
        }
    }
}

public synchronized void connected(BluetoothSocket socket, BluetoothDevice
        device, final String socketType) {
    Log.d(TAG, &amp;quot;connected, Socket Type:&amp;quot; + socketType);

    // Cancel the thread that completed the connection
    if (mConnectThread != null) {
        mConnectThread.cancel();
        mConnectThread = null;
    }

    // Cancel any thread currently running a connection
    if (mConnectedThread != null) {
        mConnectedThread.cancel();
        mConnectedThread = null;
    }

    // Cancel the accept thread because we only want to connect to one device
    if (mSecureAcceptThread != null) {
        mSecureAcceptThread.cancel();
        mSecureAcceptThread = null;
    }
    if (mInsecureAcceptThread != null) {
        mInsecureAcceptThread.cancel();
        mInsecureAcceptThread = null;
    }

    // Start the thread to manage the connection and perform transmissions
    mConnectedThread = new ConnectedThread(socket, socketType);
    mConnectedThread.start();

    // Send the name of the connected device back to the UI Activity
    Message msg = mHandler.obtainMessage(Constants.MESSAGE_DEVICE_NAME);
    Bundle bundle = new Bundle();
    bundle.putString(Constants.DEVICE_NAME, device.getName());
    msg.setData(bundle);
    mHandler.sendMessage(msg);

    setState(STATE_CONNECTED);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ConnectedThreadではsocketからinputStreamとoutputStreamを取得し、
runでは読んでメッセージで渡し、writeで書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private class ConnectedThread extends Thread {
    private final BluetoothSocket mmSocket;
    private final InputStream mmInStream;
    private final OutputStream mmOutStream;

    public ConnectedThread(BluetoothSocket socket, String socketType) {
        Log.d(TAG, &amp;quot;create ConnectedThread: &amp;quot; + socketType);
        mmSocket = socket;
        InputStream tmpIn = null;
        OutputStream tmpOut = null;

        // Get the BluetoothSocket input and output streams
        try {
            tmpIn = socket.getInputStream();
            tmpOut = socket.getOutputStream();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;temp sockets not created&amp;quot;, e);
        }

        mmInStream = tmpIn;
        mmOutStream = tmpOut;
    }

    public void run() {
        Log.i(TAG, &amp;quot;BEGIN mConnectedThread&amp;quot;);
        byte[] buffer = new byte[1024];
        int bytes;

        // Keep listening to the InputStream while connected
        while (mState == STATE_CONNECTED) {
            try {
                // Read from the InputStream
                bytes = mmInStream.read(buffer);

                // Send the obtained bytes to the UI Activity
                mHandler.obtainMessage(Constants.MESSAGE_READ, bytes, -1, buffer)
                        .sendToTarget();
            } catch (IOException e) {
                Log.e(TAG, &amp;quot;disconnected&amp;quot;, e);
                connectionLost();
                // Start the service over to restart listening mode
                BluetoothChatService.this.start();
                break;
            }
        }
    }

    /**
     * Write to the connected OutStream.
     *
     * @param buffer The bytes to write
     */
    public void write(byte[] buffer) {
        try {
            mmOutStream.write(buffer);

            // Share the sent message back to the UI Activity
            mHandler.obtainMessage(Constants.MESSAGE_WRITE, -1, -1, buffer)
                    .sendToTarget();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;Exception during write&amp;quot;, e);
        }
    }

    public void cancel() {
        try {
            mmSocket.close();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;close() of connect socket failed&amp;quot;, e);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;AcceptThreadでは常に受け入れられる形にしておく。もしつながったらConnectThreadと同様にconnectedする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private class AcceptThread extends Thread {
    // The local server socket
    private final BluetoothServerSocket mmServerSocket;
    private String mSocketType;

    public AcceptThread(boolean secure) {
        BluetoothServerSocket tmp = null;
        mSocketType = secure ? &amp;quot;Secure&amp;quot; : &amp;quot;Insecure&amp;quot;;

        // Create a new listening server socket
        try {
            if (secure) {
                tmp = mAdapter.listenUsingRfcommWithServiceRecord(NAME_SECURE,
                        MY_UUID_SECURE);
            } else {
                tmp = mAdapter.listenUsingInsecureRfcommWithServiceRecord(
                        NAME_INSECURE, MY_UUID_INSECURE);
            }
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;Socket Type: &amp;quot; + mSocketType + &amp;quot;listen() failed&amp;quot;, e);
        }
        mmServerSocket = tmp;
    }

    public void run() {
        Log.d(TAG, &amp;quot;Socket Type: &amp;quot; + mSocketType +
                &amp;quot;BEGIN mAcceptThread&amp;quot; + this);
        setName(&amp;quot;AcceptThread&amp;quot; + mSocketType);

        BluetoothSocket socket = null;

        // Listen to the server socket if we&#39;re not connected
        while (mState != STATE_CONNECTED) {
            try {
                // This is a blocking call and will only return on a
                // successful connection or an exception
                socket = mmServerSocket.accept();
            } catch (IOException e) {
                Log.e(TAG, &amp;quot;Socket Type: &amp;quot; + mSocketType + &amp;quot;accept() failed&amp;quot;, e);
                break;
            }

            // If a connection was accepted
            if (socket != null) {
                synchronized (BluetoothChatService.this) {
                    switch (mState) {
                        case STATE_LISTEN:
                        case STATE_CONNECTING:
                            // Situation normal. Start the connected thread.
                            connected(socket, socket.getRemoteDevice(),
                                    mSocketType);
                            break;
                        case STATE_NONE:
                        case STATE_CONNECTED:
                            // Either not ready or already connected. Terminate new socket.
                            try {
                                socket.close();
                            } catch (IOException e) {
                                Log.e(TAG, &amp;quot;Could not close unwanted socket&amp;quot;, e);
                            }
                            break;
                    }
                }
            }
        }
        Log.i(TAG, &amp;quot;END mAcceptThread, socket Type: &amp;quot; + mSocketType);

    }

    public void cancel() {
        Log.d(TAG, &amp;quot;Socket Type&amp;quot; + mSocketType + &amp;quot;cancel &amp;quot; + this);
        try {
            mmServerSocket.close();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;Socket Type&amp;quot; + mSocketType + &amp;quot;close() of server failed&amp;quot;, e);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;connectでは、接続しようとしているならそれをキャンセル、接続したものがあるならsocketを閉じて
新しい接続を始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public synchronized void connect(BluetoothDevice device, boolean secure) {
    Log.d(TAG, &amp;quot;connect to: &amp;quot; + device);

    // Cancel any thread attempting to make a connection
    if (mState == STATE_CONNECTING) {
        if (mConnectThread != null) {
            mConnectThread.cancel();
            mConnectThread = null;
        }
    }

    // Cancel any thread currently running a connection
    if (mConnectedThread != null) {
        mConnectedThread.cancel();
        mConnectedThread = null;
    }

    // Start the thread to connect with the given device
    mConnectThread = new ConnectThread(device, secure);
    mConnectThread.start();
    setState(STATE_CONNECTING);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;writeでは接続済みであることを確認後、connectedThreadの(参照を)コピーして、writeしている。
この間にmConnectedThreadにnullが代入されたりすることをsynchronizedで防ぐ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void write(byte[] out) {
    // Create temporary object
    ConnectedThread r;
    // Synchronize a copy of the ConnectedThread
    synchronized (this) {
        if (mState != STATE_CONNECTED) return;
        r = mConnectedThread;
    }
    // Perform the write unsynchronized
    r.write(out);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;devicelistactivity&#34;&gt;DeviceListActivity&lt;/h2&gt;

&lt;p&gt;検出可能にしている他端末を探し、選択する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;requestWindowFeature(Window.FEATURE_INDETERMINATE_PROGRESS)&lt;/code&gt;して、
&lt;code&gt;setProgressBarIndeterminateVisibility(true)&lt;/code&gt;すると右上にプログレスバーが表示できる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;new IntentFilter(BluetoothDevice.ACTION_FOUND)&lt;/code&gt;と
&lt;code&gt;new IntentFilter(BluetoothAdapter.ACTION_DISCOVERY_FINISHED)&lt;/code&gt;で
&lt;code&gt;registerReceiver(mReceiver, filter)&lt;/code&gt;して、
デバイスを見つけたときと探し終わったときにブロードキャストされてくるインテントを受信するレシーバーを登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);

    // Setup the window
    requestWindowFeature(Window.FEATURE_INDETERMINATE_PROGRESS);
    setContentView(R.layout.activity_device_list);

    // Set result CANCELED in case the user backs out
    setResult(Activity.RESULT_CANCELED);

    // Initialize the button to perform device discovery
    Button scanButton = (Button) findViewById(R.id.button_scan);
    scanButton.setOnClickListener(new View.OnClickListener() {
        public void onClick(View v) {
            doDiscovery();
            v.setVisibility(View.GONE);
        }
    });

    // Initialize array adapters. One for already paired devices and
    // one for newly discovered devices
    ArrayAdapter&amp;lt;String&amp;gt; pairedDevicesArrayAdapter =
            new ArrayAdapter&amp;lt;String&amp;gt;(this, R.layout.device_name);
    mNewDevicesArrayAdapter = new ArrayAdapter&amp;lt;String&amp;gt;(this, R.layout.device_name);

    // Find and set up the ListView for paired devices
    ListView pairedListView = (ListView) findViewById(R.id.paired_devices);
    pairedListView.setAdapter(pairedDevicesArrayAdapter);
    pairedListView.setOnItemClickListener(mDeviceClickListener);

    // Find and set up the ListView for newly discovered devices
    ListView newDevicesListView = (ListView) findViewById(R.id.new_devices);
    newDevicesListView.setAdapter(mNewDevicesArrayAdapter);
    newDevicesListView.setOnItemClickListener(mDeviceClickListener);

    // Register for broadcasts when a device is discovered
    IntentFilter filter = new IntentFilter(BluetoothDevice.ACTION_FOUND);
    this.registerReceiver(mReceiver, filter);

    // Register for broadcasts when discovery has finished
    filter = new IntentFilter(BluetoothAdapter.ACTION_DISCOVERY_FINISHED);
    this.registerReceiver(mReceiver, filter);

    // Get the local Bluetooth adapter
    mBtAdapter = BluetoothAdapter.getDefaultAdapter();

    // Get a set of currently paired devices
    Set&amp;lt;BluetoothDevice&amp;gt; pairedDevices = mBtAdapter.getBondedDevices();

    // If there are paired devices, add each one to the ArrayAdapter
    if (pairedDevices.size() &amp;gt; 0) {
        findViewById(R.id.title_paired_devices).setVisibility(View.VISIBLE);
        for (BluetoothDevice device : pairedDevices) {
            pairedDevicesArrayAdapter.add(device.getName() + &amp;quot;\n&amp;quot; + device.getAddress());
        }
    } else {
        String noDevices = getResources().getText(R.string.none_paired).toString();
        pairedDevicesArrayAdapter.add(noDevices);
    }
}

private void doDiscovery() {
    Log.d(TAG, &amp;quot;doDiscovery()&amp;quot;);

    // Indicate scanning in the title
    setProgressBarIndeterminateVisibility(true);
    setTitle(R.string.scanning);

    // Turn on sub-title for new devices
    findViewById(R.id.title_new_devices).setVisibility(View.VISIBLE);

    // If we&#39;re already discovering, stop it
    if (mBtAdapter.isDiscovering()) {
        mBtAdapter.cancelDiscovery();
    }

    // Request discover from BluetoothAdapter
    mBtAdapter.startDiscovery();
}

private final BroadcastReceiver mReceiver = new BroadcastReceiver() {
    @Override
    public void onReceive(Context context, Intent intent) {
        String action = intent.getAction();

        // When discovery finds a device
        if (BluetoothDevice.ACTION_FOUND.equals(action)) {
            // Get the BluetoothDevice object from the Intent
            BluetoothDevice device = intent.getParcelableExtra(BluetoothDevice.EXTRA_DEVICE);
            // If it&#39;s already paired, skip it, because it&#39;s been listed already
            if (device.getBondState() != BluetoothDevice.BOND_BONDED) {
                mNewDevicesArrayAdapter.add(device.getName() + &amp;quot;\n&amp;quot; + device.getAddress());
            }
            // When discovery is finished, change the Activity title
        } else if (BluetoothAdapter.ACTION_DISCOVERY_FINISHED.equals(action)) {
            setProgressBarIndeterminateVisibility(false);
            setTitle(R.string.select_device);
            if (mNewDevicesArrayAdapter.getCount() == 0) {
                String noDevices = getResources().getText(R.string.none_found).toString();
                mNewDevicesArrayAdapter.add(noDevices);
            }
        }
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;onDestroyで、探索をやめ、登録したレシーバーを外す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onDestroy() {
    super.onDestroy();

    // Make sure we&#39;re not doing discovery anymore
    if (mBtAdapter != null) {
        mBtAdapter.cancelDiscovery();
    }

    // Unregister broadcast listeners
    this.unregisterReceiver(mReceiver);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接続先リストから選択されたら、アドレスを付けて結果を返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private AdapterView.OnItemClickListener mDeviceClickListener
        = new AdapterView.OnItemClickListener() {
    public void onItemClick(AdapterView&amp;lt;?&amp;gt; av, View v, int arg2, long arg3) {
        // Cancel discovery because it&#39;s costly and we&#39;re about to connect
        mBtAdapter.cancelDiscovery();

        // Get the device MAC address, which is the last 17 chars in the View
        String info = ((TextView) v).getText().toString();
        String address = info.substring(info.length() - 17);

        // Create the result Intent and include the MAC address
        Intent intent = new Intent();
        intent.putExtra(EXTRA_DEVICE_ADDRESS, address);

        // Set result and finish this Activity
        setResult(Activity.RESULT_OK, intent);
        finish();
    }
};
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>静的ウェブサイトエンジンHugoに乗り換えた</title>
          <link>https://www.sambaiz.net/article/22/</link>
          <pubDate>Tue, 04 Oct 2016 22:21:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/22/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://gohugo.io/&#34;&gt;https://gohugo.io/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今までこのサイトはフロントのReactからLambda &amp;amp; API Gatewayで作った記事APIを呼ぶ構成になっていた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/1&#34;&gt;ホームページ作った&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;当初はページの描画をフロントに任せることで、
サーバーレス
(記事の情報をjsonで渡すAPI Gatewayと、S3の組み合わせ)
で作れると思っていたが、結果そんなに甘くはなく、サーバーサイドレンダリングするはめになる。
最初からレンダリングしたものを置いておけばいいと思った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/5&#34;&gt;webpack環境でredux&amp;amp;react-routerのページをサーバーサイドレンダリングする&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;そんなこんなでHugoに乗り換えることにした。
記事はmarkdownで管理していたので、これにメタ情報を加えるだけで移行できた。
タグで絞り込むこともできるようになったので良いと思う。
また、静的なページになったのでgithub pagesに置けるようにもなった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DeepDreaming with TensorFlowをやる(2)</title>
          <link>https://www.sambaiz.net/article/21/</link>
          <pubDate>Sat, 10 Sep 2016 14:46:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/21/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/20&#34;&gt;前回&lt;/a&gt;の続き。&lt;/p&gt;

&lt;h2 id=&#34;multiscale-image-generation&#34;&gt;Multiscale image generation&lt;/h2&gt;

&lt;p&gt;様々なスケールで勾配上昇させる。小さなスケールで上昇させたものをより大きなスケールでさらに上昇させていく。
ただ、壁紙のようなサイズを生成するような場合にそれを行うと、GPUのメモリを食いつぶしてしまう。
これを避けるために、画像を小さなタイルに分割し、それぞれ独立に勾配を計算する。
また、毎回画像をランダムにシフトしていくことで、タイルに見えることを避け、画像全体の品質を向上させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def tffunc(*argtypes):
    &#39;&#39;&#39;Helper that transforms TF-graph generating function into a regular one.
    See &amp;quot;resize&amp;quot; function below.
    &#39;&#39;&#39;
    placeholders = list(map(tf.placeholder, argtypes))
    def wrap(f):
        out = f(*placeholders)
        def wrapper(*args, **kw):
            return out.eval(dict(zip(placeholders, args)), session=kw.get(&#39;session&#39;))
        return wrapper
    return wrap

# Helper function that uses TF to resize an image
def resize(img, size):
    img = tf.expand_dims(img, 0)
    return tf.image.resize_bilinear(img, size)[0,:,:,:]
resize = tffunc(np.float32, np.int32)(resize)


def calc_grad_tiled(img, t_grad, tile_size=512):
    &#39;&#39;&#39;Compute the value of tensor t_grad over the image in a tiled way.
    Random shifts are applied to the image to blur tile boundaries over
    multiple iterations.&#39;&#39;&#39;
    sz = tile_size
    h, w = img.shape[:2]
    sx, sy = np.random.randint(sz, size=2)
    img_shift = np.roll(np.roll(img, sx, 1), sy, 0)
    grad = np.zeros_like(img)
    for y in range(0, max(h-sz//2, sz),sz):
        for x in range(0, max(w-sz//2, sz),sz):
            sub = img_shift[y:y+sz,x:x+sz]
            g = sess.run(t_grad, {t_input:sub})
            grad[y:y+sz,x:x+sz] = g
    return np.roll(np.roll(grad, -sx, 1), -sy, 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.image.resize_bilinear&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/image.html#resize_bilinear&#34;&gt;双線形補間によってリサイズする。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;numpy.roll&lt;/code&gt;は&lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/generated/numpy.roll.html&#34;&gt;配列を第三引数axisによってローリングする&lt;/a&gt;。
axisを指定しない場合、フラットなものとして扱われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hoge = [[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]]

print(np.roll(hoge, 1))
# [[8 0 1]
#  [2 3 4]
#  [5 6 7]]

print(np.roll(hoge, 1, axis=0))
# [[6 7 8]
#  [0 1 2]
#  [3 4 5]]

print(np.roll(hoge, 1, axis=1))
# [[2 0 1]
#  [5 3 4]
#  [8 6 7]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;つまり、&lt;code&gt;calc_grad_tiled&lt;/code&gt;では、ランダムにローリングして、タイルに分割して勾配を求め、ローリングした分を戻して返している。
これと、画像サイズを&lt;code&gt;octave_scale&lt;/code&gt;倍にしていく以外は前回やったのと基本的に同じだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def render_multiscale(t_obj, img0=img_noise, iter_n=10, step=1.0, octave_n=3, octave_scale=1.4):
    t_score = tf.reduce_mean(t_obj) # defining the optimization objective
    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!

    img = img0.copy()
    for octave in range(octave_n):
        if octave&amp;gt;0:
            hw = np.float32(img.shape[:2])*octave_scale
            img = resize(img, np.int32(hw))
        for i in range(iter_n):
            g = calc_grad_tiled(img, t_grad)
            # normalizing the gradient, so the same step size should work
            g /= g.std()+1e-8         # for different layers and networks
            img += g*step
            print(&#39;.&#39;, end = &#39; &#39;)
        clear_output()
        showarray(visstd(img))

render_multiscale(T(layer)[:,:,:,channel])
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;laplacian-pyramid-gradient-normalization&#34;&gt;Laplacian Pyramid Gradient Normalization&lt;/h2&gt;

&lt;p&gt;結果の画像は、高い周波数(ピクセルの変化の度合が高い)が多く含まれている。
これを改善するための一つの方法として、毎回画像をぼかし、高周波数を抑え、画像を滑らかにするものがある。
ただ、この方法は良い画像にするためにより多くの繰り返しが必要になってしまう。
逆に、低周波数を上げるのは、ラプラシアンピラミッドを使う方法があって、これで勾配を正規化する。&lt;/p&gt;

&lt;p&gt;ラプラシアンピラミッドというのは、ガウシアンピラミッドにおける、ある解像度の画像と、
その一つレベルの高い(解像度1/2 * &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; = &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;)画像をアップサンプルしたものの差分だ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_pyramids/py_pyramids.html&#34;&gt;画像ピラミッド — OpenCV-Python Tutorials 1 documentation&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;k = np.float32([1,4,6,4,1])
k = np.outer(k, k)
# [[  1.   4.   6.   4.   1.]
#  [  4.  16.  24.  16.   4.]
#  [  6.  24.  36.  24.   6.]
#  [  4.  16.  24.  16.   4.]
#  [  1.   4.   6.   4.   1.]]

k5x5 = k[:,:,None,None]/k.sum()*np.eye(3, dtype=np.float32)

print(len(k5x5))
# 5

print(k5x5[0])
# [[[ 0.00390625  0.          0.        ]
#  [ 0.          0.00390625  0.        ]
#  [ 0.          0.          0.00390625]]

# [[ 0.015625    0.          0.        ]
#  [ 0.          0.015625    0.        ]
#  [ 0.          0.          0.015625  ]]

# [[ 0.0234375   0.          0.        ]
#  [ 0.          0.0234375   0.        ]
#  [ 0.          0.          0.0234375 ]]

# [[ 0.015625    0.          0.        ]
#  [ 0.          0.015625    0.        ]
#  [ 0.          0.          0.015625  ]]

# [[ 0.00390625  0.          0.        ]
#  [ 0.          0.00390625  0.        ]
#  [ 0.          0.          0.00390625]]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;numpy.outer&lt;/code&gt;は&lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/generated/numpy.outer.html&#34;&gt;外積を求める&lt;/a&gt;もので、
&lt;code&gt;numpy.eye&lt;/code&gt;は&lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html&#34;&gt;対角線が1で、それ以外は0の2次元行列を返す&lt;/a&gt;。
&lt;code&gt;k&lt;/code&gt;を指定すると、対角線の位置を変更できるが、指定していない場合はNxNの単位行列が返ることになる。
このフィルターで畳み込むことで、ラプラシアンピラミッドの1レベル高い画像に変換できる。
&lt;code&gt;tf.nn.conv2d_transpose&lt;/code&gt;は
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#conv2d_transpose&#34;&gt;畳み込みの逆処理&lt;/a&gt;のようなもので、
これでアップサンプルした画像と元画像の差分を取って、ラプラシアンピラミッドを生成している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def lap_split(img):
    &#39;&#39;&#39;Split the image into lo and hi frequency components&#39;&#39;&#39;
    with tf.name_scope(&#39;split&#39;):
        lo = tf.nn.conv2d(img, k5x5, [1,2,2,1], &#39;SAME&#39;)
        lo2 = tf.nn.conv2d_transpose(lo, k5x5*4, tf.shape(img), [1,2,2,1])
        hi = img-lo2
    return lo, hi

def lap_split_n(img, n):
    &#39;&#39;&#39;Build Laplacian pyramid with n splits&#39;&#39;&#39;
    levels = []
    for i in range(n):
        img, hi = lap_split(img)
        levels.append(hi)
    levels.append(img)
    return levels[::-1]

def lap_merge(levels):
    &#39;&#39;&#39;Merge Laplacian pyramid&#39;&#39;&#39;
    img = levels[0]
    for hi in levels[1:]:
        with tf.name_scope(&#39;merge&#39;):
            img = tf.nn.conv2d_transpose(img, k5x5*4, tf.shape(hi), [1,2,2,1]) + hi
    return img

def normalize_std(img, eps=1e-10):
    &#39;&#39;&#39;Normalize image by making its standard deviation = 1.0&#39;&#39;&#39;
    with tf.name_scope(&#39;normalize&#39;):
        std = tf.sqrt(tf.reduce_mean(tf.square(img)))
        return img/tf.maximum(std, eps)

def lap_normalize(img, scale_n=4):
    &#39;&#39;&#39;Perform the Laplacian pyramid normalization.&#39;&#39;&#39;
    img = tf.expand_dims(img,0)
    tlevels = lap_split_n(img, scale_n)
    tlevels = list(map(normalize_std, tlevels))
    out = lap_merge(tlevels)
    return out[0,:,:,:]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;lap_normalize&lt;/code&gt;で画像からラプラシアンピラミッドを生成し、それぞれで正規化してからマージして元の画像に戻す処理をしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def render_lapnorm(t_obj, img0=img_noise, visfunc=visstd,
                   iter_n=10, step=1.0, octave_n=3, octave_scale=1.4, lap_n=4):
    t_score = tf.reduce_mean(t_obj) # defining the optimization objective
    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!
    # build the laplacian normalization graph
    lap_norm_func = tffunc(np.float32)(partial(lap_normalize, scale_n=lap_n))

    img = img0.copy()
    for octave in range(octave_n):
        if octave&amp;gt;0:
            hw = np.float32(img.shape[:2])*octave_scale
            img = resize(img, np.int32(hw))
        for i in range(iter_n):
            g = calc_grad_tiled(img, t_grad)
            g = lap_norm_func(g)
            img += g*step
            print(&#39;.&#39;, end = &#39; &#39;)
        clear_output()
        showarray(visfunc(img))

render_lapnorm(T(layer)[:,:,:,channel])
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deepdream&#34;&gt;DeepDream&lt;/h2&gt;

&lt;p&gt;で、これがDeepDreamのアルゴリズム。
ラプラシアンピラミッドを生成して、リサイズの際に次のレベルのを足していっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def render_deepdream(t_obj, img0=img_noise,
                     iter_n=10, step=1.5, octave_n=4, octave_scale=1.4):
    t_score = tf.reduce_mean(t_obj) # defining the optimization objective
    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!

    # split the image into a number of octaves
    img = img0
    octaves = []
    for i in range(octave_n-1):
        hw = img.shape[:2]
        lo = resize(img, np.int32(np.float32(hw)/octave_scale))
        hi = img-resize(lo, hw)
        img = lo
        octaves.append(hi)

    # generate details octave by octave
    for octave in range(octave_n):
        if octave&amp;gt;0:
            hi = octaves[-octave]
            img = resize(img, hi.shape[:2])+hi
        for i in range(iter_n):
            g = calc_grad_tiled(img, t_grad)
            img += g*(step / (np.abs(g).mean()+1e-7))
            print(&#39;.&#39;,end = &#39; &#39;)
        clear_output()
        showarray(img/255.0)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DeepDreaming with Tensorflowをやる(1)</title>
          <link>https://www.sambaiz.net/article/20/</link>
          <pubDate>Wed, 07 Sep 2016 01:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/20/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb&#34;&gt;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;例の通りまとめながら進めていく。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;このノートブックは、畳み込みニューラルネットワークによる画像生成の手法を説明するものだ。
ネットワークは入力画像へ変換させる配列のレイヤーの集合から成り立っている。
変換のパラメータは勾配降下法で変形しながら学習していく。
内部的な画像の表現は意味不明なように見えるが、可視化し、解釈することができる。&lt;/p&gt;

&lt;h3 id=&#34;loading-and-displaying-the-model-graph&#34;&gt;Loading and displaying the model graph&lt;/h3&gt;

&lt;p&gt;学習済みネットワークのprotobufファイルが用意されていて、これをダウンロードして使う。
ただ&lt;code&gt;gcr.io/tensorflow/tensorflow&lt;/code&gt;にwgetもunzipも入っていなかったので、中に入ってapt-getした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model_fn = &#39;tensorflow_inception_graph.pb&#39;

# creating TensorFlow session and loading the model
graph = tf.Graph()
sess = tf.InteractiveSession(graph=graph)
with tf.gfile.FastGFile(model_fn, &#39;rb&#39;) as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
t_input = tf.placeholder(np.float32, name=&#39;input&#39;) # define the input tensor
imagenet_mean = 117.0
t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)
tf.import_graph_def(graph_def, {&#39;input&#39;:t_preprocessed})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.gfile.FastGFile&lt;/code&gt;のドキュメントが見つからないので
&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/568092d4507996d8aff0c46d6c57488a26596dd5/tensorflow/python/platform/gfile.py#L218&#34;&gt;ソース&lt;/a&gt;
を探したところFile I/Oのラッパーのようだ。これでprotobufファイルを読み、ParseFromStringでGraphDefにする。&lt;/p&gt;

&lt;p&gt;さらにこれと入力データを&lt;code&gt;tf.import_graph_def&lt;/code&gt;に
渡すことで&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/framework.html#import_graph_def&#34;&gt;Graphに取り込む&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.expand_dims&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/array_ops.html#expand_dims&#34;&gt;値が1の次元を指定の場所に挿入する&lt;/a&gt;
もの。なんでそんなことをしたり、&lt;code&gt;imagenet_mean&lt;/code&gt;を引いているのかは説明がなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;layers = [op.name for op in graph.get_operations() if op.type==&#39;Conv2D&#39; and &#39;import/&#39; in op.name]
feature_nums = [int(graph.get_tensor_by_name(name+&#39;:0&#39;).get_shape()[-1]) for name in layers]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このlayersに入っているのはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import/conv2d0_pre_relu/conv
import/conv2d1_pre_relu/conv
import/conv2d2_pre_relu/conv
import/mixed3a_1x1_pre_relu/conv
import/mixed3a_3x3_bottleneck_pre_relu/conv
import/mixed3a_3x3_pre_relu/conv
import/mixed3a_5x5_bottleneck_pre_relu/conv
import/mixed3a_5x5_pre_relu/conv
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらのレイヤーのうち、&lt;code&gt;mixed4d_3x3_bottleneck_pre_relu&lt;/code&gt;を可視化してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;layer = &#39;mixed4d_3x3_bottleneck_pre_relu&#39;
channel = 139 # picking some feature channel to visualize

def T(layer):
    &#39;&#39;&#39;Helper for getting layer output tensor&#39;&#39;&#39;
    return graph.get_tensor_by_name(&amp;quot;import/%s:0&amp;quot;%layer)

render_naive(T(layer)[:,:,:,channel])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;mixed4d_3x3_bottleneck_pre_relu&#39;&lt;/code&gt;は144チャンネルのフィルターで、今回はそのうち139番目のチャンネルを選んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(T(layer))
-&amp;gt; Tensor(&amp;quot;import/mixed4d_3x3_bottleneck_pre_relu:0&amp;quot;, shape=(?, ?, ?, 144), dtype=float32, device=/device:CPU:0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初期値はRGB100(グレー)にノイズを加えた画像。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# start with a gray image with a little noise
img_noise = np.random.uniform(size=(224,224,3)) + 100.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;スコアはそのチャンネルの値の平均で、これが高くなるように画像を変化させていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def render_naive(t_obj, img0=img_noise, iter_n=20, step=1.0):
    t_score = tf.reduce_mean(t_obj) # defining the optimization objective
    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!

    img = img0.copy()
    for i in range(iter_n):
        g, score = sess.run([t_grad, t_score], {t_input:img})
        # normalizing the gradient, so the same step size should work
        g /= g.std()+1e-8         # for different layers and networks
        img += g*step
        print(score, end = &#39; &#39;)
    clear_output()
    showarray(visstd(img))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.gradients(ys,xs)&lt;/code&gt;で
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html#gradients&#34;&gt;xそれぞれで偏微分したyの和&lt;/a&gt;が得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a = tf.Variable(tf.constant([
            [1., 2.],
            [3., 4.]]))
b = tf.Variable(tf.constant([
            [2., 3.],
            [4., 5.]]))
c = tf.matmul(a, b)
​
grad = tf.gradients(c, a)[0]
init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)

    print(sess.run(c))
    # [[ 10.  13.]
    # [ 22.  29.]]

    print(sess.run(grad))
    # [[ 5.  9.]
    # [ 5.  9.]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入力画像にこれをを加算していくと、その状態からスコアが上がるパラメータが増え、下がるパラメータが減るため、勾配を上っていくことになる。
スコアが上昇するに従って、そのフィルターによる模様が浮かんできた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/21&#34;&gt;続く&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Grafana/InfluxDB/Fluentdでログを可視化する</title>
          <link>https://www.sambaiz.net/article/19/</link>
          <pubDate>Wed, 31 Aug 2016 20:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/19/</guid>
          <description>

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/grafana-influxdb-fluentd&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;influxdb-https-github-com-influxdata-influxdb&#34;&gt;&lt;a href=&#34;https://github.com/influxdata/influxdb&#34;&gt;InfluxDB&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Golangで書かれた時系列データベース。今回使うのは&lt;code&gt;v0.13&lt;/code&gt;。前のバージョンと結構違うので注意。&lt;/p&gt;

&lt;p&gt;デフォルトでは無効になっている認証を&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.13/administration/authentication_and_authorization/#set-up-authentication&#34;&gt;有効にする&lt;/a&gt;ために設定ファイルを編集して設置する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install influxdb # OSX
$ influxd config &amp;gt; influxdb.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[http]
  ...
  auth-enabled = true
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;FROM influxdb:0.13

VOLUME /var/lib/influxdb
ADD influxdb.conf /
ENV INFLUXDB_CONFIG_PATH /influxdb.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -p 8083:8083 -p 8086:8086 myinfluxdb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;influxd&lt;/code&gt;コマンドや
&lt;code&gt;:8083&lt;/code&gt;のWebインタフェースの他に
&lt;code&gt;:8086&lt;/code&gt;に&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.13/concepts/api/&#34;&gt;HTTP API&lt;/a&gt;が用意されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -i -XPOST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE USER root WITH PASSWORD &#39;root&#39; WITH ALL PRIVILEGES&amp;quot;

$ curl -i -XPOST http://localhost:8086/query -u root:root --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot;
{&amp;quot;results&amp;quot;:[{}]}

# Line Protocol(https://docs.influxdata.com/influxdb/v0.13/write_protocols/line/)
$ curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; -u root:root --data-binary &#39;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&#39;
(204 No Content)

$ curl -GET &#39;http://localhost:8086/query?db=mydb&#39; -u root:root --data-urlencode &#39;q=SELECT * FROM &amp;quot;cpu_load_short&amp;quot;&#39; | jq
{
  &amp;quot;results&amp;quot;: [
    {
      &amp;quot;series&amp;quot;: [
        {
          &amp;quot;name&amp;quot;: &amp;quot;cpu_load_short&amp;quot;,
          &amp;quot;columns&amp;quot;: [
            &amp;quot;time&amp;quot;,
            &amp;quot;host&amp;quot;,
            &amp;quot;region&amp;quot;,
            &amp;quot;value&amp;quot;
          ],
          &amp;quot;values&amp;quot;: [
            [
              &amp;quot;2015-06-11T20:46:02Z&amp;quot;,
              &amp;quot;server01&amp;quot;,
              &amp;quot;us-west&amp;quot;,
              0.64
            ]
          ]
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fluent-plugin-influxdb-https-github-com-fangli-fluent-plugin-influxdb&#34;&gt;&lt;a href=&#34;https://github.com/fangli/fluent-plugin-influxdb&#34;&gt;fluent-plugin-influxdb&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;設定はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  type tail
  path      /usr/src/app/test.log
  pos_file  /etc/td-agent/test.log.pos
  tag       something.log
  format    json
&amp;lt;/source&amp;gt;

&amp;lt;match *.log&amp;gt;
  @type     influxdb
  host      influxdb
  port      8086
  dbname    mydb
  user      root
  password  root
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5秒ごとにランダムな値valueのログを出力し続ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from twisted.internet import task, reactor
import logging
import json
import random

INTERVAL = 5 # sec
logging.basicConfig(filename=&#39;test.log&#39;, format=&#39;%(message)s&#39;, level=logging.INFO)

def somethingHappend():
  data = {
    &amp;quot;value&amp;quot;: random.randint(0, 100),
    &amp;quot;event&amp;quot;: &amp;quot;something&amp;quot;
  }
  logging.info(json.dumps(data))  

if __name__ == &#39;__main__&#39;:
    instance = task.LoopingCall(somethingHappend)
    instance.start(INTERVAL)
    reactor.run()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;grafana-http-grafana-org&#34;&gt;&lt;a href=&#34;http://grafana.org/&#34;&gt;Grafana&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;可視化ツール。データソースとしてInfluxDB、Garaphite、Elasticsearchなどが使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://play.grafana.org/&#34;&gt;Demo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kibana(+Elasticsearch)だと
認証するのに&lt;a href=&#34;https://www.elastic.co/subscriptions&#34;&gt;有償&lt;/a&gt;のShieldプラグインが必要だが、
こちらは最初からできて手軽。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;これらのDockerイメージを作って、minikubeで立ち上げてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pods
NAME                        READY     STATUS    RESTARTS   AGE
grafana-1386260931-lq8wh    1/1       Running   0          2m
influxdb-2543054961-yj1bd   1/1       Running   0          2m
testapp-532457622-269qo     1/1       Running   0          2m

$ curl -i -XPOST http://192.168.99.100:30005/query?db=mydb -u root:root --data-urlencode &#39;q=SELECT * FROM &amp;quot;something.log&amp;quot; LIMIT 1&#39;
{&amp;quot;results&amp;quot;:[{&amp;quot;series&amp;quot;:[{&amp;quot;name&amp;quot;:&amp;quot;something.log&amp;quot;,&amp;quot;columns&amp;quot;:[&amp;quot;time&amp;quot;,&amp;quot;event&amp;quot;,&amp;quot;value&amp;quot;],&amp;quot;values&amp;quot;:[[&amp;quot;2016-08-31T08:38:37Z&amp;quot;,&amp;quot;something&amp;quot;,23]]}]}]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://192.168.99.100:30003&#34;&gt;http://192.168.99.100:30003&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;admin/adminでログインしてDataSourceに&lt;code&gt;http://192.168.99.100:30005&lt;/code&gt;のInfluxDBを設定すると、
Dashboardにグラフやテーブルなどを置いて表示させることができるようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/19_grafana.png&#34; alt=&#34;grafanaのDashboard&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;1秒以内に複数のログが発生する場合-2016-11-07&#34;&gt;1秒以内に複数のログが発生する場合 (2016-11-07)&lt;/h2&gt;

&lt;p&gt;時系列DBであるinfluxdbは同じタイムスタンプで複数のデータを持つことができない。
fluentdはv0.14からナノ秒でタイムスタンプを持つようになったので、これを利用することで1秒以内に発生するログも
正常に処理できるようになる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/32&#34;&gt;td-agentをビルドしてfluentdのバージョンを上げる&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;fluent-plugin-influxdbのtime_precisionはデフォルトでs(秒)になっているが、
これをns(ナノ秒)にしただけでは、(現時点では)秒のままのタイムスタンプが送られるのでうまくいかない。
そのため、以下のようにナノ秒を取れる場合はそれを使い、そうでない場合は無視するように修正した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nstime = time * (10 ** 9) + (defined?(Fluent::EventTime) ? time.nsec : 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/fangli/fluent-plugin-influxdb/pull/62&#34;&gt;プルリク&lt;/a&gt;は出した。
自分のプラグインはこんな感じで使うことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;td-agent-gem install specific_install &amp;amp;&amp;amp; \
td-agent-gem specific_install https://github.com/sambaiz/fluent-plugin-influxdb.git
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GKEで複数コンテナのアプリケーションを動かす</title>
          <link>https://www.sambaiz.net/article/18/</link>
          <pubDate>Fri, 26 Aug 2016 21:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/18/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/17&#34;&gt;前回&lt;/a&gt;は単一コンテナのアプリケーションを動かしたが、今回はコンテナ間でやり取りが発生するものを動かす。
流れとしては、クライアントからのリクエストを&lt;code&gt;GATEWAY&lt;/code&gt;サーバーで受け取り、&lt;code&gt;SERVICE&lt;/code&gt;サーバーにリクエストし、その結果を返すまで。&lt;/p&gt;

&lt;p&gt;プログラムは以下の通り、環境変数&lt;code&gt;TYPE&lt;/code&gt;の値によって挙動を変えていて、同じイメージを使い回す。コードは&lt;a href=&#34;https://github.com/sambaiz/gke-multi-container-app&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var http = require(&#39;http&#39;);
var handleRequest = function(request, response) {
  if(process.env.TYPE == &amp;quot;GATEWAY&amp;quot;){
    console.log(&#39;Passed.&#39;);
    var options = {
      host: &#39;service&#39;,
      port: 8080,
      method: &#39;GET&#39;
    };
    var req = http.request(options, function(res) {
      data = &amp;quot;&amp;quot;
      res.on(&#39;data&#39;, function (chunk) {
        data+=chunk;
      });

      res.on(&#39;end&#39;, () =&amp;gt; {
        response.writeHead(200);
        response.end(data);
      });
    });
    req.on(&#39;error&#39;, function(e) {
      response.writeHead(500)
      response.end(e.message);
    });
    req.end();
  }else{
    console.log(&#39;Received.&#39;);
    response.writeHead(200);
    response.end(&#39;ok&#39;);
  }
};
var www = http.createServer(handleRequest);
www.listen(8080);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをContainer RegistryにPushする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export PROJECT_ID=&amp;quot;gcp-test-141011&amp;quot;
$ docker build -t gcr.io/$PROJECT_ID/multitest:v1 .
$ gcloud docker push gcr.io/$PROJECT_ID/multitest:v1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ローカルで試すためにminikubeを起動。コンテキストがminikubeに設定される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ minikube start
$ kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;minikubeでContainer Registryから取得できるようにsecretを作成する。
ローカルでビルドしたimageを使うこともできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/151/&#34;&gt;ローカルでビルドしたimageをminikubeで使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create secret docker-registry myregistrykey --docker-server=https://gcr.io --docker-username=oauth2accesstoken --docker-password=&amp;quot;$(gcloud auth print-access-token)&amp;quot; --docker-email=***
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず、以下の&lt;code&gt;service_deployment.yaml&lt;/code&gt;でDeploymentを作成する。
envのところで環境変数&lt;code&gt;TYPE&lt;/code&gt;を&lt;code&gt;SERVICE&lt;/code&gt;に設定した。
また、先ほど作成したsecretを&lt;code&gt;imagePullSecrets&lt;/code&gt;で指定し、
ローカルのminikube環境でContainer Registryから取得できるようにしている。
同様に&lt;code&gt;gateway_deployment.yaml&lt;/code&gt;でも作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: service
  labels:
    app: service
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: service
    spec:
      containers:
      - name: service
        image: gcr.io/gcp-test-141011/multitest:v1
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: TYPE
          value: SERVICE
        ports:
        - containerPort: 8080
      imagePullSecrets:
      - name: myregistrykey    
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f service_deployment.yaml
$ kubectl create -f gateway_deployment.yaml
$ kubectl get deployment
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
gateway   1         1         1            1           8m
service   1         1         1            1           28m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に、これを内部から呼べるようにするためのServiceを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: service
  labels:
    app: service
spec:
  ports:
  - port: 8080
  selector:
    app: service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;GATEWAY&lt;/code&gt;の方は外に開くので、EXTERNAL IPが割り当てられるようにする。
ただ、minikubeでは&lt;code&gt;type: LoadBalancer&lt;/code&gt;に対応していないので代わりに&lt;code&gt;type: NodePort&lt;/code&gt;を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: gateway
  labels:
    app: gateway
spec:
  # type: LoadBalancer
  type: NodePort
  ports:
  - port: 8080
    nodePort: 30002
  selector:
    app: gateway
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f service_service.yaml
$ kubectl create -f gateway_service.yaml
$ kubectl get services
NAME            CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
gateway         10.0.0.176   &amp;lt;nodes&amp;gt;       8080/TCP   1h
service         10.0.0.111   &amp;lt;none&amp;gt;        8080/TCP   2d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;GATEWAY&lt;/code&gt;サーバーを越えて&lt;code&gt;SERVICE&lt;/code&gt;サーバーまで到達したことが確認できた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl 192.168.99.100:30002
ok

$ kubectl get pods
NAME                       READY     STATUS    RESTARTS   AGE
gateway-3043515563-a0tb5   1/1       Running   0          38m
service-2727435432-9glvb   1/1       Running   0          38m

$ kubectl logs service-2727435432-9glvb
Received.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一通り動いたのでこんなシェルスクリプトを書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash

context=`kubectl config current-context`
echo &amp;quot;${context}で実行します。よろしいですか[Y/N]&amp;quot;
read ANSWER
case $ANSWER in
    &amp;quot;Y&amp;quot; ) :;;
    * ) exit;;
esac
if [ $context = &amp;quot;minikube&amp;quot; ] ; then
  kubectl create -f yaml/gateway_service_minikube.yaml
  kubectl create -f yaml/service_deployment_minikube.yaml
  kubectl create -f yaml/gateway_deployment_minikube.yaml
else
  kubectl create -f yaml/gateway_service.yaml
  kubectl create -f yaml/service_deployment.yaml
  kubectl create -f yaml/gateway_deployment.yaml
fi
kubectl create -f yaml/service_service.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行するとこうなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud container clusters create multi-container-app
$ kubectl config current-context
gke_gcp-test-141011_asia-east1-b_multi-container-app

$ sh create.sh
gke_gcp-test-141011_asia-east1-b_multi-container-appで実行します。よろしいですか[Y/N]
Y
service &amp;quot;gateway&amp;quot; created
deployment &amp;quot;service&amp;quot; created
deployment &amp;quot;gateway&amp;quot; created
service &amp;quot;service&amp;quot; created

$ kubectl get service
NAME         CLUSTER-IP      EXTERNAL-IP       PORT(S)    AGE
gateway      10.83.254.5     104.199.206.147   8080/TCP   4m
service      10.83.255.118   &amp;lt;none&amp;gt;            8080/TCP   4m

$ curl 104.199.206.147:8080
ok
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Google Container Engine(GKE)で単一コンテナのアプリケーションを動かす</title>
          <link>https://www.sambaiz.net/article/17/</link>
          <pubDate>Sun, 21 Aug 2016 23:37:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/17/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://kubernetes.io/docs/hellonode/&#34;&gt;Kubernetes - Hello World Walkthrough&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;cloudsdkとkubectlのインストール&#34;&gt;CloudSDKとkubectlのインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/sdk/#Quick_Start&#34;&gt;Cloud SDKをインストール&lt;/a&gt;して&lt;code&gt;gloud&lt;/code&gt;コマンドを使えるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud --version
Google Cloud SDK 122.0.0
$ gcloud components install kubectl
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;google-container-registryにpush&#34;&gt;Google Container RegistryにPush&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ export PROJECT_ID=&amp;quot;******&amp;quot;
$ docker build -t gcr.io/$PROJECT_ID/test:v1 .
$ gcloud docker push gcr.io/$PROJECT_ID/test:v1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プロジェクトの課金を有効にしていないとこんなエラーメッセージが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;denied: Unable to create the repository, please check that you have access to do so.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;clusterの作成&#34;&gt;Clusterの作成&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud config set core/project $PROJECT_ID
$ gcloud config set compute/zone asia-east1-b
$ gcloud container clusters create test-cluster
$ gcloud config set container/cluster test-cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Container Engine APIが有効になっていない場合はこうなる。
一度コンソールからContainer Engineを選ぶと、サービスの準備が始まって有効になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERROR: (gcloud.container.clusters.create) ResponseError: code=503, message=Project **** is not fully initialized with the default service accounts. Please try again later.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pod-とそのdeployment-の作成&#34;&gt;Pod(とそのDeployment)の作成&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl run test-node --image=gcr.io/$PROJECT_ID/test:v1 --port=8080
$ kubectl get deployments
NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
test-node   1         1         1            0           12s

$ kubectl get pods
NAME                         READY     STATUS              RESTARTS   AGE
test-node-1016577872-h7yiz   0/1       ContainerCreating   0          18s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;serviceを作成してクラスタの外からアクセスできるようにする&#34;&gt;Serviceを作成してクラスタの外からアクセスできるようにする&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;--type=&amp;quot;LoadBalancer&amp;quot;&lt;/code&gt;のServiceを作成すると外からアクセスできるようになる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/173/&#34;&gt;GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl expose deployment test-node --type=&amp;quot;LoadBalancer&amp;quot;
$ kubectl get services test-node
NAME        CLUSTER-IP     EXTERNAL-IP       PORT(S)    AGE
test-node   10.43.247.66   104.199.158.131   8080/TCP   1m
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;スケーリング&#34;&gt;スケーリング&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl scale deployment test-node --replicas=4
$ kubectl get deployment
NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
test-node   4         4         4            2           11m

$ kubectl get pods
NAME                         READY     STATUS              RESTARTS   AGE
test-node-1016577872-fso09   0/1       ContainerCreating   0          12s
test-node-1016577872-h7yiz   1/1       Running             0          11m
test-node-1016577872-sbdvl   1/1       Running             0          12s
test-node-1016577872-z9ji3   0/1       ContainerCreating   0          12s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;更新&#34;&gt;更新&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t gcr.io/$PROJECT_ID/test:v2 .
$ gcloud docker push gcr.io/$PROJECT_ID/test:v2
$ kubectl set image deployment/test-node test-node=gcr.io/$PROJECT_ID/test:v2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;削除&#34;&gt;削除&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl delete service,deployment test-node
$ gcloud container clusters delete test-cluster
$ gcloud config unset container/cluster
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>JenkinsのMultiple SCMs PluginからPipeline Pluginへの移行</title>
          <link>https://www.sambaiz.net/article/16/</link>
          <pubDate>Sat, 20 Aug 2016 16:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/16/</guid>
          <description>&lt;p&gt;Jenkins環境を作り直すことになり、
長らく使ってきた&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Multiple+SCMs+Plugin&#34;&gt;Multiple SCMs Plugin&lt;/a&gt;がDeprecatedなので、
&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Plugin&#34;&gt;Pipeline Plugin&lt;/a&gt;に移行することにした。&lt;/p&gt;

&lt;p&gt;プラグインをインストールすると、ジョブ作成時にPipelineを選択できるようになる。
Pipeline scriptの複数リポジトリを指定するところはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node {
   stage &#39;Checkout rep1&#39;
   git([url: &#39;git@rep1.git&#39;, branch: REP1_BRANCH])

   stage &#39;Checkout rep2&#39;
   dir(&#39;rep2&#39;) {
      git([url: &#39;git@rep2.git&#39;, branch: REP2_BRANCH])
   }

   stage &#39;Checkout rep3&#39;
   dir(&#39;subdir3/rep3&#39;) {
      git([url: &#39;git@rep3.git&#39;, branch: REP3_BRANCH])
   }

   stage &#39;Build&#39;
   ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まとめて入った&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Stage+View+Plugin&#34;&gt;Pipeline Stage View Plugin&lt;/a&gt;によって、
経過や変更などいろいろ見やすくなった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GolangでAPIとテストを書く(echo/dbr/glide/goose/mock)</title>
          <link>https://www.sambaiz.net/article/15/</link>
          <pubDate>Mon, 15 Aug 2016 04:07:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/15/</guid>
          <description>

&lt;p&gt;以下の記事を参考にして簡単なAPIとそのテストを書いてみた。コードは&lt;a href=&#34;https://github.com/sambaiz/go-api-with-test&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ameblo.jp/principia-ca/entry-12130127314.html&#34;&gt;Go言語でTestableなWebアプリケーションを目指して｜サイバーエージェント 公式エンジニアブログ&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;使った主なライブラリ-ツール&#34;&gt;使った主なライブラリ・ツール&lt;/h2&gt;

&lt;h3 id=&#34;echo-https-github-com-labstack-echo&#34;&gt;&lt;a href=&#34;https://github.com/labstack/echo&#34;&gt;echo&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;webフレームワーク。速いらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/labstack/echo
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    conn, err := dbr.Open(&amp;quot;mysql&amp;quot;, &amp;quot;root:@tcp(localhost:3306)/mboard&amp;quot;, nil)
    if err != nil {
        panic(err)
    }
    conn.SetMaxIdleConns(200)
    conn.SetMaxOpenConns(200)

    e := echo.New()

    // middlewares
    e.Use(middleware.Logger())
    e.Use(middleware.Recover())
    e.Use(middleware.CORSWithConfig(middleware.CORSConfig{
        AllowOrigins: []string{&amp;quot;*&amp;quot;},
        AllowMethods: []string{echo.GET, echo.PUT, echo.POST, echo.DELETE},
    }))

    // endpoints
    e.GET(&amp;quot;/&amp;quot;, func(c echo.Context) error {
		    return c.String(http.StatusOK, &amp;quot;Hello, World!&amp;quot;)
  	})
  	e.GET(&amp;quot;/messages&amp;quot;, func(c echo.Context) error {
  		  return handler.NewMessageWithSession(conn.NewSession(nil)).GetMessages(c)
  	})
  	e.POST(&amp;quot;/messages&amp;quot;, func(c echo.Context) error {
  		  return handler.NewMessageWithSession(conn.NewSession(nil)).CreateMessage(c)
  	})
    std := standard.New(&amp;quot;:1323&amp;quot;)
    std.SetHandler(e)
    gracehttp.Serve(std.Server)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dbr-https-github-com-gocraft-dbr&#34;&gt;&lt;a href=&#34;https://github.com/gocraft/dbr&#34;&gt;dbr&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;database/sql&lt;/code&gt;を強化したもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/gocraft/dbr
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;res, err := t.sess.InsertInto(&amp;quot;message&amp;quot;).Columns(&amp;quot;content&amp;quot;).Record(model.Message{Content: content}).Exec()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;glide-https-github-com-masterminds-glide&#34;&gt;&lt;a href=&#34;https://github.com/Masterminds/glide&#34;&gt;glide&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;パッケージ管理ツール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install glide
$ glide create
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で&lt;code&gt;glide.yaml&lt;/code&gt;が作られる。&lt;code&gt;glide get&lt;/code&gt;で&lt;code&gt;glide.yaml&lt;/code&gt;に追加していったり、
&lt;code&gt;glide install&lt;/code&gt;でvendor下にインストールしたりする。&lt;/p&gt;

&lt;h3 id=&#34;goose-https-bitbucket-org-liamstask-goose&#34;&gt;&lt;a href=&#34;https://bitbucket.org/liamstask/goose&#34;&gt;goose&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;DBマイグレーションツール。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;db/dbconf.yml&lt;/code&gt;に以下のようなyamlファイルを置いて&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;development:
  driver: mymysql
  open: tcp:localhost:3306*bbs_go/root/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;goose create&lt;/code&gt;でマイグレーションファイルを作成する。これはgoかsqlで書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get bitbucket.org/liamstask/goose/cmd/goose
$ goose create CreateMessages sql
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;
-- +goose Up
-- SQL in section &#39;Up&#39; is executed when this migration is applied
CREATE TABLE message (
  id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,
  content TEXT NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- +goose Down
-- SQL section &#39;Down&#39; is executed when this migration is rolled back
DROP TABLE message;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ goose up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/149/&#34;&gt;Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;テストの書き方&#34;&gt;テストの書き方&lt;/h2&gt;

&lt;p&gt;参考にした記事と同じく、handler, service, daoで構成し、
それぞれのコンストラクタの引数に直下のレイヤーのインタフェースを取ることでDIする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewMessage(tx dao.Tx, messageDao dao.Message) *MessageImpl {
	return &amp;amp;MessageImpl{tx: tx, messageDao: messageDao}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
テスト時には&lt;a href=&#34;https://github.com/golang/mock&#34;&gt;mock&lt;/a&gt;を渡す。
&lt;code&gt;mockgen&lt;/code&gt;でmockを生成し、以下のようにして入力と出力を指定することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/golang/mock/gomock
$ go get github.com/golang/mock/mockgen
$ mockgen -package dao -source message.go -destination message_mock.go
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ctl := gomock.NewController(t)
defer ctl.Finish()

message := model.Message{ID: 1, Content: &amp;quot;メッセージ&amp;quot;}
messageDaoMoc := dao.NewMockMessage(ctl)
messageDaoMoc.EXPECT().Create(message.Content).Return(int64(1), nil)
messageDaoMoc.EXPECT().FindById(message.ID).Return(&amp;amp;message, nil)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;何も指定しないと1回も呼ばれなかったり、2回以上呼ばれるとエラーになるが、
&lt;a href=&#34;https://godoc.org/github.com/golang/mock/gomock#Call.MinTimes&#34;&gt;MinTimes()&lt;/a&gt;などで柔軟に書くこともできる。
とはいえmockの内容によっては無理にgomockを使うと真にテストしたいことが埋もれてしまうことがあるので、
あくまでmockを作る選択肢の一つとして考えておくと良いと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>O&#39;Reillyの「マイクロサービスアーキテクチャ」を読んだ</title>
          <link>https://www.sambaiz.net/article/14/</link>
          <pubDate>Sat, 06 Aug 2016 18:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/14/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873117607/&#34;&gt;O&amp;rsquo;Reilly Japan - マイクロサービスアーキテクチャ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;設計、開発、テストや監視など一通りまとまっているマイクロサービスアーキテクチャの本。&lt;/p&gt;

&lt;p&gt;マイクロサービスアーキテクチャというのは、協調して動作する小規模で自律的なサービスでシステムを構成するもので、
一般的なモノリシック(一枚岩)システムのモジュールのように独立したサービスを作っていく。
自律的というのは、他には何も変更せずに、単独でサービスの変更やデプロイを行えるということ。&lt;/p&gt;

&lt;p&gt;メリットとしては&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;サービスごとに異なる技術を使うことができる&lt;/li&gt;
&lt;li&gt;一部のサービスで障害が発生しても、機能低下させて稼働し続けるシステムを構築できる&lt;/li&gt;
&lt;li&gt;性能を高める必要があるサービスだけをスケールでき、効率的にリソースを使うことができる&lt;/li&gt;
&lt;li&gt;デプロイのリスクを最小限に抑えることができるため、迅速に行うことができる&lt;/li&gt;
&lt;li&gt;レガシーなコードを捨て去る障壁が低い&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;などが挙げられていた。&lt;/p&gt;

&lt;p&gt;正しくサービスを切り分けるにはドメインの理解が必要で、「境界づけられたコンテキスト」が1つのサービスとなるようにする。
そのため、最初はモノシリックに進めることも推奨されていた。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;特に初めてのドメインでは、システムをマイクロサービスに分解するのが時期尚早だとコストがかかってしまう場合があります。いろいろな意味で、マイクロサービスに分解したい既存のコードベースがある方が、最初からマイクロサービスに取り組むよりもはるかに簡単です (3.3.3)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;実現する上で、DBの扱いが難しいと思った。
サービス間のDBの共有はスキーマの変更に弱く、技術の縛りが発生してしまうので避けなければならない。
一方で、DBを分割すると1つのトランザクションで完結しなくなり、どのように整合性を保っていくか。
そんな話が5章に書いてあって、いくつか方法は挙げられているが、いずれにせよ何かしらの制御をしなくてはいけないし、
データの取得の上でも一つのデータベースにあったほうが便利だったりする。
サービスの単位がデータに引きずられてしまうと、マイクロサービスとはいえないものが出来上がりそうだ。
きれいに分けられればいいけど実際どうなんだろう。&lt;/p&gt;

&lt;p&gt;すぐにマイクロサービスを採用するかは別としても、考え方として活かせそうなことが多かった。
実際にやってみて、また読み返して自分のものにしていこうと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Tensorflowの学習データを使ったAPIを作る</title>
          <link>https://www.sambaiz.net/article/13/</link>
          <pubDate>Fri, 05 Aug 2016 22:08:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/13/</guid>
          <description>

&lt;p&gt;チュートリアルのMNISTの学習データを使って、手書き数字画像のデータを受け取り、数字を返すAPIを作る。
コードは&lt;a href=&#34;https://github.com/sambaiz/tensorflow-use-api-sample&#34;&gt;ここ&lt;/a&gt;にある。&lt;/p&gt;

&lt;h2 id=&#34;学習して結果を保存する&#34;&gt;学習して結果を保存する&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/6&#34;&gt;前回&lt;/a&gt;の学習結果のcheckpointファイルを出力する。
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Saver#save&#34;&gt;tf.train.Saver().save&lt;/a&gt;でnameで対応するVariableの値が保存できる。
また、その際&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/training/saver.py#L1560&#34;&gt;デフォルト&lt;/a&gt;で&lt;a href=&#34;https://www.tensorflow.org/api_guides/python/meta_graph&#34;&gt;MetaGraph&lt;/a&gt;もexportされ、これをimportすればGraphも復元することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

class Mnist:

    def __init__(self):

        g = tf.Graph()

        with g.as_default():

            W_conv1 = self._weight_variable([5, 5, 1, 32],  &amp;quot;W_conv1&amp;quot;)
            b_conv1 = self._bias_variable([32],  &amp;quot;b_conv1&amp;quot;)

            self._x = tf.placeholder(tf.float32, [None, 784])
            x_image = tf.reshape(self._x, [-1,28,28,1])

            h_conv1 = tf.nn.relu(self._conv2d(x_image, W_conv1) + b_conv1)
            h_pool1 = self._max_pool_2x2(h_conv1)

            W_conv2 = self._weight_variable([5, 5, 32, 64],  &amp;quot;W_conv2&amp;quot;)
            b_conv2 = self._bias_variable([64],  &amp;quot;b_conv2&amp;quot;)

            h_conv2 = tf.nn.relu(self._conv2d(h_pool1, W_conv2) + b_conv2)
            h_pool2 = self._max_pool_2x2(h_conv2)

            W_fc1 = self._weight_variable([7 * 7 * 64, 1024],  &amp;quot;W_fc1&amp;quot;)
            b_fc1 = self._bias_variable([1024],  &amp;quot;b_fc1&amp;quot;)

            h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

            self._keep_prob = tf.placeholder(tf.float32)
            h_fc1_drop = tf.nn.dropout(h_fc1, self._keep_prob)

            W_fc2 = self._weight_variable([1024, 10],  &amp;quot;W_fc2&amp;quot;)
            b_fc2 = self._bias_variable([10],  &amp;quot;b_fc2&amp;quot;)

            y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
            self._what_number = tf.argmax(y_conv, 1)

            self._y_ = tf.placeholder(tf.float32, [None, 10])
            cross_entropy = tf.reduce_mean(-tf.reduce_sum(self._y_ * tf.log(y_conv), reduction_indices=[1]))
            self._train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
            correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(self._y_,1))
            self._accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

            self.sess = tf.Session()
            init = tf.initialize_all_variables()
            self.sess.run(init)
            self._saver = tf.train.Saver()

    def save(self, ckpt_file_name):
        self._saver.save(self.sess, ckpt_file_name)

    def restore(self, ckpt_file_name):
        self._saver.restore(self.sess, ckpt_file_name)

    def what_number(self, image_array):
        return self.sess.run(self._what_number, feed_dict={self._x: image_array, self._keep_prob: 1.0})

    def train(self, num):
        if not hasattr(self, &amp;quot;_mnist&amp;quot;):
            self._mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)

        for i in range(num):
            batch = self._mnist.train.next_batch(50)
            if i%100 == 0:
              train_accuracy = self._accuracy.eval(session=self.sess, feed_dict={
                      self._x:batch[0], self._y_: batch[1], self._keep_prob: 1.0
                  })
              print(&amp;quot;step %d, training accuracy %g&amp;quot;%(i, train_accuracy))
            self.sess.run(self._train_step, feed_dict={self._x: batch[0], self._y_: batch[1], self._keep_prob: 0.5})

        print(&amp;quot;test accuracy %g&amp;quot;%self._accuracy.eval(session=self.sess, feed_dict={
                self._x: self._mnist.test.images, self._y_: self._mnist.test.labels, self._keep_prob: 1.0
            }))

    def close(self):
        self.sess.close()

    def _weight_variable(self, shape, name):
      initial = tf.truncated_normal(shape, stddev=0.1)
      return tf.Variable(initial, name=name)

    def _bias_variable(self, shape, name):
      initial = tf.constant(0.1, shape=shape)
      return tf.Variable(initial, name=name)

    def _conv2d(self, x, W):
      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;)

    def _max_pool_2x2(self, x):
      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1], padding=&#39;SAME&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;train&lt;/code&gt;で学習し、&lt;code&gt;save&lt;/code&gt;でチェックポイントファイルを保存できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from mnist import Mnist

mnist = Mnist()
mnist.train(20000)
mnist.save(&amp;quot;model.ckpt&amp;quot;)
mnist.close()
print(&amp;quot;done&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なので、例えばこんなDockerfileを書いて&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM gcr.io/tensorflow/tensorflow

ADD training.py /
ADD mnist.py /

CMD python /training.py &amp;amp;&amp;amp; /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しばらく待つ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t training .
$ docker run -itd training
$ docker logs -f &amp;lt;CONTAINER_ID&amp;gt;
$ docker cp &amp;lt;CONTAINER_ID&amp;gt;:/notebooks/model.ckpt .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;学習データを使う&#34;&gt;学習データを使う&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;tf.train.Saver().restore&lt;/code&gt;でチェックポイントファイルを読み、Variableの値を復元できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from flask import Flask, request, jsonify
import tensorflow as tf
from mnist import Mnist

app = Flask(__name__)

mnist = Mnist()
mnist.restore(&amp;quot;/model.ckpt&amp;quot;)

@app.route(&amp;quot;/&amp;quot;, methods=[&#39;POST&#39;])
def what_number():

    json = request.json
    if(json is None or &amp;quot;image&amp;quot; not in json or len(json[&amp;quot;image&amp;quot;]) != 784):
        return jsonify(error=&amp;quot;Need json includes image property which is 784(28 * 28) length, float([0, 1.0]) array&amp;quot;)
    else:
        result = list(mnist.what_number([json[&amp;quot;image&amp;quot;]]))
        return jsonify(result=result[0])

if __name__ == &amp;quot;__main__&amp;quot;:
    app.run(port=3000, host=&#39;0.0.0.0&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これもDockerで動かすならこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM gcr.io/tensorflow/tensorflow

ADD requirements.txt /tmp
ADD model.ckpt /
ADD training/mnist.py /
ADD app.py /

RUN pip install -q -r /tmp/requirements.txt

EXPOSE 3000

CMD [&amp;quot;python&amp;quot;, &amp;quot;/app.py&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t tensor_api .
$ docker run -itd -p 3000:3000 tensor_app
$ docker logs -f &amp;lt;CONTAINER_ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これに以下のようにして28*28の画像のデータを渡すと、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;image&amp;quot;: [ ..., 0.32941177, 0.72549021, 0.62352943, ...]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それが何の数字なのかが返ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;result&amp;quot;: 7
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;(追記 2018-07-25)&lt;/p&gt;

&lt;p&gt;この記事ではcheckpointをそのまま使っているが、モデルを公開する際はSaverをwrapしたSavedModelにするのが&lt;a href=&#34;https://github.com/tensorflow/tensorflow/tree/r1.9/tensorflow/python/saved_model#background&#34;&gt;標準的&lt;/a&gt;だ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/172/&#34;&gt;TensorFlowのモデルをsave/loadする - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Googleが作ったRPCフレームワークgRPCを使ってみた</title>
          <link>https://www.sambaiz.net/article/12/</link>
          <pubDate>Fri, 29 Jul 2016 22:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/12/</guid>
          <description>

&lt;blockquote&gt;
&lt;p&gt;A high performance, open source, general RPC framework that puts mobile and HTTP/2 first.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;what-is-grpc-http-www-grpc-io-docs-what-is-grpc&#34;&gt;&lt;a href=&#34;http://www.grpc.io/docs/#what-is-grpc&#34;&gt;What is gRPC?&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;gRPCを使うと、クライアントアプリケーションは直接ローカルのオブジェクトのように、他のマシンのサーバーアプリケーションのメソッドを呼ぶことができ、
分散したアプリケーションやサービスを簡単に作ることができる。
多くのRPCシステムと同様にgRPCはサービスを定義し、リモートから呼べるメソッドとそのパラメーターおよび返り値の型を記述するようになっている。
サーバーサイドではインタフェースを実装し、クライアントからの呼び出しをハンドリングするgRPCサーバーを実行する。
クライアントサイドではサーバーと同じメソッドを提供するスタブを持っている。&lt;/p&gt;

&lt;p&gt;gRPCクライアントとサーバーは様々な環境同士でやり取りすることができ、いくつもの言語でサポートされている。
そのため例えば、gRPCサーバーをJavaでクライアントをGoやPython、Rubyで作るのも可能だ。
加えて、最新のGoodle APIにはgRPCのインタフェースが存在するので、これらをアプリケーションに組み込むのも容易にできる。&lt;/p&gt;

&lt;h2 id=&#34;protobuf&#34;&gt;Protobuf&lt;/h2&gt;

&lt;p&gt;デフォルトではgRPCはprotobuf(protocol buffers)でやり取りする。
&lt;a href=&#34;https://github.com/google/protobuf&#34;&gt;protobuf&lt;/a&gt;というのは、
Googleによるオープンソースのシリアライズフォーマット。&lt;/p&gt;

&lt;p&gt;今回作るのは、同じ文字列を返すだけのEchoサーバーで、コードは&lt;a href=&#34;https://github.com/sambaiz/try-gRPC&#34;&gt;ここ&lt;/a&gt;にある。
以下のprotoファイルでは、&lt;code&gt;Echo&lt;/code&gt;というサービスは&lt;code&gt;RetEcho&lt;/code&gt;というメソッドを含み、
これは文字列&lt;code&gt;say&lt;/code&gt;を含む&lt;code&gt;EchoRequest&lt;/code&gt;に対して、文字列&lt;code&gt;ret&lt;/code&gt;を含む&lt;code&gt;EchoReply&lt;/code&gt;を返すということを表している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;syntax = &amp;quot;proto3&amp;quot;;

option java_package = &amp;quot;net.sambaiz.trygrpc.protos&amp;quot;;

package protos;

service Echo {
  rpc RetEcho (EchoRequest) returns (EchoReply) {}
}

message EchoRequest {
  string say = 1;
}

message EchoReply {
  string ret = 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;code&gt;protoc&lt;/code&gt;でコンパイルすると&lt;code&gt;echo.pb.go&lt;/code&gt;のようなコードが生成される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install --devel protobuf # install Install Protocol Compiler v3.0.0-beta-2
$ go get -u github.com/golang/protobuf/protoc-gen-go # Install Go Protobuf Runtime Installation
$ protoc --go_out=plugins=grpc:protos/. protos/*.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;サーバー&#34;&gt;サーバー&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ go get google.golang.org/grpc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;protoファイルに書いたRetEchoを実装し、サーバーを立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;golang.org/x/net/context&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;net&amp;quot;
	&amp;quot;log&amp;quot;
	pb &amp;quot;github.com/sambaiz/try-gRPC/protos&amp;quot;
)

const (
	port = &amp;quot;:50051&amp;quot;
)

type server struct{}

func (s *server) RetEcho(ctx context.Context, in *pb.EchoRequest) (*pb.EchoReply, error) {
	return &amp;amp;pb.EchoReply{Ret: in.Say}, nil
}

func main() {
	lis, err := net.Listen(&amp;quot;tcp&amp;quot;, port)
	if err != nil {
		log.Fatalf(&amp;quot;failed to listen: %v&amp;quot;, err)
	}
	s := grpc.NewServer()
	pb.RegisterEchoServer(s, &amp;amp;server{})
	log.Printf(&amp;quot;server start localhost%s&amp;quot;, port)
	s.Serve(lis)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/174/&#34;&gt;GoのgRPC ServerのInterceptor(recovery/auth/zap/prometheus) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;クライアント&#34;&gt;クライアント&lt;/h2&gt;

&lt;p&gt;サーバーに接続すると、他のメソッドと同じようにサーバー側の&lt;code&gt;RetEcho&lt;/code&gt;メソッドを呼び出すことができるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;log&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;golang.org/x/net/context&amp;quot;
	pb &amp;quot;github.com/sambaiz/try-gRPC/protos&amp;quot;

)

const (
	address = &amp;quot;localhost:50051&amp;quot;
)

func main() {
	conn, err := grpc.Dial(address, grpc.WithInsecure())
	if err != nil {
		log.Fatalf(&amp;quot;did not connect: %v&amp;quot;, err)
	}
	defer conn.Close()
	c := pb.NewEchoClient(conn)

	r, err := c.RetEcho(context.Background(), &amp;amp;pb.EchoRequest{Say: &amp;quot;hello&amp;quot;})
	if err != nil {
		log.Fatalf(&amp;quot;Error: %v&amp;quot;, err)
	}
	log.Printf(&amp;quot;Return: %s&amp;quot;, r.Ret)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最新のprotoファイルを共有すれば、どんな言語で書いても自分で型を定義したり、呼び出すロジックを書く必要がないし、
インタフェースが変わったときにコードレベルでエラーに気づけるのは通常のAPIリクエストと比較して良い点だと思う。
ロジックが複数のサーバーに渡る場合の負担を最小限にできるため、サービスを小さく作るマイクロサービスアーキテクチャで使われるが、性能や管理のしやすさなどの面でもメリット/デメリットはある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/14&#34;&gt;O&amp;rsquo;Reillyの「マイクロサービスアーキテクチャ」を読んだ - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLで大文字小文字を区別しないのを直す</title>
          <link>https://www.sambaiz.net/article/11/</link>
          <pubDate>Sun, 24 Jul 2016 22:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/11/</guid>
          <description>&lt;p&gt;Collationの話。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MySQL 5.6
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE sample (
  id SERIAL,
  name VARCHAR(30)
) ENGINE=InnoDB CHARACTER SET utf8mb4;

INSERT INTO sample (name) VALUES (&#39;tom&#39;),(&#39;Tom&#39;),(&#39;TOM&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このテーブルを&amp;rdquo;tom&amp;rdquo;で絞り込むとこうなる。大文字小文字を区別していない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SELECT * FROM sample2 WHERE name = &#39;tom&#39;;
+----+------+
| id | name |
+----+------+
|  1 | tom  |
|  2 | Tom  |
|  3 | TOM  |
+----+------+
3 rows in set (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/case-sensitivity.html&#34;&gt;MySQL :: MySQL 5.6 リファレンスマニュアル :: B.5.5.1 文字列検索での大文字/小文字の区別&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;単純な比較操作 (&amp;gt;=、&amp;gt;、=、&amp;lt;、&amp;lt;=、ソート、およびグループ化) は、各文字の「ソート値」に基づきます。
同じソート値を持つ文字は同じ文字として扱われます。たとえば、「e」 と 「é」 が対象の照合順序で同じソート値を持つ場合は、等しいと判断されます。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.mysql.com/doc/refman/5.6/ja/charset-mysql.html&#34;&gt;MySQL :: MySQL 5.6 リファレンスマニュアル :: 10.1.2 MySQL での文字セットと照合順序&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;照合順序名には、関連する文字セットの名前で始まる、通常は言語名を含む、
_ci (大文字と小文字を区別しない)、_cs (大文字と小文字を区別する)、_bin (バイナリ)
のいずれかで終わる、という規則が適用されます。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ciはcase-insensitive、csというのはcase-sensitiveの略だ。
照合順序(Collation)を&lt;code&gt;SHOW FULL COLUMNS FROM sample&lt;/code&gt;で確認したところ、確かに区別しない&lt;code&gt;utf8mb4_general_ci&lt;/code&gt;となっていた。
これは、文字コード&lt;code&gt;utf8mb4&lt;/code&gt;のデフォルトの照合順序だ。(&lt;code&gt;SHOW CHARACTER SET&lt;/code&gt;で確認できる)&lt;/p&gt;

&lt;p&gt;それなら&lt;code&gt;utf8mb4_general_cs&lt;/code&gt;というのがあるんだなと、&lt;code&gt;SHOW COLLATION LIKE &#39;utf8mb4%&#39;&lt;/code&gt;で確認してみたが、
そんなものはなかった。どうやら区別させるためには&lt;code&gt;utf8mb4_bin&lt;/code&gt;を使うのが正解みたいで、これをCOLLATEで指定してやるか、
カラム単位でBINARYとすると、照合順序が&lt;code&gt;utf8mb4_bin&lt;/code&gt;となり、期待通りの結果が得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE sample2 (
  id SERIAL,
  name VARCHAR(30)
) ENGINE=InnoDB CHARACTER SET utf8mb4 COLLATE utf8mb4_bin;

CREATE TABLE sample3 (
  id SERIAL,
  name VARCHAR(30) BINARY
) ENGINE=InnoDB CHARACTER SET utf8mb4;

ALTER TABLE sample MODIFY name VARCHAR(30) BINARY;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SELECT * FROM sample2 WHERE name = &#39;tom&#39;;
+----+------+
| id | name |
+----+------+
|  1 | tom  |
+----+------+
1 row in set (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>グラフデータベースNeo4jを触ってみた</title>
          <link>https://www.sambaiz.net/article/10/</link>
          <pubDate>Thu, 21 Jul 2016 09:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/10/</guid>
          <description>

&lt;p&gt;社内勉強会で&lt;a href=&#34;https://github.com/neo4j/neo4j&#34;&gt;オープンソース&lt;/a&gt;の
グラフデータベース&lt;a href=&#34;https://neo4j.com/&#34;&gt;Neo4j&lt;/a&gt;が紹介されていたので触ってみた。&lt;/p&gt;

&lt;h2 id=&#34;what-is-a-graph-database-https-neo4j-com-developer-graph-database&#34;&gt;&lt;a href=&#34;https://neo4j.com/developer/graph-database/&#34;&gt;What is a Graph Database?&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;つながりも含めたグラフとしてデータを扱うデータベース。
データセットのサイズによらず、複雑なつながりや、クエリをうまく扱える。
無数のデータの中から、関係ないデータを見ることなく多数のノードとつながりからなる必要なデータだけを取れる。&lt;/p&gt;

&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://neo4j.com/download/&#34;&gt;ここ&lt;/a&gt;からCommunity Editionを選んで
OSごとに用意されている実行ファイルをダウンロードしてくる。
ファイルを実行し、Startを押すとブラウザで開けるようになる。&lt;/p&gt;

&lt;h2 id=&#34;グラフ&#34;&gt;グラフ&lt;/h2&gt;

&lt;p&gt;グラフは以下の要素から構成される。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Node: データそのもので、まとめるためのラベルを複数付けられる&lt;/li&gt;
&lt;li&gt;Relationships: typeを持つ、Nodeのつながり&lt;/li&gt;
&lt;li&gt;Properties: NodeやRelationshipsが持てるkey-valueの値&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cypher&#34;&gt;Cypher&lt;/h2&gt;

&lt;p&gt;Neo4jで使うクエリ言語。&lt;/p&gt;

&lt;p&gt;まずはCREATE文でNodeを作る。Personはラベルだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE (ee:Person { name: &amp;quot;Emil&amp;quot;, from: &amp;quot;Sweden&amp;quot;, klout: 99 })
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CREATE文では使われていなかった謎のeeだが、MATCH文を見るとデータが格納される変数だということがわかる。
このeeは次のCREATE文でも参照できて、&lt;code&gt;(ee)-[:KNOWS {since: 2001}]-&amp;gt;(js)&lt;/code&gt;で
作ったNodeとのRelationshipsを張るのに使っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MATCH (ee:Person) WHERE ee.name = &amp;quot;Emil&amp;quot; RETURN ee;

CREATE (js:Person { name: &amp;quot;Johan&amp;quot;, from: &amp;quot;Sweden&amp;quot;, learn: &amp;quot;surfing&amp;quot; }),
(ir:Person { name: &amp;quot;Ian&amp;quot;, from: &amp;quot;England&amp;quot;, title: &amp;quot;author&amp;quot; }),
(rvb:Person { name: &amp;quot;Rik&amp;quot;, from: &amp;quot;Belgium&amp;quot;, pet: &amp;quot;Orval&amp;quot; }),
(ally:Person { name: &amp;quot;Allison&amp;quot;, from: &amp;quot;California&amp;quot;, hobby: &amp;quot;surfing&amp;quot; }),
(ee)-[:KNOWS {since: 2001}]-&amp;gt;(js),(ee)-[:KNOWS {rating: 5}]-&amp;gt;(ir),
(js)-[:KNOWS]-&amp;gt;(ir),(js)-[:KNOWS]-&amp;gt;(rvb),
(ir)-[:KNOWS]-&amp;gt;(js),(ir)-[:KNOWS]-&amp;gt;(ally),
(rvb)-[:KNOWS]-&amp;gt;(ally)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のようにパターンマッチもできる。この例だとEmilの友達が取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MATCH (ee:Person)-[:KNOWS]-(friends)
WHERE ee.name = &amp;quot;Emil&amp;quot; RETURN ee, friends
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必ずしも変数に入れなくても良く、&lt;code&gt;()&lt;/code&gt;のように無視することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MATCH (js:Person)-[:KNOWS]-()-[:KNOWS]-(surfer)
WHERE js.name = &amp;quot;Johan&amp;quot; AND surfer.hobby = &amp;quot;surfing&amp;quot;
RETURN DISTINCT surfer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最短経路を取得するのも簡単だ。&lt;code&gt;[*1..4]&lt;/code&gt;にして、ホップ数に制限をかけたり、範囲を指定したりすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MATCH p=shortestPath(
  (bacon:Person {name:&amp;quot;Kevin Bacon&amp;quot;})-[*]-(meg:Person {name:&amp;quot;Meg Ryan&amp;quot;})
)
RETURN p
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もちろんSQLの&lt;code&gt;LIMIT&lt;/code&gt;や&lt;code&gt;ORDER BY&lt;/code&gt;、&lt;code&gt;GROUP BY&lt;/code&gt;相当のこともできる。
文法が直感的に分かりやすいものになっていて良いと思った。&lt;/p&gt;

&lt;h2 id=&#34;欠点&#34;&gt;欠点&lt;/h2&gt;

&lt;p&gt;とにかくSQLのJOIN地獄から脱出できそうなのが大きくて、それだけで採用したい気になってしまうが、
データの総量とは関係なく一つのNodeに大量にRelationshipsが付くと非常に遅くなるという問題があるらしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cyberagent.co.jp/technology/ca_tech/report/8980456.html&#34;&gt;【CyberAgent】技術情報／TechReport - テックレポート／MongoDB de GraphDB | 株式会社サイバーエージェント&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;なぜかというと隣接Node/RelationshipsのポインタをLinkedListで持っているからみたいだ。これは苦しい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://the.igreque.info/posts/2014-06-08-neo4j.html&#34;&gt;igreque : Info -&amp;gt; Neo4jについてちょちょいと調べたまとめ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;電車の路線のように一つのNodeに対して高々いくつかのRelationshipsしかつながらないことが分かっている場合には問題ないので、
そういうモデルを作るか、あるいはデータの数を絞るか、使うにあたって工夫が必要そうだ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesのチュートリアルをたどる</title>
          <link>https://www.sambaiz.net/article/9/</link>
          <pubDate>Mon, 18 Jul 2016 22:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/9/</guid>
          <description>

&lt;h2 id=&#34;kubernetesとは-http-kubernetes-io-docs-whatisk8s&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/whatisk8s/&#34;&gt;Kubernetesとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Kubernetes(発音は&lt;a href=&#34;https://cloudplatform.googleblog.com/2014/06/an-update-on-container-support-on-google-cloud-platform.html&#34;&gt;koo-ber-nay&amp;rsquo;-tace&lt;/a&gt;。
ギリシャ語で操舵手。)はGoogleによって開発が始められた、アプリケーションコンテナにおける自動デプロイ、スケーリング、操作を
自動化するOSS。K8sと略される。&lt;/p&gt;

&lt;h2 id=&#34;minikube-https-github-com-kubernetes-minikube&#34;&gt;&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;Minikube&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;K8sをローカルで試すために、MinikubeというVMの中で単一ノードのK8sクラスターを動かすツールを入れる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/minikube/releases/tag/v0.6.0&#34;&gt;v0.6.0&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.6.0/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ minikube start
Starting local Kubernetes cluster...

...

$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;2&amp;quot;, GitVersion:&amp;quot;v1.2.4&amp;quot;, GitCommit:&amp;quot;3eed1e3be6848b877ff80a93da3785d9034d0a4f&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;3&amp;quot;, GitVersion:&amp;quot;v1.3.0&amp;quot;, GitCommit:&amp;quot;283137936a498aed572ee22af6774b6fb6e9fd94&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pods-http-kubernetes-io-docs-user-guide-walkthrough-pods&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/#pods&#34;&gt;Pods&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;K8sではコンテナのグループをpodと呼ぶ。pod中のコンテナは共にデプロイされ、起動し、停止する。
また、グループとして複製される。&lt;/p&gt;

&lt;p&gt;Podの定義は次のようにyamlで書かれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.7.9
    ports:
    - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podの定義に望ましい状態を記述すると、Kubernatesはそれを見て現在の状態が一致しているかどうか確認する。
例えば、Podが作られたときに、コンテナがその中で動いている状態が望ましい状態だとすると、
コンテナが動かなくなったときに、Kubernatesは新しいものを再作成することで望ましい状態にする。&lt;/p&gt;

&lt;p&gt;podの作成とリストの取得のコマンドは次の通り。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f nginx.yaml
$ kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          4s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl exec&lt;/code&gt;でps&lt;a href=&#34;http://kubernetes.io/docs/user-guide/getting-into-containers/&#34;&gt;コマンドを実行&lt;/a&gt;し、
podが動いていることを確認しようとしたがコマンドがなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl exec -it nginx ps
rpc error: code = 2 desc = &amp;quot;oci runtime error: exec failed: exec: \&amp;quot;ps\&amp;quot;: executable file not found in $PATH&amp;quot;error: error executing remote command: error executing command in container: Error executing in Docker Container: 126
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこでリクエストを投げるために&lt;code&gt;kubectl run&lt;/code&gt;で単一コンテナのDeploymentを&lt;a href=&#34;http://kubernetes.io/docs/user-guide/kubectl/kubectl_run/&#34;&gt;作成する&lt;/a&gt;。
Deploymentについては後で説明がある。
&lt;code&gt;--restart=Never&lt;/code&gt;でpodが存在しなくなったときに再起動しないようにし、&lt;code&gt;--env&lt;/code&gt;で環境変数としてnginxのpodのIPを渡している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl run busybox --image=busybox --restart=Never --tty -i --env &amp;quot;POD_IP=$(kubectl get pod nginx -o go-template={{.status.podIP}})&amp;quot;
busybox$ wget -qO- http://$POD_IP
busybox$ exit # Exit the busybox container

$ kubectl get deployments

$ kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          54m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--restart=Never&lt;/code&gt;なしで実行するとこうなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl run busybox --image=busybox --tty -i --env &amp;quot;POD_IP=$(kubectl get pod nginx -o go-template={{.status.podIP}})&amp;quot;
busybox$ exit
Session ended, resume using &#39;kubectl attach busybox-985443498-9elny -c busybox -i -t&#39; command when the pod is running

$ kubectl get deployments
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
busybox   1         1         1            1           3m

$ kubectl get pods
NAME                      READY     STATUS    RESTARTS   AGE
busybox-985443498-9elny   1/1       Running   1          3m
nginx                     1/1       Running   0          59m

$ kubectl delete pods busybox-985443498-9elny
pod &amp;quot;busybox-985443498-9elny&amp;quot; deleted

$ kubectl get pods # Podsだけ削除しても新しいものが立ち上がってくる
NAME                      READY     STATUS              RESTARTS   AGE
busybox-985443498-4iyvx   0/1       ContainerCreating   0          1s
busybox-985443498-9elny   1/1       Terminating         1          13m
nginx                     1/1       Running             0          1h

$ kubectl delete deployment busybox

$ kubectl get pods # Deploymentを削除するとPodsも消える
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;volumes-http-kubernetes-io-docs-user-guide-walkthrough-volumes&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/#volumes&#34;&gt;Volumes&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;コンテナのファイルシステムはコンテナが生存しているときに限り有効なので、
永続化したいデータはコンテナの外に保存する必要がある。&lt;/p&gt;

&lt;p&gt;次の例のように&lt;code&gt;volumes&lt;/code&gt;でvolumeを定義し、&lt;code&gt;volumeMounts&lt;/code&gt;でどこにマウントするか指定することができる。
&lt;code&gt;volumes&lt;/code&gt;には、そのPodがノードで実行されている間存在するディレクトリを作成して使う&lt;code&gt;EmptyDir&lt;/code&gt;か、
ノードのファイルシステムに既に存在するディレクトリを使う&lt;code&gt;HostPath&lt;/code&gt;を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: redis
spec:
  containers:
  - name: redis
    image: redis
    volumeMounts:
    - name: redis-persistent-storage
      mountPath: /data/redis
  volumes:
  - name: redis-persistent-storage
    emptyDir: {}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;labels-http-kubernetes-io-docs-user-guide-walkthrough-k8s201-labels&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/k8s201/#labels&#34;&gt;Labels&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;metadataとしてkey-valueのラベルを付けることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;metadata:
  name: nginx
  labels:
    app: nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubectl get pods -l app=nginx
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          2m
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deployments-http-kubernetes-io-docs-user-guide-walkthrough-k8s201-deployments&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/k8s201/#deployments&#34;&gt;Deployments&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;実行しているPodの維持と更新を管理するのが上でも出てきたDeployment。
Deploymentの定義にはPodを作るためのテンプレートと維持するPod数を記述する。
pod名はDeployment名から生成されるのでtemplateには含めない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f deployment.yaml
$ kubectl get deployment
NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   2         2         2            2           3m

$ kubectl get pods -l app=nginx
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1159050644-ar3i7   1/1       Running   0          3m
nginx-deployment-1159050644-kdjly   1/1       Running   0          3m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl apply&lt;/code&gt;でDeploymentの変更を実行中のPodに適用する。
次の例ではnginxのバージョンを上げている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.8
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl apply -f deployment-update.yaml
$ kubectl get pods
NAME                                READY     STATUS              RESTARTS   AGE
nginx-deployment-1159050644-kdjly   1/1       Running             0          30m
nginx-deployment-1771418926-pi3vy   0/1       ContainerCreating   0          7s
nginx-deployment-1771418926-ygoxl   0/1       ContainerCreating   0          7s

$ kubectl get pods
NAME                                READY     STATUS              RESTARTS   AGE
nginx-deployment-1771418926-pi3vy   0/1       ContainerCreating   0          12s
nginx-deployment-1771418926-ygoxl   1/1       Running             0          12s

$ kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1771418926-pi3vy   1/1       Running   0          15s
nginx-deployment-1771418926-ygoxl   1/1       Running   0          15s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;services-http-kubernetes-io-docs-user-guide-walkthrough-k8s201-services&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/k8s201/#services&#34;&gt;Services&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;アプリケーションのレイヤー間(例えばフロントエンドとバックエンド)の接続で使われるのがService。
次のServiceは、8080番ポートで待ち、&lt;code&gt;app: nginx&lt;/code&gt;のラベルが付いているPodの80番ポートに向けるロードバランサーとして働く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  ports:
  - port: 8000
    targetPort: 80
    protocol: TCP
  selector:
    app: nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f service.yaml
$ kubectl get services
NAME            CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
kubernetes      10.0.0.1     &amp;lt;none&amp;gt;        443/TCP    19h
nginx-service   10.0.0.90    &amp;lt;none&amp;gt;        8000/TCP   36s

$ export SERVICE_IP=$(kubectl get service nginx-service -o go-template=&#39;{{.spec.clusterIP}}&#39;)
$ export SERVICE_PORT=$(kubectl get service nginx-service -o go-template=&#39;{{(index .spec.ports 0).port}}&#39;)
$ echo &amp;quot;$SERVICE_IP:$SERVICE_PORT&amp;quot;
10.0.0.90:8000
$ kubectl run busybox --image=busybox --restart=Never --tty -i --env &amp;quot;SERVICE_IP=$SERVICE_IP,SERVICE_PORT=$SERVICE_PORT&amp;quot;
busybox$ wget -qO- http://$SERVICE_IP:$SERVICE_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;health-checking-http-kubernetes-io-docs-user-guide-walkthrough-k8s201-health-checking&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/k8s201/#health-checking&#34;&gt;Health Checking&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;livenessProbe&lt;/code&gt;にヘルスチェックの設定を含めることができる。
次の例では、初期化のために30秒待った後、&lt;code&gt;/_status/healthz&lt;/code&gt;へのHTTP GETリクエストに対して
200~399以外のステータスコードが返るか、1秒以上かかった場合、コンテナを再起動する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: pod-with-healthcheck
spec:
  containers:
  - name: nginx
    image: nginx
    livenessProbe:
      httpGet:
        path: /_status/healthz
        port: 80
      initialDelaySeconds: 30
      timeoutSeconds: 1
    ports:
    - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsのバージョン管理</title>
          <link>https://www.sambaiz.net/article/8/</link>
          <pubDate>Fri, 15 Jul 2016 19:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/8/</guid>
          <description>

&lt;h2 id=&#34;n-https-github-com-tj-n&#34;&gt;&lt;a href=&#34;https://github.com/tj/n&#34;&gt;n&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;nodeが必要だけど手軽。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;n latest&lt;/code&gt;, &lt;code&gt;n stable&lt;/code&gt;, &lt;code&gt;n lts&lt;/code&gt;でバージョンが切り替わる。
バージョンを指定する場合、&lt;code&gt;n &amp;lt;version&amp;gt;&lt;/code&gt;でインストールし、&lt;code&gt;n&lt;/code&gt;でインストールされているバージョンの一覧から選択できる。
バージョンの削除は&lt;code&gt;n - &amp;lt;version&amp;gt;&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g n
$ n stable
$ node -v
v6.2.2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;nvm-https-github-com-creationix-nvm&#34;&gt;&lt;a href=&#34;https://github.com/creationix/nvm&#34;&gt;nvm&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;nodeが必要ない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.1/install.sh | bash
$ nvm install node
$ node -v
v7.7.2

$ nvm install 6
$ node -v
v6.10.0

$ nvm ls
        v6.10.0
-&amp;gt;       v7.7.2
default -&amp;gt; node (-&amp;gt; v7.7.2)
node -&amp;gt; stable (-&amp;gt; v7.7.2) (default)
stable -&amp;gt; 7.7 (-&amp;gt; v7.7.2) (default)
iojs -&amp;gt; N/A (default)
lts/* -&amp;gt; lts/boron (-&amp;gt; v6.10.0)
lts/argon -&amp;gt; v4.8.0 (-&amp;gt; N/A)
lts/boron -&amp;gt; v6.10.0

$ nvm use node
Now using node v7.7.2 (npm v4.1.2)

$ nvm use 6
Now using node v6.10.0 (npm v3.10.10)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Docker公式ドキュメント&#34;network コマンドを使う&#34;を読む</title>
          <link>https://www.sambaiz.net/article/7/</link>
          <pubDate>Fri, 15 Jul 2016 00:38:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/7/</guid>
          <description>&lt;pre&gt;&lt;code&gt;Docker version 1.12.0-rc2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;公式ドキュメント&lt;a href=&#34;http://docs.docker.jp/engine/userguide/networking/work-with-networks.html&#34;&gt;network コマンドを使う&lt;/a&gt;
の内容をまとめてみた。&lt;/p&gt;

&lt;p&gt;dockerには3つのデフォルトネットワークが存在する。&lt;code&gt;docker run&lt;/code&gt;時に&lt;code&gt;--net&lt;/code&gt;オプションでネットワークを指定しない限り、
docker0として表示されるbridgeネットワークにコンテナを接続する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
a3b712537566        bridge              bridge              local               
f6d86cb54edd        host                host                local               
33cb30b024d9        none                null                local            
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただし、後方互換性を維持するため、デフォルトのbridgeネットワークでは自動的に名前解決が行われない。&lt;/p&gt;

&lt;p&gt;これらのネットワークとは別にユーザー定義のネットワークを作成することもできる。
単一ホストの&lt;code&gt;bridge&lt;/code&gt;ネットワークと、複数ホストにまたがる&lt;code&gt;overlay&lt;/code&gt;ネットワークから選択でき、
何も指定しなかったら&lt;code&gt;bridge&lt;/code&gt;になる。&lt;code&gt;subnet&lt;/code&gt;を指定しなければ、
dockerデーモンがネットワークに対してサブネットを自動的に割り当てるが、
dockerが管理していないサブネットと重複するのを避けるために指定することが推奨されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker network create -d bridge --subnet 172.25.0.0/16 isolated_nw
$ docker network inspect isolated_nw
$ docker network rm isolated_nw  # 削除
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker network inspect&lt;/code&gt;で以下のようなネットワークの情報が得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[
    {
        &amp;quot;Name&amp;quot;: &amp;quot;isolated_nw&amp;quot;,
        &amp;quot;Id&amp;quot;: &amp;quot;c81547cf7ed897054ea645192c6c47dcf7a248e77bc8067609becab5330e417d&amp;quot;,
        &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;,
        &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;,
        &amp;quot;EnableIPv6&amp;quot;: false,
        &amp;quot;IPAM&amp;quot;: {
            &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;,
            &amp;quot;Options&amp;quot;: {},
            &amp;quot;Config&amp;quot;: [
                {
                    &amp;quot;Subnet&amp;quot;: &amp;quot;172.25.0.0/16&amp;quot;
                }
            ]
        },
        &amp;quot;Internal&amp;quot;: false,
        &amp;quot;Containers&amp;quot;: {},
        &amp;quot;Options&amp;quot;: {},
        &amp;quot;Labels&amp;quot;: {}
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動時に&lt;code&gt;--net&lt;/code&gt;オプションでネットワークに接続したり、
既に存在するコンテナを&lt;code&gt;docker network connect&lt;/code&gt;で接続することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --net=isolated_nw -itd --name=container1 --link container2:c2 busybox
$ docker network connect isolated_nw container1
$ docker network disconnect isolated_nw container1 # 切断
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上の&lt;code&gt;run&lt;/code&gt;によって同一ネットワークからこのコンテナへ、&lt;code&gt;ping container1&lt;/code&gt;が届くようになり、
このコンテナから同一ネットワークのconteiner2にc2というエイリアスが付くため、&lt;code&gt;ping c2&lt;/code&gt;が届くようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker attach container1
# ping c2
PING c2 (172.25.0.2): 56 data bytes
64 bytes from 172.25.0.2: seq=0 ttl=64 time=0.094 ms
...
CTRL-p CTRL-q
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この設定時点でcontainer2が存在しなかったとしてもエラーにならない。
また、この&lt;code&gt;--link&lt;/code&gt;によるエイリアスは所属するネットワーク全体に適用される。&lt;/p&gt;

&lt;p&gt;他にrunで指定している&lt;a href=&#34;http://docs.docker.jp/engine/reference/commandline/run.html&#34;&gt;オプション&lt;/a&gt;は以下の通り。
どれも良く使うもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-i コンテナの STDIN にアタッチ
-t 疑似ターミナル (pseudo-TTY) を割り当てる
-d コンテナをバックグラウンドで実行し、コンテナIDを表示
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--link&lt;/code&gt;は、コンテナ内におけるプライベートな名前解決のために、他のコンテナの&lt;code&gt;name&lt;/code&gt;に対してエイリアスを付けるものだったが、
これとは別に同一ネットワークの他のコンテナからの名前解決のために使われる、ネットワーク範囲のエイリアスを&lt;code&gt;--net-alias&lt;/code&gt;で付けることができる。
このエイリアスは同一ネットワークの複数のコンテナで同じものに設定でき、有効ないずれかのコンテナに名前解決される。
つまり、コンテナが停止するかネットワークから切断されると、同じネットワーク範囲のエイリアスを持った別のコンテナに名前解決されることになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --net=isolated_nw -itd --name=container3 --net-alias app busybox
$ docker run --net=isolated_nw -itd --name=container4 --net-alias app busybox
$ docker network connect --alias app isolated_nw container5 # connectで指定するとき
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow チュートリアル2(Deep MNIST for Experts)</title>
          <link>https://www.sambaiz.net/article/6/</link>
          <pubDate>Tue, 12 Jul 2016 21:16:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/6/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/3&#34;&gt;前回&lt;/a&gt;に引き続き、まとめながら進めていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html&#34;&gt;Deep MNIST for Experts&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;start-tensorflow-interactivesession&#34;&gt;Start TensorFlow InteractiveSession&lt;/h3&gt;

&lt;p&gt;今回は、前回のようにグラフを作成してからSessionを開始する代わりに
&lt;code&gt;InteractiveSession&lt;/code&gt;を使う。
グラフを作成し実行するのをインタラクティブに行うことができ、IPythonのような環境で便利だ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
sess = tf.InteractiveSession()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;build-a-multilayer-convolutional-network&#34;&gt;Build a Multilayer Convolutional Network&lt;/h3&gt;

&lt;p&gt;前回のシンプルなモデルではあまり良い結果が出なかった。
そこで、今回はもう少し良いモデルの畳み込みニューラルネットワークを作成する。&lt;/p&gt;

&lt;h3 id=&#34;weight-initialization&#34;&gt;Weight Initialization&lt;/h3&gt;

&lt;p&gt;勾配が0になるのを避けるために重みの初期化時にノイズを付ける。
&lt;code&gt;tf.truncated_normal&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/constant_op.html#truncated_normal&#34;&gt;正規分布で、μ±2σ範囲内のランダムな値を返す&lt;/a&gt;。
以下の例だと、&lt;code&gt;mean&lt;/code&gt;のデフォルトが0.0なので、正規分布 &lt;code&gt;N(0, 0.01)&lt;/code&gt;の、&lt;code&gt;-0.2&amp;lt;=x&amp;lt;=0.2&lt;/code&gt;な値がランダムに返ることになる。&lt;/p&gt;

&lt;p&gt;また、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0#ReLU.EF.BC.88.E3.83.A9.E3.83.B3.E3.83.97.E9.96.A2.E6.95.B0.EF.BC.89&#34;&gt;ReLU(Rectified Linear Unit, 正規化線形関数)&lt;/a&gt;ニューロンを使うので、&amp;rdquo;死んだニューロン&amp;rdquo;を避けるために、バイアスは小さな正の値で初期化する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/133/&#34;&gt;ニューラルネットワークと活性化関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;convolution-and-pooling&#34;&gt;Convolution and Pooling&lt;/h3&gt;

&lt;p&gt;TensorFlowに畳み込みとプーリングの関数が用意されている。&lt;/p&gt;

&lt;p&gt;畳み込みというのは、画像に対してフィルターを少しずつ動かしながら掛けていく処理のこと。&lt;a href=&#34;http://www.clg.niigata-u.ac.jp/~medimg/practice_medical_imaging/imgproc_scion/4filter/index.htm&#34;&gt;このページ&lt;/a&gt;が分かりやすい。
例えば、&lt;a href=&#34;https://en.wikipedia.org/wiki/Sobel_operator&#34;&gt;ソーベルフィルタ&lt;/a&gt;で輪郭になっているところを抽出するように、
フィルターの値によって、その区域における、ある特徴を際立たせたりすることができる。
今回はこのフィルターが重みとなり、際立たせたいのはその数字を識別するための特徴ということになる。
前回は画像を一次元の配列として扱い重みを学習していたので、縦の情報が失われていたが、この方法ではそれがない。&lt;/p&gt;

&lt;p&gt;プーリングというのは画像から区域ごとにサンプリングする処理のこと。最大プーリングや、平均プーリングなどの手法がある。
畳み込みのように順番に区域を見ていって、最大プーリングならそのうちの最大のものを採用し、他のものは無視する。
サイズが小さくなるだけではなく、ちょっとした位置のずれを吸収することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;)

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding=&#39;SAME&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.nn.conv2d&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#conv2d&#34;&gt;畳み込みを行う。&lt;/a&gt;
主な入力は&lt;code&gt;[画像の数, 縦サイズ, 横サイズ, チャンネル数(色とか)]&lt;/code&gt;の画像と、
&lt;code&gt;[縦サイズ, 横サイズ, 入力チャンネル数, 出力チャンネル数]&lt;/code&gt;のフィルター。
&lt;code&gt;strides&lt;/code&gt;は一度にどれくらいフィルターを動かしていくかで、&lt;code&gt;strides[1]&lt;/code&gt;が縦、&lt;code&gt;strides[2]&lt;/code&gt;が横に動かす量。
&lt;code&gt;strides[0]&lt;/code&gt;と&lt;code&gt;strides[3]&lt;/code&gt;は1でなくてはならない。
&lt;code&gt;padding&lt;/code&gt;は&amp;rdquo;SAME&amp;rdquo;か&amp;rdquo;VALID&amp;rdquo;から選択できるパディングについての設定だ。詳細は
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#convolution&#34;&gt;ここ&lt;/a&gt;
に書いてある。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.nn.max_pool&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#max_pool&#34;&gt;最大プーリングを行う。&lt;/a&gt;
&lt;code&gt;ksize&lt;/code&gt;は入力のそれぞれの次元に対応した見ていく区域のサイズ。&lt;code&gt;[1, 2, 2, 1]&lt;/code&gt;ならそれぞれの画像を&lt;code&gt;2*2&lt;/code&gt;ずつ見ていくことになる。&lt;/p&gt;

&lt;h3 id=&#34;first-convolutional-layer&#34;&gt;First Convolutional Layer&lt;/h3&gt;

&lt;p&gt;最初のレイヤーは、畳み込みと最大プーリングで構成される。
畳み込みはそれぞれ&lt;code&gt;5*5&lt;/code&gt;の32チャンネル出力のフィルターでされる。
つまり、重みであるフィルターは&lt;code&gt;[5, 5, 1, 32]&lt;/code&gt;のtensorということになる。
それぞれのチャンネルに対してのバイアスがb_conv1。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;画像に対して、畳み込みを適用するするために&lt;code&gt;tf.reshape&lt;/code&gt;で
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/array_ops.html#reshape&#34;&gt;変形する&lt;/a&gt;
必要がある。-1というのは特別な値で、他の次元との積が合計が元のものと変わらないように決定される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = tf.placeholder(tf.float32, [None, 784])
x_image = tf.reshape(x, [-1,28,28,1])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで畳み込めるようになったので画像と重みを畳み込み、バイアスを足したものにReLUを適用した後、最大プーリングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;second-convolutional-layer&#34;&gt;Second Convolutional Layer&lt;/h3&gt;

&lt;p&gt;deepネットワークにするために最初のレイヤーのようなものをいくつか重ねる。
2番目のレイヤーでは64チャンネル出力のフィルターで畳み込みを行いプーリングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;densely-connected-layer&#34;&gt;Densely Connected Layer&lt;/h3&gt;

&lt;p&gt;2つのレイヤーを経て元々&lt;code&gt;28*28&lt;/code&gt;だった画像は&lt;code&gt;7*7&lt;/code&gt;にまで削減された。
2つめのレイヤーの出力は64チャンネルだったので、&lt;code&gt;7*7*64&lt;/code&gt;次元のデータになっている。
このレイヤーでは、これらにそれぞれ1024のニューロンを結びつける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dropout&#34;&gt;Dropout&lt;/h3&gt;

&lt;p&gt;過学習を防ぐために訓練データごとにニューロンを何割か無視する
&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0#.E3.83.89.E3.83.AD.E3.83.83.E3.83.97.E3.82.A2.E3.82.A6.E3.83.88&#34;&gt;ドロップアウト&lt;/a&gt;
を行う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;readout-layer&#34;&gt;Readout Layer&lt;/h3&gt;

&lt;p&gt;最後にsoftmaxでそれぞれの数字である確率を求める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;train-and-evaluate-the-model&#34;&gt;Train and Evaluate the Model&lt;/h3&gt;

&lt;p&gt;今回は前回使った&lt;code&gt;GradientDescentOptimizer&lt;/code&gt;よりも性能が高い&lt;code&gt;AdamOptimizer&lt;/code&gt;というのが使われている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
sess.run(tf.initialize_all_variables())
for i in range(20000):
  batch = mnist.train.next_batch(50)
  if i%100 == 0:
    train_accuracy = accuracy.eval(feed_dict={
        x:batch[0], y_: batch[1], keep_prob: 1.0})
    print(&amp;quot;step %d, training accuracy %g&amp;quot;%(i, train_accuracy))
  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})

print(&amp;quot;test accuracy %g&amp;quot;%accuracy.eval(feed_dict={
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行するとこんな出力が得られた。
かなり時間がかかったのでここで打ち切ったが、およそ99.2%の正解率になるらしい。
前回が92%だったのに比べてもすごく良い値に見える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;step 0, training accuracy 0.12
step 100, training accuracy 0.8
step 200, training accuracy 0.9
step 300, training accuracy 0.9
step 400, training accuracy 0.98
step 500, training accuracy 0.88
step 600, training accuracy 0.98
step 700, training accuracy 0.98
step 800, training accuracy 0.9
step 900, training accuracy 1
step 1000, training accuracy 0.98
step 1100, training accuracy 0.98
step 1200, training accuracy 1
step 1300, training accuracy 0.98
step 1400, training accuracy 0.94
step 1500, training accuracy 0.98
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>webpack環境でredux&amp;react-routerのページをサーバーサイドレンダリングする</title>
          <link>https://www.sambaiz.net/article/5/</link>
          <pubDate>Sun, 10 Jul 2016 03:08:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/5/</guid>
          <description>&lt;p&gt;このページをGoogleのSearch Consoleからクローラーがちゃんと見ているか確認してみたら、
なぜか真っ白のページが表示されていた・・・。とりあえずサーバーサイドレンダリングしてみることにした。
コードは&lt;a href=&#34;https://github.com/sambaiz/sambaiz.net/tree/v0.23&#34;&gt;github&lt;/a&gt;に上げてある。&lt;/p&gt;

&lt;p&gt;サーバーサイドとはいえ、css-loaderでcss moduleを使っているのでwebpackを使う必要があった。
まず、そのままのwebpackの設定で作ったものをserver.jsから呼ぶとエラーが出た。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;***/sambaiz-net/web/public/bundle.js:20933
	module.exports = self.fetch.bind(self);
ReferenceError: self is not defined
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこで、targetをnodeにしたサーバーサイド用にwebpackの設定を作成し、実行してみたところ&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.exports = {
	entry: &#39;./js/server.js&#39;,
	target: &#39;node&#39;,
	output: {
		path: path.join(__dirname, &#39;dist&#39;),
		filename: &#39;server.js&#39;,
		publicPath: &#39;/&#39;
	},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今度はこんなエラーが出たので&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERROR in ./~/iconv-lite/encodings/tables/gb18030-ranges.json
Module parse failed: ***/sambaiz-net/web/node_modules/iconv-lite/encodings/tables/gb18030-ranges.json Unexpected token (1:9)
You may need an appropriate loader to handle this file type.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;loadersに下の設定を追加した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{ test: /\.json$/, loader: &amp;quot;json-loader&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webpackには成功したが、serverを起動すると今度は以下のようなエラーが出た。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return /msie [6-9]\b/.test(window.navigator.userAgent.toLowerCase());
ReferenceError: window is not defined
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;style-loaderのコードだったので、
まず、フロント側のwebpackで
&lt;a href=&#34;https://github.com/webpack/extract-text-webpack-plugin&#34;&gt;extract-text-webpack-plugin&lt;/a&gt;を使ってcssを別に出力することにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;);
...
{
  test: /\.css$/,
  loader:  ExtractTextPlugin.extract(&#39;style&#39;, &#39;css?modules&#39;, &#39;postcss&#39;),
  include: __dirname
},
...
plugins: [
    new ExtractTextPlugin(&amp;quot;styles.css&amp;quot;)
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そして、サーバー側のwebpackでは&lt;a href=&#34;https://github.com/kriasoft/isomorphic-style-loader&#34;&gt;isomorphic-style-loader&lt;/a&gt;でなんとか動かして、
フロント側で出力したcssと対応するようにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;loaders: [&#39;isomorphic-style&#39;, &#39;css?modules&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでようやくwebpackまわりの問題は解決できたので、react-routerの方のコードを書いていく。&lt;/p&gt;

&lt;p&gt;reduxに関しては&lt;a href=&#34;http://redux.js.org/docs/recipes/ServerRendering.html&#34;&gt;ドキュメント&lt;/a&gt;通りに
描画した後のstoreをこんな感じでフロントに渡す。
そのほかに、同じ処理をサーバーとフロントで二度行わないようにするための値を追加する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;window.__INITIAL_STATE__ = ${JSON.stringify(state)}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;react-routerも以下のようにmatchとRouterContextを組み合わせるだけだ。
ただし、APIリクエスト等の非同期処理が含まれているので、レンダリングが完了したかどうか判断しなくてはならない。
そのため、storeの状態をsubscribeしてレンダリングの終了判定を都度チェックしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function render(req, res, isFinishLoading, title, description, fullUrl) {

  match({ routes, location: req.url }, (error, redirectLocation, renderProps) =&amp;gt; {

    let store = createStore();

    if (error) {
      res.status(500).send(error.message)
    } else if (redirectLocation) {
      res.redirect(302, redirectLocation.pathname + redirectLocation.search)
    } else if (renderProps) {

      const _render = () =&amp;gt;
        renderToString(&amp;lt;Provider store={store}&amp;gt;
          &amp;lt;RouterContext {...renderProps} /&amp;gt;
        &amp;lt;/Provider&amp;gt;)

      let unscribe = store.subscribe(() =&amp;gt; {
        if(isFinishLoading(store.getState()) === true){
          res.status(200).send(
            page(_render(), store.getState(), title, description, fullUrl)
          )
          unscribe();
        }
      })

      _render();

    } else {
      res.status(404).send(&#39;Not found&#39;)
    }
  })
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLのUNIX_TIMESTAMPにある程度未来の日付を渡すと0になる</title>
          <link>https://www.sambaiz.net/article/4/</link>
          <pubDate>Mon, 04 Jul 2016 19:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/4/</guid>
          <description>&lt;p&gt;以下、MySQL5.6で遭遇した。&lt;/p&gt;

&lt;p&gt;MySQLの&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/date-and-time-functions.html#function_unix-timestamp&#34;&gt;UNIX_TIMESTAMP&lt;/a&gt;は
DATETIME文字列などを引数にとり、UNIXタイムスタンプ(1970-01-01 00:00:00 UTCを起点とした経過秒数)を返す関数だ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SET SESSION time_zone = &#39;UTC&#39;;
mysql&amp;gt; select UNIX_TIMESTAMP(&#39;1970-01-01 00:00:00&#39;);
+---------------------------------------+
| UNIX_TIMESTAMP(&#39;1970-01-01 00:00:00&#39;) |
+---------------------------------------+
|                                     0 |
+---------------------------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただし、2038年1月19日3時14分7秒(UTC)以降を渡すと0になってしまう。
これはドキュメントにも書いてある通り範囲外だから。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select UNIX_TIMESTAMP(&#39;2038-01-19-03-14-07&#39;);
+---------------------------------------+
| UNIX_TIMESTAMP(&#39;2038-01-19-03-14-07&#39;) |
+---------------------------------------+
|                            2147483647 |
+---------------------------------------+
1 row in set (0.04 sec)

mysql&amp;gt; select UNIX_TIMESTAMP(&#39;2038-01-19-03-14-08&#39;);
+---------------------------------------+
| UNIX_TIMESTAMP(&#39;2038-01-19-03-14-08&#39;) |
+---------------------------------------+
|                                     0 |
+---------------------------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では、この境目は何かというと、32ビットで表せる符号付数値の最大値だ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; 2 ** 31
=&amp;gt; 2147483648
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これはMySQLに限らず、&lt;a href=&#34;https://ja.wikipedia.org/wiki/2038%E5%B9%B4%E5%95%8F%E9%A1%8C&#34;&gt;2038年問題&lt;/a&gt;と呼ばれているもので、
DATETIME型は&amp;rsquo;9999-12-31&amp;rsquo;までサポートしているのでこれ以降も表すことはできるが、&lt;code&gt;UNIX_TIMESTAMP&lt;/code&gt;しても正しい値は得られなくなる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow チュートリアルまで</title>
          <link>https://www.sambaiz.net/article/3/</link>
          <pubDate>Sun, 03 Jul 2016 23:37:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/3/</guid>
          <description>

&lt;p&gt;Googleが公開した人工知能ライブラリTensorFlowを使ってみる。
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html&#34;&gt;セットアップ&lt;/a&gt;方法はいくつか提供されているが、Dockerで動かすことにした。
Jupyter Notebookが立ち上がるのですぐに試せて良い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:8888/tree&#34;&gt;http://localhost:8888/tree&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;公式のチュートリアルをまとめながら進めてみる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html&#34;&gt;MNIST For ML Beginners&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-mnist-data&#34;&gt;The MNIST Data&lt;/h3&gt;

&lt;p&gt;MNISTというのは0~9の書き数字の画像のデータセットのことで、これらを正しく分類するのが目的。&lt;/p&gt;

&lt;p&gt;それぞれの画像は一律28*28=784ピクセルで、それぞれのピクセルは0と1の間の数値(強さ)で表されている。
今回はこれの縦横を取っ払って784次元のベクトルとして扱っている。&lt;/p&gt;

&lt;p&gt;したがって、学習用の画像データは[55000, 784]のtensor(n次元の配列)で表される。
55000というのが画像の数で、784というのがそれぞれの画像の次元を意味している。&lt;/p&gt;

&lt;p&gt;それぞれの画像に対応した数字のラベルは[55000, 10]で表される。
10というのは、0~9それぞれに対応した次元のうち、一つだけ1で、それ以外が0という風に使われる。これをone-hot vectorという。&lt;/p&gt;

&lt;h3 id=&#34;softmax-regressions&#34;&gt;Softmax Regressions&lt;/h3&gt;

&lt;p&gt;Softmaxはいくつかの異なるもの(今回でいうと数字)に確率を割り当てる。&lt;/p&gt;

&lt;p&gt;画像が特定のクラス(0~9)に属するかどうか計算するために、ピクセルの強さに重みを付けた合計を計算する。
もし、そのピクセルがそのクラスに属さない根拠になるなら負の重みがかかり、属する根拠になるなら、正の重みがかかるようにする。
また合計にさらに入力と無関係なクラスごとに異なるバイアスを足す。&lt;/p&gt;

&lt;p&gt;全てのクラスで計算した値をsoftmax関数に入れ、それぞれ確率に変換する。この確率の和は1になるようになっている。&lt;/p&gt;

&lt;h3 id=&#34;implementing-the-regression&#34;&gt;Implementing the Regression&lt;/h3&gt;

&lt;p&gt;Pythonでは行列の積のような重い処理をするとき、NumPyのようなライブラリを使ってPythonの外で行うが、
外からPythonに戻るときにオーバーヘッドが発生してしまう。
TensorFlowでも重い処理を外で行うが、オーバーヘッドを避けるために、
単体の重い処理をPythonから独立して実行するのではなく、Pythonの外側で実行される関連した処理のグラフを記述させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
x = tf.placeholder(tf.float32, [None, 784])
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
y = tf.nn.softmax(tf.matmul(x, W) + b)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.placeholder&lt;/code&gt;は実行時に与えられる値で、今回が画像データ。
W(重み)とb(バイアス)は学習する変数。
&lt;code&gt;tf.matmul(x, W) + b&lt;/code&gt;の部分が重みを付けた合計にバイアスを足したものに対応している。
matmulはmatrix multiple、つまり行列の積。&lt;/p&gt;

&lt;h3 id=&#34;training&#34;&gt;Training&lt;/h3&gt;

&lt;p&gt;機械学習では一般的に、悪いモデルとは何か定義し、それを最小化しようとする。
一般的で、良い損失関数としてクロスエントロピーがある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/134/&#34;&gt;自己情報量、エントロピー、KL情報量、クロスエントロピー - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;y_が正しい答えで、これとy(softmaxで求めた各数字の確率)の対数の積をを次元ごとにとり、それらの和を求めて-1を掛ける。
&lt;code&gt;reduction_indices=[1]&lt;/code&gt;というのは[784, 10]の10の方を指しているようだ。
全ての学習データにおいてこれを求め、さらにそれらの平均をとったものがクロスエントロピーになる。
この値はy_とyが離れていれば大きくなるので、なるべく小さくすることが良いモデルにするということになる。&lt;/p&gt;

&lt;p&gt;ではどうやってこの値を小さくするか、TensorFlowは関係する計算のグラフを持っているので、自動的に&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3&#34;&gt;バックプロパゲーション&lt;/a&gt;を使って、どの変数がクロスエントロピーに影響しているか効率的に特定することができる。&lt;/p&gt;

&lt;p&gt;以下のようにGradientDescent(勾配降下)Optimizerで0.5のleartning rateでクロスエントロピーが小さくなるように、変数を少しずつ変えていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/191/&#34;&gt;ロジスティック回帰の尤度と交差エントロピー誤差と勾配降下法 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを使って学習していく。学習とテストに使うデータは&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/examples/tutorials/mnist/input_data.py&#34;&gt;これ&lt;/a&gt;
と&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行すれば用意できるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.Session()&lt;/code&gt;と&lt;code&gt;tf.run()&lt;/code&gt;はSessionを取得し、モデルを実行するもの。
変数は&lt;code&gt;tf.initialize_all_variables()&lt;/code&gt;で初期化する必要がある。
batch_xsが画像のピクセルデータで、batch_ysが正しい答え。
&lt;code&gt;sess.run()&lt;/code&gt;の&lt;code&gt;feed_dict={x: batch_xs, y_: batch_ys}&lt;/code&gt;はそれぞれ対応するplaceholderのところに与えられる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)
for i in range(1000):
  batch_xs, batch_ys = mnist.train.next_batch(100)
  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このような小さいランダムなデータを使うのはstochastic(確率的) trainingと呼ばれていて、
今回はstochastic gradient descent。
理想的には全てのデータを全ての訓練のステップで使いたいが、コストがかかるので代わりに毎回異なるサブセットを使うことで
同じ効果を得ている。&lt;/p&gt;

&lt;h3 id=&#34;evaluating-our-model&#34;&gt;Evaluating Our Model&lt;/h3&gt;

&lt;p&gt;モデルがどのくらい良いかを測る。&lt;/p&gt;

&lt;p&gt;以下のcorrect_predictionでは&lt;code&gt;tf.argmax&lt;/code&gt;で最も数値の大きい、つまり確率の高いラベルを取得し、これが正解のものと一致するかというのを
画像データごとに比較している。
結果、[True, False, True, True]であるなら、これを[1, 0, 1, 1]にキャストし、平均を取ったものがaccuracy、正解率となる。
そしてこの値をテスト用のデータで出力している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
&amp;gt; 0.9206
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この簡単なモデルだと正解率は92%になったが、実はこれは非常に悪いとのこと。
モデルにもう少し変更を加えるだけで97%になったりするらしい。&lt;/p&gt;

&lt;p&gt;続き: &lt;a href=&#34;https://www.sambaiz.net/article/6&#34;&gt;TensorFlow チュートリアル2(Deep MNIST for Experts)&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Reactで作ったページにTwitterCardsとOGPのメタデータを埋める</title>
          <link>https://www.sambaiz.net/article/2/</link>
          <pubDate>Sat, 02 Jul 2016 13:23:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/2/</guid>
          <description>&lt;p&gt;せっかくページを作ったので、SNSにシェアするときに見栄えをよくしようと思った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/2_ogp.jpg&#34; alt=&#34;Facebookに表示される例&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Twitter CardsやOGPのmetaタグを埋めるとTwitterやFacebookにURLを貼ったときに上のように表示されるようになる(上はFacebookの例)。そこで、&lt;a href=&#34;https://github.com/nfl/react-helmet&#34;&gt;react-helmet&lt;/a&gt;でこんな感じで動的に埋め込んだんだけど読んでくれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Helmet title={&#39;sambaiz.net&#39;}
        meta={[
            {&amp;quot;name&amp;quot;: &amp;quot;twitter:card&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;summary&amp;quot;},
            {&amp;quot;name&amp;quot;: &amp;quot;twitter:site&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;@sambaiz&amp;quot;},
            {&amp;quot;name&amp;quot;: &amp;quot;twitter:title&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;sambaiz.net&amp;quot;},
            {&amp;quot;name&amp;quot;: &amp;quot;twitter:description&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;僕のホームページ&amp;quot;},
            {&amp;quot;property&amp;quot;: &amp;quot;og:title&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;sambaiz.net&amp;quot;},
            {&amp;quot;property&amp;quot;: &amp;quot;og:type&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;blog&amp;quot;},
            {&amp;quot;property&amp;quot;: &amp;quot;og:image&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;http://d2wgaf7ubdj1mv.cloudfront.net/my.jpg&amp;quot;},
            {&amp;quot;property&amp;quot;: &amp;quot;og:url&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;https://www.sambaiz.net&amp;quot;}
        ]}
/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Googleのクローラーのように&lt;a href=&#34;https://webmasters.googleblog.com/2014/05/understanding-web-pages-better.html&#34;&gt;Javascriptを解釈してくれる&lt;/a&gt;
と思ってた。残念。&lt;/p&gt;

&lt;p&gt;しょうがないのでここだけサーバーサイドレンダリングすることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;use strict&#39;

import express from &#39;express&#39;
import path from &#39;path&#39;
import compression from &#39;compression&#39;

require(&#39;isomorphic-fetch&#39;);

var app = express()

app.use(compression())

// serve our static stuff
app.use(express.static(path.join(__dirname, &#39;..&#39;, &#39;..&#39;, &#39;public&#39;)))

app.get(&#39;/&#39;, function (req, res) {
  res.status(200).send(page(&#39;https://www.sambaiz.net&#39;, &#39;sambaiz.net&#39;, &#39;僕のホームページ&#39;));
})

app.get(&#39;/article/:articleId&#39;, function (req, res) {
  fetch(`https://zx9h12n6jb.execute-api.ap-northeast-1.amazonaws.com/api/articles/${req.params.articleId}`).then(function(response){
    if (response.status == 404) {
      res.status(404).send(&#39;not found&#39;)
    }else if(response.status != 200){
      res.status(response.status).send(`API error ${response.status}`)
    }else{
      return response.json();
    }
  }).then(function(json) {
    if(json){
      res.status(200).send(page(`https://www.sambaiz.net${req.url}`, json.title, &#39;書いた&#39;));
    }
  })
})

function page(fullUrl, title, description)  {
  return `
    &amp;lt;!doctype html&amp;gt;
    &amp;lt;html&amp;gt;
      &amp;lt;head&amp;gt;
        &amp;lt;title&amp;gt;${title}&amp;lt;/title&amp;gt;
        &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;
        &amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;twitter:card&amp;quot; content=&amp;quot;summary&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;twitter:site&amp;quot; content=&amp;quot;@sambaiz&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;twitter:title&amp;quot; content=&amp;quot;${title}&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;twitter:description&amp;quot; content=&amp;quot;${description}&amp;quot;&amp;gt;
        &amp;lt;meta property=&amp;quot;og:title&amp;quot; content=&amp;quot;${title}&amp;quot;&amp;gt;
        &amp;lt;meta property=&amp;quot;og:type&amp;quot; content=&amp;quot;blog&amp;quot;&amp;gt;
        &amp;lt;meta property=&amp;quot;og:image&amp;quot; content=&amp;quot;http://d2wgaf7ubdj1mv.cloudfront.net/my.jpg&amp;quot;&amp;gt;
        &amp;lt;meta property=&amp;quot;og:url&amp;quot; content=&amp;quot;${fullUrl}&amp;quot;&amp;gt;
      &amp;lt;/head&amp;gt;
      &amp;lt;body&amp;gt;
        &amp;lt;div id=&amp;quot;app&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
        &amp;lt;script src=&amp;quot;/bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
      &amp;lt;/body&amp;gt;
    &amp;lt;/html&amp;gt;
    `
}

var PORT = process.env.PORT || 8080

app.listen(PORT, function() {
  console.log(&#39;Production Express server running at localhost:&#39; + PORT)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと読まれているかは以下のページで確認できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cards-dev.twitter.com/validator&#34;&gt;Card validator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developers.facebook.com/tools/debug/&#34;&gt;Sharing Debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;が、&lt;a href=&#34;https://www.sambaiz.net/article/5&#34;&gt;結局全部サーバーサイドレンダリングすることになった。&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ブログを作った</title>
          <link>https://www.sambaiz.net/article/1/</link>
          <pubDate>Wed, 29 Jun 2016 23:43:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/1/</guid>
          <description>&lt;p&gt;最近表に出るものを作っていなかったので、このサイトを作ってみた。&lt;/p&gt;

&lt;p&gt;表はReact/Reduxで、裏側はAWSのLambdaでサーバーレスに作ってある。
コードは&lt;a href=&#34;https://github.com/sambaiz/sambaiz.net&#34;&gt;github&lt;/a&gt;に公開してみた。&lt;/p&gt;

&lt;p&gt;これを期になるべくアウトプットしていこうと思う。大抵三日坊主なのだけれど。&lt;/p&gt;

&lt;p&gt;&amp;ndash;&lt;/p&gt;

&lt;p&gt;追記: 今はHugoに置き換わっている&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/22&#34;&gt;静的ウェブサイトエンジンHugoに乗り換えた&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
