<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sambaiz-net</title>
    <link>https://www.sambaiz.net/</link>
    <description>Recent content on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sat, 23 Apr 2022 18:09:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Athenaのデータソースコネクタとユーザー定義関数(UDF)を実装する</title>
      <link>https://www.sambaiz.net/article/402/</link>
      <pubDate>Sat, 23 Apr 2022 18:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/402/</guid>
      <description>AthenaにはLambdaをコネクタとしてS3以外のデータソースにアクセスできるFederate Queryという機能があって、公式のリポジトリでBigQueryやSnowFlakeなど様々なデータソースのコネクタが提供されているが自作することもできる。 今回はExample Connectorを参考にしながら最低限のコネクタを実装しその動作を確認する。全体のコードはGitHubにある。
AthenaのFederated QueryでTPC-DS Connectorを用いてデータを生成する - sambaiz-net
CompositeHandler テーブルのスキーマなどを返すMetadataHandlerとデータを返すExampleRecordHandlerをまとめるためのHandlerで、 必要ならUDFを実行するUserDefinedFuncHandlerもこれに含めることができる。
package net.sambaiz.athena_connector_udf_example; import com.amazonaws.athena.connector.lambda.handlers.CompositeHandler; public class App extends CompositeHandler { public App() { super(new ExampleMetadataHandler(), new ExampleRecordHandler(), new ExampleUserDefinedFuncHandler()); } } MetadataHandler テーブルのスキーマやパーティションといったデータソースのメタデータを返すHandler。
describe `lambda:athena-connector-udf-example`.sample_db.sample_table /* foo struct&amp;lt;bar:int&amp;gt; # Partition Information # col_name data_type comment year int */ データベースやテーブルの一覧を返すdoListSchemaNames()やdoListTables()、
@Override public ListSchemasResponse doListSchemaNames(BlockAllocator allocator, ListSchemasRequest request) { logger.info(&amp;#34;MetadataHandler.doListSchemaNames() with requestType: &amp;#34; + request.getRequestType()); Set&amp;lt;String&amp;gt; schemas = new HashSet&amp;lt;&amp;gt;(); schemas.</description>
    </item>
    
    <item>
      <title>CloudWatch Logsを介さずにLambdaのテレメトリを行うnewrelic-lambda-extensionとその仕組み</title>
      <link>https://www.sambaiz.net/article/401/</link>
      <pubDate>Fri, 08 Apr 2022 12:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/401/</guid>
      <description>New RelicにLambdaのログを転送するには、CloudWatch Logsに出力したものをサブスクライブして送るLambda function aws-log-ingestionを用いる従来の方法のほかに、Lambda layer newrelic-lambda-extensionを用いる方法があって、トレースログなどをCloudWatc Logsに出力することなく送れるのでコストを最小限に抑えられる。
インストール newrelic-lambda integrations install するとLayerが参照するAPI KeyのSecretのStackなどがデプロイされる。
$ pip3 install newrelic-lambda-cli $ newrelic-lambda integrations install \  --nr-account-id &amp;lt;account id&amp;gt; \  --nr-api-key &amp;lt;api key&amp;gt; \  --linked-account-name &amp;lt;linked account name&amp;gt; \  --enable-license-key-secret \  --aws-profile &amp;lt;aws_profile_name&amp;gt; --aws-region &amp;lt;aws_region&amp;gt; Validating New Relic credentials Retrieving integration license key Creating the AWS role for the New Relic AWS Lambda Integration Waiting for stack creation to complete.</description>
    </item>
    
    <item>
      <title>New RelicのGraphQL API、NerdGraphでリソースを取得する</title>
      <link>https://www.sambaiz.net/article/400/</link>
      <pubDate>Fri, 01 Apr 2022 22:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/400/</guid>
      <description>New RelicのNerdGraphはGraphQLのAPIで、リソースを取得したり更新することができる。
curl -X POST https://api.newrelic.com/graphql \ -H &amp;#39;Content-Type: application/json&amp;#39; \ -H &amp;#39;API-Key: *****&amp;#39; \ -d &amp;#39;{ &amp;#34;query&amp;#34;: &amp;#34;{ requestContext { userId apiKey } actor { user { name } } }&amp;#34; }&amp;#39; | jq { &amp;#34;data&amp;#34;: { &amp;#34;actor&amp;#34;: { &amp;#34;user&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;Taiki Sakamoto&amp;#34; } }, &amp;#34;requestContext&amp;#34;: { &amp;#34;apiKey&amp;#34;: &amp;#34;*****&amp;#34;, &amp;#34;userId&amp;#34;: &amp;#34;*****&amp;#34; } } } GraphiQL explorerで項目を選ぶとクエリが生成される。
 クライアントライブラリから実行することもできる。structはtutoneというツールで GraphQLのスキーマとtemplateから自動生成されている。
package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;os&amp;#34; &amp;#34;github.com/newrelic/newrelic-client-go/newrelic&amp;#34; &amp;#34;github.</description>
    </item>
    
    <item>
      <title>New Relicでインフラやアプリケーションをモニタリングする</title>
      <link>https://www.sambaiz.net/article/399/</link>
      <pubDate>Wed, 30 Mar 2022 19:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/399/</guid>
      <description>New RelicはインフラやアプリケーションをモニタリングするSaaSで、同種のサービスとしてはDatadogがある。 2020年に製品や課金体系が変わり、転送量とユーザー数に対して課金されるようになったようだ。 ホストや機能に対して課金されるDatadogと比べると、少人数で多くのインスタンスを管理している場合に有利ということになる。また、Datadogの課金体系はやや複雑で頻繁に台数が増減する環境では請求がどの程度になるか読みづらいところがあるが、こちらは分かりやすい。新しい機能を使っても単価が上がることもないのでいろいろと試しやすいのも良いと思う。
一方、大人数で管理していたり、捌くリクエストが膨大な場合APMの転送量がかさむことでDatadogより高くなるケースがある。 多くの場合はユーザー課金の割合が大きくなるので、Full platform userの数を減らして半額のCore userや無料のBasic userにすればコストが抑えられるが、 DashboardやAlertについては全てのユーザーが使える一方APMの画面が見られるのはFull platform userのみだったりするのが悩ましい。 転送量についてはDrop dataすることで減らすことができるが現状画面からは設定できずNerdGraphを用いる必要がある。次はTerraformで設定を行う例。
New RelicのGraphQL API、NerdGraphでリソースを取得する - sambaiz-net
resource &amp;#34;newrelic_nrql_drop_rule&amp;#34; &amp;#34;heavy_path&amp;#34; { account_id = ***** description = &amp;#34;Drop transactions data&amp;#34; action = &amp;#34;drop_data&amp;#34; nrql = &amp;#34;SELECT * FROM Transaction WHERE `request.uri` = &amp;#39;/heavy_path&amp;#39;&amp;#34; } また、トラブルシューティングが比較的難しい印象があり、なぜかメトリクスが送られないといったことがあったり、古いドキュメントを参照してしまったりしたが、ライブラリやドキュメントはOSSになっており、いざとなれば実装を読んだり修正のPRを出すことができるので大きな問題は感じていない。
AWS連携 New RelicのアカウントからAssumeRoleするReadOnlyAccessとbudgets:ViewBudgetを付与したRoleを作る。
AWSのAssumeRole - sambaiz-net
{ &amp;#34;Statement&amp;#34;: [ { &amp;#34;Action&amp;#34;: [ &amp;#34;budgets:ViewBudget&amp;#34; ], &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; } ], &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34; } メトリクスの取得は従来の定期的にAPIを呼んでポーリングする方法と、FirehoseにストリーミングするCloudWatch Metric Steamsを用いる方法がサポートされていて、後者が推奨されている。用意されているCloudFormationのテンプレートにLicense Keyを渡してスタックを作成すると次のリソースが作成され、New Relicの画面上に各種リソースのメトリクスが表示されるようになる。</description>
    </item>
    
    <item>
      <title>VSCode NeovimでVSCodeをVimのように操作する</title>
      <link>https://www.sambaiz.net/article/398/</link>
      <pubDate>Tue, 15 Mar 2022 00:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/398/</guid>
      <description>VSCode NeovimはVSCodeをVimのように操作できるようにするExtension。 同種のExtensionとしてVimをエミュレートするVSCodeVimというのもあるが、 こちらはエミュレートするのではなく実際のNeovimをバックエンドとすることで ほぼ完全な互換性と軽快な動作を実現しているらしい。
Neovimをインストールする。
$ brew install neovim $ which nvim /usr/local/bin/nvim $ nvim --version NVIM v0.6.1 Build type: Release LuaJIT 2.1.0-beta3 日本語入力のままコマンドを打ってしまうと面倒なので、挿入モードから離れたときに入力モードを切り替えるようにする。
$ brew tap daipeihust/tap &amp;amp;&amp;amp; brew install im-select $ vi ~/.config/nvim/init.vim autocmd InsertLeave * :silent !/usr/local/bin/im-select com.apple.inputmethod.Kotoeri.RomajiTyping.Roman Extensionをインストールして Neovimのパスを設定する。ドキュメントにscrollBeyondLastLineもfalseにした方が良いと書いてあったのでそうしている。
$ vi ~/Library/Application\ Support/Code/User/settings.json { ... &amp;#34;vscode-neovim.neovimExecutablePaths.darwin&amp;#34;: &amp;#34;/usr/local/bin/nvim&amp;#34;, &amp;#34;editor.scrollBeyondLastLine&amp;#34;: false } これで再起動すれば使えるようになる。
よく使うコマンド  :e[dit]: ファイルを開く :vs[plit]: 横方向に分割  Ctrl-w hjkl: エディタを移動    よく使うVSCodeのショートカット Macのデフォルト。</description>
    </item>
    
    <item>
      <title>TPC-DSのクエリを用いたRedshift ServerlessとAthenaの性能比較</title>
      <link>https://www.sambaiz.net/article/397/</link>
      <pubDate>Sun, 20 Feb 2022 01:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/397/</guid>
      <description>Redshift Serverlessと他のサーバーレス集計サービス、Glue Data Catalogのテーブルへのクエリ実行 - sambaiz-net
現在PreviewのRedshift ServerlessとAthenaでデータベースのベンチマークであるTPC-DSのクエリを実行し性能を比較する。
GlueのTPC-DS Connectorで合計1TBのデータを生成しS3に保存した。 IAM Roleなどのリソースを作るCDKのコードはGitHubにある。
GlueのTPC-DS Connectorでデータを生成する - sambaiz-net
まずはjsonとparquetのデータに対して次のクエリを実行してみる。
select /* TPC-DS query96.tpl 0.1 */ count(*) from store_sales ,household_demographics ,time_dim, store where ss_sold_time_sk = time_dim.t_time_sk and ss_hdemo_sk = household_demographics.hd_demo_sk and ss_store_sk = s_store_sk and time_dim.t_hour = 8 and time_dim.t_minute &amp;gt;= 30 and household_demographics.hd_dep_count = 5 and store.s_store_name = &amp;#39;ese&amp;#39; order by count(*) limit 100; 結果は次の通り。
   service format run time (sec) cost (ap-northeast-1)     Athena json 738.</description>
    </item>
    
    <item>
      <title>IntelliJ IDEA/IdeaVimでよく使うショートカット/コマンド</title>
      <link>https://www.sambaiz.net/article/396/</link>
      <pubDate>Wed, 16 Feb 2022 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/396/</guid>
      <description>IntelliJのショートカット 基本Macのデフォルト設定で使っていて、最低限次の3つだけで事済む。
 Command + Shift + F: プロジェクト内の文字列検索 Shift Shift: プロジェクト内のファイルやシンボルの検索 Command + Shift + A: アクションの検索  renameでプレビューを見てOption + Dで適用できる    頻繁に行う操作は覚えておくと便利。
 Command + E: 最近編集したファイル Command + [ / ]: ジャンプ元に戻る/進む Option + F12: ターミナルを開く Alt + F1 → 1: 現在のファイルを選択してる状態でプロジェクトウィンドウを開く  ファイルを開いてShift + Escapeでウィンドウを閉じる   F2 / Shift + F2: 次/前のエラーへ移動  IdeaVimのコマンド 移動  h, j, k, l: カーソル移動 W, B: 次/前の単語に移動 /text → n / N: 検索して次/前に移動 :%s/text/text/g: 置換 ^, $; 行の先頭/末尾に移動 :100: 行移動 Control + ]: 定義箇所や利用箇所にジャンプ  $ vi ~/.</description>
    </item>
    
    <item>
      <title>最小二乗法(OLS)による線形回帰と決定係数</title>
      <link>https://www.sambaiz.net/article/395/</link>
      <pubDate>Fri, 11 Feb 2022 00:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/395/</guid>
      <description>最小二乗法(OLS)による線形回帰 線形回帰は時系列データに見られる前の時間との自己相関がないことを前提に
$$ y = \alpha + \sum_i^n \beta_i x_i $$
のような線形関数で表される回帰方程式によって\(y\)を説明変数\(x\)で説明するモデルを作る。
時系列データのMAモデルとARモデル、その定常性と反転可能性 - sambaiz-net
\(x\)が一つの場合は単回帰分析といい、複数の場合は重回帰分析という。 単回帰分析では母集団\(X, Y\)の関係を次の母回帰方程式で表す。 全ての要素が単一の直線上にあることはほとんどないので誤差項\(\varepsilon_i\)が含まれている。
$$ Y_i = \alpha + \beta_1 X_i + \varepsilon_i $$
 この誤差項\(\varepsilon_i\)の二乗の和\(S\)が最小となるように係数の値を決めるのが最小二乗法(OLS; Ordinary Least Squares)となる。
$$ S = \sum \varepsilon_i^2 = \sum (Y_i - \alpha - \beta_1 X_i)^2 $$
一次の偏微分が0となる次の連立方程式を解いてそのような最小二乗推定量\(\hat{\alpha},\hat{\beta_1}\)を求める。
$$ \begin{align*} \frac{\partial S}{\partial \alpha} &amp;amp;= -2 \sum (Y_i - \alpha - \beta_1 X_i) = 0 \\ \frac{\partial S}{\partial \beta_1} &amp;amp;= -2 \sum (Y_i - \alpha - \beta_1 X_i) X_i = 0 \end{align*} $$</description>
    </item>
    
    <item>
      <title>2種の母集団の比較を行う2標本問題での統計量</title>
      <link>https://www.sambaiz.net/article/394/</link>
      <pubDate>Tue, 25 Jan 2022 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/394/</guid>
      <description>男性の身長と女性の身長といった異なる分布の2種の母集団について、その独立な標本から母集団の比較を行う問題を2標本問題(two-sample problem)という。
平均\(\mu_1\)分散\(\sigma_1^2\)の母集団と平均\(\mu_2\)分散\(\sigma_2^2\)の母集団からそれぞれ\(m,n\)個の標本を取って、その平均が\(\bar{X_1}, \bar{X_2}\)のとき、 \(\bar{X_1}, \bar{X_2}\)は独立なので分散の加法性\(V[X \pm Y] = V[X] + V[Y]\)が成り立ち、中心極限定理より正規分布になるので、\(\bar{X_1} - \bar{X_2}\)の分布は\(N(\mu_1 - \mu_2, \frac{\sigma_1^2}{m} + \frac{\sigma_2^2}{n} )\)となる。
確率分布(二項分布/ポアソン分布/正規分布/t分布/カイ二乗分布) - sambaiz-net
もし母分散が未知だが等しい場合は次のプールした分散を用いる。
$$ s^2 = \frac{\Sigma (X_i - \bar{X})^2 + \Sigma (Y_i - \bar{Y})^2}{m+n-2} = \frac{(m-1)s_1^2 + (n-1)s_2^2}{m+n-2} $$
このとき次の統計量は自由度\(m+n-2\)の\(\chi^2\)分布に従う。
$$ \frac{(m+n-2)s^2}{\sigma^2} = \frac{(m-1)s_1^2 + (n-1)s_2^2}{\sigma^2} $$
したがって、標準化変換した\(Z\)を
$$ Z = \frac{(\bar{X} - \bar{Y}) - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma^2}{m} + \frac{\sigma^2}{n}}} $$
\(\sqrt{\frac{\frac{(m+n-2)s^2}{\sigma^2}}{m+n-2}}\)で割ると自由度\(m+n-2\)のt分布となり、未知の母分散\(\sigma^2\)が消せる。
$$ t = \frac{Z}{\sqrt{\frac{\frac{(m+n-2)s^2}{\sigma^2}}{m+n-2}}} = \frac{(\bar{X} - \bar{Y}) - (\mu_1 - \mu_2)}{\sqrt{\frac{s^2}{m} + \frac{s^2}{n}}} $$</description>
    </item>
    
    <item>
      <title>GlueのTPC-DS Connectorでデータを生成する</title>
      <link>https://www.sambaiz.net/article/393/</link>
      <pubDate>Tue, 18 Jan 2022 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/393/</guid>
      <description>AthenaのTPC-DS Connectorで250GBのデータを生成してS3に出力しようとしたところ最大までLambdaのリソースを上げてもタイムアウトしてしまったのでGlueで行う。
AthenaのFederated QueryでTPC-DS Connectorを用いてデータを生成する - sambaiz-net
GlueのTPC-DS connectorをSubscribeしてActivateする。
 スクリプトはこんな感じで必要なパラメータを外から渡せるようにした。scaleはAthenaのものと同じくGB単位。 アップロード時にカタログにテーブルが追加されるようにしている。
from socket import create_connection import sys from awsglue.transforms import * from awsglue.utils import getResolvedOptions from pyspark.context import SparkContext from awsglue.context import GlueContext from awsglue.job import Job args = getResolvedOptions(sys.argv, [&amp;#34;JOB_NAME&amp;#34;, &amp;#34;BUCKET_NAME&amp;#34;, &amp;#34;DATABASE_NAME&amp;#34;, &amp;#34;SCALE&amp;#34;, &amp;#34;NUM_PARTITIONS&amp;#34;, &amp;#34;FORMAT&amp;#34;, &amp;#34;CONNECTION_NAME&amp;#34;]) sc = SparkContext() glueContext = GlueContext(sc) spark = glueContext.spark_session job = Job(glueContext) job.init(args[&amp;#34;JOB_NAME&amp;#34;], args) bucketName = args[&amp;#34;BUCKET_NAME&amp;#34;] tables = [ &amp;#34;call_center&amp;#34;, &amp;#34;catalog_page&amp;#34;, &amp;#34;catalog_returns&amp;#34;, &amp;#34;catalog_sales&amp;#34;, &amp;#34;customer&amp;#34;, &amp;#34;customer_address&amp;#34;, &amp;#34;customer_demographics&amp;#34;, &amp;#34;date_dim&amp;#34;, &amp;#34;dbgen_version&amp;#34;, &amp;#34;household_demographics&amp;#34;, &amp;#34;income_band&amp;#34;, &amp;#34;inventory&amp;#34;, &amp;#34;item&amp;#34;, &amp;#34;promotion&amp;#34;, &amp;#34;reason&amp;#34;, &amp;#34;ship_mode&amp;#34;, &amp;#34;store&amp;#34;, &amp;#34;store_returns&amp;#34;, &amp;#34;store_sales&amp;#34;, &amp;#34;time_dim&amp;#34;, &amp;#34;warehouse&amp;#34;, &amp;#34;web_page&amp;#34;, &amp;#34;web_returns&amp;#34;, &amp;#34;web_sales&amp;#34;, &amp;#34;web_site&amp;#34; ] for table in tables: df = glueContext.</description>
    </item>
    
    <item>
      <title>Redshift Serverlessと他のサーバーレス集計サービス、Glue Data Catalogのテーブルへのクエリ実行</title>
      <link>https://www.sambaiz.net/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/392/</guid>
      <description>Redshift Serverless Redshift Serverlessは今年のre:Inventで発表された、インスタンスを立てることなく従量課金でペタバイトスケールのDWHであるRedshiftを使える機能。 S3のデータを直接参照できるRedshift SpectrumやRDSへのFederated Query、機械学習のRedshift MLも使える。 分析のような不定期に発生する需要のためにインスタンスを立てておくのはコストの上でハードルが高かったのでこのアップデートは嬉しい。
料金は最低1分のオートスケールするRPU (2vCPU, 16GiBメモリ)時間とストレージに対してかかり、オレゴンリージョンなどが$0.45/RPU hourなのに対して東京はなぜか$0.70/RPU hourと少し割高な設定になっている。2vCPU, 15 GiBメモリのインスタンスdc2.largeがオンデマンドで$0.314/hourなので、利用頻度が少なかったり不定期なために平均40%以上リソースが使えていない場合のコストは抑えられそうだ。RIが最大まで効いている場合は$0.110/hourとなり15%まで閾値が下がるが、スケールを気にしなくて良いのは運用の上でもメリットがある。また、Redshift Spectrumのロード量に対する課金は発生しない。
他のサーバーレス集計サービス サーバーレスで集計を行える他のサービスとしてはPrestoのマネージドサービスであるAthenaやSparkのマネージドサービスであるGlueがあって、前者は手軽にクエリを実行できロード量による課金も分かりやすいが、実行時間や同時実行数などの制約があり、後者は時間のかかる集計も行うことができるがジョブを作る必要があってアドホックな実行にはあまり向かない。
これらはHive Metastoreに対応しており、その互換サービスであるGlue Data Catalogでスキーマを共有できるので用途に応じて使い分けることもできるが、使える文法に差があったり、同じクエリを実行しても異なる結果を返すことがあったりと、移植する際には注意する必要がある。
Athena(Presto)とGlue(Spark)で同じクエリを実行した際に異なる値が返る原因 - sambaiz-net
また、いずれもRDSに加えてDynamoDBやMongoDBなどのコネクタが用意されており、カスタムコネクタを用いることで他のデータソースにも接続することができる。
AthenaのFederated QueryでTPC-DS Connectorを用いてデータを生成する - sambaiz-net
GlueのカスタムコネクタでBigQueryに接続する - sambaiz-net
 同じく今年のre:Inventで発表されたEMR Serverlessもある。 巨大なデータに対して重い集計やrepartition()を行ったりするとOOMやNo space left on deviceになることがあるが、Glueだとスケールアップできないため物理的に解決が難しいことがあり、そのような場合はEMRを検討することになる。
サードパーティにも目を向ければ各クラウドにホストされるSnowflakeがある。コストやスケールの容易さのためにRedshiftからSnowflakeに移行した事例もあり良い評判を目にするが、立ち位置が近いRedshift Serverlessが発表されたことでこれからの技術選定に影響があるかもしれない。料金はプランによって単価が異なるSnowflake Creditとストレージに対してかかる。
他にはAnthosを用いてマルチクラウドでクエリエンジンを動かすBigQuery Omniもある。今年の10月にGAになったばかりで、対応リージョンがまだ少なく、料金も従量課金でないので他と同様に使うイメージではないが、データを転送することなくAWS上でBigQueryのクエリを実行できるのは待望の機能なので今後の動きが気になる。
Glue Data Catalogのテーブルにクエリを実行する CDKでData CatalogのDatabaseとTable、それらにアクセスできるRoleを作成する。
CDKでGlue Data CatalogのDatabase,Table,Partition,Crawlerを作成する - sambaiz-net
これも今年のre:Inventで発表があったが、ついにCDKのv2がstableになったのでv2で書く。 各サービスのパッケージ @aws-cdk/aws-xxx が aws-cdk-lib に統合され、alphaのものだけ旧パッケージ名に-alphaを付けたものになった。
$ npx aws-cdk@2.x init app --language typescript $ npm install --save aws-cdk-lib $ npm install --save @aws-cdk/aws-glue-alpha Redshift Serverlessで用いるRoleはPrincipalに redshift.</description>
    </item>
    
    <item>
      <title>AthenaのFederated QueryでTPC-DS Connectorを用いてデータを生成する</title>
      <link>https://www.sambaiz.net/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/391/</guid>
      <description>AthenaのFederated Queryは データソースコネクタとなるLambdaを通してDynamoDBやRDSといったS3以外のデータソースにクエリを実行できる機能。
Athenaのデータソースコネクタとユーザー定義関数(UDF)を実装する
 今回はAWS公式のリポジトリにあるTPC-DS Connectorを用いて、意思決定支援(Decision Support)におけるデータベースのベンチマークであるTPC-DSのデータを生成する。
公式のリポジトリにあるとはいえカスタム扱いなので自分でビルドする必要がある。基本的にREADME通り進めれば良いが、jdk16ではビルドに失敗したのでjdk8を入れて実行した。
$ brew tap homebrew/cask-versions $ brew install --cask corretto8 export JAVA_HOME=`/usr/libexec/java_home -v 1.8` export PATH=${JAVA_HOME}/bin:${PATH} $ java -version openjdk version &amp;#34;1.8.0_312&amp;#34; OpenJDK Runtime Environment Corretto-8.312.07.1 (build 1.8.0_312-b07) OpenJDK 64-Bit Server VM Corretto-8.312.07.1 (build 25.312-b07, mixed mode) publish.shの引数でもリージョンを取るが、これとは別に.aws/configなどで指定されていないとAWS SDKの方で読めずに失敗する。
$ git clone https://github.com/awslabs/aws-athena-query-federation.git -b v2021.51.1 --depth 1 $ cd aws-athena-query-federation/ $ mvn clean install -DskipTests=true $ cd athena-tpcds/ $ mvn clean install -DskipTests=true # export AWS_REGION=us-west-2 $ .</description>
    </item>
    
    <item>
      <title>Union-Find木で無向グラフに閉路があるかを判定する</title>
      <link>https://www.sambaiz.net/article/390/</link>
      <pubDate>Sun, 12 Dec 2021 16:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/390/</guid>
      <description>Union-Find木 Union-Find木はいくつかの素集合の木を持つデータ構造で、 2つの集合を結合するUnionと、要素の含まれる集合を特定し2つの要素が同じ集合に含まれるかを判定できるFindを、 ならし計算量 O(α(n)) (α(n)はアッカーマン間数A(n,n)の逆関数でlog(n)よりも小さい)で行うことができる。
Unionはなるべく木が平衡になるようrankが小さい方の木が下に来るように辺を張る。1要素の木のrankは0で、同じrankの木を結合すると上にした木のrankが1増える。 Findは根の値を比較した後、辿ったノードから根へ辺を張り直して次回以降の処理を効率的に行えるようにする。
 #include &amp;lt;bits/stdc++.h&amp;gt;using namespace std; class union_find_tree { unordered_map&amp;lt;int, int&amp;gt; parent; unordered_map&amp;lt;int, int&amp;gt; rank; public: union_find_tree(vector&amp;lt;int&amp;gt; values) { for(int i = 0; i &amp;lt; values.size(); i++) { parent[values[i]] = values[i]; rank[values[i]] = 0; } } int find(int x) { if (parent[x] == x) return x; int root = find(parent[x]); parent[x] = root; return root; } void unite(int x, int y) { x = find(x); y = find(y); if (x == y) return; if (rank[x] &amp;gt; rank[y]) { parent[y] = x; } else { parent[x] = y; if (rank[x] == rank[y]) rank[y]++; } } bool same(int x, int y) { return find(x) == find(y); } }; int main() { auto tree = new union_find_tree({1,2,3,4,5,6}); tree-&amp;gt;unite(2, 3); tree-&amp;gt;unite(1, 2); tree-&amp;gt;unite(4, 5); tree-&amp;gt;unite(5, 6); cout &amp;lt;&amp;lt; tree-&amp;gt;same(2, 5) &amp;lt;&amp;lt; endl; // 0  tree-&amp;gt;unite(2, 5); cout &amp;lt;&amp;lt; tree-&amp;gt;same(2, 5) &amp;lt;&amp;lt; endl; // 1 } Union-Find木による無向グラフの閉路の判定 無向グラフの辺をUnion-Find木に入れると、すでに到達可能なノードは同じ集合に属することになるので、 辺を張った時に閉路ができるかを判定できる。</description>
    </item>
    
    <item>
      <title>FlutterのNavigatorとAuroRoute</title>
      <link>https://www.sambaiz.net/article/389/</link>
      <pubDate>Sat, 11 Dec 2021 16:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/389/</guid>
      <description>Navigator FlutterのNavigatorは Routeをスタックし画面遷移させるクラスで、push()やpop()といったAPIを提供する。
 import &amp;#39;package:flutter/material.dart&amp;#39;; void main() { runApp(const MyApp()); } class MyApp extends StatelessWidget { const MyApp({Key? key}) : super(key: key); @override Widget build(BuildContext context) { return MaterialApp( title: &amp;#39;Navigation Test&amp;#39;, theme: ThemeData( primarySwatch: Colors.blue, ), home: const Page1(), ); } } class Page1 extends StatelessWidget { const Page1({Key? key}) : super(key: key); @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: const Text(&amp;#34;page1&amp;#34;), ), body: ListView.builder( itemCount: 10, itemBuilder: (context, index) { return ListTile( title: Text(index.</description>
    </item>
    
    <item>
      <title>FlutterでiOS/Android/Webアプリをビルドする</title>
      <link>https://www.sambaiz.net/article/388/</link>
      <pubDate>Sun, 05 Dec 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/388/</guid>
      <description>FlutterはGoogleによるクロスプラットフォームフレームワーク。 iOS/Androidに加え、今年の3月にリリースされた2.0でWebがstableになり、 Windows/Mac/Linuxはbetaとなっている。ネイティブのUIを用いるReact Nativeと異なり独自のUIで、 MaterialのほかにiOSスタイルのCupertinoも提供されているが、 分岐等しない限りはプラットフォームによらず同じ見た目になる。
環境構築 公式のGet startedに従って環境を構築していく。
まずFlutter SDKをインストールしてパスを通す。
$ mv ~/Downloads/flutter ~/ $ echo &amp;#39;export PATH=&amp;#34;$PATH:~/flutter/bin&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile $ source ~/.bash_profile $ flutter doctor Android Android Studioをインストールし起動して依存コンポーネントをダウンロードする。 cmdline-tools component is missing が出ている場合はSDK Managerからインストールする。
 ライセンスを承認する。
$ flutter doctor --android-licenses AVD Managerからエミュレーターの設定を行う。Emulated PerformanceはHardware - GLES 2.0を選択する。
 iOS Xcodeをインストールして command-line toolsの設定を行い、CocoaPodsもインストールする。
$ sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer $ sudo xcodebuild -runFirstLaunch $ sudo gem install cocoapods VSCode Flutter extensionをインストールし、Command PaletteからFlutter: New ProjectでApplicationを選ぶと次の構成のプロジェクトが作られる。</description>
    </item>
    
    <item>
      <title>ラビン-カープアルゴリズムをC&#43;&#43;で実装する</title>
      <link>https://www.sambaiz.net/article/387/</link>
      <pubDate>Sat, 04 Dec 2021 22:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/387/</guid>
      <description>ラビン-カープアルゴリズムはローリングハッシュを用いて部分文字列を探索するアルゴリズム。 ローリングハッシュというのは前のハッシュから先頭の要素を取り除き、次の要素を追加することによってO(1)で次のハッシュが得られるもの。
class rolling_hash { string str; int window_length = 0; long hash = 0; int head_idx = 0; long tail_pow; const int base = 128; public: rolling_hash(string str, int window_length) { this-&amp;gt;str = str; this-&amp;gt;window_length = window_length; long pow = 1; for (int i = 0; i &amp;lt; window_length; i++) { hash += str[i] * pow; pow *= base; } tail_pow = pow / base; } int get() { return hash; } // a_0 * base^0 + a_1 * base^1 + .</description>
    </item>
    
    <item>
      <title>カラムナフォーマットParquetの構造とReadの最適化</title>
      <link>https://www.sambaiz.net/article/386/</link>
      <pubDate>Fri, 03 Dec 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/386/</guid>
      <description>Parquetは主にHadoopのエコシステムで使われるカラムナフォーマット。 CSVのようなrow-basedのフォーマットと比べて、必要ないデータを読まずに済むため効率的にクエリを実行することができる。
構造 データはいくつかのRow Groupに水平分割される。カラムはいくつかのColumn Chunkに切られ、圧縮やエンコーディングされる単位であるPageに分けられる。
ファイルの構造は次のようになっていて、カラムごとに1つのColumn Chunkを持ついくつかのRow Groupとそのメタデータが順に並んでいる。
 ネストしたスキーマにも対応していて、 子要素をフラットにした後、Repetiton LevelとDefinition Levelで繰り返しや階層を表している。
Readの最適化 ColumnMetadataにレコード数や最小最大値、圧縮コーデックやサイズが含まれているため、Readerは必要なものだけを展開して読むことができる。 したがって取得するカラムを絞ったり、フィルタに用いるカラムをソートしておくと読むPageを減らすことができる。
参考 What is Apache Parquet? - Databricks</description>
    </item>
    
    <item>
      <title>C&#43;&#43;のstructとclass</title>
      <link>https://www.sambaiz.net/article/385/</link>
      <pubDate>Tue, 30 Nov 2021 18:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/385/</guid>
      <description>C++のclassとstructは同じ機能を持っているが、classのデフォルトがprivateなのに対してstructはpublicになっている。 classはカプセル化のために用いられ、公開フィールドを持ちメソッドをほとんど持たない場合はstructを使うことが多いようだ。
#include &amp;lt;iostream&amp;gt;using namespace std; class C { int value; public: C(int value) { this-&amp;gt;value = value; } int func() { return value; }; }; struct S { S(int value) { this-&amp;gt;value = value; } int value; private: int func() { return value; }; }; int main () { (new C(1))-&amp;gt;value; // member &amp;#34;C::value&amp;#34; (declared at line 2) is inaccessible  (new C(1))-&amp;gt;func(); (new S(1))-&amp;gt;value; (new S(1))-&amp;gt;func(); // function &amp;#34;S::func&amp;#34; (declared at line 18) is inaccessible } いずれも継承できる。C++では継承元の関数にvirtualを付けて仮想関数にしないと、 継承元の型の変数から呼んだ際にオーバーライドされず元の関数が呼ばれる。</description>
    </item>
    
    <item>
      <title>Sparkでstructをmapとして扱いexplodeで複数行に展開できるようにする</title>
      <link>https://www.sambaiz.net/article/384/</link>
      <pubDate>Wed, 13 Oct 2021 02:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/384/</guid>
      <description>Sparkでschemaを指定せずjsonなどを読み込むと次のように入力データから自動で決定される。
# {&amp;#34;aaa&amp;#34;:123,&amp;#34;ccc&amp;#34;:[123],&amp;#34;eee&amp;#34;:{&amp;#34;fff&amp;#34;:123},&amp;#34;hhh&amp;#34;:null} df = spark.read.json(&amp;#34;s3://hogefuga/testjson/&amp;#34;) df.printSchema() &amp;#39;&amp;#39;&amp;#39; root |-- aaa: long (nullable = true) |-- ccc: array (nullable = true) | |-- element: long (containsNull = true) |-- eee: struct (nullable = true) | |-- fff: long (nullable = true) |-- hhh: string (nullable = true) &amp;#39;&amp;#39;&amp;#39; これは大抵の場合うまくはたらくが、mapを想定したフィールドがstruct判定されたり、フィールドにnullしか含まれてないためにstring判定されたりすると、関数の入力に合わず処理に失敗することがある。explode()はarrayやmapを複数行に展開する関数。
df.createOrReplaceTempView(&amp;#34;tbl&amp;#34;) print(spark.sql(&amp;#34;SELECT v FROM tbl LATERAL VIEW explode(ccc) as v&amp;#34;).head()) # Row(v=123) print(spark.sql(&amp;#34;SELECT k, v FROM tbl LATERAL VIEW explode(eee) as k, v&amp;#34;).</description>
    </item>
    
    <item>
      <title>Adaptive Replacement Cache (ARC) とは</title>
      <link>https://www.sambaiz.net/article/383/</link>
      <pubDate>Thu, 07 Oct 2021 03:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/383/</guid>
      <description>Adaptive Replacement Cache (ARC) は4つのLRU Cacheを用いることでチューニングを自動で行いヒット率を向上させたメモリのページ置換のアルゴリズム。 PostgreSQLでバッファ管理のため一時期用いられていたが、IBMの特許を回避するため今は使われていない。
ARC: A SELF-TUNING, LOW OVERHEAD REPLACEMENT CACHE, Nimrod Megiddo and Dharmendra S. Modha
それぞれ次のデータを保持する。
 T1: 最近アクセスしたもの T2: 2回以上参照したもの B1: T1から追い出されたもののキー B2: T2から追い出されたもののキー  次の図では中央が各LRU Cacheの先頭で、!がT1の先頭、^がT1のサイズを表す。 新規データは!の左に格納され、既にT1またはB1に存在するデータは!の右に格納される。
...(B1)...[...(T1)...!...^...(T2)...]...(B2)... ghost listと呼ばれるB1とB2によってrecencyとfrequencyに応じたリソースの調整が自動で行われる。 B1でヒットした場合^を右に動かしてT1のサイズを増やし、T2の末尾のデータはB2に追い出される。 B2でヒットした場合^を左に動かしてT2のサイズを増やし、T1の末尾のデータはB1に追い出される。 いずれもヒットしなかった場合は!を^に近づける。
...(B1)...[...(T1)..!...→^.(T2)...]...(B2)... ...(B1)...[...(T1)..!..^←..(T2)...]...(B2)... ...(B1)...[...(T1)..→!..^..(T2)...]...(B2)... 参考 Adaptive replacement cache - Wikipedia
IBM patent sparks open source code rewrite | ZDNet</description>
    </item>
    
    <item>
      <title>SparkのWeb UIでJobのStageとExecutorによるTask分散、SQLのplanを確認する</title>
      <link>https://www.sambaiz.net/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/382/</guid>
      <description>SparkのWeb UIはJobやExecutorをモニタリングするためのツール。
aws-glue-samplesから maven:3.6-amazoncorretto-8 ベースでSparkを動かすDockerfileを持ってきて、 History Serverを起動する。Glueで出力されたEventLogのパスと認証情報を渡している。
 $ git clone https://github.com/aws-samples/aws-glue-samples.git $ cd aws-glue-samples/utilities/Spark_UI/glue-3_0/ $ docker build -t glue/sparkui:latest . $ docker run -it -e SPARK_HISTORY_OPTS=&amp;#34;$SPARK_HISTORY_OPTS-Dspark.history.fs.logDirectory=s3a://path_to_eventlog -Dspark.hadoop.fs.s3a.access.key=$AWS_ACCESS_KEY_ID-Dspark.hadoop.fs.s3a.secret.key=$AWS_SECRET_ACCESS_KEY&amp;#34; -p 18080:18080 glue/sparkui:latest &amp;#34;/opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer&amp;#34; これで http://localhost:18080 にアクセスしApplicationを選択するとJob実行やExecutor追加のタイムラインが表示される。
 各Jobをクリックすると次のようにStageとDAG(Directed Acyclic Graph)が表示される。 WholeStageCodeGenは高速化のため処理ごとではなくStage単位でCode Generationする処理。 ただ生成されるコードが大きいとJVMがJITコンパイルしなくなるのでかえって遅くなることもあるそうだ。
Stageはコストが大きいシャッフルを必要としない実行単位なので少ない方が良い。 Joinのためにかさんでいるのであれば、パラメータを調整するなどしてシャッフルしないBroadcast Hash Joinにできないか検討する。
Apache SparkのRDD, DataFrame, DataSetとAction, Transformation - sambaiz-net
 さらにStageをクリックすると各ExecutorごとのTaskのタイムラインが表示される。 ほとんどの時間をComputing Timeに割けていて、Taskの実行時間やExecutorへのInput Recordsの統計も概ね均一で、うまく分散できているように見える。
 SQLのタブを見るとOptimizerによって最適化されたクエリのLogical planや、 実際に実行されるPhysical plan、そのどこにどれくらい時間がかかっているかを確認できる。
 参考 Apache Sparkコミッターが教える、Spark SQLの詳しい仕組みとパフォーマンスチューニング Part2 - ログミーTech</description>
    </item>
    
    <item>
      <title>Glue DataBrewでデータを可視化して分析するProjectと機械学習の前処理を行うJobをCDKで作成する</title>
      <link>https://www.sambaiz.net/article/381/</link>
      <pubDate>Mon, 27 Sep 2021 16:42:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/381/</guid>
      <description>Glue DataBrewは、データを可視化してパラメータ間の相関を見たり、カテゴリー変数のエンコードや、欠損値や外れ値を置換する処理をコードなしで実行できるマネージドサービス。KaggleのHouse Prices Competitonの学習データで試してみる。全体のコードはGitHubにある。
KaggleのHouse Prices CompetitionのKernelからデータの探り方を学ぶ - sambaiz-net
料金は30分のセッションごとに$1と、Jobのノード時間あたり$0.48かかる。 ノードには通常のGlueのJobのDPUと同じく4vCPUと16GBのメモリが含まれ、時間あたりのコストの差は$0.04とそれほど大きくない。 使い分けとしては、非エンジニアが使う場合はGUIでデータを加工できるDataBrewを、独自の変換やカスタムコネクターを要する処理は通常のJobで行うと良いとのこと。
GlueのカスタムコネクタでBigQueryに接続する - sambaiz-net
Datasetの作成 DatasetのソースとしてData CatalogのほかにRedshiftやRDS、S3に直接接続することもできる。
CDKでGlue Data CatalogのDatabase,Table,Partition,Crawlerを作成する - sambaiz-net
今回はS3にファイルを上げてそれを参照する。
createDataBucket() { const bucket = new s3.Bucket(this, &amp;#39;DataBucket&amp;#39;, { bucketName: `databrew-sample-${this.account}-${this.region}`, removalPolicy: cdk.RemovalPolicy.DESTROY }) const deployData = new s3deploy.BucketDeployment(this, &amp;#39;DeploySource&amp;#39;, { sources: [s3deploy.Source.asset(&amp;#39;./data&amp;#39;)], destinationBucket: bucket, destinationKeyPrefix: &amp;#34;src/&amp;#34; }) return {bucket, deployData} } createDataset(bucket: s3.IBucket) { return new databrew.CfnDataset(this, &amp;#39;Dataset&amp;#39;, { name: &amp;#34;databrew-sample-train-dataset&amp;#34;, input: { s3InputDefinition: { bucket: bucket.</description>
    </item>
    
    <item>
      <title>GoでAmazon Forecastに時系列データをimportしPredictorを作成して予測結果をS3にexportする</title>
      <link>https://www.sambaiz.net/article/380/</link>
      <pubDate>Mon, 20 Sep 2021 23:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/380/</guid>
      <description>以前コンソール上で実行したAmazon Forecastでの時系列データの学習、予測をGoで行う。全体のコードはGitHubにある。
Amazon Forecastで時系列データの予測を行う - sambaiz-net
Datasetの作成 以前と同じく電力消費量のデータセットを、予測対象の時系列データ(DatasetTypeTargetTimeSeries)として登録する。データの頻度は1時間でドメインはCustom。
func (f Forecast) CreateDataset(ctx context.Context, name string) (*string, error) { return f.skipIfAlreadyExists(&amp;#34;dataset&amp;#34;, name, func() (*string, error) { dataset, err := f.svc.CreateDataset(ctx, &amp;amp;forecast.CreateDatasetInput{ DatasetName: aws.String(name), DatasetType: types.DatasetTypeTargetTimeSeries, DataFrequency: aws.String(&amp;#34;H&amp;#34;), Domain: types.DomainCustom, Schema: &amp;amp;types.Schema{ Attributes: []types.SchemaAttribute{ { AttributeName: aws.String(&amp;#34;timestamp&amp;#34;), AttributeType: types.AttributeTypeTimestamp, }, { AttributeName: aws.String(&amp;#34;target_value&amp;#34;), AttributeType: types.AttributeTypeFloat, }, { AttributeName: aws.String(&amp;#34;item_id&amp;#34;), AttributeType: types.AttributeTypeString, }, }, }, }) if err != nil { return nil, err } return dataset.</description>
    </item>
    
    <item>
      <title>CDKでCloudWatch Dashboardsを作成しコンソール上からAWSアカウントを持たない外部ユーザーに公開する</title>
      <link>https://www.sambaiz.net/article/379/</link>
      <pubDate>Sat, 18 Sep 2021 14:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/379/</guid>
      <description>CloudWatch Dashboardsは、CloudWatchのメトリクスの値やグラフを配置できるダッシュボードで、 次のようにCDKで作成できる。metricName と namespace、dimensions はコンソール上で確認する。
new cloudwatch.Dashboard(this, `CloudWatchDashboard`, { dashboardName: test }) cloudwatch.TextWidget({ markdown: `# Test Dashboard by [sambaiz](https://www.sambaiz.net)`, width: 24 }) dashboard.addWidgets( new cloudwatch.GraphWidget({ title: &amp;#34;Request Count&amp;#34;, left: [new cloudwatch.Metric({ metricName: &amp;#34;RequestCount&amp;#34;, namespace: &amp;#34;AWS/ApplicationELB&amp;#34;, dimensions: { &amp;#34;LoadBalancer&amp;#34;: alb.loadBalancerFullName }, statistic: &amp;#34;sum&amp;#34; })], width: 16 }), ) ) 作ったダッシュボードはコンソール上からAWSアカウントを持たない外部のユーザーに公開することができて、Cognito UeerPoolによるパスワード認証をかけられる。
発行されたリンクにアクセスすると次のような画面が表示される。
参考 cdk-patterns/serverless</description>
    </item>
    
    <item>
      <title>CDKでECS(EC2)上にLocust masterとworkerのServiceをデプロイしCloud Mapで名前解決させる</title>
      <link>https://www.sambaiz.net/article/378/</link>
      <pubDate>Tue, 17 Aug 2021 02:34:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/378/</guid>
      <description>以前、EKS上にLocustをインストールしたが、使わないときにクラスタを落としていたりすると起動を待つ必要があったり、K8sのバージョンアップに追従する必要があったりと少し不便な所があった。
CDKでEKSクラスタの作成からHelm ChartでのLocustのインストールまでを一気に行う - sambaiz-net
そこで今回はECS上にLocust masterとworkerのServiceをデプロイする。
Dockerfile 次のようなDockerfileを用意する。
$ cat Dockerfile FROM locustio/locust COPY locustfile.py /mnt/locust/ Stack クラスタの作成については以前のものを使い回す。
CDKでALBとECS(EC2)クラスタを作成し、ecs-cliでDocker Composeの構成をデプロイする - sambaiz-net
locustfileを更新する度にデプロイすることになるので、ALBのヘルスチェックの間隔と回数および登録解除のタイムアウト時間を減らして高速化している。また、locustに認証の仕組みがないためIPアドレスでアクセス制限をしているが、ApplicationListenerのopenがデフォルトのtrueのままだとAllow from anyoneの設定が追加されフルオープンになってしまうのでfalseにしている。
import * as cdk from &amp;#39;@aws-cdk/core&amp;#39; import * as ecs from &amp;#39;@aws-cdk/aws-ecs&amp;#39; import * as ec2 from &amp;#39;@aws-cdk/aws-ec2&amp;#39; import * as iam from &amp;#39;@aws-cdk/aws-iam&amp;#39; import * as autoscaling from &amp;#39;@aws-cdk/aws-autoscaling&amp;#39; import * as elbv2 from &amp;#39;@aws-cdk/aws-elasticloadbalancingv2&amp;#39; import * as logs from &amp;#39;@aws-cdk/aws-logs&amp;#39; export class LocustECSStack extends cdk.</description>
    </item>
    
    <item>
      <title>CDKでALBとECS(EC2)クラスタを作成し、ecs-cliでDocker Composeの構成をデプロイする</title>
      <link>https://www.sambaiz.net/article/377/</link>
      <pubDate>Sun, 15 Aug 2021 16:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/377/</guid>
      <description>以前、CloudFormationでLBなしのECS(EC2)最小構成を構築したが、今回はALBのTargetGroupまでをCDKで作成し、Serviceのデプロイをecs-cliで行う。 EC2をECSクラスタに登録する際の echo ECS_CLUSTER=&amp;lt;cluster_name&amp;gt; &amp;gt;&amp;gt; /etc/ecs/ecs.config といった処理は クラスタのAsgCapacityProviderにASGを指定すると追加される。
ECS(EC2)のCloudFormation最小構成 - sambaiz-net
import * as cdk from &amp;#39;@aws-cdk/core&amp;#39; import * as ecr from &amp;#39;@aws-cdk/aws-ecr&amp;#39; import * as ecs from &amp;#39;@aws-cdk/aws-ecs&amp;#39; import * as ec2 from &amp;#39;@aws-cdk/aws-ec2&amp;#39; import * as iam from &amp;#39;@aws-cdk/aws-iam&amp;#39; import * as elbv2 from &amp;#39;@aws-cdk/aws-elasticloadbalancingv2&amp;#39; import * as autoscaling from &amp;#39;@aws-cdk/aws-autoscaling&amp;#39; import { Cluster } from &amp;#39;@aws-cdk/aws-ecs&amp;#39; export class ECSEC2Stack extends cdk.Stack { constructor(scope: cdk.Construct, id: string, props?: cdk.</description>
    </item>
    
    <item>
      <title>AWS X-rayでアプリケーションのリクエストをトレースし可視化する</title>
      <link>https://www.sambaiz.net/article/376/</link>
      <pubDate>Thu, 05 Aug 2021 02:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/376/</guid>
      <description>AWS X-rayはリクエストをトレースして、タイムラインやサービスマップを可視化、分析できるサービス。 サービスの数が増えると見えづらくなる、どこにどれくらいのトラフィックがあって、どこで問題が起きているのかといったことを一目で確認できる。
料金はトレースの記録と取得に対してかかり、SamplingRuleの設定によって抑えることができる。
今回はローカルにdocker-composeで立ち上げたWebサーバーからセグメントデータをxray-daemon経由で送り、コンソール上で取得できることを確認する。全体のコードはGitHubにある。
xray-daemonは次のようなフォーマットのデータを受け取りバッチで送るデーモン。
$ cat segment.txt {&amp;#34;format&amp;#34;: &amp;#34;json&amp;#34;, &amp;#34;version&amp;#34;: 1} {&amp;#34;trace_id&amp;#34;: &amp;#34;1-594aed87-ad72e26896b3f9d3a27054bb&amp;#34;, &amp;#34;id&amp;#34;: &amp;#34;6226467e3f845502&amp;#34;, &amp;#34;start_time&amp;#34;: 1498082657.37518, &amp;#34;end_time&amp;#34;: 1498082695.4042, &amp;#34;name&amp;#34;: &amp;#34;test.elasticbeanstalk.com&amp;#34;} $ cat segment.txt &amp;gt; /dev/udp/127.0.0.1/2000 ローカルで動かす場合は -o を付けてインスタンスメタデータを読みに行かないようにする必要がある。ドキュメントでは.awsを/rootにマウントしているが、そうすると送る際に NoCredentialProviders: no valid providers in chain. Deprecated. になってしまう。Dockerfileを見たところxrayユーザーで動かしていることが分かったので /home/xray にしている。
version: &amp;#34;3.9&amp;#34; services: xray-daemon: image: amazon/aws-xray-daemon:3.x ports: - &amp;#34;2000:2000/udp&amp;#34; command: - &amp;#34;-o&amp;#34; # Don&amp;#39;t check for EC2 instance metadata. volumes: - ~/.aws:/home/xray/.aws:ro environment: AWS_REGION: ap-northeast-1 app: build: . ports: - &amp;#34;8080:8080&amp;#34; volumes: - ~/.</description>
    </item>
    
    <item>
      <title>gomockのmockを入力とするmockが意図した出力を返さない理由</title>
      <link>https://www.sambaiz.net/article/375/</link>
      <pubDate>Tue, 27 Jul 2021 12:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/375/</guid>
      <description>interfaceを受け取るinterfaceを定義し、
package main type Foo interface { Shout() string } type Bar interface { Bar(foo Foo) string } gomockでmockgenする。
// Code generated by MockGen. DO NOT EDIT. // Source: main.go  // Package main is a generated GoMock package. package main import ( reflect &amp;#34;reflect&amp;#34; gomock &amp;#34;github.com/golang/mock/gomock&amp;#34; ) ... // MockBarMockRecorder is the mock recorder for MockBar. type MockBarMockRecorder struct { mock *MockBar } // NewMockBar creates a new mock instance.</description>
    </item>
    
    <item>
      <title>Vue 3でTODOを作る</title>
      <link>https://www.sambaiz.net/article/374/</link>
      <pubDate>Sun, 25 Jul 2021 06:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/374/</guid>
      <description>Vue CLIをインストールしプロジェクトを作成する。
$ npm install -g @vue/cli $ vue --version @vue/cli 4.5.13 $ vue create todo $ tree -I node_modules todo . ├── README.md ├── babel.config.js ├── package-lock.json ├── package.json ├── public │ ├── favicon.ico │ └── index.html └── src ├── App.vue ├── assets │ └── logo.png ├── components │ └── HelloWorld.vue └── main.js エントリーポイント main.js を見るとVue 3からのGlobal API、createApp()が使われている。
$ cat src/main.js import { createApp } from &amp;#39;vue&amp;#39; import App from &amp;#39;.</description>
    </item>
    
    <item>
      <title>Clean ArchitectureとDDDの概念と得られるもの</title>
      <link>https://www.sambaiz.net/article/369/</link>
      <pubDate>Sun, 25 Jul 2021 01:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/369/</guid>
      <description>Clean Architecture 関心事をレイヤーに分割し、依存方向を下位から上位に制限したアーキテクチャ。次のような円で説明され、中央のビジネスルールが上位、外側のフレームワークやドライバが下位となる。
依存方向を制限することで上位のレイヤーが下位のレイヤーの変更の影響を受けづらくなり安定させることができる。また、テストも書きやすくなる。
Web APIサーバーを想定して次のような関心事のレイヤーを切る。
 handler: WAFとusecase間のデータ変換 usecase: アプリケーション固有のビジネスルール entity: ビジネスデータとそれを操作するビジネスルール repository: データへのアクセス  これらを図に当てはめると次のようになる。
依存方向逆転の原則(DIP) ここで問題になるのがrepositoryの位置で、usecaseやentityよりも下位にあるので依存できず呼び出せない。これは呼ぶ側のレイヤーで定義したインタフェースをrepositoryで実装して渡すことで解決できる。
このように変化しやすい具象ではなく安定した抽象に依存することを依存方向逆転の原則(DIP)と呼ぶ。
抽象に依存することでDBMSを変更などする際も、実装を置き換えるだけで済むといった説明がよくされるので、実際に置き換える機会がないと、コードが追いづらくなるだけで利点を感じづらいかもしれない。ただ、具象に依存している場合、DBMSの置き換えまでいかずとも、テーブルやカラムの扱いを変更すれば呼び出す側に影響を与えるわけで、そのような場合もDIPが有効にはたらくはずだと考えている。
また、具象に合わせて抽象を変更するのでは、結局不安定な具象に依存しているのと変わらないため、抽象は原則呼び出す側の必要によって定義され変更される必要がある。
技術的な決定の後回し 下位のリポジトリやフレームワークの決定は後回しにできるので、早速ビジネスルールの実装に入ることもできるわけだが、もしドメインが複雑で、かつ知見を持つドメインエキスパートがいるなら、まずはDDDの戦略的パターンによってそれを明らかにするところから始めると後述する恩恵が得られるかもしれない。
ドメイン駆動設計(DDD) ドメインエキスパートが普段使う言葉であるユビキタス言語を用いてドメインモデルを作る設計手法。ユビキタス言語を見つける過程でドメインの理解が深められ、モデルの境界を明確に定められるようになり、ドメインエキスパートとの合意も取りやすくなる。
コンテキスト ドメインに含まれるサブドメインとそこで使われているユビキタス言語を見つけ出し、言葉の境界を定める。これによって明らかになった事業的に最も利益を生み出すコアドメインに優先的に投資する。
境界付けられたコンテキストのユビキタス言語を用いてドメインモデルを作る。具体的にはドメインエキスパートの説明に登場する概念や振る舞いがそのままクラスやメソッドとして表現される。ユビキタス言語にない概念はモデルに含められない。もし不要な概念がモデルに持ち込まれているならコンテキストの境界を再考する。
コンテキストマップ 協力してお互いのニーズを満たすモデルを作る&amp;quot;パートナーシップ&amp;quot;や、下流のニーズが優先される&amp;quot;顧客/供給者の開発&amp;quot;、上流の提供するモデルを使うしかない&amp;quot;順応者&amp;quot;といったコンテキスト間の関係を図に表す。
モデルの変換が複雑な場合、&amp;ldquo;腐敗防止層(ACL)&amp;ldquo;というレイヤーに隔離するといった戦略が取られる。&amp;ldquo;公開ホストサービス(OHS)&amp;ldquo;を提供し、そこにリクエストするという関係もある。
戦略的パターンと戦術的パターン ここまでの手法がDDDの戦略的パターンで、ドメインモデルの実装に用いられるエンティティや値オブジェクト、集約、サービスなどを戦術的パターンと呼ぶ。ドメインエキスパートがいないと戦略的パターンが取れず、戦術的パターンのみを採用することもあるが、それは軽量DDDと呼ばれ、戦略的パターンを用いたときほどの見返りが得られないとされている。
エンティティと値オブジェクト 一意な識別子を持ち、可変なドメインオブジェクトをエンティティと呼び、識別子を持たず、不変なものを値オブジェクトと呼ぶ。エンティティはその識別子によって検索したり変更を追跡したりすることができるが、もしそれらが必要がなくその属性のみに関心がある場合、テストもしやすい値オブジェクトにすることが推奨されている。
エンティティの識別子としてDBのIDを用いることができるが、エンティティがテーブルの定義に引っ張られてはいけない。もし、エンティティがテーブルのデータをマッピングして、それにアクセスするゲッターやセッターを持つようなものであるなら、それはドメインが表現されていない&amp;quot;ドメインモデル貧血症&amp;quot;に陥っている。
集約 トランザクション整合性を持つエンティティや値オブジェクトの単位を集約と呼ぶ。つまり、一つのトランザクションでは一つの集約しか更新できない。集約が大きいとパフォーマンスに影響が出てしまうので、不必要に大きくならないようにしたい。もし複数の集約を更新する必要があるなら、結果整合性で問題ないか確認する。結果整合性の実現方法としては、ドメインイベントを発行しサブスクライバで非同期に更新するといったものがあり、失敗したらメッセージの再送によってリトライする。
(ドメイン)サービス 複数のドメインオブジェクトが関わるなどして、いずれかのエンティティや値オブジェクトに持たせるには自然でない処理を行う。アプリケーションサービスとは異なる概念で、トランザクションやセキュリティといったアプリケーションの関心事は持たない。
まとめ  Clean Architectureによってビジネスルールをその他の関心事による影響から守ることができる DIPで上位のレイヤーが不安定な具象に依存することを避けられる DDDによってドメインエキスパートから知見を学び、それをドメインモデルに表すことができる  参考 Clean Architecture 達人に学ぶソフトウェアの構造と設計
実践ドメイン駆動設計
4. Context Mapping - What Is Domain-Driven Design? [Book]</description>
    </item>
    
    <item>
      <title>SageMaker Studioの使っていないKernelを自動でシャットダウンするsagemaker-studio-auto-shutdown-extension</title>
      <link>https://www.sambaiz.net/article/373/</link>
      <pubDate>Sun, 18 Jul 2021 23:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/373/</guid>
      <description>SageMaker Studioを使っているとインスタンスを明示的に立ち上げることがないので、シャットダウンするのを忘れて 無駄なインスタンスコストを発生させ続けてしまうことがある。
Kernelをシャットダウンすると不要になったインスタンスもシャットダウンされるので、使っていないKernelが自動で削除されるようにしたい。 かつてはこれを実現するための仕組みを自前で用意する必要があったが、現在はsagemaker-studio-auto-shutdown-extensionが公式から提供されている。
$ git clone https://github.com/aws-samples/sagemaker-studio-auto-shutdown-extension.git $ cd sagemaker-studio-auto-shutdown-extension $ ./install_tarball.sh $ jupyter serverextension list ... sagemaker_studio_autoshutdown enabled - Validating... sagemaker_studio_autoshutdown 0.1.0 OK last activityからの時間が設定値を超過するとJupyter Notebook Server APIを呼んでKernelをシャッドダウンするようになっている。
参考 Save costs by automatically shutting down idle resources within Amazon SageMaker Studio | AWS Machine Learning Blog</description>
    </item>
    
    <item>
      <title>GlueのカスタムコネクタでBigQueryに接続する</title>
      <link>https://www.sambaiz.net/article/372/</link>
      <pubDate>Tue, 13 Jul 2021 21:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/372/</guid>
      <description>GlueはConnectorによって様々なデータソースに対応していて、RDSやMongoDBなど標準で提供されているもの以外にも カスタムコネクタを用いることで接続できる。今回はMarketplaceで提供されているBigQueryのカスタムコネクタを用いてBigQueryのテーブルの内容をS3に出力するJobを作成する。
GlueのETL JobをGUIで構築したりモニタリングできるサービス、Glue StudioからMarketplaceに飛んで AWS Glue Connector for Google BigQueryをSubscribeする。
BigQuery ConnectorをactivateしConnectionを作成する。
Studioでない方のGlueのConnectionからも確認できる。
JobのRoleには 117940112483.dkr.ecr.us-east-1.amazonaws.com/818e4ebf-997f-4d87-beb3-e0196e500474/cg-1025003233/bigquery-spark-connector:2.12.0-latest をpullするための GetAuthorizationToken と GCPのcredentialをSecretsManagerから持ってくるための GetSecretValue が必要。 SecretsManagerにそのままcredentialのjsonを入れて実行したところ次のエラーが出た。正しくはcredentialsというキーにbase64エンコードしたjsonの値を入れる。
IllegalArgumentException: &amp;#39;A project ID is required for this service but could not be determined from the builder or the environment. Please set a project ID using the builder.&amp;#39; また、Apache Spark SQL connector for Google BigQueryが Storage Read APIを呼ぶので bigquery.readsessions.* の権限が必要。
JobのConnection Options に parentProject としてGCPのProjectID、table としてBQのテーブル名を入れると次のようなスクリプトが生成され、 実行するとS3にBQのデータが保存される。DataFrameに変換してクエリを実行することもできる。DynamicFrameは現状overwriteできないので次のスクリプトは冪等性を持たない。</description>
    </item>
    
    <item>
      <title>C&#43;&#43; STLのmapやunordered_mapのkeyにstructを使えるようにする</title>
      <link>https://www.sambaiz.net/article/371/</link>
      <pubDate>Fri, 09 Jul 2021 23:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/371/</guid>
      <description>map operator&amp;lt; を実装する。
#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;map&amp;gt;using namespace std; struct Item { string name; int point; }; bool operator&amp;lt;(const Item&amp;amp; a, const Item&amp;amp; b) { return tie(a.name, a.point) &amp;lt; tie(b.name, b.point); } int main() { map&amp;lt;Item, bool&amp;gt; M; M[{&amp;#34;sambaiz&amp;#34;, 1024}] = true; cout &amp;lt;&amp;lt; M[{&amp;#34;sambaiz&amp;#34;, 1024}] &amp;lt;&amp;lt; endl; return 0; } unordered_map operator== とハッシュ関数を実装する。
#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;unordered_map&amp;gt;using namespace std; struct Item { string name; int point; }; bool operator==(const Item&amp;amp; a, const Item&amp;amp; b) { return a.</description>
    </item>
    
    <item>
      <title>Athena(Presto)とGlue(Spark)で同じクエリを実行した際に異なる値が返る原因</title>
      <link>https://www.sambaiz.net/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/370/</guid>
      <description>AWSではGlueのデータカタログでテーブルを共有して、 アドホックな集計は手軽にクエリを実行できるPrestoベースのAthena、 バッチ集計はリソースや時間の制約を回避できるSparkベースのGlueといったように併用することができる。
AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net
ANSI互換のSQLを実行するPrestoと デフォルトでHive互換のSpark SQLを実行するSparkで 使える文法に差があったりするものの、同じクエリが使い回せることもあって、そのような場合は同じ結果が返ってくることを期待してしまうが、 次のような挙動の違いによって大きく結果が異なってしまうことがある。
数値の型 Presto 0.198 以降ではデフォルトで小数リテラルをDECIMALとして扱うが、 Athena engine version 2 (Presto 0.217)では DOUBLEになる。engine version 1 (Presto 0.172)との互換のために parse-decimal-literals-as-double が渡されているのかもしれない。
SELECT typeof(1.2), /* double */ 1 / 3.0 * 10000000 /* 3333333.333333333 */ Spark 2.3 以降も小数リテラルをDECIMALとして扱い、Glue 2.0 (Spark 2.4.3) でもそうなっている。 DECIMALのscale(小数点以下の桁数)は最大6に制限される。
print(spark.sql(&amp;#34;&amp;#34;&amp;#34;SELECT 1.2&amp;#34;&amp;#34;&amp;#34;).dtypes) # [(&amp;#39;1.2&amp;#39;, &amp;#39;decimal(2,1)&amp;#39;)] print(spark.sql(&amp;#34;&amp;#34;&amp;#34;SELECT 1 / 3.0 * 10000000&amp;#34;&amp;#34;&amp;#34;).collect()) # [Row((CAST((CAST(CAST(1 AS DECIMAL(1,0)) AS DECIMAL(2,1)) / CAST(3.0 AS DECIMAL(2,1))) AS DECIMAL(14,6)) * CAST(CAST(10000000 AS DECIMAL(8,0)) AS DECIMAL(14,6)))=Decimal(&amp;#39;3333330.</description>
    </item>
    
    <item>
      <title>Next.jsのpre-rendering</title>
      <link>https://www.sambaiz.net/article/367/</link>
      <pubDate>Sat, 19 Jun 2021 12:56:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/367/</guid>
      <description>Next.jsはwebpackやbabel,ESLintを内包し、 SSG/SSRやリソースの最適化といった機能を提供するReactのフレームワーク。
create-next-appを実行し、npm run dev すると development modeでサーバーが起動するので localhost:3000/abcd にアクセスすると pages/abcd.tsx の export default されたコンポーネントが描画される。 Fast Refleshが効いているのでファイルを更新するとすぐに反映される。
$ npx create-next-app --ts $ cd my-app $ tree -I node_modules . . ├── README.md ├── next-env.d.ts ├── next.config.js ├── package-lock.json ├── package.json ├── pages │ ├── _app.tsx │ ├── api │ │ └── hello.ts │ └── index.tsx ├── public │ ├── favicon.ico │ └── vercel.svg ├── styles │ ├── Home.module.css │ └── globals.</description>
    </item>
    
    <item>
      <title>Notionでタスク管理を行う際のRelationによる親子タスクの紐付けとFormulaとRollupによる完了率の表示</title>
      <link>https://www.sambaiz.net/article/368/</link>
      <pubDate>Sat, 19 Jun 2021 00:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/368/</guid>
      <description>Notionでタスク管理するためのPropertyの設定。
Relationで自身のDatabaseを選び、 Create a new property すると選択されたPropertyが追加されるので、親子タスクを表現できる。
Rollupで子タスクの完了率を集計するには、完了したかをbooleanで表すParameterをFormulaで作成し、子タスクのこれを数える。</description>
    </item>
    
    <item>
      <title>Auth0の設定をauth0-deploy-cliでexportしてバージョン管理する</title>
      <link>https://www.sambaiz.net/article/365/</link>
      <pubDate>Sat, 12 Jun 2021 18:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/365/</guid>
      <description>認証プラットフォームAuth0の設定をバージョン管理する。
Cognitoでは複数のIdPの名寄せを行うのにUserPoolのsubを自力でマッピングしたり、IdentityPoolを用いる必要があったりするが、 Auth0ではそのあたりをRuleによって行えたりと多機能で、ドキュメントやライブラリ、サンプルコードも充実している。 その分、コストが高めだが、重要だがコアではない認証回りを任せられるのは助かる。
まずTenantにAuth0 Management APIの必要なPermissionを付けたMachine to Machine Applicationを作成する。
Applicationのclient_id/secretで、APIを呼ぶ際に Authorization:Bearer *** Headerで渡すアクセストークンを取得して正しいPermissionがscopeに含まれていることを確認する。
$ curl --request POST \ --url https://sambaiz-test.jp.auth0.com/oauth/token \ --header &amp;#39;content-type: application/json&amp;#39; \ --data &amp;#39;{&amp;#34;client_id&amp;#34;:&amp;#34;Kd4e04vgdXfYf69ZcrKLLH3wDYQyxAcU&amp;#34;,&amp;#34;client_secret&amp;#34;:&amp;#34;****&amp;#34;,&amp;#34;audience&amp;#34;:&amp;#34;https://sambaiz-test.jp.auth0.com/api/v2/&amp;#34;,&amp;#34;grant_type&amp;#34;:&amp;#34;client_credentials&amp;#34;}&amp;#39; \ | jq &amp;#39;.access_token | split(&amp;#34;.&amp;#34;) | .[1] | @base64d | fromjson&amp;#39; { &amp;#34;iss&amp;#34;: &amp;#34;https://sambaiz-test.jp.auth0.com/&amp;#34;, &amp;#34;sub&amp;#34;: &amp;#34;Kd4e04vgdXfYf69ZcrKLLH3wDYQyxAcU@clients&amp;#34;, &amp;#34;aud&amp;#34;: &amp;#34;https://sambaiz-test.jp.auth0.com/api/v2/&amp;#34;, &amp;#34;iat&amp;#34;: 1623482883, &amp;#34;exp&amp;#34;: 1623569283, &amp;#34;azp&amp;#34;: &amp;#34;Kd4e04vgdXfYf69ZcrKLLH3wDYQyxAcU&amp;#34;, &amp;#34;scope&amp;#34;: &amp;#34;read:client_grants create:client_grants delete:client_grants ...&amp;#34;, &amp;#34;gty&amp;#34;: &amp;#34;client-credentials&amp;#34; } auth0-deploy-cliをインストールする。
$ npm i -g auth0-deploy-cli $ a0deploy --version 5.</description>
    </item>
    
    <item>
      <title>AWS SDK for Java 2.x のUnable to load an HTTP implementationとクライアント変更によるlambda実行高速化</title>
      <link>https://www.sambaiz.net/article/366/</link>
      <pubDate>Thu, 10 Jun 2021 22:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/366/</guid>
      <description>AWS SDK for Java 2.x では内部で使うHTTP Clientを変更できるようになっている。現在サポートされているのは次の4つ。
&amp;lt;!-- synchronous --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;software.amazon.awssdk&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;apache-client&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;software.amazon.awssdk&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;url-connection-client&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- asynchronous --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;software.amazon.awssdk&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;netty-nio-client&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;software.amazon.awssdk&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;aws-crt-client&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;2.16.79-PREVIEW&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; system propertyでデフォルトクライアントを指定でき、クライアントごとに変えることもできる。
// JAVA_TOOL_OPTIONS: &amp;#34;-Dsoftware.amazon.awssdk.http.async.service.impl=software.amazon.awssdk.http.crt.AwsCrtSdkHttpService&amp;#34; System.setProperty(&amp;#34;software.amazon.awssdk.http.async.service.impl&amp;#34;, &amp;#34;software.amazon.awssdk.http.crt.AwsCrtSdkHttpService&amp;#34;); S3Client s3 = S3Client .builder() .region(Region.US_EAST_1) .httpClientBuilder(UrlConnectionHttpClient.builder()) .build(); S3AsyncClient s3Async = S3AsyncClient .builder() .region(Region.US_EAST_1) .build(); いずれの実装も依存に入っていないと次のエラーになる。
Unable to load an HTTP implementation from any provider in the chain. You must declare a dependency on an appropriate HTTP implementation or pass in an SdkHttpClient explicitly to the client builder Clientを変更してListObjectするlambdaを実行したところ、cold start時の初期化時間はapache-clientが最も短いが、 総実行時間はドキュメント通りaws-crt-clientが最速となった。 全体のコードはGitHubにある。</description>
    </item>
    
    <item>
      <title>WindowsのターミナルからRPAツールUiPathによる自動操作を行う</title>
      <link>https://www.sambaiz.net/article/360/</link>
      <pubDate>Sun, 06 Jun 2021 11:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/360/</guid>
      <description>RPAツールUiPathを使ってWindowsのターミナルから自動操作する。 UiPathにはCommunity Licenseがあって、個人や小規模のチームなら無料で使うことができる。 最近Microsoft公式のPower Automate Desktopも無料で使えるようになったが、 スケジューリングやトリガー機能を使うには有償のPower Autoamteを契約する必要があるようだ。
起動時にいくつかの選択肢が出るが最も多機能なUiPath Studio Proで空のプロジェクトを作成した。
$ tree -a -L 2 . . ├── .entities ├── .local │ ├── AllDependencies.json │ ├── PackageCache.json │ ├── db │ └── nuget.cache ├── .settings │ ├── Debug │ └── Release ├── .tmh │ └── config.json ├── Main.xaml └── project.json gitignoreには .local だけ加えた。
シーケンスにクリックなどのアクティビティを追加していく。
$ cat Main.xaml ... &amp;lt;ui:Click AlterIfDisabled=&amp;#34;{x:Null}&amp;#34; CursorMotionType=&amp;#34;{x:Null}&amp;#34; DelayBefore=&amp;#34;{x:Null}&amp;#34; DelayMS=&amp;#34;{x:Null}&amp;#34; SendWindowMessages=&amp;#34;{x:Null}&amp;#34; SimulateClick=&amp;#34;{x:Null}&amp;#34; ClickType=&amp;#34;CLICK_DOUBLE&amp;#34; DisplayName=&amp;#34;ダブル クリック&amp;#34; sap:VirtualizedContainerService.HintSize=&amp;#34;334,106&amp;#34; sap2010:WorkflowViewState.</description>
    </item>
    
    <item>
      <title>CircleCIのOrbをPublishする</title>
      <link>https://www.sambaiz.net/article/364/</link>
      <pubDate>Fri, 04 Jun 2021 12:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/364/</guid>
      <description>CircleCI CLIをインストールする。
$ brew install circleci マニュアルで circleci orb pack して circleci orb publish することもできるが、 Orb development kitを使うのが推奨されているのでそうする。
$ circleci orb pack ./src version: 2.1 description: | Sample orb description display: home_url: https://www.website.com/docs source_url: https://www.github.com/EXAMPLE_ORG/EXAMPLE_PROJECT commands: greet: description: | This command echos &amp;#34;Hello World&amp;#34; using file inclusion. parameters: to: default: World description: Hello to whom? type: string steps: - run: command: |Greet() { echo Hello &amp;#34;${PARAM_TO}&amp;#34; } # Will not run if sourced for bats-core tests.</description>
    </item>
    
    <item>
      <title>ReviewdogのGitHub ActionsでGoのlintをかけてPRに表示する</title>
      <link>https://www.sambaiz.net/article/363/</link>
      <pubDate>Thu, 03 Jun 2021 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/363/</guid>
      <description>Reviewdogはlinterの結果をPRにコメントしてくれるツール。 差分のみに適用することができるので段階的に改善していくこともできる。
Staticcheck StaticcheckはdeprecatedになったGolintのリポジトリで移行先として紹介されているlinter。
$ go install honnef.co/go/tools/cmd/staticcheck@latest $ staticcheck --version staticcheck 2021.1 (v0.2.0) 典型的なミスや非効率な書き方など様々な項目がチェックされる。
package main import ( &amp;#34;context&amp;#34; &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;strings&amp;#34; ) type Color int const ( Red Color = 1 // main.go:14:2: only the first constant in this group has an explicit type (SA9004)  Blue = 2 ) func f(ctx context.Context, str []byte) error { var m map[string]string m[&amp;#34;A&amp;#34;] = &amp;#34;default&amp;#34; // main.go:13:2: assignment to nil map (SA5000)  if err := json.</description>
    </item>
    
    <item>
      <title>shellの条件分岐の[と[[</title>
      <link>https://www.sambaiz.net/article/362/</link>
      <pubDate>Thu, 03 Jun 2021 13:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/362/</guid>
      <description>[ はPOSIX準拠のtestコマンド。[[ はその拡張でdashなどではサポートされていない。
$ which [ /usr/bin/[ $ man [ TEST(1) NAME test - check file types and compare values SYNOPSIS test EXPRESSION test [ EXPRESSION ] [ ] [ OPTION ... あくまでコマンドなので前後にスペースを空ける必要がある。
if [ -e ./foo.txt ]; then echo &amp;#34;file exists&amp;#34; else echo &amp;#34;no file exists&amp;#34; fi 一般的なプログラミング言語と異なり、0がtrueでそれ以外がfalse。
$ true; echo $? 0 $ false; echo $? 1 if文を使わなくても条件分岐できる。
$ [ -e ./foo.txt ] &amp;amp;&amp;amp; echo &amp;#34;file exists&amp;#34; || echo &amp;#34;no file exists&amp;#34; file exists ==/!</description>
    </item>
    
    <item>
      <title>AWS App Runnerの特徴と料金、CloudFormationのResource</title>
      <link>https://www.sambaiz.net/article/361/</link>
      <pubDate>Sun, 30 May 2021 03:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/361/</guid>
      <description>AWS App Runnerは最低限の設定でロードバランシングやオートスケール、ログやメトリクス、ドメインや証明書などを備えた、 リクエストベースのステートレスなコンテナアプリケーションを動かすことができるマネージドサービス。 Elastic BeanstalkのようにEC2やALB、AutoScaling Groupなどのリソースを作成するのではなく内部に持つ。
料金は、東京リージョンの場合
 レイテンシを抑えるために常にプロビジョニングされるコンテナインスタンスのメモリ量: 0.009 USD/GB リクエストを処理するアクティブなコンテナインスタンスのCPUとメモリ量: 0.081 USD/vCPU, 0.009 USD/GB  およびビルド時間で算出される。 Lambda(+ API Gateway)と異なりリクエストが来なくても最小インスタンスのメモリ分のコストは発生するのと、 Fargateが0.05056 USD/vCPU, 0.00553 USD/GBであることを考えると少し割高に見えるが、 Lambdaの制約を受けずに、リクエストが来ない時間帯はコストが抑えられるのは良さそうだ。
FargateでECSを使う - sambaiz-net
コンテナアプリケーション管理のCLIツールAWS CopilotもApp Runnerに対応していて、 Environmentを作成するとVPCが作られるが、現状App RunnerはVPCに対応していない。 private subnetのRDSにアクセスしたり、ドキュメントでも言及されているようにElastiCacheにキャッシュを持てるようになるので対応されると嬉しい。
 (追記 2022-02-09) VPC対応された。
 CloudFormationのResourceは現状AWS::AppRunner::Serviceのみで、 これと必要なRoleだけ作れば最低限動き、https://h2w86ea3gf.ap-northeast-1.awsapprunner.com/ のようなURLでアクセスできる。 まだリリースされたばかりでAutoScalingのResourceがなかったりするので、今後のアップデートに期待している。
Resources: AccessRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Version: &amp;#39;2008-10-17&amp;#39; Statement: - Effect: Allow Principal: Service: - build.apprunner.amazonaws.com Action: sts:AssumeRole ManagedPolicyArns: - arn:aws:iam::aws:policy/service-role/AWSAppRunnerServicePolicyForECRAccess TestService: Type: AWS::AppRunner::Service Properties: ServiceName: test-service SourceConfiguration: AuthenticationConfiguration: AccessRoleArn: !</description>
    </item>
    
    <item>
      <title>127.0.0.1(localhost)と0.0.0.0</title>
      <link>https://www.sambaiz.net/article/359/</link>
      <pubDate>Mon, 24 May 2021 23:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/359/</guid>
      <description>ホストで動かしていたコンポーネント群をdocker-composeに乗せたところ、コンポーネント間の通信が通らなくなってしまった。 いずれもdocker-composeが作ったデフォルトのネットワークで動いているのでpingは通る。 コードを見てみたところサーバーがlocalhostでlistenしていたので 0.0.0.0 に修正した。
localhostは /etc/hosts で 127.0.0.1 に解決されるわけだが、これはloopback interface lo で通信するループバックアドレスで、自分自身を指す。
$ cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback ... $ ip addr 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: sit0@NONE: &amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop state DOWN qlen 1000 link/sit 0.0.0.0 brd 0.0.0.0 34: eth0@if35: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff inet 172.</description>
    </item>
    
    <item>
      <title>Windowsでの開発環境を構築する(WSL2, Docker, VSCode)</title>
      <link>https://www.sambaiz.net/article/358/</link>
      <pubDate>Sun, 16 May 2021 11:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/358/</guid>
      <description>WSL2 WSL2を有効化してストアからUbuntuとWindows Terminalをインストールする。
# PowerShell $ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart $ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart $ wsl --set-default-version 2 Ubuntuのユーザー設定後、Windows Terminalの既定のプロファイルをUbuntuに変更するとMacのターミナルのように使うことができる。 GoやAWS CLIなど必要なものをUbuntuに入れていく。
$ sudo apt install -y make # Go &amp;amp; grpc $ wget https://golang.org/dl/go1.16.4.linux-amd64.tar.gz $ sudo tar -C /usr/local -xzf go1.16.4.linux-amd64.tar.gz $ echo &amp;#34;export PATH=$PATH:/usr/local/go/bin&amp;#34; &amp;gt;&amp;gt; ~/.bash_profile $ sudo apt install -y protobuf-compiler $ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.26 $ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.1 $ echo &amp;#39;export PATH=&amp;#34;$PATH:$(go env GOPATH)/bin&amp;#34;&amp;#39; &amp;gt;&amp;gt; /.</description>
    </item>
    
    <item>
      <title>CDKでGlue Data CatalogのDatabase,Table,Partition,Crawlerを作成する</title>
      <link>https://www.sambaiz.net/article/357/</link>
      <pubDate>Sun, 09 May 2021 01:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/357/</guid>
      <description>CDKでGlue Data CatlogのDatabase,Table,Partition,Crawlerを作成する。 PartitionやCrawlerはまだL2 constructが存在しない。storageDescriptorの設定はTableの実装を参考にした。
TableやPartitionはCrawlerで自動生成することができるが、ファイル数が膨大だと時間がかかることもあり、Tableはマニュアルで、Partitionの作成はAPIを呼んで作ることがあって、CDKで管理すると今の状態に関わらずデプロイによって必要なものが存在することを保証できる。
AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net
import * as cdk from &amp;#39;@aws-cdk/core&amp;#39;; import { Database, Table, DataFormat, Schema, CfnPartition } from &amp;#39;@aws-cdk/aws-glue&amp;#39;; import { Bucket } from &amp;#39;@aws-cdk/aws-s3&amp;#39;; import { format, subDays } from &amp;#39;date-fns&amp;#39; export class CdkGlueDataCatalogSampleStack extends cdk.Stack { constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) { super(scope, id, props); const db = new Database(this, &amp;#39;TestDB&amp;#39;, { databaseName: &amp;#34;test-db&amp;#34;, }) const bucket = new Bucket(this, &amp;#39;DBBucket&amp;#39;, { bucketName: `test-db-bucket-${this.</description>
    </item>
    
    <item>
      <title>Raspberry PiでおうちKubernetesクラスタを構築する</title>
      <link>https://www.sambaiz.net/article/356/</link>
      <pubDate>Wed, 05 May 2021 19:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/356/</guid>
      <description>Raspberry Pi 3台でKubernetesクラスタを構築する、2020年版おうちKubernetesインターンの資料が公開されていたのでやってみる。 Kubernetesのバージョンはv1.20.6にした。
おうちで「おうち Kubernetes インターン」を実施しました | CyberAgent Developers Blog
材料調達 ほとんどの材料は書いてあるURLで揃えられたが、PoE HATは在庫が切れていたのでスイッチサイエンスで買った。Raspberry Pi 3 Model B+専用と書いてあるが4でも使える。 PoE(Power over Ethernet)はIEEE802.3afとして標準化されているLANケーブルで給電する技術で、48Vで最大15.4Wまで出力できる。 PDではない通常のUSB Type-Cが5Vで15Wなのでそれとほぼ同等のワット数だ。
microSDは最初Kingstonのものを買ったが、 Raspberry Pi ImagerでOSを書き込む際に3枚ともVerifying write failedになってしまったのでSanDiskのものを書い直した。これにはSDカードアダプタが付いていなくて書き込む際にKingstonに付いてきたのを使ったので完全に無駄にはならなかった。
起動後SSHの設定を行うのにUSBキーボードが必要だが、Type-CのHHKBしかなかったので、Type-C to Type-A変換ケーブルも買った。諸々で5万円くらいかかった。
組み立て ヒートシンクを貼る事ができれば貼ると書いてあったので全ての黒いチップに貼ってみた結果、HATがつけられなくなりCPU以外から剥がすことになった以外は 特に問題なく進められた。ケースにドライバーが付いているので工具も必要ない。
10cm四方のアクリル板の上に収まっていてすごく良い。
SSH接続 Raspberry Pi ImagerでmicroSDにUbuntu Server 21.04 LTSを書き込んで 起動し他マシンからsshしようとしたが繋がらない。 sshdのstatusを見ると起動に失敗している。Test modeで実行してhostkeyがないことが分かったので、作成すると無事起動し繋がるようになった。
$ systemctl status ssh ... Active: failed (Result: exit-code) $ sshd -t sshd: no hostkeys available -- exiting $ sudo ssh-keygen -A $ sudo systemctl restart ssh 次にアドレスがDHCPで変わってしまわないようにする。 ルータの方でMACアドレスに対して払い出すアドレスを固定することもできるが、 今回はNetplanの設定でアドレスを固定しDHCPを無効にした。 ついでにPodへのRoutingも行っている。 今は他と一緒のサブネットに入れているが、無線LANのNICを追加したらサブネットを/24にしてクラスタ内通信を分離しようと考えている。</description>
    </item>
    
    <item>
      <title>FluentdがどのようにMulti Process Workersで処理を実行しているのか実装を追う</title>
      <link>https://www.sambaiz.net/article/335/</link>
      <pubDate>Sun, 25 Apr 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/335/</guid>
      <description>Fluentdはv1.0から標準でマルチプロセス対応され、 指定した数のWorkerで処理が行われるようになった。
&amp;lt;system&amp;gt; workers 4 &amp;lt;/system&amp;gt; どのように実行しているのかv1.12.3の実装を見ていく。
Supervisor Multi Process Workersのドキュメントにもあるように、 Workerと通信するSupervisorというのが存在する。 具体的に何をしているかというとWorkerプロセスを作成するWorkerModuleを渡してサーバーを立てたり、SIGNALを送ったりしている。
# https://github.com/fluent/fluentd/blob/master/lib/fluent/supervisor.rb#L365-L377 module WorkerModule def spawn(process_manager) main_cmd = config[:main_cmd] env = { &amp;#39;SERVERENGINE_WORKER_ID&amp;#39; =&amp;gt; @worker_id.to_i.to_s, } @pm = process_manager.spawn(env, *main_cmd) end def after_start (config[:worker_pid] ||= {})[@worker_id] = @pm.pid end end # https://github.com/fluent/fluentd/blob/v1.12.3/lib/fluent/supervisor.rb#L808-L811 se = ServerEngine.create(ServerModule, WorkerModule){ Fluent::Supervisor.load_config(@config_path, params) } se.run # https://github.com/fluent/fluentd/blob/master/lib/fluent/supervisor.rb#L305-L317 def kill_worker if config[:worker_pid] pids = config[:worker_pid].clone config[:worker_pid].clear pids.each_value do |pid| if Fluent.windows? Process.kill :KILL, pid else Process.</description>
    </item>
    
    <item>
      <title>CDKでKinesis Data Analytics上にPyFlinkのコードをデプロイして動かす</title>
      <link>https://www.sambaiz.net/article/334/</link>
      <pubDate>Sat, 24 Apr 2021 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/334/</guid>
      <description>KDAがPyFlinkをサポートしたのでCDKで構築して動かしてみる。 全体のコードはGitHubにある。
Kinesis Data AnalyticsのSQL, Lambdaへの出力とCDKによるリソースの作成 - sambaiz-net
今回動かすのは次の、KDSから流れてきたデータにクエリを実行し、その結果をS3に書き込む簡単なコード。
from pyflink.table import EnvironmentSettings, StreamTableEnvironment from pyflink.table.window import Tumble import os import json APPLICATION_PROPERTIES_FILE_PATH = &amp;#34;/etc/flink/application_properties.json&amp;#34; # on kda def get_application_properties(): if os.path.isfile(APPLICATION_PROPERTIES_FILE_PATH): with open(APPLICATION_PROPERTIES_FILE_PATH, &amp;#34;r&amp;#34;) as file: contents = file.read() properties = json.loads(contents) return properties else: print(&amp;#39;A file at &amp;#34;{}&amp;#34; was not found&amp;#39;.format( APPLICATION_PROPERTIES_FILE_PATH)) def property_map(props, property_group_id): for prop in props: if prop[&amp;#34;PropertyGroupId&amp;#34;] == property_group_id: return prop[&amp;#34;PropertyMap&amp;#34;] def main(): table_env = StreamTableEnvironment.</description>
    </item>
    
    <item>
      <title>AWS GlueのJobのBookmarkを有効にして前回の続きから処理を行う</title>
      <link>https://www.sambaiz.net/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/333/</guid>
      <description>GlueのJobのBookmarkは どこまで処理したかを記録し、次回はその続きから実行できるようにする機能。 1.0以前は対応していなかったParquetやORCも今は対応している。
AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net
Job bookamarkをEnableにして、DynamicFrameのメソッドを呼ぶ際にtranscation_ctxを渡し、job.commit()するとBookmarkされる。
例えば、S3のjsonをソースとするテーブルをカウントして出力する次のjobは、Bookmarkを有効にすると既にカウントしたものが読まれなくなるため、 トータルの件数ではなく前回との増分が出力される。 S3の結果整合性による、参照できるようになるまでのラグも考慮されていて、 単純に保存時間のみによって対象を選ぶのではなく、リストを持って対象の時間の少し前から見るようになっている。
import sys from awsglue.transforms import * from awsglue.utils import getResolvedOptions from pyspark.context import SparkContext from awsglue.context import GlueContext from awsglue.job import Job args = getResolvedOptions(sys.argv, [&amp;#39;JOB_NAME&amp;#39;]) sc = SparkContext() glueContext = GlueContext(sc) spark = glueContext.spark_session job = Job(glueContext) job.init(args[&amp;#39;JOB_NAME&amp;#39;], args) source = glueContext.create_dynamic_frame.from_catalog( database=&amp;#34;test&amp;#34;, table_name=&amp;#34;test&amp;#34;, transformation_ctx=&amp;#34;source&amp;#34;) source.toDF().createOrReplaceTempView(&amp;#34;t&amp;#34;) df = spark.sql(&amp;#34;SELECT COUNT(1) as cnt FROM t&amp;#34;) df.write.mode(&amp;#34;append&amp;#34;).csv( &amp;#34;s3://*****/test-table-summary&amp;#34;, compression=&amp;#34;gzip&amp;#34;) job.</description>
    </item>
    
    <item>
      <title>CDKでStep Functionsによるワークフローを構築する</title>
      <link>https://www.sambaiz.net/article/332/</link>
      <pubDate>Sat, 10 Apr 2021 21:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/332/</guid>
      <description>Step FunctionsはLambdaやGlueのJobなどからなるワークフローを構築できるサービス。これをCDKで構築する。 全体のコードはGitHubにある。
taskをnext()で繋げたワークフローをStateMachineに渡す流れ。 複数のtaskを同時に実行するParallel()は配列をoutputする。 条件分岐を行うChoice()でotherwise()を指定しないとエラーになる。
Objectの中でinputの値を参照する場合、キーの名前を.$で終える必要があり、 fromJsonPathAt() を用いるとキーに.$が追加される。
import * as cdk from &amp;#39;@aws-cdk/core&amp;#39;; import * as sfn from &amp;#39;@aws-cdk/aws-stepfunctions&amp;#39;; import * as tasks from &amp;#39;@aws-cdk/aws-stepfunctions-tasks&amp;#39;; import { Function, Code, Runtime } from &amp;#39;@aws-cdk/aws-lambda&amp;#39;; import * as path from &amp;#39;path&amp;#39; export class CdkStepfunctionsSampleStack extends cdk.Stack { constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) { super(scope, id, props); const fetchScoreFunction = new Function(this, &amp;#39;FetchScoreFunction&amp;#39;, { runtime: Runtime.GO_1_X, code: Code.fromAsset(path.join(__dirname, &amp;#39;lambda&amp;#39;, &amp;#39;fetchScore&amp;#39;)), handler: &amp;#34;main&amp;#34; }) const invokeFetchScoreFunction1 = new tasks.</description>
    </item>
    
    <item>
      <title>Application Auto Scalingのcustom-resourceによるKinesis Data Streamsのオートスケール設定</title>
      <link>https://www.sambaiz.net/article/331/</link>
      <pubDate>Sun, 21 Mar 2021 23:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/331/</guid>
      <description>Application Auto Scalingは、Auto Scaling groupによるEC2のオートスケールのようなことを他のリソースでも行えるようにするサービスで、 DynamoDBのキャパシティやECSのServiceなどコンソール上から設定できるものだけではなく、自前のAPIでハンドリングすることで任意のリソースをこの仕組みに乗せることができる。これを用いてKinesis Data Streamsのオートスケールを行う手法を紹介しているのが次の記事。
Scale Amazon Kinesis Data Streams with AWS Application Auto Scaling | AWS Big Data Blog
サンプルテンプレートの設定項目を見ていく。
ScalableTarget ServiceNamespaceでdynamodbやecsといった名前空間を、ScalableDimensionでdynamodb:table:ReadCapacityUnitsやecs:service:DesiredCountといった増減する値を指定する。 ResourceIdにはScalableDimensionのResourceTypeに応じた対象を指定するわけだが、 custom-resourceの場合は状態を確認したり更新するためのAPIのURLを指定するようだ。 ドキュメントにはOutputValueの値と書いてあるが、特に関係ないように見える。
Roleにはcloudwatch:Describe/Put/DeleteAlarmsおよびexecute-api:Invoke*の権限を与える。
KinesisAutoScaling: Type: AWS::ApplicationAutoScaling::ScalableTarget DependsOn: LambdaScaler Properties: MaxCapacity: 8 MinCapacity: 1 ResourceId: !Sub https://${MyApi}.execute-api.${AWS::Region}.amazonaws.com/prod/scalableTargetDimensions/${MyKinesisStream} RoleARN: !Sub ${CustomApplicationAutoScalingServiceRole.Arn} ScalableDimension: &amp;#39;custom-resource:ResourceType:Property&amp;#39; ServiceNamespace: custom-resource ScalingPolicy AdjustmentTypeとScalingAdjsutmentの値によって増減値を設定する。 AdjustmentTypeにはChangeInCapacity | ExactCapacity | PercentChangeInCapacityのいずれかを指定する。
AutoScalingPolicyOut: Type : &amp;#34;AWS::ApplicationAutoScaling::ScalingPolicy&amp;#34; DependsOn: KinesisAutoScaling Properties: PolicyName: KinesisScaleOut PolicyType: StepScaling ResourceId: !Sub https://${MyApi}.</description>
    </item>
    
    <item>
      <title>Goのio packageのReader/Writer/Closer/Seeker interfaceとストリーム処理</title>
      <link>https://www.sambaiz.net/article/330/</link>
      <pubDate>Thu, 11 Mar 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/330/</guid>
      <description>Goのio packageにはデータの読み書きに関わるインタフェース、Reader/Writer/Closer/Seeker およびこれらを組み合わせた ReadSeeker などが定義されている。
 io.Reader  最大でlen(p)バイトpに読み込んで、読み込んだバイト数を返す。 最後まで読んだらerrでio.EOFを返すが、これは最後のバイトと同時でもその後でも良いことになっている。
type Reader interface { Read(p []byte) (n int, err error) } var EOF = errors.New(&amp;#34;EOF&amp;#34;)  io.Writer  データを書き込み、そのバイト数を返す。全て書き込めなかった(len(p) != n)場合はエラーを返す必要がある。
type Writer interface { Write(p []byte) (n int, err error) }  io.Closer  2回以上呼んだときの挙動は規定されていない。
type Closer interface { Close() error }  io.Seeker  オフセットと起点を渡して読み書きする地点を変更し、Startからのオフセットを返す。
type Seeker interface { Seek(offset int64, whence int) (int64, error) } const ( SeekStart = 0 // seek relative to the origin of the file 	SeekCurrent = 1 // seek relative to the current offset 	SeekEnd = 2 // seek relative to the end ) ReaderとWriterを繋げてストリーム処理を行うことで、メモリ使用量を抑えることができる。 io.</description>
    </item>
    
    <item>
      <title>x/sync/semaphoreでgoroutineの数を制御する</title>
      <link>https://www.sambaiz.net/article/329/</link>
      <pubDate>Tue, 09 Mar 2021 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/329/</guid>
      <description>Goの特長の一つにgoroutineによる並列実行の容易さがあるが、 無尽蔵にgoroutineを生成するとパフォーマンスが悪化してしまうため、 都度go func()するのではなく、一定数走らせておいたgoroutineに処理を渡すなどして、その数を制御することがある。
Goroutineの数をworkerで抑制する - sambaiz-net
重み付きのセマフォを提供する準標準パッケージgolang.org/x/sync/semaphoreを用いると 容易にこれを行うことができる。
次のようにAcquire(context, weight)して、使い終わったらRelease(weight)する。 セマフォのWeightを使い切るとAcquire()でブロッキングされるので、1ずつAcquire()していった場合、goroutineの数は最大でもWeightの値で抑えられる。 x/sync/errgroupはGo()で非同期処理を実行し、エラーが返るか全ての処理が終わるまで Wait() する。errgroupを用いない場合、最後に最大WeightでAcquire()することで全ての処理が終わったことを確認する。
package main import ( &amp;#34;context&amp;#34; &amp;#34;errors&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;golang.org/x/sync/errgroup&amp;#34; &amp;#34;golang.org/x/sync/semaphore&amp;#34; ) func countWithSem(ctx context.Context, maxWorkers int64) { sem := semaphore.NewWeighted(maxWorkers) eg, ctx := errgroup.WithContext(ctx) for i := 0; i &amp;lt; 5; i++ { if err := sem.Acquire(ctx, 1); err != nil { fmt.Printf(&amp;#34;failed to acquire semaphore: %v\n&amp;#34;, err) break } func(i int) { eg.Go(func() error { defer sem.</description>
    </item>
    
    <item>
      <title>Athena(Presto)でWindow関数を用いた集計を行う</title>
      <link>https://www.sambaiz.net/article/328/</link>
      <pubDate>Wed, 24 Feb 2021 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/328/</guid>
      <description>Athena(Presto)でSUM()やAVG()といった集計関数にOVERを付けてWindow集計を行う。
Window Functions — Presto 0.247 Documentation
次のテストデータを使う。
$ cat test-data.csv {&amp;#34;date&amp;#34;:&amp;#34;2021-02-01&amp;#34;,&amp;#34;user&amp;#34;:1,&amp;#34;value&amp;#34;:10} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-01&amp;#34;,&amp;#34;user&amp;#34;:2,&amp;#34;value&amp;#34;:20} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-01&amp;#34;,&amp;#34;user&amp;#34;:3,&amp;#34;value&amp;#34;:30} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-01&amp;#34;,&amp;#34;user&amp;#34;:1,&amp;#34;value&amp;#34;:40} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-01&amp;#34;,&amp;#34;user&amp;#34;:2,&amp;#34;value&amp;#34;:50} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-01&amp;#34;,&amp;#34;user&amp;#34;:3,&amp;#34;value&amp;#34;:60} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-02&amp;#34;,&amp;#34;user&amp;#34;:1,&amp;#34;value&amp;#34;:100} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-02&amp;#34;,&amp;#34;user&amp;#34;:2,&amp;#34;value&amp;#34;:200} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-02&amp;#34;,&amp;#34;user&amp;#34;:3,&amp;#34;value&amp;#34;:300} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-02&amp;#34;,&amp;#34;user&amp;#34;:1,&amp;#34;value&amp;#34;:400} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-02&amp;#34;,&amp;#34;user&amp;#34;:2,&amp;#34;value&amp;#34;:500} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-02&amp;#34;,&amp;#34;user&amp;#34;:3,&amp;#34;value&amp;#34;:600} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-03&amp;#34;,&amp;#34;user&amp;#34;:1,&amp;#34;value&amp;#34;:1} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-03&amp;#34;,&amp;#34;user&amp;#34;:2,&amp;#34;value&amp;#34;:2} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-03&amp;#34;,&amp;#34;user&amp;#34;:3,&amp;#34;value&amp;#34;:3} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-03&amp;#34;,&amp;#34;user&amp;#34;:1,&amp;#34;value&amp;#34;:4} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-03&amp;#34;,&amp;#34;user&amp;#34;:2,&amp;#34;value&amp;#34;:5} {&amp;#34;date&amp;#34;:&amp;#34;2021-02-03&amp;#34;,&amp;#34;user&amp;#34;:3,&amp;#34;value&amp;#34;:6} PARTITION BY その値ごとに集計する。
SELECT date, user, value, SUM(value) OVER (PARTITION BY user) as sum_value FROM test ORDER BY date, user; GROUP BYしているわけではないので、行数は減らない。
&amp;#34;date&amp;#34;,&amp;#34;user&amp;#34;,&amp;#34;value&amp;#34;,&amp;#34;sum_value&amp;#34; &amp;#34;2021-02-01&amp;#34;,&amp;#34;1&amp;#34;,&amp;#34;40&amp;#34;,&amp;#34;555&amp;#34; &amp;#34;2021-02-01&amp;#34;,&amp;#34;1&amp;#34;,&amp;#34;10&amp;#34;,&amp;#34;555&amp;#34; &amp;#34;2021-02-01&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;20&amp;#34;,&amp;#34;777&amp;#34; &amp;#34;2021-02-01&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;50&amp;#34;,&amp;#34;777&amp;#34; &amp;#34;2021-02-01&amp;#34;,&amp;#34;3&amp;#34;,&amp;#34;60&amp;#34;,&amp;#34;999&amp;#34; &amp;#34;2021-02-01&amp;#34;,&amp;#34;3&amp;#34;,&amp;#34;30&amp;#34;,&amp;#34;999&amp;#34; &amp;#34;2021-02-02&amp;#34;,&amp;#34;1&amp;#34;,&amp;#34;100&amp;#34;,&amp;#34;555&amp;#34; &amp;#34;2021-02-02&amp;#34;,&amp;#34;1&amp;#34;,&amp;#34;400&amp;#34;,&amp;#34;555&amp;#34; &amp;#34;2021-02-02&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;500&amp;#34;,&amp;#34;777&amp;#34; &amp;#34;2021-02-02&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;200&amp;#34;,&amp;#34;777&amp;#34; &amp;#34;2021-02-02&amp;#34;,&amp;#34;3&amp;#34;,&amp;#34;600&amp;#34;,&amp;#34;999&amp;#34; &amp;#34;2021-02-02&amp;#34;,&amp;#34;3&amp;#34;,&amp;#34;300&amp;#34;,&amp;#34;999&amp;#34; &amp;#34;2021-02-03&amp;#34;,&amp;#34;1&amp;#34;,&amp;#34;1&amp;#34;,&amp;#34;555&amp;#34; &amp;#34;2021-02-03&amp;#34;,&amp;#34;1&amp;#34;,&amp;#34;4&amp;#34;,&amp;#34;555&amp;#34; &amp;#34;2021-02-03&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;5&amp;#34;,&amp;#34;777&amp;#34; &amp;#34;2021-02-03&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;777&amp;#34; &amp;#34;2021-02-03&amp;#34;,&amp;#34;3&amp;#34;,&amp;#34;6&amp;#34;,&amp;#34;999&amp;#34; &amp;#34;2021-02-03&amp;#34;,&amp;#34;3&amp;#34;,&amp;#34;3&amp;#34;,&amp;#34;999&amp;#34; ORDER BY (+ RANGE) ソートし範囲を絞って集計する。 デフォルトの集計範囲は RANGE UNBOUNDED PRECEDING なので、次の例はそれまでの値の行で集計されている。</description>
    </item>
    
    <item>
      <title>Amazon Forecastで時系列データの予測を行う</title>
      <link>https://www.sambaiz.net/article/327/</link>
      <pubDate>Sun, 21 Feb 2021 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/327/</guid>
      <description>Amazon Forecastは機械学習によって時系列データの予測を行うマネージドサービス。 ドメインやアルゴリズムを選んでデータを投入すればそれらしい出力が得られる。 まずこれで予測してみて、その結果をベースラインとしてSageMakerなどで自作したモデルを評価するといった使い方もできる。
SageMakerでPyTorchのモデルを学習させる - sambaiz-net
料金はデータストレージに$0.088/GB、学習に$0.24/hour、予測に$0.60/1000回かかる。
今回は開発者ガイドと同じく 電力消費量のデータセットを用いて動かしてみる。
$ head electricityusagedata.csv 2014-01-01 01:00:00,2.53807106598985,client_0 2014-01-01 01:00:00,23.648648648648624,client_1 2014-01-01 01:00:00,0.0,client_2 2014-01-01 01:00:00,144.81707317073176,client_3 ... データのインポート まずドメインを選んでDataset groupを作成する。Dataset groupには予測対象の時系列データに加えて、他の関連する時系列データやメタデータを含めることができる。
CSVをS3に置き、それを読めるRoleを渡してインポートする。データの間隔とカラムの順は元データと合致するように設定する。 タイムスタンプは yyyy-MM-dd か yyyy-MM-dd HH:mm:ss の形式である必要がある。
学習 インポートが終わるとTrain predictorできるようになる。 予測の間隔と期間を設定し、アルゴリズムを、AutoMLか、ARIMAやCNN-QRといったものの中からマニュアルで選んで学習を始める。
時系列データのMAモデルとARモデル、その定常性と反転可能性 - sambaiz-net
ハイパーパラメータの最適化や、国ごとの祝日や天気を考慮するオプションもある。
予測 学習が終わるとCreate a forecastして予測値を得られる。
Goでの取得はこんな感じ。
package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/forecastqueryservice&amp;#34; ) func main() { mySession := session.Must(session.NewSession()) svc := forecastqueryservice.New(mySession) ctx := context.TODO() output, err := svc.</description>
    </item>
    
    <item>
      <title>偽陽性を許容して空間効率良くキーの存在を確認するBloom filterとCuckoo filter</title>
      <link>https://www.sambaiz.net/article/326/</link>
      <pubDate>Wed, 17 Feb 2021 02:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/326/</guid>
      <description>例えばデータストアへのアクセス抑制のためにキーの存在を確認する際、 全てのキーを保持して探索すれば100%正しく判定できるが、キーが長く数が膨大になるとメモリの使用量が問題になることがある。 もし偽陽性が許容できるなら、次のフィルタを使うことで空間効率良くキーの存在を確認できる。
Bloom filter 1970年に考案されたフィルタで、 LevelDBやCassandraで使われている。
GoogleのkvsライブラリLevelDBを使う - sambaiz-net
初期値0のビット配列と、そのいずれかのビットにデータをマッピングするk個のハッシュ関数を定義し、 含めるデータを各ハッシュ関数に通して、マッピングされたビットを1に更新していく。 これにより、いずれかのハッシュ関数によって0のビットにマッピングされるデータは、必ずフィルタに含まれないことが分かる。 また、ビット配列のANDを取れば和集合のフィルタになる。
データの追加と存在の確認を、いずれも要素数に依存しないO(k)で行うことができるが、削除はできない。 0/1ではなくインクリメントしていくCounting filterという実装にすると空間効率は劣るが、デクリメントすることで削除できるようになる。
偽陽性率はビット配列長を大きくすると低くなり、データの数が増えると高くなる。 kはビット配列の情報量を最大化させる、つまり半分のビットが1になるように最適化する。
自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net
Goのwillf/bloomで作成したBloom filterにデータを追加し存在を確認しているのが次のコード。 ハッシュ関数にはpybloomfiltermmap3などと同じくMurmurHash3が用いられている。
package main import ( &amp;#34;encoding/binary&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;github.com/willf/bitset&amp;#34; &amp;#34;github.com/willf/bloom&amp;#34; ) func bits(filter *bloom.BloomFilter) []uint64 { r, w := io.Pipe() ret := []uint64{} wg := &amp;amp;sync.WaitGroup{} wg.Add(1) go func() { var m, k uint64 if err := binary.Read(r, binary.BigEndian, &amp;amp;m); err != nil { panic(err) } if err := binary.</description>
    </item>
    
    <item>
      <title>PythonのProtocolによるstructural subtypingでインタフェースを記述する</title>
      <link>https://www.sambaiz.net/article/325/</link>
      <pubDate>Fri, 12 Feb 2021 02:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/325/</guid>
      <description>interfaceが文法に存在しないPythonで関数が呼べることを保証する方法の一つに 組み込み関数hasattr()によるチェックがあるが、 都度処理を挟む必要があるのと、実行してみないと分からない問題があった。
class ImplClass(): def foo(self): print(&amp;#34;ok&amp;#34;) class NoImplClass(): pass def call(d): assert hasattr(d, &amp;#39;foo&amp;#39;) d.foo() if __name__ == &amp;#34;__main__&amp;#34;: call(ImplClass()) # =&amp;gt; ok call(NoImplClass()) # =&amp;gt; AssertionError Python 3.5で実装されたType Hintsで共通の基底クラスを型として取れば実行前にmypyによる静的解析で検知できるが、サブクラスでの実装は強制できない。
PythonのType Hintsとmypy - sambaiz-net
class BaseClass: def foo(self): print(&amp;#34;please implement this&amp;#34;) class ImplClass(BaseClass): def foo(self): print(&amp;#34;ok&amp;#34;) class NoImplClass(BaseClass): pass def call(d: BaseClass): d.foo() if __name__ == &amp;#34;__main__&amp;#34;: call(BaseClass()) # =&amp;gt; please implement this call(ImplClass()) # =&amp;gt; ok call(NoImplClass()) # =&amp;gt; please implement this それを解決するのがPEP3119のAbstract Base Classesで、 次のようにabc.</description>
    </item>
    
    <item>
      <title>Kinesis Data Analyticsによる集計遅延箇所の特定</title>
      <link>https://www.sambaiz.net/article/324/</link>
      <pubDate>Sun, 07 Feb 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/324/</guid>
      <description>Kinesis Data Analytics (KDA)はマッピングしたカラムに加えて、Kinesis Data Streams (KDS)に入った時間 APPROXIMATE_ARRIVAL_TIME とKDAのin-app STREAMに入った時間 ROWTIME をソースに含める。これらとログのタイムスタンプを合わせることで集計遅延が起きた際にどこが原因になっているかを特定することができる。
Log aggregatorでのタイムスタンプの付加 集計対象のログを集約サーバーを中継して送っている場合、そこでのタイムスタンプを付加しておくとバッファリングによる滞りを検知できる。 fluentdのmonitor_agentの値をDatadogなどに送って監視することもできるが、 集計ウィンドウが短い場合、collection_intervalの関係で、正確な状態を把握しづらいことがある。
fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する - sambaiz-net
レコードへの付加にはfluentdのコアに含まれているrecord_transformerを使うこともできるが、性能が良いfluent-plugin-record-modifierという選択肢もある。
fluentdのrecord_transformerでログを加工する - sambaiz-net
&amp;lt;filter test.log&amp;gt; @type record_modifier &amp;lt;record&amp;gt; ts_aggr ${Time.now().strftime(&amp;#39;%Y-%m-%dT%H:%M:%S.%L%z&amp;#39;)} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; また、ログのタイムスタンプをtime_keyとしている場合、keep_time_key trueにするか&amp;lt;inject&amp;gt;してKDSに送られるようにする。
fluentdのとでtime_formatを指定しなかった場合の挙動と内部処理 - sambaiz-net
TIMESTAMPのパース タイムスタンプ文字列をTIMESTAMP型のカラムにマッピングすることもできるが、2021-01-01T00:00:00.000+0900形式の文字列をマッピングしたところ、UTCで18時間後ろにずれた時間になってしまった。
そこで一度CHARにマッピングしてからフォーマットを明示してCHAR_TO_TIMESTAMP(&#39;&amp;lt;format_string&amp;gt;&#39;,&amp;ldquo;column_name&amp;rdquo;)することにした。 &amp;lt;format_string&amp;gt;はJavaのSimpleDateFormatで記述し、この例の場合はyyyy-MM-dd&#39;&#39;T&#39;&#39;HH:mm:ss.SSSZのようになる。
マッピングの変更後にSourcesの方に何も出てこなくなった場合は、クエリの方で問題が起きている可能性があるので、コンソール上でクエリを保存してみてエラーにならないか確認し、必要なら修正する。
クエリ Kinesis Data AnalyticsのSQL, Lambdaへの出力とCDKによるリソースの作成 - sambaiz-net
各タイムスタンプのMINを取って現在時刻との差を取れば、そのウインドウ集計対象のログのうち最も古いものの各箇所からのレイテンシが出せる。
CREATE OR REPLACE PUMP &amp;#34;TEST_PUMP&amp;#34; AS INSERT INTO &amp;#34;TEST_STREAM&amp;#34; (&amp;#34;min_ts&amp;#34;, &amp;#34;min_ts_kds&amp;#34;, &amp;#34;min_ts_kda&amp;#34;) SELECT STREAM MIN(CHAR_TO_TIMESTAMP(&amp;#39;yyyy-MM-dd&amp;#39;&amp;#39;T&amp;#39;&amp;#39;HH:mm:ss.SSSZ&amp;#39;, &amp;#34;ts&amp;#34;)) as min_ts, MIN(&amp;#34;APPROXIMATE_ARRIVAL_TIME&amp;#34;) as min_ts_kds, &amp;#34;ROWTIME&amp;#34; as min_ts_kda FROM &amp;#34;SOURCE_SQL_STREAM_001&amp;#34; GROUP BY STEP(&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;.</description>
    </item>
    
    <item>
      <title>Pythonのmoduleとpackage</title>
      <link>https://www.sambaiz.net/article/323/</link>
      <pubDate>Sat, 23 Jan 2021 19:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/323/</guid>
      <description>6. モジュール — Python 3.9.1 ドキュメント
Pythonではファイル名がそのままimportするmodule名となり、グローバル変数__name__にその名前が入る。 エントリーポイントではこれが__main__となるので、if __name__ == &amp;quot;__main__&amp;quot;:のようにしてimportした場合は実行されないコードが書ける。
moduleをコンパイルしたpycファイルは__py_cache__にキャッシュされ、ソースの変更日時を見て再利用される。
$ cat foo.py def bar(): print(&amp;#34;hello&amp;#34;) def _bar(): print(&amp;#34;world&amp;#34;) print(&amp;#34;aaaa&amp;#34;) $ python Python 3.9.0 (default, Nov 21 2020, 14:01:50) [Clang 12.0.0 (clang-1200.0.32.27)] on darwin Type &amp;#34;help&amp;#34;, &amp;#34;copyright&amp;#34;, &amp;#34;credits&amp;#34; or &amp;#34;license&amp;#34; for more information. &amp;gt;&amp;gt;&amp;gt; import foo as f aaaa &amp;gt;&amp;gt;&amp;gt; f.__name__ foo &amp;gt;&amp;gt;&amp;gt; f.bar() hello &amp;gt;&amp;gt;&amp;gt; f._bar() world from module import *でimportすると関数外のコードは実行されず、_から始まる関数はimportされない。
&amp;gt;&amp;gt;&amp;gt; from foo import * &amp;gt;&amp;gt;&amp;gt; bar() hello &amp;gt;&amp;gt;&amp;gt; _bar() Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; NameError: name &amp;#39;_bar&amp;#39; is not defined &amp;gt;&amp;gt;&amp;gt; from foo import _bar &amp;gt;&amp;gt;&amp;gt; _bar() world packageはmoduleをまとめたもので、そのディレクトリ名の名前空間を作る。</description>
    </item>
    
    <item>
      <title>fluentdの&lt;parse&gt;と&lt;inject&gt;でtime_formatを指定しなかった場合の挙動と内部処理</title>
      <link>https://www.sambaiz.net/article/322/</link>
      <pubDate>Sat, 23 Jan 2021 00:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/322/</guid>
      <description>挙動 fluent/fluentdのDockerイメージで試す。
$ vi fluent.conf &amp;lt;source&amp;gt; @type tail path /home/fluent/test.log pos_file /home/fluent/test.log.pos tag test.log &amp;lt;parse&amp;gt; @type json time_key ts time_type string &amp;lt;/parse&amp;gt; &amp;lt;/source&amp;gt; &amp;lt;match test.log&amp;gt; @type stdout &amp;lt;inject&amp;gt; time_key ts2 time_type string &amp;lt;/inject&amp;gt; &amp;lt;/match&amp;gt; $ touch test.log $ docker run -it --rm -v $(pwd)/fluent.conf:/fluentd/etc/fluent.conf -v $(pwd)/test.log:/home/fluent/test.log fluent/fluentd:v1.12-1 # echo &amp;#39;{&amp;#34;ts&amp;#34;: &amp;#34;2021-01-01T01:23:45&amp;#34;, &amp;#34;data&amp;#34;: 123}&amp;#39; &amp;gt;&amp;gt; test.log 2021-01-01 01:23:45.000000000 +0000 test.log: {&amp;#34;data&amp;#34;:123,&amp;#34;ts2&amp;#34;:&amp;#34;2021-01-01T01:23:45+00:00&amp;#34;} # echo &amp;#39;{&amp;#34;ts&amp;#34;: &amp;#34;2021-01-01T01:23:45&amp;#34;, &amp;#34;data&amp;#34;: 123}&amp;#39; &amp;gt;&amp;gt; test.log 2021-01-01 01:23:45.000000000 +0000 test.</description>
    </item>
    
    <item>
      <title>剰余を取った値の四則演算</title>
      <link>https://www.sambaiz.net/article/321/</link>
      <pubDate>Sat, 16 Jan 2021 18:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/321/</guid>
      <description>競プロの64bit整数でもオーバーフローする大きな値が出てくる問題では、言語による差が出ないよう 10^9+7 といった数で割ったときの余りが要求される。
四則演算の内、割り算以外は各項の剰余を取ってから計算してもその剰余の値は変わらないので、都度剰余を取ってオーバーフローを回避できる。
#include &amp;lt;bits/stdc++.h&amp;gt;using namespace std; int mod(int a, int n) { int x = a % n; if (x &amp;gt;= 0) { return x; } else { return n + x; } } int main() { int X = 7; int Y = 9; int Z = 5; // (AZ + B) + (CZ + D) = (A+C)Z + (B+D) ≡ B+D (mod Z)  cout &amp;lt;&amp;lt; mod(X + Y, Z) &amp;lt;&amp;lt; endl; // 1  cout &amp;lt;&amp;lt; mod(X, Z) + mod(Y, Z) &amp;lt;&amp;lt; endl; // 6  cout &amp;lt;&amp;lt; mod(mod(X, Z) + mod(Y, Z), Z) &amp;lt;&amp;lt; endl; // 1  // (AZ + B) - (CZ + D) = (A-C)Z + (B-D) ≡ B-D (mod Z)  cout &amp;lt;&amp;lt; mod(X - Y, Z) &amp;lt;&amp;lt; endl; // 3  cout &amp;lt;&amp;lt; mod(X, Z) - mod(Y, Z) &amp;lt;&amp;lt; endl; // -1  cout &amp;lt;&amp;lt; mod(mod(X, Z) - mod(Y, Z), Z) &amp;lt;&amp;lt; endl; // 3  // (AZ + B) * (CZ + D) = (ACZ+AD+BC)Z + (BD) ≡ BD (mod Z)  cout &amp;lt;&amp;lt; mod(X * Y, Z) &amp;lt;&amp;lt; endl; // 2  cout &amp;lt;&amp;lt; mod(X, Z) + mod(Y, Z) &amp;lt;&amp;lt; endl; // 6  cout &amp;lt;&amp;lt; mod(mod(X, Z) * mod(Y, Z), Z) &amp;lt;&amp;lt; endl; // 3  return 0; } 割り算は b^{-1}b ≡ 1 (mod n) となるようなモジュラ逆数b^{-1}があれば、a/b ≡ (a mod n)(b^{-1} mod n) (mod n)が成り立つ。bとnが互いに素(gcd(b,n)=1)であることが必要十分条件。 モジュラ逆数を計算する方法としては、mx + ny = gcd(m, n) の解 x, y が得られる、拡張されたユークリッドの互除法などがあり、これにより bx - ny = 1 のxを求める。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;で標準入力から数が不定なスペース区切りの文字列を読み込んで分割する</title>
      <link>https://www.sambaiz.net/article/320/</link>
      <pubDate>Tue, 12 Jan 2021 21:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/320/</guid>
      <description>std::getline(basic_istream, basic_string, delim)を使う。 第三引数delimかEOFに達するとそこまでの文字列を出力する。delimを渡さないとis.widen(&#39;\n&#39;)となり一行読む。 一度stringstreamにしているのは、getline(cin, s, &#39; &#39;) のように直接読み込もうとすると最後の文字列の後にdelimもEOFも来ずに止まってしまうため。
#include &amp;lt;bits/stdc++.h&amp;gt;using namespace std; int main() { string s; getline(cin, s); stringstream ss(s); while (getline(ss, s, &amp;#39; &amp;#39;)) { cout &amp;lt;&amp;lt; s &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; endl; } return 0; } </description>
    </item>
    
    <item>
      <title>ウェブアプリとしてデプロイしたGASをブラウザからAPIとして呼ぶ際のCORSエラー</title>
      <link>https://www.sambaiz.net/article/319/</link>
      <pubDate>Wed, 23 Dec 2020 08:41:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/319/</guid>
      <description>GASでAPIを公開する方法として、scripts.run APIで実行できる実行可能APIと、ウェブアプリがある。 前者は認証が走り実行者の権限で動くが、後者は認証を行わずデプロイユーザーの権限で動かすこともできるのでパブリックなAPIとして使うことができる。 当然、不正な操作が行われないように注意する必要があり、GASのQuotaやhard limitも気にする必要がある。無料で運用することができるが、レイテンシやエラーハンドリング、監視などを考えるとやや心許ない。
ウェブアプリではdoGet(e)とdoPost(e)を実装することでそれぞれのメソッドのリクエストをハンドリングできる。これ以外のメソッドには対応していない。
function doGet(e) { return ContentService.createTextOutput(JSON.stringify(e.parameter)) } function doPost(e) { return ContentService.createTextOutput(e.postData.contents) } claspでデプロイする際は一度画面上でウェブアプリとして公開した後、そのDeplymentsを更新するとそのまま反映できる。ただしDeploymentsに紐づくVersionに限りがあるので一旦undeployしている。
claspでGoogle Apps Scriptをローカルで開発しデプロイする - sambaiz-net
$ clasp push &amp;amp;&amp;amp; clasp undeploy --all &amp;amp;&amp;amp; clasp deploy -V 1 ウェブアプリのURLにリクエストを送ると https://script.googleusercontent.com/macros/echo?user_content_key=**** にリダイレクトするので、curlでリクエストする際は-Lフラグを付ける必要がある。 また、POSTする際は-X POSTを付けるとステータスコードに関わらずリダイレクト先にPOSTでリクエストし、Not Foundとなってしまうので付けない。
$ curl -L https://script.google.com/macros/s/*****/exec?aaa=bbb {&amp;#34;aaa&amp;#34;:&amp;#34;bbb&amp;#34;} $ $ curl -d &amp;#39;aaaa&amp;#39; -L https://script.google.com/macros/s/*****/exec &amp;#34;aaaa&amp;#34; GETとPOSTしか対応してないということは、OPTIONSメソッドによるCORSのpreflightリクエストも送れないということになる。 したがって、preflightリクエストが送られないように、余分なHeaderを付けずに Content-Typeをapplication/x-www-form-urlencoded、multipart/form-data、text/plainのいずれかで送る必要がある。 Request.modeをno-corsにすると送られるHeaderが制限されてエラーにはならなくなるが、レスポンスをスクリプトから取ることができない。
$ cat test.html &amp;lt;script&amp;gt; (async () =&amp;gt; { const resp = await fetch(&amp;#39;https://script.</description>
    </item>
    
    <item>
      <title>CDKでCognito UserPoolとClientを作成しトリガーやFederationを設定する</title>
      <link>https://www.sambaiz.net/article/318/</link>
      <pubDate>Sun, 06 Dec 2020 18:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/318/</guid>
      <description>CloudFormationでCognito UserPoolを作成すると、以前はドメインやFederationの設定などを手作業で行う必要があったが、 去年の10月に諸々のリソースが追加され、その必要がなくなった。
API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く - sambaiz-net
今回はCDKの高レベルAPIを用いて、UserPoolとClientを作成し、トリガーやGoogleのFederationの設定を行って、特定のGoogleアカウントでのみ登録されるようにする。 全体のコードはGitHubにある。
Cognito UserPoolのPreSignUp時に呼ばれるLambdaで登録ユーザーを制限する - sambaiz-net
UserPool 事前にdomainPrefixを決めておき、OAuthのclient_idとsecretをSecretsManagerに置いておく。
standardAttributesと、ログイン時にusernameの代わりとなるsignInAliasesは後から変更できない。 変更してデプロイしてもreplaceではなくエラーになってしまう。 トリガーのruntimeはCDKと同じNodeにしても良いがバージョンのライフサイクルが早く追従するのが大変なのでGoにしている。
private createUserPool(userPoolName: string, domainPrefix: string, signUpAllowEmails: string[]): UserPool { const userPool = new UserPool(this, &amp;#39;UserPool&amp;#39;, { userPoolName, standardAttributes: { email: { required: true, mutable: true }, fullname: { required: true, mutable: true }, }, signInAliases: { username: true, email: true }, lambdaTriggers: { preSignUp: new Function(this, &amp;#39;PreSignUpFunction&amp;#39;, { runtime: Runtime.GO_1_X, code: Code.fromAsset(path.join(__dirname, &amp;#39;userPoolTrigger&amp;#39;)), handler: &amp;#34;preSignUp.</description>
    </item>
    
    <item>
      <title>IstioのSidecarでmTLS認証を行いServiceAccountによるアクセス制御を行う</title>
      <link>https://www.sambaiz.net/article/317/</link>
      <pubDate>Fri, 04 Dec 2020 12:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/317/</guid>
      <description>mTLS (Mutual TLS)認証は、RFC8705に記載されている、TLSハンドシェイクの際にサーバーからだけではなくクライアントからも証明書を送ることで相互に認証を行う手法。クライアントは事前に自身の秘密鍵で生成したCSRをサーバーに送り、サーバーがルート認証局となって発行した証明書を取得しておく。 KubernetesではIstioのSidecarを通すことで透過的にmTLS認証を行うことができる。 実際に試してみる。なお、証明書はEnvoy SDS(secret discovery service) APIのリクエストによってCSRが定期的にistiodに送られて発行、更新されるらしい。
Istio OperatorでIstioをインストールする。 以前はHelmで入れていたが今はこれがベストプラクティスのようだ。
IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net
$ curl -L https://istio.io/downloadIstio | sh - $ istio-1.8.0/bin/istioctl version no running Istio pods in &amp;#34;istio-system&amp;#34; 1.8.0 $ istioctl operator init Installing operator controller in namespace: istio-operator using image: docker.io/istio/operator:1.8.0 Operator controller will watch namespaces: istio-system ✔ Istio operator installed ✔ Installation complete $ kubectl get pods --namespace istio-operator NAME READY STATUS RESTARTS AGE istio-operator-76766bc79-lfm49 1/1 Running 0 2m32s $ kubectl create ns istio-system $ kubectl apply -f - &amp;lt;&amp;lt;EOF apiVersion: install.</description>
    </item>
    
    <item>
      <title>EKSにKubeflowをインストールする</title>
      <link>https://www.sambaiz.net/article/316/</link>
      <pubDate>Sun, 29 Nov 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/316/</guid>
      <description>Kubernetes上で機械学習を行うためのツールキットKubeflowを EKSにインストールする。 m5.large * 4のクラスタをCDKで作成した。
CDKでEKSクラスタの作成からHelm ChartでのLocustのインストールまでを一気に行う - sambaiz-net
まずKubeflowのCLIツールkfctlをインストールする。 内部でeksctlが呼ばれるがフラグでprofileを指定できないので環境変数に入れておく。
$ curl -L https://github.com/kubeflow/kfctl/releases/download/v1.2.0/kfctl_v1.2.0-0-gbc038f9_darwin.tar.gz &amp;gt; kfctl.tar.gz $ tar -xvf kfctl.tar.gz $ ./kfctl version kfctl v1.2.0-0-gbc038f9 $ eksctl version 0.32.0 $ export AWS_PROFILE=*** AWS用の設定ファイルを持ってきて、RegionやRole、Cognito UserPoolあるいはusernameとpasswordによる認証の設定をKfAwsPluginに書く。UserPoolの作成もCDKで行える。それとACMで証明書を発行しておく。
CDKでCognito UserPoolとClientを作成しトリガーやFederationを設定する - sambaiz-net
AWSのサービスにアクセスするのにServiceAccountに関連づけられたRoleを用いる場合はenablePodIamPolicy: trueにして、ワーカーノードのRoleを用いる場合はrolesにそのロール名を書く。 KfDefにはManifestごとのKustomizeに関する設定が並んでいるがそのままで問題ない。
kustomizeでkubernetesのmanifestを環境ごとに生成する - sambaiz-net
$ mkdir &amp;lt;cluster_name&amp;gt; &amp;amp;&amp;amp; cd &amp;lt;cluster_name&amp;gt; $ curl -L https://raw.githubusercontent.com/kubeflow/manifests/v1.1-branch/kfdef/kfctl_aws_cognito.v1.2.0.yaml &amp;gt; kfctl_aws.yaml $ cat kfctl_aws.yaml apiVersion: kfdef.apps.kubeflow.org/v1 kind: KfDef metadata: namespace: kubeflow spec: applications: - kustomizeConfig: repoRef: name: manifests path: namespaces/base name: namespaces .</description>
    </item>
    
    <item>
      <title>claspでGoogle Apps Scriptをローカルで開発しデプロイする</title>
      <link>https://www.sambaiz.net/article/315/</link>
      <pubDate>Sun, 29 Nov 2020 14:42:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/315/</guid>
      <description>claspはGASをローカルで開発するための公式のツール。
$ npm install -g @google/clasp $ clasp --version 2.3.0 設定でGASのAPIを有効にしてログインし、必要な権限を許可する。
$ clasp login $ cat ~/.clasprc.json {&amp;#34;token&amp;#34;:{&amp;#34;access_token&amp;#34;:&amp;#34;... clasp createでプロジェクトを作成する。typeを指定するとドキュメントが作られ、スクリプトがそれに紐づく。 紐づいているスクリプトからはSpreadsheetApp.getActiveSpreadsheet()のようにIDを指定することなくドキュメントを参照できる。
$ clasp create --type sheets --title &amp;#34;clasp test&amp;#34; Created new Google Sheet: https://drive.google.com/open?id=***** Created new Google Sheets Add-on script: https://script.google.com/d/*****/edit Warning: files in subfolder are not accounted for unless you set a &amp;#39;.claspignore&amp;#39; file. Cloned 1 file. └─ appsscript.json $ tree -a . ├── .clasp.json └── appsscript.json $ cat .</description>
    </item>
    
    <item>
      <title>GmailのSMTPサーバーにコマンドを送ってメールを送信する</title>
      <link>https://www.sambaiz.net/article/313/</link>
      <pubDate>Sat, 28 Nov 2020 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/313/</guid>
      <description>SMTP (Simple Mail Transfer Protocol) SMTPはメールクライアントからサーバーへ、あるいはサーバー間でメールを送信する際のプロトコル。 受信する際のプロトコルとしては、認証とメールのダウンロード・削除を行うPOP (Post Office Protocol) や、 複数の環境から見ることを想定した、サーバーのメールボックスを管理しアクセスするIMAP (Internet Message Access Protocol) がある。
SMTP標準には認証の仕組みが含まれておらず、以前はPOPの認証が用いられていたが、現在はSMTP-AUTHという拡張が標準化されて用いられている。 SMTPでは通常25番ポートを使うが、スパムメール対策としてプロバイダがOP25B(Outbound Port 25 Blocking)を行うようになったので、 メールクライアントからサーバーへの通信はSMTP-AUTHの認証がかかる587や465番ポートで行われる。これらのポートはサブミッションポートと呼ばれる。
通信はテキストで行われ、HELO example.comのようなコマンドを送ると250 smtp.gmail.com at your serviceのようなリプライコードとメッセージが返ってくる。
telnetでのメール送信(失敗) telnetでGmailのSMTPサーバーにコマンドを送ってみる。
DNSのMXレコードで返ってきたアドレスに接続しようとしたが、これらはサーバー間のリレー専用のようでサブミッションポートが空いていなかった。 なので接続する先はドキュメントに書いてあるsmtp.gmail.com。
$ dig gmail.com mx +short 10 alt1.gmail-smtp-in.l.google.com. 20 alt2.gmail-smtp-in.l.google.com. 30 alt3.gmail-smtp-in.l.google.com. 40 alt4.gmail-smtp-in.l.google.com. 5 gmail-smtp-in.l.google.com. $ telnet alt1.gmail-smtp-in.l.google.com. 587 ... telnet: Unable to connect to remote host 接続が完了すると220(Service ready)とメッセージが送られてきた。 HELOコマンドでクライアントのドメイン名を送ると250(Requested mail action okay, completed)が返った。 続けてMAILコマンドで送信元のアドレスを送ったところSTARTTLSでTLS接続に切り替えることを要求されたので実行すると サーバーからレスポンスが返ってきた後、TLSで再接続できずにコネクションが切れてしまった。 telnetはTLSハンドシェイクをサポートしていないのでここまで。</description>
    </item>
    
    <item>
      <title>makeで環境変数とMakefileの変数、引数の値の内どの値が参照されるか</title>
      <link>https://www.sambaiz.net/article/314/</link>
      <pubDate>Sat, 28 Nov 2020 16:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/314/</guid>
      <description>$ docker run -v `pwd`:/root -it ubuntu:20.04 /bin/sh # apt update &amp;amp;&amp;amp; apt install -y make # make --version GNU Make 4.2.1 Built for x86_64-pc-linux-gnu # cat Makefile HOGE:=aaa foo: echo $(HOGE) $(FUGA) &amp;gt; /dev/null フラグを付けないと引数の値 -&amp;gt; Makefileの変数 -&amp;gt; 環境変数の順で参照されるので、 makeの前に書いた変数は環境変数となりMakefileの変数を上書きできないが、後に書いて引数とすると上書きできる。
# export HOGE=ccc FUGA=ddd # make foo echo aaa ddd &amp;gt; /dev/null # HOGE=bbb FUGA=xxx make foo echo aaa xxx &amp;gt; /dev/null # make foo HOGE=bbb FUGA=xxx echo bbb xxx &amp;gt; /dev/null -eフラグを付けて実行すると環境変数の値がMakefileの変数よりも優先して参照される。</description>
    </item>
    
    <item>
      <title>GoのSheets API v4クライアントでSpreadsheetを読み書きする</title>
      <link>https://www.sambaiz.net/article/312/</link>
      <pubDate>Mon, 23 Nov 2020 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/312/</guid>
      <description>まずGCPのコンソールでプロジェクトを作成するか選んでGoogle Sheets APIを有効にする。 料金はかからないが、デフォルトのQuotaが、100秒ごとに100リクエスト/ユーザー、500リクエスト/プロジェクトとなっている。
OAuth 2.0で得たユーザーの権限でAPIを呼ぶこともできるが、今回はサービスアカウントを用いる。ロールは付与する必要はなく、対象のSheetの共有先に追加すればよい。 JWTの署名に用いる秘密鍵をダウンロードしておく。
OpenID ConnectのIDトークンの内容と検証 - sambaiz-net
全体のコードはGitHubにある。
クライアントの準備 サービスアカウントでアクセストークンを取得するにはJWTを認可サーバーに送る必要があるが、JWTをアクセストークンの代わりに用いることができるのでそうしている。
SpreadsheetIDはURLから得られる。
package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;os&amp;#34; &amp;#34;golang.org/x/oauth2/google&amp;#34; &amp;#34;google.golang.org/api/sheets/v4&amp;#34; ) type SheetClient struct { srv *sheets.Service spreadsheetID string } func NewSheetClient(ctx context.Context, spreadsheetID string) (*SheetClient, error) { b, err := ioutil.ReadFile(&amp;#34;secret.json&amp;#34;) if err != nil { return nil, err } // read &amp;amp; write permission 	jwt, err := google.JWTConfigFromJSON(b, &amp;#34;https://www.googleapis.com/auth/spreadsheets&amp;#34;) if err != nil { return nil, err } srv, err := sheets.</description>
    </item>
    
    <item>
      <title>kustomizeでkubernetesのmanifestを環境ごとに生成する</title>
      <link>https://www.sambaiz.net/article/311/</link>
      <pubDate>Sun, 22 Nov 2020 19:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/311/</guid>
      <description>Kustomizeはk8sのmanifestを生成するツールでkubectlに統合されている。Helmやksonnetのようにテンプレートからではなく、kusomization.yaml以外は素のmanifestをソースとするのでツール独自の記法を覚えたり変換したりする必要がない。
KubernetesのパッケージマネージャーHelmを使う - sambaiz-net
ksonnetでkubernetesのmanifestを環境ごとに生成/applyする - sambaiz-net
kustomization.yamlには対象とするresources、共通のnamespace, label, prefixやパッチなどを記述する。
$ tree . |-- deployment.yaml `-- kustomization.yaml $ cat kustomization.yaml resources: - deployment.yaml commonLabels: foo: bar $ cat deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx name: nginx-deployment spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - image: nginx:1.14.2 name: nginx ports: - containerPort: 80 kubectl kustomize でkustomize適用後のyamlをstdoutに出力し、kubectl apply -kで直接applyできる。 出力を見ると commonLabels の foo: bar labelが追加されている。</description>
    </item>
    
    <item>
      <title>GitHub ActionsのDocker container actionを作る</title>
      <link>https://www.sambaiz.net/article/310/</link>
      <pubDate>Sun, 22 Nov 2020 01:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/310/</guid>
      <description>GitHub ActionsのActionにはランナーで直接実行されるJavaScript actionと、Docker container action、複数のステップをまとめたComposite run steps actionがある。 Docker container actionは環境を固定できるが、イメージを取得する分JavaScript actionと比べて時間がかかり、DockerがインストールされているLinuxでしか使えない。 今回はこのDocker container actionを作って動かしてみる。
Dockerfileとメタデータのaction.ymlを用意する。 using: &#39;docker&#39; にするとDocker container actionになる。
::set-output name={name}::{value}の文字列をstdoutに出力するとoutputsのパラメータに値がセットされる。
$ cat Dockerfile FROM alpine:20200917 ENTRYPOINT [&amp;#34;echo&amp;#34;, &amp;#34;::set-output name=return-json::&amp;#34;] $ cat action.yml name: &amp;#39;sambaiz-test-docker-github-action&amp;#39; description: &amp;#39;Echo your word&amp;#39; inputs: i-say: description: &amp;#39;What do you say?&amp;#39; required: true default: &amp;#39;{}&amp;#39; outputs: return-word: description: &amp;#39;return word you said&amp;#39; runs: using: &amp;#39;docker&amp;#39; image: &amp;#39;Dockerfile&amp;#39; args: - ${{ inputs.i-say }} usesにはリポジトリではなくパスを渡すこともできるので、次のようなワークフローで試しに実行できる。</description>
    </item>
    
    <item>
      <title>GoでAthenaのクエリを実行する</title>
      <link>https://www.sambaiz.net/article/309/</link>
      <pubDate>Sat, 14 Nov 2020 16:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/309/</guid>
      <description>segmentio/go-athenaを使う。database/sqlのドライバーとして提供されていて、 StartQueryExecution()と stateのポーリング、 値のキャストを行う。
package main import ( &amp;#34;database/sql&amp;#34; &amp;#34;errors&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/sts&amp;#34; _ &amp;#34;github.com/segmentio/go-athena&amp;#34; ) func outputLocation() (string, error) { svc := sts.New(session.Must(session.NewSession())) result, err := svc.GetCallerIdentity(&amp;amp;sts.GetCallerIdentityInput{}) if err != nil { return &amp;#34;&amp;#34;, err } if result.Account == nil || svc.Config.Region == nil { return &amp;#34;&amp;#34;, errors.New(&amp;#34;account or region is nil&amp;#34;) } return fmt.Sprintf(&amp;#34;s3://aws-athena-query-results-%s-%s&amp;#34;, *result.Account, *svc.Config.Region), nil } func execute(query string) (*sql.Rows, error) { loc, err := outputLocation() if err !</description>
    </item>
    
    <item>
      <title>GitHub ActionsでPRのコメントに返事を返すbotを動かす</title>
      <link>https://www.sambaiz.net/article/308/</link>
      <pubDate>Tue, 10 Nov 2020 09:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/308/</guid>
      <description>APIトークン コメントを投稿するAPIを呼ぶためにトークンが必要だが、GitHub Actionsのジョブの実行中有効なGitHub Appトークンが自動生成され、${{secrets.GITHUB_TOKEN}}で参照できるのでこれを使う。 このトークンによるイベントではワークフローが発火しないので無限ループの心配がない。
AWS SAMとGoでPRのコメントに対して返事を返すGitHub Appを作る - sambaiz-net
リポジトリに対して大方の権限は付いているが、フォークしたリポジトリからはreadしかできないようになっている。
actions/github-script octokit/core.jsを用いたGitHub APIを呼ぶスクリプトを実行できるAction。 直接ワークフローファイルに書くこともできるが、別のファイルに分けている。
containsで hey botという文字列が含まれるときのみジョブを実行するようにしている。
name: echo-bot on: issue_comment: types: [created] jobs: echo-bot: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - uses: actions/github-script@v2 if: ${{ contains(github.event.comment.body, &amp;#39;hey bot&amp;#39;) }} with: github-token: ${{secrets.GITHUB_TOKEN}} script: |const script = require(`${process.env.GITHUB_WORKSPACE}/.github/workflows/script.js`) script({github, context}) $ cat .github/workflows/script.js module.exports = ({github, context}) =&amp;gt; { github.issues.createComment({ issue_number: context.payload.issue.number, owner: context.payload.repository.owner.login, repo: context.payload.repository.name, body: `You said ${context.</description>
    </item>
    
    <item>
      <title>GitHub Actionsのself-hosted runner</title>
      <link>https://www.sambaiz.net/article/307/</link>
      <pubDate>Sat, 07 Nov 2020 13:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/307/</guid>
      <description>GitHub Actionsのself-hosted runnerは GitHubがホストする環境以外でジョブを実行できる機能。 権限やネットワークなどの都合で特定の環境でしか実行できない処理を行うことができ、GitHubへロングポーリングしてジョブを待ち構えるのでwebhookのように外からアクセスできるようにする必要がない。 実行時間やストレージによる料金は発生しない。
self-hosted runnerは単一リポジトリだけではなくOrganization、Enterprise単位でも追加できる。Settings-&amp;gt;ActionsからAdd runnerするとOS/アーキテクチャごとのself-hosted runner アプリケーションのインストールコマンドが出てくるので実行する。アップデートは自動で行われ、失敗し続けてバージョンが古くなるとジョブが実行できなくなる。
Dockerで動かす。
$ cat Dockerfile FROMdebian:buster ARG USERNAME=user ARG USER_UID=1000 ARG USER_GID=$USER_UID ARG APP_VERSION=2.273.6 RUN groupadd --gid $USER_GID $USERNAME \  &amp;amp;&amp;amp; useradd --uid $USER_UID --gid $USER_GID -m $USERNAME \  &amp;amp;&amp;amp; apt-get update \  &amp;amp;&amp;amp; apt-get install -y sudo \  &amp;amp;&amp;amp; echo $USERNAME ALL=\(root\) NOPASSWD:ALL &amp;gt; /etc/sudoers.d/$USERNAME \  &amp;amp;&amp;amp; chmod 0440 /etc/sudoers.d/$USERNAME USER$USERNAME WORKDIR/home/$USERNAME RUN sudo apt-get install -y curl &amp;amp;&amp;amp; \  mkdir actions-runner &amp;amp;&amp;amp; cd actions-runner &amp;amp;&amp;amp; \  curl -O -L https://github.</description>
    </item>
    
    <item>
      <title>個数制限がある場合の重複組合せの総数を動的計画法で求める</title>
      <link>https://www.sambaiz.net/article/306/</link>
      <pubDate>Mon, 02 Nov 2020 15:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/306/</guid>
      <description>個数制限がない場合 n種から制限なく重複を許してr個選ぶ組合せの総数nHrはn+r-1個の枠に入れるn-1個の種類を分ける区切りの場所の組合わせの総数と等しいので、 (n+r-1)C(n-1) = (n+r-1)Crで求められる。
int factorial(int n) { int x = 1; for (int i = n; i &amp;gt; 0; i--) { x *= i; } return x; } int H(int n, int r) { // (n+r-1)Cr  return factorial(n + r - 1) / (factorial(r) * factorial(n - 1)); } 個数制限がある場合 nHrは
 n種類目が少なくとも1つ選ばれる場合： nH(r-1) (それぞれの組み合わせにn種類目が1つ加わる) n種類目が1つも選ばれない場合: (n-1)Hr (残りのn-1種類からr個選ぶ)  の和として表すこともでき、 漸化式　H(n, r) = H(n, r-1) + H(n-1, r) が成り立つ。</description>
    </item>
    
    <item>
      <title>SSH Agentに鍵を登録してVSCodeのdevcontainerの中で使えるようにする</title>
      <link>https://www.sambaiz.net/article/305/</link>
      <pubDate>Sat, 17 Oct 2020 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/305/</guid>
      <description>VSCodeのdevcontainer内からホストのSSH Keyでgit pushなどできるようにする。
VSCodeのRemote DevelopmentでSageMakerのコンテナ環境でモデルを開発する - sambaiz-net
macOSの場合ホストのKeyChainかSSH Agentに鍵を登録すると自動でExtensionが参照する。今回はSSH Agentの方で行う。
ssh-addを-Kフラグを付けて実行するとKeychainにパスフレーズが保存される。SSH Agentは自分で起動する必要はなくコマンドを実行すると起動するようだ。
$ ssh-add -K ~/.ssh/id_rsa $ ssh-add -l 4096 ****** ***** (RSA) Sierra以降では.ssh/configのAddKeysToAgentとUseKeychainをyesにしないと起動時に自動で登録されずKeychainも参照されない。
Host * ... AddKeysToAgent yes UseKeychain yes devcontainerに反映されていることを確認。
# ssh-add -l 4096 ****** ***** (RSA) 参考 Mac OS X以降のssh-agent事情 - Qiita</description>
    </item>
    
    <item>
      <title>VSCodeのdevcontainerにSAM CLIをインストールしlocal invokeする</title>
      <link>https://www.sambaiz.net/article/301/</link>
      <pubDate>Mon, 12 Oct 2020 09:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/301/</guid>
      <description>VSCodeのdevcontainerにAWS SAM CLIをインストールしてDockerを用いたlocal invokeもできるようにする。
VSCodeのRemote DevelopmentでSageMakerのコンテナ環境でモデルを開発する - sambaiz-net
HomebrewとSAM CLIのインストール 手順に従ってbrewでインストールする。
 Homebrewがsudoとgit、psを必要とするのでインストールする デフォルトのrootでHomebrewをインストールするとDon&amp;rsquo;t run this as root!になるので non-root userを作って そのユーザーで実行する brew install aws-sam-cliでsamはインストールできているのにexit 1して失敗するのを握り潰している 次にdockerが必要となるので入れている  FROMdebian:buster ARG USERNAME=vscode ARG USER_UID=1000 ARG USER_GID=$USER_UID # Create the user RUN groupadd --gid $USER_GID $USERNAME \  &amp;amp;&amp;amp; useradd --uid $USER_UID --gid $USER_GID -m $USERNAME \  # # [Optional] Add sudo support. Omit if you don&amp;#39;t need to install software after connecting.</description>
    </item>
    
    <item>
      <title>ElastiCacheでRedisクラスタを作成する際の設定</title>
      <link>https://www.sambaiz.net/article/303/</link>
      <pubDate>Fri, 09 Oct 2020 00:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/303/</guid>
      <description>CacheClusterとReplicationGroup コンソールでは意識することがないが、CloudFormationでElastiCacheクラスターを構築する場合は CacheClusterと ReplicationGroupという概念が存在する。 プライマリノードとリードレプリカノードは別のCacheClusterに作成され、それらをカプセル化したのがReplicationGroup。
Cluster Mode 有効にすると最大90までシャードを増やせるようになる。作成後にCluster Modeを有効にはできない。
シャードには1つのPrimary Nodeと0-5つのReplica Nodeが含まれる。 Replica NodeはPrimary NodeのデータをレプリケーションするRead Onlyなノード。手動でPrimary Nodeに昇格させたり、NodeやAZの障害時に自動で昇格したりする。
CloudFormationではシャード数はReplicationGroupのNumNodeGroupsで、レプリカノードの数はReplicasPerNodeGroupで設定できる。
リクエストはキーから計算されるハッシュスロットによって各シャードに分散され、 ClUSTER SLOTSコマンドでハッシュスロットとノードのマッピングが取れる。 go-redisのようなCluster対応クライアントは内部でこのマッピングと計算したハッシュスロットからリクエストを送るノードを決定している。
Node Size 少なくとも総アイテムサイズをシャード数で割った分がメモリに乗るようにする。 これに加えてスナップショットを作成する際にフォークしたプロセスで実行されるBGSAVEや、フェイルオーバーで使うメモリが必要。 reserved-memory-percentパラメータ(以前のバージョンではreserved-memoryだった)でmaxmemoryの25%を予約することが推奨されており、デフォルトは25になっている。
Subnet Group クラスタに設定するVPCのサブネットの集合。クラスタ作成後には変更できない。</description>
    </item>
    
    <item>
      <title>Go CompilerのFunction Inlining</title>
      <link>https://www.sambaiz.net/article/304/</link>
      <pubDate>Tue, 06 Oct 2020 22:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/304/</guid>
      <description>Go Compilerが行う、関数の処理をインラインに展開することで呼び出しコストを削減するFunction Inliningの話。 式の数が40未満でループやクロージャなどが含まれないシンプルな処理の関数が対象となる。
 (追記: 2021-02-17) Go 1.16でラベルのないループがInliningされるようになった
 まずは次の例で挙動を確認する。
package main import &amp;#34;fmt&amp;#34; func myfunc(a, b int) int { return a + b } func main() { fmt.Println(myfunc(1, 2)) } -gcflags に -m を渡してビルドすると最適化の内容が確認でき、2つ渡すとより詳細な出力が得られる。
$ go tool compile -help usage: compile [options] file.go... ... -m print optimization decisions myfunc()やfmt.Println()がInliningされたことや、myfunc(1, 2)がヒープに割り当てられたことなどが分かる。 ちなみにコストの低いスタックか、高いヒープのどちらに割り当てるかはEscape analysisによって決まる。
$ go build -gcflags &amp;#39;-m -m&amp;#39; main.go # command-line-arguments ./main.go:5:6: can inline myfunc with cost 4 as: func(int, int) int { return a + b } &amp;lt;---- .</description>
    </item>
    
    <item>
      <title>Kinesis Data AnalyticsのSQL, Lambdaへの出力とCDKによるリソースの作成</title>
      <link>https://www.sambaiz.net/article/302/</link>
      <pubDate>Sat, 03 Oct 2020 19:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/302/</guid>
      <description>Kinesis Data AnalyticsでStreaming SQLを実行し、 Lambdaに送る。ほかの接続先としてData StreamやFirehoseがあり、フォーマットはJSONとCSVから選べる。
Kinesis Streams/Firehose/Analyticsを試す - sambaiz-net
STREAMとPUMP (in-application) STREAMを作成し、PUMPで他のSTREAMをSELECTした結果をINSERTすることでデータを流していく。出力先を設定する際にSTREAMを選ぶ。 STREAMはRDBのテーブルのようにカラムを持ち、JOINもできる。
CREATE OR REPLACE STREAM &amp;#34;TEMPSTREAM&amp;#34; ( &amp;#34;column1&amp;#34; BIGINT NOT NULL, &amp;#34;column2&amp;#34; INTEGER, &amp;#34;column3&amp;#34; VARCHAR(64)); CREATE OR REPLACE PUMP &amp;#34;SAMPLEPUMP&amp;#34; AS INSERT INTO &amp;#34;TEMPSTREAM&amp;#34; (&amp;#34;column1&amp;#34;, &amp;#34;column2&amp;#34;, &amp;#34;column3&amp;#34;) SELECT STREAM inputcolumn1, inputcolumn2, inputcolumn3 FROM &amp;#34;INPUTSTREAM&amp;#34;; Windowed Queries  Tumbling Windows  固定の重複しない区間で集計するクエリ。次のように書くと60秒区切りで集計できる。
GROUP BY STEP(&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;.ROWTIME BY INTERVAL &amp;#39;60&amp;#39; SECOND) ROWTIMEは 最初のSTREAMにデータが入った時のタイムスタンプが格納される特別なカラム。SELECTしなくても自動で渡される。
 Stagger Windows  固定の区間ではなく最初に対象パーティションのデータが届くとそこからINTERVALの区間のWindowが始まる。 Tumbling Windowsではデータに含まれるタイムスタンプで集計する場合、遅れて届くことで同じ区間のレコードが分かれてしまう問題があるがそれを緩和できる。</description>
    </item>
    
    <item>
      <title>EKS上のLocustから負荷をかける際のリソースの割り当てやインスタンスタイプの調整</title>
      <link>https://www.sambaiz.net/article/299/</link>
      <pubDate>Sun, 20 Sep 2020 16:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/299/</guid>
      <description>EKS上にLocustをインストールしたのだが、ユーザーを増やしてもRPSが大して伸びない。リソースを調整してなるべく効率的に負荷をかけられるようにする。
CDKでEKSクラスタの作成からHelm ChartでのLocustのインストールまでを一気に行う - sambaiz-net
前提 実行するシナリオは次のGETリクエストを送るだけのもの。Chartの都合で0.x系のlocustfileになっている。
from locust import HttpLocust, TaskSet, task class MyTaskSet(TaskSet): @task def index(self): self.client.get(&amp;#34;/&amp;#34;) class MyUser(HttpLocust): task_set = MyTaskSet min_wait = 5 max_wait = 15 ちなみに負荷をかける対象はECS+Fargateに立ち上げたAPIサーバーで、こちらが問題にならないよう余裕を持って動かしている。 スケールするからといってAPI Gatewayなどに向けるとリクエスト数による多額の課金が発生し得るので注意だ。
ECSでアプリケーションを動かすBoilerplateを作った - sambaiz-net
なお、ファイルディスクリプタの数は元から十分大きかったため特に変更していない。
ファイルディスクリプタの上限を増やす - sambaiz-net
$ kubectl exec tryeksstackclusterchartlocustchart1abdd876-worker-d5c7b85cbq6sh -- /bin/sh -c &amp;#34;ulimit -n&amp;#34; 1048576 ワーカー数とリソースの割り当て m5.large (2vCPU, メモリ10GiB)の2ノードに5ワーカーを立ち上げ負荷をかけたところ230RPSあたりで頭打ちになってしまった。
Container Insightsのメトリクスを見るとワーカーPodのCPUの使用率が100%に張り付いていることが分かる。
CloudWatch Container InsightsでEKSのメトリクスを取得する - sambaiz-net
ノードのCPUは40%ほどしかリクエストされておらず同量のlimitsがかかっているので、ワーカーのリクエストCPUを増やすか数を増やせば簡単にRPSを増やせそうだ。
まずはリクエストCPUを100mから500mに増やした。2.5倍ではないのは40%の中にはkube-systemやContainer InsightsのDaemonSetが含まれているため。リクエスト率は90%ほどになった。
$ kubectl describe nodes ... Non-terminated Pods: (9 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits AGE --------- ---- ------------ ---------- --------------- ------------- --- amazon-cloudwatch cloudwatch-agent-sfz5l 200m (10%) 200m (10%) 200Mi (6%) 200Mi (6%) 5m49s amazon-cloudwatch fluentd-cloudwatch-5vnhg 100m (5%) 0 (0%) 200Mi (6%) 400Mi (13%) 5m49s default tryeksstackclusterchartlocustchart1abdd876-master-595c44cczwmcm 100m (5%) 100m (5%) 128Mi (4%) 128Mi (4%) 4m54s default tryeksstackclusterchartlocustchart1abdd876-worker-fddd54db4d7xr 500m (25%) 500m (25%) 128Mi (4%) 128Mi (4%) 4m54s default tryeksstackclusterchartlocustchart1abdd876-worker-fddd54dbz2kpj 500m (25%) 500m (25%) 128Mi (4%) 128Mi (4%) 4m54s kube-system aws-node-875rb 10m (0%) 0 (0%) 0 (0%) 0 (0%) 6m39s kube-system coredns-75b44cb5b4-7qpfl 100m (5%) 0 (0%) 70Mi (2%) 170Mi (5%) 4m54s kube-system coredns-75b44cb5b4-gc6mv 100m (5%) 0 (0%) 70Mi (2%) 170Mi (5%) 4m54s kube-system kube-proxy-wj8fk 100m (5%) 0 (0%) 0 (0%) 0 (0%) 6m39s worker: { replicaCount: 5, config: { configmapName: configmap.</description>
    </item>
    
    <item>
      <title>CloudWatch Container InsightsでEKSのメトリクスを取得する</title>
      <link>https://www.sambaiz.net/article/300/</link>
      <pubDate>Fri, 18 Sep 2020 19:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/300/</guid>
      <description>CloudWatch Container Insightsは EKS/EC2上で動くK8sクラスタおよびECSのメトリクスを取得する機能。今回はEKSで使う。
CDKでクラスタを作成する場合、ECSではcontainerInsightsをtrueにすることでセットアップされるが、EKSにはまだ存在しないため手動で行う。PRは上がっている。
CDKでEKSクラスタの作成からHelm ChartでのLocustのインストールまでを一気に行う - sambaiz-net
まずCloudWatchにログとメトリクスを送れるようにするため、ワーカーノードのIAMロールか、 PodのServiceAccountに関連づけられたIAMロールに CloudWatchAgentServerPolicyをアタッチする。今回はCDKで先にクラスタやロールを作るため前者の方法を取る。
cluster.defaultNodegroup?.role.addManagedPolicy(ManagedPolicy.fromAwsManagedPolicyName(&amp;#39;CloudWatchAgentServerPolicy&amp;#39;)) セットアップは次のコマンドの実行で完了し、amazon-cloudwatchネームスペースにCloudWatchメトリクスを送信するエージェントとFluentdのDaemonSetや、 各リソースを取得するClusterRoleやServiceAccountなどが作成される。cluster-nameとregion-nameの部分は書き換える。
$ curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluentd-quickstart.yaml | sed &amp;#34;s/{{cluster_name}}/cluster-name/;s/{{region_name}}/cluster-region/&amp;#34; | kubectl apply -f - $ kubectl get daemonset --namespace amazon-cloudwatch NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE cloudwatch-agent 2 2 2 2 2 &amp;lt;none&amp;gt; 60s fluentd-cloudwatch 2 2 2 2 2 &amp;lt;none&amp;gt; 57s メトリクスはCloudWatchのContainerInsightsネームスペースに送られる。 Podに割り当てられたCPUとメモリの使用率を出してみたところ、負荷をかけた際にCPUが100%に張り付いたので正しく送られていそうだ。</description>
    </item>
    
    <item>
      <title>CDKでEKSクラスタの作成からHelm ChartでのLocustのインストールまでを一気に行う</title>
      <link>https://www.sambaiz.net/article/297/</link>
      <pubDate>Wed, 16 Sep 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/297/</guid>
      <description>以前、Helmでlocustをインストールしたが、今回はEKSにCDKでインストールする。CDKだとクラスタの作成からできるのでcdk deployで一気に環境が整う。
KubernetesにHelmでLocustによる分散負荷試験環境を立てる - sambaiz-net
$ npm run cdk -- --version 1.62.0 (build 8c2d7fc) まずVPCとClusterを作成する。mastersRoleをユーザーもassumeできるようPrincipalにAWSアカウントも入れている。
AWSのAssumeRole - sambaiz-net
その後、実行するタスクを記述したスクリプトlocustfileのConfigMapを作成し、 これをChartのworker.config.configmapNameで参照する。キー名を間違えがち。 ChartのリポジトリはHelm Hubのもの。
 追記 (2020-12-21): 以前はHelm Hubの https://kubernetes-charts.storage.googleapis.com/ を参照していたが、helm/charts リポジトリがdeprecated になり削除されてしまったので、archiveを参照するようにした。
 import * as cdk from &amp;#39;@aws-cdk/core&amp;#39;; import { Cluster, KubernetesVersion, DefaultCapacityType } from &amp;#39;@aws-cdk/aws-eks&amp;#39; import { Vpc, SubnetType, InstanceType } from &amp;#39;@aws-cdk/aws-ec2&amp;#39; import { Role, ManagedPolicy, ServicePrincipal, AccountPrincipal, CompositePrincipal } from &amp;#39;@aws-cdk/aws-iam&amp;#39; import * as fs from &amp;#39;fs&amp;#39;; export class TryEksStack extends cdk.</description>
    </item>
    
    <item>
      <title>AWS Organizaionsで複数のアカウントを一元管理する</title>
      <link>https://www.sambaiz.net/article/298/</link>
      <pubDate>Tue, 15 Sep 2020 23:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/298/</guid>
      <description>AWS Organizationsは複数のAWSアカウントを一元管理する機能。 既存のアカウントを一元管理できるだけではなく新規アカウントを簡単に作成することができるので、 セキュリティの向上やコストの分離、クォータなどアカウント全体に及ぶ影響の局所化などのためにサービスや環境ごとにアカウントを分けるハードルが下がる。 引き続きアカウントごとのコストも確認できるが、請求は一括で行われるので支払いの管理が楽になるし、ボリュームディスカウントの使用量が合算されRIも共有できるのでコストの上でも不利にならない。
また、アカウントやそれをグルーピングしたOrganizational Unit(OU)およびOrganizaion全体に対して、 サービスやアカウントを制御するService control policies (SCPs)などのポリシーを設定することもできる。
Organizationを作成したアカウントがマスターアカウントとなる。変更するにはOrganizationを削除する必要があるため管理専用のアカウントを作成するのがおすすめらしい。 通常、新規アカウントを作成するには住所や支払い情報などを入れる必要があるが、 Organizationだとその辺りが省略されアカウント名とルートアカウントのメールアドレスだけで済む。 管理に用いられるIAMロール名を入れる項目もあるが何も入れなければデフォルトのOrganizationAccountAccessRoleになる。
新アカウントのルートユーザーのパスワードは発行されないので必要なら再発行することになるが、 マスターアカウントのIAMユーザーにアカウント作成時に入力したロールのsts:AssumeRole権限を与えれば 新アカウントの方にユーザーを作らなくてもコンソール上部のメニューからスイッチできる。
AWSのAssumeRole - sambaiz-net
{ &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: &amp;#34;sts:AssumeRole&amp;#34;, &amp;#34;Resource&amp;#34;: &amp;#34;arn:aws:iam::&amp;lt;new_account_id&amp;gt;:role/&amp;lt;role_name&amp;gt;&amp;#34; } ] } 基本的にマスターアカウントのリソースの権限は必要ないと思われるが、MFAの権限はないと設定できないので追加する。
初回はアカウントIDとロール名を入力することになる。一度入力すると履歴に残るのでそこから選べる。
参考 20180214 AWS Black Belt Online Seminar AWS Organizations</description>
    </item>
    
    <item>
      <title>Goの実装に手を入れずにHTTPリクエストをmockするライブラリhttpmockとその仕組み</title>
      <link>https://www.sambaiz.net/article/296/</link>
      <pubDate>Tue, 08 Sep 2020 23:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/296/</guid>
      <description>jarcoal/httpmockは次のようなHTTPリクエストが飛ぶ関数に対して、
import ( &amp;#34;io/ioutil&amp;#34; &amp;#34;net/http&amp;#34; ) func Req() (string, error) { res, err := http.DefaultClient.Get(&amp;#34;https://google.com&amp;#34;) if err != nil { return &amp;#34;&amp;#34;, err } defer res.Body.Close() body, err := ioutil.ReadAll(res.Body) if err != nil { return &amp;#34;&amp;#34;, err } return string(body), nil } 次のように実装に手を入れずmockできるライブラリ。
import ( &amp;#34;testing&amp;#34; &amp;#34;github.com/jarcoal/httpmock&amp;#34; &amp;#34;github.com/stretchr/testify/assert&amp;#34; ) func TestReq(t *testing.T) { httpmock.Activate() defer httpmock.DeactivateAndReset() httpmock.RegisterResponder(&amp;#34;GET&amp;#34;, &amp;#34;https://google.com&amp;#34;, httpmock.NewStringResponder(200, &amp;#34;mocked&amp;#34;), ) res, err := Req() assert.Nil(t, err) assert.Equal(t, &amp;#34;mocked&amp;#34;, res) } 仕組みとしてはActivate()で http.</description>
    </item>
    
    <item>
      <title>nkfによる文字コードの判定とGoでのShiftJISの扱い</title>
      <link>https://www.sambaiz.net/article/295/</link>
      <pubDate>Mon, 07 Sep 2020 21:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/295/</guid>
      <description>file --mime で文字コードを判定しようとしたら charset=unknown-8bit と表示されてしまったので、nkf --guess したところShift_JISであることが分かった。
$ file --mime unknown.txt unknown.txt: text/plain; charset=unknown-8bit $ brew install nkf $ nkf --guess unknown.txt Shift_JIS (CRLF) このファイルをGoで扱うにはjapanese packageでエンコード/デコードする。 ShiftJISのほかにEUCJPとISO2022JPをサポートしている。
import ( &amp;#34;bytes&amp;#34; &amp;#34;golang.org/x/text/encoding/japanese&amp;#34; &amp;#34;golang.org/x/text/transform&amp;#34; ) transform.NewReader(bytes.NewReader(b), japanese.ShiftJIS.NewDecoder()) </description>
    </item>
    
    <item>
      <title>VSCodeのDocker開発コンテナでJupyter Notebookを開いてAthenaのクエリを実行し可視化する</title>
      <link>https://www.sambaiz.net/article/294/</link>
      <pubDate>Fri, 04 Sep 2020 19:34:04 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/294/</guid>
      <description>ローカルでJupyter Notebookを動かすために以前はjupyter/datascience-notebookのイメージを立ち上げていた。 Notebookはエディタとしての機能に乏しいため通常のコードを書くのが大変だったのだが、 VSCodeのPython extensionにはJupyter notebookサポートが入っていてそのまま開けて実行できるのを知ったので移行することにした。 今回はVSCodeのDocker開発コンテナからNotebookを開いてAthenaのクエリを実行し可視化する。
VSCodeのRemote DevelopmentでSageMakerのコンテナ環境でモデルを開発する - sambaiz-net
環境構築 ~/.awsをマウントする。Dockerfileは上記の記事のと同じ。
{ &amp;#34;name&amp;#34;: &amp;#34;Python&amp;#34;, &amp;#34;build&amp;#34;: { &amp;#34;dockerfile&amp;#34;: &amp;#34;Dockerfile&amp;#34; }, &amp;#34;settings&amp;#34;: { &amp;#34;terminal.integrated.shell.linux&amp;#34;: &amp;#34;/bin/bash&amp;#34;, &amp;#34;python.pythonPath&amp;#34;: &amp;#34;/usr/local/bin/python&amp;#34;, &amp;#34;python.linting.enabled&amp;#34;: true, &amp;#34;python.linting.pylintEnabled&amp;#34;: false, &amp;#34;python.linting.flake8Enabled&amp;#34;: true, &amp;#34;python.linting.flake8Path&amp;#34;: &amp;#34;/usr/local/bin/flake8&amp;#34;, &amp;#34;editor.formatOnSave&amp;#34;: true, &amp;#34;python.formatting.provider&amp;#34;: &amp;#34;yapf&amp;#34;, &amp;#34;python.formatting.yapfPath&amp;#34;: &amp;#34;/usr/local/bin/yapf&amp;#34;, &amp;#34;python.linting.mypyEnabled&amp;#34;: true, &amp;#34;python.linting.mypyPath&amp;#34;: &amp;#34;/usr/local/bin/mypy&amp;#34;, }, &amp;#34;extensions&amp;#34;: [ &amp;#34;ms-python.python&amp;#34; ], &amp;#34;mounts&amp;#34;: [ &amp;#34;source=${localEnv:HOME}/.aws,target=/root/.aws,type=bind,readonly&amp;#34; ] } アプリケーションで使うパッケージはPoetryでインストールすることにしている。
PoetryでPythonの依存パッケージを管理する - sambaiz-net
KernalをvenvのPythonに切り替えるためにipykernelをインストールする必要がある。
[tool.poetry.dependencies] python = &amp;#34;^3.8&amp;#34; PyAthena = &amp;#34;^1.11.1&amp;#34; pandas = &amp;#34;^1.1.1&amp;#34; ipykernel = &amp;#34;^5.</description>
    </item>
    
    <item>
      <title>時系列データのMAモデルとARモデル、その定常性と反転可能性</title>
      <link>https://www.sambaiz.net/article/285/</link>
      <pubDate>Fri, 14 Aug 2020 19:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/285/</guid>
      <description>時系列データにLjung-Box testを行い自己相関があることが分かったら、次はそれをモデルで表現したい。今回は自己相関を表す最も基本的なモデルであるMAモデルとARモデルを見ていく。これらを組み合わせたものがARMAモデルで、階差に対するARMAモデルがARIMAモデル。
Pythonで時系列データを検定(Shapiro-Wilk test, runs test, Ljung-Box test)する - sambaiz-net
MAモデル q次のMA(Moving Average; 移動平均)モデルMA(q)は次の式で表される。\(c\)は定数で\(\theta\)はパラメータ、\(\varepsilon\)は分散\(\sigma^2\)のホワイトノイズ。ホワイトノイズというのは期待値が0で\(lag=0\)以外での自己共分散も0である定常過程で、定義から自己相関も0になるので何の傾向もなく動く。期待値が0のiid(independent and identically distributed; 同一の分布の独立なデータ)系列はホワイトノイズであるが、ホワイトノイズがiid系列であるとは限らない。
時系列データの定常性と定常過程、単位根過程 - sambaiz-net
$$ y_t = c + \varepsilon_t + \sum_{i=1}^q \theta_i \varepsilon_{t-i} $$
過去の項と共通部分\(\varepsilon\)を持つことで自己相関が表されている。したがって共通部分を持たないq次以降の項の自己相関は0になってしまうが、次数を上げるとパラメータ\(\theta\)の数が増えてしまう。
期待値\(E\)と自己共分散\(\gamma\)、自己相関\(\rho\)は次の通りで常に定常性を持つ。
$$ \begin{align*} E[y_t] &amp;amp;= c \\ \gamma_k &amp;amp;= (\theta_k + \theta_1 \theta_{k+1} + \cdots + \theta_{q-k}\theta_q) \sigma^2 \ (\rm{if}\ k \le q \ \rm{otherwise}\ 0) \\ \rho_k &amp;amp;= \frac {\theta_k + \theta_1 \theta_{k+1} + \cdots + \theta_{q-k}\theta_q}{1 + \theta_1^2 + \cdots + \theta_q^2} \ (\rm{if}\ k \le q \ \rm{otherwise}\ 0) \end{align*} $$</description>
    </item>
    
    <item>
      <title>SageMakerでTensorFlowのモデルを学習させる</title>
      <link>https://www.sambaiz.net/article/293/</link>
      <pubDate>Mon, 10 Aug 2020 13:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/293/</guid>
      <description>以前PyTorchのモデルを学習させたが、そのTensorFlow版。
SageMakerでPyTorchのモデルを学習させる - sambaiz-net
コード 全体のコードはGitHubにある。
モデル モデルはTitanicのを使う。
TensorFlow2のKeras APIでTitanicのモデルを作る - sambaiz-net
make_csv_dataset()はbatch_sizeが必須になっているが、 これをそのままfilter()しようとすると、ValueError: predicate return type must be convertible to a scalar boolean tensor.になってしまうのでunbatch()している。 SageMakerのServing containerを用いる場合はsave_format=&amp;quot;tf&amp;quot;にしてSavedModel形式で保存する必要がある。
$ cat model.py import tensorflow as tf import logging class Model: def __init__(self, logger: logging.Logger, dropout: float): self.logger = logger self.model = tf.keras.Sequential([ tf.keras.layers.DenseFeatures(self._feature_columns()), tf.keras.layers.Dense(128, activation=tf.nn.relu), tf.keras.layers.Dropout(dropout), tf.keras.layers.Dense(128, activation=tf.nn.relu), tf.keras.layers.Dense(2, activation=tf.nn.sigmoid), ]) self.model.compile(optimizer=&amp;#39;adam&amp;#39;, loss=&amp;#39;binary_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;]) def _feature_columns(self): return [ tf.feature_column.numeric_column(&amp;#39;age&amp;#39;), tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_identity(&amp;#39;sex&amp;#39;, 2)), tf.feature_column.numeric_column(&amp;#39;fare&amp;#39;) ] def _fill(self, feature: str, value): def __fill(x): if x[feature] == -1.</description>
    </item>
    
    <item>
      <title>TensorFlow2のKeras APIでTitanicのモデルを作る</title>
      <link>https://www.sambaiz.net/article/291/</link>
      <pubDate>Sat, 08 Aug 2020 18:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/291/</guid>
      <description>データセット TensorFlow Datasetsの Titanicを使う。
$ pip install tensorflow-datasets tfds.load()して tf.data.Datasetを作る。 tf.data はCPUやGPUがなるべくアイドル状態にならないようにする効率的な入力パイプラインを構築するAPI。
TensorFlowのtf.data API - sambaiz-net
import tensorflow as tf import tensorflow_datasets as tfds ds_train = tfds.load(&amp;#39;titanic&amp;#39;, split=&amp;#39;train&amp;#39;, shuffle_files=True) print(ds_train.element_spec) &amp;#39;&amp;#39;&amp;#39; {&amp;#39;features&amp;#39;: {&amp;#39;age&amp;#39;: TensorSpec(shape=(), dtype=tf.float32, name=None), &amp;#39;boat&amp;#39;: TensorSpec(shape=(), dtype=tf.string, name=None), &amp;#39;body&amp;#39;: TensorSpec(shape=(), dtype=tf.int32, name=None), &amp;#39;cabin&amp;#39;: TensorSpec(shape=(), dtype=tf.string, name=None), &amp;#39;embarked&amp;#39;: TensorSpec(shape=(), dtype=tf.int64, name=None), &amp;#39;fare&amp;#39;: TensorSpec(shape=(), dtype=tf.float32, name=None), &amp;#39;home.dest&amp;#39;: TensorSpec(shape=(), dtype=tf.string, name=None), &amp;#39;name&amp;#39;: TensorSpec(shape=(), dtype=tf.string, name=None), &amp;#39;parch&amp;#39;: TensorSpec(shape=(), dtype=tf.int32, name=None), &amp;#39;pclass&amp;#39;: TensorSpec(shape=(), dtype=tf.</description>
    </item>
    
    <item>
      <title>Androidのプロキシ設定をMacのCharlesに向けて通信をキャプチャする</title>
      <link>https://www.sambaiz.net/article/292/</link>
      <pubDate>Wed, 05 Aug 2020 20:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/292/</guid>
      <description>Mac側の設定 Charlesを入れて次の設定を行う。
 Proxy SettingsでEnable transparent HTTP proxingをオン   SSH Proxy Settingsのincludeに*:*を追加   Access Control SettingsにAndroidのローカルIPアドレスを追加  Android側の設定 同じネットワークにつないで詳細設定からMacへプロキシされるようにする。
$ ifconfig en0 ... inet 192.168.11.6 これで適当なHTTPSのページにアクセスするとSSL HandshakeのエラーがCharlesに出るので http://www.charlesproxy.com/getssl にアクセスしてCharles Proxy CAの証明書をインストールする。 証明書はプロファイルに紐づくので、個人用のプロファイルにインストールしても仕事用のプロファイルのアプリでは使われない。
Chromeからの通信はこれで見られるようになるが、 Android 7からはアプリのnetwork-security-configで信頼した 証明書しか使われないため他のアプリでは大抵Handshakeに失敗する。次のように書くとデバッグ時のみプロキシできるようになる。
&amp;lt;network-security-config&amp;gt; &amp;lt;debug-overrides&amp;gt; &amp;lt;trust-anchors&amp;gt; &amp;lt;!-- Trust user added CAs while debuggable only --&amp;gt; &amp;lt;certificates src=&amp;#34;user&amp;#34; /&amp;gt; &amp;lt;/trust-anchors&amp;gt; &amp;lt;/debug-overrides&amp;gt; &amp;lt;/network-security-config&amp;gt; </description>
    </item>
    
    <item>
      <title>SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする</title>
      <link>https://www.sambaiz.net/article/290/</link>
      <pubDate>Sun, 26 Jul 2020 02:43:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/290/</guid>
      <description>学習させたモデルをSageMakerのホスティングサービスにデプロイする。
SageMakerでPyTorchのモデルを学習させる - sambaiz-net
推論時に呼ばれる関数 推論時には次の関数が呼ばれる。
 model_fn(model_dir): モデルをロードする input_fn(request_body, request_content_type): リクエストボディのデシリアライズ predict_fn(input_data, model): モデルで推論する output_fn(prediction, content_type): Content-Typeに応じたシリアライズ  input_fn() と output_fn() はJSON, CSV, NPYに対応した実装が、predict_fn() はモデルを呼び出す実装がデフォルトとして用意されていて、 model_fn() も後述するElastic Inferenceを使う場合model.ptというファイルをロードするデフォルト実装が使われる。 ただしその場合モデルがtorch.jit.save()でTorchScriptとして保存してある必要がある。
今回は predict_fn() のみ実装した。
$ cat inference.py import torch def predict_fn(input_data, model): device = torch.device(&amp;#39;cuda&amp;#39; if torch.cuda.is_available() else &amp;#39;cpu&amp;#39;) model = model.to(device) input_data = input_data.to(device) model.eval() with torch.jit.optimized_execution(True, {&amp;#34;target_device&amp;#34;: &amp;#34;eia:0&amp;#34;}): output = model(input_data) return output.max(1)[1] デプロイ Training jobがモデルを保存したS3のパスを取ってきてPyTorchModelを作る。
from sagemaker.pytorch.model import PyTorchModel training_job_name = &amp;#39;pytorch-training-2020-07-25-08-41-45-674&amp;#39; training_job = sess.</description>
    </item>
    
    <item>
      <title>SageMakerでPyTorchのモデルを学習させる</title>
      <link>https://www.sambaiz.net/article/287/</link>
      <pubDate>Fri, 24 Jul 2020 22:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/287/</guid>
      <description>AWSの機械学習サービスSageMakerでPyTorchのモデルを学習させる。
コード まず学習させるモデルとそれを呼び出すエントリーポイントになるコードを書く。全体のコードはGitHubにある。 実際の環境と同じSageMakerのコンテナをローカルで動かしてVSCodeのRemote Developmentで接続して開発すると入っていないパッケージは警告が出たりして良い。
VSCodeのRemote DevelopmentでSageMakerのコンテナ環境でモデルを開発する - sambaiz-net
モデル 以前作ったMNISTのモデルを使う。
PyTorchでMNISTする - sambaiz-net
$ cat model.py import torch from torch import nn, cuda import torch.nn.functional as F import torch.distributed as dist import torch.optim as optim class Model(nn.Module): def __init__(self, dropout): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 64, 5) # -&amp;gt; 24x24 self.pool1 = nn.MaxPool2d(2) # -&amp;gt; 12x12 self.conv2 = nn.Conv2d(64, 128, 5) # -&amp;gt; 8x8 self.dropout = nn.Dropout(p=dropout) self.dense = nn.</description>
    </item>
    
    <item>
      <title>VSCodeのRemote DevelopmentでSageMakerのコンテナ環境でモデルを開発する</title>
      <link>https://www.sambaiz.net/article/289/</link>
      <pubDate>Sun, 19 Jul 2020 19:34:04 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/289/</guid>
      <description>SageMakerで学習させるモデルを開発するにあたって、Notebooks上ではコードを書きづらいのでVS Codeで書いているのだが、ローカルに依存パッケージをインストールして実行しているため エディタ上では警告が出ていなくても、実際の環境にはパッケージがなかったりすることがある。
そんな場合に便利なのがVS CodeのRemote Development。 これはローカルのVS CodeからリモートのVS Code Serverに接続してその環境で開発することができるエクステンションで、 Dockerコンテナのほか、SSHでリモートマシンやVMに接続したり、WindowsならWSLにも接続して開発環境を揃えることができる。
SageMakerでPyTorchのモデルを学習させる - sambaiz-net
設定 .devcontainer/に次のファイルを置く。
PyTorch  Dockerfile  aws/deep-learning-containersの Deep Learning Containers Imagesから選び、ECRからpullするため認証情報を登録しておく。
$ aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin https://763104351884.dkr.ecr.us-east-1.amazonaws.com これをベースに、開発用ツールを入れてVSCodeのDevelopment Container Scriptsを実行する。
$ cat .devcontainer/Dockerfile FROM763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.1-cpu-py36-ubuntu16.04 RUN conda install -y yapf flake8 mypy # VS Code Development Container Scripts # https://github.com/microsoft/vscode-dev-containers/tree/v0.128.0/script-library ARG INSTALL_ZSH=&amp;#34;true&amp;#34; ARG USERNAME=&amp;#34;vscode&amp;#34; ARG USER_UID=&amp;#34;1000&amp;#34; ARG USER_GID=&amp;#34;${USER_UID}&amp;#34; ARG UPGRADE_PACKAGES=&amp;#34;true&amp;#34; ARG COMMON_SCRIPT_SOURCE=&amp;#34;https://raw.</description>
    </item>
    
    <item>
      <title>PoetryでPythonの依存パッケージを管理する</title>
      <link>https://www.sambaiz.net/article/288/</link>
      <pubDate>Sat, 18 Jul 2020 21:23:04 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/288/</guid>
      <description>Poetryは比較的新しいPythonの依存管理ツールで、 pipenvの依存解決に失敗することがある問題を解消したり、ライブラリを開発しやすくしたものらしい。 まだスターはpipenvの半分ほどだがバージョンもv1.0.0に到達したしpipenvよりも速くて安定しているという話もあるので使ってみる。
インストール pipでインストールした。ドキュメントによると依存が衝突する可能性があるとのことだったが、自分の環境では特に問題なかった。
$ pip install --user poetry $ poetry --version Poetry version 1.0.9 使い方 PEP 518で定義されている設定ファイルpyproject.tomlを置く。
$ cat pyproject.toml [tool.poetry] name = &amp;#34;poetry-demo&amp;#34; version = &amp;#34;0.1.0&amp;#34; description = &amp;#34;&amp;#34; authors = [&amp;#34;sambaiz &amp;lt;godgourd@gmail.com&amp;gt;&amp;#34;] [tool.poetry.dependencies] python = &amp;#34;^3.7&amp;#34; [build-system] requires = [&amp;#34;poetry&amp;gt;=0.12&amp;#34;] build-backend = &amp;#34;poetry.masonry.api&amp;#34; poetry addするとvenvがなければ作成してその中にパッケージをインストールしpyproject.tomlにも追加する。
$ poetry add pendulum Creating virtualenv poetry-demo-t1vYebNd-py3.7 in /Users/*****/Library/Caches/pypoetry/virtualenvs ... $ cat pyproject.toml ... [tool.poetry.dependencies] python = &amp;#34;^3.7&amp;#34; pendulum = &amp;#34;^2.1.1&amp;#34; poetry install でpyproject.</description>
    </item>
    
    <item>
      <title>iOSアプリとLLVMのbitcode</title>
      <link>https://www.sambaiz.net/article/286/</link>
      <pubDate>Tue, 07 Jul 2020 21:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/286/</guid>
      <description>Objective-CやSwiftはLLVMを通して機械語にコンパイルされる。 Swiftの場合、フロントエンドのコンパイラによってASTが作られ SIL(Swift Intermediate Language)という中間表現に変換された後、 LLVM IR(intermediate representation)に再度変換され、 これをLLVM Optimizerで最適化したものが バックエンドのLLVMに渡りターゲットアーキテクチャの機械語に変換される流れになっている。
bitcodeはこのLLVM IRのバイナリフォーマットのこと。 ちなみに、bitcodeはターゲットに依存しなさそうなのだが実際は依存してしまう。 SILは一般的にターゲットに依存しない。
Xcode7以降ではデフォルトでBuild OptionsのEnable BitcodeがYesになっているため Archive時にbitcodeが埋め込まれる。これを提出するとAppleがコンパイルして最適化してくれるのでアプリサイズが減る。 アプリにbitcodeを埋め込む場合、依存フレームワークにもbitcodeが埋め込まれている必要があるが、 Xcodeのバージョンがフレームワークのビルドに使われたバージョンより古いと&#39;Invalid bitcode version (Producer: &#39;xxx&#39; Reader: &#39;yyy&#39;)&#39;でArchiveに失敗することがある。
参考 Swiftから透けて見えるAppleのコンパイラ技術 (1/2)：CodeZine（コードジン）
「LLVM bitcode はポータブルでない」ってどういう意味なの？ - Qiita
What is app thinning? (iOS, tvOS, watchOS) - Xcode Help</description>
    </item>
    
    <item>
      <title>時系列データの定常性と定常過程、単位根過程</title>
      <link>https://www.sambaiz.net/article/279/</link>
      <pubDate>Sun, 05 Jul 2020 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/279/</guid>
      <description>時系列データを各時間\(t\)ごとの分布から抽出された確率変数\(R_t\)の列とみなすと、次の性質が定義される。
 弱定常性(weak stationarity): 各分布の平均\(E(R_t) = \mu\)が\(t\)に依らず一定で、\(lag=k\) のデータとの共分散である自己共分散 \(Cov(R_t, R_{t-k}) = E[(R_t - E(R_t))(R_{t-k} - E(R_{t-k}))] = \gamma_k\) がlagのみに依存する(つまり分散 \(\gamma_0\) も一定) 強定常性(strict stationarity): 任意の\(t,k\)に対する \((R_t, R_{t+1}, &amp;hellip;, R_{t+k})\) の同時分布が同一  つまり弱定常性を持つデータは、一定の平均のまわりの一定の振れ幅の中で、それ以前の値にlagに応じた影響を受けながら推移することになる。単に定常性と言う場合この弱定常性のことを指す。
同一の分布でなくても平均と分散、自己共分散が一定ならば弱定常性の条件は満たされるため、弱定常性のみを持ち強定常性を持たないことはある。 逆に強定常性を持つ場合は弱定常性も持ちそうだが、強定常性の条件は平均や分散(1次と2次のモーメント)を必須としないので必ずしも正しくなく、 平均と分散が定義されないコーシー分布では弱定常性を持たないことになる。
確率変数の列を確率過程(stochastic process)と呼び、定常性を持つものを定常過程(stationary process)と呼ぶ。 また、それ自体は定常過程でなく、差分系列 \(\Delta R_t = R_t - R_{t-1}\) が定常過程であるものを単位根過程(unit root process)と呼ぶ。 単位根という用語はAR特性方程式の根に1が含まれることに由来しているらしい。
時系列データのMAモデルとARモデル、その定常性と反転可能性 - sambaiz-net
参考 現場ですぐ使える時系列データ分析～データサイエンティストのための基礎知識〜
CHAPTER 4. STATIONARY TS MODELS
定常性についてのまとめ ｜ Developers.IO
第１章「離散時間確率過程」</description>
    </item>
    
    <item>
      <title>SwiftのクラスをObjective-CのClass型に渡してinitしたときに落ちるパターン</title>
      <link>https://www.sambaiz.net/article/284/</link>
      <pubDate>Sun, 28 Jun 2020 23:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/284/</guid>
      <description>Objective-Cのクラスは基本的にNSObjectをルートクラスに持ち、そのinit()が継承またはオーバーライドされるが、 SwiftのクラスはNSObjectを継承していなかったり他のdesignated initializerが存在することでinit()が存在しないことや、default initializerのために明示的なinit()が存在しない場合がある。
Swiftのdesignated/convenience/required/default initializerと継承 - sambaiz-net
そんなクラスのMetatypeをObjective-CのClass型に代入してinitするとどうなるか確認する。
SwiftのMetatypeとMetadata - sambaiz-net
#import &amp;lt;Foundation/Foundation.h&amp;gt;  @interface Hoge: NSObject @property (weak, nonatomic) id &amp;lt;HogeDelegate&amp;gt; delegate; @property Class klass; - (void)fuga; @end #import &amp;#34;Hoge.h&amp;#34; #import &amp;lt;UIKit/UIKit.h&amp;gt;  @implementation Hoge - (void)fuga { dispatch_async(dispatch_get_main_queue(), ^{ [[_klass alloc] init]; }); } @end func f() { var hoge = Hoge() hoge.klass = B.self hoge.fuga() }  init()を実装したクラス: 実行時にUnrecognized selector -[***.B init]で落ちる  init()を実装しないでdefault initializerが存在する場合も同様。
class B{ init() {} }  NSObjectを継承したクラス: 落ちない  class B: NSObject{ }  NSObjectを継承し、init()以外のdesignated initializerを実装したクラス: 実行時にUse of unimplemented initializer &#39;init()&#39; for class &#39;***.</description>
    </item>
    
    <item>
      <title>SwiftのARCとweak、delegateが呼ばれなかったりObjective-Cで返り値が0やNOになる原因</title>
      <link>https://www.sambaiz.net/article/283/</link>
      <pubDate>Sat, 27 Jun 2020 23:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/283/</guid>
      <description>SwiftやObjective-CはARC (Automatic Reference Counting)という仕組みでメモリを管理していて、 インスタンスへの参照カウントが0になったときにそのメモリが開放される。昔は参照カウントの増減を手動でやっていたが今はARCが自動でやってくれる。
class X { deinit { print(&amp;#34;deinit X&amp;#34;) } } var x: X? = X() print(&amp;#34;inited X&amp;#34;) x = nil print(&amp;#34;setted nil&amp;#34;) /* inited X deinit X setted nil */ 通常それでうまく働くが、次のように循環参照するといずれの参照カウントも0にならずメモリリークする。
protocol SomeDeleagete: AnyObject { func foo() -&amp;gt; Int } class A { var b: B init() { self.b = B() self.b.delegate = self } deinit { print(&amp;#34;deinit A&amp;#34;) } } extension A: SomeDeleagete { func foo() -&amp;gt; Int { return 100 } } class B { var delegate: SomeDeleagete?</description>
    </item>
    
    <item>
      <title>SwiftのMetatypeとMetadata</title>
      <link>https://www.sambaiz.net/article/282/</link>
      <pubDate>Thu, 25 Jun 2020 20:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/282/</guid>
      <description>ObjcのClass型のように インスタンスではなくクラスそのものを取りたい場合、SwiftではFoo.Typeで表せるMetatypeを用いる。 値はクラスからはFoo.selfで、インスタンスからはtype(of: Foo())で得られる。 初期化の際はサブクラスにも存在することが保証されるrequired initializerを呼ぶか、継承できないfinal classである必要がある。
Swiftのdesignated/convenience/required/default initializerと継承 - sambaiz-net
class Foo { required init() {} func aaa() -&amp;gt; String { return &amp;#34;foo.aaa&amp;#34; } } class Bar: Foo { override func aaa() -&amp;gt; String { return &amp;#34;bar.aaa&amp;#34; } } class Hoge { func aaa() -&amp;gt; String { return &amp;#34;hoge.aaa&amp;#34; } } func initFooAndCallFunc(type: Any.Type) -&amp;gt; String { guard let fooType = type as? Foo.Type else { return &amp;#34;this is not Foo&amp;#34; } return fooType.</description>
    </item>
    
    <item>
      <title>Swiftのassociatedtypeとtype erasure</title>
      <link>https://www.sambaiz.net/article/281/</link>
      <pubDate>Wed, 24 Jun 2020 23:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/281/</guid>
      <description>associatedtypeはprotocolのジェネリクスのようなもので、複数の型に対応した定義を書くことができる。
protocol P1 { associatedtype T func some(x: T) func some2(x: T) } class C1: P1 { func some(x: Int) { print(x) } /* // ambiguous inference of associated type &amp;#39;T&amp;#39;: &amp;#39;String&amp;#39; vs. &amp;#39;Int&amp;#39; func some2(x: String) { print(x) } */ func some2(x: Int) { print(x) } } class C2: P1 { func some(x: Int) { print(x) } // OK func some2&amp;lt;T&amp;gt;(x: T) { print(x) } } 通常、protocolはexistential typeとして変数の型に指定できるが、 associatedtypeが含まれるとその型が不明なので指定できない。</description>
    </item>
    
    <item>
      <title>Swiftのdesignated/convenience/required/default initializerと継承</title>
      <link>https://www.sambaiz.net/article/280/</link>
      <pubDate>Tue, 23 Jun 2020 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/280/</guid>
      <description>Initialization — The Swift Programming Language (Swift 5.3)
designated initializerはプライマリなinitializerで、全ての初期化されていないプロパティを初期化し、スーパークラスのinit()を呼んでチェーンを作る。 convenience initializerは利便性のためのinitializerで、他のinitializerを呼んで最終的にdesignated initializerが呼ばれるようにする。 required initializerは継承が必須なinitializerで、サブクラスにも存在することが保証される。
class A: NSObject { var some: String // designated initializer override init() { print(&amp;#34;designated&amp;#34;) some = &amp;#34;foo&amp;#34; } // designated &amp;amp; required initializer required init(_ str: String) { print(&amp;#34;required \(str)&amp;#34;) some = &amp;#34;bar&amp;#34; } convenience init(_ num: Int) { self.init() print(&amp;#34;convenience \(num)&amp;#34;) } convenience init(num2: Int) { self.init(num2) print(&amp;#34;convenience2 \(num2)&amp;#34;) } } designated initializerはクラスに一つ以上存在する必要があるが、次のように全てのプロパティが初期化されている場合default initializerが作られる。</description>
    </item>
    
    <item>
      <title>Pythonで時系列データを検定(Shapiro-Wilk test, runs test, Ljung-Box test)する</title>
      <link>https://www.sambaiz.net/article/273/</link>
      <pubDate>Sun, 21 Jun 2020 01:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/273/</guid>
      <description>統計的仮説検定 - sambaiz-net
テストデータ Dominick&amp;rsquo;s datasetのビールの週売上データを使う。 UPC(Universal Product Code)に対応する商品データと、店(STORE)で週(WEEK)に売れた数(MOVE)と価格(PRICE)、収益(PROFIT)を含むMovementデータがCSVで提供されている。
  これらをカレントディレクトリに置いてJupyter Notebookを立ち上げる。
$ docker run -p 8888:8888 -v `pwd`:/home/jovyan/work jupyter/datascience-notebook start-notebook.sh ロードしてplotしてみる。
import pandas as pd df = pd.read_csv(&amp;#39;./wber.csv&amp;#39;, usecols=[&amp;#39;STORE&amp;#39;, &amp;#39;WEEK&amp;#39;, &amp;#39;UPC&amp;#39;, &amp;#39;MOVE&amp;#39;, &amp;#39;PRICE&amp;#39;, &amp;#39;PROFIT&amp;#39;]) agg = df[df[&amp;#39;STORE&amp;#39;] == 5].groupby([&amp;#39;WEEK&amp;#39;]).sum().loc[:, [&amp;#39;MOVE&amp;#39;, &amp;#39;PROFIT&amp;#39;]] agg.plot()   この内、中央の区間の値や差分に対してα=0.05で検定する。
Shapiro-Wilk test 帰無仮説は&amp;quot;正規分布に従っている&amp;quot;。p&amp;gt;αとなり帰無仮説は棄却されず、正規分布に従うとみなせる。
from scipy import stats W, p = stats.shapiro(agg[&amp;#39;PROFIT&amp;#39;].loc[230:310]) print(f&amp;#39;p={p:.3f}&amp;#39;) # p=0.183 runs test 帰無仮説は&amp;quot;2値の数列の値がランダムである&amp;quot;。runというのは数列の連続して増加/減少している部分のことで、帰無仮説が正しい場合数列に含まれるrunの数は次の平均と分散の正規分布に従う。
updown = agg[&amp;#39;PROFIT&amp;#39;].loc[230:310].diff().map(lambda x: x &amp;gt; 0) Np = updown.</description>
    </item>
    
    <item>
      <title>iOSのnibで作ったViewにCustom Classを対応させて描画する</title>
      <link>https://www.sambaiz.net/article/278/</link>
      <pubDate>Fri, 05 Jun 2020 05:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/278/</guid>
      <description>nibとUIViewを継承したCustomViewクラスを作成し、nibにLabelを配置して@IBOutletと繋げた。
import Foundation import UIKit import viewframework class CustomView: UIView { @IBOutlet weak var labelview: UILabel? } このCustomViewをnibのViewと対応させるのに次の2通りの方法がある。
ルートのViewのCustom Classとして設定する nibのルートのViewのCustom ClassをCustomViewにすると、UINib.instantiate()でCustomViewのrequired init?(coder: NSCoder)が呼ばれインスタンスが作られるので、 それをaddSubViewすることで描画できる。
import UIKit class ViewController: UIViewController { override func viewDidLoad() { super.viewDidLoad() let customView = UINib(nibName: &amp;#34;CustomView&amp;#34;, bundle: Bundle(for: type(of: self))).instantiate(withOwner: nil, options: nil).first as! CustomView customView.labelview?.text = &amp;#34;OK&amp;#34; view.addSubview(customView) } } File&amp;rsquo;s OwnerのCustom Classとして設定する nibのFile&amp;rsquo;s OwnerのCustom ClassをCustomViewにし、 CustomView内でwithOwner: selfでnibをロードすると@IBOutletにインスタンスが詰まるので、ルートのViewも繋げておいてそれをaddSubViewすればCustomView以下にnibのヒエラルキーそのまま描画される。 Custom ClassがUIViewである必要は必ずしもなくロードしたviewを親のviewに直接addSubViewしても良い。
import Foundation import UIKit class CustomView: UIView { @IBOutlet var view: UIView!</description>
    </item>
    
    <item>
      <title>C&#43;&#43;でnext_permutationを使わずに順列を列挙する</title>
      <link>https://www.sambaiz.net/article/277/</link>
      <pubDate>Wed, 03 Jun 2020 01:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/277/</guid>
      <description>Permutations - LeetCode
配列が渡されてそれを並び替えてできる全ての順列を返す問題。 まさにSTLのalgorithmに辞書順で次の順列を返すnext_permutation()というのがあって次のようにするだけでできてしまう。
vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; ret; sort(nums.begin(), nums.end()); do { ret.push_back(nums); } while (next_permutation(nums.begin(), nums.end())); return ret; せっかくなのでこれを使わず実装してみた。 あるindexの要素とそれ以降の全ての要素をそれぞれswapすることでそのindexに入り得る全ての値を網羅し、 それら全ての配列に対して対象のindexを一つ増やして同じ処理を再帰的に繰り返す。
class Solution { public: vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; permute(vector&amp;lt;int&amp;gt;&amp;amp; nums) { return _permute(nums, 0); } vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; _permute(vector&amp;lt;int&amp;gt; nums, int swap_index) { vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; ret; if (swap_index &amp;gt;= nums.size()) { return {nums}; } for(int i = swap_index; i &amp;lt; nums.size(); i++) { swap(nums[swap_index], nums[i]); auto v = _permute(nums, swap_index+1); copy(v.begin(), v.end(), back_inserter(ret)); swap(nums[swap_index], nums[i]); } return ret; } }; </description>
    </item>
    
    <item>
      <title>SwiftのURLSession</title>
      <link>https://www.sambaiz.net/article/276/</link>
      <pubDate>Sun, 31 May 2020 02:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/276/</guid>
      <description>SwiftのURLSessionは ネットワーク通信を行うURLSessionTaskを生成するオブジェクト。
func request(_ session: URLSession) -&amp;gt; () -&amp;gt; Void { return { guard let url = URL(string: &amp;#34;https://api.publicapis.org/health&amp;#34;) else { return } var request = URLRequest(url: url) request.httpMethod = &amp;#34;GET&amp;#34; request.addValue(&amp;#34;application/json&amp;#34;, forHTTPHeaderField: &amp;#34;content-type&amp;#34;) let task = session.dataTask(with: request) { data, response, error in guard let httpResponse = response as? HTTPURLResponse else { print(&amp;#34;not http response \(error)&amp;#34;) return } guard httpResponse.statusCode / 100 == 2 else { print(&amp;#34;bad status code: \(httpResponse.</description>
    </item>
    
    <item>
      <title>SwiftのJSONEncoder/DecoderとCodable protocol</title>
      <link>https://www.sambaiz.net/article/275/</link>
      <pubDate>Tue, 26 May 2020 01:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/275/</guid>
      <description>SwiftのJSONEncoder/Decoderは JSON文字列をCodable(Encodable &amp;amp; Decodable) protocolを実装したClassやStructにエンコード/デコードするオブジェクト。
全ての変数がCodableで、特に何もする必要がない場合はCodableを付ければうまくいく。 String、Int、Doubleといったstandard libraryの型や、DateやDataなどFoundationの型はCodableになっている。
CodingKeyでフィールド名のマッピングができる。デコード時にOptionalでないフィールドが足りなかったり型が異なると例外が飛び、エンコード時にはnilを無視する。
struct Foo: Codable { var nums: [Int] var str: String enum CodingKeys: String, CodingKey { case nums = &amp;#34;numbers&amp;#34; case str } } var data = &amp;#34;&amp;#34;&amp;#34; { &amp;#34;numbers&amp;#34;: [100, 120], &amp;#34;str&amp;#34;: &amp;#34;Aaa&amp;#34; } &amp;#34;&amp;#34;&amp;#34;.data(using: .utf8)! let json = try! JSONDecoder().decode(Foo.self, from: data) print(json.str) // =&amp;gt; Aaa let enc = try! JSONEncoder().encode(json) print(String(data: enc, encoding: .utf8)!) // =&amp;gt; {&amp;#34;numbers&amp;#34;:[100,120],&amp;#34;str&amp;#34;:&amp;#34;Aaa&amp;#34;} var data = &amp;#34;&amp;#34;&amp;#34; { &amp;#34;numbers&amp;#34;: [100, 120], } &amp;#34;&amp;#34;&amp;#34;.</description>
    </item>
    
    <item>
      <title>VPCエンドポイント</title>
      <link>https://www.sambaiz.net/article/274/</link>
      <pubDate>Sat, 23 May 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/274/</guid>
      <description>VPCエンドポイントは PrivateLink対応のサービスおよび、S3やDynamoとAWSネットワーク内で接続するためのエンドポイント。 インターネットに出ない分セキュアでゲートウェイへの負荷も抑えられる。 料金は時間あたりとトラフィック量による。
VPCエンドポイントを使うためにアプリケーション側に手を入れる必要はなく、 S3とDynamoがサポートしているGatewayのエンドポイントではルートテーブルによって、 その他多くのサービスがサポートしているInterfaceのエンドポイントでは名前解決の時点で向き先が変わるようになっている。
まずVPCのDNS ResolutionとDNS HostnamesをtrueにしてPrivate DNSで名前解決されるようにしておく必要がある。 エンドポイントを作成する際の設定項目は対象サービスと、VPCとSubnet、SGとサービスによってはPolicy。 サービスと1:1対応しているわけではなく、例えばECSの場合は次の3つのエンドポイントが必要。
com.amazonaws.region.ecs-agent com.amazonaws.region.ecs-telemetry com.amazonaws.region.ecs 作成するとSubnet内にエンドポイントとそれに紐づくENIが立ち、インターネットゲートウェイなしでもAPIが叩けるようになった。</description>
    </item>
    
    <item>
      <title>統計的仮説検定</title>
      <link>https://www.sambaiz.net/article/271/</link>
      <pubDate>Sun, 10 May 2020 23:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/271/</guid>
      <description>統計的仮説検定(statistical hypothesis test)は母集団に対するある仮説が妥当だと言えるか標本から判断する手法。 棄却(reject)されることが期待される帰無仮説(null hypothesis)\(H_0\)と、それに相対する本命の対立仮説(alternative hypothesis)\(H_1\)を立て、 検定統計量を出し、帰無仮説が真である場合での確率分布でそれより外れた値が観測される確率であるp値が、設定した有意水準\(α\)(0.05にすることが多い)を下回れば帰無仮説が棄却され対立仮説が採択(accept)される。
有意水準はあくまで帰無仮説を棄却できるかのラインなので、それを上回ったからといって積極的に採択できるわけではない。 帰無仮説が真であるのに、たまたま棄却域の値が出ることで棄却してしまう場合を第一種の誤りといい、 逆に帰無仮説が偽であるのに採択してしまう場合を第二種の誤りという。 前者が起きる確率は有意水準αと等しく、\(α\)を小さくして棄却域を狭めると後者の確率βが大きくなる。 第二種の誤りを犯さない確率\(1-β\)を検出力といい、これが大きいほど厳しい検定と言える。
検定には母集団が特定の分布に従うと仮定しそのパラメータである平均や分散などを用いるパラメトリックな手法と、そうでないノンパラメトリックな手法がある。 パラメトリックな手法の方が検出力は高いが、標本数が小さい場合は分布を仮定することが難しいためノンパラメトリックな手法の方が適している。
t検定 正規分布を仮定するパラメトリックな手法。ちなみに正規分布かどうかの検定としてShapiro–Wilkの検定などがある。
Pythonで時系列データを検定(Shapiro-Wilk test, runs test, Ljung-Box test)する - sambaiz-net
t検定では平均\(\mu\)の正規表現に従う\(n\)個の標本から計算される次の確率変数\(t\)が、自由度\(n-1\)のt分布に従うことを利用する。もし十分な標本数があるか母分散が分かっているなら標準化変換した\(Z\)を用いてZ検定を行うことになる。
$$ t = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}} $$
確率分布(二項分布/ポアソン分布/正規分布/t分布/カイ二乗分布) - sambaiz-net
標本 (1.1, 1.5, 1.2, 1.3, 1.4) に対して帰無仮説&amp;quot;平均1.0の正規分布に従う&amp;quot;で検定してみる。
$$ \begin{align*} n &amp;amp;= 5 \\ \bar{X} &amp;amp;= \sqrt{1.1 + 1.5 + 1.2 + 1.3 + 1.4}{5} = 1.3 \\ s^2 &amp;amp;= \sqrt{(1.1 - 1.3)^2 + (1.5 - 1.</description>
    </item>
    
    <item>
      <title>C&#43;&#43;でO(1)で読み書きできるLRUキャッシュを実装する</title>
      <link>https://www.sambaiz.net/article/270/</link>
      <pubDate>Sun, 26 Apr 2020 18:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/270/</guid>
      <description>LRU Cache - LeetCode
最初次のようなコードを書いたがタイムアウトしてしまった。 C++のstd::mapは二分木で実装されているので各操作にO(log n)かかり、dequeの先頭への挿入はO(1)でできるが重複するキーを探して削除するのにO(n^2)かかってしまう。
C++ STLのContainersとAlgorithms - sambaiz-net
class LRUCache { public: deque&amp;lt;int&amp;gt; Q; // key  map&amp;lt;int, int&amp;gt; V; // &amp;lt;key, value&amp;gt;  int cap = 0; LRUCache(int capacity) { cap = capacity; } int get(int key) { if (V.count(key) != 0) { for (int i = 0; i &amp;lt; Q.size(); i++) { if (Q[i] == key) { Q.erase(Q.begin() + i); break; } } Q.push_front(key); return V[key]; } return -1; } void put(int key, int value) { if (cap == 0) { return; } if (get(key) == -1) { if (Q.</description>
    </item>
    
    <item>
      <title>Goで参照型の変数に代入し値を変更したとき元の値に影響がある場合とない場合</title>
      <link>https://www.sambaiz.net/article/269/</link>
      <pubDate>Sat, 25 Apr 2020 22:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/269/</guid>
      <description>サンプル用struct。
package main import ( &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; ) type Data struct { Value string ValueP *string `json:&amp;#34;,omitempty&amp;#34;` Slice []Data `json:&amp;#34;,omitempty&amp;#34;` SliceP []*Data `json:&amp;#34;,omitempty&amp;#34;` } func NewData() *Data { return &amp;amp;Data{ Value: &amp;#34;no-changed&amp;#34;, ValueP: &amp;amp;[]string{&amp;#34;no-changed&amp;#34;}[0], Slice: []Data{ Data{ Value: &amp;#34;no-changed&amp;#34;, }, Data{ Value: &amp;#34;no-changed&amp;#34;, }, }, SliceP: []*Data{ &amp;amp;Data{ Value: &amp;#34;no-changed&amp;#34;, }, }, } } 参照を取って値を取る アドレスは変わらず、そのフィールドを書き換えると当然元々の値も書き換わる。 各要素が順番に代入されるfor-rangeでのループも他と同じく参照型でないなら変わらず、参照型なら変わる。
func main() { s := NewData() fmt.Printf(&amp;#34;%p %p %p\n&amp;#34;, s, s.ValueP, s.Slice) // 0xc00009a000 0xc000010240 0xc00009c000  s2tmp := &amp;amp;s s2 := *s2tmp fmt.</description>
    </item>
    
    <item>
      <title>Goのcipher packageに実装されている暗号利用モードのベンチマーク</title>
      <link>https://www.sambaiz.net/article/268/</link>
      <pubDate>Sun, 12 Apr 2020 23:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/268/</guid>
      <description>暗号利用モードはブロック長より長いメッセージに対してどのようにブロック暗号を適用するかのアルゴリズム。
ブロック暗号 ブロック暗号は固定長のブロックを暗号化/復号する共通鍵暗号で、入力と同じ長さの出力を返す暗号化/復号関数からなる。 アメリカ国立標準技術研究所（NIST) が標準暗号として採用したAES (Rijndael) が有名。 最も単純な暗号利用モードとして、メッセージをブロックに分割してそれぞれ独立に適用する Electronic Codebook (ECB) というのがあるが、 鍵とブロックが同じなら毎回同じ出力になってしまうため、メッセージのパターンが残ってしまうのとリプレイ攻撃に弱い問題があり使われない。 また、メッセージがブロック長の整数倍になるようにパディングが必要。
Goのcrypto/cipher packageに実装されている暗号化利用モード Goのcrypto/cipher packageには次の暗号化利用モードが実装されている。
$ go version go version go1.14 darwin/amd64 Cipher Block Chaining (CBC) メッセージをブロックに分割し、前段の暗号文(最初はランダムなIV)と入力ブロックのXORを取ったものが暗号文で、 これを復号関数にかけて前段の暗号文とのXORを取って復号する。IVは平文のまま暗号文の前に付けるなどする。 IVがないと最初のブロックが復号できず、暗号文の一部が破損すると次のブロックまで復号できない。 ECBと同様パディングが必要。最も広く使われているらしい。
最後のブロックの暗号文をMAC(Message Authentication Code)とするCBC-MACでは最初のブロックの改変を防ぐためIVが0固定で、 任意のメッセージの最初のブロックを他のメッセージのMACとXORを取って後ろに結合することで、それまでの影響を打ち消し任意のメッセージ単体のMACと同じ値にする Length extension attackが成立する。そのためメッセージを固定長にするかメッセージ長を先頭に入れるなどの対策が必要。
Goではパディングは自分でやる必要がある。
func (x *cbcEncrypter) CryptBlocks(dst, src []byte) { if len(src)%x.blockSize != 0 { panic(&amp;#34;crypto/cipher: input not full blocks&amp;#34;) } if len(dst) &amp;lt; len(src) { panic(&amp;#34;crypto/cipher: output smaller than input&amp;#34;) } if subtle.</description>
    </item>
    
    <item>
      <title>Bellman–Ford法とDijkstra法で最短経路問題を解く</title>
      <link>https://www.sambaiz.net/article/267/</link>
      <pubDate>Wed, 01 Apr 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/267/</guid>
      <description>Bellman–Ford法とDijkstra法で最短経路問題を解く。
Bellman-Ford法 始点の距離が0、それ以外の頂点の距離が無限大な初期状態から、 全辺を見て各辺を通るとしたときに現在の距離を下回るなら更新する、というのを繰り返すアルゴリズム。 辺の重みは負でも問題ないが、総和が負の値になる閉路が存在する場合、そこで無限ループしてしまうので決まらない。 その場合を除けば、頂点の数を|V|、辺の数を|E|とすると、繰り返しは|V|-1回で終わり、計算量はO(|V||E|)になる。
Dijkstra法 同じく始点の距離が0、それ以外の頂点の距離が無限大な初期状態から、 まだ選ばれていない頂点の中から最小の距離のものを1つ選んでその最短距離を確定させ、そこから伸びている辺を見て更新していく、というのを繰り返す。 Bellman-Ford法が全ての頂点から同時に探索するのに対してDijkstra法は始点から着実に進んでいくイメージ。 頂点を選ぶ/取り除くのにO(log|V|)かかる二分ヒープのpriority queueで実装すると計算量はO((|E|+|V|)log|V|)となる。 Bellman-Ford法より高速だが、負の重みがあると選んだ頂点の現在の距離が最短であることが確定しないので適用できない。
Cheapest Flights Within K Stops - LeetCode 乗継K回以内のフライトの最安値を返す問題。
There are n cities connected by m flights. Each flight starts from city u and arrives at v with a price w. Now given all the cities and flights, together with starting city src and the destination dst, your task is to find the cheapest price from src to dst with up to k stops.</description>
    </item>
    
    <item>
      <title>作ったライブラリをCocoaPods/Carthageでimportする</title>
      <link>https://www.sambaiz.net/article/266/</link>
      <pubDate>Sat, 28 Mar 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/266/</guid>
      <description>CocoaPods 長らく使われている依存ライブラリ管理ツール。
$ sudo gem install cocoapods $ pod --version 1.9.1 podspec まずはライブラリ側の作業。podspecを埋めていく。 Trunkに上げないPodに依存する場合、spec.dependency では :git や :path を指定できないので、アプリ側のPodfileで指定する。
$ ls SampleFramework	SampleFramework.xcodeproj	SampleFrameworkTests $ pod spec create SampleFrameworkSambaiz Specification created at SampleFrameworkSambaiz.podspec $ cat SampleFrameworkSambaiz.podspec Pod::Spec.new do |spec| spec.name = &amp;#39;SampleFrameworkSambaiz&amp;#39; spec.version = &amp;#39;0.0.2&amp;#39; spec.license = { :type =&amp;gt; &amp;#39;MIT&amp;#39;, :file =&amp;gt; &amp;#39;LICENSE&amp;#39; } spec.homepage = &amp;#39;https://github.com/sambaiz/ios-sample-framework&amp;#39; spec.authors = { &amp;#39;Taiki Sakamoto&amp;#39; =&amp;gt; &amp;#39;godgourd@gmail.com&amp;#39; } spec.summary = &amp;#39;Sample Framework&amp;#39; spec.</description>
    </item>
    
    <item>
      <title>iOSのipa(app)のProfileを異なるTeamのものに置き換えて実機で動かす</title>
      <link>https://www.sambaiz.net/article/265/</link>
      <pubDate>Tue, 24 Mar 2020 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/265/</guid>
      <description>Profileを置き換えて有効期限やDevice IDを更新する。
iOSアプリのProvisioning profile - sambaiz-net
codesignでの試み .ipa をunzipすると .app が出てくる。
$ unzip my-test-app.ipa $ tree Payload/ Payload/ └── my-test-app.app ├── Base.lproj │ └── LaunchScreen.storyboardc │ ├── 01J-lp-oVM-view-Ze5-6b-2t3.nib │ ├── Info.plist │ └── UIViewController-01J-lp-oVM.nib ├── Info.plist ├── PkgInfo ├── _CodeSignature │ └── CodeResources ├── embedded.mobileprovision └── my-test-app codesign で entitlements を確認する。
$ codesign -d --entitlements :- my-test-app.app &amp;gt; entitlements.plist $ cat entitlements.plist &amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;!DOCTYPE plist PUBLIC &amp;#34;-//Apple//DTD PLIST 1.</description>
    </item>
    
    <item>
      <title>iOSアプリのProvisioning Profile</title>
      <link>https://www.sambaiz.net/article/264/</link>
      <pubDate>Tue, 24 Mar 2020 21:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/264/</guid>
      <description>アプリを実機にデプロイするために必要なもの。 App ID (prefix + Bundle ID)やインストール可能なDevice ID、 コード署名に用いた Apple発行の証明書などを含む。これらが一致しないとインストールできない。
次のTypeのProfileが存在する。
 development profile: 開発用のprofile。TeamのDeviceで動かす。 ad hoc profile: テスト用のprofile。UDIDを登録したDeviceに配布できる。 AccountにDevice family (iPhone, iPad, etc.)ごとに100台まで登録可能。 App Store profile: App Storeに上げるためのprofile。  $ ls ~/Library/MobileDevice/Provisioning\ Profiles ****.mobileprovision ... $ security cms -D -i ~/Library/MobileDevice/Provisioning\ Profiles/****.mobileprovision &amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;!DOCTYPE plist PUBLIC &amp;#34;-//Apple//DTD PLIST 1.0//EN&amp;#34; &amp;#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd&amp;#34;&amp;gt; &amp;lt;plist version=&amp;#34;1.0&amp;#34;&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;AppIDName&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;XC net sambaiz test-app&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;ApplicationIdentifierPrefix&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;string&amp;gt;****&amp;lt;/string&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;CreationDate&amp;lt;/key&amp;gt; &amp;lt;date&amp;gt;2020-03-18T11:05:13Z&amp;lt;/date&amp;gt; &amp;lt;key&amp;gt;Platform&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;string&amp;gt;iOS&amp;lt;/string&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;IsXcodeManaged&amp;lt;/key&amp;gt; &amp;lt;true/&amp;gt; &amp;lt;key&amp;gt;DeveloperCertificates&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;data&amp;gt;****&amp;lt;/data&amp;gt; &amp;lt;data&amp;gt;****&amp;lt;/data&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;Entitlements&amp;lt;/key&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;application-identifier&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;****.</description>
    </item>
    
    <item>
      <title>Goのツールのバージョンをgo.modで指定する</title>
      <link>https://www.sambaiz.net/article/263/</link>
      <pubDate>Sun, 22 Mar 2020 01:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/263/</guid>
      <description>依存moduleと同様にツールもバージョンを指定し、挙動や出力が変わらないようにする。
Tools as dependencies
まず次の tools.go のようなファイルを作ってimportし、 go mod tidy で消えないようにする。 build tagが付いているので通常のbuild時には影響を及ぼさない。
$ cat tools.go // +build tools  package pkg import ( _ &amp;#34;golang.org/x/lint/golint&amp;#34; ) 次にGOBINを変更して go install し指定したディレクトリにバイナリを持ってきてこれを実行する。
export GOBIN:=$(PWD)/bin $(GOBIN)/golint: go install golang.org/x/lint/golint .PHONY: test test: $(GOBIN)/golint go test -v ./pkg/... bin/golint ./pkg/... </description>
    </item>
    
    <item>
      <title>Go Modulesのreplaceでforkしたコードのimportを書き換えずにfork後のpackageに向ける</title>
      <link>https://www.sambaiz.net/article/262/</link>
      <pubDate>Sun, 01 Mar 2020 21:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/262/</guid>
      <description>Goはimportの際に相対パスやモジュール名ではなくgithub.com/foo/barのようなフルパスで指定するため、forkしたコードを使うと参照するpackageは元のままになってしまう。Go Modulesのreplace directiveを使うとコードを書き換えずに依存先を変えることができる。相対パスも使える。
When should I use the replace directive? · golang/go Wiki · GitHub
module example.com/me/hello require ( example.com/foo/bar v0.0.0 ) replace ( example.com/foo/bar/aaa =&amp;gt; ./ example.com/foo/bar/bbb =&amp;gt; example.com/hoge/bar/bbb v1.0.0 ) fork元のmodule。文字列を出力するだけのもの。
$ cat go-something/lib/lib.go package lib import &amp;#34;fmt&amp;#34; func Do() { fmt.Println(&amp;#34;this is original&amp;#34;) } $ cat go-something/main.go package main import &amp;#34;github.com/sambaiz/go-something/lib&amp;#34; func main() { lib.Do() } $ go run go-something/main.go this is original fork先のmodule。出力する文字列を変えている。
$ cat go-something-fork/lib/lib.go package lib import &amp;#34;fmt&amp;#34; func Do() { fmt.</description>
    </item>
    
    <item>
      <title>Go Modulesのproxyとsumdb</title>
      <link>https://www.sambaiz.net/article/261/</link>
      <pubDate>Sat, 29 Feb 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/261/</guid>
      <description>Module Mirror and Checksum Database Launched - The Go Blog
Go1.13からデフォルトで使われるようになったGo Modulesのミラーとchecksumを返すサーバー。 Googleによって運営されている。
 proxy.golang.org index.golang.org: proxyで利用可能なmoduleとバージョンの一覧 sum.golang.org  $ curl &amp;#34;https://proxy.golang.org/github.com/labstack/echo/v4/@v/v4.1.14.mod&amp;#34; module github.com/labstack/echo/v4 go 1.12 require ( github.com/dgrijalva/jwt-go v3.2.0+incompatible github.com/labstack/gommon v0.3.0 github.com/mattn/go-colorable v0.1.4 // indirect github.com/mattn/go-isatty v0.0.11 // indirect github.com/stretchr/testify v1.4.0 github.com/valyala/fasttemplate v1.1.0 golang.org/x/crypto v0.0.0-20191227163750-53104e6ec876 golang.org/x/net v0.0.0-20191209160850-c0dbc17a3553 // indirect golang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8 // indirect golang.org/x/text v0.3.2 // indirect ) $ wget &amp;#34;https://proxy.golang.org/github.com/labstack/echo/v4/@v/v4.1.14.zip&amp;#34; $ curl &amp;#34;https://index.golang.org/index?since=2020-02-28T09:00:00.000000Z&amp;amp;limit=5&amp;#34; {&amp;#34;Path&amp;#34;:&amp;#34;github.com/openebs/api&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v0.0.0-20200228085622-f3442fff37bf&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:00:05.62813Z&amp;#34;} {&amp;#34;Path&amp;#34;:&amp;#34;github.com/dirkarnez/dirk-commons&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v0.0.0-20200228090031-1926f326c678&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:00:50.00608Z&amp;#34;} {&amp;#34;Path&amp;#34;:&amp;#34;github.com/jfrog-solutiontest/food&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v4.107.0+incompatible&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:01:10.76502Z&amp;#34;} {&amp;#34;Path&amp;#34;:&amp;#34;github.com/nexus49/dapr-components&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v0.0.0-20200228090009-67e985bdc953&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:01:15.618406Z&amp;#34;} {&amp;#34;Path&amp;#34;:&amp;#34;github.com/Krajiyah/ble-sdk&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v0.0.7-0.20200228090109-03b5ffe425a0&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:01:23.38344Z&amp;#34;} $ curl &amp;#34;https://sum.</description>
    </item>
    
    <item>
      <title>DAX (DynamoDB Accelerator)の特性と挙動確認</title>
      <link>https://www.sambaiz.net/article/260/</link>
      <pubDate>Wed, 26 Feb 2020 23:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/260/</guid>
      <description>DAXとは DAXはDynamoDBの前段に置かれるマネージドなインメモリキャッシュで、 Read速度の向上(数ms-&amp;gt;数百μs)とテーブルのRead Capacityの節約に効果がある。
DynamoDBとSDKのAPIの互換性があるため置き換えるだけで使えるようになっている。 クライアントの実装としてはHTTPではない独自のプロトコルで通信している点が異なる。
クラスタ作成時に指定するのはノード数とインスタンスタイプで、 ノード数はスループットに、インスタンスタイプはスループットとメモリ量(キャッシュヒット率)に影響する。 複数のノードがある場合、一つがWriteするプライマリーノードになり、他はリードレプリカになる。 なのでノード数を増やしてもWriteのスループットは上がらない。プライマリーノードに問題が発生したら自動でフェイルオーバーする。 ノードは最大10個まで増減できるが、インスタンスタイプは変更できない。最大10個というのは足りるのかと思ったが、数百万RPS捌けるようなので十分そうだ。
インスタンスに対して時間課金が発生し、可用性のために3ノード以上にすることが推奨されている。 そのため、リクエストがそれほどなかったり、キャッシュミスばかりだとインスタンス代の方が高くつくこともあるが、 そこそこReadするなら目に見えてコスト削減されるはずだ。ただしどれくらい次の整合性を許容できるかによる。
キャッシュの整合性 DAXはDynamoDBとは異なり、結果整合性のある読み込み(Eventually Consistent Reads)のみをサポートしているので、プライマリノードにキャッシュされ、全てのノードにレプリケーションが完了するまでの間は異なる結果を返す可能性がある。また、DAXからDynamoDBへのリクエストも結果整合性のある読み込みで行われる。
リクエストの結果は、Itemがなかった場合のネガティブキャッシュも含めて、 Item Cache(GetItem,BatchGetItem)とQuery Cache(Query,Scan)にキャッシュされ、 それぞれパラメータグループで設定されたTTLが過ぎるか、LRUアルゴリズムによって破棄される。 TTLのデフォルトは5分。
書き込みリクエストが来るとまずDynamoDBに書き込んで成功したことを確認してからキャッシュしてレスポンスを返す。 この際Item Cacheは更新されるが、Query Cacheは更新されずTTL/LRUによって破棄されるまで同じ値を返し続けてしまう。 もし問題がある場合は、TTLを短くするかDynamoDBを直接見に行くことになるが、そうするとDAXの効果が薄れてしまう。 また、大量のデータを書き込むと、その分レイテンシが増加したり、それらがすべてキャッシュに乗ることで既存のものがLRUで追い出されてキャッシュヒット率が悪くなることがあり、それらを回避するため直接書き込むという選択肢もあるが、Item Cacheが更新されないことを許容する必要がある。
取れるメトリクス CPU使用率や、キャッシュヒット数、各リクエスト数や接続数が取れる。
ノードごとのCPU使用率も取れる。Writeやキャッシュミスによるプライマリーノードの負荷の高まりに注意。 レイテンシが大きくなり接続数が増える悪循環に陥る。
プライマリーノードのCPU使用率が80%程度でテーブルのキャパシティに余裕があってもリクエストがスロットリングされることがあり、一つ上のインスタンスタイプでクラスタを作り直したところ解消した。 この際、いきなり全リクエストが新クラスタに送られることで膨大なキャッシュミスが発生し、 テーブルのキャパシティを超過したりプライマリーノードに負荷が集中しないように、 Route53で割合で解決されるようにしたが、これはうまく流れてくれた。
挙動確認 DAX/DynamoへリクエストするだけだったらLambdaでも良いが、負荷をかけるのでECS上にアプリケーションをデプロイすることにした。 以前作ったBoilerplateベースで、コードはここ。
ECSでアプリケーションを動かすBoilerplateを作った - sambaiz-net
TableとDAXのClusterを作成。
createDynamoTable() { return new dynamodb.Table(this, &amp;#39;DynamoTable&amp;#39;, { tableName: &amp;#34;dax-test-table&amp;#34;, partitionKey: { name: &amp;#39;id&amp;#39;, type: dynamodb.AttributeType.STRING }, readCapacity: 50, writeCapacity: 50, }); } createDaxCluster(subnetIds: string[]) { const subnetGroup = new dax.</description>
    </item>
    
    <item>
      <title>ECSでアプリケーションを動かすBoilerplateを作った</title>
      <link>https://www.sambaiz.net/article/259/</link>
      <pubDate>Mon, 24 Feb 2020 16:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/259/</guid>
      <description>https://github.com/sambaiz/ecs-boilerplate
ECS上でアプリケーションを動かすBoilerplateを作った。CDKでデプロイする。以前Digdagを動かしたときのを汎用的にしたもの。
CDKでECS+Fargate上にDigdagを立ててCognito認証を挟む - sambaiz-net
new ECSStack(app, &amp;#39;ECSBoilerplateSampleStack&amp;#39;, { /* // If vpcAttributes is not specified, new VPC is created. vpcAttributes: { vpcId: &amp;#39;&amp;#39;, availabilityZones: [], publicSubnetIds: [], privateSubnetIds: [], }, // DNS record. Even if this is not specified, you can access with ELB domain (***.elb.amazonaws.com) route53: { zoneId: &amp;#39;&amp;#39;, zoneName: &amp;#39;example.com&amp;#39;, recordName: &amp;#39;foo&amp;#39;, }, // Certificate Manager ARN. Required if accessing with HTTPS acmArn: &amp;#39;arn:aws:acm:****&amp;#39; // default values containerPort: 8080, cpu: 256, memoryLimitMiB: 512, minCapacity: 1, maxCapacity: 5, scaleCPUPercent: 80 */ }); CDKがECRへのpushまでやってくれるのでcdk deployすれば動き始め、削除するときもStackを消せばよい。</description>
    </item>
    
    <item>
      <title>AndroidのListViewで再利用されるViewのgetGlobalVisibleRect()が意図した値を返さない</title>
      <link>https://www.sambaiz.net/article/257/</link>
      <pubDate>Tue, 11 Feb 2020 01:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/257/</guid>
      <description>ListViewのViewの再利用 まずはListViewのViewが再利用されていることを確認する。
package com.example.listviewglobalvisiblerect import android.widget.BaseAdapter import android.content.Context import android.view.View import android.view.ViewGroup import android.app.Activity import android.graphics.Color import android.graphics.Rect import android.util.Log import android.widget.TextView data class SampleData(val id: Long, val value: String) class SampleAdapter: BaseAdapter { private val context: Context private val items: List&amp;lt;SampleData&amp;gt; private val views = ArrayList&amp;lt;View&amp;gt;() constructor(context: Context, items: List&amp;lt;SampleData&amp;gt;) { this.context = context this.items = items } override fun getCount(): Int { return items.size } override fun getItem(position: Int): Any { return items.</description>
    </item>
    
    <item>
      <title>Buildkitとは</title>
      <link>https://www.sambaiz.net/article/258/</link>
      <pubDate>Tue, 11 Feb 2020 01:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/258/</guid>
      <description>Buildkitは高速でセキュアなコンテナイメージのビルドツール。 Docker本体にも18.09から統合され、 DOCKER_BUILDKIT=1 docker build するとBuildkitが使われるようになった。
LLB (low-level builder) BuildkitはDockerfileなどをLLBという中間言語にコンパイルする。 LLBは依存関係を表すDAG(Directed acyclic graph; 有向非巡回グラフ)で、 protobufで定義されている。 これによって処理を並列に実行したり、Dockerfileを変更してもそれ以降のステージのキャッシュを全て破棄する必要がなくなった。
--mount=type=cache Dockerfileを変更しても残せるキャッシュ。
# syntax = docker/dockerfile:1.1-experimental FROMgolang RUN --mount=type=cache,target=/root/.cache/go-build \  go build ... --mount=type=secret 秘密鍵など一度ADDしてしまったファイルは最終的に消してもレイヤ上に残ってしまうが、--mount=type=secret でマウントすると残らない。
# syntax = docker/dockerfile:1.1-experimental FROMalpine:20200122 RUN apk add --no-cache git openssh RUN --mount=type=secret,id=ssh,dst=/root/.ssh/id_rsa \  ssh-keyscan -H github.com &amp;gt;&amp;gt; /root/.ssh/known_hosts &amp;amp;&amp;amp; \  git clone ... $ DOCKER_BUILDKIT=1 docker build --secret id=ssh,src=./id_rsa . 参考 Introducing BuildKit - Moby Blog</description>
    </item>
    
    <item>
      <title>SwiftでGCDのDispatchQueueに処理を投げて並列実行させる</title>
      <link>https://www.sambaiz.net/article/256/</link>
      <pubDate>Sat, 25 Jan 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/256/</guid>
      <description>GCD (Grand Central Dispatch)はmacOSやiOSのマルチコア環境で、 効率的に並列処理を実行するための仕組み。 OperationQueueというのもあるが、これもGCD上で動く。
DispatchQueue 処理をどのスレッドで実行するか管理するキュー。 どこからでも参照できるmainとglobalのキュー以外に新しくキューを作成することもできる。 labelは衝突しないようにreverse-DNS nameにすることが推奨されている。
DispatchQueue.main.async {} DispatchQueue.global(qos: .default).async {} DispatchQueue.global(qos: .background).async {} DispatchQueue(label: &amp;#34;net.sambaiz.serial_dispatch_queue&amp;#34;).async {} DispatchQueue(label: &amp;#34;net.sambaiz.concurrent_dispatch_queue&amp;#34;, attributes: .concurrent).async {} sync/async ブロッキングするsync()としないasync()。排他制御ではないのに注意。
DispatchQueue.global().async { print(&amp;#34;async&amp;#34;) DispatchQueue.main.sync { print(&amp;#34;sync&amp;#34;) } print(&amp;#34;done&amp;#34;) } print(&amp;#34;run&amp;#34;) run async sync done serial/concurrent 処理を単一のスレッドで行う(serial)か、複数のスレッドで行う(concurrent)かはキューによって決まり、 メインスレッドで動かすmainはserial、globalはconcurrentになっている。 自作のキューの場合は作成時に attributes: .concurrent を渡すとconcurrentになり、渡さないとserialになる。
まずはconcurrentの例から。
for i in 1...3 { DispatchQueue.global().async { print(&amp;#34;start concurrent \(i)thread: \(Thread.current)&amp;#34;) print(&amp;#34;return concurrent \(i)thread: \(Thread.current)&amp;#34;) } } print(&amp;#34;return thread: \(Thread.</description>
    </item>
    
    <item>
      <title>貪欲法(Greedy algorithm)で問題を解く</title>
      <link>https://www.sambaiz.net/article/255/</link>
      <pubDate>Mon, 13 Jan 2020 21:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/255/</guid>
      <description>貪欲法(Greedy algorithm)は問題を分割し、それぞれにおいて貪欲に最適な選択をしていくアルゴリズムの総称。 必ずしも最適解になるとは限らないが、うまくいけば簡潔に計算量を減らすことができる。
Best Time to Buy and Sell Stock II - LeetCode 配列で株価が与えられ、売買して得られる最大の利益を返す問題。
Say you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (i.e., buy one and sell one share of the stock multiple times). Example 1: Input: [7,1,5,3,6,4] Output: 7 Explanation: Buy on day 2 (price = 1) and sell on day 3 (price = 5), profit = 5-1 = 4.</description>
    </item>
    
    <item>
      <title>Objective-CでFrameworkを作りSwiftからimportする</title>
      <link>https://www.sambaiz.net/article/254/</link>
      <pubDate>Sun, 12 Jan 2020 17:41:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/254/</guid>
      <description>Frameworkの作成 New -&amp;gt; ProjectでFrameworkをLanguage Objective-Cで作成。
最低限の実装とHeaderを書いた。このHeaderはBuild PhasesのHeadersにPublicとして登録されている。
 TestObjcFramework.m  #import &amp;lt;Foundation/Foundation.h&amp;gt;  void hello() { NSLog(@&amp;#34;hello&amp;#34;); };  TestObjcFramework.h  #import &amp;lt;UIKit/UIKit.h&amp;gt;  //! Project version number for TestObjcFramework. FOUNDATION_EXPORT double TestObjcFrameworkVersionNumber; //! Project version string for TestObjcFramework. FOUNDATION_EXPORT const unsigned char TestObjcFrameworkVersionString[]; // In this header, you should import all the public headers of your framework using statements like #import &amp;lt;TestObjcFramework/PublicHeader.h&amp;gt;  void hello(void); arm64(実機)/x86_64(Simulator)両方で使えるUniversal Frameworkをビルドするため、 New -&amp;gt; TargetでAggregateを作成し、Build PhasesのNew Run Script Phaseで、 各環境でxcodebuildしてlipoでUniversal Binaryにする次のスクリプトを追加する。</description>
    </item>
    
    <item>
      <title>C&#43;&#43; STLのContainersとAlgorithms</title>
      <link>https://www.sambaiz.net/article/253/</link>
      <pubDate>Sat, 04 Jan 2020 21:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/253/</guid>
      <description>STL(Standard Template Library)はC++の標準ライブラリ。 その名の通りtemplateで実装され、様々な型で使えるようになっている。
// https://github.com/microsoft/STL/blob/1e8b8d4eef4b2dddeb7533c5231c876383bd0ea6/stl/inc/algorithm#L3501 template &amp;lt;class _RanIt, class _Pr&amp;gt; void sort(const _RanIt _First, const _RanIt _Last, _Pr _Pred) { // order [_First, _Last), using _Pred  _Adl_verify_range(_First, _Last); const auto _UFirst = _Get_unwrapped(_First); const auto _ULast = _Get_unwrapped(_Last); _Sort_unchecked(_UFirst, _ULast, _ULast - _UFirst, _Pass_fn(_Pred)); } 以下の例はC++14で、
$ g++-8 -dM -E -x c++ /dev/null | grep -F __cplusplus #define __cplusplus 201402L 全部入りHeader bits/stdc++.h をincludeし、std:: を省略している。
#include &amp;lt;bits/stdc++.h&amp;gt;using namespace std; Containers データを保存するオブジェクト。</description>
    </item>
    
    <item>
      <title>MacのVSCodeでC&#43;&#43;を書く環境構築</title>
      <link>https://www.sambaiz.net/article/252/</link>
      <pubDate>Sat, 04 Jan 2020 01:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/252/</guid>
      <description>(追記:2021-02-05) 今はdevcontainerで環境を作っている。mirosoft/vscode-remote-try-cppをコンテナで開くだけでbits/stdc++.hも読めるg++環境が立ち上がる。GitHubのテンプレートとして公開されているので、これをベースとしたリポジトリを作成できる。
VSCodeのRemote DevelopmentでSageMakerのコンテナ環境でモデルを開発する - sambaiz-net
 Extension  C/C++  を入れてHello Worldを書いたところ、stdio.hが見つからず#includeの行に赤線が付いた。
#include &amp;lt;stdio.h&amp;gt; int main(void) { printf(&amp;#34;Hello World!\n&amp;#34;); return 0; } Command Palletteから C/C++: Edit Configurations (JSON) を選ぶと .vscode/c_cpp_properties.json が生成されるので編集していく。
Xcode 10から/usr/includeにHeaderファイルが置かれなくなったようなのでincludePathにXcodeのSDKのパスを追加する。
$ xcode-select --install $ xcrun --show-sdk-path /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk $ ls -l /Library/Developer/CommandLineTools/SDKs/ total 0 drwxr-xr-x 7 root wheel 224 7 23 08:49 MacOSX.sdk lrwxr-xr-x 1 root wheel 10 7 23 08:48 MacOSX10.14.sdk -&amp;gt; MacOSX.sdk $ ls /Library/Developer/CommandLineTools/SDKs/MacOSX.</description>
    </item>
    
    <item>
      <title>動的計画法(DP)で計算結果を再利用して計算量を減らす</title>
      <link>https://www.sambaiz.net/article/251/</link>
      <pubDate>Mon, 30 Dec 2019 19:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/251/</guid>
      <description>動的計画法(DP, Dynamic Programming)は、 例えばフィボナッチ数列の項f(x)を記録しておいたf(x-1)とf(x-2)から計算するように、 計算結果を記録し帰納的に求められるより大きな計算で利用するアルゴリズムの総称。
いくつか問題を解いてみる。
Longest Common Subsequence 最長共通部分列問題。
Given two strings text1 and text2, return the length of their longest common subsequence. Example 1: Input: text1 = &amp;#34;abcde&amp;#34;, text2 = &amp;#34;ace&amp;#34; Output: 3 Explanation: The longest common subsequence is &amp;#34;ace&amp;#34; and its length is 3. 単純に毎回一から探索するとO(n^3)になるが、text1のi番目までとtext2のj番目までの共通部分列の長さをDP[i-1][j-1]に記録しておくと、 ヒントにあるように、それぞれの文字列に1文字足したときに それが同じ文字ならその分伸ばした DP[i - 1][j - 1] + 1 となり 違う文字ならそのまま max(DP[i - 1][j], DP[i][j - 1]) となる ことに気付けると毎回探索しなくてよくなりO(n^2)にできる。
class Solution { public: int longestCommonSubsequence(string text1, string text2) { vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; DP(text1.</description>
    </item>
    
    <item>
      <title>LA,ディズニーランドからre:Inventに参加しグランドキャニオンへドライブしてきた</title>
      <link>https://www.sambaiz.net/article/250/</link>
      <pubDate>Sun, 22 Dec 2019 23:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/250/</guid>
      <description>一昨年、去年と参加したGoogle I/Oのチケットが今年は当たらなかったので、前から行ってみたかったAWSのre:Inventに参加することにした。 会場はラスベガスで、会期は12/2-6。前後の土日ともう2日つなげて現地時間10日間の旅程にした。 去年、カナダのバンクーバーから西海岸のシアトル、ポートランド、サンフランシスコは巡ったので、今回はまだ訪れていないロサンゼルスからスタートすることにした。会期後はグランドキャニオンまで足を伸ばす。
準備 例年通りExpediaで航空券と宿を取り、加えてラスベガスからグランドキャニオンへ行くためにレンタカーを予約した。 I/O会期中のシリコンバレー近辺とは異なり、ラスベガスのホテルは本当に安くて、OYO(元フーターズ)が一泊2千円で取れた。 re:Inventは65000人規模のイベントなんだが現地のUberドライバー曰く、最大20万人規模のイベントもやったりするらしいのでキャパシティは十分そうだ。 多くの人が申し込むJTBのツアーはホテルのグレードを考えてもかなり割高に感じた。
LAでは北のハリウッド、南のアナハイム、ディズニーランドまで行くことを考えてダウンタウンに宿を取った。 価格だけで選ぶとスキッド・ロウといった危ないエリアの近くになりかねないので注意が必要だ。 ディズニーのチケットも事前に購入した。2パークいけるパークホッパーチケットに、色々な特典を含むMaxPassを付けて$214。 高い日のPeak料金ではあるんだが、家族連れで来たら大変じゃないかと思う。
ラスベガスといえばカジノとショーの街だというし、シルク・ドゥ・ソレイユ Oのチケットを買った。 チケットを印刷するのを忘れていたので現地のFedex Officeで印刷した。ファイルを添付してメールを送るとコードが送られてくるので、それを印刷機に入力するだけで簡単。
アメリカでの運転は初めてで往復できるか不安だったので、グランドキャニオンの南、フラッグスタッフという町の空港で乗り捨てられるAlamoで予約した。 日本でも5年は走っていないペーパードライバーなので、2時間出張教習してもらい、後はタイムズのカーシェアで練習した。 それと免許センターで国際免許を発行した。特に試験とかはなくて手数料だけ払えばもらえる。警察署でも発行してくれるようだが即日発行ではないようだ。
今回のSIMはこれ。
Amazon.co.jp： 【AT&amp;amp;T】ハワイ・アメリカ本土 プリペイドSIM 30日 データ容量8GB 大容量通話付き: 家電・カメラ
回線はAT&amp;amp;Tで、30日、8GB、テザリング可で電話もできる(香港の番号だが国際通話ができる)と、申し分ないスペックに対して安すぎるのが若干不安だったが、 ドキュメント通り現地でSIMを挿してAPNを作成したらすぐにつながり、その後も全く問題なかった。すごい。
LA/ディズニーランド 行きの航空券が関空乗り継ぎだった。国内線スタートの良いところは搭乗時間の締め切りが国際線よりはるかに緩いことで、実際それに救われた。
10時間ほどのフライトでLAXに到着。Lax-itというライドシェア用の乗り場を目指す。 国際線ターミナルからは逆のところにあるので、ひっきりなしに走っているシャトルバスに乗る。 Uberをこの辺りに呼ぶとLax-it内のポート番号が表示される仕様だ。
ホテルにチェックイン後、Cole&amp;rsquo;sという店のDip sandwitchを食べに行く。サンドイッチを肉汁のスープに浸して食べる。 カフェみたいなのをイメージしていったら酒場で緊張した。
地下鉄でハリウッドに移動。運賃はTapというカードにチャージする仕組み。 持ってなかったら$2くらい余分に払うと自販機から出てくる。距離に関係なく同一運賃。 このカードでMetroのバスにも乗れるが、バスではチャージできないそうなので乗る場合は少し余分に入れておく。 ただ、結局バスは乗らなかった。ディズニーランド行きのバスもあっておそらく最安なんだが、 Localなのでとても時間がかかるし、サウス・ロサンゼルスというこれまた治安悪いエリアを突っ切るのが怖かったからだ。
ハリウッドではWalk of Fameの有名人の名前プレートを見ながら散歩していた。途中ハリウッドサインが見えたが想像していたより遠い。
せっかくなのでビバリーヒルズのロデオドライブにも行ってきた。表参道みたいな感じであまり用がなかった。
次の日はディズニーランドに行く前にGrand Central MarketのEggslutで朝食を取った。8時開店で8時半には着いたんだが、既に20人くらいの行列ができている人気店だ。 よく分からなかったのでslutというのを注文した。食べるまで気づかなかったんだが星野珈琲のモーニングのあれだ。美味しい。
Uberでディズニーランドに向かう。そういえばアプリ入れてないなと思ってPlayストアで調べたがひっかからない。もしやと思って調べてみると
は？？しょうがないのでアカウントの地域をアメリカに切り替えて入れた。1年間変更できず、日本向けのアプリをダウンロードできなくなった。納得いかない。 ともあれ、これでアプリからファストパスが取れるようになった。ファストパスは30分に1回取れるが、既に持ってるものを消費しなくてはいけない。 人気のアトラクションはかなり先の時間になってしまうか取れなくなってしまうので、 東京と同様のアトラクションが結構あるディズニーランドパークよりカリフォルニアアドベンチャーの方を先に回った方が良さそう。 ただ、パークの方でもスターウォーズのエリアはかなり作り込んであって新鮮だし、写真を撮ってくれる人もいるので暗くなる前に行くべきかもしれない。 撮ってもらった写真はMaxPassならアプリからダウンロードできる。一人って言ったら、&amp;ldquo;Oh, Solo&amp;quot;って言われたのにうまく反応できなくて悔しい。
カリフォルニアアドベンチャーの方はカーズのアトラクションが一番人気で、ファストパスを取るならそれが最有力だと思う。 スピード感がありながらフワッとする感じはなくて楽しかった。 撮影ポイントがあって出たところのモニターにアプリに入力するコードが表示されているんだが、 切り替わるのが早すぎるので、カメラで撮るなりして一旦コードだけ控えておいたほうが良い。 あとミッキーの顔が書かれた観覧車にも乗った。Swingするのに乗ったら、それこそバイキングかってぐらい揺らしてきて 泣きそうになった。実際泣き出す子もいると思う。
パークの城が東京で見るのと違うなと思ったら、こっちの城はシンデレラ城じゃなくて眠れる森の美女の城らしい。
行きのUberは$40くらいだったのに対して帰りは$60くらいかかった。需要と供給だ。
ラスベガス/re:Invent re:Invent前日にLAXからLASへ。 もう降りたところからスロットマシンが置いてあってさすがカジノの街だ。ここのUber乗り場はパーキングにある。</description>
    </item>
    
    <item>
      <title>SwiftのError enumとtry, if case</title>
      <link>https://www.sambaiz.net/article/249/</link>
      <pubDate>Sun, 24 Nov 2019 23:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/249/</guid>
      <description>Error Handling — The Swift Programming Language (Swift 5.1)
SwiftではErrorをenumで列挙でき、次の例でいうsomeParamのようにAssociated valuesを含めることもできる。 throwすると他の言語ではスタックトレースを作るので重い処理になるが、Swiftは作らないのでreturnするようにエラーを返せる。
import UIKit enum SampleError: Error { case ReasonFoo case ReasonBar(someParam: Int) } func errorFunc() throws -&amp;gt; String { throw SampleError.ReasonBar(someParam: 100) } throws付きの関数を呼ぶ際はdo-catchするtryか、nilが返るtry?、落ちるtry!のいずれかを付ける。 Associated valuesがある場合、==は使えず、if case .ReasonBar = errorのように比較する。
do { try errorFunc() } catch SampleError.ReasonFoo { print(&amp;#34;foo!&amp;#34;) } catch SampleError.ReasonBar(let someParam) { print(&amp;#34;bar! \(someParam)&amp;#34;) // =&amp;gt; bar! 100 } do { try errorFunc() } catch let error { if case .</description>
    </item>
    
    <item>
      <title>SwiftのXMLParser</title>
      <link>https://www.sambaiz.net/article/248/</link>
      <pubDate>Sun, 24 Nov 2019 23:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/248/</guid>
      <description>SwiftのXMLParserはイベント駆動のparser。
import UIKit class ParserSample: NSObject { private let parser: XMLParser init(data: Data) { parser = XMLParser(data: data) super.init() parser.delegate = self } func parse() { guard parser.parse() else { guard let err = parser.parserError else { print(&amp;#34;parse error but unknown reason&amp;#34;) return } print(&amp;#34;parse error: \(err.localizedDescription)&amp;#34;) return } print(&amp;#34;after parse()&amp;#34;) } } XMLParserDelegateでイベントを拾ってオブジェクトに詰めるなりする。全て実装する必要はなく、この例ではタグの開始と文字列、CDATA、エラー、パース終了時の関数を実装している。
extension ParserSample: XMLParserDelegate { func parser(_ parser: XMLParser, didStartElement elementName: String, namespaceURI: String?, qualifiedName qName: String?, attributes attributeDict: [String : String] = [:]) { print(&amp;#34;parsing &amp;lt;\(elementName)&amp;gt;&amp;#34;) if elementName == &amp;#34;ERROR&amp;#34; { self.</description>
    </item>
    
    <item>
      <title>ECS(EC2)のCloudFormation最小構成</title>
      <link>https://www.sambaiz.net/article/247/</link>
      <pubDate>Fri, 15 Nov 2019 20:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/247/</guid>
      <description>EC2でECSのServiceを動かすCFnテンプレートを書く。以前Fargateで動かしたものを一部再利用する。
ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する - sambaiz-net
EC2で動かす場合、自分でリソースが不足しないようにインスタンスのスケールを気遣うことになるが、VPC外での実行やprivilegedをtrueにするなどEC2でしかできないことがある。あと同リソースで比較すると安い。
まずはEC2インスタンス以外のリソースを書く。LaunchType以外はFargateのときとほぼ同じ。 LBなしでバッチのようなものを動かすことを想定した最小構成。
ECSCluster: Type: AWS::ECS::Cluster Properties: ClusterName: &amp;#39;test-cluster&amp;#39; LogGroup: Type: AWS::Logs::LogGroup Properties: LogGroupName: &amp;#39;test-task-log-group&amp;#39; RetentionInDays: 1 TaskDefinition: Type: AWS::ECS::TaskDefinition Properties: RequiresCompatibilities: - EC2 Cpu: &amp;#39;256&amp;#39; Memory: &amp;#39;512&amp;#39; ContainerDefinitions: - Name: &amp;#39;app&amp;#39; Image: &amp;#39;busybox&amp;#39; EntryPoint: - &amp;#39;sh&amp;#39; - &amp;#39;-c&amp;#39; Command: - &amp;#39;while true; do echo &amp;#34;{\&amp;#34;foo\&amp;#34;:1000,\&amp;#34;time\&amp;#34;:\&amp;#34;2019-05-09T20:00:00+09:00\&amp;#34;}&amp;#34;; sleep 10; done&amp;#39; Essential: &amp;#39;true&amp;#39; LogConfiguration: LogDriver: &amp;#39;awslogs&amp;#39; Options: awslogs-group: !Ref LogGroup awslogs-region: &amp;#39;ap-northeast-1&amp;#39; awslogs-stream-prefix: &amp;#39;app&amp;#39; Environment: - Name: &amp;#39;TZ&amp;#39; Value: &amp;#39;Asia/Tokyo&amp;#39; Volumes: - Name: &amp;#39;varlog&amp;#39; ECSService: Type: AWS::ECS::Service Properties: Cluster: !</description>
    </item>
    
    <item>
      <title>Lambda環境でできない処理をECSで実行する</title>
      <link>https://www.sambaiz.net/article/245/</link>
      <pubDate>Mon, 28 Oct 2019 22:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/245/</guid>
      <description>以前cdkbotというツールを出した。これはGitHubのPRからCDKのデプロイなどを実行できるツールでlambda上で動いていた。
PR上でCDKのレビューやデプロイを行うツールcdkbotを作った - sambaiz-net
npmやgitといった外部コマンドを実行するため、layerにバイナリを詰めて上げていた。
Lambda上でnpm installできるLayerを作った - sambaiz-net
CDKにはローカルのDockerfileをbuildしてECRに上げてくれる ecs.ContainerImage.fromAsset()という関数があって、これに対応させるためlayerにdockerを追加してみたのだがrootが取れず動かない。 rootなしで動くudockerでdind(docker in docker)のイメージを動かしたりもしてみたがbuildはできなかった。
この他にもCloudFrontなどリソースによっては作成に時間がかかり、Lambdaのタイムアウト上限に到達する問題もあったので、lambda+API Gatewayでwebhookのリクエストだけ受け取り、ECSのTaskを立ち上げて処理を行わせることにした。
templateにECSまわりのものを追加したところ、Serverless Application Repository非対応ということで上げられなくなってしまった。
AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net
Taskへのパラメータの受け渡し runTaskのcontainerOverridesでコマンドの引数としてlambdaに来たリクエストをそのまま渡そうとしたところ、8192文字文字の上限に当たってしまったので SQSで受け渡すことにした。
sess := session.New() sqsSvc := sqs.New(sess) if _, err := sqsSvc.SendMessage(&amp;amp;sqs.SendMessageInput{ MessageBody: aws.String(string(payload)), QueueUrl: aws.String(os.Getenv(&amp;#34;OPERATION_QUEUE_URL&amp;#34;)), MessageGroupId: aws.String(&amp;#34;group&amp;#34;), }); err != nil { fmt.Println(err.Error()) return response{ StatusCode: http.StatusInternalServerError, }, err } 同時実行数を制限する アプリケーションの特性上、同時実行されないようにしたい。 そこで普段はTask0のServiceを作成し、実行するときは要求Taskを1にして、Queueが空になるまで実行させ、最後に0に戻すようにした。Taskがない場合は立ち上がりにやや時間がかかるが、元々Lambdaで動いていたこともあって常に料金が発生する常駐リソースをなるべく使いたくなかった。
sess := session.New() sqsSvc := sqs.New(sess) for { res, err := sqsSvc.</description>
    </item>
    
    <item>
      <title>単調性のある式の解を二分法で数値的に求める</title>
      <link>https://www.sambaiz.net/article/246/</link>
      <pubDate>Mon, 28 Oct 2019 22:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/246/</guid>
      <description>AtCoder Beginner Contest 144の D - Water Bottleをやってみた。
高橋君は、底面が1辺 a cm の正方形であり、高さが b cm であるような直方体型の水筒を持っています。(水筒の厚みは無視できます。) この水筒の中に体積 x cm^3 の水を入れ、底面の正方形の1辺を軸として、この水筒を徐々に傾けます。 水を溢れさせずに水筒を傾けることができる最大の角度を求めてください。 水を溢れさせずに水筒を傾けることができる最大の角度を度数法で出力せよ。 出力は、ジャッジの出力との絶対誤差または相対誤差が10^6以下のとき正解と判定される。 水が溢れるパターンは次の2通りあって、水が入っている、または入ってない部分の三角柱を除いた部分の体積がxになるようなθをatanで出せる。
解説を見ると、これに加えて二分法を使って数値的に求める解法も紹介されていた。 二分法というのは解が含まれる区間の中間での値を求め、その値が解より小さいか大きいかによって二分したどちらかの区間を選ぶ操作を繰り返すことで区間の幅を狭めて解を求めるアルゴリズム。収束条件として式に単調性がある必要があるが、θに対してこぼれる限界の水の体積の式は単調減少するので用いることができる。 解説にもコードが付いていたがまずは見ずに書いてみた。
#include &amp;lt;iostream&amp;gt;#include &amp;lt;cmath&amp;gt;#include &amp;lt;iomanip&amp;gt;using namespace std; double waterVolume(int a, int b, double rad) { if (rad &amp;lt; atan(1.0 * b / a)) { return a * a * b - (a * (a * tan(rad)) / 2 * a); } else { return b * (b * tan(M_PI / 2 - rad)) / 2 * a; } } int main() { double a, b, x; cin &amp;gt;&amp;gt; a &amp;gt;&amp;gt; b &amp;gt;&amp;gt; x; double min = 0, max = M_PI / 2; while (true) { double m = (min + max) / 2; double vol = waterVolume(a, b, m); if (abs(vol - x) &amp;lt; pow(10, -6)) { cout &amp;lt;&amp;lt; setprecision(8) &amp;lt;&amp;lt; m / M_PI * 180 &amp;lt;&amp;lt; endl; return 0; } else if (vol &amp;gt; x) { min = m; } else { max = m; } } } 解説のコードでは、パターンの判定でa * tan(theta) &amp;lt;= bを使っているのと、有限回のループでxを上回らない最大のθを探すようになっていた。</description>
    </item>
    
    <item>
      <title>goyaccでparserを生成しLispのcons,car,cdrの式を評価する</title>
      <link>https://www.sambaiz.net/article/244/</link>
      <pubDate>Tue, 15 Oct 2019 09:41:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/244/</guid>
      <description>GoでLispのcons,car,cdrの式を評価したい。 流れとしては字句解析器(lexer, tokenizer, scanner)でソースコードを分割しtoken列にして、構文解析器(parser)で構文木を作るなりして評価できるようにする。
$ brew install clisp $ clisp &amp;gt; (cons 1 ()) (1) &amp;gt; (cons () 1) (NIL . 1) &amp;gt; (car (cons 1 (cons 2 3))) 1 &amp;gt; (cdr (cons 1 (cons 2 3))) (2 . 3) Goの字句解析器と構文解析器 Goの字句解析器と構文解析器がGoが実装されているので見てみる。
go/scanner ソースコードを分割してgo/tokenにする。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;go/token&amp;#34; &amp;#34;go/scanner&amp;#34; ) func main() { var sc scanner.Scanner src := []byte(`(&amp;#34;A&amp;#34; + &amp;#34;B&amp;#34;) + &amp;#34;C&amp;#34;`) errorHandler := func(pos token.Position, msg string) { fmt.</description>
    </item>
    
    <item>
      <title>ISUCON9予選と本選に出た</title>
      <link>https://www.sambaiz.net/article/243/</link>
      <pubDate>Sat, 05 Oct 2019 23:41:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/243/</guid>
      <description>ISUCONはLINEが運営しているIikanjini Speed Up CONtestで、Webサービスをチューニングしベンチマークのスコアを競う。 @hiderberqと@satoshunと出た。初出場。
前 @hiderberqに誘ってもらいチームSsstohが結成された。言語はGoで行くと決めて3回くらい集まって過去問を少しやった。
予選 会社が計画停電だったので話せるネットカフェでやった。 デプロイスクリプトを整えてnginxのアクセスログをalpで見られるようにする準備や MySQLのSlow Queryを出すところまでは良かったが、pprofのエンドポイントを叩くタイミングが悪くて profileが出力できずbcryptがボトルネックであることに最後まで気づけなかった。 最後そろそろ複数マシンで動かすかという段になったが、時間があまり残っていなかったしうまく動かすことができなかった。急いでやって最後のベンチマークがFailするよりはましだったかもしれない。仕様をたいして読まなかったのでキャンペーンの数値が変えられることも忘れていた。仕様を読み込むのは本当に重要。 これはだめだなと思ったらなぜか通過していた。600チーム中20位だ。ありがとう@satoshun。
ISUCON9 予選ログ - stsnブログ
間 pprofやnginxのLB、あとMySQLのEXPLAINを練習した。あとAPMを用意していった。
K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする - sambaiz-net
本選 本選はLINE本社、新宿のミライナタワーで行われる。ミライナタワー改札というのがあってアクセスが良い。 会場のカフェスペースもソファー席や座敷もあったりして良いスペースだった。
受付でかっこいいTシャツとイカしたステッカーを獲得。
ベンチマークが最初からFailするようになってて大変だった。 急いで開発したという設定で、コードや設定に不要なものが多く含まれていて翻弄された。 ロジックが複雑でこれを何とかしないと始まらないのではと思ったが、インデックスによってFailしなくなったのでそんなことはなかった。
昼には弁当が来た。美味しい。
午後はサーバーを1台再起不能にした。あとはN+1をやって終了。表彰と講評。ブラウザチェックNGで参考記録になったが、スコアは3611で17位相当だった。 1位の白金動物園は35801、2位のnilは29704(しかも一人で)とスコアを見ると全くかなわないという感じ。 ただN+1やインデックスなど基本的なところは押さえていたようだったので、まずはそのステージを超えなくてはいけなかった。 また一通りインメモリにデータを持ったら負荷のパラメータである日数を伸ばしたときにOOMになった。 今回はメモリが少なかったのでSQLの修正でスコアを上げられるようになっていたそうだ。
全てが終わり懇親会が始まった。
感想 普段クラウドのマネージドなサービスや金で解決することに慣れているとこんなに何もできないものかと愕然した。チームの二人には申し訳なさがある。 テーブルの変更などこれやるの億劫だなというところも上位チームは普通にやっていたりして要所の見極めや実装力が足りなかったり、 なんでこれができなかったんだというポイントが多々あるので練度が低く、本番の焦燥感に打ち負けた。 その点では本選まで来れたことは今後の資産になるだろうし、とても楽しかったので実質優勝だ。嬉しい。 運営にも感謝だ。</description>
    </item>
    
    <item>
      <title>HTTPのCache-Control Header</title>
      <link>https://www.sambaiz.net/article/242/</link>
      <pubDate>Fri, 04 Oct 2019 14:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/242/</guid>
      <description>HTTPでCache-Control Headerを付けてレスポンスすると、 クライアントにキャッシュさせてリクエストの回数やレスポンスの通信量を削減することができる。CDNによって挙動が異なるようなので注意が必要。
CDN切り替え作業における、Web版メルカリの個人情報流出の原因につきまして - Mercari Engineering Blog
また、Vary Headerで クライアントが送るHeaderの値が前回と異なる場合にリクエストが送られるようにでき、 Access-Control-Allow-Origin でOriginの値を返す場合、Vary: Origin のようにしないと 他のOriginからのリクエスト時にキャッシュされたHeaderを読んでしまいCORSエラーになってしまう。
max-age キャッシュが有効な秒数を表す。s-maxageというのもあってこれはプロキシやCDNといった共有キャッシュでのみ適用される時間。 Expires Headerがあったとしてもこれらが優先される。
Cache-Control: max-age=30 private 単一ユーザー向けのレスポンスであることを表し、共有キャッシュに保存させないようにする。
Cache-Control: private, max-age=30 no-cache ETag付きのリクエストを毎回投げる。 ETagはリソースの識別子を表すHeaderで、 前回返ってきたETagをリクエストのIf-None-Match Headerで渡すと、変更されてない場合は代わりに304 Not Modifiedが返るのでキャッシュを使い、帯域を節約できる。 つまり文字通りキャッシュされないというわけではなく、304が返ってきたらキャッシュしたデータが使われる。
no-store キャッシュさせない。毎回リクエストが飛びレスポンスが返る。
max-ageもExpires Headerもない場合でもLast-Modified Headerがあれば キャッシュされるのでキャッシュさせたくない場合は明示的に書いたほうがよい。
参考 HTTP キャッシュ | Web Fundamentals | Google Developers
IPA ISEC　セキュア・プログラミング講座：Webアプリケーション編　第5章 暴露対策：プロキシキャッシュ対策</description>
    </item>
    
    <item>
      <title>K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする</title>
      <link>https://www.sambaiz.net/article/241/</link>
      <pubDate>Tue, 01 Oct 2019 23:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/241/</guid>
      <description>Elastic Cloud on Kubernetes (ECK)で Kubernetesクラスタ上にElasticsearch, KibanaとAPM Serverを立ち上げ、外部のGo製APIサーバーのリクエストをトレースする。 クラスタはGKEで作成し、ノードプールはn2-highmem-4(2vCPU, 13GB)の3台にした。
インストール ElasticSearchやKibana, APM ServerのCRDやelastic-operatorなどをインストールする。
KubernetesのCustom Resource Definition(CRD)とCustom Controller - sambaiz-net
$ kubectl apply -f https://download.elastic.co/downloads/eck/0.9.0/all-in-one.yaml customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/trustrelationships.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created clusterrole.rbac.authorization.k8s.io/elastic-operator created clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created namespace/elastic-system created statefulset.apps/elastic-operator created secret/webhook-server-secret created serviceaccount/elastic-operator created $ kubectl get pod -n elastic-system NAME READY STATUS RESTARTS AGE elastic-operator-0 1/1 Running 1 91s $ kubectl -n elastic-system logs -f statefulset.apps/elastic-operator ... {&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1569230702.0881083,&amp;#34;logger&amp;#34;:&amp;#34;kubebuilder.controller&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;Starting workers&amp;#34;,&amp;#34;controller&amp;#34;:&amp;#34;elasticsearch-controller&amp;#34;,&amp;#34;worker count&amp;#34;:1} {&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1569230702.</description>
    </item>
    
    <item>
      <title>MySQLのslow queryを出してEXPLAINしてインデックスを張る</title>
      <link>https://www.sambaiz.net/article/240/</link>
      <pubDate>Sat, 21 Sep 2019 22:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/240/</guid>
      <description>MySQLのslow queryを出してEXPLAINしてインデックスを張るのを ISUCON9の予選問題でやってみる。
$ mysql --version mysql Ver 8.0.17 for osx10.14 on x86_64 (Homebrew) slow_query_logをONにすると実行時間がlong_query_timeを超えていてmin_examined_row_limit以上の行を返すクエリがslow query logに出力される。 log_queries_not_using_indexesが有効ならインデックスを使用してないクエリもログに出て、 log_throttle_queries_not_using_indexesでその分あたりの数を制限できる。 MySQL 8.0.14から追加されたlog_slow_extraをONにするとフィールドが追加される。
mysql&amp;gt; show variables like &amp;#39;%slow%&amp;#39;; +---------------------------+-----------------------------------+ | Variable_name | Value | +---------------------------+-----------------------------------+ | log_slow_admin_statements | OFF | | log_slow_extra | OFF | | log_slow_slave_statements | OFF | | slow_launch_time | 2 | | slow_query_log | OFF | | slow_query_log_file | /usr/local/var/mysql/mbp-slow.log | +---------------------------+-----------------------------------+ 6 rows in set (0.00 sec) mysql&amp;gt; show variables like &amp;#39;%long_query%&amp;#39;; +-----------------+-----------+ | Variable_name | Value | +-----------------+-----------+ | long_query_time | 10.</description>
    </item>
    
    <item>
      <title>Ansibleでnginxを入れてLoad Balancingさせる</title>
      <link>https://www.sambaiz.net/article/239/</link>
      <pubDate>Tue, 17 Sep 2019 09:42:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/239/</guid>
      <description>EC2でUbuntu Server 18.04 LTS (ami-07d0cf3af28718ef8) の t3.medium (2vCPU, 4GiB) インスタンスを3台立ち上げた。この内1台をLB用とし、2台のAppサーバーに負荷分散させる。
https://github.com/sambaiz/ansible-nginx-lb-example
nginx.conf LBとAppのnginx.conf。upstreamはデフォルトでラウンドロビンする。
$ cat conf/lb/nginx.conf ... http { ... upstream app-server { server ip-172-31-94-208.ec2.internal; server ip-172-31-88-90.ec2.internal; } server { listen 80; server_name .compute-1.amazonaws.com; access_log /var/log/nginx/app-server.log main; location / { proxy_pass http://app-server; } } } $ cat conf/app/nginx.conf ... http { ... server { listen 80; server_name .compute-1.amazonaws.com; location / { proxy_pass http://127.0.0.1:8080; } } } Ansibleの実行 まずInventoryを書いて疎通確認する。
$ pip install --user ansible $ cat hosts [lb] ec2-3-227-2-54.</description>
    </item>
    
    <item>
      <title>Goのnet/http/pprofでCPUやMemoryをprofileする流れと内部実装</title>
      <link>https://www.sambaiz.net/article/238/</link>
      <pubDate>Mon, 16 Sep 2019 13:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/238/</guid>
      <description>Goのnet/http/pprofは pprofで可視化できるprofile.protoを返すAPIを提供するpackage。 profileを出力する方法はほかにもあるが、サーバーのような動き続けるアプリケーションのprofileを取るのに使う。
go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる - sambaiz-net
profileを取る import _ &amp;quot;net/http/pprof&amp;quot;してhttp.ListenAndServe()する。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; _ &amp;#34;net/http/pprof&amp;#34; &amp;#34;time&amp;#34; &amp;#34;golang.org/x/crypto/bcrypt&amp;#34; ) func handler(w http.ResponseWriter, r *http.Request) { for i := 0; i &amp;lt; 3; i++ { bcrypt.GenerateFromPassword([]byte(&amp;#34;PASSWORD&amp;#34;), bcrypt.DefaultCost) } arr := []int{} for i := 0; i &amp;lt; 10000; i++ { arr = append(arr, i) } fmt.Fprintf(w, &amp;#34;OK&amp;#34;) } func main() { http.HandleFunc(&amp;#34;/foo&amp;#34;, handler) fmt.Println(&amp;#34;Listening on :8080&amp;#34;) if err := http.</description>
    </item>
    
    <item>
      <title>User NamespaceでrootになってNetwork Namespaceを作りvethとNATで外と通信する</title>
      <link>https://www.sambaiz.net/article/237/</link>
      <pubDate>Fri, 06 Sep 2019 02:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/237/</guid>
      <description>LinuxのNamespaceはuidやpid、networkなどを分離できる機能で、Dockerなどのコンテナ技術で使われている。
# Amazon Linux 2 (ami-0ff21806645c5e492) $ uname -r 4.14.138-114.102.amzn2.x86_64 User NamespaceでRootになる rootでないと正常終了しないコードを書いた。
$ cat /tmp/root_only.sh #!/bin/sh if [ &amp;#34;$(id -u)&amp;#34; != &amp;#34;0&amp;#34; ]; then echo &amp;#34;you are not root...&amp;#34; exit 1 fi echo &amp;#34;you are root!&amp;#34; 実際ec2-userではexit 1になる。
$ id -u 1000 $ sh /tmp/root_only.sh; echo $? you are not root... 1 User Namespaceを作る。rootでないとそれ以外のNamespaceは作れない。
$ unshare --net unshare: unshare failed: Operation not permitted $ unshare --user $ id uid=65534(nfsnobody) gid=65534(nfsnobody) groups=65534(nfsnobody) $ echo $$ 3537 他のshellを開き、Namespaceの外側からuid_mapを書き込む。 外側の1000から始まるuidを、このNamespaceの0から始まるuidに範囲1でマッピングする。</description>
    </item>
    
    <item>
      <title>SystemdのService</title>
      <link>https://www.sambaiz.net/article/236/</link>
      <pubDate>Fri, 30 Aug 2019 00:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/236/</guid>
      <description>SystemdはLinuxで動くServiceの管理などを行うデーモン。initの後継でchkconfig/servicceの代わりにsystemctlコマンドを使う。
$ systemctl start name.service $ systemctl stop name.service $ systemctl status name.service $ systemctl enable name.service $ systemctl disable name.service Serviceの一覧を見る。
$ systemctl list-units --type service --all UNIT LOAD ACTIVE SUB DESCRIPTION accounts-daemon.service loaded active running Accounts Service acpid.service loaded active running ACPI event daemon apparmor.service loaded active exited LSB: AppArmor initialization apport.service loaded active exited LSB: automatic crash report generation $ systemctl list-unit-files --type service UNIT FILE STATE accounts-daemon.</description>
    </item>
    
    <item>
      <title>PR上でCDKのレビューやデプロイを行うツールcdkbotを作った</title>
      <link>https://www.sambaiz.net/article/235/</link>
      <pubDate>Thu, 29 Aug 2019 22:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/235/</guid>
      <description>sambaiz/cdkbot
PRのコメントで/diffや/deployと打つとcdk diffやcdk deployが走る。 diffを見てレビューし、良ければ/deployでデプロイし完了するとmergeされる。
以前CircleCIでmerge時にdeployされる仕組みを作った。
CDK/CircleCI/GitHubでAWSリソース管理リポジトリを作る - sambaiz-net
ただ、この仕組みだと CFnの実行時エラーのためにデプロイできない状態のものがmasterブランチにmergeされてしまい、その修正のために何回も試行錯誤のPRを出すことになったり、 Stack間の依存がある場合リソースを削除するとcdk deployによって依存解決された順序だと失敗してしまうという問題があった。 cdkbotでは必要ならデプロイするStackを選べて、完了してからmergeすることでこれらの問題を解決した。 また、AWS外のCIにとても強い権限を与えていたがそれも必要なくなった。
単純にブランチの状態でデプロイしてしまうと古い状態に巻き戻ってしまう可能性があるので、内部でbaseブランチをmergeしていたり、 ラベルによってそのPRがデプロイ可能かどうかを制御していたりする。 最低限デプロイできるようになってから、この辺りの仕組みを整えるまでに存外に時間がかかった。
Serverless Application Repositoryに公開してあるので簡単にインストールできる。
AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net
 追記 (2019-10-26): ap-northeast-1に対応していないのと、ECSのリソースを作成できないため、Serverless Application Repositoryに公開するのはやめた。makeでインストールできる。 Lambda環境でできない処理をECSで実行する - sambaiz-net
 外部コマンド gitやnpmといった外部コマンドを実行する必要があるが、標準では入っていないのでLambda Layerで入れている。
Lambda上でnpm installできるLayerを作った - sambaiz-net
Go moduleのキャッシュ Dockerコンテナ内でテストを実行しているが、毎回go moduleの解決が走ることで時間はかかるし、テザリングの容量に大打撃を受けたので、 ローカルのキャッシュをコピーするようにした。
test: docker build -t cdkbot-npmbin ./npm-lambda-layer docker build -t cdkbot-test -f ./test/Dockerfile . docker rm -f cdkbot-test || true docker run -itd --name cdkbot-test cdkbot-test /bin/sh docker cp .</description>
    </item>
    
    <item>
      <title>CDKでECS&#43;Fargate上にDigdagを立ててCognito認証を挟む</title>
      <link>https://www.sambaiz.net/article/234/</link>
      <pubDate>Wed, 31 Jul 2019 03:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/234/</guid>
      <description>AWSでワークフローエンジンDigdagを立てるにあたりスケールを見越してECS+Fargateで動かす。 全体のコードはGitHubにある。
FargateでECSを使う - sambaiz-net
リソースはCDKで作る。最近GAになったので高レベルのクラスを積極的に使っている。
AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする - sambaiz-net
$ npm run cdk -- --version 1.2.0 (build 6b763b7) VPC FargateなのでVPCが必要。 テンプレートを書くとSubnetやRouteTable、NATGatewayなど記述量が多くなるところだが、CDKだとこれだけで済む。
CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net
const vpc = new ec2.Vpc(this, &amp;#39;VPC&amp;#39;, { cidr: props.vpcCidr, natGateways: 1, maxAzs: 2, subnetConfiguration: [ { name: &amp;#39;digdag-public&amp;#39;, subnetType: ec2.SubnetType.PUBLIC, }, { name: &amp;#39;digdag-private&amp;#39;, subnetType: ec2.SubnetType.PRIVATE, }, { name: &amp;#39;digdag-db&amp;#39;, subnetType: ec2.SubnetType.ISOLATED, } ] }) DB DigdagはPostgreSQLを使う。
const db = new rds.DatabaseCluster(this, &amp;#39;DBCluster&amp;#39;, { engine: rds.</description>
    </item>
    
    <item>
      <title>Lambda上でnpm installできるLayerを作った</title>
      <link>https://www.sambaiz.net/article/233/</link>
      <pubDate>Tue, 23 Jul 2019 23:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/233/</guid>
      <description>Lambda上でnpm installするためにnpmとnode, npmrc入りのLambda Layerを作った。 GitHubにある。
Lambda Layerでバイナリやライブラリを切り出す - sambaiz-net
まずは/usr/bin/npmをそのまま入れて実行してみた。
FROMlambci/lambda-base:build WORKDIR/opt RUN curl -sL https://rpm.nodesource.com/setup_12.x | bash - &amp;amp;&amp;amp; \  yum install -y nodejs &amp;amp;&amp;amp; \  mkdir bin &amp;amp;&amp;amp; \  cp /usr/bin/node bin/node &amp;amp;&amp;amp; \  cp /usr/bin/npm bin/ &amp;amp;&amp;amp; \  zip -yr /tmp/npm-layer.zip ./* $ docker build -t npmbin . $ docker run npmbin cat /tmp/npm-layer.zip &amp;gt; npm-layer.zip &amp;amp;&amp;amp; unzip npm-layer.zip -d layer 相対パスでの参照に失敗したようだが対象のパスが見当たらない。</description>
    </item>
    
    <item>
      <title>Lambda Layerでバイナリやライブラリを切り出す</title>
      <link>https://www.sambaiz.net/article/232/</link>
      <pubDate>Mon, 22 Jul 2019 21:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/232/</guid>
      <description>Lambdaで実行したい外部コマンドがある場合、通常バイナリをパッケージに含めることになりデプロイに時間がかかってしまう。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;os/exec&amp;#34; &amp;#34;github.com/aws/aws-lambda-go/events&amp;#34; &amp;#34;github.com/aws/aws-lambda-go/lambda&amp;#34; ) func handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) { cmd := exec.Command(&amp;#34;git&amp;#34;, &amp;#34;clone&amp;#34;, &amp;#34;https://github.com/sambaiz/foobar.git&amp;#34;, &amp;#34;/tmp/repo&amp;#34;) output, err := cmd.CombinedOutput() if err != nil { return events.APIGatewayProxyResponse{ Body: fmt.Sprintf(&amp;#34;%s %s&amp;#34;, string(output), err.Error()), StatusCode: 500, }, nil } return events.APIGatewayProxyResponse{ Body: string(output), StatusCode: 200, }, nil } func main() { lambda.Start(handler) } exec: &amp;#34;git&amp;#34;: executable file not found in $PATH Lambda Layerを使うと ライブラリやバイナリを切り出すことができ、複数Functionで共有することもできる。 ディレクトリをzipにしてLayerに指定すると中身が/optに展開され、/opt/binにはPATHが、/opt/libにはLD_LIBRARY_PATHが通るほか、 言語ごとのパッケージ置き場がある。</description>
    </item>
    
    <item>
      <title>AWS SAMとGoでPRのコメントに対して返事を返すGitHub Appを作る</title>
      <link>https://www.sambaiz.net/article/231/</link>
      <pubDate>Fri, 19 Jul 2019 21:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/231/</guid>
      <description>GitHub Appはリポジトリにインストールできるアプリケーションで、 Access TokenやOAuth Appと異なり ユーザーとは独立した権限を与えて実行することができる。
今回はPRの特定のコメントに反応して返事を返すAppを作る。
AWS SAMでデプロイする。全体のコードはGitHubにある。
AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net
GitHub Appの作成 Settings &amp;gt; Developer settings から作成できる。いろいろ項目はあるが、NameとHomepage URL、Webhook URLを入れればひとまず作成はできる。 Webhook URLはあとで決まるので適当な値を入れておく。必須にはなっていないがリクエストを検証するため適当なWebhook secretも入れる。 PermissionsはPull requestsではなくIssueのRead &amp;amp; Writeが必要で、 さらにそうすると表示されるようになるSubscribe to eventsのIssue commentにチェックを入れる。
作成すると秘密鍵がダウンロードできるのでSecretsmanagerに上げておき、LambdaのRoleにもこれを取得できるRoleを付ける。
AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する - sambaiz-net
$ aws secretsmanager create-secret --name GitHubCdkAppSecretKey --secret-string $(cat private-key.pem) Policies: - PolicyName: read-cdk-github-app-secret-key PolicyDocument: Version: &amp;#34;2012-10-17&amp;#34; Statement: - Effect: Allow Action: secretsmanager:GetSecretValue Resource: &amp;lt;secret-key arn&amp;gt; Webhooksのリクエスト内容 設定でチェックを入れたeventが起きると次のようなリクエストが送られてくる。 Headerの X-GitHub-Event によってbodyの中身が決まり、 X-Hub-Signature と、bodyと設定したWebhook secretから生成したHMACのMAC値を比較することで リクエストを検証することができる。</description>
    </item>
    
    <item>
      <title>KaggleのHouse Prices CompetitionをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/230/</link>
      <pubDate>Tue, 09 Jul 2019 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/230/</guid>
      <description>以前TitanicをやったXGBoostでHome Prices Competitionに挑戦する。
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
import pandas as pd df_train = pd.read_csv(&amp;#39;house-prices/train.csv&amp;#39;) df_test= pd.read_csv(&amp;#39;house-prices/test.csv&amp;#39;) 前処理 目的変数であるSalePriceと相関のある変数を抽出する。XGBoostは欠損値をそのまま扱うことができるので特に何もしていない。
KaggleのHome Prices CompetitionのKernelからデータの探り方を学ぶ - sambaiz-net
use_columns = df_train.corr()[&amp;#39;SalePrice&amp;#39;].drop(&amp;#39;SalePrice&amp;#39;).where(lambda x: abs(x) &amp;gt; 0.5).dropna().keys() # Index([&amp;#39;OverallQual&amp;#39;, &amp;#39;YearBuilt&amp;#39;, &amp;#39;YearRemodAdd&amp;#39;, &amp;#39;TotalBsmtSF&amp;#39;, &amp;#39;1stFlrSF&amp;#39;, &amp;#39;GrLivArea&amp;#39;, &amp;#39;FullBath&amp;#39;, &amp;#39;TotRmsAbvGrd&amp;#39;, &amp;#39;GarageCars&amp;#39;, &amp;#39;GarageArea&amp;#39;], dtype=&amp;#39;object&amp;#39;) def preprocess(df): return df[use_columns].copy() df_train_p = preprocess(df_train) df_train_p[&amp;#39;SalePrice&amp;#39;] = df_train[&amp;#39;SalePrice&amp;#39;] df_test_p = preprocess(df_test) ハイパーパラメータの最適化 ベイズ最適化でハイパーパラメータを決める。 他にもいろいろなパラメータがあるが、やみくもに増やしても提出した後のスコアが良くならなかった。
ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す - sambaiz-net
! pip install bayesian-optimization import xgboost as xgb from sklearn.model_selection import train_test_split from sklearn.</description>
    </item>
    
    <item>
      <title>ColabでKaggleのAPIを呼んで学習データのダウンロードと提出を行う</title>
      <link>https://www.sambaiz.net/article/229/</link>
      <pubDate>Tue, 09 Jul 2019 01:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/229/</guid>
      <description>Colabではランタイムがリセットされるたびにファイルが消えてしまうのでその度に学習データをアップロードするのが面倒。 そこでKaggle APIでファイルを持ってきてついでに提出まで行う。
Notebookを公開することも考えてなるべく認証情報を直書きしたくないのでGoogle DriveをマウントしてそこからTokenを持ってくることにする。 KaggleのMy AccountからAPI Tokenを発行しGoogle Driveに上げておく。
from google.colab import drive drive.mount(&amp;#39;/content/gdrive&amp;#39;) ! mkdir -p ~/.kaggle ! cp &amp;#34;gdrive/My Drive/kaggle/kaggle.json&amp;#34; ~/.kaggle/ ! pip install kaggle --upgrade ! kaggle config view competitions downloadでファイルをダウンロードしてくる。
! kaggle competitions download house-prices-advanced-regression-techniques -p house-prices import pandas as pd df_train = pd.read_csv(&amp;#39;house-prices/train.csv&amp;#39;) df_test= pd.read_csv(&amp;#39;house-prices/test.csv&amp;#39;) competitions submitで提出し、 competitions submissionsで提出履歴とスコアが見える。 リーダーボードはcompetitions leaderboardで取得できる。
! kaggle competitions submit house-prices-advanced-regression-techniques -f submit.csv -m &amp;#34;test submission&amp;#34; ! kaggle competitions submissions house-prices-advanced-regression-techniques !</description>
    </item>
    
    <item>
      <title>Cognito UserPoolのPreSignUp時に呼ばれるLambdaで登録ユーザーを制限する</title>
      <link>https://www.sambaiz.net/article/228/</link>
      <pubDate>Sun, 07 Jul 2019 17:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/228/</guid>
      <description>サードパーティのIdPからCognitoにSignUpできるようにする場合、特定のドメインのメールアドレスといったような制限をかけたいことがある。 PreSignUp時のLambdaでこれを弾いてやることでUserPoolに入らないようにすることができる。
Lambda CognitoEventUserPoolsPreSignupを受け取って返す。
package main import ( &amp;#34;errors&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-lambda-go/events&amp;#34; &amp;#34;github.com/aws/aws-lambda-go/lambda&amp;#34; ) func handler(event events.CognitoEventUserPoolsPreSignup) (events.CognitoEventUserPoolsPreSignup, error) { fmt.Printf(&amp;#34;PreSignup of user: %s\n&amp;#34;, event.UserName) if event.Request.UserAttributes[&amp;#34;email&amp;#34;] != &amp;#34;godgourd@gmail.com&amp;#34; { return event, errors.New(&amp;#34;Forbidden&amp;#34;) } return event, nil } func main() { lambda.Start(handler) } リソース UserPoolのLambdaConfigでトリガーを設定できる。 CognitoからLambdaを呼べるPermissionが必要。
UserPool: Type: AWS::Cognito::UserPool Properties: ... LambdaConfig: PreSignUp: !GetAtt PresignupLambdaFunction.Arn UserPoolLambdaInvokePermission: Type: AWS::Lambda::Permission Properties: Action: lambda:invokeFunction Principal: cognito-idp.amazonaws.com FunctionName: !GetAtt PresignupLambdaFunction.Arn SourceArn: arn:aws:cognito-idp:&amp;lt;region&amp;gt;:&amp;lt;account_id&amp;gt;:userpool/* なおALBのActionでCognito認証を入れると登録失敗時に500エラーになってしまう。これを回避するには自前でやるしかないのかもしれない。
LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net</description>
    </item>
    
    <item>
      <title>LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす</title>
      <link>https://www.sambaiz.net/article/227/</link>
      <pubDate>Wed, 03 Jul 2019 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/227/</guid>
      <description>ALBのTargetとしてLambdaが選択できるようになり、 若干の時間課金が発生する代わりに柔軟にルーティングできるAPI Gatewayのように使えるようになった。 ActionとしてCognito認証を入れて認証に失敗したらログイン画面を表示させる。
API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く - sambaiz-net
ACMで証明書を発行する HTTPSでListenするため証明書が必要。 AWS Certificate Manager (ACM)でAWSで使える証明書を無料で発行でき参照できる。 外部で取ったドメインでもよい。 検証方法はDNSとメールとで選ぶことができて、DNSで行う場合Route53ならワンクリックで検証用のCNAMEレコードを作成できる。 検証までやや時間がかかるのでちゃんと通ってるかnslookupで確認しといた方がよい。
Application Load Balancer (ALB) 次の要素から構成されるL7のロードバランサー。
 Listener: 指定したプロトコルとポートでリクエストを受ける。 ListenerRule: パスやHeaderなどの値を条件にどのTargetGroupにルーティングするかのルール。 TargetGroup: ルーティングする1つ以上のTarget。Instance, IP, Lambdaが選べる。  Ruleの作成 Serverless FrameworkではALBのenentを付けるだけでLambdaに向くRuleが作成されるが、そこにはCognitoを追加できなさそうなので使っていない。OnUnauthenticatedRequestで認証失敗時の挙動を選択できる。UserPoolとSecretありのClientはあらかじめ作っておく。コールバックURLにはhttps://&amp;lt;domain&amp;gt;/oauth2/idpresponseを追加する。
API Gatewayだとタイムアウトの上限が30秒なのに対してALBはLambdaの上限まで待てる。
$ cat serverless.yml service: alb-cognito-auth-example frameworkVersion: &amp;#34;&amp;gt;=1.28.0 &amp;lt;2.0.0&amp;#34; provider: name: aws runtime: go1.x region: ap-northeast-1 package: exclude: - ./** include: - ./bin/** functions: privateapi: handler: bin/privateapi timeout: 30 resources: Resources: ALBTargetGroup: DependsOn: InvokeLambdaPermissionForALB Type: AWS::ElasticLoadBalancingV2::TargetGroup Properties: Name: &amp;#34;private-lambda-target-group&amp;#34; TargetType: &amp;#34;lambda&amp;#34; Targets: - Id: !</description>
    </item>
    
    <item>
      <title>API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く</title>
      <link>https://www.sambaiz.net/article/226/</link>
      <pubDate>Wed, 03 Jul 2019 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/226/</guid>
      <description>ブラウザから直接API GatewayのエンドポイントにアクセスしたときにCognitoのTokenで認証し、失敗したらログイン画面を表示させる。 API GatewayでCognitoの認証をかける場合、AuthorizerでUserPoolを指定するのが最も簡単なパターンだが、 これだとHeaderにTokenを付けてアクセスする必要があり認証に失敗するとUnauthorizedが返る。
Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる - sambaiz-net
なおAPI GatewayではなくALBをLambdaの前段に挟めば今回やることが簡単に実現できる。
LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net
準備 UserPoolとClientを作成する。 CloudFormationで作成する場合SchemaのMutableのデフォルトがfalseで、変えると作り直されてしまうことに注意。
Resources: Userpool: Type: AWS::Cognito::UserPool Properties: AdminCreateUserConfig: AllowAdminCreateUserOnly: false Schema: - Mutable: true Name: email Required: true - Mutable: true Name: name Required: true UsernameAttributes: - email UserPoolName: testpool UserpoolClient: Type: AWS::Cognito::UserPoolClient Properties: UserPoolId: Ref: Userpool ClientName: testclient GenerateSecret: true その後、GoogleのOAuth Client IDを作成し、フェデレーションの設定を行ってGoogleアカウントでもログインできるようにした。 これはID Poolのフェデレーティッドアイデンティティとは異なる機能。 UserPoolのドメインや、外部IdPとのAttributes Mapping、Clientの設定はCloudFormationではできないので手で行う。
 追記 (2020-12-06): 今はCloudFormationで行えるようになっている。
CDKでCognito UserPoolとClientを作成しトリガーやFederationを設定する - sambaiz-net</description>
    </item>
    
    <item>
      <title>ReactのFunction ComponentとHooks</title>
      <link>https://www.sambaiz.net/article/225/</link>
      <pubDate>Thu, 20 Jun 2019 19:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/225/</guid>
      <description>久々にcreate-react-appを実行したら コンポーネントがReact.ComponentのクラスではなくFunction Componentになっていた。
Function Component Function Componentは関数で書かれるStateを持たないコンポーネントで、 簡潔に書けるだけではなくReact.createElement()と比べて45%くらい速いらしい。
45% Faster React Functional Components, Now – Missive App – Medium
const App: React.FC = () =&amp;gt; { return ( &amp;lt;div className=&amp;#34;App&amp;#34;&amp;gt; {FunctionalComponent({title: &amp;#34;HELLO FC&amp;#34;})} &amp;lt;/div&amp;gt; ); } interface Props { title: string } const FunctionalComponent: React.FC&amp;lt;Props&amp;gt; = (props) =&amp;gt; { return ( &amp;lt;div&amp;gt; {props.title} &amp;lt;/div&amp;gt; ); } v16.6でリリースされた React.memo()を使うと PureComponent のようにpropsが変わらない場合は再レンダリングさせなくすることができる。
const App: React.FC = () =&amp;gt; { return ( &amp;lt;div className=&amp;#34;App&amp;#34;&amp;gt; &amp;lt;FunctionalComponent title=&amp;#34;HELLO FC&amp;#34; /&amp;gt; &amp;lt;/div&amp;gt; ); } interface Props { title: string } const FunctionalComponent = React.</description>
    </item>
    
    <item>
      <title>AWS DeepRacerを始める</title>
      <link>https://www.sambaiz.net/article/224/</link>
      <pubDate>Mon, 10 Jun 2019 23:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/224/</guid>
      <description>AWS DeepRacerは自走する1/18スケールのレーシングカーで、 SageMakerやRoboMakerなどを使って強化学習し、実機を走らせたりバーチャルのDeepRacerリーグで競うことができる。 カメラの画像の処理や、強化学習のアルゴリズムの実装の必要はなく、報酬関数だけで動いてくれるので敷居が低い。
強化学習とDQN(Deep Q-network) - sambaiz-net
設定項目 Action space 取りうるアクションである速度とステアリングの組み合わせのリスト。次の項目から生成される。
 Maximum steering angle (1 - 30) Steering angle granularity (3, 5, 7) Maximum speed (0.8 - 8) Speed granularity (1, 2, 3) Loss type (Mean square error, Huber) Number of experience episodes between each policy-updating iteration (5 - 100)  Reward function 強化学習の報酬関数。次の入力パラメータを用いて実装する。
{ &amp;#34;all_wheels_on_track&amp;#34;: Boolean, # flag to indicate if the vehicle is on the track &amp;#34;x&amp;#34;: float, # vehicle&amp;#39;s x-coordinate in meters &amp;#34;y&amp;#34;: float, # vehicle&amp;#39;s y-coordinate in meters &amp;#34;distance_from_center&amp;#34;: float, # distance in meters from the track center  &amp;#34;is_left_of_center&amp;#34;: Boolean, # Flag to indicate if the vehicle is on the left side to the track center or not.</description>
    </item>
    
    <item>
      <title>CDK/CircleCI/GitHubでAWSリソース管理リポジトリを作る</title>
      <link>https://www.sambaiz.net/article/223/</link>
      <pubDate>Mon, 20 May 2019 09:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/223/</guid>
      <description>AWS CDKでリソースを記述し、PullRequestに対して自動でcdk diffで変更があるものを表示して、mergeしたときにcdk deployする。 全体のコードはGitHubにある。
AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする - sambaiz-net
 追記 (2019-08-29): このフローで起こったいくつかの問題を解決するため新しいツールを作った。 PR上でCDKのレビューやデプロイを行うツールcdkbotを作った - sambaiz-net
 CI Userの作成 まずcdkコマンドを実行するためのCI Userを作成する。これはCDK管理外のスタックで、AWSコンソール上から手動で上げる。
AWSのAssumeRole - sambaiz-net
AssumeRoleしかできないCIUserからCIAssumeRoleをassumeすることにした。
AWSTemplateFormatVersion: &amp;#39;2010-09-09&amp;#39; Resources: CIAssumeRole: Type: &amp;#39;AWS::IAM::Role&amp;#39; Properties: RoleName: &amp;#39;CIAssumeRole&amp;#39; ManagedPolicyArns: - &amp;#39;arn:aws:iam::aws:policy/AdministratorAccess&amp;#39; AssumeRolePolicyDocument: Version: &amp;#39;2012-10-17&amp;#39; Statement: - Effect: &amp;#39;Allow&amp;#39; Principal: AWS: - !Ref AWS::AccountId Action: - &amp;#39;sts:AssumeRole&amp;#39; CIGroup: Type: &amp;#39;AWS::IAM::Group&amp;#39; Properties: GroupName: &amp;#39;CI&amp;#39; CIPolicies: Type: &amp;#39;AWS::IAM::Policy&amp;#39; Properties: PolicyName: &amp;#39;CI&amp;#39; PolicyDocument: Statement: - Effect: Allow Action: &amp;#39;sts:AssumeRole&amp;#39; Resource: !</description>
    </item>
    
    <item>
      <title>AWS CDKでCloudFormationのテンプレートをTypeScriptから生成しデプロイする</title>
      <link>https://www.sambaiz.net/article/222/</link>
      <pubDate>Sun, 19 May 2019 01:43:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/222/</guid>
      <description>AWS CDK(Cloud Development Kit)はTypeScriptやJavaなどのコードから CloudFormationのテンプレートを生成して差分を確認しデプロイできる公式のツール。まだdeveloper preview。
$ npm i -g aws-cdk $ cdk --version 0.33.0 (build 50d71bf) $ mkdir cdk-vpc $ cd cdk-vpc $ cdk init app --language=typescript CloudFormationのリソースと対応するCfnFooや、それを内部で作成する高レベル(L2)のResource ClassFooが実装されている。 ただし、現状CfnFooに対応するResource Classが存在しないものや、複数のリソースを内部で作成するResource Classが存在する。 例えば、ec2.VpcはCfnVPCだけではなく、Public/Private Subnet、NATGatewayまでまとめて一般的な構成で作る。Resource Classはまだ変更が多い。
CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net
型があり補完が効くので通常のテンプレートと比べて書きやすいし、ループしたりすることもできる。
import * as cdk from &amp;#39;@aws-cdk/cdk&amp;#39; import * as ec2 from &amp;#39;@aws-cdk/aws-ec2&amp;#39; interface Export { vpc: ec2.Vpc } export class VPCStack extends cdk.Stack { protected deployEnv: string export: Export constructor(scope: cdk.</description>
    </item>
    
    <item>
      <title>ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する</title>
      <link>https://www.sambaiz.net/article/221/</link>
      <pubDate>Thu, 09 May 2019 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/221/</guid>
      <description>DAEMONを動かすことはできず、 fluentd logdriverもサポートされていないFargateで、 サイドカーとしてFluentdのコンテナを動かしてアプリケーションのログをS3に送る。 全体のコードはGitHubにある。
FargateでECSを使う - sambaiz-net
Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net
Fluentd 必要なプラグインと設定ファイルを入れたイメージを作る。
FROMfluent/fluentd:v1.4-1 USERroot COPY ./fluent.conf /fluentd/etc/ # install plugin RUN apk add --update-cache --virtual .build-deps sudo build-base ruby-dev \  &amp;amp;&amp;amp; gem install fluent-plugin-s3 -v 1.0.0 --no-document \  &amp;amp;&amp;amp; gem install uuidtools \  &amp;amp;&amp;amp; gem sources --clear-all \  &amp;amp;&amp;amp; apk del .build-deps \  &amp;amp;&amp;amp; rm -rf /var/cache/apk/* \  /home/fluent/.gem/ruby/*/cache/*.gem # set timezone (Alpine) RUN apk --update-cache add tzdata &amp;amp;&amp;amp; \  cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime &amp;amp;&amp;amp; \  apk del tzdata &amp;amp;&amp;amp; \  rm -rf /var/cache/apk/* fluent.</description>
    </item>
    
    <item>
      <title>カテゴリカル変数を変換するsklearnのLabel/OneHotEncoderとpandasのget_dummies</title>
      <link>https://www.sambaiz.net/article/220/</link>
      <pubDate>Mon, 06 May 2019 15:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/220/</guid>
      <description>次のデータを用いる。
data = [&amp;#34;tokyo&amp;#34;, &amp;#34;berlin&amp;#34;, &amp;#34;paris&amp;#34;, &amp;#34;amsterdam&amp;#34;, &amp;#34;paris&amp;#34;, &amp;#34;amsterdam&amp;#34;, &amp;#34;berlin&amp;#34;] partial_data = data[:4] preprocessing.LabelEncoder カテゴリカル変数を数値のラベルに変換する。
from sklearn import preprocessing le = preprocessing.LabelEncoder() le.fit(data) encoded = le.transform(partial_data) print(encoded) # [3 1 2 0] print(le.inverse_transform(encoded)) # [&amp;#39;tokyo&amp;#39; &amp;#39;berlin&amp;#39; &amp;#39;paris&amp;#39; &amp;#39;amsterdam&amp;#39;] preprocessing.OneHotEncoder One-hot vectorに変換する。デフォルトだとカテゴリーと同じ数の次元に変換されるので変数同士に相関がある多重共線性が生まれてしまうが、drop=&#39;first&#39;で最初の次元を消すことで回避できる。
oh = preprocessing.OneHotEncoder(drop=&amp;#39;first&amp;#39;) oh.fit([[d] for d in data]) encoded = oh.transform([[d] for d in partial_data]).toarray() print(encoded) # [[0. 0. 1.] [1. 0. 0.] [0. 1. 0.] [0. 0. 0.]] print(oh.</description>
    </item>
    
    <item>
      <title>DatadogのAWS integrationとAlertの設定をTerraformで行う</title>
      <link>https://www.sambaiz.net/article/219/</link>
      <pubDate>Sat, 04 May 2019 19:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/219/</guid>
      <description>DatadogのAWS integrationとAlertの設定をTerraformで行い、バージョン管理やレビューできるようにする。 全体のコードはGitHubに置いてある。
AWS Integration まずdatadog_integration_awsでAWS integrationの設定を作成してExternalIDを取得し、Policy/Roleを作成する。必要な権限はドキュメントを参照。
resource &amp;#34;datadog_integration_aws&amp;#34; &amp;#34;test&amp;#34; { account_id = &amp;#34;${var.aws_account_id}&amp;#34; role_name = &amp;#34;${var.aws_integration_role_name}&amp;#34; filter_tags = [&amp;#34;datadog:1&amp;#34;] } data &amp;#34;aws_iam_policy_document&amp;#34; &amp;#34;datadog_aws_integration_assume_role&amp;#34; { statement { actions = [&amp;#34;sts:AssumeRole&amp;#34;] principals { type = &amp;#34;AWS&amp;#34; identifiers = [&amp;#34;arn:aws:iam::464622532012:root&amp;#34;] } condition { test = &amp;#34;StringEquals&amp;#34; variable = &amp;#34;sts:ExternalId&amp;#34; values = [ &amp;#34;${datadog_integration_aws.test.external_id}&amp;#34;, ] } } } Datadog providerにはないSlackなどその他のintegrationは手動で設定する必要がある。 また、ログを集める場合Serverless Application Repositoryから公式のDatadog-Log-Forwarderを入れて AWS IntegrationのところにLambdaのARNを入れるのも手動。
 追記 (2020-12-07): 今はDatadog Forwaderとなり、Serverless Application Repositoryからではなく、直接CloudFormationのスタックを上げるようになっているのでaws_cloudformation_stackでデプロイできる。AWS IntegrationのRoleに必要なPolicyを与えてCollect LogsタブのLambda Cloudwatch Logsにチェックを入れると、Optionally limit resource collectionを設定しているならそのtagを持つ、全てのFunctionのStreamに自動でForwarderへのSubscription Filterが作成され転送が始まる。チェックを外すと削除されるが、この際もtagを見ているようで、条件を変更するとSubscription Filterが一部残ることがあった。ログだけではなくlambdaからのカスタムメトリクスの中継や、estimated_costなどの拡張メトリクスの送信も行う。</description>
    </item>
    
    <item>
      <title>Box-Cox transformationで非正規分布のデータを正規分布に近づける</title>
      <link>https://www.sambaiz.net/article/218/</link>
      <pubDate>Tue, 30 Apr 2019 17:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/218/</guid>
      <description>Box-Cox Transormationは次の式による変換。λ=0のときはlog(x)。
λが1より大きい場合は小さな値の間隔が圧縮され、小さい場合は大きな値の間隔が圧縮されるように変換される。
import numpy as np from scipy.special import boxcox1p import matplotlib.pyplot as plt from bokeh.plotting import figure from bokeh.io import output_notebook, show output_notebook() p = figure( title=&amp;#34;Box-Cox Transformations&amp;#34;, x_axis_label=&amp;#39;x&amp;#39;, y_axis_label=&amp;#39;λ&amp;#39;, ) for lam in [-1, 0, 1, 2]: v = np.array([boxcox1p(i, lam) for i in range(10)]) v = v / v.max() p.line(v, lam) p.circle(v, lam, size=8) show(p) これによって左右非対称な分布を対称(skew=0)な正規分布に近づけることができる。 以前正規分布に近づけるのに対数を取ったが、これはBox-Cox transformationの1ケースだといえる。
KaggleのHome Prices CompetitionのKernelからデータの探り方を学ぶ - sambaiz-net
試しに適当な左右非対称な分布のデータを変換してみる。
import pandas as pd import seaborn as sns p = np.</description>
    </item>
    
    <item>
      <title>CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる</title>
      <link>https://www.sambaiz.net/article/217/</link>
      <pubDate>Sat, 13 Apr 2019 23:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/217/</guid>
      <description>CircleCI 2.1からOrbというjobをパッケージ化したものが使えるようになり、 自分でjobを書かずとも様々な処理を実行させることができるようになった。
CircleCI 2.0でDocker imageをbuildしてタグを付けてContainer Registryに上げる - sambaiz-net
今回は
 aws-ecr slack  を使ってdocker buildしてECRにpushし、バージョンタグが付いている場合はSlackに通知させる。
AWS_ACCESS_KEY_IDとAWS_SECRET_ACCESS_KEYを環境変数に入れて、ECRのリポジトリを作成し、 SlackのwebhookのURLを発行しておく。
version: 2.1 orbs: aws-ecr: circleci/aws-ecr@3.1.0 slack: circleci/slack@2.3.0 executors: default: machine: true environment: ECR_REPO: &amp;#39;test-ecr-push&amp;#39; AWS_ECR_ACCOUNT_URL: &amp;#39;&amp;lt;account_id&amp;gt;.dkr.ecr.&amp;lt;region&amp;gt;.amazonaws.com&amp;#39; AWS_REGION: &amp;#39;&amp;lt;region&amp;gt;&amp;#39; CLUSTER_NAME: &amp;#39;test&amp;#39; jobs: notify_slack: executor: default steps: - slack/status: success_message: &amp;#39;${ECR_REPO}:${CIRCLE_TAG} was released&amp;#39; webhook: &amp;#39;https://hooks.slack.com/services/******&amp;#39; workflows: build-push: jobs: - aws-ecr/build_and_push_image: name: &amp;amp;build_version &amp;#39;build-version&amp;#39; executor: default repo: &amp;#39;${ECR_REPO}&amp;#39; tag: &amp;#39;${CIRCLE_TAG}&amp;#39; filters: branches: ignore: /.*/ tags: only: /^v.</description>
    </item>
    
    <item>
      <title>KaggleのHouse Prices CompetitionのKernelからデータの探り方を学ぶ</title>
      <link>https://www.sambaiz.net/article/216/</link>
      <pubDate>Mon, 08 Apr 2019 21:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/216/</guid>
      <description>Kaggleの家の売値を予測するCompetitionのKernelからデータの探り方を学ぶ。
Comprehensive data exploration with Python
正規化 予測する値であるSalePriceの分布を出すと、やや左に寄った非対称の分布をしている。
import pandas as pd import seaborn as sns df = pd.read_csv(&amp;#39;train.csv&amp;#39;) df[&amp;#39;SalePrice&amp;#39;].describe() sns.distplot(df[&amp;#39;SalePrice&amp;#39;]) count 1460.000000 mean 180921.195890 std 79442.502883 min 34900.000000 25% 129975.000000 50% 163000.000000 75% 214000.000000 max 755000.000000 scipy.stats.probplot()で 生成できる、2つの分布(今回はSalePriceの分布と正規分布)の同じ分位数の値をプロットしたQ-Q (quantile-quantile) plotを見ても直線で表されている正規分布から外れていることが分かる。 本来のQ-Q plotではこの直線は同じ分位数に同じ値が来るy=xに引かれるが、この関数が生成するプロットはxがスケールされているのでそうなっていない。
from scipy import stats import matplotlib.pyplot as plt res = stats.probplot(df[&amp;#39;SalePrice&amp;#39;], dist=&amp;#39;norm&amp;#39;, plot=plt) 正規分布であることが望ましいので対数をとって近づけてやる。
import numpy as np res = stats.probplot(np.log(df[&amp;#39;SalePrice&amp;#39;]), dist=&amp;#39;norm&amp;#39;, plot=plt) なお、この変換はBox-Cox transformationのλ=0のときにあたる。
Box-Cox transformationで非正規分布のデータを正規分布に近づける - sambaiz-net</description>
    </item>
    
    <item>
      <title>React, Material-UI, Unstated, RechartsでTODOを作った</title>
      <link>https://www.sambaiz.net/article/215/</link>
      <pubDate>Thu, 28 Mar 2019 17:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/215/</guid>
      <description>コード
create-react-app create-react-appでアプリを作成した。 TypeScriptを有効にしている。
$ npx create-react-app react-todo-unstated --typescript $ cd react-todo-unstated $ tree src/ src/ ├── App.css ├── App.test.tsx ├── App.tsx ├── index.css ├── index.tsx ├── logo.svg ├── react-app-env.d.ts └── serviceWorker.ts $ npm start Material-UI UIはMaterial-UIでUIで作った。
$ npm install --save @material-ui/core @material-ui/icons public/index.htmlにRobotoフォントを入れた。
&amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;https://fonts.googleapis.com/css?family=Roboto:300,400,500&amp;#34;&amp;gt; Unstated UnstatedはReact v16からのContext APIを使ったStateを管理するための薄いライブラリ。
$ npm install --save unstated Stateを持つContainerを作る。
class TodoContainer extends Container&amp;lt;TodoState&amp;gt; { state: TodoState = { newTodo: &amp;#34;&amp;#34;, todos: [], isCreating: false }; changeNewTodo(newTodo: string) { this.</description>
    </item>
    
    <item>
      <title>HI-VAE(Heterogeneous-Incomple VAE)の論文を読んで処理を追う</title>
      <link>https://www.sambaiz.net/article/214/</link>
      <pubDate>Fri, 22 Mar 2019 20:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/214/</guid>
      <description>HI-VAE(Heterogeneous-Incomple VAE)は現実のデータセットにありがちな連続値と離散値が混ざっていたり欠損値を含んでいるものを扱えるようにしたVAE。
論文: Alfredo Nazabal, Pablo M. Olmos, Zoubin Ghahramani, Isabel Valera (2018) Handling Incomplete Heterogeneous Data using VAEs
生成モデルVAE(Variational Autoencoder) - sambaiz-net
GitHubにTensorFlow実装が上がっているので論文と合わせて追ってみる。
入力データ 入力データdata.csvと、そのスキーマdata_types.csvが用意されていて、 様々なtypeのデータが含まれる24次元のデータセットであることが分かる。
type,dim,nclass pos,1, cat,3,3 cat,7,7 cat,4,4 count,1, ordinal,11,11 ordinal,11,11 ordinal,11,11 ordinal,11,11 ordinal,11,11 ordinal,11,11 real,1, real,1, real,1, real,1, real,1, real,1, pos,1, pos,1, pos,1, pos,1, pos,1, pos,1, cat,2,2 これに対して、xx%の確率でランダムな次元を欠損値として扱う際に対象とする行と次元を表す Missingxx_y.csvがある。
2,1 3,1 ... 29985,24 29998,24 typeごとのデータの扱い real(実数値) 標準化してencoderに入力し、decoderでは正規分布の平均と分散を 出力し サンプリングしてデータを生成する。
pos(正の実数) 対数を標準化してencoderに入力し、decoderでは正規分布の平均と分散を 出力し サンプリングしたデータをexp()で元のレンジに戻す。
count 対数を取ってencoderに入力し、decoderではポアソン分布の平均λを 出力し サンプリングしてデータを生成する。</description>
    </item>
    
    <item>
      <title>VAEでエンコードしたMNISTの潜在空間をt-SNEで可視化する</title>
      <link>https://www.sambaiz.net/article/213/</link>
      <pubDate>Sun, 10 Mar 2019 19:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/213/</guid>
      <description>t-SNEは多次元のデータを2,3次元上にマッピングして可視化できるようにする手法の一つで、 Stochastic Neighbor Embedding(SNE, 確率的近傍埋め込み)という手法をベースに、t分布を用いるなどして改良したもの。
Visualizing Data using t-SNE
SNE まず入力データ間の類似度をユークリッド距離を用いた次の条件付き確率p_{j|i}で表す。 これはx_iを中心とした正規分布上で、確率密度に基づいて隣り合うデータを選ぶ場合x_jが選ばれる確率となる。
同様に出力データでも次の条件付き確率q_{j|i}を計算する。σ=1/sqrt(2)とする。
この分布間のKL情報量を勾配降下法で最小化していくことで出力を最適化するのがSME。
自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net
ロジスティック回帰の尤度と交差エントロピーと勾配降下法 - sambaiz-net
t-SNE t-SNEでは条件付き確率ではなく同時確率を用いる。また、qを自由度1のt分布で表す。
MNISTの潜在空間をt-SNEで可視化した結果 以前作ったVAEのMNISTモデルの潜在空間を scikit-learnのTSNEで可視化する。
PyTorchでVAEのモデルを実装してMNISTの画像を生成する - sambaiz-net
%matplotlib inline import matplotlib.pyplot as plt from sklearn.manifold import TSNE from random import random colors = [&amp;#34;red&amp;#34;, &amp;#34;green&amp;#34;, &amp;#34;blue&amp;#34;, &amp;#34;orange&amp;#34;, &amp;#34;purple&amp;#34;, &amp;#34;brown&amp;#34;, &amp;#34;fuchsia&amp;#34;, &amp;#34;grey&amp;#34;, &amp;#34;olive&amp;#34;, &amp;#34;lightblue&amp;#34;] def visualize_zs(zs, labels): plt.figure(figsize=(10,10)) points = TSNE(n_components=2, random_state=0).fit_transform(zs) for p, l in zip(points, labels): plt.scatter(p[0], p[1], marker=&amp;#34;${}$&amp;#34;.</description>
    </item>
    
    <item>
      <title>PyTorchでVAEのモデルを実装してMNISTの画像を生成する</title>
      <link>https://www.sambaiz.net/article/212/</link>
      <pubDate>Thu, 07 Mar 2019 19:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/212/</guid>
      <description>PyTorchでVAEを実装しMNISTの画像を生成する。
生成モデルVAE(Variational Autoencoder) - sambaiz-net
学習データ datasetsのMNIST画像を使う。
from torchvision import datasets, transforms transform = transforms.Compose([ transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))]) dataset_train = datasets.MNIST( &amp;#39;~/mnist&amp;#39;, train=True, download=True, transform=transform) dataset_valid = datasets.MNIST( &amp;#39;~/mnist&amp;#39;, train=False, download=True, transform=transform) dataloader_train = utils.data.DataLoader(dataset_train, batch_size=1000, shuffle=True, num_workers=4) dataloader_valid = utils.data.DataLoader(dataset_valid, batch_size=1000, shuffle=True, num_workers=4) VAE それぞれ3層のEncoderとDecoder。
import torch import torch.nn as nn import torch.nn.functional as F device = &amp;#39;cuda&amp;#39; class VAE(nn.Module): def __init__(self, z_dim): super(VAE, self).__init__() self.dense_enc1 = nn.Linear(28*28, 200) self.</description>
    </item>
    
    <item>
      <title>SageMaker NotebookでGitリポジトリにSSHでpush/pullできるようにする</title>
      <link>https://www.sambaiz.net/article/211/</link>
      <pubDate>Mon, 04 Mar 2019 22:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/211/</guid>
      <description>Sagemaker NotebookはAWSの機械学習のワークフローを提供するSageMakerの一部である マネージドなJupyter Notebooksで、可視化などはもちろん、ここから複数インタンスでの学習ジョブを実行したりすることができる。
Git統合 によってノートブック作成時にGitHubなどのリポジトリを指定すると前もって持ってきてくれるようになったが、 今のところHTTPSエンドポイントにしか対応していないようで、ユーザー名・パスワードまたはトークンといった個人に紐づく認証情報が必要になる。 今回はこの機能を使わずに、ライフサイクル設定でssh鍵を置き、これでpush/pullできるようにする。
パスフレーズなしの鍵を作って公開鍵を対象リポジトリのDeployKeyに登録してread/writeできるようにする。
$ mkdir sagemaker-sshkey $ cd sagemaker-sshkey $ ssh-keygen -t rsa -b 4096 -f id_rsa -N &amp;#34;&amp;#34; $ pbcopy &amp;lt; id_rsa.pub 秘密鍵はSSMのParameter Storeに登録する。
AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する - sambaiz-net
$ aws ssm put-parameter --name &amp;#34;sagemaker-sshkey&amp;#34; --value &amp;#34;`cat id_rsa`&amp;#34; --type String --overwrite $ aws ssm get-parameters --names &amp;#34;sagemaker-sshkey&amp;#34; ライフサイクル設定でノートブック開始時に次のスクリプトが実行されるようにする。 このスクリプトはrootで実行される。Parameter Storeが読める権限をNotebookのIAMに付けておく。
#!/bin/bash  set -e su - ec2-user &amp;lt;&amp;lt;EOF cd /home/ec2-user aws ssm get-parameters --names &amp;#34;sagemaker-sshkey&amp;#34; | jq -r &amp;#34;.</description>
    </item>
    
    <item>
      <title>生成モデルGAN(Generative Adversarial Network)</title>
      <link>https://www.sambaiz.net/article/210/</link>
      <pubDate>Fri, 22 Feb 2019 23:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/210/</guid>
      <description>GAN(Generative Adversarial Network)は生成器Gと、データが本物かどうか識別する識別器Dを交互に最適化していく生成モデル。 データの評価は識別器によって行われるので、VAEと異なり分布を仮定して尤度を用いる必要がなく、より良いデータが生成できるが、 GとDを交互に最適化した結果振動してしまいナッシュ均衡に収束せず、またどちらかが先に最適化されてしまうと 同じようなデータばかり生成してしまうmode collapseや勾配が消えてしまったりして うまく学習できないことがある。
生成モデルVAE(Variational Autoencoder) - sambaiz-net
識別器(Discriminator) 生成されたデータの分布をp_g(x)、真のデータの分布をp_{data}(x)として、同数のデータにそれぞれy=0, 1のラベルを付ける。 識別器D(x)はyが0か1かの分類モデルで、負の交差エントロピー誤差V(D)を最大化するように学習する。
最適化したあとのDをD^とすると、目的関数V(D^)はJensen-Shannon(JS)ダイバージェンスを使って表せる。これを最小化するのがGANの目的。
生成器(Generator) p_dataとp_gのJSダイバージェンスが小さくなるように学習する。生成器Gを学習するための目的関数は次の通りで、これを最小化する。</description>
    </item>
    
    <item>
      <title>Chrome ExtensionsとChrome Apps</title>
      <link>https://www.sambaiz.net/article/209/</link>
      <pubDate>Tue, 19 Feb 2019 23:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/209/</guid>
      <description>Chrome Extrnsions ツールバーに表示され、ChromeのAPIを呼んで色々できる拡張機能で、manifestとhtml, js, cssなどから構成される。 開発中はディレクトリごとchrome://extensions/から読み込むとインストールでき、ツールバーにアイコンが表示される。
test-chrome-extension
manifest.json manifest_version, name, versionと、brower_actionかpage_actionのどちらかはRequired。
{ &amp;#34;manifest_version&amp;#34;: 2, &amp;#34;name&amp;#34;: &amp;#34;test-chrome-extension&amp;#34;, &amp;#34;version&amp;#34;: &amp;#34;1.0&amp;#34;, &amp;#34;icons&amp;#34;: { &amp;#34;128&amp;#34;: &amp;#34;images/icon-128.png&amp;#34; }, &amp;#34;page_action&amp;#34;: { &amp;#34;default_icon&amp;#34;: { &amp;#34;32&amp;#34;: &amp;#34;images/icon-32.png&amp;#34; } }, &amp;#34;options_page&amp;#34;: &amp;#34;options.html&amp;#34;, &amp;#34;background&amp;#34;: { &amp;#34;scripts&amp;#34;: [ &amp;#34;background.js&amp;#34; ], &amp;#34;persistent&amp;#34;: false }, &amp;#34;permissions&amp;#34;: [ &amp;#34;declarativeContent&amp;#34;, &amp;#34;storage&amp;#34; ], &amp;#34;content_security_policy&amp;#34;: &amp;#34;script-src &amp;#39;self&amp;#39;; object-src &amp;#39;self&amp;#39;&amp;#34; }  page_action  常にツールバーに表示されているbrowser_actionに対して、限られたページでのみ有効なAction。 有効かどうかは declarativeContent.onPageChangedの conditionsや、tags.onUpdatedのリスナー内で制御する。
 options_page: &amp;ldquo;拡張機能のオプション&amp;quot;で表示されるページ background  インストール時や更新時など必要なときにロードされるスクリプト。イベントリスナーはここで設定する。
chrome.runtime.onInstalled.addListener(() =&amp;gt; { chrome.declarativeContent.onPageChanged.removeRules(undefined, () =&amp;gt; { chrome.</description>
    </item>
    
    <item>
      <title>Apache SparkのRDD, DataFrame, DataSetとAction, Transformation</title>
      <link>https://www.sambaiz.net/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/208/</guid>
      <description>Sparkとは ハイパフォーマンスな汎用分散処理システム。 HDFSやS3といった分散ストレージとHadoop YARNといったクラスタマネージャと共に使われる。 中間データをメモリに置いておくことでHadoopのMapReduceよりも高速に処理することができる。 APIはJava, Scala, Python, Rのものがあって、 Pythonは手軽に書ける一方、パフォーマンスはJVMとのやりとりが発生するため落ちる。
HDFS(Hadoop Distributed File System)とは - sambaiz-net
RDDとDataFrameとDataSet RDD(Resilient Distributed Dataset)はSpark Coreの低レベルな インタフェースで、 型を持つイミュータブルな分散コレクション。
DataFrameはSpark SQLのテーブル状のデータ形式で、 Tungstenというバイトレベルの最適化や Catalystというクエリのオプティマイザが効くので自分でRDDのAPIを呼ぶよりパフォーマンスが良い。
DataSetは型を持つDataFrameで、Spark 2.0からはDataFrameもDataset[Row]のエイリアスになった。
ActionとTransformation 外部への出力といった副作用を持つActionに対して RDDを返すだけの処理をTransformationという。 Transformationは都度実行されるのではなく Actionが実行される際に、依存関係を表すDAG(Directed Acyclic Graph) をもとに必要なものが遅延評価される。DAGはWeb UIで可視化できる。
SparkのWeb UIでJobのStageとExecutorによるTask分散、SQLのPhysical planを確認する - sambaiz-net
また、ネットワークやノードの障害によって計算結果が失われても依存関係をたどり、 並列に計算することで高速に復旧できるようになっている。
narrow dependencyとwide dependency TransformationはRDDのパーティションに対して各Executorが並列に実行する。 mapやfilterなどの、見るパーティションが単一か他と被らない依存関係をnarrow dependencyといって、 そのExecutorだけで処理が完結するためパイプラインでまとめて実行でき速い。 一方、groupByKeyなどの一つのパーティションが複数のパーティションの処理で必要とされる依存関係をwide dependencyといって、 そのパーティションをExecutorが持っていない場合、コストが高いシャッフルが発生する。 シャッフルを回避するためにspark.sql.autoBroadcastJoinThresholdより小さいDataFrameをjoinする際は全てのExecutorにそれを送るBroadcast Hash Joinが行われる。 シャッフルを必要としない一連の実行単位をstageという。
参考 High Performance Spark - O&amp;rsquo;Reilly Media
RDD vs DataFrames and Datasets: A Tale of Three Apache Spark APIs</description>
    </item>
    
    <item>
      <title>AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する</title>
      <link>https://www.sambaiz.net/article/207/</link>
      <pubDate>Sun, 10 Feb 2019 16:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/207/</guid>
      <description>AWS SAM (Serverless Application Model)はAWS公式の サーバーレスアプリケーションのビルドツール。 CloudFormationのテンプレートを設定ファイルに書くことでLambda関数と共にイベントトリガーや他のリソースも含めてデプロイでき、 その点でServerless Frameworkと立ち位置が近いが、向こうがLambda以外のサーバーレス環境にも対応していたり、 プラグインによって機能拡張できるようになっている一方、こちらは比較的薄いツールになっている。 ただ、Serverless Application Repositoryで公開するにはSAMの形式にする必要があり、 Serverless FrameworkにもSAMのテンプレートを出力するプラグインがある。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
SAM CLIのインストール $ brew tap aws/tap $ brew install aws-sam-cli $ sam --version SAM CLI, version 0.11.0 init initすると次の構成のディレクトリが作られる。
$ sam init --runtime go1.x -n test-sam $ cd test-sam/ $ ls Makefile	README.md	hello-world	template.yaml template.yamlの中に関数の設定やCloudFormationのテンプレートを書く。
$ cat template.yaml AWSTemplateFormatVersion: &amp;#39;2010-09-09&amp;#39; Transform: AWS::Serverless-2016-10-31 Description: &amp;gt;test-sam Sample SAM Template for test-sam # More info about Globals: https://github.</description>
    </item>
    
    <item>
      <title>CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う</title>
      <link>https://www.sambaiz.net/article/206/</link>
      <pubDate>Sun, 03 Feb 2019 17:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/206/</guid>
      <description>Aurora ServerlessはオートスケールするAuroraで、 使ったAurora Capacity Unit (ACU)によって料金が発生するため、 使用頻度が少なかったり変動するアプリケーションにおいて安くRDBを使うことができる。 インスタンスを立てると最低でも月3000円くらいかかるが、Serverlessだとほとんどストレージ分から運用することができて趣味でも使いやすい。 ただしLambdaと同様に常に同等のリソースを使っている状態だとインスタンスと比べて割高になる。
今回はLambdaで使う。 Serverlessと名前には付いているが用途としてはLambdaに限らず、 むしろコンテナの数が容易に増え得るLambdaは同時接続数が問題になるRDBと一般に相性が良くない。 現在Betaの、コネクションを張らずにHTTPSでクエリを投げられるData APIはこの問題を解消すると思われるが、トランザクションが張れなかったり、レスポンスサイズに制限があるようだ。今回はコンソール上から初期クエリを流すためにData APIを有効にしている。
他の選択肢として、DynamoDBは現状最有力で最近トランザクションもサポートされたがSQLのように複雑なクエリは投げられない。 Athenaはクエリは投げられるがそこそこ時間がかかるし、INSERT/UPDATEはできずクエリごとに料金が発生する。
Serverless Frameworkを使ってリソースを作成しデプロイする。リポジトリはここ。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
VPCの作成 Aurora Serverlessの制限の一つとしてVPC内からしか接続しかできないというものがある。ということでVPCから作成していく。以前Terraformで作ったのと同じリソースをCloudFormationで作る。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
LambdaをVPC内で動かすとコンテナ起動時にENIも作成するため立ち上がりの際時間がかかる。必要なら定期的に呼び出して削除されないようにする。 また、今回はテストのため/24でVPCを切っているが、小さいとENIのIPアドレスが枯渇する可能性がある。
 VPC  TestVPC: Type: AWS::EC2::VPC Properties: CidrBlock: 172.32.0.0/24 Tags: - Key: Name Value: test-vpc  Subnet  Aurora Serverlessのために少なくとも2つのサブネットが必要。
TestPublicSubnet: Type: AWS::EC2::Subnet Properties: VpcId: !Ref TestVPC CidrBlock: 172.32.0.0/25 AvailabilityZone: us-east-1d Tags: - Key: Name Value: test-public-subnet1 TestPrivateSubnet1: Type: AWS::EC2::Subnet Properties: VpcId: !</description>
    </item>
    
    <item>
      <title>PyTorchでMNISTする</title>
      <link>https://www.sambaiz.net/article/205/</link>
      <pubDate>Sat, 19 Jan 2019 23:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/205/</guid>
      <description>PyTorchはFacebookによるOSSの機械学習フレームワーク。 TensorFlow(v1)よりも簡単に使うことができる。 TensorFlow 2.0ではPyTorchのようにDefine-by-runなeager executionがデフォルトになるのに加え、パッケージも整理されるようなのでいくらか近くなると思われる。
使い方 インストール Colabで動かす。まずpipでインストール。
!pip install torch torchvision autograd(自動微分) Tensorは自身が作成された関数の参照.grad_fnを持ち、backward()が呼ばれるとbackpropしてrequires_grad=TrueなTensorの勾配を自動で計算し.gradに入れてくれる。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
import torch x = torch.randn(4, 4) y = torch.randn(4, 1) w = torch.randn(4, 1, requires_grad=True) b = torch.randn(1, requires_grad=True) y_pred = torch.matmul(x, w) + b loss = (y_pred - y).pow(2).sum() print(x.grad, w.grad) # None None  loss.backward() print(x.grad, w.grad) # None tensor([...]) with torch.no_grad(): y_eval = torch.matmul(x, w) + b print(y_eval.requires_grad) # False Module nnパッケージにLinearやConv2dといったModuleが実装されていて、次のように呼び出すとforward()が 呼ばれ順伝播する。</description>
    </item>
    
    <item>
      <title>AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する</title>
      <link>https://www.sambaiz.net/article/204/</link>
      <pubDate>Mon, 07 Jan 2019 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/204/</guid>
      <description>DBのパスワードやAPIトークンといった認証情報をバージョン管理するコードや設定ファイル上に書くとOSS化など公開範囲を広げるときにやや困るし漏れるリスクが高まるのでなるべく避けたい。 そこでSSMのParameter Storeに値を置き、実行時やデプロイ時に参照する。
SSMのParameter StoreとSecrets Manager Systems Manager (SSM)はAWSのリソースを可視化したり操作を自動化したりするサービス群で、 設定を持つParameter Storeはその一つ。値は暗号化して持つこともできる。 料金はかからない。
SSMのParameter Storeと似たような別のAWSのサービスに Secrets Managerというのがあって、RDSなどと連携してLambdaによって定期的に新しい値を生成しローテーションさせることができる。 ただし料金がシークレットの件数($0.4/月)とAPIコール($0.05/10000回)でかかる。
CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net
今はParamter StoreとSecrets Managerが統合されていて、Parameter StoreのAPIでどちらも参照できるようだ。 今回はローテーションしないので単純に料金がかからないParameter Storeの方に書き込むことにする。 ただし、Parameter Storeは現状一度に大量のリクエストが飛ぶような使い方をするとRate exceededになってしまう問題がある。
実行時の値取得 実行時に値を取得するのはこんな感じ。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/awserr&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/ssm&amp;#34; ) type Parameter struct { ssm *ssm.SSM } func newParameter(sess *session.Session) *Parameter { return &amp;amp;Parameter{ ssm: ssm.New(sess), } } func (s *Parameter) Get(name string, decrypt bool) (string, error) { param, err := s.</description>
    </item>
    
    <item>
      <title>AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する</title>
      <link>https://www.sambaiz.net/article/203/</link>
      <pubDate>Tue, 01 Jan 2019 17:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/203/</guid>
      <description>AWS GlueはマネージドなETL(Extract/Transform/Load)サービスで、Sparkを使ってS3などにあるデータを読み込み加工して変換出力したり、AthenaやRedshift Spectrumで参照できるデータカタログを提供する。 今回はS3のCSVを読み込んで加工し、列指向フォーマットParquetに変換しパーティションを切って出力、その後クローラを回してデータカタログにテーブルを作成してAthenaで参照できることを確認する。
料金はジョブがDPU(4vCPU/16GBメモリ)時間あたり$0.44(最低2DPU/10分)かかる。 また、クローラも同様にDPUで課金される。
なお、AthenaのCTASでもParquetを出力することができる。 出力先にファイルがないようにする必要があったり重いクエリは失敗することがあるが手軽で良い。
import * as athena from &amp;#39;athena-client&amp;#39; const clientConfig: athena.AthenaClientConfig = { bucketUri: &amp;#39;s3://*****/*****&amp;#39; skipFetchResult: true, }; const awsConfig: athena.AwsConfig = { region: &amp;#39;us-east-1&amp;#39;, }; const client = athena.createClient(clientConfig, awsConfig); (async () =&amp;gt; { await client.execute(` CREATE TABLE ***** WITH ( format = &amp;#39;PARQUET&amp;#39;, external_location = &amp;#39;s3://*****&amp;#39; ) AS ( SELECT ~~ ) })(); 開発用エンドポイント ジョブの立ち上がりにやや時間がかかるため開発用エンドポイントを立ち上げておくとDPUが確保されて効率よく開発できる。 立ち上げている間のDPUの料金がかかる。つまりずっとジョブを実行し続けているようなもので結構高くつくので終わったら閉じるようにしたい。
ローカルやEC2から自分で開発用エンドポイントにsshしてREPLで実行したりNotebookを立てることもできるが、 コンソールから立ち上げたNotebookは最初からつながっていて鍵の登録も必要なくて楽。
$ ssh -i private-key-file-path 9007:169.</description>
    </item>
    
    <item>
      <title>強化学習とDQN(Deep Q-network)</title>
      <link>https://www.sambaiz.net/article/202/</link>
      <pubDate>Tue, 18 Dec 2018 01:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/202/</guid>
      <description>強化学習というのは将来に得られる報酬を最大化するような行動を学習していくもの。
状態価値関数による学習 状態sのときに取る行動aを決定する方策(Policy)をπ(s)、次の状態s&amp;rsquo;を予測するモデルをP(s,a,s&#39;)、直後に得られる即時報酬r_{t+1}を予測するモデルをR(s,a)とすると、将来得られる報酬の期待値である状態価値関数Vπは次の式で再帰的に表すことができ、この形式をベルマン方程式という。 同じ報酬なら早くに得られた方が良いという考えから将来の報酬rは1ステップ遅れるたびに割引率γが掛けられる。
どんな状態においても状態価値関数を最大化させる最適方策π*を探すにあたり、定義通り将来の報酬を待つのではなく、即時報酬Rで状態価値関数Vを更新していく。これをTD(Temporal difference)学習という。
取り得る状態数が多いと収束するまでの時間が長くなる問題があって、これを価値関数の近似によって解消するのがDQN。
DQN (Deep Q-Network) DNNでQ学習を行う。Q学習というのは状態sのときに行動aしたときの報酬の期待値である行動価値関数Qを最大化させるように学習させるもので、 最も良かった行動でQを更新していく。 未知の行動を探索するかどうかはバンディットアルゴリズムのε-greedyによって確率的に決定し、学習が進むにつれて確率は下がっていく。
前もってランダムに行動と結果をサンプリングしておき学習の際に使う、ER(Experience Replay)というテクニックが使われる。 これによって実行回数が減るだけではなく、時系列的な相関を減らし効率的に学習させることができる。
またmain-networkとは別に、同じ形式のtarget-networkを作ってQ(s&#39;=s_{t+1}, a)の値を出すのに使う。 target-networkのパラメータはmain-networkのものを定期的に同期させる以外では更新しないことで学習を安定させることができる。 これをFixed Target Q-Networkという。
参考 強化学習の基礎
第14回　深層強化学習DQN（Deep Q-Network）の解説｜Tech Book Zone Manatee</description>
    </item>
    
    <item>
      <title>生成モデルVAE(Variational Autoencoder)</title>
      <link>https://www.sambaiz.net/article/201/</link>
      <pubDate>Tue, 11 Dec 2018 00:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/201/</guid>
      <description>生成モデルというのはデータの分布をモデリングしてそこから新しいデータを生成するもの。 VAEは入力xに対して何らかの分布を仮定し、例えばガウス分布(正規分布)だとすると平均μと分散σを推論し、 これをz=μ+(σ・ε) (ε~N(0,1))の潜在変数に変換して生成モデルへの入力とし、その出力の尤度が最大化するように学習させる。
Variational Autoencoderという名前はこの分布を推論して生成する流れがAutoencoderの形式と似ているところから来ている。 Autoencoder(自己符号化器)というのはある入力をエンコードしてデコードしたときに入力と同じものを出力するように学習させたもので、 これによって次元削減された潜在変数zが得られる。
推論モデルの確率分布をq、生成モデルの確率分布をpとする。対数尤度log{p}を計算したいが潜在変数zが訓練データにないので周辺化する(1)。 これを変換していくと(2)のようになり、第二項のKL情報量は0以上の値になるので第一項のLを最大化することが対数尤度の最大化につながる。 このLをEvidence Lower Bound (ELBO)といい、推論モデルのパラメータφと生成モデルのパラメータθを交互に最適化して これを最大化させることで尤度の下界を引き上げていく。
自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net
生成モデルがベルヌーイ分布、p(z)が標準正規分布とするとELBOは次のようになる。
第一項が再生成誤差。第二項によってp(z)とq(z|x)が近づくように学習し正則化され、zの各次元が独立になっていく。 これにβ&amp;gt;1を掛けるとさらに独立性が増し、次元ごとに、人であれば性別や年齢のような、disentangle(もつれを解く)された特徴を持つことができる。これをβ-VAEという。
PyTorchでVAEのモデルを実装してMNISTの画像を生成する - sambaiz-net
VAEは分布を仮定して尤度によって学習するため、真の分布にはないところの生成データが良くない問題がある。 VAE以外の生成モデルとしてGAN(Generative Adversarial Networks)があって、これはデータの分布を仮定せずより近い分布から良いデータを生成するのを目指す。
生成モデルGAN(Generative Adversarial Network) - sambaiz-net
参考 Kerasで学ぶAutoencoder
Carl Doersch (2016) Tutorial on Variational Autoencoders
Variational Autoencoder徹底解説 - Qiita</description>
    </item>
    
    <item>
      <title>Encoder-Decoder RNNのAttention</title>
      <link>https://www.sambaiz.net/article/200/</link>
      <pubDate>Sat, 01 Dec 2018 23:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/200/</guid>
      <description>Encoder-Decoder RNNは入力用のEncoderと出力用のDecoderの2つのLSTMを組み合わせたもので、EncoderのStateはDecoderに繋げる。
したがって入力データはDecoderに渡されるStateにまとめられることになるが、 出力ごとに入力時系列の重要な部分は異なるため、特定の部分に注目できるようにすると良い結果が期待できる。 次の論文ではAttention Layerを追加することでこれを行い翻訳の精度を向上させている。
Minh-Thang Luong, Hieu Pham, Christopher D. Manning (2015) Effective Approaches to Attention-based Neural Machine Translation
Attention LayerはEncoderの出力とDecoderの対象の出力からどの部分を重要とするかを表すAlign weights a(t)と Encoderの出力を掛けたものをContext vector c(t)として出力する。 scoreにはそのまま掛けたものや(h_{dec}h_{enc})、重みとDecoderの出力のみを掛ける(Wh_{dec})といったものが使われる。</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</title>
      <link>https://www.sambaiz.net/article/199/</link>
      <pubDate>Tue, 27 Nov 2018 09:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/199/</guid>
      <description>TPU(Tensor Processing Unit)は Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。 一般的なGPUと比べて15~30倍もの性能が出る らしく検索や翻訳などGoogleのサービスでも使われている。
TPUを使える環境として、無料で使えるJupyter NotebooksのGoogle Colabと GCPのCloud TPUがある。ColabのTPUも裏側ではCloud TPUが動いている。 Cloud TPUを直に使うとVMから接続して使うことになるので、TPUの料金に加えてVMの料金もかかる。
モデルのTPU対応 CNNのモデルをTPUEstimatorでTPUに対応させる。
EstimatorはTensorFlowの高レベルAPIで、 train()、 evaluate()、 predict()、 export_saved_model() といったモデルの学習から保存まで必要な機能を一通り提供する。
初めは比較的低レベルのAPIを使おうとしていたが、XLA(Accelerated Linear Algebra)によるコンパイルがうまくいかないなど様々な問題にあたって大変だったので使っておくと良いと思う。 それでもトライアンドエラーの繰り返しで、典型的なものはTroubleshootingにあるが、ないものは調べるなりしてなんとかやっていくしかない。
定数などの定義。BATCH_SIZEはCloud TPUのシャード数の8で割り切れる値にする必要がある。
import pandas as pd from sklearn.model_selection import train_test_split import tensorflow as tf import numpy as np flags = tf.app.flags flags.DEFINE_boolean(&amp;#39;use_tpu&amp;#39;, True, &amp;#39;use tpu or not&amp;#39;) tf.app.flags.DEFINE_string(&amp;#39;f&amp;#39;, &amp;#39;&amp;#39;, &amp;#39;kernel&amp;#39;) FLAGS = flags.FLAGS EPOCH_NUM = 100 BATCH_SIZE = 800 # must be divisible by number of replicas 8 EVAL_BATCH_SIZE = 800 SHARD_NUM = 8 # A single Cloud TPU has 8 shards.</description>
    </item>
    
    <item>
      <title>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する</title>
      <link>https://www.sambaiz.net/article/198/</link>
      <pubDate>Wed, 14 Nov 2018 02:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/198/</guid>
      <description>Batch Normalizationとは Deep Learningでは各層の学習を同時に行うため、前の層の変更によって各層の入力の分布が変わってしまうinternal covariate shiftという現象が起こり、そのためにパラメータの初期化をうまくやる必要があったり、学習率を大きくできず多くのステップを要する。 以下の論文で発表されたBatch Normalization(BN)は各層の入力を正規化して分布を固定することでこれを解決するというもの。 画像認識のコンテストILSVRC 2015で1位を取ったResNet(Residual Network)でも使われている。
Sergey Ioffe, Christian Szegedy (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
具体的にはWx+bと活性化関数の間にBNの層を入れる。μ、σ^2は入力xの平均と分散。 単に正規化するだけでは表現力が下がってしまうのでγとβでスケールやシフトできるようにする。これらの変数は他のパラメータと同様に学習させる。
TensorFlowでの確認 TensorFlowではbatch_normalization()がすでに実装されているのでこれを使う。
以下のCNNで学習率を高めに設定しBNありなしの結果を比較する。学習データはmnist。MonitoredSessionでcostをsummaryとして出力しTensorBoardで見られるようにしている。
TensorBoardでsummaryやグラフを見る - sambaiz-net
TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net
import pandas as pd import numpy as np import tensorflow as tf from sklearn.model_selection import train_test_split from sklearn.utils import shuffle from sklearn.metrics import accuracy_score train = pd.read_csv(&amp;#39;./train.csv&amp;#39;) (x_train, x_valid ,y_train, y_valid) = train_test_split( train.</description>
    </item>
    
    <item>
      <title>TensorFlow&#43;numpyでData Augmentationして画像の学習データを増やす</title>
      <link>https://www.sambaiz.net/article/197/</link>
      <pubDate>Sun, 11 Nov 2018 15:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/197/</guid>
      <description>Data Augmentationは学習データを加工したものを学習データに加えることで数を増やすというもの。 加工したデータには通常元のものと同じラベルが付くことになるが、 例えば画像を反転や回転させても元々のものと同じだと認識されるべきだとしたら妥当だ。 つまり、なんでもすれば良いわけではなくデータセットに応じた、元のデータと同じラベルが付くような加工をする必要があり、 裏を返せばそのような違いがあっても同じものであることをモデルに学習させることができる。
今回はData Augmentationで行われる加工をTensorFlowやnumpyの関数でおなじみLennaの画像に行う。
必要なパッケージと画像をimportする。Jupyter Notebooksで実行する。
%matplotlib inline from PIL import Image import matplotlib.pyplot as plt import numpy as np import tensorflow as tf im = Image.open(&amp;#34;lenna.png&amp;#34;, &amp;#34;r&amp;#34;) Flipping  flip_left_right() random_flip_left_right() flip_up_down() random_flip_up_down()  左右と上下の反転。randomは1/2で反転する。
fliph = tf.image.flip_left_right(im) flipv = tf.image.flip_up_down(im) with tf.Session() as sess: results = sess.run([fliph, flipv]) plt.imshow(np.hstack(results)) Rotating  rot90()  反時計周りに90度回転させる。
rot90 = tf.image.rot90(im) with tf.Session() as sess: results = sess.run([rot90]) plt.</description>
    </item>
    
    <item>
      <title>FargateでECSを使う</title>
      <link>https://www.sambaiz.net/article/196/</link>
      <pubDate>Fri, 09 Nov 2018 00:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/196/</guid>
      <description>ECSはAWSのコンテナオーケストレーションサービス。 クラスタはEC2上に立てることもできるが、その場合Auto Scalingグループの設定やスケールイン時のdrainなどを考慮する必要がある。 Fargateで起動するとサーバーレスで実行でき、バックエンドの管理が必要がなくなる。 料金は割り当てたvCPUとメモリによって、最低1分の1秒単位で課金される。 Lambdaと同じくリソースあたりでいうとオンデマンドのEC2と比較して高くなっているが、柔軟にリソースが指定できる分いくらか差は縮まるかもしれない。
特にバッチ処理のように常にリソースが必要ないTaskは都度インスタンスを立ち上げるのも面倒なので良いと思う。 Lambdaと比較すると、実行環境を自由に作れるのと実行時間に制限がないというところが良いが、 Taskを作るトリガーは現状cronだけなのでそれ以外のイベントで実行したい場合はLambdaと組み合わせる必要がある。
AWSにはKubernetesクラスタを立てられるEKSもあるが、こちらはまだFargateに対応していない。 もしかしたら今月末のre:Inventで何か発表されるかもしれない。
 (追記: 2021-05-30): re:Invent 2019でEKSのFargate対応が発表された。
LA,ディズニーランドからre:Inventに参加しグランドキャニオンへドライブしてきた - sambaiz-net
 Clusterの作成 まずはClusterを作成する。
$ aws ecs create-cluster --cluster-name test Taskの登録 イメージやポートマッピング、ヘルスチェックや割り当てるリソースといったContainer definition を含むTask definitionを書く。 Fargateの場合networkModeはawsvpc固定になる。
{ &amp;#34;family&amp;#34;: &amp;#34;test-task&amp;#34;, &amp;#34;networkMode&amp;#34;: &amp;#34;awsvpc&amp;#34;, &amp;#34;containerDefinitions&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;nginx&amp;#34;, &amp;#34;image&amp;#34;: &amp;#34;nginx:1.15&amp;#34;, &amp;#34;portMappings&amp;#34;: [ { &amp;#34;containerPort&amp;#34;: 80, &amp;#34;hostPort&amp;#34;: 80, &amp;#34;protocol&amp;#34;: &amp;#34;tcp&amp;#34; } ], &amp;#34;essential&amp;#34;: true } ], &amp;#34;requiresCompatibilities&amp;#34;: [ &amp;#34;FARGATE&amp;#34; ], &amp;#34;cpu&amp;#34;: &amp;#34;256&amp;#34;, &amp;#34;memory&amp;#34;: &amp;#34;512&amp;#34; } Taskを登録する。</description>
    </item>
    
    <item>
      <title>TensorFlowのtf.data API</title>
      <link>https://www.sambaiz.net/article/195/</link>
      <pubDate>Sat, 03 Nov 2018 18:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/195/</guid>
      <description>Importing Data | TensorFlow
データを読み込み変換してイテレートする入力パイプラインを作るAPI。 通常、学習にGPU/TPUを使う場合CPU処理の間はアイドル状態となりボトルネックになるが、 パイプライン処理を行うことでCPUとGPU/TPUがなるべくアイドル状態にならないようになり、 学習時間が短縮される。
Datasetの作成 from_tensor_slices()でDatasetを作成する。
dataset = tf.data.Dataset.from_tensor_slices( {&amp;#34;a&amp;#34;: tf.random_uniform([4]), &amp;#34;b&amp;#34;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)}) print(dataset.output_types) # {&amp;#39;a&amp;#39;: tf.float32, &amp;#39;b&amp;#39;: tf.int32} print(dataset.output_shapes) # {&amp;#39;a&amp;#39;: TensorShape([]), &amp;#39;b&amp;#39;: TensorShape([Dimension(100)])} 引数にnumpyのndarrayを渡すとtf.constant()で変換されてグラフに乗る。
dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3))) print(dataset.output_types) # &amp;lt;dtype: &amp;#39;int64&amp;#39;&amp;gt; print(dataset.output_shapes) # (3,) データが1GBを超える場合グラフのシリアライズ上限を超えてしまうことがある。後述するinitializableイテレータの初期化時にndarrayを渡すとこれを避けられる。
tf.contrib.data.CsvDatasetでCSVからDatasetを作ることもできる。
$ cat file1.csv a,b,c,d 1,2,3,4 2,3,4,5 6,7,8,9 filenames = [&amp;#34;file1.csv&amp;#34;] record_defaults = [tf.float32] * 2 # Two required float columns dataset = tf.contrib.data.CsvDataset(filenames, record_defaults, header=True, select_cols=[1,3]) print(dataset.</description>
    </item>
    
    <item>
      <title>同じ/異なるオリジンのiframeの中からできること</title>
      <link>https://www.sambaiz.net/article/194/</link>
      <pubDate>Wed, 24 Oct 2018 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/194/</guid>
      <description>同じ/異なるオリジンのiframeの中からできることを確認する。同じオリジンというのは ホストだけではなくプロトコルやポート番号も同じということ。
検証用ページ 3つのiframeがあるページを作った。 それぞれabout:blankで動的に書き込むのと、同じオリジンのhtmlを参照しているものと、異なるオリジンのhtmlを参照しているもの。
$ cat index.html &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;style type=&amp;#34;text/css&amp;#34;&amp;gt; p{ width:100px; height:100px; background:#999; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;p&amp;gt;parent&amp;lt;/p&amp;gt; &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;#34;about:blank&amp;#34; id=&amp;#34;if1&amp;#34;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script type=&amp;#34;text/javascript&amp;#34;&amp;gt; var parentValue = &amp;#34;PARENT&amp;#34;; window.addEventListener(&amp;#34;message&amp;#34;, (event) =&amp;gt; { console.log(`message from ${event.origin}: ${event.data}`); }, false); &amp;lt;/script&amp;gt; &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;#34;./iframe.html&amp;#34;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;#34;https://*****.ngrok.io/iframe.html&amp;#34;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;./index.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 1つ目のiframeの中にscriptタグなどを書き込むJS。
$ cat index.js const el = document.getElementById(&amp;#34;if1&amp;#34;); const doc = el.contentDocument; const p = doc.createElement(&amp;#39;p&amp;#39;); p.textContent = &amp;#34;child&amp;#34;; doc.body.appendChild(p); var scriptTag = doc.</description>
    </item>
    
    <item>
      <title>Goで高速にJSONを扱うライブラリeasyjsonとfastjson</title>
      <link>https://www.sambaiz.net/article/193/</link>
      <pubDate>Wed, 24 Oct 2018 01:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/193/</guid>
      <description>easyjson easyjsonは次のようなstructごとのコードを自動生成してReflectionなしで高速にJSON Marshal/Unmarshalできるようにするライブラリ。
$ go get -u github.com/mailru/easyjson/... $ cat struct.go package a type Foo struct { A string `json:&amp;#34;a,omitempty&amp;#34;` B *Bar } type Bar struct { C []int `json:&amp;#34;c&amp;#34;` D map[string]int `json:&amp;#34;d&amp;#34;` } $ easyjson -all struct.go $ cat struct_easyjson.go ... func easyjson9f2eff5fEncodeGithubComSambaizBenchjsonA(out *jwriter.Writer, in Foo) { out.RawByte(&amp;#39;{&amp;#39;) first := true _ = first if in.A != &amp;#34;&amp;#34; { const prefix string = &amp;#34;,\&amp;#34;a\&amp;#34;:&amp;#34; if first { first = false out.</description>
    </item>
    
    <item>
      <title>MLPと誤差逆伝搬法(Backpropagation)</title>
      <link>https://www.sambaiz.net/article/192/</link>
      <pubDate>Sun, 21 Oct 2018 19:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/192/</guid>
      <description>MLP(多層パーセプトロン)は入力層と出力層の間に隠れ層を重ねることによって、 ロジスティック回帰(単純パーセプトロン)ではできなかった非線形分離をできるようにしたニューラルネットワークモデル。
ロジスティック回帰の尤度と交差エントロピー誤差と勾配降下法 - sambaiz-net
入出力がx、y、層の数がLでl層目での重みとバイアスをW^(l), b^(l)、活性化関数をf^(l)、活性化関数適用前後をu^(l)とh^(l)とし、入力層を0層目とすると各層での演算は以下の式で表される。
活性化関数は非線形で微分可能な関数で、計算速度や勾配消失の面でReLUが最有力。
ニューラルネットワークと活性化関数 - sambaiz-net
各層の最適なWとbを探すのにロジスティック回帰と同様に勾配降下法を使うことができる。 誤差関数は分類の場合は交差エントロピーが、回帰の場合は平均二乗誤差(MSE, Mean Squared Error) または外れ値に引っ張られづらくしたHuber損失などが使われる。
隠れ層の勾配はそれより後ろの層での演算が影響するので、入力から出力への順伝搬に対して 出力から入力への逆伝播で誤差の情報を前の層に伝播させていく。これを誤差逆伝播法(Backpropagation)という。
出力から遠くなればなるほど連鎖律が長くなっていくが、途中までは後ろの層と共通になっている。 ということで順伝搬時のhを保存しておき一つ後ろの層のWと誤差δを渡してやれば必要最小限の演算で済み、実行時間を短くすることができる。
参考 深層学習</description>
    </item>
    
    <item>
      <title>ロジスティック回帰の尤度と交差エントロピーと勾配降下法</title>
      <link>https://www.sambaiz.net/article/191/</link>
      <pubDate>Sun, 14 Oct 2018 23:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/191/</guid>
      <description>ロジスティック回帰 単純パーセプトロンの活性化関数を、0か1の値を取るステップ関数ではなく値域\((0,1)\)のシグモイド関数\(\sigma\)にすることで 確率を返せるようにしたモデル。
$$ p = \frac{1}{1+e^{-(w^Tx + b)}} $$
ニューラルネットワークと活性化関数 - sambaiz-net
シグモイド関数という非線形の関数を通すので非線形分離できそうな気もするが 上の式を変形すると次のようになり線形分離モデルであることが分かる。 例えば閾値を0.5とすると\(w^Tx + b = 0\)が境界となる。 層を増やせば非線形分離できるようになる。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
$$ \begin{align*} p &amp;amp;= 1 - \frac{1}{1+e^{w^Tx + b}} \because \sigma(-x) = 1 - \sigma(x) \\ \frac{1}{1-p} &amp;amp;= 1 + e^{w^Tx + b} \\ \ln \frac{p}{1-p} &amp;amp;= w^Tx + b \end{align*} $$
この左辺をロジットといい\([0,1]\)の確率から実数\([-\infty, \infty]\)への写像となっている。 また、対数を取っている\(\frac{p}{1-p}\)をオッズといい、 事象の起こりやすさを比較する際に用いられるオッズ比はこの比となっている。
尤度関数と交差エントロピー誤差関数 尤度関数(likelihood function)はある前提条件に従って事象が起きる場合に、 観測された事象から推測される前提条件の尤もらしさを表す尤度を返す関数。
例えばコインを3回投げて2回表が出た場合、前提条件である表が出る確率を\(p\)とすると 尤度関数は
$$ L(p) = p^2(1-p) $$</description>
    </item>
    
    <item>
      <title>Kubernetesでliveness/readinessProbeのexec commandが実行される流れ</title>
      <link>https://www.sambaiz.net/article/190/</link>
      <pubDate>Sat, 06 Oct 2018 16:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/190/</guid>
      <description>Kubernetesのliveness/readinessProbe はPodが生きているか/リクエストを受けられるかの判定で、 後者はアプリケーションの起動に時間がかかる場合などに使われる。 ヘルスチェックのようなエンドポイントを叩くのはhttpGetでできるが、任意のcommandを実行することもできる。
livenessProbe: httpGet: path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome Manifestに書かれたProbeは、 各ノードで動いているkubeletが Podが追加されたときにworkerを 作って runProbe()で実行させている。
if p.Exec != nil { glog.V(4).Infof(&amp;#34;Exec-Probe Pod: %v, Container: %v, Command: %v&amp;#34;, pod, container, p.Exec.Command) command := kubecontainer.ExpandContainerCommandOnlyStatic(p.Exec.Command, container.Env) return pb.exec.Probe(pb.newExecInContainer(container, containerID, command, timeout)) } まずcommandに含まれる$( )で囲まれた文字列を Expand() で存在すればcontainerのenvの値に置き換える。
その後、 RunInContainer()で、 コンテナランタイムがK8s標準のCRI(Container Runtime Interface)に対応している場合はそのAPIの、 対応していない場合は~shimパッケージのExecSync()が呼ばれ、コンテナ内でcommandを実行させて結果を受け取り、終了コードが0でなければエラーとする。
$( )でenvの値が使えることを確認する。
$ kubectl config use-context docker-for-desktop $ cat test.yaml --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: &amp;#34;test&amp;#34; spec: replicas: 1 template: metadata: labels: app: &amp;#34;test&amp;#34; spec: containers: - name: &amp;#34;test&amp;#34; image: &amp;#34;alpine&amp;#34; command: [&amp;#34;top&amp;#34;] env: - name: TEST value: &amp;#34;foobar&amp;#34; ports: - containerPort: 5000 name: grpc readinessProbe: exec: command: - test - $(TEST) - = - foobar initialDelaySeconds: 0 timeoutSeconds: 1 $ kubectl apply test.</description>
    </item>
    
    <item>
      <title>MySQLのtime_zoneとgo-sql-driver/mysqlの設定</title>
      <link>https://www.sambaiz.net/article/189/</link>
      <pubDate>Tue, 02 Oct 2018 22:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/189/</guid>
      <description>MySQLのtime_zoneとgo-sql-driver/mysqlの設定による挙動を確認する。
&amp;gt; select version(); +-----------+  | version() | +-----------+  | 5.7.21 | +-----------+ タイムゾーンがロードされていない場合はロードする。
&amp;gt; select count(*) from mysql.time_zone \\G; *************************** 1. row *************************** count(*): 0 $ mysql_tzinfo_to_sql /usr/share/zoneinfo/ | mysql -u root mysql time_zoneはデフォルト値のSYSTEM。つまりJSTで、my.cnfのdefault-time-zoneで変更できる。 NOW()もJSTの時間を返している。
&amp;gt; show variables like &amp;#39;%time_zone%&amp;#39;; +------------------+--------+ | Variable_name | Value | +------------------+--------+ | system_time_zone | JST | | time_zone | SYSTEM | +------------------+--------+  &amp;gt; SELECT NOW(); mysql&amp;gt; SELECT NOW() \G; *************************** 1.</description>
    </item>
    
    <item>
      <title>PythonのType Hintsとmypy</title>
      <link>https://www.sambaiz.net/article/188/</link>
      <pubDate>Sun, 30 Sep 2018 14:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/188/</guid>
      <description>動的型付け言語であるPythonで型アノテーションを書けるようにするための構文。 PEP 484で提案され、Python 3.5で実装された。 実行には影響せず、mypyのようなツールで静的解析したりするために使われる。
mypyをインストールする。
$ python -m pip install -U mypy 以下のように引数と返り値に型を書くと、型が誤っている場合にmypyで検知できるようになる。
$ cat main.py def foo(n: int) -&amp;gt; str: return str(n) print(foo(3)) print(foo(&amp;#39;3&amp;#39;)) $ python main.py 3 3 $ mypy main.py main.py:5: error: Argument 1 to &amp;#34;foo&amp;#34; has incompatible type &amp;#34;str&amp;#34;; expected &amp;#34;int&amp;#34; また、Type HintsがないライブラリなどのためにStubファイルを別に作って型を書くこともできるようにもなっている。デフォルトではStubがないモジュールはエラーになってしまうので必要に応じてignore_missing_importする。 mypy.iniやsetup.cfgに設定を書くと自動で使われる。
$ cat main.py import numpy as np $ mypy main.py main.py:1: error: No library stub file for module &amp;#39;numpy&amp;#39; main.py:1: note: (Stub files are from https://github.</description>
    </item>
    
    <item>
      <title>numpyの関数</title>
      <link>https://www.sambaiz.net/article/187/</link>
      <pubDate>Sun, 23 Sep 2018 23:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/187/</guid>
      <description>ndarrayの生成 ndarrayはnumpyの多次元の配列を表すオブジェクトで、[start:stop:step, &amp;hellip;]の indexでアクセスできる。
x = np.array([[1, 2, 3, 4], [2, 4, 6, 8]]) print(x[0, 1]) # 2 print(x[0,1:-1]) # [2 3] print(x[:,2]) # [3 6] print(x[:,::2]) # [[1 3] [2 6]] print(x[1,::-1]) # [8 6 4 2]  array() fromiter()  arrayやiteratableオブジェクトからndarrayを生成する。
print(np.array([1, 2, 3])) # [1 2 3] def generate(): for x in range(3): yield x x = np.fromiter(generate(), dtype=float) print(x) # [ 0. 1. 2.]  zeros() ones() full()  引数で渡したshapeを特定の値で埋めたndarrayを生成する。</description>
    </item>
    
    <item>
      <title>cert-managerで生成した証明書をIstioのGatewayに設定してHTTPS対応する</title>
      <link>https://www.sambaiz.net/article/186/</link>
      <pubDate>Thu, 13 Sep 2018 21:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/186/</guid>
      <description>cert-managerはTLSの証明書を自動で生成し管理するK8sのアドオン。 Istioにも含まれていて、これを使ってLet&amp;rsquo;s Encryptで証明書を生成しGatewayに設定することでHTTPS対応することができる。
デフォルトではcert-managerは入らないのでenabled=trueにしてインストールする。 最初に入るLet&amp;rsquo;s EncryptのClusterIssuerはエラーになったので消す。
IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net
$ helm install install/kubernetes/helm/istio --name istio --namespace istio-system --set certmanager.enabled=true $ kubectl delete ClusterIssuer --all 確認用にBookInfoを動かす。
$ kubectl label namespace default istio-injection=enabled $ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml $ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml Let&amp;rsquo;s Encryptで使われているACMEプロトコルのドメイン認証(Challenge)には /.well-known/acme-challenge/{token}でHTTPレスポンスを返すHTTP Challenge(http-01)と DNSのTXTレコードに書き込むDNS Challenge(dns-01)がある。 HTTP Challengeは手軽に達成できる一方、CAからアクセスできるようにする必要がある。今回はDNS Challengeでやる。 cert-managerはCloud DNSやRoute53などに対応していて、今回はCloudflareを使う。
DNSに書き込めるようにするためCloudflareのMy ProfileからGlobal API Keyを持ってきてBase64デコードしSecretに入れる。 改行コードが含まれないように-nを付ける。
$ echo -n ***** | base64 apiVersion: v1 kind: Secret metadata: name: cloudflare-api-key namespace: istio-system type: Opaque data: api-key: ***** Let&amp;rsquo;s EncryptのClusterIssuerと証明書を生成するドメインのCertificateを作成する。 serverのURLはStatusのページから確認できる。 本番のURLはレート制限があるので、まずはFakeの証明書が生成されるstgで試すとよい。</description>
    </item>
    
    <item>
      <title>IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する</title>
      <link>https://www.sambaiz.net/article/185/</link>
      <pubDate>Sun, 02 Sep 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/185/</guid>
      <description>IstioはEnvoyというProxyをSidecarとしてPodに入れてトラフィックを通すことでマイクロサービスのRoutingやTelemetryをサービスのコードに手を入れずに行うことができるサービスメッシュ。 もともとEnvoy自体は単体で、コネクションを張りっぱなしのgRPC(HTTP/2)をK8sのServiceのL4ロードバランサーでは分散できない問題の解決方法の一つとして 各PodのIPの一覧を返すHeadless Serviceと使われていたが、各Manifestに入れたりConfigMapを編集したりする必要があり少し面倒だった。 Istioにするとそれらが省けて、さらに賢いRoutingやモニタリングの仕組みまで付いてくるのでとても便利だ。
インストール IstioをダウンロードしてきてHelmでインストールする。Istioには様々なコンポーネントが含まれているが、パラメータでインストールするものを選択することができる。
KubernetesのパッケージマネージャーHelmを使う - sambaiz-net
今回はデフォルトではfalseになっているGrafana/Jaeger/Kialiをtrueにしてほぼ全て入るようにしている。
RBACが有効な場合はServiceAccountを作ってcluster-adminあるいは必要なRoleをBindしておく。
RBACが有効なGKEでHelmを使う - sambaiz-net
$ curl -L https://git.io/getLatestIstio | sh - $ cd istio-1.0.1/ # helm init --service-account tiller $ helm install install/kubernetes/helm/istio --name istio --namespace istio-system --set grafana.enabled=true --set grafana.persist=true --set grafana.storageClassName=standard --set tracing.enabled=true --set kiali.enabled=true $ kubectl get pod -n istio-system NAME READY STATUS RESTARTS AGE grafana-598678cbb-bglbq 1/1 Running 0 3m istio-citadel-6f9887d776-tvdg8 1/1 Running 0 3m istio-egressgateway-84d78d84bf-zpxrq 1/1 Running 0 3m istio-galley-556f5558f5-hk2r8 1/1 Running 0 3m istio-ingressgateway-78cccbddbb-gh2xl 1/1 Running 0 3m istio-pilot-799845f56d-l777d 2/2 Running 0 3m istio-policy-7666fcd574-nbx8s 2/2 Running 0 3m istio-sidecar-injector-7b6589c9-m7x77 1/1 Running 0 3m istio-statsd-prom-bridge-55965ff9c8-s6dmj 1/1 Running 0 3m istio-telemetry-844c8d6bff-9trcf 2/2 Running 0 3m istio-tracing-77f9f94b98-g7v6f 1/1 Running 0 3m kiali-bdf7fdc78-9lpd4 1/1 Running 0 3m prometheus-7456f56c96-drhlq 1/1 Running 0 3m default namespaceにラベルを貼って自動でEnvoyが各PodにInjectionされるようにする。</description>
    </item>
    
    <item>
      <title>nohupし忘れた時間のかかる処理をdisownしてexit後も実行させ続ける</title>
      <link>https://www.sambaiz.net/article/184/</link>
      <pubDate>Thu, 23 Aug 2018 00:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/184/</guid>
      <description>時間がかかるコマンドを実行する場合、通常はnohupで実行し ターミナル終了時に飛ぶSIGHUP(SIGnal Hang UP)を無視させることで exitしても実行させ続けることができる。
$ nohup ./foo &amp;amp; ただnohupを付けずに実行し始めてから思ったより時間がかかるということもある。 その場合は、Ctrl+Zで一旦停止してからbgでバックラウンドで実行するようにしてdisown -hでSIGHUPが送られないようにできる。 disownはシェルのジョブテーブルから削除するコマンドで、そのままでもSIGHUPが送られないようにできるが、 -hを付けるとジョブテーブルから削除せずに済む。
$ jobs [1]+ 停止 ./foo $ bg 1 $ jobs [1]+ 実行中 ./foo $ disown -h %1 </description>
    </item>
    
    <item>
      <title>CircleCI 2.0でDocker imageをbuildしてタグを付けてContainer Registryに上げる</title>
      <link>https://www.sambaiz.net/article/183/</link>
      <pubDate>Wed, 22 Aug 2018 23:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/183/</guid>
      <description>(追記: 2019-04-13) 2.1からのOrbを使うと自分でjobを書かなくてもよくなる CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる - sambaiz-net
 masterにpushしたときと、リリースタグを切ったときにビルドされるようにする。
version: 2 jobs: build: docker: - image: google/cloud-sdk environment: GCP_PROJECT: &amp;lt;project_name&amp;gt; IMAGE_NAME: &amp;lt;image_name&amp;gt; steps: - checkout - setup_remote_docker: version: 18.05.0-ce - run: name: gcloud auth command: |echo $GCLOUD_SERVICE_KEY | base64 --decode &amp;gt; ${HOME}/gcloud-service-key.json gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json gcloud --quiet auth configure-docker - run: name: docker build &amp;amp; push command: |docker build -t asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} . docker tag asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:latest if [ -n &amp;#34;${CIRCLE_TAG}&amp;#34; ]; then docker tag asia.</description>
    </item>
    
    <item>
      <title>KubernetesのCustom Resource Definition(CRD)とCustom Controller</title>
      <link>https://www.sambaiz.net/article/182/</link>
      <pubDate>Thu, 09 Aug 2018 23:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/182/</guid>
      <description>K8sではDeploymentを作成したときにReplicaSetも作成されるようにしたり、 Load Balancer Serviceを作成したときにGCPなどその環境に応じたLoad Balancerも作成されるようにしたりするため、Controllerがそれらを監視してAPIを呼んでいる。
GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net
Controllerは単なるAPIを呼ぶアプリケーションなので自分でCustom Controllerを作成してDeploymentとしてデプロイすることもできる。 また、監視する対象もpodsやdeploymentsといった標準のAPIだけではなく、 Custom Resource で拡張したものを使うことができる。
特定のアプリケーションのためのControllerはOperatorとも呼ばれる。
CustomResourceDefinition(CRD) Custom Resourceを定義する。
apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: crontabs.stable.example.com spec: # REST APIで使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt; group: stable.example.com version: v1 # Namespaced か Cluster scope: Namespaced names: # 複数形 URLに使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;/&amp;lt;plural&amp;gt; plural: crontabs # 単数形 CLIなどで使われる singular: crontab # manifestで使う kind: CronTab shortNames: - ct $ kubectl create -f crd.yaml $ kubectl get crd NAME AGE crontabs.</description>
    </item>
    
    <item>
      <title>KubernetesのNetworkPolicy Resource</title>
      <link>https://www.sambaiz.net/article/181/</link>
      <pubDate>Mon, 30 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/181/</guid>
      <description>Network Policies - Kubernetes
PodのトラフィックをラベルやIPアドレスで許可するためのResource。AWSのセキュリティグループやGCPのファイアウォールルールのようなもの。 GKEでは今のところデフォルトでオフになっているので--enable-network-policyを付けてクラスタを作成する必要がある。
以前作成したmulti podのアプリケーションで挙動を確認する。
GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net
$ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE clusterip-app ClusterIP 10.23.247.54 &amp;lt;none&amp;gt; 80/TCP 48m loadbalancer-app LoadBalancer 10.23.244.137 35.224.130.196 80:31508/TCP 48m nodeport-app NodePort 10.23.246.215 &amp;lt;none&amp;gt; 80:32181/TCP 48m ... $ curl -d &amp;#39;{&amp;#34;url&amp;#34;: &amp;#34;http://nodeport-app&amp;#34;}&amp;#39; http://35.224.130.196/ 200 作成するNetworkPolicyは以下の二つで、いずれも対象はapp: nodeport-appのラベルが付いたPod。 一つ目は対象Podへのリクエストを一旦全て拒否する。 二つ目はnodeport-access: &amp;quot;true&amp;quot;のラベルが付いたPodから対象Podへの8080ポートのリクエストを許可するもの。 今回は設定しないがegressも設定できる。
$ cat networkPolicies.yaml --- # Default deny all ingress traffic apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: default-deny spec: podSelector: matchLabels: app: nodeport-app --- apiVersion: networking.</description>
    </item>
    
    <item>
      <title>GCPのCloud Pub/Sub</title>
      <link>https://www.sambaiz.net/article/180/</link>
      <pubDate>Thu, 26 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/180/</guid>
      <description>スケーラビリティに優れるメッセージングミドルウェア。 データはPullするだけではなくhttpsのエンドポイントにPushすることもでき、Cloud Dataflowを通してBigQueryやCloud MLに繋げることもできる。GAEのTaskQueueのように遅延させる機能は今のところない。
GAEのTaskQueue - sambaiz-net
料金はPublish/Pull/Pushしたデータ容量による。1TB送ると$60くらい。
Goのクライアントライブラリで動かしてみる。 まずTopicを作成して50件Publishした後、Subsriptionを作成して、再び50件Publishする。 Publishできるデータは10MB未満。
topic, err := client.CreateTopic(ctx, topicName) if err != nil { panic(err) } var wg sync.WaitGroup for i := 0; i &amp;lt; 50; i++ { wg.Add(1) go func() { if _, err := topic.Publish(ctx, &amp;amp;pubsub.Message{Data: []byte(strconv.Itoa(i))}).Get(ctx); err != nil { log.Fatalf(&amp;#34;Publish error: %s&amp;#34;, err.Error()) } else { log.Printf(&amp;#34;Publish successful: %d&amp;#34;, i) } wg.Done() }() wg.Wait() } log.Printf(&amp;#34;Create Subscription&amp;#34;) sub := createSubscription(ctx, client, topic, subscriptionName) for i := 50; i &amp;lt; 100; i++ { wg.</description>
    </item>
    
    <item>
      <title>Destributed TensorFlowの流れとSavedModelの出力</title>
      <link>https://www.sambaiz.net/article/179/</link>
      <pubDate>Wed, 25 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/179/</guid>
      <description>Distributed TensorFlow クラスタを組んでGraphを分散実行する。
クラスタは
 master: sessionを作成し、workerを制御する worker: 計算を行う ps(parameter server): 変数の値を持ち、更新する  のjobからなり、gRPCの
 Master Service Worker Service  でやり取りする。
TensorFlow serverを立てる 各jobとURLのmapをClusterSpecにして jobとindexと併せてServerDefを作って Serverを立てる。
{ &amp;#34;master&amp;#34;: [ &amp;#34;check-tf-config-master-34z8-0:2222&amp;#34; ], &amp;#34;ps&amp;#34;: [ &amp;#34;check-tf-config-ps-34z8-0:2222&amp;#34;, &amp;#34;check-tf-config-ps-34z8-1:2222&amp;#34; ], &amp;#34;worker&amp;#34;: [ &amp;#34;check-tf-config-worker-34z8-0:2222&amp;#34;, &amp;#34;check-tf-config-worker-34z8-1:2222&amp;#34; ] } cluster_spec_object = tf.train.ClusterSpec(cluster_spec) server_def = tf.train.ServerDef( cluster=cluster_spec_object.as_cluster_def(), protocol=&amp;#34;grpc&amp;#34;, job_name=job_name, # worker, master, ps  task_index=0) server = tf.train.Server(server_def) psのjobではserver.join()して待ち構える。
if job_name == &amp;#34;ps&amp;#34;: server.join() else: # build model WorkerにGraphを割り当てる workerのdeviceにGraphを割り当てる。 deviceは/job:worker/replica:0/task:0/device:GPU:0 のようなフォーマットで表される。</description>
    </item>
    
    <item>
      <title>GAEのTaskQueue</title>
      <link>https://www.sambaiz.net/article/178/</link>
      <pubDate>Sun, 15 Jul 2018 16:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/178/</guid>
      <description>GCPのマネージドなQueueサービスとしてGAEのTaskQueueがあることを教えてもらったので動かしてみる。 PushQueueとPullQueueがあって、それぞれおおよそAWSのSNSとSQSに相当する。PushQueueの場合はHTTPのリクエストとしてGAEのサービスに投げられる。PullQueueはCloud Tasks APIを使えばGAE外からも使えるらしいがまだalpha。
設定ファイルqueue.yamlはこんな感じ。bucket_sizeは最大同時実行数で空いていたらrateで埋められていく。
queue: - name: default rate: 10/m bucket_size: 5 retry_parameters: min_backoff_seconds: 10 max_backoff_seconds: 300 bucket_sizeの最大は500なのでこれ以上の性能が必要な場合は複数のQueueに分けるか Cloud Pub/Subを使うことになる。ただし、At-Least-Onceなのでレコードが重複しても問題ないように作る必要がある。SQSも同じ。
GCPのCloud Pub/Sub - sambaiz-net
アプリケーション /にアクセスすると2つのTaskをdefaultのTaskQueueにDelay25秒でPOSTする。 Taskによるリクエストは/workerで受け、30%の確率で500エラーを返すようにしている。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;net/url&amp;#34; &amp;#34;strconv&amp;#34; &amp;#34;time&amp;#34; &amp;#34;google.golang.org/appengine&amp;#34; &amp;#34;google.golang.org/appengine/log&amp;#34; &amp;#34;google.golang.org/appengine/taskqueue&amp;#34; ) func main() { http.HandleFunc(&amp;#34;/&amp;#34;, handler) http.HandleFunc(&amp;#34;/worker&amp;#34;, handlerQueue) appengine.Main() } func handler(w http.ResponseWriter, r *http.Request) { ctx := appengine.NewContext(r) // POST body: name=a%26&amp;amp;value=20 	t := taskqueue.NewPOSTTask(&amp;#34;/worker&amp;#34;, map[string][]string{&amp;#34;name&amp;#34;: {&amp;#34;a&amp;amp;&amp;#34;}, &amp;#34;time&amp;#34;: {strconv.</description>
    </item>
    
    <item>
      <title>WebSocketでの通信内容をWiresharkで見る</title>
      <link>https://www.sambaiz.net/article/177/</link>
      <pubDate>Tue, 10 Jul 2018 23:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/177/</guid>
      <description>Webで双方向通信するためのプロトコル、WebSocketでの通信内容をWiresharkで見る。
アプリケーション サーバー package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;golang.org/x/net/websocket&amp;#34; ) type Payload struct { A string } func Handler(ws *websocket.Conn) { ctx, cancel := context.WithCancel(context.Background()) go func() { var payload Payload for { err := websocket.JSON.Receive(ws, &amp;amp;payload) if err != nil { if err == io.EOF { fmt.Println(&amp;#34;connection closed&amp;#34;) } else { fmt.Println(err) } cancel() break } fmt.Println(payload.A) } }() websocket.JSON.Send(ws, Payload{A: &amp;#34;a&amp;#34;}) select { case &amp;lt;-ctx.Done(): } } func main() { http.</description>
    </item>
    
    <item>
      <title>DOMの(next/previous)SiblingとElementSiblingの値</title>
      <link>https://www.sambaiz.net/article/176/</link>
      <pubDate>Wed, 04 Jul 2018 23:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/176/</guid>
      <description>Siblingは兄弟姉妹という意味
&amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt; &amp;lt;li id=&amp;#34;li2&amp;#34;&amp;gt;2&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;3&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;script&amp;gt; const el = document.querySelector(&amp;#34;li#li2&amp;#34;); &amp;lt;/script&amp;gt; Sibling elのpreviousSiblingを取ると&amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt;になると思いきや、その直前の空白や改行を含むtext nodeが返る。 それらが全くない場合隣のElementが返ることになる。
const el2 = el.previousSibling; console.log(`previousSibling: ${el2.nodeName}&amp;#34;${el2.textContent}&amp;#34;`); /* #text &amp;#34; &amp;#34; */ const el4 = el.nextSibling; console.log(`nextSibling: ${el4.nodeName}&amp;#34;${el4.textContent}&amp;#34;`); // LI &amp;#34;3&amp;#34; ElementSibling 多くの場合で意図した結果が返るのはこっち。
const el3 = el.previousElementSibling; console.log(`previousElementSibling: ${el3.nodeName}&amp;#34;${el3.textContent}&amp;#34;`); // LI &amp;#34;1&amp;#34;  const el5 = el.nextElementSibling; console.log(`nextElementSibling: ${el5.nodeName}&amp;#34;${el5.textContent}&amp;#34;`); // LI &amp;#34;3&amp;#34; firstChildとfirstElementChildなどの関係も同じ。存在を忘れていてひっかかった。
const el6 = document.querySelector(&amp;#34;ul&amp;#34;).firstChild; console.log(`firstChild: ${el6.nodeName}&amp;#34;${el6.textContent}&amp;#34;`); /* fistChild: #text &amp;#34; &amp;#34; */ </description>
    </item>
    
    <item>
      <title>TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー</title>
      <link>https://www.sambaiz.net/article/175/</link>
      <pubDate>Sun, 01 Jul 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/175/</guid>
      <description>MonitoredSession
deprecatedになったSupervisorの後継。
MonitoredTrainingSessionで学習用のMonitoredSessionを生成する。 このコンストラクタの引数でcheckpoint_dirを渡すと内部でCheckpointSaverHookが 追加されるようになっていて、restoreしたり指定したタイミングでsaveしたりしてくれる。
なので今回明示的に渡すhooksは 指定したstepに到達したら止めてくれる、StopAtStepHookのみ。
should_stop()がTrueな状態でsession.run()しようとするとRun called even after should_stop requested.のエラーが出るため、 今回は新しいsessionを作ってAccuracyを返しているが、hookでやった方がrestoreする必要がないので良さそうだ。
Destributed TensorFlowの流れとSavedModelの出力 - sambaiz-net
全体のコードはここ。
def train(self, learning_rate, variable_default_stddev, bias_default, last_step=800): test_images = self.images[:500] test_labels = self.labels[:500] train_batch = Batch(self.images[500:], self.labels[500:]) with tf.Graph().as_default(): global_step=tf.train.get_or_create_global_step() g = MNIST_CNN(learning_rate, variable_default_stddev, bias_default).graph() saver = tf.train.Saver() savedir = &amp;#39;./ckpt-{}-{}-{}&amp;#39;.format(learning_rate, variable_default_stddev, bias_default) hooks = [ tf.train.StopAtStepHook(last_step=last_step) ] with tf.train.MonitoredTrainingSession( hooks=hooks, checkpoint_dir=savedir, save_checkpoint_secs = 300, ) as sess: sess.run(global_step) while not sess.should_stop(): # step = sess.</description>
    </item>
    
    <item>
      <title>GoのgRPC ServerのInterceptor(recovery/auth/zap/prometheus)</title>
      <link>https://www.sambaiz.net/article/174/</link>
      <pubDate>Tue, 26 Jun 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/174/</guid>
      <description>grpc-goはInterceptor(Middleware)でhandlerの前後で処理を行うことができる。 UnaryとStreamでシグネチャが異なる。
type UnaryServerInterceptor func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (resp interface{}, err error) type StreamServerInterceptor func(srv interface{}, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error func UnaryServerInterceptor(opts ...Option) grpc.UnaryServerInterceptor { return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) { resp, err := handler(newCtx, req) fmt.Println(resp) return resp, err } } 今回は良く使うgo-grpc-middlewareの
 recovery auth zap prometehus  Interceptorの挙動を確認する。
proto UnaryなRPCとBidirectional streaming(client, server共にstream)なRPCを一つずつ用意する。
$ cat protos/sample/service.</description>
    </item>
    
    <item>
      <title>GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress</title>
      <link>https://www.sambaiz.net/article/173/</link>
      <pubDate>Sat, 23 Jun 2018 15:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/173/</guid>
      <description>疎通確認用アプリケーション GETでは200を返し、POSTではURLにGETリクエストを送ってステータスコードを返す。
package main import ( &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;net/http&amp;#34; ) type PostBody struct { URL string `json:&amp;#34;url&amp;#34;` } func handler(w http.ResponseWriter, r *http.Request) { if r.Method == http.MethodGet { fmt.Fprintln(w, &amp;#34;ok&amp;#34;) } else if r.Method == http.MethodPost { data, err := ioutil.ReadAll(r.Body) if err != nil { w.WriteHeader(http.StatusInternalServerError) fmt.Fprintln(w, err.Error()) return } p := PostBody{} if err := json.Unmarshal(data, &amp;amp;p); err != nil { w.WriteHeader(http.StatusBadRequest) fmt.Fprintln(w, err.Error()) return } resp, err := http.</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをsave/loadする</title>
      <link>https://www.sambaiz.net/article/172/</link>
      <pubDate>Fri, 22 Jun 2018 01:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/172/</guid>
      <description>SavedModelBuilderで モデルを言語に依存しないSavedModelのprotobufにして保存できる。 SavedModelにはSaverによって出力されるCheckpointを共有する一つ以上のMetaGraphDefを含む。
import tensorflow as tf def build_signature(signature_inputs, signature_outputs): return tf.saved_model.signature_def_utils.build_signature_def( signature_inputs, signature_outputs, tf.saved_model.signature_constants.REGRESS_METHOD_NAME) def save(sess, export_dir, signature_def_map): builder = tf.saved_model.builder.SavedModelBuilder(export_dir) builder.add_meta_graph_and_variables( sess, [tf.saved_model.tag_constants.SERVING], signature_def_map=signature_def_map ) builder.save() import shutil import os.path export_dir = &amp;#34;./saved_model&amp;#34; if os.path.exists(export_dir): shutil.rmtree(export_dir) with tf.Graph().as_default(): a = tf.placeholder(tf.float32, name=&amp;#34;a&amp;#34;) b = tf.placeholder(tf.float32, name=&amp;#34;b&amp;#34;) c = tf.add(a, b, name=&amp;#34;c&amp;#34;) v = tf.placeholder(tf.float32, name=&amp;#34;v&amp;#34;) w = tf.Variable(0.0, name=&amp;#34;w&amp;#34;) x = w.assign(tf.add(v, w)) sv = tf.train.Supervisor() with sv.managed_session() as sess: print(sess.</description>
    </item>
    
    <item>
      <title>ksonnetでkubernetesのmanifestを環境ごとに生成/applyする</title>
      <link>https://www.sambaiz.net/article/171/</link>
      <pubDate>Wed, 20 Jun 2018 01:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/171/</guid>
      <description>ksonnetはJSONのテンプレートエンジンjsonnetからk8sのmanifestを環境ごとに生成してapplyするツール。kubeflowでも使われている。
 追記(2020-11-22): 既に開発が終了しリポジトリもアーカイブされている。 kubeflowはkustomizeに移行した。
kustomizeでkubernetesのmanifestを環境ごとに生成する - sambaiz-net
 $ brew install ksonnet/tap/ks $ ks version ksonnet version: 0.11.0 jsonnet version: v0.10.0 client-go version: init まずks initしてディレクトリを作成する。
$ kubectl config current-context minikube $ ks init kstest $ cd kstest $ ls app.yaml	components	environments	lib	vendor $ cat app.yaml apiVersion: 0.1.0 environments: default: destination: namespace: default server: https://192.168.99.100:8443 k8sVersion: v1.10.0 path: default kind: ksonnet.io/app name: kstest registries: incubator: gitVersion: commitSha: 40285d8a14f1ac5787e405e1023cf0c07f6aa28c refSpec: master protocol: github uri: github.</description>
    </item>
    
    <item>
      <title>Pandasの操作</title>
      <link>https://www.sambaiz.net/article/170/</link>
      <pubDate>Wed, 13 Jun 2018 23:47:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/170/</guid>
      <description>SeriesとDataframe import pandas as pd import numpy as np s = pd.Series([1,3]) print(s[1]) # 3 print(s.values) # [1 3] (ndarray) dates = pd.date_range(&amp;#39;2014-11-01 10:00&amp;#39;,periods=3, freq=&amp;#39;2H&amp;#39;) print(dates) # DatetimeIndex([&amp;#39;2014-11-01 10:00:00&amp;#39;, &amp;#39;2014-11-01 12:00:00&amp;#39;, &amp;#39;2014-11-01 14:00:00&amp;#39;], dtype=&amp;#39;datetime64[ns]&amp;#39;, freq=&amp;#39;2H&amp;#39;) datestr = lambda d: pd.to_datetime(d).strftime(&amp;#39;%Y-%m-%d%H:%M&amp;#39;) df = pd.DataFrame({ &amp;#39;A&amp;#39; : 1., &amp;#39;B&amp;#39; : pd.Series(range(6), index=pd.date_range(&amp;#39;2014-11-01 10:00&amp;#39;,periods=6, freq=&amp;#39;H&amp;#39;)), &amp;#39;C&amp;#39; : [9, 1, 5], }, index=dates) df2 = pd.DataFrame({ &amp;#39;D&amp;#39; : range(3), }, index=dates) print(df) |(index) |A |B|C| |-------------------|---|-|-| |2014-11-01 10:00:00|1.</description>
    </item>
    
    <item>
      <title>ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す</title>
      <link>https://www.sambaiz.net/article/169/</link>
      <pubDate>Sun, 10 Jun 2018 17:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/169/</guid>
      <description>ベイズ最適化で良いハイパーパラメータを総当りのグリッドサーチより効率的に探す。
ベイズ最適化はSMBO(Sequential Model-based Global Optimization)と呼ばれる、目的関数を近似するモデルと、ある値を探索すべきか評価する関数を用いて探索を進め、 実際の目的関数での評価とモデルの修正を行っていく手法の一種。 ベイズ最適化ではモデルとして、直近探索したパラメータとスコアの組の集合Dの条件付き事後確率分布P(y|x, D)を用いる。 確率モデルは、任意の入力(x1, x2, ... , xn)に対応する出力(y1, y2, ..., yn)がガウス分布(=正規分布)に従うガウス過程(GP)や、TPE(Tree-structured Parzen Estimator)が仮定される。
今回はKaggleのTitanicのチュートリアルを、チューニングなしのランダムフォレストとXGBoostで解いたときの結果と比較して、ベイズ最適化によるハイパーパラメータで精度が向上するか確認する。
KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
ランダムフォレスト Pythonのベイズ最適化のライブラリ、BayesianOptimizationを使う。
$ pip install bayesian-optimization RandomForestClassifierのハイパーパラメータ
 n_estimators: 木の数 min_samples_split: ノードを分割するのに必要な最小サンプル数 max_features: 分割するときに考慮する特徴量の割合  の値を探すため、BayesianOptimizationに最大化したい値(精度)とパラメータの範囲を渡す。
from sklearn.model_selection import cross_val_score from sklearn.ensemble import RandomForestClassifier from bayes_opt import BayesianOptimization import pandas as pd def preprocess(df): df[&amp;#39;Fare&amp;#39;] = df[&amp;#39;Fare&amp;#39;].fillna(df[&amp;#39;Fare&amp;#39;].mean()) df[&amp;#39;Age&amp;#39;] = df[&amp;#39;Age&amp;#39;].fillna(df[&amp;#39;Age&amp;#39;].mean()) df[&amp;#39;Embarked&amp;#39;] = df[&amp;#39;Embarked&amp;#39;].fillna(&amp;#39;Unknown&amp;#39;) df[&amp;#39;Sex&amp;#39;] = df[&amp;#39;Sex&amp;#39;].</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/168/</link>
      <pubDate>Sat, 02 Jun 2018 18:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/168/</guid>
      <description>XGBoostは高性能なGradient Boostingのライブラリ。 Boostingというのはアンサンブル学習の種類の一つで、ランダムフォレストのように弱学習器をそれぞれ並列に学習するBaggingに対して、 順番に前回までの結果を受けながら学習し、結果をまとめる際にそれぞれの重みを掛けるもの。 XGBoostではランダムフォレストと同様に決定木を弱学習器とする。
KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net
$ pip install xgboost XGBoostは欠損値をそのまま扱うこともできるが、今回は以前と同じようにデータの前処理を行った。 パラメータの objective(目的関数)には二値分類なのでbinary:logisticを指定し、確率が返るのでroundして出力している。
import pandas as pd import xgboost as xgb from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score def preprocess(df): df[&amp;#39;Fare&amp;#39;] = df[&amp;#39;Fare&amp;#39;].fillna(df[&amp;#39;Fare&amp;#39;].mean()) df[&amp;#39;Age&amp;#39;] = df[&amp;#39;Age&amp;#39;].fillna(df[&amp;#39;Age&amp;#39;].mean()) df[&amp;#39;Embarked&amp;#39;] = df[&amp;#39;Embarked&amp;#39;].fillna(&amp;#39;Unknown&amp;#39;) df[&amp;#39;Sex&amp;#39;] = df[&amp;#39;Sex&amp;#39;].apply(lambda x: 1 if x == &amp;#39;male&amp;#39; else 0) df[&amp;#39;Embarked&amp;#39;] = df[&amp;#39;Embarked&amp;#39;].map( {&amp;#39;S&amp;#39;: 0, &amp;#39;C&amp;#39;: 1, &amp;#39;Q&amp;#39;: 2, &amp;#39;Unknown&amp;#39;: 3} ).astype(int) df = df.drop([&amp;#39;Cabin&amp;#39;,&amp;#39;Name&amp;#39;,&amp;#39;PassengerId&amp;#39;,&amp;#39;Ticket&amp;#39;],axis=1) return df def train(df): train_x = df.</description>
    </item>
    
    <item>
      <title>Istio v0.7でEnvoy Proxyを付けるまで</title>
      <link>https://www.sambaiz.net/article/167/</link>
      <pubDate>Tue, 29 May 2018 22:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/167/</guid>
      <description>追記(2018-09-01) v1.0となりHelmでのインストールも問題なくできるようになった。Istio-AuthがCitadelという名前になっていたりDeprecatedになってるAPIもある
IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net
 Istioとは マイクロサービス間のネットワークの、ロードバランシングや認証、モニタリングなどを担うサービスメッシュのOSS。 概念は抽象化されていて、Kubernetes以外でもサポートされている。 通信をコントロールするdata-planeのEnvoyと、Envoyを管理するcontrol-planeのPilot, Mixer, Istio-Authからなる。
Envoy Sidecarとしてデプロイされる、サービスメッシュでの全ての通信を通すプロキシ。 アプリケーションのコードに手を入れる必要がないので言語に縛られない。 CNCFのプロジェクトの一つで、 Istio用にオリジナルから拡張されている。 ロードバランシングやヘルスチェックなどを行い、メトリクスを取る。
Mixer サービスメッシュ全体のアクセスコントロールや、Envoyからデータを集めてログに出したりモニタリングしたりする。 プラグインよってAWSやGCPといったインフラバックエンドの差異が吸収される。
Pilot サービスディスカバリしてEnvoyのトラフィックを制御する。A/Bテストやカナリアリリースをする場合や、障害に対応して適切にルーティングを行うことができる。
Istio-Auth サービスやエンドユーザーの認証を行い、ポリシーに従ってアクセス制御する。
Istioのインストール ローカルのminikubeに環境を作る。 apiserver.Admission.PluginNamesでは立ち上がらなかったので代わりに apiserver.admission-controlを指定している。
$ minikube version minikube version: v0.27.0 $ minikube start \ --extra-config=apiserver.admission-control=&amp;#34;NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota&amp;#34; \ --kubernetes-version=v1.9.0 $ kubectl config current-context minikube istioを持ってきてapplyする。 Helmも用意されていて将来的にそっちで入れるのが推奨になりそうだ。
$ curl -L https://git.io/getLatestIstio | sh - $ cd istio-0.7.1/ $ kubectl apply -f install/kubernetes/istio-auth.yaml 作成されたserviceとpodはこんな感じ。
$ kubectl get svc -o name -n istio-system NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE istio-ingress LoadBalancer 10.</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
      <link>https://www.sambaiz.net/article/166/</link>
      <pubDate>Tue, 29 May 2018 09:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/166/</guid>
      <description>ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成し並列に学習するアンサンブル学習のBaggingという種類の手法。 決定木なので特徴量の影響が分かりやすく、値の大小で分岐するので標準化の必要がないが、複数の変数で表現される特徴を学習しづらい。 また、単一の決定木と比べて過学習を防ぐことができる。
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
train.csvとtest.csvをKaggleからダウンロードする。 csvにはタイタニックの乗客者リストが含まれ、test.csvには生還したかを表すSurvivedが抜けている。 これを予測するのがこのコンペティションの目的。
データのうちFareやAge、Embarkedは入っていないものがあって、これらの欠損値をどう扱うという問題がある。
df = pd.read_csv(&amp;#39;./train.csv&amp;#39;) print(len(df)) print(df.isnull().sum()) 891 PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 欠損値については連続値をとるFareとAgeは平均を取り、Embarkedは専用のカテゴリーにしてみた。決定木は分岐を繰り返すためlabel encodingで学習できる。 数値化できないものについては除いている。
def preprocess(df): df[&amp;#39;Fare&amp;#39;] = df[&amp;#39;Fare&amp;#39;].fillna(df[&amp;#39;Fare&amp;#39;].mean()) df[&amp;#39;Age&amp;#39;] = df[&amp;#39;Age&amp;#39;].fillna(df[&amp;#39;Age&amp;#39;].mean()) df[&amp;#39;Embarked&amp;#39;] = df[&amp;#39;Embarked&amp;#39;].fillna(&amp;#39;Unknown&amp;#39;) df[&amp;#39;Sex&amp;#39;] = df[&amp;#39;Sex&amp;#39;].apply(lambda x: 1 if x == &amp;#39;male&amp;#39; else 0) df[&amp;#39;Embarked&amp;#39;] = df[&amp;#39;Embarked&amp;#39;].map( {&amp;#39;S&amp;#39;: 0, &amp;#39;C&amp;#39;: 1, &amp;#39;Q&amp;#39;: 2, &amp;#39;Unknown&amp;#39;: 3} ).</description>
    </item>
    
    <item>
      <title>TerraformでGKEクラスタとBigQueryを立てる</title>
      <link>https://www.sambaiz.net/article/165/</link>
      <pubDate>Tue, 29 May 2018 02:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/165/</guid>
      <description>GKEクラスタからBigQueryを読み書きすることを想定している。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net
GKE  google_container_cluster  oauth_scopeにbigqueryを付けている。
resource &amp;#34;google_container_cluster&amp;#34; &amp;#34;sample&amp;#34; { name = &amp;#34;${var.cluster_name}&amp;#34; description = &amp;#34;sample k8s cluster&amp;#34; zone = &amp;#34;${var.gcp_zone}&amp;#34; initial_node_count = &amp;#34;${var.initial_node_count}&amp;#34; master_auth { username = &amp;#34;${var.master_username}&amp;#34; password = &amp;#34;${var.master_password}&amp;#34; } node_config { machine_type = &amp;#34;${var.node_machine_type}&amp;#34; disk_size_gb = &amp;#34;${var.node_disk_size}&amp;#34; oauth_scopes = [ &amp;#34;https://www.googleapis.com/auth/compute&amp;#34;, &amp;#34;https://www.googleapis.com/auth/devstorage.read_only&amp;#34;, &amp;#34;https://www.googleapis.com/auth/logging.write&amp;#34;, &amp;#34;https://www.googleapis.com/auth/monitoring&amp;#34;, &amp;#34;https://www.googleapis.com/auth/bigquery&amp;#34;, ] } } variable &amp;#34;env&amp;#34; { description = &amp;#34;system env&amp;#34; } variable &amp;#34;gcp_zone&amp;#34; { description = &amp;#34;GCP zone, e.</description>
    </item>
    
    <item>
      <title>カナダのバンクーバーから南へ5都市周ってGoogleI/Oに行ってきた</title>
      <link>https://www.sambaiz.net/article/164/</link>
      <pubDate>Mon, 28 May 2018 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/164/</guid>
      <description>去年と連続でチケットが当たって2回目の参加。 前回はニューヨークで大変な目にあったが、 今回はI/OがGWの次の週だったので日程に余裕があり、カナダのバンクーバーから、ビクトリア、アメリカに入ってポートエンジェルス、シアトル、ポートランドと南下していって会場のマウンテンビューを目指すことにした。
準備 前回と同じ基本的にExpediaで航空券やホテルは取って、各業者のサイトで都市間の移動に使うフェリーやバスや電車を予約して、 あとアメリカのeSTAのようにカナダにもeTAというのがあって申請した。
前回は空港からマンハッタンのT-mobileのショップにたどり着くまでネット回線がなく、地図すら空港のwifi頼みで大変な思いをした。 今回はカナダも行くので事前にAmazonでカナダも対応しているプランのSIMを購入して業者にアクティベートしてもらうことにした。
今回は夜出発だったので時間に余裕があったが、念のため前日から万札を何枚か財布に入れておいた。つまるところ、現金とネットさえあればなんとでもなるのだ。
バンクーバー 空港から出ても怪しい人を見かけないし、駅の人も愛想良く案内してくれる。 アナウンスもはっきりしているので聞き取りやすく券売機のUIもわかりやすい。 駅の券売機で交通ICカードCompassを手に入れれば、電車・バス共に乗ることができる。 Uberは走っていないがバスが発達していて大体事足りる。バス停の標識も比較的低い位置にあって気付きやすい。
バスから降りるとき皆Thank youと言ってるのは良い感じだ。財布を落としたり傘を忘れたりしても皆で教えてくれるし、人が親切で治安が良くて安心感がある。
アジア系の飲食店が多い。漢字が併記されているのもよく見る。
朝食はJethro&amp;rsquo;s Fine Grubという店で取った。ダウンタウンからは少し離れてるのに待ちが発生していた。
これを食べてからGranville Islandという店が並んでいるところに行ってきた。 Public Marketにはソーセージやお菓子などが売ってたりするんだが、腹が一向に空かないし、中には座れず外はとても寒かったので何も買わずに帰ってきた。
ビクトリア BC Ferries ConnectorというバスがバンクーバーのPublic Central Stationから出ていて、これに乗るとそのままフェリーに乗り込んでビクトリアまで行くことができる。船内のカフェテリアにカナダらしい食べ物プーティンがあったので頼んでみたら思ったより量が多く、15分前ぐらいのアナウンスでバスに戻らないと普通に置いてかれるので、なんとかコーラで流し込んだ。
ビクトリアのダウンタウンに到着後、バスで1時間くらいかけて北へButchers Gardenという庭園に向かった。 ビクトリアには交通ICカードがないので、車内で5ドル払って1日乗車券をもらって乗る。 この時期は色とりどりのチューリップが咲いていて、歩いているだけで良い香りがする。
そのほかに鹿おどしのある日本庭園や、イタリア庭園もあったりする。
このためにビクトリアを訪れてもよいぐらい満足度が高かった。
朝食はBlueFox Caffeという店でEggs Pacificoというサーモンとアボカドのエッグベネディクトを頼んだ。 付け合わせの芋が多いが、とても美味しい。1日1食の日々がしばらく続く。
ポートエンジェルス(オリンピック半島) ビクトリアの州議事堂の近くから出ているBlack Ball Ferry Lineに乗ってポートエンジェルスに移動する。 予約しても受付でチケットを受け取る必要がある。乗る前に入国審査を受けて、I-94Aという紙をパスポートに貼ってもらった。 料金が6ドルかかる。カードでも払えるがカナダドルでは払えなかった。
町の自転車屋で電動自転車を借りて、まずはオリンピック国立公園のビジターセンターを目指した。ここで10ドル払うと入園券みたいなののとマップがもらえる。 どこに行くつもりか、と聞かれたので何も考えてないと答えると、比較的近くにあるHurricane Ridgeという所を教えてもらったのでそこを目指すことにした。
オフシーズンだからか道を工事していて所々コンディションが悪い。しかもずっと上り坂だ。 それでも電動アシストの力を借りて登っていったのだが、途中でまさかの電池切れ。しょうがないので町に引き返してその日は終わり。返すとき顛末を説明したら割り引いてくれた。
次の日はバスでMarymere fallsという小さな滝のトレッキングコースに行った。散歩みたいなコースですぐ終わってしまったので、 途中の分岐にあったStormKingというコースにも入ってみたら、傾斜が延々と続く山登りコースだった。終盤END OF MAINTAINED TRAILの標識よりあとはいろいろ厳しくなり、勇気と気合いでロープをつかみながら登っていくことになる。
頂上からはCrescent Lakeがその名の通り三日月に見える。景色はよいのだが足場が狭くて立っているだけで怖い。
シアトル ポートエンジェルスからバスでシアトルへ。Olympic Bus Linesのバスで、クッキーが配られた。
シアトルのホテルは高かったのでAirBnbを使ってみた。ナンバーロック式の部屋だったので、ホストとはメッセージのやりとりだけで済んだし、親切にも日本語のガイドブックまで用意しておいてくれた。
まず、交通ICカードOrcaを手に入れようと、駅の自販機にクレジットカードを入れたところ出てこなくなってしまった。駅員はいないので、なんとか引き抜こうと頑張っていたところ、親切な人がペンチを借りてきてくれてなんとか引き抜くことができた。よかった。 ただ、こんな苦労して手に入れたOrcaも2回ぐらいしか使わなかった。というのもバス停が他の標識と混在して分かりづらく、Uberに迎えに来てもらった方が楽だったからだ。相乗りのUber Poolならバスの倍くらいで乗ることができる。
気を取り直して、Amazonの本部、Day 1に行ってきた。前から予約すれば社内ツアーもあるみたいだが、今回の目的はこの1階にある、今年オープンしたレジ無しコンビニのAmazon Goだ。</description>
    </item>
    
    <item>
      <title>Macでの開発環境構築メモ</title>
      <link>https://www.sambaiz.net/article/163/</link>
      <pubDate>Sat, 14 Apr 2018 14:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/163/</guid>
      <description>新しいMBPを買ったので開発環境の構築でやったことを残しておく
設定  アクセシビリティから3本指スクロールを有効にする ホットコーナーの左上にLaunchPad、右上にデスクトップを割り当てている 画面をなるべく広く使うためにDockは左に置いて自動的に隠す  bash_profile パッケージマネージャ以外で持ってきたバイナリは${HOME}/binに置くことにする。
touch ~/.bash_profile mkdir ${HOME}/bin echo &amp;#34;export PATH=\$PATH:${HOME}/bin&amp;#34; &amp;gt;&amp;gt; ~/.bash_profile HomeBrew &amp;amp; Cask /usr/bin/ruby -e &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;#34; brew tap caskroom/cask 一般的なアプリケーション/コマンドのインストール XcodeとUnityとLINEは手動で入れる。
brew cask install google-chrome kap visual-studio-code slack kindle brew install jq gibo mysql wget Git git config --global user.name sambaiz git config --global user.email godgourd@gmail.com Docker &amp;amp; K8s brew cask install docker virtualbox minikube brew install docker kubernetes-helm fish bash前提で書かれたスクリプトも多いので、デフォルトシェルにはしない。</description>
    </item>
    
    <item>
      <title>Pythonのasyncioで非同期にリクエストを飛ばす</title>
      <link>https://www.sambaiz.net/article/162/</link>
      <pubDate>Sat, 14 Apr 2018 13:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/162/</guid>
      <description>Pythonのasyncioはイベントループを回してシングルスレッドで並行に非同期処理を行う。 マルチスレッドで並列に実行するのがthreadingで、 マルチプロセスで並列に実行するのがmultiprocessing。
import asyncio async def sleep(s): await asyncio.sleep(s) print(s) return s loop = asyncio.get_event_loop() loop.run_until_complete(sleep(5)) coros = [sleep(3), sleep(2)] futures = asyncio.gather(*coros) loop.run_until_complete(futures) print(futures.result()) loop.close() $ python main.py 5 2 3 [3, 2] get_event_loop() でイベントループを取得し、 gather()で処理をまとめたりして、 run_until_complete()で Futureの完了を待ち、 結果を取得してイベントループをclose()している。
async defを付けた関数はCoroutineとなり、 ensure_future()でFutureのサブクラスの、イベントループで実行させるTaskにすることができる。 run_until_complete()はそのままCoroutineを投げてもensure_future()でwrapしてくれる。
httpクライアントrequestsはBlockingするようなので、asyncioに対応しているaiohttpを使ってリクエストしてみる。
import aiohttp import asyncio import async_timeout async def fetch(session, url): print(&amp;#34;{} start&amp;#34;.format(url)) async with async_timeout.timeout(10): async with session.get(url) as response: text = await response.text() print(&amp;#34;{} done&amp;#34;.</description>
    </item>
    
    <item>
      <title>KubernetesにHelmでLocustによる分散負荷試験環境を立てる</title>
      <link>https://www.sambaiz.net/article/161/</link>
      <pubDate>Sun, 18 Mar 2018 22:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/161/</guid>
      <description>OSSの負荷試験ツールLocustをK8sクラスタに立てる。 K8sならworkerの増減も簡単だし、HelmのChartもあるので立てるのも楽。
CDKでEKSクラスタの作成からHelm ChartでのLocustのインストールまでを一気に行う - sambaiz-net
LocustはPython製で、以下のようなコードで処理を書くことができる。
@task(10)のように括弧の中に数字を書いて実行される割合を偏らせることもできる。 異なるTaskSetに対応するユーザーを複数作ることもできて、こちらもweightで重みを付けられる。 ユーザー数はあとでWeb上から入力する。
$ mkdir tasks $ cat tasks/tasks.py from locust import HttpLocust, TaskSet, task class ElbTasks(TaskSet): @task def task1(self): with self.client.get(&amp;#34;/&amp;#34;, catch_response=True) as response: if response.content != &amp;#34;Success&amp;#34;: response.failure(&amp;#34;Got wrong response&amp;#34;) class ElbWarmer(HttpLocust): task_set = ElbTasks min_wait = 1000 max_wait = 3000 stableにChartはあるが、今のところtasksの中を書き換えなくてはいけないようなので、forkしてきてtasksの中を書き換え、package して、helm repo index でこれを参照するindex.yamlを生成した。
 追記(2020-03-11): 今はConfigmapを自分で作成し --set worker.config.configmapName=*** することでforkしなくてもよくなった kubectl create configmap locust-worker-configs --from-file tasks/tasks.py
 $ helm package .</description>
    </item>
    
    <item>
      <title>RBACが有効なGKEでHelmを使う</title>
      <link>https://www.sambaiz.net/article/160/</link>
      <pubDate>Sun, 18 Mar 2018 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/160/</guid>
      <description>k8sのパッケージマネージャーHelmを使う - sambaiz-net
$ helm version Client: &amp;amp;version.Version{SemVer:&amp;#34;v2.8.2&amp;#34;, GitCommit:&amp;#34;a80231648a1473929271764b920a8e346f6de844&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;} Server: &amp;amp;version.Version{SemVer:&amp;#34;v2.8.2&amp;#34;, GitCommit:&amp;#34;a80231648a1473929271764b920a8e346f6de844&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;} GKEでhelm initしてhelm installしたところ以下のエラーが返ってきた。
Error: release my-locust failed: namespaces &amp;#34;default&amp;#34; is forbidden: User &amp;#34;system:serviceaccount:kube-system:default&amp;#34; cannot get namespaces in the namespace &amp;#34;default&amp;#34;: Unknown user &amp;#34;system:serviceaccount:kube-system:default&amp;#34; GKEではデフォルトでK8sのRBAC(Role-Based Access Control)が有効になっているため、Tillerインスタンスに権限を与える必要がある。
ということでTiller用にnamespaceを切って、その中では好きにできるRoleと、Tillerが使うServiceAccountを作成し、RoleBindingで紐づける。
kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: tiller-manager namespace: tiller-world rules: - apiGroups: [&amp;#34;&amp;#34;, &amp;#34;extensions&amp;#34;, &amp;#34;apps&amp;#34;] resources: [&amp;#34;*&amp;#34;] verbs: [&amp;#34;*&amp;#34;] --- apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: tiller-world --- kind: RoleBinding apiVersion: rbac.</description>
    </item>
    
    <item>
      <title>Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る</title>
      <link>https://www.sambaiz.net/article/159/</link>
      <pubDate>Tue, 13 Mar 2018 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/159/</guid>
      <description>Logging AgentをNodeレベルのDaemonSetとして動かすのではなく、Podの中にSidecar Containerとして動かす。その分リソースは食うが、独立した設定で動かせる。
アプリケーション https://github.com/sambaiz/go-logging-sample
Goで定期的にログを出すサンプルコードを書いたのでこれを使う。 viperで設定を持ち、 zapでログを出力する。 あとSIGINTを拾ってSync()してGraceful Shutdownするようにしている。
Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net
multistage-buildして、GKEで動かすのでContainer Registryに上げる。
$ docker build -t go-logging-sample . $ docker tag go-logging-sample gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1 $ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample Fluentdの設定 fluent-plugin-bigqueryプラグインを使う。
projectとdataset、パーティションの日付分割テーブルに入れる場合は、auto_create_tableできないのでtableも作成しておく。
fluentdの設定はConfigMapで持つ。
apiVersion: v1 kind: ConfigMap metadata: name: fluentd-config data: fluent.conf: |&amp;lt;source&amp;gt; @type tail format json path /var/log/app.log pos_file /var/log/app.log.pos tag bigquery &amp;lt;/source&amp;gt; &amp;lt;match bigquery&amp;gt; @type bigquery method load &amp;lt;buffer time&amp;gt; @type file path /var/log/bigquery.*.buffer timekey 1d flush_at_shutdown true &amp;lt;/buffer&amp;gt; auth_method	compute_engine project &amp;lt;project-name&amp;gt; dataset &amp;lt;dataset-name&amp;gt; table &amp;lt;table-name&amp;gt;$%Y%m%d fetch_schema true ignore_unknown_values true	&amp;lt;/match&amp;gt; プラグイン入りのfluentdイメージもビルドして上げる。</description>
    </item>
    
    <item>
      <title>MySQL InnoDBのロックの挙動</title>
      <link>https://www.sambaiz.net/article/158/</link>
      <pubDate>Sat, 03 Mar 2018 19:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/158/</guid>
      <description>https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html
トランザクション分離レベルはデフォルトのREPEATABLE-READ。
&amp;gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@GLOBAL.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 準備 DBを立ち上げてテーブルとレコードを入れる。
$ cat schema_and_data.sql CREATE TABLE a ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, name VARCHAR(128) NOT NULL ); CREATE TABLE b ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, a_id BIGINT UNSIGNED NOT NULL, FOREIGN KEY (a_id) REFERENCES a (id) ); INSERT INTO a (id, name) VALUES (1, &amp;#39;1&amp;#39;); INSERT INTO a (id, name) VALUES (2, &amp;#39;2&amp;#39;); INSERT INTO a (id, name) VALUES (3, &amp;#39;3&amp;#39;); INSERT INTO a (id, name) VALUES (8, &amp;#39;8&amp;#39;); INSERT INTO a (id, name) VALUES (9, &amp;#39;9&amp;#39;); INSERT INTO a (id, name) VALUES (10, &amp;#39;10&amp;#39;); $ cat start.</description>
    </item>
    
    <item>
      <title>Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる</title>
      <link>https://www.sambaiz.net/article/157/</link>
      <pubDate>Sun, 25 Feb 2018 23:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/157/</guid>
      <description>UserPoolを作成。デフォルト設定はこんな感じ。 必須項目や、確認メールの文面などを自由にカスタマイズでき、 登録時などのタイミングでLambdaを発火させることもできる。
作成したUserPoolにアプリクライアントを追加する。 ブラウザで使うのでクライアントシークレットはなし。
クライアント側 amazon-cognito-identity-jsを使う。
依存するjsを持ってくる。
$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/amazon-cognito-identity.min.js $ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/aws-cognito-sdk.min.js Sign UpからAPIを呼ぶところまでのボタンを並べた。 SignInするとOIDC標準のトークンがそのページのドメインのLocal Storageに書かれる。
OpenID ConnectのIDトークンの内容と検証 - sambaiz-net
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.idToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.accessToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.refreshToken CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.clockDrift CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.LastAuthUser APIを呼ぶときはidTokenをAuthorization Headerに乗せる。
&amp;lt;button id=&amp;#34;signUp&amp;#34;&amp;gt;Sign Up&amp;lt;/button&amp;gt; &amp;lt;p&amp;gt;&amp;lt;label&amp;gt;Code:&amp;lt;input type=&amp;#34;text&amp;#34; id=&amp;#34;code&amp;#34;&amp;gt;&amp;lt;/label&amp;gt;&amp;lt;/p&amp;gt; &amp;lt;button id=&amp;#34;confirm&amp;#34;&amp;gt;Confirm&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;#34;signIn&amp;#34;&amp;gt;Sign In&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;#34;whoAmI&amp;#34;&amp;gt;Who am I?&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;#34;requestAPI&amp;#34;&amp;gt;Request API with token&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;#34;signOut&amp;#34;&amp;gt;Sign Out&amp;lt;/button&amp;gt; &amp;lt;script src=&amp;#34;aws-cognito-sdk.min.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script src=&amp;#34;amazon-cognito-identity.min.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script&amp;gt; const USER_NAME = &amp;#34;*****&amp;#34;; const USER_PASSWORD = &amp;#34;*****&amp;#34;; const USER_EMAIL = &amp;#34;*****&amp;#34;; class CognitoUserPoolAuth { constructor(UserPoolId, clientId, apiEndpoint) { const poolData = { UserPoolId : UserPoolId, ClientId : clientId }; this.</description>
    </item>
    
    <item>
      <title>ブラウザのwindow間の値渡し</title>
      <link>https://www.sambaiz.net/article/156/</link>
      <pubDate>Fri, 23 Feb 2018 02:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/156/</guid>
      <description>直接Windowを参照する オリジン(プロトコル+ポート+ホスト)が同じ場合は、親はopen()した返り値で、子はwindow.openerで相手のwindowが取れて、直接参照したりDOMを操作したりすることもできる。
同じ/異なるオリジンのiframeの中からできること - sambaiz-net
$ cat index.html &amp;lt;button id=&amp;#34;btn&amp;#34;&amp;gt;Open window&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;#34;btn2&amp;#34;&amp;gt;Close window&amp;lt;/button&amp;gt; &amp;lt;div id=&amp;#34;view&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; let win2; const button = document.getElementById(&amp;#34;btn&amp;#34;); button.addEventListener(&amp;#34;click&amp;#34;, () =&amp;gt; { window.foo = &amp;#34;bar from window1&amp;#34;; win2 = window.open(&amp;#34;index2.html&amp;#34;); }, false); const button2 = document.getElementById(&amp;#34;btn2&amp;#34;); button2.addEventListener(&amp;#34;click&amp;#34;, () =&amp;gt; { if (win2) { win2.close(); } }, false); &amp;lt;/script&amp;gt; $ cat index2.html &amp;lt;button id=&amp;#34;btn&amp;#34;&amp;gt;Close window&amp;lt;/button&amp;gt; &amp;lt;div id=&amp;#34;view&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; console.log(window.aaa); const parentWindow = window.opener; const view = document.</description>
    </item>
    
    <item>
      <title>Serverless FrameworkでLambdaをデプロイする</title>
      <link>https://www.sambaiz.net/article/155/</link>
      <pubDate>Sun, 11 Feb 2018 23:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/155/</guid>
      <description>Serverless FrameworkでLambda Functionをデプロイする。 Apexが基本的にFunction自体のデプロイしかしないのに対して、こちらはeventの設定なども諸々やってくれて強い。
ApexでLambdaをデプロイする - sambaiz-net
$ npm install -g serverless $ serverless version 1.26.0 ApexではFunctionごとにディレクトリが作られたが、ServerlessではServiceごとに作られ、 一つのService内で複数のFunctionを定義できる。handlerは同じでも異なっていてもよい。
Apexの形式の場合、共通の処理をWebpackなどで各Functionに持って来たり、 同じような処理の複数のFunctionを立てる際はコピーする必要があったが、 こちらは必要最小限の変更でそれらを行うことができる。
templateからServiceをcreateする。
$ serverless create --template aws-nodejs --path testservice $ ls testservice/ handler.js	serverless.yml 設定ファイルserverless.yml にはLambdaの基本的なもののほかに、VPCやevent、IAM Roleなども書けて、これらはdeploy時に作られるCloudFormationのstackによって管理される。必要なら生のCloudFormationの設定も書ける。
ApexでもTerraformによって管理することができるが、書くのはこちらの方がはるかに楽。
ApexでデプロイしたLambdaのトリガーをTerraformで管理する - sambaiz-net
$ cat sesrverless.yml service: testservice provider: name: aws profile: foobar region: ap-northeast-1 runtime: nodejs6.10 memorySize: 512 timeout: 10 functions: hello: handler: handler.hello events: - http: path: hello/world method: get cors: true deployすると{service}-{stage}-{function}のFunctionが作られる。 今回の場合はtestservice-prd-test。stageをymlでも指定しなかった場合はデフォルト値のdevになる。</description>
    </item>
    
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。 全体のコードはここ。
入力 以下の関数によって生成した1次元のデータ列。 これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。
def make_time_series_data(size): data = [] for i in range(size): data.append(sin(random.normalvariate(i,0.1)*0.1)) return np.reshape(np.array(data, dtype=np.float32), (size,1)) def make_batch(data, batch_size, num_steps, num_dimensions, name=None): epoch_size = data.size // (batch_size*num_steps*num_dimensions) data = np.lib.stride_tricks.as_strided( data, shape= (epoch_size, batch_size, num_steps+1, num_dimensions), strides=( 4*batch_size*num_steps*num_dimensions, 4*num_steps*num_dimensions, 4*num_dimensions, 4 # bytes ), writeable=False ) return data[:, :, :-1], data[:, :, 1:] モデル input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。 lossはMSE(Mean squared error)。OptimizerはGradientDecentOptimizerを使っている。
チュートリアルでは自力で各time_stepの値を入れていたが、 今回はdynamic_rnn()に任せている。
class Model(object): def __init__(self, config, is_training=False): # config self.</description>
    </item>
    
    <item>
      <title>xorm reverseでDBスキーマからGoのstructを生成する</title>
      <link>https://www.sambaiz.net/article/153/</link>
      <pubDate>Sat, 10 Feb 2018 15:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/153/</guid>
      <description>GoのORMのxormにはxorm reverseというDBのスキーマから以下のようなテンプレートに沿ったGoのstructなどを生成するツールがある。
package {{.Model}} import ( {{range .Imports}}&amp;#34;{{.}}&amp;#34;{{end}} ) {{range .Tables}} type {{Mapper .Name}} struct { {{$table := .}} {{range .Columns}}	{{Mapper .Name}}	{{Type .}} {{end}} } {{end}} リポジトリにあるテンプレートにxorm用テンプレートとgo用のテンプレートが用意されているように、単体で使うこともできる。 また、テンプレートを書く言語としてもGo以外にC++もサポートしている。
xormのcmdとドライバをインストール。
$ go get github.com/go-xorm/cmd/xorm $ go get github.com/go-sql-driver/mysql $ xorm Version: 0.2.0524 様々な型のカラムを含むテーブルで試す。
$ cat schema.sql CREATE TABLE table1 ( n_tinyint TINYINT, n_int INT, n_int_unsigned INT UNSIGNED NOT NULL DEFAULT 1, n_bigint BIGINT, n_float FLOAT, n_double DOUBLE, d_date DATE, d_datetime DATETIME, s_char CHAR(64), s_varchar VARCHAR(64), s_text TEXT, s_json JSON, b_binary BLOB, e_enum ENUM(&amp;#39;aaa&amp;#39;, &amp;#39;bbb&amp;#39;, &amp;#39;ccc&amp;#39;) ) $ cat setup.</description>
    </item>
    
    <item>
      <title>DatadogのLambda Integrationで気象データを送ってアラートを飛ばす</title>
      <link>https://www.sambaiz.net/article/152/</link>
      <pubDate>Mon, 05 Feb 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/152/</guid>
      <description>最近朝が寒くて布団から出るのがつらい。雨や雪が降っていたら尚更のこと、それならそれで現状を把握する必要がある。 そこで、無料から使える気象API OpenWeatherMapのデータをdatadogに送って、特に寒い日や雨雪が降るような朝にはアラートを飛ばすことにした。
インスタンスが立っていたらDataDog AgentのDogStatsD経由で送ることができ、 そうでなければ通常はAPIを呼ぶことになるんだが、Lambdaでは、AWS Integrationを設定すると有効になるLambda Integrationによって MONITORING|unix_epoch_timestamp|value|metric_type|my.metric.name|#tag1:value,tag2のフォーマットでconsole.logするだけでメトリクスが送られるようになっている。
 追記 (2020-12-07): 今はDatadog Forwaderを通して送ることができる。
 const axios = require(&amp;#39;axios&amp;#39;); const CITY = &amp;#39;Shibuya&amp;#39;; const API_KEY = &amp;#39;*****&amp;#39;; const WEATHER_API = `http://api.openweathermap.org/data/2.5/weather?q=${CITY}&amp;amp;units=metric&amp;amp;appid=${API_KEY}`; const METRIC_COUNTER = &amp;#39;counter&amp;#39;; const METRIC_GAUGE = &amp;#39;gauge&amp;#39;; const monitor = (metricName, metricType, value, tags) =&amp;gt; { const unixEpochTimestamp = Math.floor(new Date().getTime()); console.log(`MONITORING|${unixEpochTimestamp}|${value}|${metricType}|${metricName}|#${tags.join(&amp;#39;,&amp;#39;)}`); }; exports.handler = async (event, context, callback) =&amp;gt; { const data = (await axios.get(WEATHER_API)).data const namePrefix = &amp;#39;livinginfo.</description>
    </item>
    
    <item>
      <title>ローカルでビルドしたimageをminikubeで使う</title>
      <link>https://www.sambaiz.net/article/151/</link>
      <pubDate>Thu, 01 Feb 2018 22:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/151/</guid>
      <description>$ minikube version minikube version: v0.25.0 $ kubectl version Client Version: version.Info{Major:&amp;#34;1&amp;#34;, Minor:&amp;#34;9&amp;#34;, GitVersion:&amp;#34;v1.9.2&amp;#34;, GitCommit:&amp;#34;5fa2db2bd46ac79e5e00a4e6ed24191080aa463b&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;, BuildDate:&amp;#34;2018-01-18T21:11:08Z&amp;#34;, GoVersion:&amp;#34;go1.9.2&amp;#34;, Compiler:&amp;#34;gc&amp;#34;, Platform:&amp;#34;darwin/amd64&amp;#34;} $ kubectl config current-context minikube $ minikube status minikube: Running cluster: Running kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100 dockerコマンドがminikube VM内で動いているdocker daemonを参照するようにする。
$ minikube docker-env export DOCKER_TLS_VERIFY=&amp;#34;1&amp;#34; export DOCKER_HOST=&amp;#34;tcp://192.168.99.100:2376&amp;#34; export DOCKER_CERT_PATH=&amp;#34;/Users/sambaiz/.minikube/certs&amp;#34; $ eval $(minikube docker-env) $ docker info --format &amp;#39;{{json .Name}}&amp;#39; &amp;#34;minikube&amp;#34; ビルドするDockerfile。nginxが立ち上がるだけ。
FROMnginx 何もタグを付けない(:latest)とcreate時にDockerレジストリからpullしにいって失敗してしまうため、タグ付きでビルドする。
$ docker build -t my/myapp:1.</description>
    </item>
    
    <item>
      <title>Chromeで任意のscriptを読み込まれる前に差し替える</title>
      <link>https://www.sambaiz.net/article/150/</link>
      <pubDate>Thu, 01 Feb 2018 21:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/150/</guid>
      <description>ChromeのDevToolsではSourcesからscriptを書き換えられるようになっているが、 一行目にbreakpointを挟んで更新するとそこで止まるので読み込まれる前に差し替えることができる。 ページの読み込み時に呼ばれるSDKやライブラリの影響範囲を調べたりデバッグしたりするのに便利。
確認用jsとhtml
console.log(&amp;#34;original&amp;#34;) &amp;lt;script src=&amp;#34;index.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; 読み込み時に実行されるconsole.logの文章を変えた。</description>
    </item>
    
    <item>
      <title>Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す</title>
      <link>https://www.sambaiz.net/article/149/</link>
      <pubDate>Fri, 19 Jan 2018 09:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/149/</guid>
      <description>GooseはGo製のDB Migrationツール。
コード
こんなリポジトリを作成し、各自ブランチを切ってGoose形式のup/downのSQLを書き、終わったらPullRequestを出す。
goose/ .keep .circleci/config.yml create_test_table.sql $ cat create_test_table.sql -- +goose Up -- SQL in this section is executed when the migration is applied. CREATE TABLE testtable ( id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT, n INT NOT NULL, c VARCHAR (20) NOT NULL UNIQUE ); -- +goose Down -- SQL in this section is executed when the migration is rolled back. DROP TABLE testtable; 無事Approveされ、mergeされるとCircleCIが走り、 SQLをgooseディレクトリの中にバージョンを付けて移し、 SlackにpostMessageするエンドポイントにリクエストを飛ばす。
ここでバージョンを作成することによって、並列で作業し、レビューなどの関係で適用順が前後しても修正する必要をなくしている。ただ、pushされる前に複数のブランチを連続でmergeする場合うまく動かないのでそれはなんとかする必要がある。</description>
    </item>
    
    <item>
      <title>SlackのInteractive messagesでボタンの入力を受け付ける</title>
      <link>https://www.sambaiz.net/article/148/</link>
      <pubDate>Tue, 16 Jan 2018 21:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/148/</guid>
      <description>Interactive messages
まずはサーバーを用意する。コードはここにあって、 Interactive messagesのハンドリングはSlack公式のnode-slack-interactive-messagesを使っている。
app.use(&amp;#39;/slack&amp;#39;, slackMessages.expressMiddleware()); slackMessages.action(&amp;#39;question_button&amp;#39;, (payload) =&amp;gt; { let replacement = payload.original_message; replacement.text =`${payload.user.name}likes ${payload.actions[0].value}`; delete replacement.attachments[0].actions; return replacement; }); ボタンの表示はattachmentsを使う。
web.chat.postMessage(channelId, &amp;#39;Question&amp;#39;, { attachments: [ { text: &amp;#34;Which buttons do you like?&amp;#34;, color: &amp;#34;#f9a41b&amp;#34;, callback_id: &amp;#34;question_button&amp;#34;, actions: [ { name: &amp;#34;primary_button&amp;#34;, type: &amp;#34;button&amp;#34;, style: &amp;#34;primary&amp;#34;, text: &amp;#34;Primary&amp;#34;, value: &amp;#34;Primary Button&amp;#34;, }, { name: &amp;#34;normal_button&amp;#34;, type: &amp;#34;button&amp;#34;, text: &amp;#34;Normal&amp;#34;, value: &amp;#34;Normal Button&amp;#34; }, { name: &amp;#34;danger_button&amp;#34;, type: &amp;#34;button&amp;#34;, style: &amp;#34;danger&amp;#34;, text: &amp;#34;Danger&amp;#34;, value: &amp;#34;Danger Button&amp;#34;, confirm: { title: &amp;#34;Really?</description>
    </item>
    
    <item>
      <title>TensorBoardでsummaryやグラフを見る</title>
      <link>https://www.sambaiz.net/article/147/</link>
      <pubDate>Sun, 07 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/147/</guid>
      <description>TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
で読んだコードをTensorboardでみてみる。
8888がJupyter、6006がTensorboard。
$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow コードをuploadするかJupyterからterminalを開いてcloneしてくる。
# apt-get update # apt-get install -y git wget # git clone https://github.com/tensorflow/models.git # cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz logdirを指定して実行し、Tensorboardを起動。
flags.DEFINE_string(&amp;#34;save_path&amp;#34;, &amp;#34;.&amp;#34;, &amp;#34;Model output directory.&amp;#34;) sv = tf.train.Supervisor(logdir=FLAGS.save_path)  追記(2018-11-14): Supervisorはdeprecatedなので以下の記事でやっているようにMonitoredTrainingSessionを使うとよい。
Deep LearningのBatch Normalizationの効果をTensorFlowで確認する - sambaiz-net
 # tensorboard --logdir=models/tutorials/rnn/ptb tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)による値がリアルタイムに表示される。
グラフのつながりや、各Operationの入出力やそのshapeを確認できる。 name_scopeで分けておくと見やすい。</description>
    </item>
    
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。
RNN/LSTMとは RNNは入力に対して出力のほかに情報を次のステップに渡すことで時系列データで学習できるようにするネットワーク。 展開すると同じネットワークに単語を一つずつ入れていくように表現できる。
これを単純にMLPで実装しようとすると逆誤差伝搬する際に過去の層にも伝搬させる(BPTT: Backpropagation through time)必要があり、 時間を遡るほど活性化関数の微分係数が再帰的に繰り返し掛けられるため勾配が消失や爆発しやすくなってしまう。 また、時系列データのうちに発火したいものと発火したくないものが混在している場合、同じ重みにつながっているため更新を打ち消しあってしまう入力/出力重み衝突という問題もある。
これらを解決するのがLSTM(Long Short Term Memory networks)で、 勾配消失は活性化関数がxで重みが単位行列のニューロンのCEC(Constant Error Carousel)によって常に誤差に掛けられる係数を1にすることで防ぎ、 入力/出力重み衝突は必要な入出力を通したり不必要な情報は忘れさせるために値域(0,1)の値を掛けるinput gate、forget gate、output gateによって回避する。gateは入力と前回の出力によって制御される。
TensorflowではいくつかLSTMの実装が用意されていて、CudnnLSTMやBasicLSTMCell、LSTMBlockCellなどがある。 cuDNNというのはNVIDIAのCUDAのDNNライブラリのこと。 LSTMBlockCellはもう少し複雑なLSTMでBasicLSTMCellよりも速い。
動かしてみる $ git clone https://github.com/tensorflow/models.git $ cd models/tutorials/rnn/ptb/ $ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz $ tar xvf simple-examples.tgz $ python3 -m venv env $ . ./env/bin/activate $ pip install numpy tensorflow $ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0 Epoch: 1 Learning rate: 1.000 0.004 perplexity: 5534.452 speed: 894 wps 0.</description>
    </item>
    
    <item>
      <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
      <link>https://www.sambaiz.net/article/145/</link>
      <pubDate>Sun, 24 Dec 2017 23:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/145/</guid>
      <description>https://github.com/sambaiz/athena-admin
AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。
料金はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。 データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだが都度locationを指定してADD PARTITIONを実行するのは大変。さらにスキーマを変更するのにもALTER TABLE ADD COLUMNSなどはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。
ではどうしようもないかというとMSCK REPAIR TABLEというのがあって、 これはS3のObjectのdt=YYYY-MM-DDのようなkey=valueのprefixを認識してパーティションを作るもの。作り直す際もこれ1クエリで終わる。それなら最初からそういう風に置けばよいのではというところだが、勝手にYYYY/MM/DD/HHのprefixを付けてしまうFirehoseのようなのもある。
今回作ったathena-adminは以下のような定義ファイルから、 パーティションのkey=valueのprefixが付くように置き換えたり、変更があったらmigrationする。 このファイルを書き換えるだけで基本的にどうにかなるし、バージョン管理すればテーブル定義の変更を追うことができる。
{ &amp;#34;general&amp;#34;: { &amp;#34;athenaRegion&amp;#34;: &amp;#34;ap-northeast-1&amp;#34;, &amp;#34;databaseName&amp;#34;: &amp;#34;aaaa&amp;#34;, &amp;#34;saveDefinitionLocation&amp;#34;: &amp;#34;s3://saveDefinitionBucket/aaaa.json&amp;#34; }, &amp;#34;tables&amp;#34;: { &amp;#34;sample_data&amp;#34;: { &amp;#34;columns&amp;#34;: { &amp;#34;user_id&amp;#34;: &amp;#34;int&amp;#34;, &amp;#34;value&amp;#34;: { &amp;#34;score&amp;#34;: &amp;#34;int&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;string&amp;#34; } /* &amp;#34;struct&amp;lt;score:int,category:string&amp;gt;&amp;#34; のように書くこともできる */ }, &amp;#34;srcLocation&amp;#34;: &amp;#34;s3://src/location/&amp;#34;, &amp;#34;partition&amp;#34;: { &amp;#34;prePartitionLocation&amp;#34;: &amp;#34;s3://pre/partition/&amp;#34;, /* optional */ &amp;#34;regexp&amp;#34;: &amp;#34;(\\d{4})/(\\d{2})/(\\d{2})/&amp;#34;, /* optional */ &amp;#34;keys&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;dt&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;{1}-{2}-{3}&amp;#34;, /* optional */ } ] } } } } 使い方はこんな感じ。使い方によってはmigrate()だけ呼ぶこともあると思う。 replaceObjects()にはmatchedHandlerというのを渡すこともできて、 UTCからJSTに変換するといったこともできる。</description>
    </item>
    
    <item>
      <title>ApexでデプロイしたLambdaのトリガーをTerraformで管理する</title>
      <link>https://www.sambaiz.net/article/144/</link>
      <pubDate>Sun, 12 Nov 2017 22:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/144/</guid>
      <description>Apexでfunctionをデプロイするとトリガーが登録されないのであとで追加することになる。 これを手作業で行うこともできるのだが、せっかくなのでアプリケーションと一緒に管理したい。 そんなときのためにterraformコマンドをラップしたapex infraが用意されている。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
functionsと同列にinfrastructureディレクトリを作成してtfファイルを置く。 その下に環境ごとのディレクトリを作成することもできて、その場合は--envで指定した環境のものが使われる。
- functions - infrastructure main.tf variables.tf - modules - cloudwatch_schedule main.tf variables.tf project.json functionをデプロイするとそのARNが変数で取れるようになる。
$ apex list --tfvars apex_function_hello=&amp;#34;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;#34; 今回設定するトリガーはCloudwatch Eventのスケジューリング。作成するリソースは以下の通り。
 aws_cloudwatch_event_ruleでイベントルール(今回はschedule)を作成 aws_cloudwatch_event_targetでルールにターゲット(今回はLambda)を設定 aws_lambda_permissionでルールに対象Lambdaをinvokeする権限を付ける  $ cat infrastructure/modules/cloudwatch_schefule/variables.tf variable &amp;#34;lambda_function_name&amp;#34; {} variable &amp;#34;lambda_function_arn&amp;#34; {} variable &amp;#34;schedule_expression&amp;#34; { description = &amp;#34;cloudwatch schedule expression e.g. \&amp;#34;cron(0/5 * * * ? *)\&amp;#34;&amp;#34; } $ cat infrastructure/modules/cloudwatch_schefule/main.tf resource &amp;#34;aws_cloudwatch_event_rule&amp;#34; &amp;#34;lambda&amp;#34; { name = &amp;#34;lambda_rule_${var.lambda_function_name}&amp;#34; description = &amp;#34;invoke lambda ${var.</description>
    </item>
    
    <item>
      <title>JavaScriptのrequire/importの歴史</title>
      <link>https://www.sambaiz.net/article/143/</link>
      <pubDate>Sat, 11 Nov 2017 20:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/143/</guid>
      <description>scriptタグを並べる &amp;lt;body&amp;gt; &amp;lt;script src=&amp;#34;a.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script src=&amp;#34;b.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; 先に書かれたa.jsで定義された内容はb.jsで読むことができる。
$ cat a.js const a = &amp;#39;a is defined&amp;#39;; const divA = document.createElement(&amp;#39;div&amp;#39;); divA.textContent = (typeof b !== &amp;#39;undefined&amp;#39;) ? b : &amp;#39;b is undefined&amp;#39;; document.body.appendChild(divA); $ cat b.js const b = &amp;#39;b is defined&amp;#39;; const divB = document.createElement(&amp;#39;div&amp;#39;); divB.textContent = (typeof a !== &amp;#39;undefined&amp;#39;) ? a : &amp;#39;a is undefined&amp;#39;; document.body.appendChild(divB); 依存が増えてくると順番を考えるのが大変。さらにグローバルな名前空間を汚染してしまう。
b is undefined a is defined AMDとCommonJS というのも、かつてのJSにはモジュールを読み込む仕組みがなかった。 そこで考えられたのがAMDやCommonJSというフォーマット。 AMD(Asynchronous module definition)はRequireJSによって提供されるrequire()で動的にscriptタグを埋める。CommonJSはNodeでもおなじみのrequire()で、これにWebpackを通して一つのファイルにまとめておく。同じ関数名が使われているが全くの別物。</description>
    </item>
    
    <item>
      <title>圧縮アルゴリズムZopfliとBrotli</title>
      <link>https://www.sambaiz.net/article/142/</link>
      <pubDate>Fri, 03 Nov 2017 15:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/142/</guid>
      <description>どちらもGoogleが開発した圧縮アルゴリズム。
puppetter-lambda-starter-kit のissueに 現在使っているgzipと、Zopfli、Brotliを比較したデータが上がっていたので調べてみた。
Zopfli 出力としてDeflateに対応している。
Deflate LZ77(実際は改良版のLZSS)とハフマン記号による可逆圧縮アルゴリズム。 zip、zlib、gzip、pngなどで使われていて、これらはヘッダーやフッターが異なる。 LZSSはバイト列を見ていって同じ部分を発見したらそこを参照するように置き換えていく。
a b c a b c a b c d d d =&amp;gt; a b c (距離3, 長さ6) d (距離１, 長さ2) このLZSSにあたる部分をZopfliはがんばってやるので圧縮時間が結構かかるがサイズは小さくなるらしい。 展開は通常のDeflate通り。上げてくれたデータを見ても大体そんな感じだ。
$ git clone https://github.com/google/zopfli $ cd zopfli $ make zopfli $ ./zopfli aaaa Brotli LZ77、ハフマン記号に加えて2nd order context modelingというのを使って圧縮する Deflateではない可逆圧縮アルゴリズム。 Safari以外のモダンなブラウザで既に対応しているか対応しているところ。 対応している場合、Accept-EncodingやContent-Encodingヘッダに含まれるのはbr。 圧縮率も展開時間もかなり良さそう。
Nodeにもblotliのライブラリがあって、 圧縮はEmscriptenで本家のC++コードから変換し、 展開は手で移植しているようだ。
$ npm install blotli const fs = require(&amp;#39;fs&amp;#39;); const brotli = require(&amp;#39;brotli&amp;#39;); const TARGET = process.</description>
    </item>
    
    <item>
      <title>Redashでデータを可視化する</title>
      <link>https://www.sambaiz.net/article/141/</link>
      <pubDate>Mon, 23 Oct 2017 23:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/141/</guid>
      <description>RedashはOSSのデータ可視化ツール。 BIツールのようにパラメータを変えながら指標を探っていくというよりは、分かっている指標を見るのに使うイメージ。 比較的機能が少ない分処理がわかりやすく、 クエリが自動生成されないため時間がかかるものを実行する前にある程度気づけるのが良いと思う。
docker-composeで立ち上げることもできるが、 AWSの各リージョンにAMIが用意されているのでそれで立ち上げる。
sshで入って以下のようなのを必要に応じて設定する。 メールを送る場合はSESでメールアドレスをVerifyしてやるのが簡単。 GSuiteを使っている場合、OAuthのClientID、Secretを発行しドメインを登録するとそれで認証できる。
$ ssh ubuntu@***** $ sudo vi /opt/redash/.env export REDASH_MAIL_SERVER=&amp;#34;email-smtp.us-east-1.amazonaws.com&amp;#34; export REDASH_MAIL_USE_TLS=&amp;#34;true&amp;#34; export REDASH_MAIL_USERNAME=&amp;#34;*****&amp;#34; export REDASH_MAIL_PASSWORD=&amp;#34;*****&amp;#34; export REDASH_MAIL_DEFAULT_SENDER=&amp;#34;*****&amp;#34; # Email address to send from export REDASH_GOOGLE_CLIENT_ID=&amp;#34;&amp;#34; export REDASH_GOOGLE_CLIENT_SECRET=&amp;#34;&amp;#34; $ cd /opt/redash/current $ sudo -u redash bin/run ./manage.py org set_google_apps_domains {{domains}} $ sudo supervisorctl restart all HTTPS対応するのに/etc/nginx/sites-available/redashを編集する。crtとkeyの場所は変える。
upstream rd_servers { server 127.0.0.1:5000; } server { server_tokens off; listen 80 default; access_log /var/log/nginx/rd.access.log; gzip on; gzip_types *; gzip_proxied any; location /ping { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://rd_servers; } location / { return 301 https://$host$request_uri; } } server { listen 443 ssl; # Make sure to set paths to your certificate .</description>
    </item>
    
    <item>
      <title>ApexでLambdaをデプロイする</title>
      <link>https://www.sambaiz.net/article/140/</link>
      <pubDate>Sun, 22 Oct 2017 16:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/140/</guid>
      <description>ApexでLambdaをデプロイする。 とても簡単に使えるし、変なこともしないので良い感じ。
 Serverless Frameworkだとeventの設定までカバーできてより便利。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
 インストール。ダウンロードして実行できるようにしている。
$ curl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh  IAMFullAccess AWSLambdaFullAccess  を付けたIAMのプロファイルを登録しておく。
$ aws configure --profile apex $ aws configure list --profile apex Name Value Type Location ---- ----- ---- -------- profile apex manual --profile access_key ****************OVGQ shared-credentials-file secret_key ****************oi5t shared-credentials-file region ap-northeast-1 config-file ~/.aws/config apex initしてnameとdescriptionを入れるとIAMが登録され、 ディレクトリ構造が作られる。
$ apex init --profile apex Project name: try-apex Project description: test [+] creating IAM try-apex_lambda_function role [+] creating IAM try-apex_lambda_logs policy [+] attaching policy to lambda_function role.</description>
    </item>
    
    <item>
      <title>Node.jsのコードをPrettierでフォーマットしてESLintにかける</title>
      <link>https://www.sambaiz.net/article/139/</link>
      <pubDate>Thu, 19 Oct 2017 00:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/139/</guid>
      <description>PrettierはJSやTSのコードフォーマッタで、 ReactやBabel、Yarnなどの開発にも使われている。
今回はPrettierでフォーマットしたものを eslint --fixするprettier-eslint-cliを使う。役割が被っているがPrettierはeslint --fixよりも強力にフォーマットしてくれるようだ。
$ git init $ yarn add --dev eslint eslint-config-google prettier-eslint-cli husky lint-staged $ cat .eslintrc.js module.exports = { &amp;#34;extends&amp;#34;: &amp;#34;google&amp;#34;, &amp;#34;parserOptions&amp;#34;: { &amp;#34;ecmaVersion&amp;#34;: 2017, } }; 対象のコードはこれ。
$ cat src/main.js /** * hoge function */ function hoge() { const f = (aaaaaaaaaaaaaaa, bbbbbbbbbb, ccccccccc, dddddddddddd, eeeeeeeeeeeeee) =&amp;gt; console.log(&amp;#39;a&amp;#39;); f(1, 2, 3, 4, 5); } hoge(); Prettierのドキュメントでも紹介されているようにlint-stagedを使うとCommit時にフォーマットし、Lintをかけることができる。
{ &amp;#34;scripts&amp;#34;: { &amp;#34;precommit&amp;#34;: &amp;#34;lint-staged&amp;#34;, &amp;#34;lint&amp;#34;: &amp;#34;eslint src&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;prettier-eslint --write \&amp;#34;src/**/*.</description>
    </item>
    
    <item>
      <title>確率分布(二項分布/ポアソン分布/正規分布/t分布/カイ二乗分布)</title>
      <link>https://www.sambaiz.net/article/138/</link>
      <pubDate>Sun, 15 Oct 2017 01:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/138/</guid>
      <description>二項分布 確率\(p\)で起きる事象が\(n\)回の試行で\(x\)回起きる確率関数の離散的確率分布\(B[n,p]\)。 期待値は\(np\)で、分散は\(np(1-p)\)。
$$ f(x) = {}_nC_x p^x (1-p)^{n-x} \quad (0 \leqq x \leqq n) $$
 ポアソン分布 試行回数\(n\)が多いと二項分布の\({}_nC_x\)の部分の計算が困難になってしまうが、もし\(p\)が小さければ代わりにポアソン分布で近似することができる。 \(n = 50\)ぐらいのとき\(np \leqq 5\)以下が目安。期待値も分散も\(np=\mu\)。
$$ f(x) = \lim_{n \to \infty, p \to 0} {}_nC_x p^x (1-p)^{n-x} = \frac{\mu^x}{x!}e^{-\mu} $$
 正規分布 正規分布は平均値\(\mu\)を最大値とし、左右対称な釣鐘型をしている連続的確率分布\(N[μ,\sigma^2]\)。 二項分布の\(n\)を大きくしていくと正規分布に近づいていき、\(p = 0.5\)であれば、\(n = 10\)の二項分布\(B[10,0.5]\)でも\(N[5,2.5]\)の良い近似が得られる。逆に\(n\)が大きな二項分布の近似として正規分布を用いることもできる。
$$ f(x) = \frac{1}{\sqrt{2\pi}\sigma} \exp(-\frac{(x-\mu)^2}{2\sigma^2}) $$
 \(N[0,1]\)を標準正規分布と呼び、非標準分布に従う確率変数\(x\)を、標準正規分布に従う\(z\)に変換することを標準化変換という。
$$ z = \frac{x - \mu}{\sigma} $$
標準正規分布だと確率変数が\(z\)よりも小さくなる確率
$$ \int_{-\infty}^{z} f(x) dx $$
の値をまとめた正規分布表を用いて信頼区間を求めることができるようになる。
また、母平均\(μ\)、母分散\(\sigma^2\)の任意な分布から\(n\)個の標本をとったときの平均\(\bar{X}\)は\(N[\mu, \frac{\sigma^2}{n}]\)に従う。言い換えれば、標本平均と母平均の誤差は\(N[0, \frac{\sigma^2}{n}]\)となる。これを中心極限定理という。 この分布の分散の平方根\(\frac{\sigma}{\sqrt{n}}\)を標準誤差(SE)と呼ぶ。この分布を標準化変換すると次のようになる。</description>
    </item>
    
    <item>
      <title>Lpノルムと正則化</title>
      <link>https://www.sambaiz.net/article/137/</link>
      <pubDate>Thu, 12 Oct 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/137/</guid>
      <description>ノルムとは ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。
 p(av) = |a| p(v): スケーラブル p(u + v) ≦ p(u) + p(v): 三角不等式を満たす p(v) ≧ 0: 負の値を取らない p(v) = 0 &amp;lt;=&amp;gt; v=0: 距離が0 &amp;lt;=&amp;gt; 零ベクトル  以下の式で表されるノルムをLpノルムと呼ぶ。
L1ノルム(マンハッタン距離) 絶対値の和。座標軸方向にしか移動できない縛りでの距離。 StreetとAvenueが格子状になっているマンハッタンではタクシーが移動する距離はL1ノルムのようになる。
L2ノルム(ユークリッド距離) 2乗の和の平方根。普通の距離。
正則化(regularization) 機械学習で過学習を防ぐためのもの。 Lp正則化は重みのLpノルムをp乗してハイパーパラメータΛを掛けたものを正則化項として 素の損失関数に加える。これを最小化するのだから重みがペナルティとしてはたらく。 L1正則化ではΛが大きければいくつかの重みが0になって次元削減できるが、 L2正則化では重みに比例して小さくなるだけ。それぞれLasso回帰、Ridge回帰ともいう。 また、これらを割合で足して使うElasticNetというものもある。
参考 Norm (mathematics) - Wikipedia
RでL1 / L2正則化を実践する - 六本木で働くデータサイエンティストのブログ</description>
    </item>
    
    <item>
      <title>OpenID ConnectのIDトークンの内容と検証</title>
      <link>https://www.sambaiz.net/article/136/</link>
      <pubDate>Mon, 09 Oct 2017 20:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/136/</guid>
      <description>OpenID Connectは認可(AuthoriZation)のプロトコルであるOAuth 2.0を正しく認証(AutheNtication)に使うためのプロトコル。
OpenID Connect Core 1.0(日本語訳)
OAuth2.0のメモ - sambaiz-net
OpenID ConnectではOAuthのアクセストークンに加えて Issuer(IdP)によって署名されたJWT(JSON Web Token)形式のIDトークンも返す。 このIDトークンの署名を検証し、含まれるIssuerとクライアントの情報を参照することで OAuthのImplicit flowでのトークン置き換え攻撃を防ぐことができる。
JWT/IDトークン JWTはRFC7519で定義されている、 パーティ間で安全にClaim(エンドユーザーのようなエンティティの情報)を受け渡すための表現方法。 JSONにエンコードしたClaimは、JOSE(Javascript Object Signing and Encryption)のサブセットであるJWS(JSON Web Signature)のペイロードとして署名を付与されるか、JWE(JSON Web Encryption)で暗号化される。 以下のJWTはJWSのもの。
JWSには(ヘッダ).(ペイロード).(署名)の文字列で表現されるCompact SerializationとJSONで表現されるJSON Serializationがあるが、JWTではCompact Serializationを使う。
ヘッダには署名に使うアルゴリズムalgが含まれる。 JWTを受け取った際、不正なalgになっていないかチェックする必要がある。
{ &amp;#34;alg&amp;#34;: &amp;#34;RS256&amp;#34;, &amp;#34;kid&amp;#34;: &amp;#34;5b0924f6f83c719514987954cf66683b370677d4&amp;#34; } ペイロードには以下のようなClaimが含まれる。これ以外のClaimを含めることもできる。
{ &amp;#34;iss&amp;#34;: &amp;#34;https://server.example.com&amp;#34;, # IssuerのIdentifier。httpsのURL &amp;#34;sub&amp;#34;: &amp;#34;24400320&amp;#34;, # Subject Identifier。Issuerでユニークなエンドユーザーの識別子。 &amp;#34;aud&amp;#34;: &amp;#34;s6BhdRkqt3&amp;#34;, # audience。OAuth2.0のclient_id &amp;#34;nonce&amp;#34;: &amp;#34;n-0S6_WzA2Mj&amp;#34;, # リクエストで送ったのがそのまま返ってくる。リプレイ攻撃を防ぐため &amp;#34;exp&amp;#34;: 1311281970, # IDトークンの有効期限。時間はすべてUNIXエポック秒 &amp;#34;iat&amp;#34;: 1311280970, # IDトークンの発行時刻 &amp;#34;auth_time&amp;#34;: 1311280969 # エンドユーザーの認証時刻 } IDトークンを取得する GoogleのOAuth 2.</description>
    </item>
    
    <item>
      <title>RSA暗号とPEM/DERの構造</title>
      <link>https://www.sambaiz.net/article/135/</link>
      <pubDate>Sun, 01 Oct 2017 21:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/135/</guid>
      <description>RSA暗号とは  暗号化: c ≡ m^e (mod n) 複合: m ≡ c^d (mod n)  公開鍵がe,nで秘密鍵がd。nはとても大きく近くない素数p,qの積で、 これを公開しても素因数分解できないのがこの暗号の前提になっている。 768bit(10進数で232桁)では既に解読されているので、少なくとも1024bit以上にする。
eはEuler totient function(1~nまでの整数でnと互いに素なものの個数。今回の場合はφ(n)=(p-1)(q-1))未満で互いに素な正の整数で、小さすぎても大きすぎてもだめ。2^16 + 1 = 65537がよく使われる。
dはed ≡ 1 (mod φ(n))を満たすd。
例 例として(p,q)=(193,709)とするとこんな感じ。
 n = p * q = 136837 φ(n) = (p-1)(q-1) = 135936 e = 65537 &amp;lt; φ(n)  秘密鍵dは65537*d ≡ 1 (mod 135936)の式を変形した 65537*d - 135936*x = gcd(65537,135936) = 1を、拡張されたユークリッドの互除法で解く。 以下のように135936と65537を残しながら展開していく。
135936 = 65537 * 2 + 4862 =&amp;gt; 4862 = 135936 * 1 + 65537 * -2 65537 = 4862 * 13 + 2331 =&amp;gt; 2331 = 65537 - (135936 * 1 + 65537 * -2) * 13 = 135936 * -13 + 65537 * 27 4862 = 2331 * 2 + 200 =&amp;gt; 200 = (135936 * 1 + 65537 * -2) - (135936 * -13 + 65537 * 27) * 2 = 135936 * 27 + 65537 * -56 2331 = 200 * 11 + 131 =&amp;gt; 131 = (135936 * -13 + 65537 * 27) - (135936 * 27 + 65537 * -56) * 11 = 135936 * -310 + 65537 * 643 .</description>
    </item>
    
    <item>
      <title>自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数</title>
      <link>https://www.sambaiz.net/article/134/</link>
      <pubDate>Mon, 25 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/134/</guid>
      <description>自己情報量 P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。
log(P)+log(Q)=log(P*Q)より加法性がある。 例えば、サイコロで1の目が2回連続で出る(P=1/36)情報量(5.16bits)はサイコロで1の目が出る(P=1/6)情報量(2.58bits)の2倍と等しい。 確率が高ければ高いほど自己情報量は小さくなり、P(ω)=1では0bitになる。
エントロピー 確率分布Pに従う確率変数Xのエントロピーは以下の式で定義される。情報量の平均。
これは情報を送る際に必要なビット数の平均の下限になっている。 例えば、Xが1~4の値を(0.8, 0.1, 0.06, 0.04)の確率でとるとする。 4通りなのだからそれぞれ2bits(00, 01, 10, 11)のコードで表すこともできるが、 ほとんど3や4は出ないのだからbit数を偏らせて(0, 10, 110, 111)のコードで表すと 0.8*1 + 0.1*2 + 0.06*3 + 0.04*3 = 1.3bitsまで減らすことができる。 この場合のエントロピーは1.01bitsで、これより小さくすることはできない。
カルバック・ライブラー情報量 離散確率分布PのQに対するカルバック・ライブラー情報量は以下の式で定義される。連続確率分布では積分する。 Qの自己情報量からPの自己情報量を引いて平均を取ったもので、分布間の距離のように考えることができる。非負の値を取る。
交差エントロピー 離散確率分布PとQの交差エントロピーは以下の式で定義される。連続確率分布では積分する。 PのエントロピーにPのQに対するKL情報量を足したもの。
これはQの分布に最適化されたコードでPの分布の確率変数の情報を送ってしまった際に必要なビット数の平均の下限になっている。KL情報量が余分な分。機械学習の損失関数に使われる。
ロジスティック回帰と尤度関数/交差エントロピー誤差と勾配降下法 - sambaiz-net
参考 Self-information - Wikipedia
Kullback–Leibler divergence - Wikipedia
情報理論を視覚的に理解する (3/4) | コンピュータサイエンス | POSTD</description>
    </item>
    
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>活性化関数というのは各層での重み掛けバイアス足しのあとに適用する非線形の関数。 これはカーネル法のように空間を変換して線形分離できないデータを線形分離できるようにするはたらきをする。 線形な関数を使うと層を重ねても結局線形のままで、空間もそのまま伸縮するだけなので目的を果たさない。
バックプロバゲーション(誤差逆伝播法)するために微分できる必要がある。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
Tensorflowでは以下の活性化関数が用意されている。
sigmoid 値域は(0,1)でシグマの語末系ςに似たS字を描く。 微分係数がそれほど大きくないので何層もこの関数を適用すると、バックプロバゲーションで微分係数を掛けていった結果、勾配が消失する問題がありあまり使われない。値域が(-1,1)で似たグラフを描くtanh(Hyperbolic tangent)もある。
softsign tanhと比べて漸近線に近づく速度が遅くなっている。 それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。
softplus ReLUに続く。
ReLU(Rectified Linear Unit) 単純だが最有力。勾配消失も起きにくい。x=0で微分できないが0か1として扱われる。
def deriv_relu(x): return np.where(x &amp;gt; 0, 1, 0) softplusと比べてexpやlogを含まない分高速に計算できるので、 膨大で複雑なデータセットに対して多くの層を用いることができる。
0以下は等しく0になるため、学習中に落ちてしまうとニューロンが死んでしまう。 これを避けるため0以下のときy = exp(x) - 1にするELU(Exponential Linear Unit) というのもある。
比較的起きにくいとはいえ、層を深くすると勾配消失する可能性は高まる。 活性化関数ごとに異なる重みの初期値によってこれを緩和でき、ReLUでは入力次元数によるHe Initializationというのが提案されている。
rng = np.random.RandomState(1234) n_in = 10 # 入力次元数 rng.uniform( low=-np.sqrt(6/n_in), high=+np.sqrt(6/n_in), size=5 ) # He Initialization 参考 Activation functions and it’s types-Which is better?
最適化から見たディープラーニングの考え方
Understanding the difficulty of training deep feedforward neural networks</description>
    </item>
    
    <item>
      <title>Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った</title>
      <link>https://www.sambaiz.net/article/132/</link>
      <pubDate>Sun, 10 Sep 2017 23:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/132/</guid>
      <description>PuppeteerでHeadless Chromeを動かすコードを Lambda上で動かすStarter Kitを作った。
puppeteer-lambda-starter-kit
Chromeの準備 Puppeteerのインストール時に落としてくるChromeをLambda上で動かそうとしても Lambdaにないshared libraryに依存しているため失敗する。
error while loading shared libraries: libpangocairo-1.0.so.0: cannot open shared object file: No such file or directory Lambda上でHeadless Chromeを動かす例がないか調べたらserverless-chromeというのがあって、 Headless用の設定でChromeをビルドしていた。 ほかにはchromelessというのもあるが これはserverless-chromeに 依存している。 最小構成でPuppeteerを使いたかったので、今回はこれらを使わず一から作ることにした。
serverless-chromeにもビルドしたものが置いてあるが、少しバージョンが古いようだったので最新版でビルドした。 基本的には書いてある 通りやればうまくいく。他のプロセスとのshared memoryとして/dev/shmを使っているのを、/tmpに置き換える ようにしないと、実行時のpage.goto()でFailed Provisional Load: ***, error_code: -12になる。
ビルドしたheadless_shellには問題になった依存は含まれていないようだ。
$ ldd headless_shell linux-vdso.so.1 =&amp;gt; (0x00007ffcb6fed000) libpthread.so.0 =&amp;gt; /lib64/libpthread.so.0 (0x00007f5f17dbe000) libdl.so.2 =&amp;gt; /lib64/libdl.so.2 (0x00007f5f17bba000) librt.so.1 =&amp;gt; /lib64/librt.so.1 (0x00007f5f179b1000) libnss3.so =&amp;gt; /usr/lib64/libnss3.so (0x00007f5f17692000) libnssutil3.so =&amp;gt; /usr/lib64/libnssutil3.so (0x00007f5f17466000) libsmime3.so =&amp;gt; /usr/lib64/libsmime3.</description>
    </item>
    
    <item>
      <title>Headless Chromeでファイルをダウンロードする</title>
      <link>https://www.sambaiz.net/article/131/</link>
      <pubDate>Sun, 03 Sep 2017 18:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/131/</guid>
      <description>Chrome DevTools Protocolに ExperimentalだがPage.setDownloadBehavior というのがあったので、これを呼んでファイルをダウンロードしてみた。
今回は公式のDevToolsのNode API、Puppeteerを使うが、 setDownloadBehaviorを送るAPIはまだなく、直接clientを取ってsendするので他のライブラリでもやることは変わらないと思う。 Puppeteerのインストールの際にChromiumも入る。setDownloadBehaviorは現行Chromeの60では対応していないようだが、62が入ったのでなんとかなりそう。
$ yarn add puppeteer $ find . -name &amp;#34;*chrome*&amp;#34; ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_100_percent.pak ./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_200_percent.pak ちなみに、このChromeをLambda上で実行しようとすると失敗する。
Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った
 ChromeでChromeをダウンロードしてみる。
const puppeteer = require(&amp;#39;puppeteer&amp;#39;), fs = require(&amp;#39;fs&amp;#39;); const headless = true, downloadPath = &amp;#39;./Download&amp;#39;; (async () =&amp;gt; { const browser = await puppeteer.launch({headless: headless}); const page = await browser.newPage(); await page._client.send( &amp;#39;Page.setDownloadBehavior&amp;#39;, {behavior : &amp;#39;allow&amp;#39;, downloadPath: downloadPath} ); await page.goto(&amp;#39;https://www.google.co.jp/chrome/browser/desktop/index.html&amp;#39;, {waitUntil: &amp;#39;networkidle&amp;#39;}); await page.</description>
    </item>
    
    <item>
      <title>floatやdoubleの表現と精度</title>
      <link>https://www.sambaiz.net/article/130/</link>
      <pubDate>Sat, 02 Sep 2017 12:47:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/130/</guid>
      <description>IEEE754で標準化されている浮動小数点の仕様。
符号と指数部(exponent)と仮数部(fraction)からなるデータ構造で± (基数)^(指数部) * 1.(仮数部)の値を表現する。 以下では基数を2とする。
例えばfloat(32bits)で-5.25を表す場合、まず2進数に変換して(-101.01)、± 2^n * 1.xxxxの形になるように小数点をずらす(- 2^2 * 1.0101)。その後、指数部のレンジを1-254にするため127を足した結果、 1(-) 10000001(2+127) 01010000000000000000000(.0101)となる。
ただし、指数部が0のときは± 2^-126 * 0.(仮数部) として扱い、絶対値が極端に小さい非正規数も表すことができるようになっている。 また、指数部が255のとき、仮数部が0ならInfinity、そ例外はNaNとなる。
 精度は仮数部の大きさに依存し、floatが10進数でMath.log10(2 ** 23) = 6.92桁で、doubleがMath.log10(2 ** 52) = 15.65桁。JavaScriptの数値はdoubleなので1234567890.1234569が1234567890.123457になり16~17桁目で値がおかしくなることが確認できる。
参考 IEEE 754 - Wikipedia
Double-precision floating-point format - Wikipedia</description>
    </item>
    
    <item>
      <title>Pythonのインタラクティブな可視化ライブラリBokehでグラフを描く</title>
      <link>https://www.sambaiz.net/article/129/</link>
      <pubDate>Sat, 26 Aug 2017 18:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/129/</guid>
      <description>Pythonの可視化というとmatplotlibや、 そのラッパーのseaborn、 データ解析ライブラリのPandasにもそのような機能があるが、 これらが静止画を描画するのに対して、 BokehはD3.jsによって拡大やスクロールができるグラフを描画する。Bokehはカメラのボケ。 似たようなものにPlotlyというのもあって、 こちらはPandasと同じpydata.orgドメインでスターが多い。
jupyter/datascience-notebookイメージにもBokehがインストールされている。
$ docker run -d -p 8888:8888 jupyter/datascience-notebook start-notebook.sh 簡単なグラフを描く output_notebookでJupytor Notebokに出力する。ファイルに出力する場合はouput_fileを呼ぶ。
from bokeh.plotting import figure from bokeh.io import output_notebook, show output_notebook() figure()でplotするFigureオブジェクトを作成する。
p = figure( title=&amp;#34;Hoge&amp;#34;, x_axis_label=&amp;#39;x&amp;#39;, y_axis_label=&amp;#39;y&amp;#39;, y_axis_type=&amp;#34;log&amp;#34; ) line()で線をつないでcircle()で円を描く。
x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0] y0 = [i**2 for i in x] y1 = [10**i for i in x] y2 = [10**(i**2) for i in x] p.line(x, x, legend=&amp;#34;y=x&amp;#34;) p.</description>
    </item>
    
    <item>
      <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
      <link>https://www.sambaiz.net/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/128/</guid>
      <description>Hiveとは Hadoop上で動くデータウェアハウスソフトウェア。 SQLを拡張したHiveQLを書くとデータを処理するMapReduceやSpark、Tezのジョブが生成される。 クエリの実行に時間がかかり、耐障害性があるのでDailyやHourlyのバッチで使われる。
ちなみにAthenaにも使われているPresto はタスクを並列に実行し、中間データをメモリ上に持つことで数分以内に結果が得られるので ダッシュボードなどの用途でアドホックに使える。中間データが大きいと時間がかかったり失敗する。
Impalaはさらに速いがメモリの消費が激しいらしい。
Cloudera Docker Imageを起動する Cloudera Docker Imageには
 CDH: Clouderaのディストリビューション。Hadoop、Hive、SparkなどのOSSで構成されている。 Cloudera Manager: CDHクラスタを管理する。無料のExpressと有料のEnterpriseで使える機能に差がある。  が含まれていて、これを起動すると諸々立ち上がる。CDHクラスタを組むのはサポートされていないようなのでテスト用らしい。
$ docker pull cloudera/quickstart:latest $ docker run --hostname=quickstart.cloudera --privileged=true -itd -p 8888 -p 7180 -p 80 cloudera/quickstart /usr/bin/docker-quickstart 80がチュートリアルで、8888がHadoopのWeb UIのHue、7180がCloudera Manager。Dockerに割り当てるメモリが2GBだとFailed to contact an active Resource Managerになってしまったので4GBにした。
Hiveのテーブルを作成して実行する チュートリアルではSqoopを使ってDBから取り込んでいるんだが、 今回はjsonのログのテーブルを作成する。
$ sqoop import-all-tables \ -m 1 \ --connect jdbc:mysql://localhost:3306/retail_db \ --username=retail_dba \ --password=cloudera \ --compression-codec=snappy \ --as-parquetfile \ --warehouse-dir=/user/hive/warehouse \ --hive-import JSONを扱うにはStringからLATERAL VIEW json_tuple(json_str, &amp;quot;field1&amp;quot;, &amp;quot;field2&amp;quot;) j AS field1, field2のように実行時にパースする方法と、JSON SerDeで最初から別カラムにいれる方法があるが、今回はSerDeでやる。</description>
    </item>
    
    <item>
      <title>CloudflareでカスタムドメインのGitHub PagesにHTTPSでアクセスできるようにする</title>
      <link>https://www.sambaiz.net/article/127/</link>
      <pubDate>Mon, 21 Aug 2017 23:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/127/</guid>
      <description>このサイトはGitHub Pagesでカスタムドメインsambaiz.netを設定して、 Apex Domain(sambaiz.net)にAレコードを登録して運用していたのだけれど、これだとカスタムドメインの証明書を置けないのでHTTPSでアクセスすると警告が出てしまう。 いい加減HTTPだと許されない風潮になってきたのでCloudflareを前に挟んでHTTPSでアクセスできるようにした。 ついでにCNAMEを登録できないApex Domain(sambaiz.net)をやめてwww.sambaiz.netに向ける。
DNSの設定をする Cloudflareでドメインを入れると既存のDNS Recordsを読み込むので必要に応じて修正する。 CloudflareではCNAME FlatteningによってApex Domainにも設定上ではCNAMEを与えることができ、内部でAレコードに解決してくれる。 そのためApex Domainをそのまま使っても実は問題ないのだが、今後のために変えておく。 www.sambaiz.netにGitHub PagesのCNAMEを設定し、sambaiz.net(@)にはwww.sambaiz.netをCNAMEとして設定した。
あとGitHub Pagesの方のカスタムドメインもwww.sambaiz.netにした。 wwwを設定するとApex Domainでアクセスしたときにリダイレクトするようになっているので 既存のリンクが切れたり混在することはない。
指示された*.ns.cloudflare.comのようなCloudflareのネームサーバーをドメインに設定する。 さくらの場合、Apex Domainのネームサーバーはゾーン表示ではなくWHOIS情報のところから変更できる。 設定してしばらくするとCloudflareを通してアクセスが飛び警告なくHTTPSでアクセスできるようになる。 証明書は共有のものになっている。
正常にアクセスできることを確認できたら今HTTPになっている画像やリンクもHTTPSにする。
$ find . -name &amp;#39;.git*&amp;#39; -prune -o -name &amp;#39;public&amp;#39; -prune -o -name &amp;#39;static&amp;#39; -prune -o -type d -o -print | xargs sed -i &amp;#34;&amp;#34; &amp;#34;s/http:\/\/sambaiz.net/https:\/\/www.sambaiz.net/g&amp;#34; Cloudflareの機能 Cloudflareにはいくつかプランがあって、今回はFreeプランにした。
Analytics  キャッシュされている/ないリクエスト数や帯域、それによる節約量 ブロックした脅威の数 何人/どこの国からアクセスが来たか コンテンツ(HTML/CSS/PNG)ごとのリクエストの割合  などがわかる。FreeだとWeb TrafficやGeographyが直近24時間より短いスパンで取れない。
Crypto SSLまわりの設定。
 Flexible: クライアントとCloudflareはHTTPS、CloudflareとオリジンサーバーはHTTPで通信する。 Full: デフォルト。Cloudflareとオリジンサーバーの通信もHTTPSで行うが、証明書の検証は行われない。 Full(Strict) 証明書の検証も行う。  から選択する。Business以上のPlanだと共有の証明書ではなく独自のものを上げることもできる。</description>
    </item>
    
    <item>
      <title>HDFS(Hadoop Distributed File System)とは</title>
      <link>https://www.sambaiz.net/article/126/</link>
      <pubDate>Mon, 14 Aug 2017 22:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/126/</guid>
      <description>HDFSとは Hadoopの分散ファイルシステム。 Hadoopの抽象化されたファイルシステム実装の一つで、他の実装にはLocal fileやS3などがある。 データのサイズが大きい場合に特に問題になるディスクI/Oを分散させ、 読み書きする最小の単位であるブロックサイズを大きくしシークのコストを減らすことで スループットを高めている。 ディスクI/Oがどれくらい遅いかというと、 シークがデータセンター内での往復の通信の20倍(10ms)、 1MBの読み込みが40倍の時間(20ms)かかる。
一方、小さなデータに低レイテンシでアクセスするというのは得意でなく、 また、1ファイルあたり150バイトのメタデータがNameNodeのメモリ上に乗っかるため大量のファイルを扱うのは大変。 あとデータは追記しかできない。
NameNodeとDataNode クラスタの中にはおおよそ2種類のノードがあって、 ブロックがあるいくらかのDataNodeと、
 ファイルの階層とメタデータ どのDataNodeにそのファイルのブロックがあるか  の情報が含まれる
 fsimage(メタデータのスナップショット) edit log(fsimageに含まれていない変更ログ)  を保存する、名前空間に単一のNameNodeがある。 もう一つSecondary NameNodeというのがあって、これはedit logが大きくならないよう 定期的にedit logをfsimageにマージするもの。
NameNodeが機能停止すると読み書きできなくなってしまうので、 新しいNameNodeを立てる必要がある。 その際fsimageにedit logを適用して状態を復元するため これらのファイルを別のファイルシステムにバックアップなどして失われないようにする。
巨大なクラスタだとNameNodeを立ち上げるのに30分以上かかることもあるため、 Secondary NameNodeの代わりにStandby NameNodeを立ててHigh Availabilityにすることもできる。 Standby NameNodeはNameNodeと共有ストレージでedit logを共有し、最新の状態がメモリ上に乗っているので NameNodeが死んだと判断されてから数十秒ほどで切り替えることができる。
書き込みと読み込み 書き込み ファイルシステムがNameNodeとやりとりして、ファイルが存在しているか、パーミッションがあるかを確認し、問題なければFSDataOutputStreamをクライアントに返す。 書き込むデータはdata queueにまず入って、 どのDataNodeに書き込むかはDataStreamerというのがNameNodeとやりとりして決める。 レプリカの設定数分DataNodeが選ばれ、順に書き込まれるようDataNode間でパイプラインを作る。 正常に書き込まれたDetaNodeからはack packetが返ってくるのでこれはack queryに入れて 全て正しく書き込まれたことが確認できたら消す。 失敗したDataNodeがあったら、そこに中途半端に書き込まれた分を復活したら消すようにして、パイプラインから除き 新しいパイプラインを作る。
読み込み ファイルシステムがNameNodeにファイルのブロックがどこにあるかを聞く。 NameNodeは、ブロックがあるDataNodeをクライアントからネットワークトポロジ的に近い順にソートしてアドレスを返す。 ファイルシステムはそのアドレスが含まれたFSDataInputStreamをクライアントに返して、クライアントが順にreadしていく。
SingleNode Clusterで動かす $ yum --enablerepo=epel -y install pdsh $ echo $JAVA_HOME /usr/lib/jvm/jre $ wget http://ftp.</description>
    </item>
    
    <item>
      <title>PythonのLintとFormatter</title>
      <link>https://www.sambaiz.net/article/125/</link>
      <pubDate>Fri, 11 Aug 2017 14:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/125/</guid>
      <description>YAPF スタイルに沿って整形してくれる、Goでいうgo fmtみたいなもの。 デフォルトはPython公式のスタイルガイドPEP8でフォーマットされる。
$ pip install yapf VSCodeでPythonを書くときは、 Pythonプラグイン を入れてこんな設定をWorkspaceのconfigに入れておいて、 保存した時にフォーマットがかかるようにすると快適。
&amp;#34;editor.formatOnSave&amp;#34;: true, &amp;#34;python.formatting.provider&amp;#34;: &amp;#34;yapf&amp;#34; setup.cfgに次のような項目を追加しスタイルを設定する。
[yapf] based_on_style = google column_limit = 120 indent_width = 2 Lint YAPFでフォーマットされた以下のコードにLintをかける。
class FizzBuzz: def __init__(self, start=0): self.num = start def __iter__(self): return self def __next__(self): self.num += 1 if self.num % 15 == 0: return &amp;#34;FizzBuzz&amp;#34; if self.num % 3 == 0: return &amp;#34;Fizz&amp;#34; if self.num % 5 == 0: return &amp;#34;Buzz&amp;#34; return self.</description>
    </item>
    
    <item>
      <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
      <link>https://www.sambaiz.net/article/124/</link>
      <pubDate>Sun, 06 Aug 2017 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/124/</guid>
      <description>AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリSonnetを使う。 当初はPython2しか対応していないようだったが、今は3にも対応している。
準備 TensorFlowを使うライブラリはほかにもいくつかあるのだが、 Kerasと比較してみると、 KerasがTensorFlowの部分を完全にラップしているのに対して、 Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。
SonnetとTensorFlowとPython3入りイメージをDockerHubに上げた。 Dockerfileはここ。
内容は基本的にREADME通りだが、 configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。 あとは、TensorFlowのビルドに使われているGCCのバージョンが古いようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;を付けている。
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_ 起動。
$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet $ docker logs sonnet ... Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=***** Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。
import sonnet as snt import tensorflow as tf snt.resampler(tf.constant([0.]), tf.constant([0.])) # =&amp;gt; &amp;lt;tf.Tensor &amp;#39;resampler/Resampler:0&amp;#39; shape=(1,) dtype=float32&amp;gt; MNIST TensorFlowのチュートリアルのデータを使って、畳み込みを行わない簡単なMNISTをやってみる。 このデータはtrain、validation、test用に最初から分かれていて、 それぞれピクセル濃度配列の画像データと、その画像がどの数字なのかを表すone-hot vectorのラベルを含んでいる。</description>
    </item>
    
    <item>
      <title>Node.jsをTypeScriptで書く</title>
      <link>https://www.sambaiz.net/article/123/</link>
      <pubDate>Sat, 29 Jul 2017 19:34:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/123/</guid>
      <description>公式のTypeScript-Node-Starterから始めてもいいが、依存が少し余分なので一から作ることにした。
コードはここ。
$ yarn add --dev typescript tslint tslint-microsoft-contrib jest ts-jest @types/jest package.json scriptsとテストフレームワークJestの設定を追加。
{ &amp;#34;devDependencies&amp;#34;: { ... &amp;#34;typescript&amp;#34;: &amp;#34;^2.4.2&amp;#34; }, &amp;#34;scripts&amp;#34;: { &amp;#34;start&amp;#34;: &amp;#34;npm run build &amp;amp;&amp;amp; node dist/app.js&amp;#34;, &amp;#34;build&amp;#34;: &amp;#34;npm run lint &amp;amp;&amp;amp; tsc&amp;#34;, &amp;#34;test&amp;#34;: &amp;#34;jest --forceExit&amp;#34;, &amp;#34;lint&amp;#34;: &amp;#34;tslint -c tslint.json -p tsconfig.json --type-check&amp;#34; }, &amp;#34;jest&amp;#34;: { &amp;#34;transform&amp;#34;: { &amp;#34;^.+\\.ts$&amp;#34;: &amp;#34;./node_modules/ts-jest/preprocessor.js&amp;#34; }, &amp;#34;testRegex&amp;#34;: &amp;#34;/test/.*\\.test\\.(ts|js)$&amp;#34;, &amp;#34;moduleFileExtensions&amp;#34;: [ &amp;#34;ts&amp;#34;, &amp;#34;js&amp;#34; ], &amp;#34;testEnvironment&amp;#34;: &amp;#34;node&amp;#34; } } tsconfig.json 公式のそのまま。
{ &amp;#34;compilerOptions&amp;#34;: { &amp;#34;module&amp;#34;: &amp;#34;commonjs&amp;#34;, &amp;#34;target&amp;#34;: &amp;#34;es6&amp;#34;, &amp;#34;noImplicitAny&amp;#34;: true, &amp;#34;moduleResolution&amp;#34;: &amp;#34;node&amp;#34;, &amp;#34;sourceMap&amp;#34;: true, &amp;#34;outDir&amp;#34;: &amp;#34;dist&amp;#34;, &amp;#34;baseUrl&amp;#34;: &amp;#34;.</description>
    </item>
    
    <item>
      <title>KubernetesのパッケージマネージャーHelmを使う</title>
      <link>https://www.sambaiz.net/article/122/</link>
      <pubDate>Wed, 26 Jul 2017 01:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/122/</guid>
      <description>Kubernatesが操舵手なのに対して、Helmは舵。 パッケージはChart(海図)と呼ばれている。
ChartにはデフォルトでGoのtemplateで書かれたManifestが含まれ、values.yamlの値を-f values.yamlや--set key=valueフラグで上書きして適用しインストールすることができる。
Helmコマンドをインストールする。 今回はminikubeに入れるので立ち上げる。
$ brew install kubernetes-helm $ helm version Client: &amp;amp;version.Version{SemVer:&amp;#34;v2.5.0&amp;#34;, GitCommit:&amp;#34;012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;} # brew cask install virtualbox minikube $ minikube version minikube version: v0.20.0 $ minikube start Kubectl is now configured to use the cluster. $ kubectl version Client Version: version.Info{Major:&amp;#34;1&amp;#34;, Minor:&amp;#34;7&amp;#34;, GitVersion:&amp;#34;v1.7.2&amp;#34;, GitCommit:&amp;#34;922a86cfcd65915a9b2f69f3f193b8907d741d9c&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;, BuildDate:&amp;#34;2017-07-21T19:06:19Z&amp;#34;, GoVersion:&amp;#34;go1.8.3&amp;#34;, Compiler:&amp;#34;gc&amp;#34;, Platform:&amp;#34;darwin/amd64&amp;#34;} Server Version: version.Info{Major:&amp;#34;1&amp;#34;, Minor:&amp;#34;6&amp;#34;, GitVersion:&amp;#34;v1.6.4&amp;#34;, GitCommit:&amp;#34;d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae&amp;#34;, GitTreeState:&amp;#34;dirty&amp;#34;, BuildDate:&amp;#34;2017-06-22T04:31:09Z&amp;#34;, GoVersion:&amp;#34;go1.7.5&amp;#34;, Compiler:&amp;#34;gc&amp;#34;, Platform:&amp;#34;linux/amd64&amp;#34;} $ kubectl config current-context minikube まずk8sクラスタ上にHelmの管理サーバーTillerをインストールする必要がある。</description>
    </item>
    
    <item>
      <title>TerraformでVPCを管理するmoduleを作る</title>
      <link>https://www.sambaiz.net/article/121/</link>
      <pubDate>Sun, 23 Jul 2017 02:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/121/</guid>
      <description>Terraform
$ brew install terraform $ terraform -v Terraform v0.9.11 Terraformの設定要素 provider IaaS(e.g. AWS)、PaaS(e.g. Heroku)、SaaS(e.g. CloudFlare)など。
AWS Providerはこんな感じ。 ここに直接access_keyやsecret_keyを書くこともできるが、誤って公開されてしまわないように環境変数か variableで渡す。
provider &amp;#34;aws&amp;#34; {# access_key = &amp;#34;${var.access_key}&amp;#34; # secret_key = &amp;#34;${var.secret_key}&amp;#34;  region = &amp;#34;us-east-1&amp;#34; } $ export AWS_ACCESS_KEY_ID=&amp;#34;anaccesskey&amp;#34; $ export AWS_SECRET_ACCESS_KEY=&amp;#34;asecretkey&amp;#34; varibale CLIでオーバーライドできるパラメーター。typeにはstringのほかにmapやlistを渡すことができ、 何も渡さないとdefault値のものが、それもなければstringになる。
variable &amp;#34;key&amp;#34; { type = &amp;#34;string&amp;#34; default = &amp;#34;value&amp;#34; description = &amp;#34;description&amp;#34; } 値を渡す方法はTF_VAR_をprefixとする環境変数、-var、-var-fileがある。 また、moduleのinputとして渡されることもある。
$ export TF_VAR_somelist=&amp;#39;[&amp;#34;ami-abc123&amp;#34;, &amp;#34;ami-bcd234&amp;#34;]&amp;#39; $ terraform apply -var foo=bar -var foo=baz $ terraform apply -var-file=foo.</description>
    </item>
    
    <item>
      <title>HoloLensでのUnityアプリケーションのフレームレート</title>
      <link>https://www.sambaiz.net/article/120/</link>
      <pubDate>Sun, 16 Jul 2017 23:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/120/</guid>
      <description>HoloLensディスプレイのフレームレート HoloLensのディスプレイは60fpsでリフレッシュされるので、アプリケーションもこれに合わせて60fps、 つまり16msごとにOSにイメージを渡せるのがベスト。 ただし、安定して60fpsが実現できないような重いアプリケーションの場合、 変動してしまうよりは下げて安定させる方が良い。
フレームレートはDevice Portalから確認することができ、キャプチャする際は30fpsに制限される。
Unityアプリケーションのフレームレート Unityでのフレームレートは Application.targetFrameRate で設定できる。デフォルト値は-1で、その場合プラットフォームごとのデフォルト設定が使われる。 何も設定しない状態でHoloLensで動かしたところ60fpsになった。
Debugビルドでのフレームレートの低下 DebugビルドだとSpace Robot Kyle だけ描画するだけでもフレームレートが20まで下がってしまった。
HoloLensで剣振ってみた - sambaiz-net
DebugビルドだったのをRelasseビルドに変えたら60fpsになった。 Relaseビルドではコードの最適化にチェックが入っていたりするんだが、 その辺りを外してみても特に変わらなかったのでそれではないらしい。</description>
    </item>
    
    <item>
      <title>HoloLensで剣振ってみた</title>
      <link>https://www.sambaiz.net/article/119/</link>
      <pubDate>Sun, 09 Jul 2017 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/119/</guid>
      <description>かつてCardboardでやったようにHoloLensでも剣を振ってみた。
剣を振るVRゲームを作った - sambaiz-net
剣を振ってロボットに当てると爆発する。
動画
剣の方は前回と同じくiOSアプリから傾きをBLEで送信している。今回は傘がなかったのでペットボトルにくくりつけた。
HoloLensのアプリの方はUWPのネイティブプラグインを作った。 Creater&amp;rsquo;s UpdateのAPIがまだ使えなかったので一つ前のAPIを使ってビルドしている。 なお、ペアリングはアプリ内ではなくOSの設定画面から行なっている。 エラーについては原因が分からずハンドリングできていないものもあるが、つなぎ直すと大抵どうにかなった。 つなぎ直す際はHoloLens側だけではなくiOS側の方の設定も削除する。
Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net
ロボットを小さくしているのは近づいても視野角に収まるようにするため。 小さいとどこにいるか分からないので目印を出したほうが良い。 近接武器じゃなきゃ敵に近づかなくてよくなるのでましになるかも。
上の動画を見れば分かるように、全体的に動きが重くて素でframerateが20ぐらいしか出ていない。 これはReleaseビルドにすると改善された。
HoloLensでのUnityアプリケーションのフレームレート - sambaiz-net</description>
    </item>
    
    <item>
      <title>HoloLensのSpartial MappingでNavMeshを生成してランダムにAgentを出現・移動させる</title>
      <link>https://www.sambaiz.net/article/118/</link>
      <pubDate>Sun, 02 Jul 2017 23:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/118/</guid>
      <description>Unity 5.6.2f1 HoloToolkit v1.5.7.0 Unity 5.6から動的にNavMeshを生成できるようになったので HoloLensのSpartial MappingしたものをNavMeshにしてAgentを動かしてみる。
Unityで動的にNavMeshを生成する - sambaiz-net
Spartial MappingしたものをNavMeshにするのは以下の記事のスクリプトを使った。
HoloLens の空間マップで NavMesh を使ってみる - たるこすの日記
Unity-Technologies/NavMeshComponentsから LocalNavMeshBuilderとNavMeshSourceTagを持ってきてLocalNavMeshBuilderのObjectを置いておき、 Spartial MappingしたものにNavMeshSourceTagを付けられればExampleと同様にNavMeshにできる。 そこで、このスクリプトではSpatialMappingSourceを取得し、イベントハンドラでNavMeshSourceTagが追加されるようにしている。
using HoloToolkit.Unity.SpatialMapping; using UnityEngine; using HoloToolkit.Unity; public class SpatialMappingNavMesh : MonoBehaviour { public GameObject SpatialMapping; private void Awake() { var spatialMappingSources = SpatialMapping.GetComponents&amp;lt;SpatialMappingSource&amp;gt;(); foreach (var source in spatialMappingSources) { source.SurfaceAdded += SpatialMappingSource_SurfaceAdded; source.SurfaceUpdated += SpatialMappingSource_SurfaceUpdated; } } private void SpatialMappingSource_SurfaceAdded(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceObject&amp;gt; e) { e.Data.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;(); } private void SpatialMappingSource_SurfaceUpdated(object sender, DataEventArgs&amp;lt;SpatialMappingSource.</description>
    </item>
    
    <item>
      <title>Unityで動的にNavMeshを生成する</title>
      <link>https://www.sambaiz.net/article/117/</link>
      <pubDate>Sat, 01 Jul 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/117/</guid>
      <description>Unity5.6から動的にNavMeshを生成できるようになった。
Unity-Technologies/NavMeshComponentsの Exampleの2_drop_blankのsceneを開く。
分断されたCubeの床と、その上に黄色いCylindarと赤いCubeがあって、 クリックしたところに黄色いCylindarが動くんだが、床がつながっていないのでそのままでは赤いCubeまではたどり着けない。 スペースを押すと目の前に板が出てくるのでこの上を渡って移動することができる。
板の上がNavMeshとして認識されている。
床のCubeと追加される板にはNavMeshSourceTag.csが付いていて、staticなm_Meshesとm_Terrainsにそれぞれ追加している。
public static List&amp;lt;MeshFilter&amp;gt; m_Meshes = new List&amp;lt;MeshFilter&amp;gt;(); public static List&amp;lt;Terrain&amp;gt; m_Terrains = new List&amp;lt;Terrain&amp;gt;(); void OnEnable() { var m = GetComponent&amp;lt;MeshFilter&amp;gt;(); if (m != null) { m_Meshes.Add(m); } var t = GetComponent&amp;lt;Terrain&amp;gt;(); if (t != null) { m_Terrains.Add(t); } } void OnDisable() { var m = GetComponent&amp;lt;MeshFilter&amp;gt;(); if (m != null) { m_Meshes.Remove(m); } var t = GetComponent&amp;lt;Terrain&amp;gt;(); if (t != null) { m_Terrains.</description>
    </item>
    
    <item>
      <title>Fluentdのout_copyのstoreのエラーは他のstoreに影響する</title>
      <link>https://www.sambaiz.net/article/116/</link>
      <pubDate>Sat, 01 Jul 2017 18:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/116/</guid>
      <description>Fluentdのout_copyプラグインは 一つのeventを複数のoutputに渡すために使われる。 ただ、複数設定した中のstoreでエラーが起きると他のstoreにも影響してしまう。
例えばこんなの。
&amp;lt;source&amp;gt; @type dummy dummy {&amp;#34;hello&amp;#34;:&amp;#34;world&amp;#34;} tag dummy rate 1 &amp;lt;/source&amp;gt; &amp;lt;match dummy&amp;gt; @type copy &amp;lt;store&amp;gt; @type stdout &amp;lt;/store&amp;gt; &amp;lt;store&amp;gt; @type file path /var/log/td-agent/dummy buffer_queue_limit 0 buffer_chunk_limit 1k &amp;lt;/store&amp;gt; &amp;lt;/match&amp;gt; fileの方でqueue size exceeds limitになるとstdoutも出力されなくなってしまう。
ちなみに一旦relabelしてもだめ。
&amp;lt;source&amp;gt; @type dummy dummy {&amp;#34;hello&amp;#34;:&amp;#34;world&amp;#34;} tag dummy rate 1 &amp;lt;/source&amp;gt; &amp;lt;match dummy&amp;gt; @type copy &amp;lt;store&amp;gt; @type stdout &amp;lt;/store&amp;gt; &amp;lt;store&amp;gt; @type relabel @label @file &amp;lt;/store&amp;gt; &amp;lt;/match&amp;gt; &amp;lt;label @file&amp;gt; &amp;lt;match dummy&amp;gt; @type file path /var/log/td-agent/dummy buffer_queue_limit 0 buffer_chunk_limit 1k &amp;lt;/match&amp;gt; &amp;lt;/label&amp;gt; ドキュメントでも紹介されている、sonots氏のout_copy_exでは storeにignore_errorを付けるとrescueするようになっているので他に巻き込まれなくなる。</description>
    </item>
    
    <item>
      <title>Unityの経路探索: NavMeshとAgentとObstacle</title>
      <link>https://www.sambaiz.net/article/115/</link>
      <pubDate>Thu, 29 Jun 2017 00:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/115/</guid>
      <description>NavMeshと経路探索 NavMeshというのはエージェントが移動できる面についてのデータ構造で、凸ポリゴンの面と位置関係を含んでいる。 経路探索は2点間を一番近いポリゴンにマッピングし、A*アルゴリズムを用いて行われる。あとからオブジェクトが追加されるなどして道を塞いでしまってもCarvingしてNavMeshに穴をあければ別の経路で移動することができるが、このようなグローバルの経路探索に影響を及ぼす操作は計算にコストがかかるので、各エージェントローカルの衝突回避で済むならそのほうがよい。
NavMeshをbakeする こんな感じで床に適当なオブジェクトを置いてみた。
Window -&amp;gt; NavigationでBakeするのを選択してNavigation Staticし(StaticになってBakeの対象になる)、 Bakeボタンを押すとこんな感じでBakeされる。
オブジェクトの上がNavMeshに含まれていないのはAgent sizeのStep Heightよりも高いため。 段差を移動するときに浮いてしまうのを避けるためにはAdvancedのHeight Meshをオンにする。 また、端が含まれていないのはこのAgentの中心が入れる位置を表しているためで、 Agent Radiusを変更すると広がったり狭まったりするのを確認できる。
NavMesh Agent Radius0.5, Height2のCylindarを作成し、Nav Mesh Agentを追加する。
で、ゴールにオブジェクトを置いてそこまで移動させてみる。
using UnityEngine.AI; public GameObject goal; void Start () { var agent = GetComponent&amp;lt;NavMeshAgent&amp;gt;(); agent.destination = goal.transform.position; } NavMesh Obstacle 障害物。上で通った経路上にNavMesh Obstacleを追加したCubeを置いたところうまく避けてゴールまでたどり着いた。
ただ、完全に道をふさいでしまうと立ち往生してしまうので Carveにチェックを入れるとCarvingされ、他の経路でゴールまで進むようになる。
Unityで動的にNavMeshを生成する - sambaiz-net</description>
    </item>
    
    <item>
      <title>Unityの物理エンジン・衝突: RigidbodyとCollidarとJoint</title>
      <link>https://www.sambaiz.net/article/114/</link>
      <pubDate>Sun, 25 Jun 2017 23:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/114/</guid>
      <description>Rigidbody GameObjectを物理特性によって制御し、力の影響を受けるようにする。 Mass(質量)やDrag(空気抵抗)、Use Gravityなどのプロパティがある。
移動させるのに自分でTransformは変更せず力をかけて物理演算に任せる。 Is Kinematicにチェックを入れると物理エンジンによって移動しないようになるので、 Transformを直接変更する場合は有効にする。 ただし、スクリプトで動的にIs Kinematicを切り替えるのはパフォーマンスが良くない。
Collidar RigidBodyの物理特性の境界を定義する。衝突させるには両方にCollidarが設定されている必要がある。 RigidBodyなしのCollidarを静的Collidarといって、無効にしたり移動しないことを前提に最適化される。 移動したりするものについてはRigidBodyを付けて、必要ならIs Kinematicを有効にする。
衝突時にはOnCollisionEnter() が呼ばれる。ほかに離れたときのOnCollisionExit()、 触れている間、毎フレーム呼ばれるOnCollisionStay()がある。
void OnCollisionEnter(Collision collision) { foreach (ContactPoint contact in collision.contacts) { if (contact.otherCollider.tag == &amp;#34;Player&amp;#34;) { Debug.Log(collision.relativeVelocity.magnitude); } } } Is Triggerにチェックを入れると物理エンジンには無視されてすり抜け、侵入に対してトリガーイベントが呼ばれる。 OnCollistionと同様に OnTriggerEnter()、 OnTriggerExit()、 OnTriggerStay() がある。
void OnTriggerEnter(Collider other) { Debug.Log(other.tag); } Joint Rigitbodyを他のRigitbodyとつなげるもの。 例えばSprint Jointだとオブジェクト間がばねのように伸縮する。
 </description>
    </item>
    
    <item>
      <title>fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする</title>
      <link>https://www.sambaiz.net/article/113/</link>
      <pubDate>Sun, 25 Jun 2017 00:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/113/</guid>
      <description>デプロイやスループットの調整を簡単にするため、BeanstalkでAggregatorを立ち上げた。
負荷分散 TCPの24224(設定による)が通るようにEC2,ELBのSGとリスナーの設定をする必要があって、 ELBのSGのアウトバウンドの設定が見落とされがち。ELBのクロスゾーン分散は有効になっている。
まず、ELBに3台、それぞれ別のAZ(1b, 1c, 1d)に配置されている状態でログを送り始めるとそれぞれ均等にログが届いた。 その状態から4台(1b * 2, 1c, 1d)にすると、2つのインスタンス(1b, 1c)のみに均等にログが届くようになった。 4台になると(1b, 1c)と(1b, 1d)に分けられてELBのノードがそれらの組に紐づいたということだと思う。 各ノードにはDNSラウンドロビンするようになっている。実際restartすると今度は別の組の方に送られた。
では、なぜ一度送り始めると同じ方にしか飛ばないかというと、forwardプラグインのexpire_dns_cacheがデフォルトでnilになっていて、 heartbeatが届いている間は無期限にDNSキャッシュするようになっているため。これに0(キャッシュしない)か秒数を指定すると、 その間隔で他の組のインスタンスにもログが届くようになった。 expire_dns_cacheしなくても複数のインスタンスからラウンドロビンされるため全体でいえば分散される。
heartbeat ELB配下のEC2を全て落としてもheartbeatに失敗しないため、standyに移行せずELBのバックエンド接続エラーになってログがロストしてしまうようだ。 ログにも出ず、以下のようにactive-standbyの設定をしてもstandbyに移行しない。 全てのインスタンスが同時に落ちるというのは滅多に起きないだろうが、少なくとも検知できるようにはしておく。
&amp;lt;server&amp;gt; name td1 host autoscale-td1.us-east-1.elasticbeanstalk.com port 24224 &amp;lt;/server&amp;gt; &amp;lt;server&amp;gt; name td2 host autoscale-td2.us-east-1.elasticbeanstalk.com port 24224 standby &amp;lt;/server&amp;gt; Blue/Green Deployment Blue-Green Deploymentというのは、2つの系を用意し、activeでない方にデプロイし、 スワップして反映させるもの。ダウンタイムなしで問題が起きた際にもすぐに切り戻すことができる。 スワップして向き先を変えるにはexpire_dns_cacheを設定する必要がある。
Auto Scaling 増えるのはいいとして減るときに、 送り先で一時的に障害が起きていたりするとバッファをflushできずにログがロストする可能性がある。 それでいうとログの送り元でも同じことが起こりうるんだが、通常Aggregatorにしか送らないので比較的問題になりにくい。
これを避けたい場合、Auto Scalingグループの設定で スケールインから保護を有効にして これから立ち上がるインスタンスはスケールインしなくすることができる。 それまでに立ち上がっていたインスタンスには適用されないので注意。
スケールインしないということは最大の台数で止まってしまうので、 ピークを過ぎたらスワップしてバッファが全て掃けたことを確認してからTerminateすることになる。 これを日常的にやるのは面倒なので、実際は予期しない流量の増加に備えて一応設定しておき、 普段はしきい値にひっかからないような最低台数で待ち構えておくことにするかな。
あとはヘルスチェックによって潰される可能性はなくもないが、それはもうやむなし・・・。
参考 AWS ELBの社内向け構成ガイドを公開してみる 負荷分散編 – Cross-Zone Routingを踏まえて ｜ Developers.</description>
    </item>
    
    <item>
      <title>UnityのMecanimでヒューマノイドアニメーションさせる</title>
      <link>https://www.sambaiz.net/article/112/</link>
      <pubDate>Tue, 20 Jun 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/112/</guid>
      <description>Space Robot Kyleを動かす。
アバターの作成 AssetsのModel/Robot Kyleを選択し、RigのAnimation TypeをHumanoidにすると、 自動的にボーン構造を解析して人型にマッピングしたアバターが設定される。 Configure Avatarで確認すると正しく設定されているようだ。
 モーションの設定 KyleのAnimatorのAnimationに設定するAnimation Controllerを作成する。 まずは2つCreate Stateし、それぞれMotionに適当なモーション(今回はFighter Pack Bundle FREEを使った)を設定し、 Make Transitionで相互に結ぶと、オレンジになっているデフォルトステートから交互にモーションする。 ステートにはStateMachineBehaviourのScriptを設定することもできる。
 次にParametersでモーションを変化させる。
 Animatorの左上、parametersタブからBoolのWalkを追加する。 そして片方のTransitionのConditionにWalkがfalse、もう片方にはWalkがtrueを追加すると、 状態によって違うモーションをするようになる。 ちなみに、AnyStateからConditionを設定したTransitionを設定すると、どこのStateからでもそれで遷移させることができる。
 このParameterはこんな感じに値を設定できる。
void Update () { GetComponent&amp;lt;Animator&amp;gt; ().SetBool (&amp;#34;Walk&amp;#34;, Random.value &amp;lt; 0.5); } 一部だけモーションさせる 人体の一部だけをモーションさせるにはAvatar Maskを使う。
  Animationで複数のレイヤーを作成すれば、異なるMaskでそれぞれステートを持たせることができる。
Animation Override Controller 作ったAnimationを違うモーションで再利用することができる。
 </description>
    </item>
    
    <item>
      <title>NorikraでログをJOINする</title>
      <link>https://www.sambaiz.net/article/111/</link>
      <pubDate>Thu, 15 Jun 2017 00:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/111/</guid>
      <description>NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net
適当なログを出すコードを書いた。
sambaiz/lottery-log
これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。 広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。
// lottery.log {&amp;#34;ts&amp;#34;:1497453504.6818597,&amp;#34;uid&amp;#34;:&amp;#34;b18c0d98-19b2-4e37-8fc4-6b00a4b728c3&amp;#34;,&amp;#34;prize&amp;#34;:855,&amp;#34;isWin&amp;#34;:true} // received.log {&amp;#34;ts&amp;#34;:1497453515.932101,&amp;#34;uid&amp;#34;:&amp;#34;bc4f578f-4a5f-47f1-a4e0-1ef0b43c316e&amp;#34;} クエリはこんな感じ。一つはlotteryログとreceivedログをuidでJOINするもので、 received_rateの計算にはサブクエリも使っている。 received_rateの計算で分母に小さな値を足しているのはNaNやInfinityにならないようにするため。 receivedログは最大30秒遅れて出力されるため、40秒前までのreceivedログをwin:timeで見ている。 これをtime_batchにしてしまうと期待通りの結果にならないので注意。
もう一つはJavaの関数でboolを0/1にして平均をとることでisWinがtrueである割合を出している。
$ docker exec norikra norikra-client query add lottery_agg &amp;#39; SELECT COUNT(*) as received_count, (COUNT(*) / (SELECT COUNT(*) + 0.00001 FROM lottery.win:time_batch(1 sec, 0).std:unique(uid))) as received_rate, AVG(prize) as prize_avg, SUM(prize) as prize_sum FROM lottery.win:time(40 sec).std:unique(uid) as a, received.win:time_batch(1 sec, 0).std:unique(uid) as b WHERE a.uid = b.uid&amp;#39; $ docker exec norikra norikra-client query add lottery_win_rate &amp;#39;SELECT avg(Boolean.</description>
    </item>
    
    <item>
      <title>VSでのネイティブプラグインのビルドからUnityでのWSAのビルドまでをバッチでする</title>
      <link>https://www.sambaiz.net/article/110/</link>
      <pubDate>Tue, 13 Jun 2017 00:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/110/</guid>
      <description>VSでのネイティブプラグインのビルド VSが使っているビルドツール MSBuildを使う。 VSのプロジェクトファイルにはMSBuildのXMLが含まれている。 これ自体はVSに依存していないため、単体で動かすこともできる。
パスが通ってなかったらパスを通す。管理者権限が必要。
&amp;gt; MSBuild &amp;#39;MSBuild&amp;#39; は、内部コマンドまたは外部コマンド、 操作可能なプログラムまたはバッチ ファイルとして認識されていません。 &amp;gt;　SETX /M PATH &amp;#34;%PATH%;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\Bin&amp;#34; 成功: 指定した値は保存されました。 別プロセスから適用されるので立ち上げ直すとパスが通っていることを確認できる。
&amp;gt; MSBuild /version Microsoft (R) Build Engine バージョン 15.1.1012.6693 Copyright (C) Microsoft Corporation.All rights reserved. 15.1.1012.6693 ビルドしてAssets\Pluginsに配置する。これは前作ったBLEのネイティブプラグインのもの。
Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net
&amp;gt; git clone git@github.com:sambaiz/UnityBLE_UWP.git &amp;gt; cd UnityBLE_UWP &amp;gt; MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;#34;x86&amp;#34; &amp;gt; MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release &amp;gt; copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA &amp;gt; copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.dll .</description>
    </item>
    
    <item>
      <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
      <link>https://www.sambaiz.net/article/109/</link>
      <pubDate>Sat, 10 Jun 2017 12:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/109/</guid>
      <description>NorikraはTD社のtagomoris氏が作った、 スキーマレスのストリーミングデータを処理するOSS。
モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだが、 流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。
Norikraを立ち上げてクエリを実行する 公式で紹介されているDockerイメージがあったのでこれで動かしてみる。
$ docker run -e &amp;#34;TZ=Asia/Tokyo&amp;#34; -p 26578:26578 -p 26571:26571 -v `pwd`:/var/tmp/norikra:rw -d myfinder/docker-norikra norikra start --stats /var/tmp/norikra/stats.json -l /var/tmp/norikra ほかのオプションとして-Xmsや-XmxでJVMのヒープメモリの量を設定したり、Experimentalではあるが--shutoffでヒープメモリが一杯になる前に弾いて OutOfMemoryを防ぐことができる。 また、Norikraのコアエンジンで使われているOSSの CEP (Complex event processing)エンジン、 Esper のパフォーマンスチューニングとして--microや--smallなどを渡すこともできるが試していない。
公式サイトの例に従ってクライアントからデータを入れてクエリを実行してみる。
まずはtargetをopenする。targetというのはスキーマレスのイベントストリームのこと。 ここで定義したフィールドは必須になる。
$ norikra-client target open www path:string status:integer referer:string agent:string userid:integer $ norikra-client target list TARGET	AUTO_FIELD www	true 次にクエリを追加する。一見普通のSQLのように見えるが、EsperのクエリであるEPL(Event Processing Language)。 ただしSELECTしか使えないのも含めてクエリにいくらかの制限がある。
このクエリではwin:time_batchで10秒のWindowを定義し、eventをgroup byして、その数をeventとして出力する。
$ norikra-client query add www.toppageviews &amp;#39;SELECT count(*) AS cnt FROM www.</description>
    </item>
    
    <item>
      <title>fluentdでKinesis streamsに送るときの性能確認</title>
      <link>https://www.sambaiz.net/article/108/</link>
      <pubDate>Mon, 05 Jun 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/108/</guid>
      <description>localでのstreamsとproducerのbenchmark aws-fluent-plugin-kinesisの make benchmarkはlocalにDummyServerを立ち上げて送っている。
空でもいいのでroleをつけておく必要がある。
$ git clone https://github.com/awslabs/aws-fluent-plugin-kinesis.git $ cd aws-fluent-plugin-kinesis $ yum install -y ruby-devel gcc $ echo &amp;#39;gem &amp;#34;io-console&amp;#34;&amp;#39; &amp;gt;&amp;gt; Gemfile $ make $ make benchmark RATEを指定しなければデフォルトで秒間1000レコードが送られる設定。 fluentdを起動してから10秒後にプロセスをkillし、そのレコード数などを出力している。
t2.microでデフォルト(RATE=1000)で実行した結果がこれ。 固める分producerの方はややパフォーマンスが落ちる。
bundle exec rake benchmark TYPE=streams Results: requets: 20, raw_records: 9400, records: 9400 bundle exec rake benchmark TYPE=producer Results: requets: 14, raw_records: 1005, records: 8900 RATE=3000のとき。producerではraw_recordsが1/100、リクエスト数は1/5。 streamsだとシャードを増やしていく必要があるが、producerの方は当分大丈夫そうだ。
bundle exec rake benchmark TYPE=streams Results: requets: 57, raw_records: 27600, records: 27600 bundle exec rake benchmark TYPE=producer Results: requets: 12, raw_records: 241, records: 25200 RATE=10000のとき。raw_records, requestの圧縮率はさらに上がり、 パフォーマンスの差が大きくなってきている。</description>
    </item>
    
    <item>
      <title>td-agent2.3.5のfluentdが0.14系になってしまっているのでソースからビルドする</title>
      <link>https://www.sambaiz.net/article/107/</link>
      <pubDate>Sun, 04 Jun 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/107/</guid>
      <description>追記(2016-06-25): 現在は普通に入れても0.12系の2.3.5-1が入るようになっている。
 $ curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh $ td-agent --version td-agent 0.14.16 0.12系じゃない！？
$ yum list installed | grep td-agent td-agent.x86_64 2.3.5-0.el2017 @treasuredata どうやら2.3.5では0.14系になってしまっているよう。 そのあとにリリースされた2.3.5-1では直ってるみたいだが、現時点ではrpmリポジトリに上がっていない。
しょうがないのでソースからビルドすることにした。 いずれにせよ各環境で同じバージョンのビルドに合わせるべきだとは思う。 Beanstalk環境の場合、AMIに固めていたとしても非Beanstalk AMIではyum updateされてしまうので注意が必要だ。
BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因 - sambaiz-net
前UbuntuでやったようにDockerでビルドする。今回はAmazon Linux向け。
td-agentをビルドしてfluentdのバージョンを上げる - sambaiz-net
https://hub.docker.com/r/sambaiz/docker-td-agent-build-amazon-linux/
FROMamazonlinux:2017.03 WORKDIR/tmp RUN yum -y update &amp;amp;&amp;amp; \  yum groupinstall -y &amp;#34;Development Tools&amp;#34; &amp;amp;&amp;amp; \  yum install -y ruby23 ruby23-devel &amp;amp;&amp;amp; \  gem install bundler io-console &amp;amp;&amp;amp; \  git clone https://github.</description>
    </item>
    
    <item>
      <title>BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因</title>
      <link>https://www.sambaiz.net/article/106/</link>
      <pubDate>Sun, 04 Jun 2017 23:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/106/</guid>
      <description>User-Dataとは EC2インスタンス起動時に、シェルスクリプトを走らせたりcloud-initディレクティブを適用できる機能。 コンソールではインスタンスの詳細の設定の、高度な詳細のところから設定できる。
BeanstalkでのUser-Data 実はBeanstalkでも使われていて、CloudFormationで設定されている。
&amp;#34; /bin/bash /tmp/ebbootstrap.sh &amp;#34;, ... &amp;#34;Fn::FindInMap&amp;#34;: [ &amp;#34;AWSEBOptions&amp;#34;, &amp;#34;options&amp;#34;, &amp;#34;UserDataScript&amp;#34; ] &amp;#34; &amp;gt; /tmp/ebbootstrap.sh &amp;#34;, ... &amp;#34;AWSEBOptions&amp;#34;: { &amp;#34;options&amp;#34;: { &amp;#34;UserDataScript&amp;#34;: &amp;#34;https://s3-ap-northeast-1.amazonaws.com/elasticbeanstalk-env-resources-ap-northeast-1/stalks/eb_node_js_4.0.1.90.2/lib/UserDataScript.sh&amp;#34;, &amp;#34;guid&amp;#34;: &amp;#34;f08557fc43ac&amp;#34;, } } このshellの中では、時計を同期させたり、awsebユーザーを作成したりするほかに、 User-Dataで渡しているguidとAMI作成時に焼かれたguidが一致していない(is_baked=false)場合yum updateが走るようになっている。 そのためAMIを変更するとAMIでのバージョンとBeanstalkで立ち上がったときのバージョンが異なることがあって、固定するにはUser-Dataのguidを併せて変更する必要がある。
GUID=$7 function update_yum_packages { if is_baked update_yum_packages_$GUID; then log yum update has already been done. else log Updating yum packages. yum --exclude=aws-cfn-bootstrap update -y || echo Warning: cannot update yum packages. Continue... mark_installed update_yum_packages_$GUID # Update system-release RPM package will reset the .</description>
    </item>
    
    <item>
      <title>Unity/UWPでBLEを扱うプラグインを作る</title>
      <link>https://www.sambaiz.net/article/105/</link>
      <pubDate>Sun, 04 Jun 2017 11:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/105/</guid>
      <description>コードはここ
この動画の 50:00あたりから説明があるように、 ビルドされたWSAが読むUWPのdllのほかに、 Unityエディタ上から読むための.NET Framework3.5のdllを用意する。 こうすることで実行環境ごとの違いをUnityコード上で気にしなくてもよくなる。
新しいプロジェクトで
  Visual C# から.NET Framework 3.5にしてクラスライブラリ(.NET Framework)
  Visual C# -&amp;gt; Windows -&amp;gt; ユニバーサルからクラスライブラリ(ユニバーサルWindows)
  の2つのプロジェクトを同じソリューションに作成する。 VS2017で.NET Frameworkのクラスライブラリプロジェクトを作成するためには Visual Studio Installerで.NET Coreのワークロードをインストールする必要がある。 また、これとは別に動作確認用のUWPアプリケーションプロジェクトを作成した。
UWPの方のプロジェクトにあるClass1.csを削除し、追加 -&amp;gt; 既存の項目から、 もう片方のClass1.csをリンクとして追加して、この共通のcsにUWPのコードを書いていくんだが、 そのまま書くと当然.NET Frameworkの方でビルドできないので 実装部分を#if WINDOWS_UWP ~ #endif で囲む。UWPの方のプロジェクトにはプロパティ -&amp;gt; ビルドの条件付きコンパイルにWINDOWS_UWPが含まれているので有効になる。
public void Start() { #if WINDOWS_UWP  ... #endif } UWPでBLEを扱うのは前書いた通り。 ただし、なぜかXAMLに依存しているようでD3Dビルドすると失敗する。
UWPでBLEデバイスとペアリングして値を取得する - sambaiz-net
ビルドするとdllができるので.NET Frameworkの方をAssets/Pluginsに置いてInspectorからEditorにだけチェックを入れる。 UWPの方はAssets/Plugins/WSAに置くとWSA Playerにだけチェックが入る。
あとは普通にusingして使うだけ。Edit-&amp;gt;Project Settings-&amp;gt;PlayerからBluetoothのcapabilityを有効にするのを忘れずに。 Package.appxmanifestは上書きされないようなので前にビルドしたやつがあったら一旦消す。
using UnityBLE; public class BLE : MonoBehaviour { string value = &amp;#34;no connection&amp;#34;; public GameObject text; private string serviceUUID = &amp;#34;***&amp;#34;; private string characteristicUUID = &amp;#34;***&amp;#34;; void Start() { var ble = new UnityBLE.</description>
    </item>
    
    <item>
      <title>Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる</title>
      <link>https://www.sambaiz.net/article/104/</link>
      <pubDate>Sat, 27 May 2017 16:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/104/</guid>
      <description>https://github.com/uber-go/zap
$ go get -u go.uber.org/zap $ go get -u gopkg.in/natefinch/lumberjack.v2 速さの秘訣 Go言語のLogger「zap」は何故高速に構造化されたログを出力する事が出来るのか｜株式会社CAリワード
reflectionとallocationの回避。
一度allocateしたBufferやEncoderは sync.Poolで使い回している。 このPoolはまさにallocateされたアイテムを再利用するためのもので、GCの負担を緩和させることができる。 Poolのアイテムは勝手に削除されることがあり、もし参照しか持っていなかったらそのままdeallocateされる。
https://github.com/uber-go/zap/blob/v1.4.0/buffer/pool.go#L34
func NewPool() Pool { return Pool{p: &amp;amp;sync.Pool{ New: func() interface{} { return &amp;amp;Buffer{bs: make([]byte, 0, _size)} }, }} } 使い方 現状ドキュメントが乏しいのでコードから探っていく必要がある。 まずはQuick Startから。
zap.NewProduction()はNewProductionConfig().Build(options...)のショートカット。 ConfigをBuildしてLoggerを取得し、InfoやErrorで書く流れ。
logger, _ := zap.NewProduction() defer logger.Sync() logger.Info(&amp;#34;Hoge&amp;#34;, // Structured context as strongly-typed Field values.  zap.Int(&amp;#34;attempt&amp;#34;, 3), zap.Duration(&amp;#34;backoff&amp;#34;, time.Second), ) {&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1495870212.3378785,&amp;#34;caller&amp;#34;:&amp;#34;zap-log/main.go:36&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;Hoge&amp;#34;,&amp;#34;attempt&amp;#34;:3,&amp;#34;backoff&amp;#34;:1} NewProductionConfig()の内容はこんな感じ。ここからOutputPathを書き換えるとファイルに出力されるようにできる。
config := zap.Config{ Level: zap.</description>
    </item>
    
    <item>
      <title>夜のNY郊外を無一文で彷徨い、Google I/OとMaker Faire Bay Areaに行ってきた</title>
      <link>https://www.sambaiz.net/article/103/</link>
      <pubDate>Mon, 22 May 2017 23:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/103/</guid>
      <description>Googleが毎年やっているイベント、Google I/Oのチケットが当たったのでアメリカに行ってきた。 海外に行くのはこれが3回目でアメリカははじめて。一人での海外もはじめて。
準備 チケットが当たってからExpediaで航空券やホテルを取った。航空券の流れで保険にも加入した。 アメリカの医療費は相当高いそうなので何かしらの保険に入っておかないと不安だ。
会期中は会場近辺のサンフランシスコ/マウンテンビューのホテルがとんでもなく値上がりしている模様。 多分通常の倍ぐらいにはなっているので早めに取っておくとよいと思われる。
GoogleI/Oは週末にかけての3日間だったので、その前の週末から出発し、前半はニューヨークに行くことにして、 マンハッタンに宿を取った。
アメリカに入国するのにはESTAを申請する必要がある。 申請自体は72時間以内に通るのだが、パスポート番号が必要がなので持っていなければ先に作っておく必要がある。 ESTAが通っていないと本当に入れないらしい。怖い。
現地での通信手段はT-mobileのTourist plan($30プリペイドでSIM+2GB LTE+国内通話+SMS) を購入することにした。 日本にはsimを送ってくれないので現地で調達する必要がある。モバイルルータはちょっと高いような気がして借りなかった。
あとは英語力をなんとかしようと付け焼刃でDMM英会話をはじめてみたが、準備期間が短すぎたかなと思う。
出国 チェックインの締め切りが出発の1時間前だったので、 余裕を持って2時間前ぐらいには着くはずだったんだが、こんなときに限って財布を落とすわ成田エクスプレスは突然運休するわで大ピンチ。 日暮里から京急のスカイライナーに乗ってスーツケースをかついで走ってなんとか飛行機には間に合ったが、 両替などする時間はなく、財布に1000円しか入っていない状態で出発することになってしまった。
距離にして11000km、12時間のフライトの末、ニューヨークのジョン・F・ケネディ国際空港(JFK)に到着。 時差で-13時間になるため出発よりも早い時刻に到着することになって得した気分だ。 ついにアメリカに来た。
ニューヨーク 当初はニューヨーク観光しつつ、アムトラック(電車)でワシントンD.C.にも行っちゃおうかと考えてチケットまで買っていた。 しかし現実は厳しい。
現地に到着し、通信手段を調達するためT-mobileのショップに向かおうとしたが、肝心のショップの場所がわからない。 もちろん日本のsimカードはすでに機能停止しているので空港のWifiで調べたところ、そこから一番近いところでも数km離れていることがわかった。 タイムズスクエアの近くにはあるようだったので、まずはなんとかしてホテルに向かうことにしたが、 JFKからマンハッタンまでは直線距離で20km以上離れている。ホテルの送迎サービスはなかった。 それでもGoogle mapに従って、途中free wifiを乗り継いでいけばこのときはなんとかなるかなと思っていた。
空港から電車で行こうと思っていたところ、うかつにも謎タクシーに誘導されて乗ってしまった。 47ドルでホテルまで行ってくれると思いきや、それはJamaica駅までの料金で、ホテルまでは100ドルという。調べていた相場の倍だ。 傷口を広げないようJamaicaで降ろしてもらうことにした。 乗る前に現金はないからクレジットカードで払う旨を伝えたのだが、 支払いの段になってクレジットカードの機械が壊れたから現金でと言い出して困った。なにせ1ドルも持っていないのだから。 近くのATMで現金を下ろすよう言われたのでクレジットカードを入れたのだけれど 2枚ともアウト。そこからどうやって払うんだって問いつめられるもののどうしようもない。 結局解放してもらえたが、初っ端からほとんど心が折れてしまって国に帰りたかった。
それでもなんとかしてホテルにはたどり着かなくてはならないので、LIRRという電車でJamaicaからWoodside駅に向かった。 空港で調べたGoogle mapの経路に出たからそうしたのだが、 マンハッタンにあるハブ駅、Pensilvania(Penn) stationまで行くほうが行き先表示に出ているので分かりやすかった。 改札はなくて切符は車内で確認される。
案内の人に聞いて電車に乗ったんだが、切符の確認の際にこの電車ではないと言われる。 乗り間違えると、引き返すためにホームで割と長く待つことになる。5月も半ばなのに白い息が出るぐらい寒い。 Googleで調べようにも、駅にあるWifiはどうも契約していないと使えなさそうなものしかなかった。 地下鉄にはfree wifiが通っていたが、それも全ての駅で使えるというわけではなさそうだった。
Woodsideからは地下鉄に乗るのだけれど、この券売機がなぜかクレジットカードのPINをうけつけてくれずチケットを買えなかった。 カードが止まったかと思い、しょうがないので6kmほど歩いてマンハッタンまで向かうことにした。雨が降っていて、寒くて泣きたくなった。 空港でマップのデータを読んでいたのでGPSと合わせればオフラインでも自分の位置はわかるのが唯一の救いだ。 電話もなかったので、道中あったスタバなどのfree wifiを外から使わせてもらって、 家族に連絡をとって日本からクレジットカード会社に問い合わせてもらったが、 本人からの連絡じゃないとだめとのことでどうしようもなかった。
マンハッタンに行くためにはイースト川を越える必要があったので、 地図上で橋になっているところを順番に見てまわったが、車や電車でないとだめなところばかりで暗雲がただこめる。 あとから調べたら、マンハッタンの南側、ブルックリンとマンハッタン橋は歩いて渡れたらしい。 あの向こうがマンハッタンなのになと沿岸を眺めながら、この時点で夜中の0時を回っていて、野宿の可能性を考え始める。
 途方に暮れて彷徨っていたところ、歩いていたおじさんとたまたま目が合って、 お金がなくて電車には乗れないんだが、徒歩でマンハッタンに渡る方法はあるか聞いたら、 なんと地下鉄の駅まで案内してくれて運賃を出してくれた。 お礼するために連絡先を聞こうとしたのにすぐいなくなってしまわれた。命の恩人だ。</description>
    </item>
    
    <item>
      <title>io17で発表されたFirebaseのphone number authをwebで試してみた</title>
      <link>https://www.sambaiz.net/article/102/</link>
      <pubDate>Wed, 17 May 2017 23:34:00 -0700</pubDate>
      
      <guid>https://www.sambaiz.net/article/102/</guid>
      <description>今日のdeveloper keynoteで発表されたphone number authを試してみた。 Firebaseだと他にはPerformance Monitoringも発表されている。 あとSDKをオープンソースにするとか。
firebase-toolsを最新版にする。
# npm install -g firebase-tools $ firebase -V 3.9.0 FirebaseUIを使う場合、これも最新版にしないと出てこない。
&amp;lt;script src=&amp;#34;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;link type=&amp;#34;text/css&amp;#34; rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.css&amp;#34; /&amp;gt; firebase.auth.PhoneAuthProvider.PROVIDER_IDがphone number authの オプション。
const uiConfig = { signInOptions: [ firebase.auth.PhoneAuthProvider.PROVIDER_ID ], ... } const ui = new firebaseui.auth.AuthUI(firebase.auth()); ui.start(&amp;#39;#firebaseui-auth-container&amp;#39;, uiConfig); こんなボタンを押すと
 電話番号とCAPTCHAが入り、
 SMSに書かれた番号を入力すると認証される。
 二段階認証のようなものだと思っていたがそうではないようだ。</description>
    </item>
    
    <item>
      <title>UWPでBLEデバイスとペアリングして値を取得する</title>
      <link>https://www.sambaiz.net/article/101/</link>
      <pubDate>Sat, 13 May 2017 10:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/101/</guid>
      <description>ManifestからBluetoothを許可しておく。
BLEデバイスを見つける CreateWatcherにBluetooth LEプロトコルのAEP(Association EndPoint)サービスクラスIDと requestPropaertiesで必要なデバイス情報を渡している。 最後のAssociationEndpointはSystem.Devices.Aep.ProtocolIdのAepと対応している。
using Windows.Devices.Enumeration; string[] requestedProperties = { &amp;#34;System.Devices.Aep.DeviceAddress&amp;#34;, &amp;#34;System.Devices.Aep.IsConnected&amp;#34; }; deviceWatcher = DeviceInformation.CreateWatcher( &amp;#34;(System.Devices.Aep.ProtocolId:=\&amp;#34;{bb7bb05e-5972-42b5-94fc-76eaa7084d49}\&amp;#34;)&amp;#34;, requestedProperties, DeviceInformationKind.AssociationEndpoint); deviceWatcher.Start(); deviceWatcher.Added += DeviceWatcher_Added; deviceWatcher.Removed += DeviceWatcher_Removed; deviceWatcher.Updated += DeviceWatcher_Updated; /* deviceWatcher.EnumerationCompleted += DeviceWatcher_EnumerationCompleted; deviceWatcher.Stopped += DeviceWatcher_Stopped; */ Dictionary&amp;lt;string, DeviceInformation&amp;gt; deviceInfos = new Dictionary&amp;lt;string, DeviceInformation&amp;gt;(); private void DeviceWatcher_Added(DeviceWatcher sender, DeviceInformation deviceInfo) { if (sender == deviceWatcher) { if (deviceInfo.Name != string.Empty) { deviceInfos.Add(deviceInfo.Id, deviceInfo); } } } private void DeviceWatcher_Updated(DeviceWatcher sender, DeviceInformationUpdate deviceInfoUpdate) { if (sender == deviceWatcher) { deviceInfos[deviceInfoUpdate.</description>
    </item>
    
    <item>
      <title>RxJSでObservableを結合する(merge, forkJoin, concat, combineLatest)</title>
      <link>https://www.sambaiz.net/article/100/</link>
      <pubDate>Tue, 09 May 2017 20:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/100/</guid>
      <description>RxJSでRxをはじめる - sambaiz.net
merge 2つのstreamの両方の値がemitされる。
Rx.Observable.merge( stream1, stream2 ).subscribe( data =&amp;gt; console.log(`merge ${data}`), err =&amp;gt; console.log(`merge ${err}`) ); forkJoin completeしたときの最後の値を配列としてemitする。 非同期で一つ値をemitするようなstreamで、Promise.allのようなことをしたいときはこれ。
Rx.Observable.forkJoin( stream1, stream2 ).subscribe( data =&amp;gt; console.log(` forkJoin: ${data}`), err =&amp;gt; console.log(` forkJoin: ${err}`) ) concat 前のstreamがcompleteしたら次のstreamの値がemitされる。
Rx.Observable.concat( stream1, stream2 ).subscribe( data =&amp;gt; console.log(` concat ${data}`), err =&amp;gt; console.log(` concat ${err}`) ); combineLatest stream自体を結合するのではなく値を結合する。 この例だと、stream1でemitされた値がa、stream2で最後にemitされた値がbのときa+bをemitする。 combineする値がない場合はemitされない。
stream1.combineLatest(stream2, (a, b) =&amp;gt; a + b).subscribe( data =&amp;gt; console.log(` combineLatest ${data}`), err =&amp;gt; console.</description>
    </item>
    
    <item>
      <title>angular/material2でフォームを作る</title>
      <link>https://www.sambaiz.net/article/99/</link>
      <pubDate>Sat, 06 May 2017 22:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/99/</guid>
      <description>コード
angular/material2の準備 現時点で DatePickerや Tableなど 開発中のコンポーネントが多いため足りないものを他のライブラリで補うなどする必要がある。 DatePickerはもう少しで出そう。
$ npm install --save @angular/material $ npm install --save hammerjs # gesture用 $ npm install --save @angular/animations Moduleでimport &#39;hammerjs&#39;;して、以下のModuleをimportに加える。
 BrowserAnimationsModule(from &#39;@angular/platform-browser/animations&#39;) MdButtonModuleなど使うもの(from &#39;@angular/material&#39;)  スタイルとアイコン(md-icon)を追加。
&amp;lt;link href=&amp;#34;../node_modules/@angular/material/prebuilt-themes/indigo-pink.css&amp;#34; rel=&amp;#34;stylesheet&amp;#34;&amp;gt; &amp;lt;link href=&amp;#34;https://fonts.googleapis.com/icon?family=Material+Icons&amp;#34; rel=&amp;#34;stylesheet&amp;#34;&amp;gt; フォームを作る とりあえずコンポーネントを作成。
$ ng g component TodoForm Formの値をバインドするためのクラスを作成する。
export class TodoForm { constructor( public id: number, public title: string, public active: boolean, public priority?: number, ) { } } まずはmaterial2のmdInput, mdSelect, mdButtonでフォームを作る。 #todoFormのように頭についている#は reference variableで、 titleはrequiredとしている。</description>
    </item>
    
    <item>
      <title>CSSのdisplayとposition</title>
      <link>https://www.sambaiz.net/article/98/</link>
      <pubDate>Sat, 06 May 2017 14:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/98/</guid>
      <description>display レンダリングに使うボックスを指定する。
outer display type pのようなブロックレベル要素やspanのようなインラインレベル要素に関わらず、指定したボックスにレンダリングする。
&amp;lt;style&amp;gt; .bg { background-color: #22ee22; width: 150px; height: 50px; } &amp;lt;/style&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;#34;display:none&amp;#34; class=&amp;#34;bg&amp;#34;&amp;gt;none&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;p style=&amp;#34;display:inline&amp;#34; class=&amp;#34;bg&amp;#34;&amp;gt;inline&amp;lt;/p&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;#34;display:block&amp;#34; class=&amp;#34;bg&amp;#34;&amp;gt;block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;#34;display:inline-block&amp;#34; class=&amp;#34;bg&amp;#34;&amp;gt;inline-block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt; flexbox displayでflexやinline-flexを指定すると領域に応じてサイズやレイアウトが柔軟に決定されるflexboxになる。 IE11もいくつかのバグのため挙動が異なることがあるがサポートはしている。 レスポンシブなデザインを実現する他の方法としては後述するgridや、@media screen and (min-width: 900px) {}のような メディアクエリによる条件付きスタイルがある。 メディアクエリは&amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width, initial-scale=1.0&amp;quot;&amp;gt;のようにしてビューポートのサイズを指定しないと意図通りに動かない。
flex-flowは 表示する方向のflex-directionと 折り返しのflex-wrapのショートハンドプロパティ。
子要素のflexは 伸びるときの倍率のflex-grow(default: 0)と 縮むときの倍率のflex-shrink(default: 1)、 初期サイズのflex-basis(default: auto)の ショートハンドプロパティ。
&amp;lt;style&amp;gt; .bg { background-color: #22ee22; } .</description>
    </item>
    
    <item>
      <title>AngularのRouter</title>
      <link>https://www.sambaiz.net/article/97/</link>
      <pubDate>Sun, 30 Apr 2017 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/97/</guid>
      <description>@angular/core&amp;#34;: 4.1.0 Angular2とangular-cliでTODOを作る - sambaiz.net
angular-cliは@angular/cliに変更された。
routingを行うのでnewで--routingオプションを付けている。
$ npm install -g @angular/cli $ ng -v @angular/cli: 1.0.1 $ ng new angular4-routing --routing $ cd angular4-routing/ $ cat package.json | grep @angular/core &amp;#34;@angular/core&amp;#34;: &amp;#34;^4.0.0&amp;#34;, $ ng serve ** NG Live Development Server is running on http://localhost:4200 ** --routingを付けたのでapp-routing.module.tsが作成され、app.module.tsにAppRoutingModuleが追加される。 index.htmlのheadにはpushStateのroutingが働くように base要素が 追加されている。
import { NgModule } from &amp;#39;@angular/core&amp;#39;; import { Routes, RouterModule } from &amp;#39;@angular/router&amp;#39;; const routes: Routes = [ { path: &amp;#39;&amp;#39;, children: [] } ]; @NgModule({ imports: [RouterModule.</description>
    </item>
    
    <item>
      <title>Node.jsのStream API</title>
      <link>https://www.sambaiz.net/article/96/</link>
      <pubDate>Sat, 22 Apr 2017 19:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/96/</guid>
      <description>Stream APIとは NodeでStreamデータを扱うためのもの。 例えばサイズが大きいファイルの入出力をStreamとして扱うことでバッファを最小限にできる。
StreamはEventEmitterで、 Readable streamやWritable stream、ReadableとWritableを合わせたDuplex streamと Readしたものを加工してWriteするTransform streamの種類があり、 それぞれ特定の関数が実装されている必要がある。
Readable stream Readable streamにはflowingとpausedの 二つのモードがある。 最初はpausedモードで、readableになってからread()することで読むことができる。
const fs = require(&amp;#39;fs&amp;#39;); let readable = fs.createReadStream(&amp;#39;sample.txt&amp;#39;); var i = 0; readable.on(&amp;#39;readable&amp;#39;, () =&amp;gt; { let chunk; while (null !== (chunk = readable.read(10))) { console.log(`${i++}: ${chunk}`); } }); dable.on(&amp;#39;end&amp;#39;, () =&amp;gt; { console.log(&amp;#39;end&amp;#39;); }); $ cat sample.txt abcdefghijklmnopqrstuvwxyz 1234567890 あいうえお $ node main.js 0: abcdefghij 1: klmnopqrst 2: uvwxyz 123 3: 4567890 あい 4: うえお end dataのイベントハンドラーを追加するか、後で書くpipeを使うとflowingモードになる。</description>
    </item>
    
    <item>
      <title>tmuxのメモ</title>
      <link>https://www.sambaiz.net/article/95/</link>
      <pubDate>Fri, 21 Apr 2017 00:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/95/</guid>
      <description>https://tmux.github.io/
セッションを立ち上げてその中で複数のウィンドウやペインからコマンドを実行できるやつ。 サーバーでの作業中にネットワークが切断されてしまってもセッションをattachすることで再開することができる。 ローカル環境でもコマンドキーでのウィンドウ作成やペインの分割、 複数のサーバーにsshで入って調査するようなときにペインの同時入力は便利。 もちろんターミナルを閉じてしまっても再開できる。
$ brew install tmux $ tmux $ tmux ls $ tmux a # sessionをattachする bind key(デフォルトでCtrl + b)を入れてからコマンドキーを入れる。よく使うもの。
 c: 新しいウインドウをCreateする d: 今のクライアントをDetachする n: Nextウィンドウに移動する p: Previousウィンドウに戻る w: Windowを一覧表示して選択する x: ペインを削除する ,: ウィンドウの名前を変更する z: ウィンドウ一杯にペインをzoomする/解除 [: ペイン内をスクロールできるようになる。qで解除  ~/.tmux.confはこんな感じにしている。
# bind keyをC-tに変更してC-bを解除 set -g prefix C-t unbind C-b # Vimのキーバインドでペインを移動する bind h select-pane -L bind j select-pane -D bind k select-pane -U bind l select-pane -R # - でペインを横に分割する(縦に切る) bind - split-window -h # | でペインを縦に分割する(横に切る) bind | split-window -v # 同時入力 bind s set-window-option synchronize-panes on bind S set-window-option synchronize-panes off </description>
    </item>
    
    <item>
      <title>Firebaseをwebで使う(Hosting, Authentication, Realtime Database, Storage)</title>
      <link>https://www.sambaiz.net/article/94/</link>
      <pubDate>Sun, 16 Apr 2017 20:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/94/</guid>
      <description>Firebaseとは GoogleのmBaaS。Android/iOSアプリの開発に使う認証、データストア、クラッシュレポート、分析、通知、広告などなど全部入りサービス。 今年のGoogleI/Oでも毎時間のように Firebaseのセッションがあって大分推している印象。
基本的にはアプリで使うのだけれど、webで使える機能も結構ある。今回は
 Hosting Authentication Realtime Database Storage  を使ってみる。
料金 プランは無料のSPARKと25ドル/月のFLAME、従量課金のBLAZEがある。 試す分にはSPARKで十分だが、Realtime Databaseの同時接続数が100なので注意。
セットアップ firebase-cliをインストール、ログインして初期化する。
$ npm install -g firebase-tools $ firebase login $ mkdir firebase-chat &amp;amp;&amp;amp; cd firebase-chat $ firebase init ... ? What Firebase CLI features do you want to setup for this folder? ❯◉ Database: Deploy Firebase Realtime Database Rules ◉ Functions: Configure and deploy Cloud Functions ◉ Hosting: Configure and deploy Firebase Hosting sites ?</description>
    </item>
    
    <item>
      <title>MySQLのALTER TABLEのメモ</title>
      <link>https://www.sambaiz.net/article/93/</link>
      <pubDate>Sat, 15 Apr 2017 19:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/93/</guid>
      <description>しばらく書かないとどういう構文だったか忘れてしまう。
MySQL :: MySQL 5.6 リファレンスマニュアル :: 13.1.7 ALTER TABLE 構文
CREATE TABLE t0 ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, c1 VARCHAR(30), c2 VARCHAR(30) ); CREATE TABLE t2 ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY ); ALTER TABLE t0 RENAME t1; ALTER TABLE t1 ADD COLUMN t2_id BIGINT UNSIGNED AFTER id, ADD COLUMN c3 INTEGER NOT NULL AFTER t2_id, MODIFY COLUMN c1 VARCHAR(30) NOT NULL, DROP COLUMN c2, ADD INDEX (c3), ADD FOREIGN KEY (t2_id) REFERENCES t2(id) ON UPDATE RESTRICT ON DELETE RESTRICT ; mysql&amp;gt; SHOW CREATE TABLE t1 \G; *************************** 1.</description>
    </item>
    
    <item>
      <title>Unityのパーティクル設定(Shuriken)</title>
      <link>https://www.sambaiz.net/article/92/</link>
      <pubDate>Thu, 13 Apr 2017 17:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/92/</guid>
      <description>UnityにはShurikenというパーティクルシステムがある。
Sphereを置いてParticle Systemを追加すると、Particleが出始める。
モジュール 設定項目が多いためモジュールに分かれている。ひとまずデフォルトで有効になっている
 (メインモジュール) Emission Shape Renderer  について見ていく。
メインモジュール  Duration: 5 Looping: true  デフォルトだとLoopingにチェックが入っているのでずっと出ているが、チェックを外すとDurationで止まる。
 Start Delay: 0 Play On Awake: true  PlayOnAwakeがtrueでStartDelayが0なので実行してからすぐにParticleが出始める。
 Start Lifetime: 5 Max Particles: 1000  StartLifetimeはParticleが消えるまでの時間。ただしMaxParticlesに達したら消される。
 Start Speed: 5 Simulation Speed: 1  StartSpeedはParticleの初速で、上げると勢い良く飛んでいく。 SimulationSpeedを上げるとParticleが出るのも含めて全体のスピードが上がる。
 Start Size: 1  Particleの初期サイズ。小さくすると塵みたいになる。
 Start Rotation: 0  Particleの初期角度。
 Gravity Modifier: 0  重力値。0だと無重力。
 Simulation Space: Local  Particleをlocal座標かworld座標で動かすか。 Localだとオブジェクトが移動したときに一緒に移動する。Worldだと置いてかれる。</description>
    </item>
    
    <item>
      <title>godocのメモ</title>
      <link>https://www.sambaiz.net/article/91/</link>
      <pubDate>Wed, 05 Apr 2017 22:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/91/</guid>
      <description>https://godoc.org/golang.org/x/tools/cmd/godoc
コメントからドキュメントを生成する。
$ godoc cmd/fmt Printf func Printf(format string, a ...interface{}) (n int, err error) Printf formats according to a format specifier and writes to standard output. It returns the number of bytes written and any write error encountered. $ godoc -src cmd/fmt Printf // Printf formats according to a format specifier and writes to standard output. // It returns the number of bytes written and any write error encountered. func Printf(format string, a .</description>
    </item>
    
    <item>
      <title>Nightmareでブラウザでの操作を自動化する</title>
      <link>https://www.sambaiz.net/article/90/</link>
      <pubDate>Wed, 29 Mar 2017 23:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/90/</guid>
      <description>最近、POSTWASHという洗濯代行サービスを使っている。 専用のカバンに詰めて集荷にきた人に渡すと、きれいに畳まれた洗濯ものが届く便利なサービスだ。 注文時にはWebのフォームから集荷、配達時間や支払い方法などを選ぶ必要があるんだが、毎週のことなのでこれを自動化してみる。
ブラウザの操作を自動化するのにNightmareを使う。 Electronを使っていて、PahntomJSより2倍くらい速く、簡潔に書ける。
$ npm install nightmare Nightmare()の引数にshow: trueを渡すとウィンドウが開いて実行し始める。 これで確認画面までいくのであとは注文ボタンを押すだけ。 ウィンドウが閉じないように最後にnightmare.end()を呼んでいない。
const co = require(&amp;#39;co&amp;#39;); const moment = require(&amp;#39;moment&amp;#39;) const jst = +9 const Nightmare = require(&amp;#39;nightmare&amp;#39;);	const nightmare = Nightmare({ show: true, waitTimeout: 3000, gotoTimeout: 3000 }); const loginID = process.env.LOGIN_ID; const loginPassword = process.env.LOGIN_PASSWORD; moment.locale(&amp;#39;ja&amp;#39;); const now = moment().utcOffset(jst) const dayAfterTomorrow = now.add(2, &amp;#39;days&amp;#39;).format(&amp;#34;YYYY年M月D日(ddd)&amp;#34;); const nextWeek = now.add(7, &amp;#39;days&amp;#39;).format(&amp;#34;YYYY年M月D日(ddd)&amp;#34;) console.log(`${dayAfterTomorrow}~${nextWeek}`); // IDとパスワードを入れてログイン const login = () =&amp;gt; nightmare .</description>
    </item>
    
    <item>
      <title>Node.jsでの文字コードの変換</title>
      <link>https://www.sambaiz.net/article/89/</link>
      <pubDate>Tue, 28 Mar 2017 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/89/</guid>
      <description>node-iconvを使う。
$ npm install iconv SHIFT_JISからUTF-8への変換はこんな感じ。
const Iconv = require(&amp;#39;iconv&amp;#39;).Iconv; const before = new Buffer([ 0x8b, 0x8d, 0x8e, 0x4d, 0x26, 0x82, 0xb2, 0x94, 0xd1 ]); const iconv = new Iconv(&amp;#39;SHIFT_JIS&amp;#39;, &amp;#39;UTF-8&amp;#39;); console.log(`before: ${before.toString(&amp;#39;hex&amp;#39;)}${before.toString()}`) const after = iconv.convert(before); console.log(`after: ${after.toString(&amp;#39;hex&amp;#39;)}${after.toString()}`); before: 8b8d8e4d2682b294d1 ���M&amp;amp;���� after: e7899be79abf26e38194e9a3af 牛皿&amp;amp;ご飯 文字コードによっては変換後に表せないことがある。 例えば、UTF-8からSHIFT_JISへの変換でサロゲートペア🍚を渡すと変換できず、エラーになる。
throw errnoException(&amp;#39;EILSEQ&amp;#39;, &amp;#39;Illegal character sequence.&amp;#39;); //IGNOREを付けることで そのような文字があった場合でもエラーにしないようにできる。
const Iconv = require(&amp;#39;iconv&amp;#39;).Iconv; const before = &amp;#34;牛皿&amp;amp;🍚&amp;#34;; const iconv = new Iconv(&amp;#39;UTF-8&amp;#39;, &amp;#39;SHIFT_JIS//IGNORE&amp;#39;); console.log(`before: ${new Buffer(before).</description>
    </item>
    
    <item>
      <title>HoloLensのSharing</title>
      <link>https://www.sambaiz.net/article/88/</link>
      <pubDate>Sat, 25 Mar 2017 22:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/88/</guid>
      <description>HoloToolkit-Unity v1.5.5.0  サーバー SharingService.exeを ここ からとってきて実行する。開発に使っているHoloToolkitと同じリリースバージョンのものを使う。
&amp;gt; SharingService.exe -local ... SharingService: Listening for session list connections on port 20602 of all network devices of the local machine. SharingService: Local IP addresses are: SharingService: xxx.xxx.xxx.xxx SharingService: Created Session &amp;#34;Default&amp;#34; with ID 0 on port 20601 今日のTokyo Hololens Meetup Vol.2の開発者セッションで、 ちょうどSharingの話があったのだけれど、残念ながら先着順で出遅れて聞けなかった。
Tweetを見る限りだとカスタマイズできず、スケーリングできないSharingService.exeは使わずに MagicOnionというのを自前で作ったらしい。
Tokyo Hololens MeetuUp Vol.2 Session5 #HoloLensJP #TMCN - Togetterまとめ
クライアント Assets/HoloToolkit/Sharing/TestsのSceneで試してみる。
以下のcapabilitiesを設定し、
 SpatialPerception InternetClient  SharingのServer Addressを設定してビルド。ほかにはこんな設定がある。</description>
    </item>
    
    <item>
      <title>Unixのパイプをmkfifo()で作ってdup2()で標準出力にコピーして書き込む</title>
      <link>https://www.sambaiz.net/article/87/</link>
      <pubDate>Fri, 24 Mar 2017 22:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/87/</guid>
      <description>パイプとは Unixでプロセス間通信するためのもの。シェルで使う|は無名パイプ。 mkfifo()システムコールで名前付きパイプを作成でき、これを読み書きすることで任意のプロセス間でやりとりできる。
$ mkfifo hoge $ ls -lh $ prw-r--r-- ... 0B ... hoge 通常のファイルと同様に読み書きすることができ、読み書きどちらかを行おうとすると待つことになる。
$ echo hoge &amp;amp; # 読まれるまで待つ $ cat hoge aaaaa [1]+ Done echo &amp;#34;aaaaa&amp;#34; &amp;gt; hoge $ cat hoge &amp;amp; # 書かれるまで待つ $ echo &amp;#34;bbbbb&amp;#34; &amp;gt; hoge bbbbb [1]+ Done cat hoge ファイルディスクリプタをコピーするシステムコールdup2()でopenしたパイプを標準出力(1)にコピーしてみる。
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt; int main(){ int fd = open(&amp;#34;./hoge&amp;#34;, O_WRONLY); if(fd &amp;lt; 0){ printf(&amp;#34;fail to open\n&amp;#34;); return 1; } printf(&amp;#34;OPEN %d \n&amp;#34;, fd); if(dup2(fd, 1) &amp;lt; 0){ printf(&amp;#34;fail to dup2\n&amp;#34;); return 2; } printf(&amp;#34;WRITE\n&amp;#34;); // これがどこに書き込まれるか  close(fd); } 最後のprintfの内容は標準出力ではなく、パイプに書き込まれていることがわかる。</description>
    </item>
    
    <item>
      <title>CuratorでElasticsearchの古いindexを削除する</title>
      <link>https://www.sambaiz.net/article/86/</link>
      <pubDate>Wed, 22 Mar 2017 00:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/86/</guid>
      <description>Curatorとは indexやsnapshotを管理するのに使えるツール。
インストール インストールする。
$ cat /etc/yum.repos.d/curator.repo [curator-4] name=CentOS/RHEL 7 repository for Elasticsearch Curator 4.x packages baseurl=http://packages.elastic.co/curator/4/centos/7 gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 $ yum install -y elasticsearch-curator $ curator --version curator, version 4.2.6 config configファイルを書く。
client: hosts: - 127.0.0.1 port: 9200 logging: loglevel: INFO logfile: logformat: default blacklist: [&amp;#39;elasticsearch&amp;#39;, &amp;#39;urllib3&amp;#39;] action 今回はindexを削除するのでdelete_indices。 対象はfilterで指定する。 logstash formatだとhogehoge-2017.01.01のようなindex名になるので%Y.%m.%d。okder than 3 daysのものを削除する。
actions: 1: action: delete_indices description: &amp;gt;- 3日前より古いhogehoge-* indexを消す filters: - filtertype: pattern kind: prefix value: hogehoge- - filtertype: age source: name direction: older timestring: &amp;#39;%Y.</description>
    </item>
    
    <item>
      <title>RxJSでRxをはじめる</title>
      <link>https://www.sambaiz.net/article/85/</link>
      <pubDate>Sat, 18 Mar 2017 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/85/</guid>
      <description>https://github.com/ReactiveX/rxjs
Rx(ReactiveX)とは 非同期処理をうまく扱えるようにするライブラリ。いろんな言語で実装されている。 非同期処理の結果はObservableなStreamに流される。 ObservableはIteratableのように扱うことができる。
RxはObserver pattern を拡張したもの。 Observer patternというのは、Subjectが、Observeしている全てのObserverに対して通知を送るデザインパターン。 C#などのeventのそれ。
C#のdelegateとevent - sambaiz.net
試してみる inputのkeyupイベントのObservableを作成し、それをsubscribe()して出力している。
&amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;script src=&amp;#34;https://cdnjs.cloudflare.com/ajax/libs/rxjs/5.0.1/Rx.min.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;input type=&amp;#34;text&amp;#34; id=&amp;#34;input&amp;#34; /&amp;gt; &amp;lt;script&amp;gt; const inputForm = document.querySelector(&amp;#39;#input&amp;#39;); const keyups = Rx.Observable.fromEvent(inputForm, &amp;#39;keyup&amp;#39;); keyups.subscribe( data =&amp;gt; console.log(data), err =&amp;gt; console.log(err) ); &amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 入力するとこんなのが出力される。
KeyboardEvent {isTrusted: true, key: &amp;#34;a&amp;#34;, code: &amp;#34;KeyA&amp;#34;, location: 0, ctrlKey: false…} KeyboardEvent {isTrusted: true, key: &amp;#34;b&amp;#34;, code: &amp;#34;KeyB&amp;#34;, location: 0, ctrlKey: false…} KeyboardEvent {isTrusted: true, key: &amp;#34;c&amp;#34;, code: &amp;#34;KeyC&amp;#34;, location: 0, ctrlKey: false…} Observable create next()でObservableに値をemitし、complete()で終了させる。 error()でエラーをemitするとそれ以後の値はemitされない。</description>
    </item>
    
    <item>
      <title>FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ</title>
      <link>https://www.sambaiz.net/article/84/</link>
      <pubDate>Wed, 15 Mar 2017 23:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/84/</guid>
      <description>KPL(Kinesis Producer Library)とは Developing Amazon Kinesis Streams Producers Using the Amazon Kinesis Producer Library - Amazon Kinesis Streams
Kinesisに送るとき、自動リトライしてくれたり、レコードをまとめてスループットを向上してくれたりするアプリケーション。Protobufを使っている。 普通に送るとどんなに小さくてもシャード*1000レコード/秒しか最大でPUTできないのを、KPLを使ってまとめることで増やすことができる。
fluentdで送る aws-fluent-plugin-kinesisでkinesis_producerを指定するとKPLを使って送信する。
&amp;lt;kinesis_producer&amp;gt;の中にKPLの設定を書くことができる。
&amp;lt;kinesis_producer&amp;gt; record_max_buffered_time 10 &amp;lt;/kinesis_producer&amp;gt; record_max_bufferd_time はバッファされたレコードが送られるまでの最大時間(ms)。デフォルトは100ms。この時間が経つか、他のリミットに当たったらレコードは送られる。
 AggregationMaxCount: 一つのレコードにまとめる最大レコード数 AggregationMaxSize: まとめたレコードの最大バイト数 CollectionMaxCount: PutRecordsで送る最大アイテム数 CollectionMaxSize: PutRecordsで送るデータ量  CloudWatchに送るmetrics_levelはデフォルトでdetailedになっていて、 コンソールのメトリクスからstream名で検索すると KinesisProducerLibraryにUserRecordsPerKinesisRecordや、UserRecordsDataPut、BufferingTime、RequestTimeなどいろいろ表示される。
とりあえず試しにこんな設定で送ってみる。
&amp;lt;match hoge.log&amp;gt; @type kinesis_producer region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt; Lambdaで読む まとめられたレコードをkinesis-aggregationで分解して読む。 今回はNode.jsでやる。
$ npm install --save aws-kinesis-agg 注意する必要があるのはドキュメントの情報が古くて、 関数の引数が足りないこと。第二引数のcomputeChecksumsが抜けているので気付かないと一つずつずれていくことになる。</description>
    </item>
    
    <item>
      <title>C#のdelegateとevent</title>
      <link>https://www.sambaiz.net/article/83/</link>
      <pubDate>Sun, 12 Mar 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/83/</guid>
      <description>delegate カプセル化するためのdelegate(移譲)メソッドに使う型。
public class Converter{ private static double defaultConvert(double num){ return num; } public delegate double Convert(double num); public Convert convert = defaultConvert; public double run(double num){ return convert (num); } } 匿名メソッドやラムダ式を渡すこともできる。
var conv = new Converter (); print (conv.run (2)); // 2  // 匿名メソッドの例 conv.convert = delegate(double input) { return input + 1; }; print (conv.run (2)); // 2 + 1 = 3  // ラムダ式の例 conv.convert = s =&amp;gt; s * s; print (conv.</description>
    </item>
    
    <item>
      <title>UnityのMaterial</title>
      <link>https://www.sambaiz.net/article/82/</link>
      <pubDate>Sat, 11 Mar 2017 20:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/82/</guid>
      <description>MaterialとShaderとTexture Materialは表面がどのようにレダリングされるかを定義するもの。 Shaderを指定し、Textureなどのパラメーターを設定する。
Shaderは光と、Materialの設定から、ピクセルの色を計算するスクリプト。 大体Standard Shader で事足りるらしい。
Textureはビットマップイメージ。色(Albedo)だけではなく、反射率や粗さなど、いろんな要素に使える。
Standard Shader Rendering Mode Albedoは(255, 255, 255, 255)で、テクスチャにはDefault Particleを指定している。 透明度はテクスチャのアルファチャンネルとAlbedoのアルファ値に基づく。
 Opaque: デフォルト。すべて不透明。   CutOut: 閾値を境に、完全に透明か、不透明になる。  Alpha Cutoffを0.1にした。
 Transparent: 透明度が適用される。現実世界の透明なマテリアルのように、反射のハイライトは完全に表示される。   Fade: ハイライトにも透明度を適用する。フェードイン/アウトしたいときに使う。  Metallic マテリアルチャートをもとにAlbedoとMetallicとSmoothnessを設定する。
これは
 Albedo: (255, 255, 255, 255) Metallic: 1 Smoothness: 0.68  を設定している。</description>
    </item>
    
    <item>
      <title>UnityのUI</title>
      <link>https://www.sambaiz.net/article/81/</link>
      <pubDate>Wed, 08 Mar 2017 16:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/81/</guid>
      <description>Canvas UI要素を配置するための領域。
renderMode   Overlay: スクリーンに対してオーバーレイするように表示
  Camera: Cameraから指定した距離(planeDistance)離れた前方に表示
  World Space 他のオブジェクトと同じように表示
  Canvas Scaler   UI Scale Mode (World Space以外)
  Constant Pixel Size: 画面サイズに関わらず同じピクセル数にする
  Scale With Screen Size: 画面サイズでスケールさせる
  Constant Physical Size 解像度や画面サイズによらず物理的に同じサイズにする
    Dynami Pixels Per Unit (World Spaceのみ): Textなどの動的に生成されたビットマップの解像度
  1と3でそれぞれこんな感じになる。
AutoLayout Vertical Layout Groupや Grid Layout Group など。これらのComponentを追加すると子要素のTransform(の一部)が自動で設定される。
Content Size Fitter Layout Component要素に合うように自動で調整される。</description>
    </item>
    
    <item>
      <title>UnityのTransform</title>
      <link>https://www.sambaiz.net/article/80/</link>
      <pubDate>Tue, 07 Mar 2017 02:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/80/</guid>
      <description>https://docs.unity3d.com/jp/current/ScriptReference/Transform.html
オブジェクトの位置、スケール、回転を保持する。親子関係を持つ。
Position positionがワールド空間の、 localPosition が親から見た相対的なローカル空間の位置。localPositionの1unitはscaleに依存する。
transform.position = new Vector3(0, 0, 0); transform.localPosition = new Vector3(0, 0, 0); 徐々に移動するにはTranslate()を使う。 最後の引数はデフォルトでSpace.Selfになっていて、Space.Worldを指定するとワールド座標を基準にする。
Time.deltaTimeは最後のフレームを完了するのにかかった秒数。 なのでフレームレートにかかわらず同じ速度で移動させることができる。
transform.Translate(0, Time.deltaTime, 0, Space.World); transform.Translate(Vector3.up * Time.deltaTime, Space.World); // 軸に沿って移動 transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform); // 最後の引数のローカル座標を基準にする transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform); Scale localScale はローカル空間のスケール。ワールド空間のScaleはない。
transform.localScale = new Vector3(0.1f, 1f, 1f); Rotation ワールド空間の rotationと ローカル空間の localRoation。
UnityはQuarternion(四元数)で回転を持っている。 実際はQuarternionそのものを自分で計算することはなく、 Quaternion.LookRotation()や Quaternion.Euler()などを使う。
Vector3 relativePos; transform.rotation = Quaternion.LookRotation(relativePos); // そのPointを向くように回転 transform.localRotation = Quaternion.Euler(0, 30, 0); Transformを向くように回転する場合は LookAt()を使う。</description>
    </item>
    
    <item>
      <title>Moment.jsでNode.jsのDateを任意のフォーマットの文字列にする</title>
      <link>https://www.sambaiz.net/article/79/</link>
      <pubDate>Mon, 06 Mar 2017 20:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/79/</guid>
      <description>Moment.js
相対時間(5 years ago)を出したり、日付の計算(add(3, &#39;days&#39;))もできる便利なライブラリ。 ブラウザでも使える。
$ npm install moment const moment = require(&amp;#39;moment&amp;#39;) const jst = +9 let now = moment().utcOffset(jst).format(&amp;#34;YYYY-MM-DD HH:mm:ss.SSSZ&amp;#34;); console.log(now); $ TZ=Africa/Ouagadougou node main.js mutableなのでadd()などの操作で元の値が変わってしまうのに注意。 変わると困る場合clone()する必要がある。
let now2 = moment(); let now3 = now2.clone(); console.log(now2); console.log(now2.add(1, &amp;#39;days&amp;#39;)); console.log(now2); console.log(now3); </description>
    </item>
    
    <item>
      <title>Unityと.NETとMono</title>
      <link>https://www.sambaiz.net/article/78/</link>
      <pubDate>Sun, 05 Mar 2017 18:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/78/</guid>
      <description>.NETとかよくわからなかったのでまとめてみた。
.NET Framework .NET Framework - Wikipedia
Microsoftが開発したアプリケーション開発、実行環境。
各言語のコンパイラによって言語、環境によらない共通の中間言語(CIL, Common Intermediate Language)バイナリ(exeやdll)に変換し、 実行時に共通言語基盤(CLI, Common Language Infrastructure)の仮想実行システム(VES)が環境依存の機械語を動的に生成(JIT, Just in time)する。 CLIの仕様はECMAで標準化されていて、Microsoftが実装したCLIが共通言語ランタイム(CLR)。Windowsでしか動かない。
.NET Core .NET Core - .NET Core による .NET のクロスプラットフォームへの移行
Microsoft/dotnet
オープンソースで、クロスプラットフォームに対応した.NET。CoreCLRはWindowsだけではなくMacやLinuxでも動く。 .NET Frameworkと共通のAPIもあるが、GUIまわりでどちらかにしかないAPIが存在する。
Mono オープンソースで、クロスプラットフォームな.NET Framework互換ソフトウェア。C#のコンパイラとCLIが実装されている。 Unityはこれを使っているが、バージョンが古くて使えないライブラリがある。
.NET CoreでHello World インストール手順に沿って dotnetコマンドを使えるようにする。
Hello Worldまで。
$ dotnet console -o hwapp $ cd hwapp $ ls Program.cs	hwapp.csproj $ dotnet restore $ ls Program.cs	hwapp.csproj	obj $ ls obj hwapp.csproj.nuget.g.props	project.assets.json hwapp.</description>
    </item>
    
    <item>
      <title>Elasticsearchで期間ごとの集計値を出す</title>
      <link>https://www.sambaiz.net/article/77/</link>
      <pubDate>Sun, 05 Mar 2017 01:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/77/</guid>
      <description>Bucket(SQLでいうGROUP BY)にまとめて(Bucket Aggreagtion)、集計(Metric Aggregation)する。
使うデータは作ったツールで生成したこんなの。
{&amp;#34;@timestamp&amp;#34;:1488635130,&amp;#34;os_name&amp;#34;:&amp;#34;linux&amp;#34;,&amp;#34;score&amp;#34;:82} Bucket Aggregations Date Range Aggregation date_rangeで期間のBucketを作る。この例だと今から10分前の00秒~今の分の00秒まで。
$ curl localhost:9200/hoge/_search -d&amp;#39; { &amp;#34;aggs&amp;#34;: { &amp;#34;range_10minutes&amp;#34;: { &amp;#34;date_range&amp;#34;: { &amp;#34;field&amp;#34;: &amp;#34;@timestamp&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;HH-mm-ssZ&amp;#34;, &amp;#34;ranges&amp;#34;: [ { &amp;#34;to&amp;#34;: &amp;#34;now/m&amp;#34;, &amp;#34;from&amp;#34;: &amp;#34;now-10m/m&amp;#34; } ] } } } }&amp;#39; | jq .aggregations { &amp;#34;range_10minutes&amp;#34;: { &amp;#34;buckets&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;15-17+0000-15-27+0000&amp;#34;, &amp;#34;from&amp;#34;: 1488640620000, &amp;#34;from_as_string&amp;#34;: &amp;#34;15-17+0000&amp;#34;, &amp;#34;to&amp;#34;: 1488641220000, &amp;#34;to_as_string&amp;#34;: &amp;#34;15-27+0000&amp;#34;, &amp;#34;doc_count&amp;#34;: 600 } ] } } Date Histogram Aggregation date_histogramで日付の間隔でBucketを作る。この例だと1分ごとにBucketが作られる。
$ curl localhost:9200/hoge/_search -d&amp;#39; { &amp;#34;aggs&amp;#34;: { &amp;#34;histogram_1minute&amp;#34;: { &amp;#34;date_histogram&amp;#34;: { &amp;#34;field&amp;#34;: &amp;#34;@timestamp&amp;#34;, &amp;#34;interval&amp;#34;: &amp;#34;1m&amp;#34; } } } }&amp;#39; | jq .</description>
    </item>
    
    <item>
      <title>一定間隔でjsonデータを作って送り続けるCLIツールを作った</title>
      <link>https://www.sambaiz.net/article/76/</link>
      <pubDate>Sat, 04 Mar 2017 23:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/76/</guid>
      <description>Elasticsearchにリアルタイムなテストデータを投入するために、一定間隔でjsonを作って送り続けるCLIツールを作った。Go製。 urfave/cliを使った。
sambaiz/sendjson
こんなindexにデータを入れてみる。
$ curl -XPUT &amp;#39;http://localhost:9200/hoge&amp;#39; -d&amp;#39; { &amp;#34;mappings&amp;#34;: { &amp;#34;test_type&amp;#34;: { &amp;#34;_all&amp;#34;: { &amp;#34;enabled&amp;#34;: false }, &amp;#34;properties&amp;#34;: { &amp;#34;os_name&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;keyword&amp;#34; }, &amp;#34;score&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;byte&amp;#34; }, &amp;#34;@timestamp&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;date&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;epoch_second&amp;#34; } } } } } &amp;#39; こんな感じでキーに対してtypeと入る値を定義するとそれっぽいデータができて送られていく。
$ go install github.com/sambaiz/sendjson $ sendjson --interval 0.5s --duration 10s --url http://localhost:9200/hoge/test_type &amp;#39; { &amp;#34;os_name&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;or&amp;#34;: [&amp;#34;windows&amp;#34;, &amp;#34;mac&amp;#34;, &amp;#34;linux&amp;#34;, &amp;#34;ios&amp;#34;, &amp;#34;android&amp;#34;]}, &amp;#34;score&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;integer&amp;#34;, &amp;#34;min&amp;#34;: 0, &amp;#34;max&amp;#34;: 100}, &amp;#34;@timestamp&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;time&amp;#34;, &amp;#34;time_format&amp;#34;: &amp;#34;unix_epoch&amp;#34;} }&amp;#39; {&amp;#34;@timestamp&amp;#34;:1488635130,&amp;#34;os_name&amp;#34;:&amp;#34;linux&amp;#34;,&amp;#34;score&amp;#34;:82} {&amp;#34;@timestamp&amp;#34;:1488635130,&amp;#34;os_name&amp;#34;:&amp;#34;windows&amp;#34;,&amp;#34;score&amp;#34;:9} {&amp;#34;@timestamp&amp;#34;:1488635131,&amp;#34;os_name&amp;#34;:&amp;#34;windows&amp;#34;,&amp;#34;score&amp;#34;:73} {&amp;#34;@timestamp&amp;#34;:1488635131,&amp;#34;os_name&amp;#34;:&amp;#34;ios&amp;#34;,&amp;#34;score&amp;#34;:50} {&amp;#34;@timestamp&amp;#34;:1488635132,&amp;#34;os_name&amp;#34;:&amp;#34;windows&amp;#34;,&amp;#34;score&amp;#34;:69} .</description>
    </item>
    
    <item>
      <title>H2OでHTTPS-&gt;HTTPのリバースプロキシを立てる</title>
      <link>https://www.sambaiz.net/article/75/</link>
      <pubDate>Thu, 02 Mar 2017 20:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/75/</guid>
      <description>良くチューニングされたNginxと同じくらい速いと 評判のHTTP/2サーバーH2Oでリバースプロキシを立ててみる。 HTTP/2だけではなく1.xにも対応しているので古い環境などでも大丈夫。
設定は Reverse Proxyと HTTP to HTTPSの サンプルをもとにして書いた。
hosts: &amp;#34;*&amp;#34;: listen: port: 443 ssl: certificate-file: /etc/h2o/oreore.crt key-file: /etc/h2o/server.key paths: &amp;#34;/&amp;#34;: proxy.reverse.url: http://127.0.0.1:3000/ access-log: /dev/stdout error-log: /dev/stderr とりあえずオレオレ証明書で試してみる。
$ openssl genrsa 2048 &amp;gt; server.key # private key $ openssl req -new -key server.key &amp;gt; server.csr # certificate signing request $ openssl x509 -days 365000 -req -signkey server.key &amp;lt; server.csr &amp;gt; oreore.crt # oreore certificate Dockerで動かす。lkwg82/h2o.docker
$ vi h2o.conf $ docker run -v $(pwd):/etc/h2o --net=host --name h2o --restart=always -itd lkwg82/h2o-http2-server $ curl --insecure https://127.</description>
    </item>
    
    <item>
      <title>Goroutineの数をworkerで抑制する</title>
      <link>https://www.sambaiz.net/article/74/</link>
      <pubDate>Mon, 27 Feb 2017 23:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/74/</guid>
      <description>Goのnet/httpとKeep-Alive - sambaiz.netでやったように、 あるエンドポイントに連続してGoroutineでリクエストを投げると、リクエスト数を増やしたときにタイムアウトが頻発するようになった。
まず、2000リクエストを投げてみた結果。
[RESULT] request: 2000, ok: 2000, ng: 0, time(ms) 138 一応全部捌けてはいるが、おおよそ同時にリクエストを送っているのにタイムアウト(100ms)時間を超えてしまっている。これをさらに3000に増やしてみる。
[RESULT] request: 3000, ok: 13, ng: 2987, time(ms) 372 ほぼ全滅してしまった・・・。時間もおかしいのでGoroutineでの処理に遅延が発生しているようだ。 そこで、都度Goroutineを生成してリクエストを投げるのではなく、 一定数のWorkerに処理させることで、同時に作られるGoroutineの数を抑制する。
type Req struct { Okch chan int Ngch chan int } func startWorker(ctx context.Context, num int) (requestch chan *Req) { requestch = make(chan *Req) for i := 0; i &amp;lt; num; i++ { go func() { for { select { case req := &amp;lt;-requestch: request(req.</description>
    </item>
    
    <item>
      <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
      <link>https://www.sambaiz.net/article/73/</link>
      <pubDate>Sun, 26 Feb 2017 18:56:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/73/</guid>
      <description>aws-fluent-plugin-kinesisでKinesis Streamsに送り、Lambdaで読んでS3に保存する。 要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。
fluentdで送る $ td-agent-gem install fluent-plugin-kinesis try_flush_intervalとqueued_chunk_flush_intervalはドキュメントには載っていないが、 以下のページによるとそれぞれqueueに次のchunkがないときとあるときのflushする間隔。 いずれもデフォルトは1だが、これを減らすことでもっと頻繁に吐き出されるようになるらしい。
Fluentd の out_forward と BufferedOutput
あとシャードに振り分けるためのpartition_key を指定できる。デフォルトはランダム。
&amp;lt;source&amp;gt; @type tail path /var/log/td-agent/hoge.log pos_file /etc/td-agent/log.pos tag hoge.log format json time_key timestamp # 2017-01-01T01:01:01+0900 time_format %Y-%m-%dT%H:%M:%S%z &amp;lt;/source&amp;gt; &amp;lt;match hoge.log&amp;gt; @type kinesis_streams region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt; いくつか送ってみる。
for i in `seq 1 1000` do echo &amp;#39;{&amp;#34;hoge&amp;#34;: &amp;#34;fuga&amp;#34;, &amp;#34;timestamp&amp;#34;: &amp;#34;2017-01-01T01:01:01+0900&amp;#34;}&amp;#39; &amp;gt;&amp;gt; /var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>AWSのAssumeRole</title>
      <link>https://www.sambaiz.net/article/72/</link>
      <pubDate>Sat, 25 Feb 2017 20:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/72/</guid>
      <description>AWS Security Token Serviceによる、 RoleArn(arn:aws:iam::&amp;lt;account id&amp;gt;:role/&amp;lt;role name&amp;gt;)から一時的なCredentialを取得する仕組み。 前もって発行したAPIキーとは違い、有効期限が存在するため続けて呼ぶ場合は失効する前に再発行する必要がある。
ではRoleArnを知っていたら誰でも取得できるかというと、もちろんそうではなく、 ロールの信頼関係、&amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;のPrincipalのところで信頼する対象を設定する。 例えば、Serviceでec2.amazonaws.comを指定してEC2がAssumeRoleするのを許可したり、 AWSで(他の)アカウントやユーザーを指定してそのAPIキーでこのRoleのCredentialを取得できるようにしたりといった感じ。
{ &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Principal&amp;#34;: { &amp;#34;Service&amp;#34;: &amp;#34;ec2.amazonaws.com&amp;#34; }, &amp;#34;Action&amp;#34;: &amp;#34;sts:AssumeRole&amp;#34; } ] } EC2にロールを設定すると、実はそのロールについてAssumeRoleして自動でCredentialを取得している。 EC2にロールを設定するにはロールとは別に インスタンスプロファイルを作成 する必要があるが、コンソールでEC2のサービスロールを作ると同名のインスタンスプロファイルが自動で作成される。 さらに、AssumeRoleのServiceとしてec2.amazonaws.comが追加されている。
$ curl http://169.254.169.254/latest/meta-data/iam/info { &amp;#34;Code&amp;#34; : &amp;#34;Success&amp;#34;, &amp;#34;LastUpdated&amp;#34; : &amp;#34;2017-02-25T10:56:33Z&amp;#34;, &amp;#34;InstanceProfileArn&amp;#34; : &amp;#34;arn:aws:iam::*****:instance-profile/assume_role_test&amp;#34;, &amp;#34;InstanceProfileId&amp;#34; : &amp;#34;*****&amp;#34; } $ curl http://169.254.169.254/latest/meta-data/iam/security-credentials/assume_role_test { &amp;#34;Code&amp;#34; : &amp;#34;Success&amp;#34;, &amp;#34;LastUpdated&amp;#34; : &amp;#34;2017-02-25T10:56:23Z&amp;#34;, &amp;#34;Type&amp;#34; : &amp;#34;AWS-HMAC&amp;#34;, &amp;#34;AccessKeyId&amp;#34; : &amp;#34;*****&amp;#34;, &amp;#34;SecretAccessKey&amp;#34; : &amp;#34;*****&amp;#34;, &amp;#34;Token&amp;#34; : &amp;#34;*****&amp;#34;, &amp;#34;Expiration&amp;#34; : &amp;#34;2017-02-25T17:26:07Z&amp;#34; } 参考 IAMロール徹底理解 〜 AssumeRoleの正体 ｜ Developers.</description>
    </item>
    
    <item>
      <title>ElasticsearchのCircuit Breaker</title>
      <link>https://www.sambaiz.net/article/71/</link>
      <pubDate>Fri, 24 Feb 2017 21:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/71/</guid>
      <description>ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net
ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。 表示されたエラーはこういうの。
&amp;#34;root_cause&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;circuit_breaking_exception&amp;#34;, &amp;#34;reason&amp;#34;: &amp;#34;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;#34;, &amp;#34;bytes_wanted&amp;#34;: 10464007168, &amp;#34;bytes_limit&amp;#34;: 8998512230 } ], これは1リクエストの集計などで使うメモリ量がしきい値をこえて Circuit Breakerが発動したということ。 メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。
情報はstatsのapiでも取得できる。
$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request { &amp;#34;limit_size_in_bytes&amp;#34;: 8998512230, &amp;#34;limit_size&amp;#34;: &amp;#34;8.3gb&amp;#34;, &amp;#34;estimated_size_in_bytes&amp;#34;: 10348347504, &amp;#34;estimated_size&amp;#34;: &amp;#34;9.6gb&amp;#34;, &amp;#34;overhead&amp;#34;: 1, &amp;#34;tripped&amp;#34;: 470 } 今回ひっかかったのはindices.breaker.request.limit。デフォルトではJVMのヒープメモリの60%になっているが、 これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。
$ curl -XPUT localhost:9200/_cluster/settings -d &amp;#39;{ &amp;#34;persistent&amp;#34; : { &amp;#34;indices.breaker.request.limit&amp;#34;: &amp;#34;80%&amp;#34;, &amp;#34;indices.breaker.total.limit&amp;#34;: &amp;#34;80%&amp;#34; } }&amp;#39; $ curl -XPUT localhost:9200/_cluster/settings -d &amp;#39;{ &amp;#34;persistent&amp;#34; : { &amp;#34;indices.</description>
    </item>
    
    <item>
      <title>crontabのメモ</title>
      <link>https://www.sambaiz.net/article/70/</link>
      <pubDate>Fri, 24 Feb 2017 21:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/70/</guid>
      <description>各ユーザーごとのcron設定。crontab -eでも編集できるが、間違えて-rにすると全部消えてしまうのでこういう風に一旦取り出してから編集すると安全。
$ crontab -l &amp;gt; ~/crontab $ echo &amp;#34;*/1 * * * * /hoge/fuga.sh&amp;#34; &amp;gt;&amp;gt; ~/crontab $ crontab &amp;lt; ~/crontab $ crontab -l */1 * * * * /hoge/fuga.sh 参考 cron 設定ファイル (crontab ファイル) の置き場所と書式について - ひだまりソケットは壊れない</description>
    </item>
    
    <item>
      <title>Cookieのメモ</title>
      <link>https://www.sambaiz.net/article/69/</link>
      <pubDate>Wed, 22 Feb 2017 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/69/</guid>
      <description>https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies
レスポンスにSet-Cookieヘッダーが含まれていればブラウザはcookieに保存する。
HTTP/1.0 200 OK Content-type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry リクエスト時にはCookieヘッダーにcookieを入れて送る。
GET /sample_page.html HTTP/1.1 Host: www.example.org Cookie: yummy_cookie=choco; tasty_cookie=strawberry CookieにExpire(ある期間まで有効)またはMax-Age(特定の期間の間有効)を設定するとPermanent cookieとなる。 いずれも設定しなかった場合Session cookieとなり、ブラウザを閉じると削除されることになっているが、 ブラウザのセッション復元機能が有効になっていれば永続化される。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secureを付けるとHTTPSでのみ送られる。 また、HttpOnlyはjsからdocument.cookieなどでアクセスすることができなくなる。 サイトにXSSの脆弱性があるとき、cookieが盗まれてしまうのを防ぐことができるので問題なければ設定するべき。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly Domainを指定するとそのドメインとサブドメインへのリクエストのときに送られる。しないとそのドメインだけ。Pathも指定できる。
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Domain=example.com; Path=/ リクエストが飛び、Set-Cookieヘッダーを受け取ればCookieに書かれるので、アクセスしたサイトのドメイン以外のCookieが書かれることがある。 このようなCookieを3rd party cookieといって、広告のトラッキングによく使われるが、 Safariなどのデフォルト設定では書き込めなくなっている。</description>
    </item>
    
    <item>
      <title>ELBのスケーリングとsurge queue</title>
      <link>https://www.sambaiz.net/article/68/</link>
      <pubDate>Tue, 21 Feb 2017 19:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/68/</guid>
      <description>バックエンドだけではなくELB自体もスケーリングし、内部node数はdigで調べることができる。 このnode数は自分ではコントロールできず、基本的に意識することはない。
$ dig ****.ap-northeast-1.elb.amazonaws.com ;; ANSWER SECTION: *****.elb.amazonaws.com. 60 IN A xxx.xxx.xxx.xxx *****.elb.amazonaws.com. 60 IN A yyy.yyy.yyy.yyy nodeが増えるのにはある程度時間がかかるので、 アクセスが急増(5分間で50%以上のトラフィック増加が目安) したら捌ききれず、503を返すことがある。 前もって多量のアクセスが来ることが分かっていて、 AWSサポートがBusiness以上なら pre-warming申請することでnodeが増えた状態で待ち構えられる。
バックエンドのアプリケーションがリクエストを処理できない場合、ELBのsurge queueに溜まっていく。 この数はCloudWatchのSurgeQueueLength(キュー長の急増)メトリクスで確認できる。 また、SurgeQueueLengthの最大値1024を超えるとリクエストは拒否され、その数はSpoiloverCount(過剰数)メトリクスに出る。
参考 ELBの挙動とCloudWatchメトリクスの読み方を徹底的に理解する ｜ Developers.IO
Elastic Load Balancing でのレイテンシーのトラブルシューティング</description>
    </item>
    
    <item>
      <title>Kinesis Streams/Firehose/Analyticsを試す</title>
      <link>https://www.sambaiz.net/article/67/</link>
      <pubDate>Mon, 20 Feb 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/67/</guid>
      <description>https://aws.amazon.com/jp/kinesis/
リアルタイムのストリーミングデータを扱うサービス群。 いまのところTokyoリージョンではKinesis Streamsしか使えない。
Kinesis Firehose AWSのデータストアに送るストリーム。自分でデータを読む処理を書かなくてよく、スケーリングも勝手にやってくれるので簡単に使える。
https://aws.amazon.com/jp/kinesis/firehose/faqs/
Q: 送信先とは何ですか? 送信先はデータが配信されるデータストアです。Amazon Kinesis Firehose では、 現在送信先として Amazon S3、Amazon Redshift、Amazon Elasticsearch Service がサポートされています。 料金は取り込まれたデータ量による。 一見そんなに高くならないように見えるが、5KB単位で切り上げられるのでレコードのサイズが小さくて数が多い場合に注意が必要。
今回はS3に送ってみる。
圧縮方法を設定したり、Lambdaを噛ませたりすることができる。
StatusがActiveになったらKinesis Agentで送ってみる。 CloudWatchとFirehoseにPutする権限が必要。Firehoseはkinesis:ではなくfirehose:なので注意。
$ sudo yum install –y aws-kinesis-agent /etc/aws-kinesis/agent.jsonを編集する。リージョンごとのエンドポイントは ここ にある。
{ &amp;#34;awsAccessKeyId&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;awsSecretAccessKey&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;firehose.endpoint&amp;#34;: &amp;#34;https://firehose.us-east-1.amazonaws.com&amp;#34;, &amp;#34;flows&amp;#34;: [ { &amp;#34;filePattern&amp;#34;: &amp;#34;/tmp/hoge.log&amp;#34;, &amp;#34;deliveryStream&amp;#34;: &amp;#34;hogefugastream&amp;#34; } ] } $ sudo service aws-kinesis-agent start $ sudo chkconfig aws-kinesis-agent on $ echo &amp;#34;aaa&amp;#34; &amp;gt;&amp;gt; /tmp/hoge.log $ tail /var/log/aws-kinesis-agent/aws-kinesis-agent.</description>
    </item>
    
    <item>
      <title>fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する</title>
      <link>https://www.sambaiz.net/article/66/</link>
      <pubDate>Sun, 19 Feb 2017 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/66/</guid>
      <description>fluentdのmonitor_agent メトリクスをjsonで返すAPIを提供する。
&amp;lt;source&amp;gt; @type monitor_agent bind 0.0.0.0 port 24220 &amp;lt;/source&amp;gt; $ curl localhost:24220/api/plugins.json | jq { &amp;#34;plugins&amp;#34;: [ { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590d8c250&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;input&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;forward&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;forward&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;24222&amp;#34;, &amp;#34;bind&amp;#34;: &amp;#34;0.0.0.0&amp;#34; }, &amp;#34;output_plugin&amp;#34;: false, &amp;#34;retry_count&amp;#34;: null }, { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590d894c4&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;input&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;monitor_agent&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;monitor_agent&amp;#34;, &amp;#34;bind&amp;#34;: &amp;#34;0.0.0.0&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;24220&amp;#34; }, &amp;#34;output_plugin&amp;#34;: false, &amp;#34;retry_count&amp;#34;: null }, { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590dc1f2c&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;output&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>Goのselectの中断処理(close, context)</title>
      <link>https://www.sambaiz.net/article/65/</link>
      <pubDate>Thu, 16 Feb 2017 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/65/</guid>
      <description>close(chan) closeしたチャネルを読むとゼロ値になるので、selectで待っているやつにまとめて送れる。
func main() { done := make(chan bool) wg := new(sync.WaitGroup) waitTillDone(wg, done) waitTillDone(wg, done) // こんなことしなくていい 	// done &amp;lt;- true 	// done &amp;lt;- true  close(done) wg.Wait() } func waitTillDone(wg *sync.WaitGroup, done &amp;lt;-chan bool) { wg.Add(1) go func() { select { case v := &amp;lt;-done: fmt.Println(v) // false (ゼロ値) 	wg.Done() } }() } context key-valueの値を渡せるほかにキャンセルやタイムアウトの仕組みをもつ。
ctx := context.Background() // empty context ctx, cancel = context.WithCancel(ctx) ctx, cancel = context.</description>
    </item>
    
    <item>
      <title>fluentd自身のログを拾う</title>
      <link>https://www.sambaiz.net/article/64/</link>
      <pubDate>Tue, 14 Feb 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/64/</guid>
      <description>fluentdは自身のログもfluent.errorのようなタグでイベントとして流す。
バッファを0にして意図的にエラーを発生させてみる。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; # throw away &amp;lt;match fluent.info&amp;gt; @type null &amp;lt;/match&amp;gt; &amp;lt;match fluent.**&amp;gt; @type stdout &amp;lt;/match&amp;gt; # error! &amp;lt;match **&amp;gt; @type file path /var/log/td-agent/hoge.log buffer_chunk_limit 0 buffer_queue_limit 0 &amp;lt;/match&amp;gt; すると、こんなのがtd-agent.logに出力される。
fluent.error: {&amp;#34;error&amp;#34;:&amp;#34;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;#34;,&amp;#34;error_class&amp;#34;:&amp;#34;Fluent::BufferQueueLimitError&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;#34;} ただ、これだとaggregatorに集めたときにどのサーバーのfluentdに問題が発生してるのか分からない。 そこでホスト名を追加する。
fluentdのrecord_transformerでログを加工する - sambaiz.net
&amp;lt;filter fluent.**&amp;gt; @type record_transformer enable_ruby &amp;lt;record&amp;gt; hostname &amp;#34;#{Socket.gethostname}&amp;#34; tag ${tag} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; fluent.error: {&amp;#34;error&amp;#34;:&amp;#34;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;#34;,&amp;#34;error_class&amp;#34;:&amp;#34;Fluent::BufferQueueLimitError&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;#34;, &amp;#34;hostname&amp;#34;:&amp;#34;*****&amp;#34;,&amp;#34;tag&amp;#34;:&amp;#34;fluent.</description>
    </item>
    
    <item>
      <title>GoでDynamoDBを使う</title>
      <link>https://www.sambaiz.net/article/63/</link>
      <pubDate>Sun, 12 Feb 2017 23:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/63/</guid>
      <description>テーブルを作成する プライマリキー テーブルの操作のガイドライン - Amazon DynamoDB
プライマリキーとしてパーティションキー(ハッシュキー)とオプションのソートキー(レンジキー)を設定する。 DynamoDBはこのパーティションキーに基づいて、複数のパーティションに分散して保存する。 テーブルにプロビジョニングされたスループット性能はパーティション間で均等に使われるので、 ソートキーを設定する場合にこれを最大限に活用するためには、 あるパーティションにリクエストが集中しないよう、パーティションキーに特定の値ばかり集中しないようなフィールドを 選ぶ必要がある。
セカンダリインデックス パーティションキーのグローバルセカンダリインデックス(GSI)と ソートキーのローカルセカンダリインデックス(LSI)がある。 射影されるフィールドを選択でき、ここに含まれないフィールドは返さない。 ただし、すべてをインデックスに書き込むのはコストが高いのでなるべく絞る。
キャパシティユニット  1読み込みキャパシティユニット: 4kbを超えないデータを1秒に1~2回(整合性による)読み込める 1書き込みキャパシティユニット: 1kbを超えないデータを1秒に1回書き込める  ユニットに応じて1時間あたりで課金される。
未使用のキャパシティがある場合、最大5分保持してバーストに備えてくれる。
読み書きする aws-sdk-goを直接使ってもいいが、簡単に扱えるラッパー guregu/dynamo を使うことにした。
type Data struct { ID int64 `dynamo:&amp;#34;id&amp;#34;` Name string Age int } db := dynamo.New(session.New(), &amp;amp;aws.Config{Region: aws.String(&amp;#34;ap-northeast-1&amp;#34;)}) table := db.Table(&amp;#34;testtable&amp;#34;) Create &amp;amp; Update d := Data{ID: 1, Name: &amp;#34;hogefuga&amp;#34;, Age: 123} if err := table.Put(d).Run(); err != nil { return err } if err := table.</description>
    </item>
    
    <item>
      <title>Elasticsearchのmapping</title>
      <link>https://www.sambaiz.net/article/62/</link>
      <pubDate>Thu, 09 Feb 2017 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/62/</guid>
      <description>Dynamic mappingがあるので、自分で設定しなくてもデータは入るが、 自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。 バージョンは5.2。
$ curl -XPOST &amp;#39;localhost:9200/test_hoge/fuga?pretty&amp;#39; -d&amp;#39; { &amp;#34;name&amp;#34;: 0 } &amp;#39; $ curl -XPOST &amp;#39;localhost:9200/test_hoge/fuga?pretty&amp;#39; -d&amp;#39; { &amp;#34;name&amp;#34;: &amp;#34;sambaiz&amp;#34; } &amp;#39; { &amp;#34;error&amp;#34; : { &amp;#34;root_cause&amp;#34; : [ { &amp;#34;type&amp;#34; : &amp;#34;mapper_parsing_exception&amp;#34;, &amp;#34;reason&amp;#34; : &amp;#34;failed to parse [name]&amp;#34; } ], &amp;#34;type&amp;#34; : &amp;#34;mapper_parsing_exception&amp;#34;, &amp;#34;reason&amp;#34; : &amp;#34;failed to parse [name]&amp;#34;, &amp;#34;caused_by&amp;#34; : { &amp;#34;type&amp;#34; : &amp;#34;number_format_exception&amp;#34;, &amp;#34;reason&amp;#34; : &amp;#34;For input string: \&amp;#34;sambaiz\&amp;#34;&amp;#34; } }, &amp;#34;status&amp;#34; : 400 } Mapping parameters index falseにするとindexしない。クエリで必要ないものはfalseにする。</description>
    </item>
    
    <item>
      <title>Goのnet/httpとKeep-Alive</title>
      <link>https://www.sambaiz.net/article/61/</link>
      <pubDate>Tue, 07 Feb 2017 22:42:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/61/</guid>
      <description>Keep-AliveするとTCPコネクションを使い回し、名前解決やコネクション(3 way handshake)を毎回行わなくてよくなる。 Goのnet/httpではデフォルトでKeep-Aliveが 有効になっているが、 全体と同一ホストでそれぞれKeep-Aliveするコネクション数が制限される。 これらの値はClientのTransportが持っていて、 これがnullだとDefaultTransportが参照されるので、意識しなければこの値が使われる。
 MaxIdleConns: DefaultTransportでは100になっている。0にすると無制限。 MaxIdleConnsPerHost: デフォルト値は2。0にするとデフォルト値が使われる。  同一のホストに同時にたくさんリクエストする場合、2だとほとんど意味を持たない。これを増やして比較してみた。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;time&amp;#34; ) var client = http.Client{ Timeout: time.Millisecond * 100, } const TOTAL_REQUEST_NUM = 3000 const TARGET_URL = &amp;#34;*****&amp;#34; func main() { http.DefaultTransport.(*http.Transport).MaxIdleConns = 0 http.DefaultTransport.(*http.Transport).MaxIdleConnsPerHost = 3000 okChan := make(chan int, TOTAL_REQUEST_NUM) ngChan := make(chan int, TOTAL_REQUEST_NUM) var okCount = 0 var ngCount = 0 // connect and keep-alive 	for i := 0; i &amp;lt; TOTAL_REQUEST_NUM; i++ { go request(okChan, ngChan) } for { select { case &amp;lt;-okChan: okCount++ case &amp;lt;-ngChan: ngCount++ } if okCount+ngCount == TOTAL_REQUEST_NUM { break } } okCount = 0 ngCount = 0 startNs := time.</description>
    </item>
    
    <item>
      <title>iftopでネットワークの帯域を見る</title>
      <link>https://www.sambaiz.net/article/60/</link>
      <pubDate>Tue, 07 Feb 2017 20:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/60/</guid>
      <description>$ yum install --enablerepo=epel iftop $ iftop -f &amp;#34;not dst net 10.0.0.0/8&amp;#34; -i eth0のようにしてインタフェースを指定し、-fでフィルタをかけられる。フィルタの詳細はman pcap-filterで。
12.5Kb 25.0Kb 37.5Kb 50.0Kb	62.5Kb └─────────────────────────┴──────────────────────────┴──────────────────────────┴──────────────────────────┴────────────────────────── ip-172-31-9-9.ap-northeast-1.compute.internal =&amp;gt; 61-121-217-66.dh-connect.net 1.72Kb 6.57Kb 2.40Kb &amp;lt;= 416b 2.13Kb 702b ... ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── TX: cum: 22.6KB peak: 13.2Kb rates: 1.22Kb 1.27Kb 2.46Kb RX: 6.63KB 5.03Kb 208b 330b 748b TOTAL: 29.2KB 18.2Kb 1.42Kb 1.59Kb 3.19Kb 左から2, 10, 40秒間の平均kbps。TXが送信量、RXが受信量で、cumが総量、peakが最大。
実行中にSでソースのポートをDでディスティネーションのポートが表示される。</description>
    </item>
    
    <item>
      <title>vmstatのメモ</title>
      <link>https://www.sambaiz.net/article/59/</link>
      <pubDate>Mon, 06 Feb 2017 22:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/59/</guid>
      <description>$ vmstat 間隔(秒) procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 118588 80388 2516284 0 0 2 77 141 85 1 0 98 0 0 procs   r: 実行待ちプロセス数。CPUの処理が追いついていない。
  b: 割り込み不可能なスリープ中のプロセス数。I/O待ちらしい。
  memory   swpd: バーチャルメモリの使用量。
  free: 空きメモリ量。
  buff: バッファに使われてるメモリ量。
  cache: キャッシュに使われているメモリ量。</description>
    </item>
    
    <item>
      <title>EC2のインスタンスストア</title>
      <link>https://www.sambaiz.net/article/58/</link>
      <pubDate>Mon, 06 Feb 2017 21:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/58/</guid>
      <description>http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/InstanceStorage.html
EC2ではインスタンスタイプによってはEBSに加えてインスタンスストアが使える。しかも追加料金なし。 対象はストレージが&amp;quot;EBSのみ&amp;quot;でないもの。
https://aws.amazon.com/jp/ec2/instance-types/
インスタンスストアはインスタンスが停止したり、障害が起きると消える一時ストレージ。再起動では消えない。 ホストに物理的にアタッチされているので、バッファやキャッシュなどの頻繁に読み書きされ、消えてもいいデータに最適。 他のインスタンスにアタッチすることはできない。容量や性能もインスタンスタイプに依存する。
インスタンスストアボリュームの追加は インスタンスの起動時に、新しいボリュームを追加し、ボリュームタイプをインスタンスストアにすることで行うことができる。
今回はSSDストレージ1 x 4のm3.mediumで試す。これは4gbのボリュームが一つ追加できるという意味。
まずはインスタンスストアを追加してないインスタンス。 lsblkというのはlist block devicesの略。
$ df -h ファイルシス サイズ 使用 残り 使用% マウント位置 /dev/xvda1 7.8G 1.2G 6.6G 15% / ... $ dd if=/dev/zero of=hoge bs=1M count=1000 $ ls -sh 合計 1001M 1001M hoge $ df -h ファイルシス サイズ 使用 残り 使用% マウント位置 /dev/xvda1 7.8G 2.2G 5.6G 28% / ... $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 8G 0 disk └─xvda1 202:1 0 8G 0 part / それに対してインスタンスストア(/dev/xvdb)を追加したインスタンス。</description>
    </item>
    
    <item>
      <title>HoloLensでGaze, Click, Hold, Voiceイベントを拾う</title>
      <link>https://www.sambaiz.net/article/57/</link>
      <pubDate>Sun, 05 Feb 2017 20:01:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/57/</guid>
      <description>こんなの。SparitalMappingを有効にしているので球が床で止まっている。
動画
HoloToolKit のインタフェースを実装することでイベントを拾えるようになっている。
IFocusable Gazeしたとき。
public void OnFocusEnter（） { gazing = true; } public void OnFocusExit() { gazing = false; } IInputClickHandler クリックしたとき。
public void OnInputClicked(InputEventData eventData) { if (!clicked) { clicked = true; clickedRotationFrame = 0; } countUp(); } IHoldHandler Hold(指を下げたまま維持する)したとき。 指を上げたときがCompletedで、Objectを外れたときCanceledになる。
public void OnHoldStarted(HoldEventData eventData) { holding = true; clicked = true; } public void OnHoldCompleted(HoldEventData eventData) { holding = false; } public void OnHoldCanceled(HoldEventData eventData) { holding = false; } ISpeechHandler 声の入力。 InspectorからSpeech Input Source(Script)を追加して反応するキーワードを設定して使う。 MicrophoneのCapabilitiesが必要。</description>
    </item>
    
    <item>
      <title>HoloLensの開発を始める</title>
      <link>https://www.sambaiz.net/article/56/</link>
      <pubDate>Sat, 04 Feb 2017 21:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/56/</guid>
      <description>HoloLensでのアプリケーション https://developer.microsoft.com/en-us/windows/holographic/app_model
ある点を見るGazeと指で選択するGesture、声で入力するVoiceで操作する。
HoloLens shell では壁などにタイルを配置することでアプリケーションが起動する。
一度に動くアプリケーションは一つ。 他にアクティブなアプリケーションがあれば中断され、タイルは最後の状態のスクリーンショットになる。 タイルを削除するとプロセスが終了する。
Viewには空間全体を使うHolographic Viewと、通常のウィンドウのような2D Viewがある。
開発を始める Unityを使ってHolographic Viewのアプリケーションを開発する。
必要なツールをインストールする。エミュレーターは空きメモリが2GB以上ないと立ち上がらない。
https://developer.microsoft.com/en-us/windows/holographic/install_the_tools
チュートリアル https://developer.microsoft.com/en-us/windows/holographic/holograms_100
QualityのところでWindows Storeのマークがなかったら、 UnityのFile-&amp;gt;Build SettingsからWindows Storeモジュールをダウンロードする。
https://developer.microsoft.com/en-us/windows/holographic/holograms_101e
エミュレーターはWASDキーで移動してカーソルキーで向きを変え、エンターキーで選択できる。
エミュレーターで動かしてみる UnityProjectを作成してHolograms 100のように設定していく。
まずはCamera。
 Position: (0,0,0) Clear Flags: Solid Color Background: (0,0,0,0) Clipping Planes Near: 0.85  とりあえず動くことを確認するため適当なオブジェクトを置いてビルドしてみる。
Edit-&amp;gt;Project Settings-&amp;gt;QualityでWindows StoreをFastestにする。
Build Settings-&amp;gt;Windows Storeで
 SDK: Universal: 10 Target device: HoloLens UWP Build Type: D3D Unity C# Projectにチェック  にする。
BuildSettingsにあるPlayer Settingsボタンを押して Other SettingsのVirtual Reality Supportedにチェックを入れ、 SDKsにWindows Holographicが出るのを確認する。</description>
    </item>
    
    <item>
      <title>fluentdのrecord_transformerでログを加工する</title>
      <link>https://www.sambaiz.net/article/55/</link>
      <pubDate>Fri, 03 Feb 2017 21:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/55/</guid>
      <description>http://docs.fluentd.org/v0.12/articles/filter_record_transformer
追加したり、編集したり、削除したりできるフィルタ。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;filter hoge.log&amp;gt; @type record_transformer enable_ruby auto_typecast true remove_keys b,d &amp;lt;record&amp;gt; what_is_tag ${tag} what_is_a ${record[&amp;#34;a&amp;#34;]} what_is_c_of_b_add_1 ${record[&amp;#34;b&amp;#34;][&amp;#34;c&amp;#34;] + 1} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; &amp;lt;match hoge.log&amp;gt; @type stdout &amp;lt;/match&amp;gt; この例だとタグを値に持つ&amp;quot;what_is_tag&amp;quot;、aを値に持つ&amp;quot;what_is_a&amp;quot;、b.cの値に1を足す&amp;quot;what_is_c_of_b_add_1&amp;quot;が追加され、 bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。
auto_typecastをtrueにしないと&amp;quot;what_is_c_of_b_add_1&amp;quot;の値がstringになる。
$ echo &amp;#39;{&amp;#34;a&amp;#34;: &amp;#34;hoge&amp;#34;, &amp;#34;b&amp;#34;: {&amp;#34;c&amp;#34;: 1}, &amp;#34;d&amp;#34;: &amp;#34;fuga&amp;#34;}&amp;#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.log hoge.log: {&amp;#34;a&amp;#34;:&amp;#34;hoge&amp;#34;,&amp;#34;what_is_tag&amp;#34;:&amp;#34;hoge.log&amp;#34;,&amp;#34;what_is_a&amp;#34;:&amp;#34;hoge&amp;#34;,&amp;#34;what_is_c_of_b_add_1&amp;#34;:2} エラーが起きるとnullになるが、それ以外の処理はされる。
$ echo &amp;#39;{&amp;#34;a&amp;#34;: &amp;#34;hoge&amp;#34;, &amp;#34;b&amp;#34;: {&amp;#34;c&amp;#34;: &amp;#34;error!&amp;#34;}, &amp;#34;d&amp;#34;: &amp;#34;fuga&amp;#34;}&amp;#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.</description>
    </item>
    
    <item>
      <title>fluentdでElasticsearchに送る</title>
      <link>https://www.sambaiz.net/article/54/</link>
      <pubDate>Wed, 01 Feb 2017 21:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/54/</guid>
      <description>uken/fluent-plugin-elasticsearch
必要なものをいれていく。Amazon LinuxのAMIから。
 Failed to build gem native extension.  $ yum install -y ruby-devel  serverengine requires Ruby version &amp;gt;= 2.1.0.  rbenvでバージョンを上げる。
$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv $ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src $ echo &amp;#39;export PATH=&amp;#34;$HOME/.rbenv/bin:$PATH&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile $ ~/.rbenv/bin/rbenv init $ echo &amp;#39;eval &amp;#34;$(rbenv init -)&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile $ source ~/.bash_profile $ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build $ rbenv -v rbenv 1.1.0-2-g4f8925a  Ruby install aborted due to missing extensions  $ yum install -y openssl-devel readline-devel zlib-devel $ rbenv install -l 1.</description>
    </item>
    
    <item>
      <title>Goのnet/http.Client.Doの内部実装をたどったメモ</title>
      <link>https://www.sambaiz.net/article/53/</link>
      <pubDate>Mon, 30 Jan 2017 20:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/53/</guid>
      <description>package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;io/ioutil&amp;#34; ) var client = http.Client{} func main() { req, err := http.NewRequest(&amp;#34;GET&amp;#34;, &amp;#34;http://example.com&amp;#34;, nil) if err != nil{ panic(err) } resp, err := client.Do(req) if err != nil{ panic(err) } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil{ panic(err) } fmt.Println(string(body)) } Client TransportがTCPコネクションをキャッシュするのでClientは使い回すべき。複数のgoroutineでコンカレントに使っても大丈夫。
https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36
type Client struct { // nilならDefaultTransportが使われる  Transport RoundTripper // nilなら10回で止まる  CheckRedirect func(req *Request, via []*Request) error // nilならcookieは無視される  Jar CookieJar Timeout time.</description>
    </item>
    
    <item>
      <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
      <link>https://www.sambaiz.net/article/52/</link>
      <pubDate>Sun, 29 Jan 2017 17:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/52/</guid>
      <description>https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
vm.max_map_count (バーチャルメモリにマッピングできる最大ページ数) を262144以上にする。
$ sysctl vm.max_map_count $ grep vm.max_map_count /etc/sysctl.conf vm.max_map_count=262144 # sysctl -w vm.max_map_count=262144 30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。
-cap-add=IPC_LOCKでLock memory(スワップアウトしないようにする)を 許可する。
https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html
ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。 ただし、物理RAMの50%以下で、32GB近辺の境界を超えないようにする。
$ mkdir -p ~/do/elasticsearch/data $ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \ --name elasticsearch \ -p 9200:9200 \ -e xpack.security.enabled=false \ -e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;#34;-Xms28g -Xmx28g&amp;#34; \ --cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \ --restart=always \ docker.elastic.co/elasticsearch/elasticsearch:5.1.2 $ docker volume ls local elasticsearch 問題なく起動しているか確認する。
$ curl localhost:9200 | jq { &amp;#34;name&amp;#34;: &amp;#34;eqIkJ48&amp;#34;, &amp;#34;cluster_name&amp;#34;: &amp;#34;docker-cluster&amp;#34;, &amp;#34;cluster_uuid&amp;#34;: &amp;#34;Lsu_C7wORS6G-0m9PJ9sFQ&amp;#34;, &amp;#34;version&amp;#34;: { &amp;#34;number&amp;#34;: &amp;#34;5.</description>
    </item>
    
    <item>
      <title>fluentdのforward</title>
      <link>https://www.sambaiz.net/article/51/</link>
      <pubDate>Wed, 25 Jan 2017 22:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/51/</guid>
      <description>td-agent間でログをやりとりするとき に使われるforwardについて。内部ではMessagePackを使っている。
forward input http://docs.fluentd.org/articles/in_forward
受け取る側。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;match **&amp;gt; @type stdout &amp;lt;/match&amp;gt; /etc/init.d/td-agent restartしてfluent-catで送ってみる。
$ echo &amp;#39;{&amp;#34;hoge&amp;#34;: &amp;#34;fuga&amp;#34;}&amp;#39; | /opt/td-agent/embedded/bin/fluent-cat -h xx.xx.xx.xx test.tag /var/log/td-agent/td-agent.logに出力される。
test.tag: {&amp;#34;hoge&amp;#34;:&amp;#34;fuga&amp;#34;} forward output http://docs.fluentd.org/articles/out_forward
http://docs.fluentd.org/articles/buffer-plugin-overview
送る側。
ポートはデフォルトで24224で、イベントの送信にTCPを、heartbeatにUDP(heartbeat_typeで変えられる)を使う。
flush_intervalははデフォルトで60秒。 確認のときは短くしておくと分かりやすい。 buffer_queueの一番上のチャンクがこの時間経過するか、サイズがbuffer_chunk_limitを超えると、一番下のチャンクが書き込まれ、新しいチャンクがpushされる。 chunkの数がbuffer_queue_limitに到達してしまうと新しいイベントは破棄されてしまうので リソースを圧迫(buffer_chunk_limit * buffer_queue_limit)しない程度に十分大きな数にしておき、 スパイクや障害時に備えておく。 buffer_typeはデフォルトがmemory。fileだとflush_at_shutdownのデフォルトがfalseなので注意。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;match **&amp;gt; @type forward flush_interval 1s buffer_type file buffer_path /var/log/td-agent/forward-buf flush_at_shutdown true buffer_chunk_limit 256m &amp;lt;server&amp;gt; name log_server host xx.</description>
    </item>
    
    <item>
      <title>Goのinterface/structの埋め込み</title>
      <link>https://www.sambaiz.net/article/50/</link>
      <pubDate>Wed, 18 Jan 2017 01:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/50/</guid>
      <description>Goには継承が存在しない。その代わりstructを埋め込み、委譲することができる。
https://golang.org/doc/effective_go.html#embedding
挙動 interfaceにinterfaceを埋め込む type I interface { Hoge() } type J interface { Fuga() } type K interface { I J } インタフェースKはIとJを合わせたものになる。IとJに重複する関数がある場合はエラーになる。
type L struct { } func (l L) Hoge() { fmt.Println(&amp;#34;hoge&amp;#34;) } func (l L) Fuga() { fmt.Println(&amp;#34;fuga&amp;#34;) } var k K k = L{} k.Hoge() k.Fuga() structにinterfaceを埋め込む type K interface { Hoge() Fuga() } type M struct { K } 埋め込むとm.Hoge()のように透過的にKを扱うことができるようになる。
m := M{L{}} m.Hoge() // m.</description>
    </item>
    
    <item>
      <title>Goのpanicとrecover</title>
      <link>https://www.sambaiz.net/article/49/</link>
      <pubDate>Tue, 17 Jan 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/49/</guid>
      <description>panic https://golang.org/pkg/builtin/#panic
panicは現在のgoroutineの通常の実行を停止する組み込み関数。 index out of rangeや invalid memory address or nil pointer dereference のときなどでも呼ばれる。
deferを実行して呼び出し元に戻り、panicの実行-&amp;gt;deferの実行-&amp;gt;呼び出し元に戻る、を繰り返して 最後まで戻ったらプログラムを終了し、panicに渡した引数と共にエラーをレポートする。
func main() { a() } func a() { defer fmt.Println(&amp;#34;a&amp;#34;) b() fmt.Println(&amp;#34;a2&amp;#34;) } func b() { defer fmt.Println(&amp;#34;b1&amp;#34;) panic(&amp;#34;b2&amp;#34;) defer fmt.Println(&amp;#34;b3&amp;#34;) } b1 a panic: b2 goroutine 1 [running]: panic(0x89840, 0xc42000a2c0) /*****/libexec/src/runtime/panic.go:500 +0x1a1 main.b() /*****/main.go:19 +0x107 main.a() /*****/main.go:13 +0xce main.main() /*****/main.go:8 +0x14 exit status 2 recover https://golang.org/pkg/builtin/#recover
deferで呼ぶことによってpanicを停止させることができる組み込み関数。 panicの引数に渡した値を取得できる。
func main() { fmt.Println(a()) fmt.</description>
    </item>
    
    <item>
      <title>OAuth2.0のメモ</title>
      <link>https://www.sambaiz.net/article/48/</link>
      <pubDate>Sun, 08 Jan 2017 02:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/48/</guid>
      <description>認可(Authorization)と認証(Authentication) それぞれAuthZ、AuthNとも書かれる。
 認可: リソースへのアクセスを許可する 認証: ユーザーが何者かを検証する  OAuth 2.0 認可のプロトコル。 それによってアクセスできるようになったリソースの情報をもとに認証を行ったりすることもあるが、 以下に示すImplicit Flowでそれをやると他のサービスのトークンで他人に成りすませてしまう問題があるため、 認証する場合はOAuth 2.0ベースの認証プロトコルのOpenID Connectを使うべき。 その場合もトークンを取得するまでの流れはほとんどOAuth 2.0通りなのでフローを理解しておいて無駄はない。
OpenID ConnectのIDトークンの内容と検証 - sambaiz-net
Authorization Code Flow  OAuthクライアントがアプリケーションサーバーのときのフロー。
まずユーザーがOAuth認可ページで認可する。 このリクエストには
 client_id redirect_uri scope: アクセスできるリソースの種類 response_type=code: 認可コードが返される state: CSRFを防ぐためのランダムで一意な文字列。アプリケーションサーバーが保持して、前後で一致するかチェックする  が含まれる。
認可されると認可コードとstateを付けてredirect_uri(事前に登録しておく)にリダイレクトするので、 アプリケーションサーバーは認可コードをアクセストークンに交換する。 この際、client_idとclient_secretも送る。
オプションでリフレッシュトークンを含み、これを使うと期限が切れたとき新しいアクセストークンを取得できる。
アクセストークンは通常Bearer Token(Authorization: Bearer ***)としてリクエストに含まれる。
Implicit Flow  OAuthクライアントがアプリなどでclient_secretの機密性を保てない場合のフロー。
認可コードは不要なのでresponse_type=tokenでリクエストし、アクセストークンをブラウザで取得する。 リフレッシュトークンは含まない。 他のサービスで発行された他人のトークンを使うことでなりすませてしまうので、 そのトークンがどのサービスに対して発行されたかを確認する術が特に用意されているのでなければ 認証に使ってはいけない。OpenID Connectでは署名されたIDトークンに発行されたサービスの情報が含まれている。
参考 O&amp;rsquo;Reilly Japan - OAuth 2.0をはじめよう
Implicit Flow では Covert Redirect で Token 漏れるね - OAuth.</description>
    </item>
    
    <item>
      <title>go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる</title>
      <link>https://www.sambaiz.net/article/47/</link>
      <pubDate>Wed, 04 Jan 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/47/</guid>
      <description>この関数のベンチマークを取る。
package cal import ( &amp;#34;math/big&amp;#34; ) var cache = map[int]*big.Int{} func resetCache() { cache = map[int]*big.Int{} } func Fibonacci(n int) *big.Int { if c := cache[n]; c != nil { return c } ret := new(big.Int) before := big.NewInt(1) for i := 1; i &amp;lt; n; i++ { tmp := new(big.Int).Add(ret, before) before = ret ret = tmp cache[i] = ret } cache[n] = ret return ret } 引数にtesting.Bを取る、Benchmarkから始まる関数を書いて、b.N回ループさせる。</description>
    </item>
    
    <item>
      <title>汎用シリアライズ方法(MessagePack/Protocol Buffers/FlatBuffers)</title>
      <link>https://www.sambaiz.net/article/46/</link>
      <pubDate>Fri, 30 Dec 2016 18:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/46/</guid>
      <description>MessagePackとは JSONのように使うことができ、速くてサイズが小さい。
{&amp;#34;compact&amp;#34;:true,&amp;#34;スキーマ&amp;#34;:{&amp;#34;number&amp;#34;: 999, &amp;#34;string&amp;#34;: &amp;#34;aaa&amp;#34;}} のjson(61bytes)をMessagePack(45bytes)に変換したのがこれ。見やすいように改行している。
82 a7 63 6f 6d 70 61 63 74 c3 ac e3 82 b9 e3 82 ad e3 83 bc e3 83 9e 82 a6 6e 75 6d 62 65 72 cd 03 e7 a6 73 74 72 69 6e 67 a3 61 61 61 一行目の82は要素数2のfixmap(要素数15まで)を表す。
二行目のa7が7バイトのfixstr(31bytesまで)で、 63 6f 6d 70 61 63 74が&amp;quot;compact&amp;quot;。c3はtrue。
三行目のacは12バイトのfixstrで、e3 82 b9 e3 82 ad e3 83 bc e3 83 9eが&amp;quot;スキーマ&amp;quot;。</description>
    </item>
    
    <item>
      <title>GoogleのkvsライブラリLevelDBを使う</title>
      <link>https://www.sambaiz.net/article/45/</link>
      <pubDate>Sat, 24 Dec 2016 21:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/45/</guid>
      <description>LevelDBとは https://github.com/google/leveldb
Googleが作った高速なkey-valueストレージライブラリ。
ChromeのIndexedDBやprometheusなどで使われている。
特徴  Keyと任意のバイト配列のValue データはKeyでソートされる。ソートのための比較関数はオーバーライドできる。 基本的な操作はPut, Get, Delete。 複数の変更を一つのatomicなバッチで行える 一環したデータのビューを取得するために、一時的なスナップショットを作成できる データを前にも後ろにもイテレーションできる データはSnappy compression libraryで自動で圧縮される。 ファイルシステムの操作など外部のアクティビティを仮想的なインタフェースを通して行うので、OSとのやりとりをカスタマイズできる。  制限  SQLデータベースではない。リレーショナルなデータモデルは持てないし、SQLやインデックスにも対応していない。 一度に一つのプロセスしかDBにアクセスできない。  キャッシュ  DBはファイルシステムのディレクトリに対応する名前を持ち、内容はそのディレクトリに保存される。 各ファイルには圧縮したブロックが保存され、良く使うものについては非圧縮のブロックがキャッシュされる。 ソートして隣接するキーは通常、同じブロックに配置される。ディスク転送とキャッシュはブロック単位。  フィルタ  Getの際、不要なデータを読まなくていいようにフィルタ(Bloom Filter)を用いることができる。 独自の比較関数(末尾のスペースを無視するなど)を使う場合、Bloom Filterを使うことができないことがあるので、その場合は独自のフィルタが必要。  レベル  最近の更新はログファイルに保存される。これが決められたサイズ(デフォルトでは約4MB)に達すると、sorted table(sst)に変換され、新しいログファイルが生成される。 現在のログファイルのコピーがメモリ(memtable)にも乗って読み取りで参照される。 sstはキーによってソートされたエントリーを保存する。エントリーはキーの値か、削除マーカー。 sstはレベルによってまとめられる。ログファイルから変換されると、特別なyoungレベル(level-0とも呼ばれる)に配置される。 youngファイルの数があるしきい値(現在4つ)を超えると全てのyoungファイルを全てのlevel-1ファイルとマージし、新しいlevel-1ファイルを生成する(2MBごとに1ファイル)。 youngレベルのファイルにはキーが重複していることがある。しかし、他のレベルでは重複しないキーの範囲がある。 level-L(L&amp;gt;=1)のファイルの合計サイズが10^L MBを超えたとき、level-Lのファイルと、level-(L+1)の全てのファイルをマージし、新しいlevel-(L+1)ファイルを生成する。 これによって、バルク読み込み/書き込みのみを使い、コストが高いシークを最小限にして、youngレベルから大きいレベルに更新を徐々にマイグレーションすることができる。  動かしてみる LevelDBのgo実装。
syndtr/goleveldb
$ go get github.com/syndtr/goleveldb/leveldb まずDBを開く。
// open db, err := leveldb.OpenFile(&amp;#34;/Users/sambaiz/leveldb&amp;#34;, nil) defer db.Close() if err != nil { panic(err) } 普通に5個(key0~4)、バッチで5個(key5~9)のデータを入れて、そのうち一つを消す。</description>
    </item>
    
    <item>
      <title>gvmでGoのバージョン管理</title>
      <link>https://www.sambaiz.net/article/44/</link>
      <pubDate>Tue, 20 Dec 2016 20:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/44/</guid>
      <description>moovweb/gvm
必要なものはREADMEを見て入れる。
$ bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) $ source ${HOME}/.gvm/scripts/gvm $ gvm install go1.7 -B $ gvm use go1.7 $ go version go version go1.7 linux/amd64 $GOPATHと$GOROOTが書き変わる(${HOME}/.gvm/pkgsets/go1.7/global/)ので注意。</description>
    </item>
    
    <item>
      <title>複数EC2インスタンスを立ち上げてvegetaで負荷試験する</title>
      <link>https://www.sambaiz.net/article/43/</link>
      <pubDate>Sun, 18 Dec 2016 20:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/43/</guid>
      <description>vegetaで負荷をかける。
インスタンスを立ち上げるスクリプト コードはここ。 sambaiz/loadtest
まずキーペアを作成し、EC2インスタンスを立ち上げて、全てのインスタンスが使えるようになるまで待つ。
aws ec2 create-key-pair --key-name LoadTestKeyPare --query &amp;#39;KeyMaterial&amp;#39; --output text &amp;gt; LoadTestKeyPare.pem chmod 400 LoadTestKeyPare.pem aws ec2 run-instances --image-id $AMI_ID --count $INSTANCE_NUM --instance-type t2.micro --key-name LoadTestKeyPare --security-group-ids $SECURITY_GROUP_IDS --subnet-id $SUBNET_ID ... aws ec2 wait instance-status-ok --instance-ids $INSTANCE_IDS このAMIは事前にPackerでつくったもの。vegetaをインストールしてファイルディスクリプタの上限を増やしている。
{ &amp;#34;variables&amp;#34;: { &amp;#34;aws_access_key&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;aws_secret_key&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;builders&amp;#34;: [{ &amp;#34;type&amp;#34;: &amp;#34;amazon-ebs&amp;#34;, &amp;#34;access_key&amp;#34;: &amp;#34;{{user `aws_access_key`}}&amp;#34;, &amp;#34;secret_key&amp;#34;: &amp;#34;{{user `aws_secret_key`}}&amp;#34;, &amp;#34;region&amp;#34;: &amp;#34;ap-northeast-1&amp;#34;, &amp;#34;source_ami&amp;#34;: &amp;#34;ami-0c11b26d&amp;#34;, &amp;#34;instance_type&amp;#34;: &amp;#34;t2.micro&amp;#34;, &amp;#34;ssh_username&amp;#34;: &amp;#34;ec2-user&amp;#34;, &amp;#34;ami_name&amp;#34;: &amp;#34;loadtest {{timestamp}}&amp;#34; }], &amp;#34;provisioners&amp;#34;: [{ &amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;inline&amp;#34;: [ &amp;#34;wget https://github.</description>
    </item>
    
    <item>
      <title>SSHポートフォワーディングとnetstatのメモ</title>
      <link>https://www.sambaiz.net/article/42/</link>
      <pubDate>Sat, 17 Dec 2016 12:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/42/</guid>
      <description>SSHポートフォワーディング ローカルの8080ポートを、example.comを通したexample2.comの80ポートに向ける。
$ ssh hoge@example.com -Nf -L 8080:example2.com:80 $ curl localhost:8080 # =&amp;gt; example2.com:80  -N: リモートでコマンドを実行しない -f: バックグラウンドで実行  netstat ネットワークの状態を確認する。
$ netstat -ant Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN ...  -a: non-listening(TCPではESTABLISHED状態)しているソケットだけではなく、listeningしている情報も出す -n: 数値のアドレスで表示する -t: TCPで制限  </description>
    </item>
    
    <item>
      <title>ファイルディスクリプタの上限を増やす</title>
      <link>https://www.sambaiz.net/article/41/</link>
      <pubDate>Thu, 08 Dec 2016 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/41/</guid>
      <description>ファイルディスクリプタとは プロセスの外部とやりとりするための識別子。POSIXではint型で、0がstdin、1がstdout、2がstderrとなっている。 ファイルやデバイスに対するopen()や、 ネットワーク(INETドメインソケット)やホスト内(UNIXドメインソケット)で 通信するためのソケットを生成するsocket()などのシステムコールで割り当てられる。
ファイルディスクリプタの上限 一つのプロセスがリソースを食いつぶさないように使えるファイルディスクリプタの上限が決まっていて、現在のプロセスの値はulimit -nで確認できる。
$ ulimit -n 1024 各プロセスの上限と、使っているファイルディスクリプタは次のようにして確認できる。
$ cat /proc/&amp;lt;プロセスID&amp;gt;/limits ... Max open files 1024 4096 files ... $ ls -l /proc/&amp;lt;プロセスID&amp;gt;/fd webサーバーのような同時に大量の通信をするプロセスではこの上限に達してしまい、Too many open filesになってしまうことがあるので増やす必要がある。 上限を変更する方法として次の方法がある。
/etc/security/limits.confで変更する ログインの際などに行われるPAM認証時に適用されるので、サーバーの起動時に立ち上がったデーモンには適用されない。
$ cat /etc/pam.d/sshd ... session required pam_limits.so ... 全てのユーザー(*)のプロセスが使えるファイルディスクリプタの、ユーザーが設定できるsoftとrootが設定できるhard limitを共に64000にする。
$ echo &amp;#34;* hard nofile 64000&amp;#34; &amp;gt;&amp;gt; /etc/security/limits.conf $ echo &amp;#34;* soft nofile 64000&amp;#34; &amp;gt;&amp;gt; /etc/security/limits.conf $ ulimit -n 64000 ulimit -nで変更する シェルと、そこから起動したプロセスでのみ有効。
$ ulimit -n 64000 (dockerの場合) run時の&amp;ndash;ulimitで変更する $ docker run -itd --ulimit nofile=11111 ubuntu $ docker exec -it &amp;lt;id&amp;gt; /bin/bash -c &amp;#34;ulimit -n&amp;#34; 11111 参考 /etc/security/limits.</description>
    </item>
    
    <item>
      <title>Angular2とangular-cliでTODOを作る</title>
      <link>https://www.sambaiz.net/article/40/</link>
      <pubDate>Mon, 05 Dec 2016 00:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/40/</guid>
      <description>コード: https://github.com/sambaiz/angular2-todo
 アプリケーションの作成と立ち上げ angular-cliをインストールしてサーバーを立ち上げるまで。
$ npm install angular-cli -g $ ng -v angular-cli: 1.0.0-beta.21 node: 5.12.0 os: darwin x64 $ ng new mytodo $ cd mytodo $ ng server http://localhost:4200/
新しいコンポーネントを作る 新しいコンポーネントを作る。
$ ng g component todo-list これでtodo-listディレクトリにコンポーネントクラスとテンプレートとCSS、テストとindexが出力される。
また、app.module.ts(BootstrapするRoot Module)にも追加されている。 NgModuleのdeclartionsなどに入っているものは、各Componentで指定しなくても使えるようになる。
import { BrowserModule } from &amp;#39;@angular/platform-browser&amp;#39;; import { NgModule } from &amp;#39;@angular/core&amp;#39;; import { FormsModule } from &amp;#39;@angular/forms&amp;#39;; import { HttpModule } from &amp;#39;@angular/http&amp;#39;; import { AppComponent } from &amp;#39;.</description>
    </item>
    
    <item>
      <title>OpenVPNサーバーPritunlをDockerで動かす</title>
      <link>https://www.sambaiz.net/article/39/</link>
      <pubDate>Fri, 02 Dec 2016 21:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/39/</guid>
      <description>PritunlでVPNサーバーを立てる。
Dockerfileはこんな感じ。
https://hub.docker.com/r/sambaiz/pritunl/
FROMmongo:3.4 # https://docs.pritunl.com/docs/installation RUN echo &amp;#39;deb http://repo.pritunl.com/stable/apt jessie main&amp;#39; &amp;gt; /etc/apt/sources.list.d/pritunl.list &amp;amp;&amp;amp; \  apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 7568D9BB55FF9E5287D586017AE645C0CF8E292A &amp;amp;&amp;amp; \  apt-get --assume-yes update &amp;amp;&amp;amp; \  apt-get --assume-yes upgrade &amp;amp;&amp;amp; \  apt-get --assume-yes install pritunl iptables EXPOSE80 443 12345/udp CMD mongod --fork --logpath /data/db/mongod.log &amp;amp;&amp;amp; echo &amp;#39;Setup Key:&amp;#39; `pritunl setup-key` &amp;amp;&amp;amp; pritunl start $ docker run -itd -p 80:80 -p 443:443 -p 12345:12345/udp --privileged sambaiz/pritunl $ docker logs &amp;lt;id&amp;gt; .</description>
    </item>
    
    <item>
      <title>aws-sdk-goでs3にput/get</title>
      <link>https://www.sambaiz.net/article/38/</link>
      <pubDate>Wed, 30 Nov 2016 20:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/38/</guid>
      <description>aws-sdk-goでS3にputしてgetする。
package main import ( &amp;#34;bytes&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/s3&amp;#34; ) const REGION = &amp;#34;ap-northeast-1&amp;#34; const BUCKET_NAME = &amp;#34;faweijojio4f3e4&amp;#34; func main() { sess, err := session.NewSession(aws.NewConfig().WithRegion(REGION)) if err != nil { fmt.Println(err.Error()) return } svc := s3.New(sess) // put 	data := []byte(&amp;#34;BBBBBB&amp;#34;) key := &amp;#34;AAA.txt&amp;#34; params := &amp;amp;s3.PutObjectInput{ Bucket: aws.String(BUCKET_NAME), Key: aws.String(key), Body: bytes.NewReader(data), ContentLength: aws.Int64(int64(len(data))), ContentType: aws.String(&amp;#34;text/plain&amp;#34;), } if _, err = svc.PutObject(params); err != nil { fmt.Println(err.Error()) return } // bucket list 	keys := []string{} err = svc.</description>
    </item>
    
    <item>
      <title>Goでstructをリフレクションしてcsvを出力する</title>
      <link>https://www.sambaiz.net/article/37/</link>
      <pubDate>Mon, 28 Nov 2016 21:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/37/</guid>
      <description>こんなstructとデータがあったら、
type Result struct{ Name string `col:&amp;#34;who&amp;#34;` Point int } x := Result{&amp;#34;sam&amp;#34;, 100} フィールド名と、値、タグはrefrectで取れる。
x := Result{&amp;#34;sam&amp;#34;, 100} v := reflect.ValueOf(x) fmt.Println(v.Type().Field(0).Name) // -&amp;gt; Name fmt.Println(v.Type().Field(1).Name) // -&amp;gt; Point fmt.Println(v.Field(0).Interface()) // -&amp;gt; sam fmt.Println(v.Field(1).Interface()) // -&amp;gt; 100 fmt.Println(v.Type().Field(0).Tag.Get(&amp;#34;col&amp;#34;)) // -&amp;gt; who fmt.Println(v.Type().Field(1).Tag.Get(&amp;#34;col&amp;#34;)) // -&amp;gt; これらをencoding/csvで書く。
ただ、引数を[]interface{}にするとinterface{}のスライスしか渡せないので、 一旦interface{}で受け取ってスライスにする。このときにもrefrectを使っている。
package main import ( &amp;#34;encoding/csv&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;os&amp;#34; &amp;#34;reflect&amp;#34; &amp;#34;strings&amp;#34; ) type Result struct { Name string `col:&amp;#34;who&amp;#34;` Point int Age int `col:&amp;#34;-&amp;#34;` // ignore } const COLTAG = &amp;#34;col&amp;#34; func main() { x := []Result{Result{&amp;#34;sam&amp;#34;, 100, 24}, Result{&amp;#34;tom&amp;#34;, 0, 100025}} file, err := os.</description>
    </item>
    
    <item>
      <title>WebVRを動かす</title>
      <link>https://www.sambaiz.net/article/36/</link>
      <pubDate>Wed, 16 Nov 2016 00:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/36/</guid>
      <description>WebVRとは Webブラウザ上でVRアプリケーションを動かすためのAPI。 ヘッドマウントディスプレイの動きを3D空間上の動きに変換してくれる。
WebVR API - Web API インターフェイス | MDN
ただし、まだほとんどのブラウザがVR APIをサポートしていないので、 実際はPolyfillで動かすことになる。
動かしてみる まず、webvr-boilerplateを動かしてみる。
$ npm init $ npm install node-static $ git clone https://github.com/borismus/webvr-boilerplate.git $ cd webvr-boilerplate/ &amp;amp;&amp;amp; npm install &amp;amp; cd .. var static = require(&amp;#39;node-static&amp;#39;); var fileServer = new static.Server(&amp;#39;./webvr-boilerplate&amp;#39;); require(&amp;#39;http&amp;#39;).createServer(function (request, response) { request.addListener(&amp;#39;end&amp;#39;, function () { fileServer.serve(request, response); }).resume(); }).listen(8080); http://localhost:8080
を見ると箱が回っているのが映る。
 ただ、start_modeに3を指定してVRモードにしようとしたところ、
http://localhost:8080/index.html?start_mode=3
PCのChromeから見ると
base.js:191 Uncaught (in promise) Error: VRDisplay is not capable of presenting というエラーが出てしまった。</description>
    </item>
    
    <item>
      <title>JVMのヒープ領域とFull GC</title>
      <link>https://www.sambaiz.net/article/35/</link>
      <pubDate>Mon, 14 Nov 2016 23:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/35/</guid>
      <description>ヒープ領域 ヒープ領域というのはメモリ上の動的に確保する領域のこと。 JVMでは、ヒープ領域のNew領域とOld領域、非ヒープ領域のPermanent領域が存在する(した)。
Permanent領域 ロードしたクラスやメソッドが入る。 Java8版のHotspotVM(OracleのJVM)ではMetaspace領域となり、ネイティブメモリに乗るようになったらしい。
New領域 New領域の中はさらに分かれている。
 Eden領域: オブジェクトが作られて最初に配置される。 To領域(Survivor領域1): Edenが一杯になると、EdenとFromから送られる。 From領域(Survivor領域0): Edenが一杯になると、Toから送られる。  Edenが一杯になったときに不要なオブジェクトは破棄、必要なものは領域を移動させるのがScavenge GC。 つまり、Edenが一杯になるたびにToに飛んだオブジェクトはFromと往復し続ける。 ただし、MaxTenuringThresholdの回数を超えるとOld領域に送られることになる。
Old領域 Old領域も一杯になったらどうしようもないのでFull GCが走る。 Full GCでは全ての領域のオブジェクトをチェックして不要なものを探す。 これに集中するので他のことはできなくなり、時間もかかる。 Full GCばかり起きていたらまともに動かないので、 Old領域にまで行かないようにオブジェクトの寿命を短くするか、 ヒープ領域の大きさ(-Xms, -Xmx)を変えたりしてなるべく起きないようにしたい。
どれくらいFull GCしているかどうか -XloggcでGCのログが出せる。-XX:+UseGCLogFileRotationでローテーションしたりもできる。 あと手軽にjpsからのjstat -gc &amp;lt;pid&amp;gt;、あるいはグラフで可視化できるようなやつでヒープ領域の状態を確認する。 jstatの結果の意味はここに書いてある。 例えばFGCがフルGCイベントの数。
参考 JVMとGCのしくみ
Java8のHotSpotVMからPermanent領域が消えた理由とその影響 | ギークを目指して
Java開発の性能改善！ その２ GCログの解析とHeepの設定</description>
    </item>
    
    <item>
      <title>API BlueprintでAPI仕様を書く</title>
      <link>https://www.sambaiz.net/article/34/</link>
      <pubDate>Thu, 10 Nov 2016 00:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/34/</guid>
      <description>API BlueprintというのはAPIの仕様を書くための言語で、 これを元にHTMLのドキュメントにしたり、モックサーバーを立てたりするツールがある。
最初にMetadataとして、API Blueprintのバージョンを書く。
FORMAT: 1A 基本的にはMarkdownのように書ける。
# テストAPI テスト 頭にGroupと書くとグループができる。
# Group echo やまびこ 終わりに[]で囲んでリソースを書く。
## echo [/echo] やっほー アクション。
### echo [POST] 叫ぶ + say (string) - 発声 リクエスト例とレスポンス例はこんな感じ。JSON Schemaを書くこともできる。
+ Request (application/json) { &amp;#34;say&amp;#34;: &amp;#34;yahho&amp;#34; } + Response 200 (application/json) + Headers Hoge: Fuga + Body { &amp;#34;echo&amp;#34;: &amp;#34;yahho&amp;#34; } 全体
FORMAT: 1A # テストAPI テスト # Group echo やまびこ ## echo [/echo] やっほー ### echo [POST] 叫ぶ + say (string) - 発声 + Request (application/json) { &amp;#34;say&amp;#34;: &amp;#34;yahho&amp;#34; } + Response 200 (application/json) + Headers Hoge: Fuga + Body { &amp;#34;echo&amp;#34;: &amp;#34;yahho&amp;#34; } これを使って、aglioでHTMLにしたり、</description>
    </item>
    
    <item>
      <title>logrotateでログをローテーションする</title>
      <link>https://www.sambaiz.net/article/33/</link>
      <pubDate>Wed, 09 Nov 2016 22:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/33/</guid>
      <description>logrusがローテーションする仕組みを持っていなかったので、 READMEに書いてあったlogrotateを使う。/etc/logrotate.dの中に設定ファイルを入れて、cronで回して使う。
FROM ubuntu:14.04 ADD logrotate /etc/logrotate.d/app RUN echo &amp;#34;/usr/sbin/logrotate /etc/logrotate.conf&amp;#34; &amp;gt; /etc/cron.daily/logrotate 設定ファイル(logrotate)はこんな感じ。
/var/log/*.log { daily rotate 4 missingok delaycompress dateext sharedscripts postrotate echo &amp;#34;hi&amp;#34; endscript } dailyで1日に1回、rotate 4で過去4日分残し、 missingokでファイルがなくてもエラーにせず、delaycompressで圧縮するのをローテーションした次の回にして、 dateextでローテーションしたファイルの末尾を数字ではなく日付にする。 postrotateはローテーション後に実行されるスクリプトで、sharedscriptsによって各ログごとではなくまとめて一回実行される。
実際に動かして確かめる。
logrotateを実行すると、/var/lib/logrotate/statusに過去に見た時間が入る。
$ echo &amp;#34;aaaaa&amp;#34; &amp;gt; /var/log/app.log $ logrotate /etc/logrotate.conf $ cat /var/lib/logrotate/status logrotate state -- version 2 ... &amp;#34;/var/log/app.log&amp;#34; 2016-11-9-11:0:0 ... 強制的にローテーションさせてみる。
$ echo &amp;#34;aaaa&amp;#34; &amp;gt; /var/log/app.log $ logrotate -f /etc/logrotate.conf $ ls /var/log | grep app app.</description>
    </item>
    
    <item>
      <title>td-agentをビルドしてfluentdのバージョンを上げる</title>
      <link>https://www.sambaiz.net/article/32/</link>
      <pubDate>Sun, 06 Nov 2016 11:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/32/</guid>
      <description>$td-agent --version td-agent 0.12.26 td-agentって書いてあるが、これがfluentdのバージョンらしい。
fluentdはv0.14からナノ秒で時間を持つようになった。 ただ、現行のtd-agent(v2.3.2)は上の通り古いバージョンを使っている。 0.14になるtd-agent-3はまだリリースされていないので、 自分でfluentdをv0.14.8に上げてビルドすることにした。
FROMubuntu:14.04 WORKDIR/tmp RUN apt-get update &amp;amp;&amp;amp; \  apt-get install -y git software-properties-common build-essential curl &amp;amp;&amp;amp; \  add-apt-repository -y ppa:brightbox/ruby-ng &amp;amp;&amp;amp; \  apt-get update &amp;amp;&amp;amp; \  apt-get install -y ruby2.3 ruby2.3-dev &amp;amp;&amp;amp; \  gem install bundler &amp;amp;&amp;amp; \  git clone https://github.com/treasure-data/omnibus-td-agent WORKDIR/tmp/omnibus-td-agent RUN sed -ie &amp;#34;s/^default_version.*$/default_version &amp;#39;3d1dd53f31d1fe49508f230a71a2b4c2ceb20f47&amp;#39;/&amp;#34; config/software/fluentd.rb &amp;amp;&amp;amp; \  sed -ie &amp;#34;s/^license_file.*$/license_file &amp;#39;LICENSE&amp;#39;/&amp;#34; config/projects/td-agent2.rb &amp;amp;&amp;amp; \  bundle install --binstubs &amp;amp;&amp;amp; \  bin/gem_downloader core_gems.</description>
    </item>
    
    <item>
      <title>d3.jsで折れ線グラフを書くコードを読む</title>
      <link>https://www.sambaiz.net/article/31/</link>
      <pubDate>Thu, 03 Nov 2016 00:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/31/</guid>
      <description>http://bl.ocks.org/mbostock/3883245
CSSと
&amp;lt;style&amp;gt; .axis--x path { display: none; } .line { fill: none; stroke: steelblue; stroke-width: 1.5px; } &amp;lt;/style&amp;gt; グラフを書くsvgとd3.js。
&amp;lt;svg width=&amp;#34;960&amp;#34; height=&amp;#34;500&amp;#34;&amp;gt;&amp;lt;/svg&amp;gt; &amp;lt;script src=&amp;#34;https://d3js.org/d3.v4.min.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; var svg = d3.select(&amp;#34;svg&amp;#34;), margin = {top: 20, right: 20, bottom: 30, left: 50}, width = +svg.attr(&amp;#34;width&amp;#34;) - margin.left - margin.right, height = +svg.attr(&amp;#34;height&amp;#34;) - margin.top - margin.bottom, g = svg.append(&amp;#34;g&amp;#34;).attr(&amp;#34;transform&amp;#34;, &amp;#34;translate(&amp;#34; + margin.left + &amp;#34;,&amp;#34; + margin.top + &amp;#34;)&amp;#34;); d3.selectでsvg要素を選択。widthとheightを取得したり、中にg(グループ)を入れてtransformでmarginを作っている。
&amp;lt;svg width=&amp;#34;960&amp;#34; height=&amp;#34;500&amp;#34;&amp;gt;&amp;lt;g transform=&amp;#34;translate(50,20)&amp;#34;&amp;gt;&amp;lt;/g&amp;gt;&amp;lt;/svg&amp;gt; svg.</description>
    </item>
    
    <item>
      <title>mp4をエンコードしてMPEG-DASHにして再生する</title>
      <link>https://www.sambaiz.net/article/30/</link>
      <pubDate>Sun, 30 Oct 2016 23:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/30/</guid>
      <description>MPEG-DASHとは HTTPで動画をストリーミングするための規格。似たようなのにAppleの独自規格であるHLSなどがある。
サーバーはMPD(Media Presentation Description)ファイルと、セグメントに分けられた動画や音声ファイルを持っていて、 クライアントはMPDファイルをリクエストし、この内容をもとにセグメントをリクエストしていく。
準備 ffmpegと MP4Boxを使うので、これらを実行できるようにする。 Docker上で実行することもできて、その場合は以下のようにエイリアスを付けると便利。
$ alias ffmpeg=&amp;#39;docker run --rm -v `pwd`:/tmp/workdir jrottenberg/ffmpeg&amp;#39; $ alias MP4Box=&amp;#39;docker run --rm -v `pwd`:/work sambaiz/mp4box&amp;#39; エンコード $ffmpeg -i input.mp4 -vcodec libx264 -vb 448k -r 30 -x264opts no-scenecut -g 15 -acodec libfaac -ac 2 -ab 128k -frag_duration 5000000 -movflags empty_moov output.mp4  -vcodec libx264: 動画をH.264にエンコードする -vb 448k: 動画の平均ビットレート(bps)。可変(VBR, Variable Bitrate)ではなく固定(CBR, Constant Bitrate)にする場合は-min/maxrateを同じ値にする -r 30: 動画のフレームレート(fps) -x264opts no-scenecut: キーフレームの間隔を動画の内容によらず固定にする -g 15: キープレームの間隔。フレームレート(-r) * フラグメントの時間(-frag_duration) / キーフレームの間隔(-g)が整数になるようにする。 -acodec libfaac: 音声をAACにエンコードする -ac 2: 音声チャンネル数2(ステレオ) -ab 128k: 音声のビットレート(bps) -frag_duration 5000000: フラグメント(セグメント)の時間(μs)。 -movflags empty_moov: 頭にmdat atom(データが含まれる)なしで、moov atom(メタ情報が含まれている)を書き始めるらしい。これにしないとMP4Boxに入れるときに失敗した。  $ MP4Box -info -v input.</description>
    </item>
    
    <item>
      <title>剣を振るVRゲームを作った</title>
      <link>https://www.sambaiz.net/article/29/</link>
      <pubDate>Sun, 30 Oct 2016 19:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/29/</guid>
      <description>プレイ動画
CardboardにAndroidを入れて、
 iPhoneをくくりつけた傘を動かすと、画面の剣も動くのでこれで敵を倒すゲーム。
 実装 剣(iOS) 剣にくくりつけたiPhoneの傾きの値をUnity(Android)に送信している。 iOSはClassic Bluetoothを自由に使えないので、Androidと通信する場合はBLEを使う。 BLEは通常だと20byteしか一度に送れないので、これを超えないよう注意する必要がある。
BLEで通信するところは
iOS端末をBLEのPeripheralにする
で作ったので、端末の傾きを取得して送るだけ。
import UIKit import CoreMotion class Motion{ let peripheral: BLEPeripheral let accelHandler:CMDeviceMotionHandler let manager = CMMotionManager() public init(peripheral :BLEPeripheral, label :UILabel){ self.peripheral = peripheral accelHandler = { (data: CMDeviceMotion?, error: Error?) -&amp;gt; Void in let str = String(format: &amp;#34;%.1f %.1f %.1f&amp;#34;, arguments: [data!.attitude.pitch * 180 / M_PI, data!.attitude.roll * 180 / M_PI, data!.attitude.yaw * 180 / M_PI] ) let res = peripheral.</description>
    </item>
    
    <item>
      <title>gcloudのアカウント切り替えとkubectlのcontext変更</title>
      <link>https://www.sambaiz.net/article/28/</link>
      <pubDate>Tue, 25 Oct 2016 20:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/28/</guid>
      <description>いつも迷うのでまとめた。
gcloudのアカウント一覧と切り替え $ gcloud auth list $ gcloud config set account `ACCOUNT` configにprojectなども設定している場合はconfig自体を作成して切り替えた方が楽。
$ gcloud config configurations create &amp;lt;name&amp;gt; $ gcloud config configurations activate &amp;lt;name&amp;gt; $ gcloud config list ... Your active configuration is: [&amp;lt;name&amp;gt;] $ gcloud config set account &amp;lt;accout&amp;gt; $ gcloud config set project &amp;lt;project&amp;gt; kubectlのcontext変更 $ kubectl config current-context $ kubectl config view # contexts $ kubectl config use-context minikube </description>
    </item>
    
    <item>
      <title>UnityでAndroidのBLEを使うネイティブプラグインを作る</title>
      <link>https://www.sambaiz.net/article/27/</link>
      <pubDate>Sun, 23 Oct 2016 20:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/27/</guid>
      <description>UnityからBLEを使うためのネイティブプラグインを作る。
Android側 まず、Activityなしのプロジェクトを作って、New ModuleからAndroid Libraryを選択。 これらのパッケージ名がUnityで使うものと被らないようにする。
/Applications/Unity/PlaybackEngines/AndroidPlayer/Variations/mono/Release/Classes/classes.jar をModuleの方のlibsに置く。
import com.unity3d.player.UnityPlayer; このjarは元々のやつとかぶってしまうので除外(build.gradleに追加)
android.libraryVariants.all { variant -&amp;gt; variant.outputs.each { output -&amp;gt; output.packageLibrary.exclude(&amp;#39;libs/classes.jar&amp;#39;) } } ActiviyはUnityPlayer.currentActivityで取得でき、 Unity側のメソッドを呼ぶのも UnityPlayer.UnitySendMessage(mGameObjName, mCallBackName, new String(characteristic.getValue())); のようにできる。
public class BLE { private final static String TAG = BLE.class.getSimpleName(); private static final int REQUEST_ENABLE_BT = 1; private static final int MY_PERMISSION_RESPONSE = 2; private static final String PERIPHERAL_LOCAL_NAME = &amp;#34;my-ble&amp;#34;; private static final UUID PERIPHERAL_SERIVCE_UUID = UUID.fromString(&amp;#34;BF9CB85F-620C-4A67-BDD2-1A64213F74CA&amp;#34;); private static final UUID PERIPHERAL_CHARACTERISTIC_UUID = UUID.</description>
    </item>
    
    <item>
      <title>iOS端末をBLEのPeripheralにする</title>
      <link>https://www.sambaiz.net/article/26/</link>
      <pubDate>Sun, 23 Oct 2016 01:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/26/</guid>
      <description>CoreBluetoothプログラミングガイド
流れ まず、CoreBluetooth.frameworkを追加する。
import CoreBluetooth CBPeripheralManagerを生成。
peripheralManager = CBPeripheralManager(delegate: self, queue: nil) stateが変化したらdelegateメソッドが呼ばれるので.poweredOnであることを確認できれば Managerの準備は完了。
public func peripheralManagerDidUpdateState(_ peripheral: CBPeripheralManager){ switch (peripheral.state){ case .poweredOn: print(&amp;#34;PeripheralManager state is ok&amp;#34;) ready = true default: print(&amp;#34;PeripheralManager state is ng:&amp;#34;, peripheral.state) ready = false } } Characteristicを作成。CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify)で、 Centralが読みにくることも、通知を受け取ることもできるようにし、CBAttributePermissions.readableでreadのみ許可する。 このvalueをnilにしておかないと、キャッシュされあとで変更できなくなる。
characteristic = CBMutableCharacteristic( type: CHARACTERISTIC_UUID, properties: CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify), value:nil, permissions:CBAttributePermissions.readable) このCharacteristicのServiceを作成し、Managerに登録する。
let service = CBMutableService(type: SERVICE_UUID, primary: true) service.characteristics = [characteristic] peripheralManager!.add(service) ready = true public func peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?</description>
    </item>
    
    <item>
      <title>android-BluetoothLeGattを読む</title>
      <link>https://www.sambaiz.net/article/25/</link>
      <pubDate>Fri, 21 Oct 2016 14:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/25/</guid>
      <description>BLEのサンプルコード。
https://github.com/googlesamples/android-BluetoothLeGatt
DeviceScanActivity BLEをサポートしているかチェックする。 BluetoothChatではBluetoothAdapterを取得するのに BluetoothAdapter.getDefaultAdapter()のようにしていたが、 BLEをサポートしているような新しいバージョンでは、BluetoothManagerのgetAdapter()を使うらしい。
@Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); getActionBar().setTitle(R.string.title_devices); mHandler = new Handler(); // Use this check to determine whether BLE is supported on the device. Then you can  // selectively disable BLE-related features.  if (!getPackageManager().hasSystemFeature(PackageManager.FEATURE_BLUETOOTH_LE)) { Toast.makeText(this, R.string.ble_not_supported, Toast.LENGTH_SHORT).show(); finish(); } // Initializes a Bluetooth adapter. For API level 18 and above, get a reference to  // BluetoothAdapter through BluetoothManager.  final BluetoothManager bluetoothManager = (BluetoothManager) getSystemService(Context.</description>
    </item>
    
    <item>
      <title>PackerでAMIを作る</title>
      <link>https://www.sambaiz.net/article/24/</link>
      <pubDate>Tue, 18 Oct 2016 22:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/24/</guid>
      <description>https://www.packer.io/
いろんなプラットフォームのイメージを作ることができるツール。 これでfluentdのログサーバーのAMIを作る。
$ brew install packer # mac $ packer -v 0.10.1 設定ファイルはこんな感じ。variablesの値は{{user ... }}のところで使われる。 buildersに作るイメージの情報を書いて、provisionersで環境を作る。
provisionersにはchefやansibleなども指定できるが、 継ぎ足し継ぎ足しで秘伝のタレ化したAMIも最初は、コマンドいくつか実行するだけなのでとりあえず手作業で作った、後でなんとかするなんてものもあったりして、 そういうものは無理にchefなどで始めず、手軽にshellでpacker buildするといいと思う。 手作業よりも楽だしソースが別にあるので使われていないAMIを消すのも簡単。
fileではpermissionがないところに置くことができないので、一旦置いてshellで移動する。
{ &amp;#34;variables&amp;#34;: { &amp;#34;aws_access_key&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;aws_secret_key&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;builders&amp;#34;: [{ &amp;#34;type&amp;#34;: &amp;#34;amazon-ebs&amp;#34;, &amp;#34;access_key&amp;#34;: &amp;#34;{{user `aws_access_key`}}&amp;#34;, &amp;#34;secret_key&amp;#34;: &amp;#34;{{user `aws_secret_key`}}&amp;#34;, &amp;#34;region&amp;#34;: &amp;#34;ap-northeast-1&amp;#34;, &amp;#34;source_ami&amp;#34;: &amp;#34;ami-1a15c77b&amp;#34;, &amp;#34;instance_type&amp;#34;: &amp;#34;t2.small&amp;#34;, &amp;#34;ssh_username&amp;#34;: &amp;#34;ec2-user&amp;#34;, &amp;#34;ami_name&amp;#34;: &amp;#34;fluentd-logserver {{timestamp}}&amp;#34; }], &amp;#34;provisioners&amp;#34;: [{ &amp;#34;type&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;source&amp;#34;: &amp;#34;td-agent.conf&amp;#34;, &amp;#34;destination&amp;#34;: &amp;#34;/home/ec2-user/td-agent.conf&amp;#34; }, { &amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;inline&amp;#34;: [ &amp;#34;curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh&amp;#34;, &amp;#34;sudo mv /home/ec2-user/td-agent.</description>
    </item>
    
    <item>
      <title>android-bluetoothChatを読む</title>
      <link>https://www.sambaiz.net/article/23/</link>
      <pubDate>Sat, 15 Oct 2016 14:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/23/</guid>
      <description>Classic Bluetoothのサンプルコード。
https://github.com/googlesamples/android-BluetoothChat
MainActivity まず、MainActivity。
Fragmentのcommitや、
@Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); if (savedInstanceState == null) { FragmentTransaction transaction = getSupportFragmentManager().beginTransaction(); BluetoothChatFragment fragment = new BluetoothChatFragment(); transaction.replace(R.id.sample_content_fragment, fragment); transaction.commit(); } } オプションメニューの設定をしている。
// 最初だけ呼ばれる @Override public boolean onCreateOptionsMenu(Menu menu) { getMenuInflater().inflate(R.menu.main, menu); return true; } // 表示される度に呼ばれる @Override public boolean onPrepareOptionsMenu(Menu menu) { MenuItem logToggle = menu.findItem(R.id.menu_toggle_log); logToggle.setVisible(findViewById(R.id.sample_output) instanceof ViewAnimator); logToggle.setTitle(mLogShown ? R.string.sample_hide_log : R.string.sample_show_log); return super.onPrepareOptionsMenu(menu); } @Override public boolean onOptionsItemSelected(MenuItem item) { switch(item.</description>
    </item>
    
    <item>
      <title>静的ウェブサイトエンジンHugoに乗り換えた</title>
      <link>https://www.sambaiz.net/article/22/</link>
      <pubDate>Tue, 04 Oct 2016 22:21:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/22/</guid>
      <description>https://gohugo.io/
今までこのサイトはフロントのReactからLambda &amp;amp; API Gatewayで作った記事APIを呼ぶ構成になっていた。
ホームページ作った
当初はページの描画をフロントに任せることで、 サーバーレス (記事の情報をjsonで渡すAPI Gatewayと、S3の組み合わせ) で作れると思っていたが、結果そんなに甘くはなく、サーバーサイドレンダリングするはめになる。 最初からレンダリングしたものを置いておけばいいと思った。
webpack環境でredux&amp;amp;react-routerのページをサーバーサイドレンダリングする
そんなこんなでHugoに乗り換えることにした。 記事はmarkdownで管理していたので、これにメタ情報を加えるだけで移行できた。 タグで絞り込むこともできるようになったので良いと思う。 また、静的なページになったのでgithub pagesに置けるようにもなった。</description>
    </item>
    
    <item>
      <title>DeepDreaming with TensorFlowをやる(2)</title>
      <link>https://www.sambaiz.net/article/21/</link>
      <pubDate>Sat, 10 Sep 2016 14:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/21/</guid>
      <description>前回の続き。
Multiscale image generation 様々なスケールで勾配上昇させる。小さなスケールで上昇させたものをより大きなスケールでさらに上昇させていく。 ただ、壁紙のようなサイズを生成するような場合にそれを行うと、GPUのメモリを食いつぶしてしまう。 これを避けるために、画像を小さなタイルに分割し、それぞれ独立に勾配を計算する。 また、毎回画像をランダムにシフトしていくことで、タイルに見えることを避け、画像全体の品質を向上させる。
def tffunc(*argtypes): &amp;#39;&amp;#39;&amp;#39;Helper that transforms TF-graph generating function into a regular one. See &amp;#34;resize&amp;#34; function below. &amp;#39;&amp;#39;&amp;#39; placeholders = list(map(tf.placeholder, argtypes)) def wrap(f): out = f(*placeholders) def wrapper(*args, **kw): return out.eval(dict(zip(placeholders, args)), session=kw.get(&amp;#39;session&amp;#39;)) return wrapper return wrap # Helper function that uses TF to resize an image def resize(img, size): img = tf.expand_dims(img, 0) return tf.image.resize_bilinear(img, size)[0,:,:,:] resize = tffunc(np.float32, np.int32)(resize) def calc_grad_tiled(img, t_grad, tile_size=512): &amp;#39;&amp;#39;&amp;#39;Compute the value of tensor t_grad over the image in a tiled way.</description>
    </item>
    
    <item>
      <title>DeepDreaming with Tensorflowをやる(1)</title>
      <link>https://www.sambaiz.net/article/20/</link>
      <pubDate>Wed, 07 Sep 2016 01:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/20/</guid>
      <description>https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb
例の通りまとめながら進めていく。
 このノートブックは、畳み込みニューラルネットワークによる画像生成の手法を説明するものだ。 ネットワークは入力画像へ変換させる配列のレイヤーの集合から成り立っている。 変換のパラメータは勾配降下法で変形しながら学習していく。 内部的な画像の表現は意味不明なように見えるが、可視化し、解釈することができる。
Loading and displaying the model graph 学習済みネットワークのprotobufファイルが用意されていて、これをダウンロードして使う。 ただgcr.io/tensorflow/tensorflowにwgetもunzipも入っていなかったので、中に入ってapt-getした。
model_fn = &amp;#39;tensorflow_inception_graph.pb&amp;#39; # creating TensorFlow session and loading the model graph = tf.Graph() sess = tf.InteractiveSession(graph=graph) with tf.gfile.FastGFile(model_fn, &amp;#39;rb&amp;#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) t_input = tf.placeholder(np.float32, name=&amp;#39;input&amp;#39;) # define the input tensor imagenet_mean = 117.0 t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0) tf.import_graph_def(graph_def, {&amp;#39;input&amp;#39;:t_preprocessed}) tf.gfile.FastGFileのドキュメントが見つからないので ソース を探したところFile I/Oのラッパーのようだ。これでprotobufファイルを読み、ParseFromStringでGraphDefにする。
さらにこれと入力データをtf.import_graph_defに 渡すことでGraphに取り込む。
tf.expand_dimsは値が1の次元を指定の場所に挿入する もの。なんでそんなことをしたり、imagenet_meanを引いているのかは説明がなかった。
layers = [op.name for op in graph.</description>
    </item>
    
    <item>
      <title>Grafana/InfluxDB/Fluentdでログを可視化する</title>
      <link>https://www.sambaiz.net/article/19/</link>
      <pubDate>Wed, 31 Aug 2016 20:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/19/</guid>
      <description>コードはここ。
InfluxDB Golangで書かれた時系列データベース。今回使うのはv0.13。前のバージョンと結構違うので注意。
デフォルトでは無効になっている認証を有効にするために設定ファイルを編集して設置する。
$ brew install influxdb # OSX $ influxd config &amp;gt; influxdb.conf [http] ... auth-enabled = true ... FROMinfluxdb:0.13 VOLUME/var/lib/influxdb ADD influxdb.conf / ENV INFLUXDB_CONFIG_PATH /influxdb.conf $ docker run -p 8083:8083 -p 8086:8086 myinfluxdb influxdコマンドや :8083のWebインタフェースの他に :8086にHTTP APIが用意されている。
$ curl -i -XPOST http://localhost:8086/query --data-urlencode &amp;#34;q=CREATE USER root WITH PASSWORD &amp;#39;root&amp;#39; WITH ALL PRIVILEGES&amp;#34; $ curl -i -XPOST http://localhost:8086/query -u root:root --data-urlencode &amp;#34;q=CREATE DATABASE mydb&amp;#34; {&amp;#34;results&amp;#34;:[{}]} # Line Protocol(https://docs.</description>
    </item>
    
    <item>
      <title>GKEで複数コンテナのアプリケーションを動かす</title>
      <link>https://www.sambaiz.net/article/18/</link>
      <pubDate>Fri, 26 Aug 2016 21:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/18/</guid>
      <description>前回は単一コンテナのアプリケーションを動かしたが、今回はコンテナ間でやり取りが発生するものを動かす。 流れとしては、クライアントからのリクエストをGATEWAYサーバーで受け取り、SERVICEサーバーにリクエストし、その結果を返すまで。
プログラムは以下の通り、環境変数TYPEの値によって挙動を変えていて、同じイメージを使い回す。コードはここ。
var http = require(&amp;#39;http&amp;#39;); var handleRequest = function(request, response) { if(process.env.TYPE == &amp;#34;GATEWAY&amp;#34;){ console.log(&amp;#39;Passed.&amp;#39;); var options = { host: &amp;#39;service&amp;#39;, port: 8080, method: &amp;#39;GET&amp;#39; }; var req = http.request(options, function(res) { data = &amp;#34;&amp;#34; res.on(&amp;#39;data&amp;#39;, function (chunk) { data+=chunk; }); res.on(&amp;#39;end&amp;#39;, () =&amp;gt; { response.writeHead(200); response.end(data); }); }); req.on(&amp;#39;error&amp;#39;, function(e) { response.writeHead(500) response.end(e.message); }); req.end(); }else{ console.log(&amp;#39;Received.&amp;#39;); response.writeHead(200); response.end(&amp;#39;ok&amp;#39;); } }; var www = http.createServer(handleRequest); www.listen(8080); これをContainer RegistryにPushする。</description>
    </item>
    
    <item>
      <title>Google Container Engine(GKE)で単一コンテナのアプリケーションを動かす</title>
      <link>https://www.sambaiz.net/article/17/</link>
      <pubDate>Sun, 21 Aug 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/17/</guid>
      <description>Kubernetes - Hello World Walkthrough
CloudSDKとkubectlのインストール Cloud SDKをインストールしてgloudコマンドを使えるようにする。
$ gcloud --version Google Cloud SDK 122.0.0 $ gcloud components install kubectl Google Container RegistryにPush $ export PROJECT_ID=&amp;#34;******&amp;#34; $ docker build -t gcr.io/$PROJECT_ID/test:v1 . $ gcloud docker push gcr.io/$PROJECT_ID/test:v1 プロジェクトの課金を有効にしていないとこんなエラーメッセージが出る。
denied: Unable to create the repository, please check that you have access to do so. Clusterの作成 $ gcloud config set core/project $PROJECT_ID $ gcloud config set compute/zone asia-east1-b $ gcloud container clusters create test-cluster $ gcloud config set container/cluster test-cluster Container Engine APIが有効になっていない場合はこうなる。 一度コンソールからContainer Engineを選ぶと、サービスの準備が始まって有効になる。</description>
    </item>
    
    <item>
      <title>JenkinsのMultiple SCMs PluginからPipeline Pluginへの移行</title>
      <link>https://www.sambaiz.net/article/16/</link>
      <pubDate>Sat, 20 Aug 2016 16:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/16/</guid>
      <description>Jenkins環境を作り直すことになり、 長らく使ってきたMultiple SCMs PluginがDeprecatedなので、 Pipeline Pluginに移行することにした。
プラグインをインストールすると、ジョブ作成時にPipelineを選択できるようになる。 Pipeline scriptの複数リポジトリを指定するところはこんな感じ。
node { stage &amp;#39;Checkout rep1&amp;#39; git([url: &amp;#39;git@rep1.git&amp;#39;, branch: REP1_BRANCH]) stage &amp;#39;Checkout rep2&amp;#39; dir(&amp;#39;rep2&amp;#39;) { git([url: &amp;#39;git@rep2.git&amp;#39;, branch: REP2_BRANCH]) } stage &amp;#39;Checkout rep3&amp;#39; dir(&amp;#39;subdir3/rep3&amp;#39;) { git([url: &amp;#39;git@rep3.git&amp;#39;, branch: REP3_BRANCH]) } stage &amp;#39;Build&amp;#39; ... } まとめて入ったPipeline Stage View Pluginによって、 経過や変更などいろいろ見やすくなった。</description>
    </item>
    
    <item>
      <title>GolangでAPIとテストを書く(echo/dbr/glide/goose/mock)</title>
      <link>https://www.sambaiz.net/article/15/</link>
      <pubDate>Mon, 15 Aug 2016 04:07:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/15/</guid>
      <description>以下の記事を参考にして簡単なAPIとそのテストを書いてみた。コードはここ。
Go言語でTestableなWebアプリケーションを目指して｜サイバーエージェント 公式エンジニアブログ
使った主なライブラリ・ツール echo webフレームワーク。速いらしい。
$ go get -u github.com/labstack/echo func main() { conn, err := dbr.Open(&amp;#34;mysql&amp;#34;, &amp;#34;root:@tcp(localhost:3306)/mboard&amp;#34;, nil) if err != nil { panic(err) } conn.SetMaxIdleConns(200) conn.SetMaxOpenConns(200) e := echo.New() // middlewares  e.Use(middleware.Logger()) e.Use(middleware.Recover()) e.Use(middleware.CORSWithConfig(middleware.CORSConfig{ AllowOrigins: []string{&amp;#34;*&amp;#34;}, AllowMethods: []string{echo.GET, echo.PUT, echo.POST, echo.DELETE}, })) // endpoints  e.GET(&amp;#34;/&amp;#34;, func(c echo.Context) error { return c.String(http.StatusOK, &amp;#34;Hello, World!&amp;#34;) }) e.GET(&amp;#34;/messages&amp;#34;, func(c echo.Context) error { return handler.NewMessageWithSession(conn.NewSession(nil)).GetMessages(c) }) e.POST(&amp;#34;/messages&amp;#34;, func(c echo.Context) error { return handler.</description>
    </item>
    
    <item>
      <title>O&#39;Reillyの「マイクロサービスアーキテクチャ」を読んだ</title>
      <link>https://www.sambaiz.net/article/14/</link>
      <pubDate>Sat, 06 Aug 2016 18:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/14/</guid>
      <description>O&amp;rsquo;Reilly Japan - マイクロサービスアーキテクチャ
設計、開発、テストや監視など一通りまとまっているマイクロサービスアーキテクチャの本。
マイクロサービスアーキテクチャというのは、協調して動作する小規模で自律的なサービスでシステムを構成するもので、 一般的なモノリシック(一枚岩)システムのモジュールのように独立したサービスを作っていく。 自律的というのは、他には何も変更せずに、単独でサービスの変更やデプロイを行えるということ。
メリットとしては
 サービスごとに異なる技術を使うことができる 一部のサービスで障害が発生しても、機能低下させて稼働し続けるシステムを構築できる 性能を高める必要があるサービスだけをスケールでき、効率的にリソースを使うことができる デプロイのリスクを最小限に抑えることができるため、迅速に行うことができる レガシーなコードを捨て去る障壁が低い  などが挙げられていた。
正しくサービスを切り分けるにはドメインの理解が必要で、「境界づけられたコンテキスト」が1つのサービスとなるようにする。 そのため、最初はモノシリックに進めることも推奨されていた。
 特に初めてのドメインでは、システムをマイクロサービスに分解するのが時期尚早だとコストがかかってしまう場合があります。いろいろな意味で、マイクロサービスに分解したい既存のコードベースがある方が、最初からマイクロサービスに取り組むよりもはるかに簡単です (3.3.3)
 実現する上で、DBの扱いが難しいと思った。 サービス間のDBの共有はスキーマの変更に弱く、技術の縛りが発生してしまうので避けなければならない。 一方で、DBを分割すると1つのトランザクションで完結しなくなり、どのように整合性を保っていくか。 そんな話が5章に書いてあって、いくつか方法は挙げられているが、いずれにせよ何かしらの制御をしなくてはいけないし、 データの取得の上でも一つのデータベースにあったほうが便利だったりする。 サービスの単位がデータに引きずられてしまうと、マイクロサービスとはいえないものが出来上がりそうだ。 きれいに分けられればいいが実際どうなんだろう。
すぐにマイクロサービスを採用するかは別としても、考え方として活かせそうなことが多かった。 実際にやってみて、また読み返して自分のものにしていこうと思う。</description>
    </item>
    
    <item>
      <title>Tensorflowの学習データを使ったAPIを作る</title>
      <link>https://www.sambaiz.net/article/13/</link>
      <pubDate>Fri, 05 Aug 2016 22:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/13/</guid>
      <description>チュートリアルのMNISTの学習データを使って、手書き数字画像のデータを受け取り、数字を返すAPIを作る。 コードはここにある。
学習して結果を保存する 前回の学習結果のcheckpointファイルを出力する。 tf.train.Saver().saveでnameで対応するVariableの値が保存できる。 また、その際デフォルトでMetaGraphもexportされ、これをimportすればGraphも復元することができる。
import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data class Mnist: def __init__(self): g = tf.Graph() with g.as_default(): W_conv1 = self._weight_variable([5, 5, 1, 32], &amp;#34;W_conv1&amp;#34;) b_conv1 = self._bias_variable([32], &amp;#34;b_conv1&amp;#34;) self._x = tf.placeholder(tf.float32, [None, 784]) x_image = tf.reshape(self._x, [-1,28,28,1]) h_conv1 = tf.nn.relu(self._conv2d(x_image, W_conv1) + b_conv1) h_pool1 = self._max_pool_2x2(h_conv1) W_conv2 = self._weight_variable([5, 5, 32, 64], &amp;#34;W_conv2&amp;#34;) b_conv2 = self._bias_variable([64], &amp;#34;b_conv2&amp;#34;) h_conv2 = tf.nn.relu(self._conv2d(h_pool1, W_conv2) + b_conv2) h_pool2 = self.</description>
    </item>
    
    <item>
      <title>Googleが作ったRPCフレームワークgRPCを使ってみた</title>
      <link>https://www.sambaiz.net/article/12/</link>
      <pubDate>Fri, 29 Jul 2016 22:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/12/</guid>
      <description>A high performance, open source, general RPC framework that puts mobile and HTTP/2 first.
 What is gRPC? gRPCを使うと、クライアントアプリケーションは直接ローカルのオブジェクトのように、他のマシンのサーバーアプリケーションのメソッドを呼ぶことができ、 分散したアプリケーションやサービスを簡単に作ることができる。 多くのRPCシステムと同様にgRPCはサービスを定義し、リモートから呼べるメソッドとそのパラメーターおよび返り値の型を記述するようになっている。 サーバーサイドではインタフェースを実装し、クライアントからの呼び出しをハンドリングするgRPCサーバーを実行する。 クライアントサイドではサーバーと同じメソッドを提供するスタブを持っている。
gRPCクライアントとサーバーは様々な環境同士でやり取りすることができ、いくつもの言語でサポートされている。 そのため例えば、gRPCサーバーをJavaでクライアントをGoやPython、Rubyで作るのも可能だ。 加えて、最新のGoodle APIにはgRPCのインタフェースが存在するので、これらをアプリケーションに組み込むのも容易にできる。
Protobuf デフォルトではgRPCはprotobuf(protocol buffers)でやり取りする。 protobufというのは、 Googleによるオープンソースのシリアライズフォーマット。
今回作るのは、同じ文字列を返すだけのEchoサーバーで、コードはここにある。 以下のprotoファイルでは、EchoというサービスはRetEchoというメソッドを含み、 これは文字列sayを含むEchoRequestに対して、文字列retを含むEchoReplyを返すということを表している。
syntax = &amp;#34;proto3&amp;#34;; option java_package = &amp;#34;net.sambaiz.trygrpc.protos&amp;#34;; package protos; service Echo { rpc RetEcho (EchoRequest) returns (EchoReply) {} } message EchoRequest { string say = 1; } message EchoReply { string ret = 1; } これをprotocでコンパイルするとecho.</description>
    </item>
    
    <item>
      <title>MySQLで大文字小文字を区別しないのを直す</title>
      <link>https://www.sambaiz.net/article/11/</link>
      <pubDate>Sun, 24 Jul 2016 22:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/11/</guid>
      <description>Collationの話。
MySQL 5.6 CREATE TABLE sample ( id SERIAL, name VARCHAR(30) ) ENGINE=InnoDB CHARACTER SET utf8mb4; INSERT INTO sample (name) VALUES (&amp;#39;tom&amp;#39;),(&amp;#39;Tom&amp;#39;),(&amp;#39;TOM&amp;#39;); このテーブルを&amp;quot;tom&amp;quot;で絞り込むとこうなる。大文字小文字を区別していない。
mysql&amp;gt; SELECT * FROM sample2 WHERE name = &amp;#39;tom&amp;#39;; +----+------+ | id | name | +----+------+ | 1 | tom | | 2 | Tom | | 3 | TOM | +----+------+ 3 rows in set (0.01 sec) MySQL :: MySQL 5.6 リファレンスマニュアル :: B.5.5.1 文字列検索での大文字/小文字の区別
 単純な比較操作 (&amp;gt;=、&amp;gt;、=、&amp;lt;、&amp;lt;=、ソート、およびグループ化) は、各文字の「ソート値」に基づきます。 同じソート値を持つ文字は同じ文字として扱われます。たとえば、「e」 と 「é」 が対象の照合順序で同じソート値を持つ場合は、等しいと判断されます。</description>
    </item>
    
    <item>
      <title>グラフデータベースNeo4jを触ってみた</title>
      <link>https://www.sambaiz.net/article/10/</link>
      <pubDate>Thu, 21 Jul 2016 09:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/10/</guid>
      <description>社内勉強会でオープンソースの グラフデータベースNeo4jが紹介されていたので触ってみた。
What is a Graph Database? つながりも含めたグラフとしてデータを扱うデータベース。 データセットのサイズによらず、複雑なつながりや、クエリをうまく扱える。 無数のデータの中から、関係ないデータを見ることなく多数のノードとつながりからなる必要なデータだけを取れる。
インストール ここからCommunity Editionを選んで OSごとに用意されている実行ファイルをダウンロードしてくる。 ファイルを実行し、Startを押すとブラウザで開けるようになる。
グラフ グラフは以下の要素から構成される。
 Node: データそのもので、まとめるためのラベルを複数付けられる Relationships: typeを持つ、Nodeのつながり Properties: NodeやRelationshipsが持てるkey-valueの値  Cypher Neo4jで使うクエリ言語。
まずはCREATE文でNodeを作る。Personはラベルだ。
CREATE (ee:Person { name: &amp;#34;Emil&amp;#34;, from: &amp;#34;Sweden&amp;#34;, klout: 99 }) CREATE文では使われていなかった謎のeeだが、MATCH文を見るとデータが格納される変数だということがわかる。 このeeは次のCREATE文でも参照できて、(ee)-[:KNOWS {since: 2001}]-&amp;gt;(js)で 作ったNodeとのRelationshipsを張るのに使っている。
MATCH (ee:Person) WHERE ee.name = &amp;#34;Emil&amp;#34; RETURN ee; CREATE (js:Person { name: &amp;#34;Johan&amp;#34;, from: &amp;#34;Sweden&amp;#34;, learn: &amp;#34;surfing&amp;#34; }), (ir:Person { name: &amp;#34;Ian&amp;#34;, from: &amp;#34;England&amp;#34;, title: &amp;#34;author&amp;#34; }), (rvb:Person { name: &amp;#34;Rik&amp;#34;, from: &amp;#34;Belgium&amp;#34;, pet: &amp;#34;Orval&amp;#34; }), (ally:Person { name: &amp;#34;Allison&amp;#34;, from: &amp;#34;California&amp;#34;, hobby: &amp;#34;surfing&amp;#34; }), (ee)-[:KNOWS {since: 2001}]-&amp;gt;(js),(ee)-[:KNOWS {rating: 5}]-&amp;gt;(ir), (js)-[:KNOWS]-&amp;gt;(ir),(js)-[:KNOWS]-&amp;gt;(rvb), (ir)-[:KNOWS]-&amp;gt;(js),(ir)-[:KNOWS]-&amp;gt;(ally), (rvb)-[:KNOWS]-&amp;gt;(ally) 以下のようにパターンマッチもできる。この例だとEmilの友達が取得できる。</description>
    </item>
    
    <item>
      <title>Kubernetesのチュートリアルをたどる</title>
      <link>https://www.sambaiz.net/article/9/</link>
      <pubDate>Mon, 18 Jul 2016 22:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/9/</guid>
      <description>Kubernetesとは Kubernetes(発音はkoo-ber-nay&#39;-tace。 ギリシャ語で操舵手。)はGoogleによって開発が始められた、アプリケーションコンテナにおける自動デプロイ、スケーリング、操作を 自動化するOSS。K8sと略される。
Minikube K8sをローカルで試すために、MinikubeというVMの中で単一ノードのK8sクラスターを動かすツールを入れる。
v0.6.0
curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.6.0/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/ $ minikube start Starting local Kubernetes cluster... ... $ kubectl version Client Version: version.Info{Major:&amp;#34;1&amp;#34;, Minor:&amp;#34;2&amp;#34;, GitVersion:&amp;#34;v1.2.4&amp;#34;, GitCommit:&amp;#34;3eed1e3be6848b877ff80a93da3785d9034d0a4f&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;} Server Version: version.Info{Major:&amp;#34;1&amp;#34;, Minor:&amp;#34;3&amp;#34;, GitVersion:&amp;#34;v1.3.0&amp;#34;, GitCommit:&amp;#34;283137936a498aed572ee22af6774b6fb6e9fd94&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;} Pods K8sではコンテナのグループをpodと呼ぶ。pod中のコンテナは共にデプロイされ、起動し、停止する。 また、グループとして複製される。
Podの定義は次のようにyamlで書かれる。
apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 Podの定義に望ましい状態を記述すると、Kubernatesはそれを見て現在の状態が一致しているかどうか確認する。 例えば、Podが作られたときに、コンテナがその中で動いている状態が望ましい状態だとすると、 コンテナが動かなくなったときに、Kubernatesは新しいものを再作成することで望ましい状態にする。</description>
    </item>
    
    <item>
      <title>Node.jsのバージョン管理</title>
      <link>https://www.sambaiz.net/article/8/</link>
      <pubDate>Fri, 15 Jul 2016 19:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/8/</guid>
      <description>n nodeが必要だが手軽。
n latest, n stable, n ltsでバージョンが切り替わる。 バージョンを指定する場合、n &amp;lt;version&amp;gt;でインストールし、nでインストールされているバージョンの一覧から選択できる。 バージョンの削除はn - &amp;lt;version&amp;gt;。
$ npm install -g n $ n stable $ node -v v6.2.2 nvm nodeが必要ない。
$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.1/install.sh | bash $ nvm install node $ node -v v7.7.2 $ nvm install 6 $ node -v v6.10.0 $ nvm ls v6.10.0 -&amp;gt; v7.7.2 default -&amp;gt; node (-&amp;gt; v7.7.2) node -&amp;gt; stable (-&amp;gt; v7.7.2) (default) stable -&amp;gt; 7.7 (-&amp;gt; v7.</description>
    </item>
    
    <item>
      <title>Docker公式ドキュメント&#34;network コマンドを使う&#34;を読む</title>
      <link>https://www.sambaiz.net/article/7/</link>
      <pubDate>Fri, 15 Jul 2016 00:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/7/</guid>
      <description>Docker version 1.12.0-rc2 公式ドキュメントnetwork コマンドを使う の内容をまとめてみた。
dockerには3つのデフォルトネットワークが存在する。docker run時に--netオプションでネットワークを指定しない限り、 docker0として表示されるbridgeネットワークにコンテナを接続する。
$ docker network ls NETWORK ID NAME DRIVER SCOPE a3b712537566 bridge bridge local f6d86cb54edd host host local 33cb30b024d9 none null local ただし、後方互換性を維持するため、デフォルトのbridgeネットワークでは自動的に名前解決が行われない。
これらのネットワークとは別にユーザー定義のネットワークを作成することもできる。 単一ホストのbridgeネットワークと、複数ホストにまたがるoverlayネットワークから選択でき、 何も指定しなかったらbridgeになる。subnetを指定しなければ、 dockerデーモンがネットワークに対してサブネットを自動的に割り当てるが、 dockerが管理していないサブネットと重複するのを避けるために指定することが推奨されている。
$ docker network create -d bridge --subnet 172.25.0.0/16 isolated_nw $ docker network inspect isolated_nw $ docker network rm isolated_nw # 削除 docker network inspectで以下のようなネットワークの情報が得られる。
[ { &amp;#34;Name&amp;#34;: &amp;#34;isolated_nw&amp;#34;, &amp;#34;Id&amp;#34;: &amp;#34;c81547cf7ed897054ea645192c6c47dcf7a248e77bc8067609becab5330e417d&amp;#34;, &amp;#34;Scope&amp;#34;: &amp;#34;local&amp;#34;, &amp;#34;Driver&amp;#34;: &amp;#34;bridge&amp;#34;, &amp;#34;EnableIPv6&amp;#34;: false, &amp;#34;IPAM&amp;#34;: { &amp;#34;Driver&amp;#34;: &amp;#34;default&amp;#34;, &amp;#34;Options&amp;#34;: {}, &amp;#34;Config&amp;#34;: [ { &amp;#34;Subnet&amp;#34;: &amp;#34;172.</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアル2(Deep MNIST for Experts)</title>
      <link>https://www.sambaiz.net/article/6/</link>
      <pubDate>Tue, 12 Jul 2016 21:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/6/</guid>
      <description>前回に引き続き、まとめながら進めていく。
Deep MNIST for Experts
Start TensorFlow InteractiveSession 今回は、前回のようにグラフを作成してからSessionを開始する代わりに InteractiveSessionを使う。 グラフを作成し実行するのをインタラクティブに行うことができ、IPythonのような環境で便利だ。
import tensorflow as tf sess = tf.InteractiveSession() Build a Multilayer Convolutional Network 前回のシンプルなモデルではあまり良い結果が出なかった。 そこで、今回はもう少し良いモデルの畳み込みニューラルネットワークを作成する。
Weight Initialization 勾配が0になるのを避けるために重みの初期化時にノイズを付ける。 tf.truncated_normalは正規分布で、μ±2σ範囲内のランダムな値を返す。 以下の例だと、meanのデフォルトが0.0なので、正規分布 N(0, 0.01)の、-0.2&amp;lt;=x&amp;lt;=0.2な値がランダムに返ることになる。
また、ReLU(Rectified Linear Unit, 正規化線形関数)ニューロンを使うので、&amp;ldquo;死んだニューロン&amp;quot;を避けるために、バイアスは小さな正の値で初期化する。
ニューラルネットワークと活性化関数 - sambaiz-net
def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) Convolution and Pooling TensorFlowに畳み込みとプーリングの関数が用意されている。
畳み込みというのは、画像に対してフィルターを少しずつ動かしながら掛けていく処理のこと。このページが分かりやすい。 例えば、ソーベルフィルタで輪郭になっているところを抽出するように、 フィルターの値によって、その区域における、ある特徴を際立たせたりすることができる。 今回はこのフィルターが重みとなり、際立たせたいのはその数字を識別するための特徴ということになる。 前回は画像を一次元の配列として扱い重みを学習していたので、縦の情報が失われていたが、この方法ではそれがない。
プーリングというのは画像から区域ごとにサンプリングする処理のこと。最大プーリングや、平均プーリングなどの手法がある。 畳み込みのように順番に区域を見ていって、最大プーリングならそのうちの最大のものを採用し、他のものは無視する。 サイズが小さくなるだけではなく、ちょっとした位置のずれを吸収することができる。
def conv2d(x, W): return tf.</description>
    </item>
    
    <item>
      <title>webpack環境でredux&amp;react-routerのページをサーバーサイドレンダリングする</title>
      <link>https://www.sambaiz.net/article/5/</link>
      <pubDate>Sun, 10 Jul 2016 03:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/5/</guid>
      <description>このページをGoogleのSearch Consoleからクローラーがちゃんと見ているか確認してみたところ真っ白のページになってしまったので、 サーバーサイドレンダリングすることにした。 コードはgithubに上げてある。
サーバーサイドとはいえ、css-loaderでcss moduleを使っているのでwebpackを使う必要があった。 まず、そのままのwebpackの設定で作ったものをserver.jsから呼ぶと次のエラーが出た。
***/sambaiz-net/web/public/bundle.js:20933 module.exports = self.fetch.bind(self); ReferenceError: self is not defined そこで、targetをnodeにしたサーバーサイド用にwebpackの設定を作成し、実行してみたところ
module.exports = { entry: &amp;#39;./js/server.js&amp;#39;, target: &amp;#39;node&amp;#39;, output: { path: path.join(__dirname, &amp;#39;dist&amp;#39;), filename: &amp;#39;server.js&amp;#39;, publicPath: &amp;#39;/&amp;#39; }, 今度はこんなエラーが出たので
ERROR in ./~/iconv-lite/encodings/tables/gb18030-ranges.json Module parse failed: ***/sambaiz-net/web/node_modules/iconv-lite/encodings/tables/gb18030-ranges.json Unexpected token (1:9) You may need an appropriate loader to handle this file type. loadersに下の設定を追加した。
{ test: /\.json$/, loader: &amp;#34;json-loader&amp;#34;} webpackには成功したが、serverを起動すると今度は次のようなエラーが出た。
return /msie [6-9]\b/.test(window.navigator.userAgent.toLowerCase()); ReferenceError: window is not defined style-loaderのコードだったので、 まず、フロント側のwebpackで extract-text-webpack-pluginを使ってcssを別に出力することにした。</description>
    </item>
    
    <item>
      <title>MySQLのUNIX_TIMESTAMPにある程度未来の日付を渡すと0になる</title>
      <link>https://www.sambaiz.net/article/4/</link>
      <pubDate>Mon, 04 Jul 2016 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/4/</guid>
      <description>以下、MySQL5.6で遭遇した。
MySQLのUNIX_TIMESTAMPは DATETIME文字列などを引数にとり、UNIXタイムスタンプ(1970-01-01 00:00:00 UTCを起点とした経過秒数)を返す関数だ。
mysql&amp;gt; SET SESSION time_zone = &amp;#39;UTC&amp;#39;; mysql&amp;gt; select UNIX_TIMESTAMP(&amp;#39;1970-01-01 00:00:00&amp;#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&amp;#39;1970-01-01 00:00:00&amp;#39;) | +---------------------------------------+ | 0 | +---------------------------------------+ 1 row in set (0.00 sec) ただし、2038年1月19日3時14分7秒(UTC)以降を渡すと0になってしまう。 これはドキュメントにも書いてある通り範囲外だから。
mysql&amp;gt; select UNIX_TIMESTAMP(&amp;#39;2038-01-19-03-14-07&amp;#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&amp;#39;2038-01-19-03-14-07&amp;#39;) | +---------------------------------------+ | 2147483647 | +---------------------------------------+ 1 row in set (0.04 sec) mysql&amp;gt; select UNIX_TIMESTAMP(&amp;#39;2038-01-19-03-14-08&amp;#39;); +---------------------------------------+ | UNIX_TIMESTAMP(&amp;#39;2038-01-19-03-14-08&amp;#39;) | +---------------------------------------+ | 0 | +---------------------------------------+ 1 row in set (0.00 sec) では、この境目は何かというと、32ビットで表せる符号付数値の最大値だ。</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアルまで</title>
      <link>https://www.sambaiz.net/article/3/</link>
      <pubDate>Sun, 03 Jul 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/3/</guid>
      <description>Googleが公開した人工知能ライブラリTensorFlowを使ってみる。 セットアップ方法はいくつか提供されているが、Dockerで動かすことにした。 Jupyter Notebookが立ち上がるのですぐに試せて良い。
$ docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow http://localhost:8888/tree
公式のチュートリアルをまとめながら進めてみる。
MNIST For ML Beginners
The MNIST Data MNISTというのは0~9の書き数字の画像のデータセットのことで、これらを正しく分類するのが目的。
それぞれの画像は一律28*28=784ピクセルで、それぞれのピクセルは0と1の間の数値(強さ)で表されている。 今回はこれの縦横を取っ払って784次元のベクトルとして扱っている。
したがって、学習用の画像データは[55000, 784]のtensor(n次元の配列)で表される。 55000というのが画像の数で、784というのがそれぞれの画像の次元を意味している。
それぞれの画像に対応した数字のラベルは[55000, 10]で表される。 10というのは、0~9それぞれに対応した次元のうち、一つだけ1で、それ以外が0という風に使われる。これをone-hot vectorという。
Softmax Regressions Softmaxはいくつかの異なるもの(今回でいうと数字)に確率を割り当てる。
画像が特定のクラス(0~9)に属するかどうか計算するために、ピクセルの強さに重みを付けた合計を計算する。 もし、そのピクセルがそのクラスに属さない根拠になるなら負の重みがかかり、属する根拠になるなら、正の重みがかかるようにする。 また合計にさらに入力と無関係なクラスごとに異なるバイアスを足す。
全てのクラスで計算した値をsoftmax関数に入れ、それぞれ確率に変換する。この確率の和は1になるようになっている。
Implementing the Regression Pythonでは行列の積のような重い処理をするとき、NumPyのようなライブラリを使ってPythonの外で行うが、 外からPythonに戻るときにオーバーヘッドが発生してしまう。 TensorFlowでも重い処理を外で行うが、オーバーヘッドを避けるために、 単体の重い処理をPythonから独立して実行するのではなく、Pythonの外側で実行される関連した処理のグラフを記述させる。
import tensorflow as tf x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b) tf.placeholderは実行時に与えられる値で、今回が画像データ。 W(重み)とb(バイアス)は学習する変数。 tf.matmul(x, W) + bの部分が重みを付けた合計にバイアスを足したものに対応している。 matmulはmatrix multiple、つまり行列の積。</description>
    </item>
    
    <item>
      <title>Reactで作ったページにTwitterCardsとOGPのメタデータを埋める</title>
      <link>https://www.sambaiz.net/article/2/</link>
      <pubDate>Sat, 02 Jul 2016 13:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/2/</guid>
      <description>せっかくページを作ったので、SNSにシェアするときに見栄えをよくしたい。
 Twitter CardsやOGPのmetaタグを埋めるとTwitterやFacebookにURLを貼ったときに上のように表示されるようになる(上はFacebookの例)。そこで、react-helmetでこんな感じで動的に埋め込んだんだが読んでくれない。
&amp;lt;Helmet title={&amp;#39;sambaiz.net&amp;#39;} meta={[ {&amp;#34;name&amp;#34;: &amp;#34;twitter:card&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;summary&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;twitter:site&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;@sambaiz&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;twitter:title&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;sambaiz.net&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;twitter:description&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;僕のホームページ&amp;#34;}, {&amp;#34;property&amp;#34;: &amp;#34;og:title&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;sambaiz.net&amp;#34;}, {&amp;#34;property&amp;#34;: &amp;#34;og:type&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;blog&amp;#34;}, {&amp;#34;property&amp;#34;: &amp;#34;og:image&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;http://d2wgaf7ubdj1mv.cloudfront.net/my.jpg&amp;#34;}, {&amp;#34;property&amp;#34;: &amp;#34;og:url&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;https://www.sambaiz.net&amp;#34;} ]} /&amp;gt; GoogleのクローラーのようにJavascriptを解釈してくれる と思っていた。
しょうがないのでここだけサーバーサイドレンダリングすることにした。
&amp;#39;use strict&amp;#39; import express from &amp;#39;express&amp;#39; import path from &amp;#39;path&amp;#39; import compression from &amp;#39;compression&amp;#39; require(&amp;#39;isomorphic-fetch&amp;#39;); var app = express() app.use(compression()) // serve our static stuff app.use(express.static(path.join(__dirname, &amp;#39;.</description>
    </item>
    
    <item>
      <title>ブログを作った</title>
      <link>https://www.sambaiz.net/article/1/</link>
      <pubDate>Wed, 29 Jun 2016 23:43:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/1/</guid>
      <description>最近表に出るものを作っていなかったので、このサイトを作ってみた。
表はReact/Reduxで、裏側はAWSのLambdaでサーバーレスに作ってある。 コードはgithubに公開してみた。
これを期になるべくアウトプットしていこうと思う。大抵三日坊主なのだけれど。
&amp;ndash;
追記: 今はHugoに置き換わっている
静的ウェブサイトエンジンHugoに乗り換えた</description>
    </item>
    
  </channel>
</rss>
