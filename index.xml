<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sambaiz-net</title>
    <link>https://www.sambaiz.net/</link>
    <language>ja</language>
    <author>sambaiz</author>
    <rights>(C) 2018</rights>
    <updated>2018-12-01 23:09:00 &#43;0900 JST</updated>

    
      
        <item>
          <title>Encoder-Decoder RNNのAttention</title>
          <link>https://www.sambaiz.net/article/200/</link>
          <pubDate>Sat, 01 Dec 2018 23:09:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/200/</guid>
          <description>&lt;p&gt;Encoder-Decoder RNNは入力用のEncoderと出力用のDecoderの2つのLSTMを組み合わせたもので、EncoderのStateはDecoderに繋げる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/200.png&#34; alt=&#34;Encoder-Decoder RNN&#34; /&gt;&lt;/p&gt;

&lt;p&gt;したがって入力データはDecoderに渡されるStateにまとめられることになるが、
出力ごとに入力時系列の重要な部分は異なるため、特定の部分に注目できるようにすると良い結果が期待できる。
次の論文ではAttention Layerを追加することでこれを行い翻訳の精度を向上させている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1508.04025&#34;&gt;Minh-Thang Luong, Hieu Pham, Christopher D. Manning (2015) Effective Approaches to Attention-based Neural Machine Translation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Attention LayerはEncoderの出力とDecoderの対象の出力からどの部分を重要とするかを表すAlign weightsと
Encoderの出力を掛けたものをContext vectorとして出力する。
scoreにはそのまま掛けたものや(&lt;code&gt;h_{dec}h_{enc}&lt;/code&gt;)、重みとDecoderの出力のみを掛ける(&lt;code&gt;Wh_{dec}&lt;/code&gt;)といったものが使われる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/200-2.png&#34; alt=&#34;Attention Layer&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/200-3.png&#34; alt=&#34;Align weightsとContext vectorの式&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</title>
          <link>https://www.sambaiz.net/article/199/</link>
          <pubDate>Tue, 27 Nov 2018 09:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/199/</guid>
          <description>

&lt;p&gt;TPU(Tensor Processing Unit)は
Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。
&lt;a href=&#34;https://cloudplatform-jp.googleblog.com/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu.html&#34;&gt;一般的なGPUと比べて15~30倍もの性能が出る&lt;/a&gt;
らしく検索や翻訳などGoogleのサービスでも使われている。&lt;/p&gt;

&lt;p&gt;TPUを使える環境として、無料で使えるJupyter Notebooksの&lt;a href=&#34;https://colab.research.google.com/&#34;&gt;Google Colab&lt;/a&gt;と
GCPの&lt;a href=&#34;https://cloud.google.com/tpu/&#34;&gt;Cloud TPU&lt;/a&gt;がある。ColabのTPUも裏側ではCloud TPUが動いている。
Cloud TPUを直に使うとVMから接続して使うことになるので、TPUの&lt;a href=&#34;https://cloud.google.com/tpu/docs/pricing&#34;&gt;料金&lt;/a&gt;に加えてVMの料金もかかる。&lt;/p&gt;

&lt;h2 id=&#34;モデルのtpu対応&#34;&gt;モデルのTPU対応&lt;/h2&gt;

&lt;p&gt;CNNのモデルを&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimator&#34;&gt;TPUEstimator&lt;/a&gt;でTPUに対応させる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/guide/estimators&#34;&gt;Estimator&lt;/a&gt;はTensorFlowの高レベルAPIで、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#train&#34;&gt;train()&lt;/a&gt;、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate&#34;&gt;evaluate()&lt;/a&gt;、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#predict&#34;&gt;predict()&lt;/a&gt;、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#export_saved_model&#34;&gt;export_saved_model()&lt;/a&gt;
といったモデルの学習から保存まで必要な機能を一通り提供する。&lt;/p&gt;

&lt;p&gt;初めは比較的低レベルのAPIを使おうとしていたが、XLA(Accelerated Linear Algebra)によるコンパイルがうまくいかないなど様々な問題にあたって大変だったので使っておくと良いと思う。
それでもトライアンドエラーの繰り返しで、典型的なものは&lt;a href=&#34;https://cloud.google.com/tpu/docs/troubleshooting&#34;&gt;Troubleshooting&lt;/a&gt;にあるが、ないものは調べるなりしてなんとかやっていくしかない。&lt;/p&gt;

&lt;p&gt;定数などの定義。BATCH_SIZEはCloud TPUのシャード数の8で割り切れる値にする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
from sklearn.model_selection import train_test_split
import tensorflow as tf
import numpy as np
flags = tf.app.flags
flags.DEFINE_boolean(&#39;use_tpu&#39;, True, &#39;use tpu or not&#39;)
tf.app.flags.DEFINE_string(&#39;f&#39;, &#39;&#39;, &#39;kernel&#39;)
FLAGS = flags.FLAGS

EPOCH_NUM = 100
BATCH_SIZE = 800 # must be divisible by number of replicas 8
EVAL_BATCH_SIZE = 800
SHARD_NUM = 8 # A single Cloud TPU has 8 shards.
ITERATION_NUM = 100 # Number of training steps to run on the Cloud TPU before returning control.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;入力データの準備&#34;&gt;入力データの準備&lt;/h3&gt;

&lt;p&gt;入力は関数で渡し、tf.data APIのdatasetを返せばイテレートしてくれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/195/&#34;&gt;TensorFlowのtf.data API - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;batch()でdrop_remainderをTrueにして端数を切り捨てないと、shapeが確定せずコンパイルできない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from google.colab import auth
from googleapiclient.discovery import build
from io import BytesIO

auth.authenticate_user()
bucket = &amp;quot;&amp;lt;bucket_name&amp;gt;&amp;quot;
gcs_service = build(&#39;storage&#39;, &#39;v1&#39;)
train_data = gcs_service.objects().get_media(bucket=bucket, object=&#39;train.csv&#39;).execute()
train = pd.read_csv(BytesIO(train_data))

MODEL_DIR = &#39;gs://{}/model/tpu&#39;.format(bucket)

(x_train, x_valid, y_train, y_valid) = train_test_split(
    train.drop(&#39;label&#39;, axis=1).values.reshape((-1, 28, 28, 1)).astype(np.float32), 
    np.identity(10)[train[&#39;label&#39;]].astype(np.float32), 
    test_size = 0.1, random_state = 100)

def train_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({&#39;x&#39;: x_train}, y_train)) # (features, labels)
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(params[&#39;batch_size&#39;], drop_remainder=True)
    return dataset

def valid_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({&#39;x&#39;: x_valid}, y_valid))
    dataset = dataset.batch(params[&#39;batch_size&#39;], drop_remainder=True)
    return dataset
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入出力するファイルはローカルではなくGCSなどに置く必要があるのでCloud TPUからも読み書きできるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;domain&amp;quot;: &amp;quot;global&amp;quot;,
    &amp;quot;reason&amp;quot;: &amp;quot;forbidden&amp;quot;,
    &amp;quot;message&amp;quot;: &amp;quot;service-******@cloud-tpu.iam.gserviceaccount.com does not have storage.objects.create access to &amp;lt;bucket_name&amp;gt;.&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;!gsutil acl ch -u service-*****@cloud-tpu.iam.gserviceaccount.com:WRITER gs://&amp;lt;bucket_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;モデルの作成&#34;&gt;モデルの作成&lt;/h3&gt;

&lt;p&gt;Estimatorには次のシグネチャのmodel_fnを渡す。
引数のfeaturesとlabelsはinput_fnの返り値で、
modeは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys&#34;&gt;tf.estimator.ModeKeys&lt;/a&gt;の&lt;code&gt;TRAIN&lt;/code&gt;、&lt;code&gt;EVAL&lt;/code&gt;、&lt;code&gt;PREDICT&lt;/code&gt;で、
paramsはEstimator生成時に渡せるパラメータ。
optimizerは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/CrossShardOptimizer&#34;&gt;CrossShardOptimizer&lt;/a&gt;で&lt;a href=&#34;https://www.tensorflow.org/guide/using_tpu#optimizer&#34;&gt;wrapする&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;TPUに対応している&lt;a href=&#34;https://cloud.google.com/tpu/docs/tensorflow-ops&#34;&gt;op&lt;/a&gt;で作る必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def model_fn(features, labels, mode, params):
    def metric_fn(labels, logits):
        return {
            &#39;accuracy&#39;: tf.metrics.accuracy(
                labels=tf.argmax(labels, axis=1), predictions=tf.argmax(logits, axis=1))
         }
    is_training = tf.equal(mode, tf.estimator.ModeKeys.TRAIN)
    conv1 = tf.layers.conv2d(
        inputs=features[&#39;x&#39;],
        filters=32, 
        kernel_size=[5, 5], 
        padding=&amp;quot;same&amp;quot;, 
        activation=tf.nn.relu)
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)
    conv2 = tf.layers.conv2d(
        inputs=pool1, 
        filters=64, 
        kernel_size=[5, 5],
        padding=&amp;quot;same&amp;quot;, 
        activation=tf.nn.relu)
    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
    pool2_flat = tf.layers.flatten(pool2)
    dense = tf.layers.dense(inputs=pool2_flat, units=128, activation=tf.nn.relu)
    dropout = tf.layers.dropout(
        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)
    logits = tf.layers.dense(inputs=dropout, units=10)

    loss = tf.losses.softmax_cross_entropy(
        onehot_labels=labels, logits=logits)
    
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.contrib.tpu.TPUEstimatorSpec(mode, loss=loss, 
                                               eval_metrics=(metric_fn, [labels, logits]))

    optimizer = tf.train.AdamOptimizer(0.01)
    if FLAGS.use_tpu:
        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)

    return tf.contrib.tpu.TPUEstimatorSpec(
        mode=mode,
        loss=loss,
        train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tpuestimatorの生成&#34;&gt;TPUEstimatorの生成&lt;/h3&gt;

&lt;p&gt;TPUのアドレスが環境変数COLAB_TPU_ADDRに入るのでこれをmasterとする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if FLAGS.use_tpu:
    master = &#39;grpc://&#39; + os.environ[&#39;COLAB_TPU_ADDR&#39;]
    run_config = tf.contrib.tpu.RunConfig(
        master=master,
        session_config=tf.ConfigProto(
            allow_soft_placement=True, log_device_placement=True),
        tpu_config=tf.contrib.tpu.TPUConfig(ITERATION_NUM, SHARD_NUM))
else:
    run_config = tf.contrib.tpu.RunConfig()

classifier = tf.contrib.tpu.TPUEstimator(
    model_fn=model_fn,
    model_dir=MODEL_DIR,
    config=run_config,
    params={},
    train_batch_size=BATCH_SIZE,
    eval_batch_size=EVAL_BATCH_SIZE,
    use_tpu=FLAGS.use_tpu)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;学習&#34;&gt;学習&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;for epoch in range(EPOCH_NUM):
  max_steps = len(x_train)*(epoch+1)//BATCH_SIZE
  valid_steps = len(x_valid)//EVAL_BATCH_SIZE
  if FLAGS.use_tpu: 
    max_steps //= SHARD_NUM
  train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_steps)
  eval_spec = tf.estimator.EvalSpec(input_fn=valid_input_fn, steps=valid_steps)
  result = tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
  if result[0] is not None:
    print(&#39;epoch: {}, loss: {} accuracy: {}&#39;.format(epoch+1, result[0][&#39;loss&#39;], result[0][&#39;accuracy&#39;]))
  else:
    print(&#39;epoch: {} is already trained&#39;.format(epoch+1))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;colabでtensorboardを開く&#34;&gt;ColabでTensorBoardを開く&lt;/h3&gt;

&lt;p&gt;このスクリプトを実行するとTensorBoardを立ち上げてngrokで外に開いてくれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/mixuala/colab_utils&#34;&gt;mixuala/colab_utils&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;!git clone https://github.com/mixuala/colab_utils
import os
import colab_utils.tboard

# set paths
ROOT = %pwd
LOG_DIR = os.path.join(ROOT, &#39;model&#39;)
colab_utils.tboard.launch_tensorboard(bin_dir=ROOT, log_dir=LOG_DIR)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;学習させて実行時間を計測する。計測はセルの頭に&lt;code&gt;%%time&lt;/code&gt;を付けるとできる。&lt;/p&gt;

&lt;h3 id=&#34;cpu&#34;&gt;CPU&lt;/h3&gt;

&lt;p&gt;ベースライン。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 18min 28s, sys: 32.8 s, total: 19min 1s
Wall time: 14min 33s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;gpu&#34;&gt;GPU&lt;/h3&gt;

&lt;p&gt;ランタイムからアクセラレータをGPUに設定。使われるGPUはNVIDIAの&lt;a href=&#34;https://www.nvidia.co.jp/object/tesla-k80-jp.html&#34;&gt;Tesla K80&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.python.client import device_lib
device_lib.list_local_devices()
# ...
# physical_device_desc: &amp;quot;device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 3min 2s, sys: 24.2 s, total: 3min 26s
Wall time: 8min 6s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tpu&#34;&gt;TPU&lt;/h3&gt;

&lt;p&gt;アクセラレータをTPUに変更。
GPUより速くなることを期待したが、むしろCPUよりも遅くなってしまった。その上精度の伸びも遅くて良いところがない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 3min, sys: 23.8 s, total: 3min 24s
Wall time: 15min
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;再チャレンジ&#34;&gt;再チャレンジ&lt;/h2&gt;

&lt;p&gt;エポックの立ち上がりが遅いので学習を切らずに続けて行わせてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def train_input_fn(params):
    dataset = tf.data.Dataset.from_tensor_slices(({&#39;x&#39;: x_train}, y_train)) # (features, labels)
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(params[&#39;batch_size&#39;], drop_remainder=True)
    dataset = dataset.repeat(EPOCH_NUM)
    return dataset

epoch = EPOCH_NUM-1
max_steps = len(x_train)*(epoch+1)/BATCH_SIZE
valid_steps = len(x_valid)//EVAL_BATCH_SIZE
if FLAGS.use_tpu: 
  max_steps //= SHARD_NUM
train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_steps)
eval_spec = tf.estimator.EvalSpec(input_fn=valid_input_fn, steps=valid_steps)
result = tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
if result[0] is not None:
  print(&#39;epoch: {}, loss: {} accuracy: {}&#39;.format(epoch+1, result[0][&#39;loss&#39;],  result[0][&#39;accuracy&#39;]))
else:
  print(&#39;epoch: {} is already trained&#39;.format(epoch+1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行したところGPUと同程度には速くなった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# GPU
CPU times: user 40.9 s, sys: 7.8 s, total: 48.7 s
Wall time: 1min 43s

# TPU
CPU times: user 35.2 s, sys: 4.46 s, total: 39.7 s
Wall time: 1min 34s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらにEPOCH_NUMを5から100にして再計測する。&lt;/p&gt;

&lt;h2 id=&#34;結果-1&#34;&gt;結果&lt;/h2&gt;

&lt;h3 id=&#34;gpu-1&#34;&gt;GPU&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 3min 27s, sys: 2min, total: 5min 28s
Wall time: 6min 5s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tpu-1&#34;&gt;TPU&lt;/h3&gt;

&lt;p&gt;エポック数を大幅に増やしたのにも関わらずほとんど実行時間が変わらずとても速い。
CPU時間も変わっていないので演算がTPUで完結していてCPU-TPU間のデータの受け渡しが最小限で済んでいるのかもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 34.5 s, sys: 7.32 s, total: 41.8 s
Wall time: 1min 38s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d&#34;&gt;Google Colab Free GPU Tutorial – Deep Learning Turkey – Medium&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/koshian2/items/fb989cebe0266d1b32fc&#34;&gt;Google ColabのTPUで対GPUの最速に挑戦する - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する</title>
          <link>https://www.sambaiz.net/article/198/</link>
          <pubDate>Wed, 14 Nov 2018 02:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/198/</guid>
          <description>

&lt;h2 id=&#34;batch-normalizationとは&#34;&gt;Batch Normalizationとは&lt;/h2&gt;

&lt;p&gt;Deep Learningでは各層の学習を同時に行うため、前の層の変更によって各層の入力の分布が変わってしまうinternal covariate shiftという現象が起こり、そのためにパラメータの初期化をうまくやる必要があったり、学習率を大きくできず多くのステップを要する。
以下の論文で発表されたBatch Normalization(BN)は各層の入力を正規化して分布を固定することでこれを解決するというもの。
画像認識のコンテスト&lt;a href=&#34;http://image-net.org/challenges/LSVRC/2015/results&#34;&gt;ILSVRC 2015&lt;/a&gt;で1位を取った&lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34;&gt;ResNet(Residual Network)&lt;/a&gt;でも使われている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1502.03167&#34;&gt;Sergey Ioffe, Christian Szegedy (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;具体的にはWx+bと活性化関数の間にBNの層を入れる。μ、σ^2は入力xの平均と分散。
単に正規化するだけでは表現力が下がってしまうのでγとβでスケールやシフトできるようにする。これらの変数は他のパラメータと同様に学習させる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/198.png&#34; alt=&#34;BN層の演算&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;tensorflowでの確認&#34;&gt;TensorFlowでの確認&lt;/h2&gt;

&lt;p&gt;TensorFlowでは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization&#34;&gt;batch_normalization()&lt;/a&gt;がすでに実装されているのでこれを使う。&lt;/p&gt;

&lt;p&gt;以下のCNNで学習率を高めに設定しBNありなしの結果を比較する。学習データはmnist。MonitoredSessionでcostをsummaryとして出力しTensorBoardで見られるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/147/&#34;&gt;TensorBoardでsummaryやグラフを見る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/175/&#34;&gt;TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score

train = pd.read_csv(&#39;./train.csv&#39;)
(x_train, x_valid ,y_train, y_valid) = train_test_split(
    train.drop(&#39;label&#39;, axis=1).values.reshape((-1, 28, 28, 1)), 
    np.identity(10)[train[&#39;label&#39;]], 
    test_size = 0.1, random_state = 100)

print(&amp;quot;data shape: {}, label shape {}&amp;quot;.format(x_train.shape, y_train.shape))

tf.reset_default_graph()

class ConvBnRelu:
    def __init__(self, filters, kernel_size):
        self.filters = filters
        self.kernel_size= kernel_size
        
    def __call__(self, x, use_bn, is_training):
        h = tf.layers.Conv2D(filters=self.filters, kernel_size=self.kernel_size)(x)
        h = tf.cond(
            use_bn,
            true_fn=lambda: tf.layers.batch_normalization(h, training=is_training),
            false_fn=lambda: h
        )
        return tf.nn.relu(h)

is_training = tf.placeholder(tf.bool, shape=())
use_bn = tf.placeholder(tf.bool, shape=())
x = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32)
t = tf.placeholder(tf.float32, [None, 10])

with tf.name_scope(&amp;quot;Conv1&amp;quot;):
    h = ConvBnRelu(filters=32, kernel_size= [3, 3])(x, use_bn, is_training)
    h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h)

with tf.name_scope(&amp;quot;Conv2&amp;quot;):
    h = ConvBnRelu(filters= 64, kernel_size= [3, 3])(h, use_bn, is_training)
    h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h)

h = tf.layers.Flatten()(h)
y = tf.layers.Dense(units=10, activation=tf.nn.softmax)(h)

global_step=tf.train.get_or_create_global_step()
cost = - tf.reduce_mean(tf.reduce_sum(t * tf.log(tf.clip_by_value(y, 1e-10, y)), axis=1))
summary_cost = tf.summary.scalar(&#39;cost&#39;, cost)
optimizer = tf.train.AdamOptimizer(0.01).minimize(cost, global_step=global_step)

EPOCH_NUM = 5
BATCH_SIZE = 100

hooks = [
    tf.train.StopAtStepHook(last_step=EPOCH_NUM*(len(x_train) // BATCH_SIZE))
]

init = tf.global_variables_initializer()

for bn in [False, True]:
    epoch = -1
    print(&amp;quot;--- use binary norm: {} ---&amp;quot;.format(bn))
    with tf.train.MonitoredTrainingSession(
        hooks=hooks, 
        summary_dir=&amp;quot;/home/jovyan/summary&amp;quot;,
        save_summaries_steps=100) as sess:    
        sess.run(init, feed_dict={x: x_valid, t: y_valid, is_training: False, use_bn: bn})
        while not sess.should_stop():
            epoch += 1
            y_pred, cost_valid, _ = sess.run([y, cost, summary_cost], feed_dict={x: x_valid, t: y_valid, is_training: False, use_bn: bn})
            print(&amp;quot;epoch: {:2d}, cost: {:.4f}, accuracy: {:.4f}&amp;quot;.format(
                epoch, cost_valid, accuracy_score(y_pred.argmax(axis=1), y_valid.argmax(axis=1))))
            x_train, y_train = shuffle(x_train, y_train, random_state=100)
            for batch in range(len(x_train) // BATCH_SIZE):
                start = batch * BATCH_SIZE
                end = start + BATCH_SIZE
                sess.run(optimizer, feed_dict={x: x_train[start:end], t: y_train[start:end], is_training: True, use_bn: bn})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BNを行わなかったときの結果。コストを下げられていない。ちなみに学習率を0.01から0.001にしたら下げられるようになった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/198-2.png&#34; alt=&#34;BNしない場合のコスト&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一方、BNを行ったときの結果がこれ。学習率はそのままで順調にコストを下げることができている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/198-3.png&#34; alt=&#34;BNした場合のコスト&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow&#43;numpyでData Augmentationして画像の学習データを増やす</title>
          <link>https://www.sambaiz.net/article/197/</link>
          <pubDate>Sun, 11 Nov 2018 15:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/197/</guid>
          <description>

&lt;p&gt;Data Augmentationは学習データを加工したものを学習データに加えることで数を増やすというもの。
加工したデータには通常元のものと同じラベルが付くことになるが、
例えば画像を反転や回転させても元々のものと同じだと認識されるべきだとしたら妥当だ。
つまり、なんでもすれば良いわけではなくデータセットに応じた、元のデータと同じラベルが付くような加工をする必要があり、
裏を返せばそのような違いがあっても同じものであることをモデルに学習させることができる。&lt;/p&gt;

&lt;p&gt;今回はData Augmentationで行われる加工をTensorFlowやnumpyの関数でおなじみLennaの画像に行う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna.png&#34; alt=&#34;Lenna&#34; /&gt;&lt;/p&gt;

&lt;p&gt;必要なパッケージと画像をimportする。Jupyter Notebooksで実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%matplotlib inline
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
im = Image.open(&amp;quot;lenna.png&amp;quot;, &amp;quot;r&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;flipping&#34;&gt;Flipping&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/flip_left_right&#34;&gt;flip_left_right()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/random_flip_left_right&#34;&gt;random_flip_left_right()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/flip_up_down&#34;&gt;flip_up_down()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/random_flip_up_down&#34;&gt;random_flip_up_down()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;左右と上下の反転。randomは1/2で反転する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fliph = tf.image.flip_left_right(im)
flipv = tf.image.flip_up_down(im)

with tf.Session() as sess:
    results = sess.run([fliph, flipv])
plt.imshow(np.hstack(results))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna2.png&#34; alt=&#34;左右と上下反転したLenna&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;rotating&#34;&gt;Rotating&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/rot90&#34;&gt;rot90()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;反時計周りに90度回転させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rot90 = tf.image.rot90(im)

with tf.Session() as sess:
    results = sess.run([rot90])
plt.imshow(np.hstack(results))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna3.png&#34; alt=&#34;90度回転したLenna&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;cropping&#34;&gt;Cropping&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/central_crop&#34;&gt;central_crop()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/crop_to_bounding_box&#34;&gt;crop_to_bounding_box()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/image/random_crop&#34;&gt;random_crop()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;中央と一部分の切り取り。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;central_crop = tf.image.central_crop(im, 0.7)
crop_to_box =  tf.image.crop_to_bounding_box(im, 50, 50, 100, 100)
ops = [tf.cast(tf.image.resize_images(op, (200, 200)), tf.uint8) for op in [central_crop, crop_to_box]]
with tf.Session() as sess:
    results = sess.run(ops)
plt.imshow(np.hstack(results))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna4.png&#34; alt=&#34;中央と一部分を切り取ったLenna&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;cutout&#34;&gt;Cutout&lt;/h3&gt;

&lt;p&gt;以下の論文にあるランダムな正方形の領域をマスキングすることで、画像の一部分だけではなくなるべく全体のコンテキストを使わせる手法。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1708.04552&#34;&gt;Terrance DeVries, Graham W. Taylor (2017) Improved Regularization of Convolutional Neural Networks with Cutout&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/187/&#34;&gt;numpyの関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def random_cutout(image, size = 100):
    w = image.shape[0]
    h = image.shape[1]
    mask = np.ones((w, h, 3), np.uint8)
    x = np.random.randint(w)
    y = np.random.randint(h)
    x1 = np.clip(x - size // 2, 0, w)
    x2 = np.clip(x + size // 2, 0, w)
    y1 = np.clip(y - size // 2, 0, h)
    y2 = np.clip(y + size // 2, 0, h)
    mask[x1: x2, y1: y2] = 0
    return im * mask

result = random_cutout(np.array(im))
plt.imshow(result)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/197-lenna5.png&#34; alt=&#34;CutoutしたLenna&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>FargateでECSを使う</title>
          <link>https://www.sambaiz.net/article/196/</link>
          <pubDate>Fri, 09 Nov 2018 00:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/196/</guid>
          <description>

&lt;p&gt;ECSはAWSのコンテナオーケストレーションサービス。
クラスタは&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/launch_types.html#launch-type-ec2&#34;&gt;EC2上に立てる&lt;/a&gt;こともできるが、その場合Auto Scalingグループの設定や&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/how-to-automate-container-instance-draining-in-amazon-ecs/&#34;&gt;スケールイン時のdrain&lt;/a&gt;などを考慮する必要がある。
&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/launch_types.html#launch-type-fargate&#34;&gt;Fargate&lt;/a&gt;で起動するとサーバーレスで実行でき、バックエンドの管理が必要がなくなる。
&lt;a href=&#34;https://aws.amazon.com/jp/fargate/pricing/&#34;&gt;料金&lt;/a&gt;は割り当てたvCPUとメモリによって、最低1分の1秒単位で課金される。
Lambdaと同じくリソースあたりでいうとオンデマンドのEC2と比較して割高。ただし柔軟にリソースが指定できる分いくらか差は縮まる。&lt;/p&gt;

&lt;p&gt;特にバッチ処理のように常にリソースが必要ないTaskは都度インスタンスを立ち上げるのも面倒なので良いと思う。
Lambdaと比較すると、実行環境を自由に作れるのと実行時間に制限がないというところが良いが、
Taskを作るトリガーは現状cronだけなのでそれ以外のイベントで実行したい場合はLambdaと組み合わせる必要がある。&lt;/p&gt;

&lt;p&gt;AWSにはKubernetesクラスタを立てられるEKSもあるが、こちらはまだFargateに対応していない。
もしかしたら今月末の&lt;a href=&#34;https://reinvent.awsevents.com/&#34;&gt;re:Invent&lt;/a&gt;で何か発表されるかもしれない。&lt;/p&gt;

&lt;h2 id=&#34;clusterの作成&#34;&gt;Clusterの作成&lt;/h2&gt;

&lt;p&gt;まずはClusterを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws ecs create-cluster --cluster-name test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/196.png&#34; alt=&#34;ECSオブジェクト&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;taskの登録&#34;&gt;Taskの登録&lt;/h2&gt;

&lt;p&gt;イメージやポートマッピング、ヘルスチェックや割り当てるリソースといった&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions&#34;&gt;Container definition&lt;/a&gt;
を含む&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task_definition_parameters.html&#34;&gt;Task definition&lt;/a&gt;を書く。
Fargateの場合networkModeはawsvpc固定になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;family&amp;quot;: &amp;quot;test-task&amp;quot;, 
    &amp;quot;networkMode&amp;quot;: &amp;quot;awsvpc&amp;quot;, 
    &amp;quot;containerDefinitions&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;nginx&amp;quot;, 
            &amp;quot;image&amp;quot;: &amp;quot;nginx:1.15&amp;quot;, 
            &amp;quot;portMappings&amp;quot;: [
                {
                    &amp;quot;containerPort&amp;quot;: 80, 
                    &amp;quot;hostPort&amp;quot;: 80, 
                    &amp;quot;protocol&amp;quot;: &amp;quot;tcp&amp;quot;
                }
            ], 
            &amp;quot;essential&amp;quot;: true
        }
    ], 
    &amp;quot;requiresCompatibilities&amp;quot;: [
        &amp;quot;FARGATE&amp;quot;
    ], 
    &amp;quot;cpu&amp;quot;: &amp;quot;256&amp;quot;, 
    &amp;quot;memory&amp;quot;: &amp;quot;512&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Taskを登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws ecs register-task-definition --cli-input-json file://$(pwd)/task.json
$ aws ecs list-task-definitions
    &amp;quot;taskDefinitionArns&amp;quot;: [
        &amp;quot;arn:aws:ecs:ap-northeast-1:*****:task-definition/test-task:1&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;taskを実行&#34;&gt;Taskを実行&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/reference/ecs/run-task.html&#34;&gt;run-task&lt;/a&gt;でTaskを実行できる。
外からアクセスできるようにPublicIPを割り当てている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;cluster&amp;quot;: &amp;quot;test&amp;quot;,
  &amp;quot;taskDefinition&amp;quot;: &amp;quot;test-task:1&amp;quot;,
  &amp;quot;launchType&amp;quot;: &amp;quot;FARGATE&amp;quot;,
  &amp;quot;networkConfiguration&amp;quot;: {
    &amp;quot;awsvpcConfiguration&amp;quot;: {
      &amp;quot;subnets&amp;quot;: [
        &amp;quot;subnet-*****&amp;quot;
      ],
      &amp;quot;securityGroups&amp;quot;: [
        &amp;quot;sg-*****&amp;quot;
      ],
      &amp;quot;assignPublicIp&amp;quot;: &amp;quot;ENABLED&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ aws ecs run-task --cli-input-json file://$(pwd)/run-task.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TaskのNetworkのところにPublicIPが出ていて、アクセスするとWelcome to nginx!の表示が確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/196-2.png&#34; alt=&#34;TaskのNetwork&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;serviceを作成&#34;&gt;Serviceを作成&lt;/h2&gt;

&lt;p&gt;上の方法でTaskを実行することもできるが、
常時動くアプリケーションの場合、何か問題が起きてTaskが終了したら復活してほしい。
それをやるのが&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/service_definition_parameters.html&#34;&gt;Service&lt;/a&gt;で、K8sでいうDeploymentのようなリソース。ELBと紐づけると複数のTaskで負荷分散できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;cluster&amp;quot;: &amp;quot;test&amp;quot;,
    &amp;quot;serviceName&amp;quot;: &amp;quot;test-service&amp;quot;,
    &amp;quot;taskDefinition&amp;quot;: &amp;quot;test-task:1&amp;quot;,
    &amp;quot;desiredCount&amp;quot;: 2,
    &amp;quot;launchType&amp;quot;: &amp;quot;FARGATE&amp;quot;,
    &amp;quot;networkConfiguration&amp;quot;: {
        &amp;quot;awsvpcConfiguration&amp;quot;: {
            &amp;quot;subnets&amp;quot;: [
                &amp;quot;subnet-*****&amp;quot;
            ],
            &amp;quot;securityGroups&amp;quot;: [
                &amp;quot;sg-******&amp;quot;
            ],
            &amp;quot;assignPublicIp&amp;quot;: &amp;quot;ENABLED&amp;quot;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serviceを作成するとdesiredCountの分Taskが立ち上がり、Taskを消すと再びその数になるように立ち上がる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws ecs create-service --cli-input-json file://$(pwd)/service.json
$ aws ecs list-services --cluster test
{
    &amp;quot;serviceArns&amp;quot;: [
        &amp;quot;arn:aws:ecs:ap-northeast-1:*****:service/test-service&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのtf.data API</title>
          <link>https://www.sambaiz.net/article/195/</link>
          <pubDate>Sat, 03 Nov 2018 18:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/195/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/guide/datasets&#34;&gt;Importing Data  |  TensorFlow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;データを読み込み変換してイテレートする入力パイプラインを作るAPI。
通常、学習にGPU/TPUを使う場合CPU処理の間はアイドル状態となりボトルネックになるが、
パイプライン処理を行うことでCPUとGPU/TPUがなるべくアイドル状態にならないようになり、
&lt;a href=&#34;https://www.tensorflow.org/guide/performance/datasets&#34;&gt;学習時間が短縮される&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;dataset-https-www-tensorflow-org-api-docs-python-tf-data-dataset-の作成&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset&#34;&gt;Dataset&lt;/a&gt;の作成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices&#34;&gt;from_tensor_slices()&lt;/a&gt;でDatasetを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.data.Dataset.from_tensor_slices(
   {&amp;quot;a&amp;quot;: tf.random_uniform([4]),
    &amp;quot;b&amp;quot;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})
print(dataset.output_types) # {&#39;a&#39;: tf.float32, &#39;b&#39;: tf.int32}
print(dataset.output_shapes) # {&#39;a&#39;: TensorShape([]), &#39;b&#39;: TensorShape([Dimension(100)])}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;引数にnumpyのndarrayを渡すとtf.constant()で変換されてグラフに乗る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)))
print(dataset.output_types) # &amp;lt;dtype: &#39;int64&#39;&amp;gt;
print(dataset.output_shapes) # (3,)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;データが1GBを超える場合グラフのシリアライズ上限を超えてしまうことがある。後述するinitializableイテレータの初期化時にndarrayを渡すとこれを避けられる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/data/CsvDataset&#34;&gt;tf.contrib.data.CsvDataset&lt;/a&gt;でCSVからDatasetを作ることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat file1.csv
a,b,c,d
1,2,3,4
2,3,4,5
6,7,8,9
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;filenames = [&amp;quot;file1.csv&amp;quot;]
record_defaults = [tf.float32] * 2 # Two required float columns
dataset = tf.contrib.data.CsvDataset(filenames, record_defaults, header=True, select_cols=[1,3])
print(dataset.output_types) # (tf.float32, tf.float32)
print(dataset.output_shapes) # (TensorShape([]), TensorShape([]))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;前処理&#34;&gt;前処理&lt;/h3&gt;

&lt;p&gt;Datasetは
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map&#34;&gt;map&lt;/a&gt;や
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#flat_map&#34;&gt;flat_map&lt;/a&gt;、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#filter&#34;&gt;filter&lt;/a&gt;で変換でき、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch&#34;&gt;batch&lt;/a&gt;を作ったり
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat&#34;&gt;repeat&lt;/a&gt;したり
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle&#34;&gt;shuffle&lt;/a&gt;できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.data.Dataset.range(5).map(lambda d: d*2) # 0 2 4 6 8
dataset = tf.data.Dataset.from_tensor_slices((np.arange(4).reshape((2,2)))).flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x * 2)) # 0 2 4 6
dataset = tf.data.Dataset.range(5).filter(lambda d: tf.equal(tf.mod(d, 2), 0)) # 0 2 4

dataset = tf.data.Dataset.range(10).batch(4) # [0 1 2 3] [4 5 6 7] [8 9]
dataset = tf.data.Dataset.range(3).repeat(3) # 0 1 2 0 1 2 0 1 2
dataset = tf.data.Dataset.range(5).shuffle(buffer_size=10) # 1 0 3 4 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;iterator-https-www-tensorflow-org-api-docs-python-tf-data-iterator-の作成&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Iterator&#34;&gt;Iterator&lt;/a&gt;の作成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Iterator#get_next&#34;&gt;get_next()&lt;/a&gt;で次の要素が取れる。&lt;/p&gt;

&lt;h3 id=&#34;one-shot&#34;&gt;one-shot&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#make_one_shot_iterator&#34;&gt;make_one_shot_iterator()&lt;/a&gt;で作れるone-shotイテレータはDatasetを一周イテレートする基本的なイテレータ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.data.Dataset.range(100)
iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

with tf.Session() as sess:
    try:
        while True:
            print(sess.run(next_element)) # 0 1 2, ..., 99
    except tf.errors.OutOfRangeError:
        pass
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;initializable&#34;&gt;initializable&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#make_initializable_iterator&#34;&gt;make_initializable_iterator()&lt;/a&gt;で単一Datasetから作れるinitializableイテレータはDatasetのplaceholderを初期化できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;max_value = tf.placeholder(tf.int64, shape=[])
dataset = tf.data.Dataset.range(max_value)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

with tf.Session() as sess:
    sess.run(iterator.initializer, feed_dict={max_value: 10})
    try:
        while True:
            print(sess.run(next_element)) # 0 1 2, ..., 9
    except tf.errors.OutOfRangeError:
        pass
    print(&amp;quot;---&amp;quot;)
    sess.run(iterator.initializer, feed_dict={max_value: 20})
    try:
        while True:
            print(sess.run(next_element)) # 0 1 2, ..., 19
    except tf.errors.OutOfRangeError:
        pass
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;reinitializable&#34;&gt;reinitializable&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Iterator#from_structure&#34;&gt;Iterator.from_structure()&lt;/a&gt;でtypeとshapeから作れるreinitializableイテレータは複数のDatasetで初期化できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;training_dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)))
validation_dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)) * 2)

iterator = tf.data.Iterator.from_structure(training_dataset.output_types,
                                           training_dataset.output_shapes)
next_element = iterator.get_next()
training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

with tf.Session() as sess:
    sess.run(training_init_op)
    try:
        while True:
            print(sess.run(next_element)) # [0 1 2] [3 4 5] [6 7 8]
    except tf.errors.OutOfRangeError:
        pass
    print(&amp;quot;---&amp;quot;)
    sess.run(validation_init_op)
    try:
        while True:
            print(sess.run(next_element)) # [0 2 4] [ 6  8 10] [12 14 16]
    except tf.errors.OutOfRangeError:
        pass
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;feedable&#34;&gt;feedable&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/data/Iterator#from_string_handle&#34;&gt;Iterator.from_string_handle()&lt;/a&gt;でplaceholderとtypeとshapeから作れるfeedableイテレータは
reinitializableと同じく複数のDatasetを切り替えることができるが、
初期化はせずrunごとにDatasetのhandleをplaceholderの値として渡せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;training_dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)))
validation_dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3)) * 2)

handle = tf.placeholder(tf.string, shape=[])
iterator = tf.data.Iterator.from_string_handle(
    handle, training_dataset.output_types, training_dataset.output_shapes)
next_element = iterator.get_next()

training_iterator = training_dataset.make_one_shot_iterator()
validation_iterator = validation_dataset.make_one_shot_iterator()

with tf.Session() as sess:
    sess.run(training_init_op)
    training_handle = sess.run(training_iterator.string_handle())
    validation_handle = sess.run(validation_iterator.string_handle())
    try:
        while True:
            print(sess.run(next_element, feed_dict={handle: training_handle})) # [0 1 2] [3 4 5] [6 7 8]
    except tf.errors.OutOfRangeError:
        pass
    try:
        while True:
            print(sess.run(next_element, feed_dict={handle: validation_handle})) # [0 2 4] [ 6  8 10] [12 14 16]
    except tf.errors.OutOfRangeError:
        pass
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>同じ/異なるオリジンのiframeの中からできること</title>
          <link>https://www.sambaiz.net/article/194/</link>
          <pubDate>Wed, 24 Oct 2018 23:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/194/</guid>
          <description>

&lt;p&gt;同じ/異なるオリジンのiframeの中からできることを確認する。同じ&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/Security/Same-origin_policy&#34;&gt;オリジン&lt;/a&gt;というのは
ホストだけではなくプロトコルやポート番号も同じということ。
Web広告では非同期のレンダリングや、CSSやJSのグローバルスコープといったページ全体に及ぶ影響の分離のためによく使われている。&lt;/p&gt;

&lt;h2 id=&#34;検証用ページ&#34;&gt;検証用ページ&lt;/h2&gt;

&lt;p&gt;3つのiframeがあるページを作った。
それぞれabout:blankで動的に書き込むのと、同じオリジンのhtmlを参照しているものと、異なるオリジンのhtmlを参照しているもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;style type=&amp;quot;text/css&amp;quot;&amp;gt;
p{
  width:100px;
  height:100px;
  background:#999;
}
&amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
  &amp;lt;p&amp;gt;parent&amp;lt;/p&amp;gt;
  &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;about:blank&amp;quot; id=&amp;quot;if1&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
    var parentValue = &amp;quot;PARENT&amp;quot;;
    window.addEventListener(&amp;quot;message&amp;quot;, (event) =&amp;gt; {
      console.log(`message from ${event.origin}: ${event.data}`);
    }, false);
  &amp;lt;/script&amp;gt;

  &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;./iframe.html&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;div&amp;gt;&amp;lt;iframe src=&amp;quot;https://*****.ngrok.io/iframe.html&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;./index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1つ目のiframeの中にscriptタグなどを書き込むJS。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.js
const el = document.getElementById(&amp;quot;if1&amp;quot;);
const doc = el.contentDocument;

const p = doc.createElement(&#39;p&#39;);
p.textContent = &amp;quot;child&amp;quot;;
doc.body.appendChild(p);

var scriptTag = doc.createElement(&#39;script&#39;);
const script = `
    var childValue = &amp;quot;CHILD&amp;quot;;
    console.log(location.href + &amp;quot; parentValue: &amp;quot; + window.parent.parentValue);
    window.frameElement.style.width = &#39;400px&#39;;
`;
scriptTag.innerHTML = script;
doc.body.appendChild(scriptTag);
console.log(`${location.href} childValue: ${el.contentWindow.childValue}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;iframeのsrcで参照するhtml。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat iframe.html
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
  &amp;lt;p&amp;gt;child&amp;lt;/p&amp;gt; 
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
    try{
      console.log(`${location.href} parentValue: ${window.parent.parentValue}`);
    } catch (e) {
      console.log(`${location.href} ${e}`);
    }
    window.parent.postMessage(&amp;quot;aaaa&amp;quot;, &amp;quot;*&amp;quot;);
    if (window.frameElement) {
      window.frameElement.style.width = &#39;400px&#39;;
    } else {
      console.log(`${location.href} window.frameElement is ${window.frameElement}`);
    }
  &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行&#34;&gt;実行&lt;/h2&gt;

&lt;p&gt;異なるホストにするためngrokを立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install http-server -g
$ http-server -p 3000
$ ngrok http 3000
$ open http://localhost:3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/194.png&#34; alt=&#34;検証用ページ&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;about:blank parentValue: PARENT
http://localhost:3000/ childValue: CHILD
http://localhost:3000/iframe.html parentValue: PARENT
message from http://localhost:3000: aaaa
https://*****.ngrok.io/iframe.html SecurityError: Blocked a frame with origin &amp;quot;https://*****.ngrok.io&amp;quot; from accessing a cross-origin frame.
https://*****.ngrok.io/iframe.html window.frameElement is null
message from http://localhost:3000: 
message from https://*****.ngrok.io: aaaa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;about:blank&lt;/code&gt;は表示ページと同じオリジンになるので、srcが同じオリジンの場合の挙動と同じでparentの値やiframeを参照して書き換えることもできる。
Web広告の標準規格を定める&lt;a href=&#34;https://www.iab.com/&#34;&gt;IAB&lt;/a&gt;の&lt;a href=&#34;https://www.iab.com/wp-content/uploads/2015/09/rich_media_ajax_best_practices.pdf&#34;&gt;Best Practices for Rich Media Ads&lt;/a&gt;で言及されているFriendly IFrame(FIF)は
about:brankのiframeの中に、対象スクリプトをsrcとしたscriptタグを入れて&lt;code&gt;inDapIF = true&lt;/code&gt;を定義してFIF内で実行されていることを通知するというもの。これによって広告のスクリプトにdocument.write()のようなページの描画に問題を起こし得るコードが含まれていても、iframeで影響を分離しながら
計測や表示領域の拡大縮小などはさせることができる。裏を返せばやろうと思えば何でもできるので悪意のあるスクリプトに対する防衛策にはならない。&lt;/p&gt;

&lt;p&gt;オリジンが異なる場合は値を参照しようとするとブロックされる。
ただしparentのwindow自体は参照できるのでpostMessage()で外側とやりとりすることはできる。
これを利用したのが同じくIABが定めた&lt;a href=&#34;https://www.iab.com/wp-content/uploads/2014/08/SafeFrames_v1.1_final.pdf&#34;&gt;SafeFrame&lt;/a&gt;で、
iframeを異なるオリジンにして直接外側に干渉させず、SafeFrame APIを介して拡大などさせることでセキュアにする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/156/&#34;&gt;ブラウザのwindow間の値渡し - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/nag4/items/de044690dd227865a134&#34;&gt;SafeFrame ver1.1 仕様読解、媒体側の実装例&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goで高速にJSONを扱うライブラリeasyjsonとfastjson</title>
          <link>https://www.sambaiz.net/article/193/</link>
          <pubDate>Wed, 24 Oct 2018 01:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/193/</guid>
          <description>

&lt;h2 id=&#34;easyjson-https-github-com-mailru-easyjson&#34;&gt;&lt;a href=&#34;https://github.com/mailru/easyjson&#34;&gt;easyjson&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;easyjsonは以下のようなstructごとのコードを自動生成してReflectionなしで高速にJSON Marshal/Unmarshalできるようにするライブラリ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/mailru/easyjson/...
$ cat struct.go
package a

type Foo struct {
        A string `json:&amp;quot;a,omitempty&amp;quot;`
        B *Bar
}

type Bar struct {
        C []int          `json:&amp;quot;c&amp;quot;`
        D map[string]int `json:&amp;quot;d&amp;quot;`
}

$ easyjson -all struct.go
$ cat struct_easyjson.go
...
func easyjson9f2eff5fEncodeGithubComSambaizBenchjsonA(out *jwriter.Writer, in Foo) {
	out.RawByte(&#39;{&#39;)
	first := true
	_ = first
	if in.A != &amp;quot;&amp;quot; {
		const prefix string = &amp;quot;,\&amp;quot;a\&amp;quot;:&amp;quot;
		if first {
			first = false
			out.RawString(prefix[1:])
		} else {
			out.RawString(prefix)
		}
		out.String(string(in.A))
	}
	{
		const prefix string = &amp;quot;,\&amp;quot;B\&amp;quot;:&amp;quot;
		if first {
			first = false
			out.RawString(prefix[1:])
		} else {
			out.RawString(prefix)
		}
		if in.B == nil {
			out.RawString(&amp;quot;null&amp;quot;)
		} else {
			(*in.B).MarshalEasyJSON(out)
		}
	}
	out.RawByte(&#39;}&#39;)
}
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;標準のencoding/jsonと同じ様に使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x := a.Foo{
    B: &amp;amp;a.Bar{
        C: []int{1, 2, 3},
    },
}
b, err := easyjson.Marshal(x)
if err != nil {
    panic(err)
}
fmt.Println(string(b)) // {&amp;quot;B&amp;quot;:{&amp;quot;c&amp;quot;:[1,2,3],&amp;quot;d&amp;quot;:null}}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fastjson-https-github-com-valyala-fastjson&#34;&gt;&lt;a href=&#34;https://github.com/valyala/fastjson&#34;&gt;fastjson&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;fastjsonはstructを介さず、ParseしてGetIntのような関数で取り出す。
そのため持ち回すとデータ形式が分からなくなるという問題はあるが、曖昧な型のJSONを扱う際はかえって使いやすいかもしれない。
MarshalToの引数には[]byteを渡せてnilを渡すとallocateされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var p fastjson.Parser
value, err := p.Parse(`{&amp;quot;a&amp;quot;: {&amp;quot;b&amp;quot;: 100, &amp;quot;c&amp;quot;: null}}`)
fmt.Println(value.GetInt(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;)) // 100
fmt.Println(value.GetStringBytes(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;)) // []
fmt.Println(string(value.MarshalTo(nil))) // {&amp;quot;a&amp;quot;:{&amp;quot;b&amp;quot;:100,&amp;quot;c&amp;quot;:null}}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ベンチマーク&#34;&gt;ベンチマーク&lt;/h2&gt;

&lt;p&gt;簡単な例でベンチマークを取ってみる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/47/&#34;&gt;go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;encoding/json&amp;quot;
	&amp;quot;strings&amp;quot;
	&amp;quot;testing&amp;quot;

	&amp;quot;github.com/mailru/easyjson&amp;quot;
	&amp;quot;github.com/sambaiz/benchjson/a&amp;quot;
	&amp;quot;github.com/valyala/fastjson&amp;quot;
)

var target = a.Foo{
	A: strings.Repeat(&amp;quot;ABCD&amp;quot;, 100),
	B: &amp;amp;a.Bar{
		C: []int{1, 2, 3},
		D: map[string]int{
			&amp;quot;AAA&amp;quot;: 100,
			&amp;quot;BBB&amp;quot;: 200,
			&amp;quot;CCC&amp;quot;: 300,
			&amp;quot;DDD&amp;quot;: 400,
		},
	},
}

func targetBytes() []byte {
	dat, err := easyjson.Marshal(target)
	if err != nil {
		panic(err)
	}
	return dat
}

func BenchmarkEncodingJSONMarshal(b *testing.B) {
	for i := 0; i &amp;lt; b.N; i++ {
		_, err := json.Marshal(target)
		if err != nil {
			b.Error(err)
		}
	}
}

func BenchmarkEasyJSONMarshal(b *testing.B) {
	for i := 0; i &amp;lt; b.N; i++ {
		_, err := easyjson.Marshal(target)
		if err != nil {
			b.Error(err)
		}
	}
}

func BenchmarkFastJSONMarshalTo(b *testing.B) {
	dat := targetBytes()
	var p fastjson.Parser
	value, err := p.ParseBytes(dat)
	if err != nil {
		b.Error(err)
	}
	b.ResetTimer()
	for i := 0; i &amp;lt; b.N; i++ {
		value.MarshalTo(nil)
	}
}

func BenchmarkEncodingJSONUnmarshal(b *testing.B) {
	dat := targetBytes()
	v := a.Foo{}
	b.ResetTimer()
	for i := 0; i &amp;lt; b.N; i++ {
		err := json.Unmarshal(dat, &amp;amp;v)
		if err != nil {
			b.Error(err)
		}
	}
}

func BenchmarkEasyJSONUnmarshal(b *testing.B) {
	dat := targetBytes()
	v := a.Foo{}
	b.ResetTimer()
	for i := 0; i &amp;lt; b.N; i++ {
		err := easyjson.Unmarshal(dat, &amp;amp;v)
		if err != nil {
			b.Error(err)
		}
	}
}

func BenchmarkFastJSONParse(b *testing.B) {
	dat := targetBytes()
	var p fastjson.Parser
	b.ResetTimer()
	for i := 0; i &amp;lt; b.N; i++ {
		_, err := p.ParseBytes(dat)
		if err != nil {
			b.Error(err)
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確かにencoding/jsonと比べて格段に速い。適所で使っていきたい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test --bench .
goos: darwin
goarch: amd64
pkg: github.com/sambaiz/benchjson
BenchmarkEncodingJSONMarshal-4     	  300000	      4548 ns/op
BenchmarkEasyJSONMarshal-4         	 1000000	      1829 ns/op
BenchmarkFastJSONMarshalTo-4       	 3000000	       429 ns/op
BenchmarkEncodingJSONUnmarshal-4   	  300000	      5143 ns/op
BenchmarkEasyJSONUnmarshal-4       	 1000000	      1780 ns/op
BenchmarkFastJSONParse-4           	 5000000	       373 ns/op
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MLPと誤差逆伝搬法(Backpropagation)</title>
          <link>https://www.sambaiz.net/article/192/</link>
          <pubDate>Sun, 21 Oct 2018 19:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/192/</guid>
          <description>

&lt;p&gt;MLP(多層パーセプトロン)は入力層と出力層の間に隠れ層を重ねることによって、
ロジスティック回帰(単純パーセプトロン)ではできなかった非線形分離をできるようにしたニューラルネットワークモデル。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/191/&#34;&gt;ロジスティック回帰の尤度と交差エントロピー誤差と勾配降下法 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;入出力が&lt;code&gt;x&lt;/code&gt;、&lt;code&gt;y&lt;/code&gt;、層の数がLでl層目での重みとバイアスを&lt;code&gt;W^(l)&lt;/code&gt;, &lt;code&gt;b^(l)&lt;/code&gt;、活性化関数を&lt;code&gt;f^(l)&lt;/code&gt;、活性化関数適用前後を&lt;code&gt;u^(l)&lt;/code&gt;と&lt;code&gt;h^(l)&lt;/code&gt;とし、入力層を0層目とすると各層での演算は以下の式で表される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/192-1.png&#34; alt=&#34;各層での演算&#34; /&gt;&lt;/p&gt;

&lt;p&gt;活性化関数は非線形で微分可能な関数で、計算速度や勾配消失の面でReLUが最有力。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/133/&#34;&gt;ニューラルネットワークと活性化関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;各層の最適なWとbを探すのにロジスティック回帰と同様に勾配降下法を使うことができる。
誤差関数は分類の場合は交差エントロピーが、回帰の場合は平均二乗誤差(MSE, Mean Squared Error)が使われる。&lt;/p&gt;

&lt;p&gt;隠れ層の勾配はそれより後ろの層での演算が影響するので、入力から出力への順伝搬に対して
出力から入力への逆伝播で誤差の情報を前の層に伝播させていく。これを誤差逆伝播法(Backpropagation)という。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/192-2.png&#34; alt=&#34;誤差逆伝播法&#34; /&gt;&lt;/p&gt;

&lt;p&gt;出力から遠くなればなるほど連鎖律が長くなっていくが、途中までは後ろの層と共通になっている。
ということで順伝搬時のhを保存しておき一つ後ろの層のWと誤差δを渡してやれば必要最小限の演算で済み、実行時間を短くすることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/192-3.png&#34; alt=&#34;l層での誤差δを使った逆伝播&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92-%E3%82%A2%E3%82%B9%E3%82%AD%E3%83%BC%E3%83%89%E3%83%AF%E3%83%B3%E3%82%B4-%E9%BB%92%E6%BB%9D-%E7%B4%98%E7%94%9F-ebook/dp/B07GQV1X76&#34;&gt;深層学習&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ロジスティック回帰の尤度と交差エントロピーと勾配降下法</title>
          <link>https://www.sambaiz.net/article/191/</link>
          <pubDate>Sun, 14 Oct 2018 23:28:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/191/</guid>
          <description>

&lt;h2 id=&#34;ロジスティック回帰&#34;&gt;ロジスティック回帰&lt;/h2&gt;

&lt;p&gt;単純パーセプトロンの活性化関数を0/1のステップ関数ではなく0~1のシグモイド関数にしたモデルで、分類の確率を返すことができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/133/&#34;&gt;ニューラルネットワークと活性化関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;線形分離不可能な場合はうまくいかない。入力と出力の間に隠れ層があるMLPでは非線形分離もできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/192/&#34;&gt;MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;尤度関数と交差エントロピー誤差関数&#34;&gt;尤度関数と交差エントロピー誤差関数&lt;/h2&gt;

&lt;p&gt;尤度(likelihood)関数はXという事象が観察されたときにC=tである尤もらしさを表す関数。
例えば、6面ダイスを2回振って両方1の目が出た(X)ときに1の目が出る確率が1/6&amp;copy;である尤度は(&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;)*(&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;)=1/36となる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-likelihood.png&#34; alt=&#34;尤度関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;学習ではモデルのパラメータw,bを、各入力x(x1,x2,&amp;hellip;,xn)に対して正解であるC=tの尤度の和が最大になるように最適化していく。
通常のロジスティック回帰では二値分類を行うので正解データtは{0,1}とし、&lt;code&gt;P(C=1) = 1-P(C=0)&lt;/code&gt;となる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-l.png&#34; alt=&#34;ロジスティック回帰の尤度関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただ、このままだと積になっていて計算しづらいので、対数を取って和にして、
損失として扱うため負の数にする。これを交差エントロピー誤差関数という。
この値を最小化させるということは尤度を最大化させることになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-e.png&#34; alt=&#34;交差エントロピー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/134/&#34;&gt;自己情報量、エントロピー、KL情報量、交差エントロピー - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;勾配降下法&#34;&gt;勾配降下法&lt;/h2&gt;

&lt;p&gt;誤差をw,bでそれぞれ偏微分したのを引いてパラメータを更新していき、
勾配が0になるような値を探す。&lt;/p&gt;

&lt;p&gt;ηは学習率で正の小さな値にする。
大きすぎると収束しないが、小さすぎても収束に必要なステップ数が増え、さらに局所最適解で止まってしまう可能性が高まるので
最初は大きくして徐々に小さくしていったりする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-gradient.png&#34; alt=&#34;勾配降下法&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ほかに局所最適解で止まるのを避ける手法として、サンプル全体ではなく毎回異なる一部を使う(Minibatch)確率的勾配降下法(SGD: Stochastic Gradient Descent)や、SGDに慣性を追加したMomentumなどがある。&lt;/p&gt;

&lt;h2 id=&#34;多クラスロジスティック回帰&#34;&gt;多クラスロジスティック回帰&lt;/h2&gt;

&lt;p&gt;活性化関数をsoftmax関数にすると多クラス分類できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-softmax.png&#34; alt=&#34;多クラスでの確率&#34; /&gt;&lt;/p&gt;

&lt;p&gt;多クラスの場合の正解データtは{0,1,2,&amp;hellip;}といったようにはせず
正解のindexだけ1でほかは0のone-hot vectorで表し、尤度関数、交差エントロピー誤差関数は以下のようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-le2.png&#34; alt=&#34;多クラスでの尤度関数と交差エントロピー誤差関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;偏微分するとこうなる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/191-gradient2.png&#34; alt=&#34;交差エントロピー誤差関数の偏微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;あとは同様に勾配降下法でパラメータを更新していく。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3-%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0-TensorFlow%E3%83%BBKeras%E3%81%AB%E3%82%88%E3%82%8B%E6%99%82%E7%B3%BB%E5%88%97%E3%83%87%E3%83%BC%E3%82%BF%E5%87%A6%E7%90%86-%E5%B7%A3%E7%B1%A0-%E6%82%A0%E8%BC%94/dp/4839962510&#34;&gt;詳解 ディープラーニング ~TensorFlow・Kerasによる時系列データ処理~&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesでliveness/readinessProbeのexec commandが実行される流れ</title>
          <link>https://www.sambaiz.net/article/190/</link>
          <pubDate>Sat, 06 Oct 2018 16:32:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/190/</guid>
          <description>&lt;p&gt;Kubernetesの&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/&#34;&gt;liveness/readinessProbe&lt;/a&gt;
はPodが生きているか/リクエストを受けられるかの判定で、
後者はアプリケーションの起動に時間がかかる場合などに使われる。
ヘルスチェックのようなエンドポイントを叩くのはhttpGetでできるが、任意のcommandを実行することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
    httpHeaders:
    - name: X-Custom-Header
      value: Awesome
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Manifestに書かれたProbeは、
各ノードで動いている&lt;a href=&#34;https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/&#34;&gt;kubelet&lt;/a&gt;が
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/kubelet.go#L1983&#34;&gt;Podが追加されたとき&lt;/a&gt;にworkerを
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/prober/prober_manager.go#L157&#34;&gt;作って&lt;/a&gt;
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/prober/prober.go#L147&#34;&gt;runProbe()&lt;/a&gt;で実行させている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if p.Exec != nil {
    glog.V(4).Infof(&amp;quot;Exec-Probe Pod: %v, Container: %v, Command: %v&amp;quot;, pod, container, p.Exec.Command)
    command := kubecontainer.ExpandContainerCommandOnlyStatic(p.Exec.Command, container.Env)
    return pb.exec.Probe(pb.newExecInContainer(container, containerID, command, timeout))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずcommandに含まれる&lt;code&gt;$( )&lt;/code&gt;で囲まれた文字列を
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/third_party/forked/golang/expansion/expand.go#L38&#34;&gt;Expand()&lt;/a&gt;
で存在すればcontainerのenvの値に置き換える。&lt;/p&gt;

&lt;p&gt;その後、
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/kuberuntime/kuberuntime_container.go#L778&#34;&gt;RunInContainer()&lt;/a&gt;で、
コンテナランタイムがK8s標準のCRI(Container Runtime Interface)に対応している場合はその&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.13.0-alpha.0/pkg/kubelet/apis/cri/services.go#L50&#34;&gt;API&lt;/a&gt;の、
対応していない場合は~shimパッケージのExecSync()が呼ばれ、コンテナ内でcommandを実行させて結果を受け取り、終了コードが0でなければエラーとする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$( )&lt;/code&gt;でenvの値が使えることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl config use-context docker-for-desktop
$ cat test.yaml
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: &amp;quot;test&amp;quot;
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: &amp;quot;test&amp;quot;
    spec:
      containers:
        - name: &amp;quot;test&amp;quot;
          image: &amp;quot;alpine&amp;quot;
          command: [&amp;quot;top&amp;quot;]
          env:
          - name: TEST
            value: &amp;quot;foobar&amp;quot;
          ports:
          - containerPort: 5000
            name: grpc
          readinessProbe:
            exec:
              command:
              - test
              - $(TEST)
              - =
              - foobar
            initialDelaySeconds: 0
            timeoutSeconds: 1

$ kubectl apply test.yaml
$ kubectl describe pod $(kubectl get pods -l app=test -o jsonpath=&#39;{.items[0].metadata.name}&#39;)
test-85994ddf4d-gpxpq       1/1       Running   0          9s
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLのtime_zoneとgo-sql-driver/mysqlの設定</title>
          <link>https://www.sambaiz.net/article/189/</link>
          <pubDate>Tue, 02 Oct 2018 22:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/189/</guid>
          <description>

&lt;p&gt;MySQLのtime_zoneとgo-sql-driver/mysqlの設定による挙動を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; select version();
    +-----------+
    | version() |
    +-----------+
    | 5.7.21    |
    +-----------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;タイムゾーンがロードされていない場合はロードする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; select count(*) from mysql.time_zone \\G;
*************************** 1. row ***************************
count(*): 0

$ mysql_tzinfo_to_sql /usr/share/zoneinfo/ | mysql -u root mysql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;time_zoneはデフォルト値のSYSTEM。つまりJSTで、my.cnfのdefault-time-zoneで変更できる。
NOW()もJSTの時間を返している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; show variables like &#39;%time_zone%&#39;;
+------------------+--------+
| Variable_name    | Value  |
+------------------+--------+
| system_time_zone | JST    |
| time_zone        | SYSTEM |
+------------------+--------+

&amp;gt; SELECT NOW();
mysql&amp;gt; SELECT NOW() \G;
*************************** 1. row ***************************
NOW(): 2018-10-02 20:26:29
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DATETIMEはそのまま格納され返される。
TIMESTAMPはUTCに変換して格納され、
返すときにtime_zoneに&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/time-zone-support.html&#34;&gt;変換される&lt;/a&gt;。
したがってtime_zoneを変更するとDATETIMEは変わらず、TIMESTAMPは変わる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; CREATE TABLE t (
    dt DATETIME,
    ts TIMESTAMP
);
&amp;gt; INSERT INTO t VALUES (NOW(), NOW());
&amp;gt; select * from t \G;
*************************** 1. row ***************************
dt: 2018-10-02 20:27:13
ts: 2018-10-02 20:27:13

&amp;gt; SET SESSION time_zone = &amp;quot;UTC&amp;quot;;
&amp;gt; select NOW() \G;
*************************** 1. row ***************************
NOW(): 2018-10-02 11:27:56

&amp;gt; select * from t \G;
*************************** 1. row ***************************
dt: 2018-10-02 20:27:13
ts: 2018-10-02 11:27:13
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;go-sql-driver-mysql&#34;&gt;go-sql-driver/mysql&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/go-sql-driver/mysql&#34;&gt;go-sql-driver/mysql&lt;/a&gt;で
Data Source Nameに&lt;a href=&#34;https://github.com/go-sql-driver/mysql#loc&#34;&gt;loc&lt;/a&gt;とtime_zoneを付けて実行してみる。
time.Localの影響を確認するためUTCでもJSTでもない&lt;code&gt;US/Alaska&lt;/code&gt;にしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;database/sql&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;math&amp;quot;
    &amp;quot;time&amp;quot;

    _ &amp;quot;github.com/go-sql-driver/mysql&amp;quot;
)
    
const format = &amp;quot;2006-01-02 15:04:05 Z0700&amp;quot;
    
func main() {
    var err error
    if time.Local, err = time.LoadLocation(&amp;quot;US/Alaska&amp;quot;); err != nil {
        panic(err)
    }
    now := time.Now()
    fmt.Printf(&amp;quot;%15s: %s\n&amp;quot;, &amp;quot;time.Now()&amp;quot;, now.Format(format))
    fmt.Println(&amp;quot;* none&amp;quot;)
    run(now, &amp;quot;root:@/hoge?parseTime=true&amp;quot;)
    fmt.Println(&amp;quot;* loc (mysql&#39;s timezone != Local timezone)&amp;quot;)
    run(now, &amp;quot;root:@/hoge?parseTime=true&amp;amp;loc=Local&amp;quot;)
    fmt.Println(&amp;quot;* loc &amp;amp; time_zone&amp;quot;)
    run(now, &amp;quot;root:@/hoge?parseTime=true&amp;amp;loc=Local&amp;amp;time_zone=%27US%2FAlaska%27&amp;quot;)
}

func run(now time.Time, src string) {
    db, err := sql.Open(&amp;quot;mysql&amp;quot;, src)
    if err != nil {
        panic(err)
    }
    defer db.Close()

    if _, err := db.Exec(&amp;quot;DELETE FROM t&amp;quot;); err != nil {
        panic(err)
    }

    if _, err := db.Exec(&amp;quot;INSERT INTO t VALUES (NOW(), NOW())&amp;quot;); err != nil {
        panic(err)
    }

    if _, err := db.Exec(&amp;quot;INSERT INTO t VALUES (?, ?)&amp;quot;, now, now); err != nil {
        panic(err)
    }

    rows, err := db.Query(&amp;quot;SELECT dt, ts FROM t&amp;quot;)
    if err != nil {
        panic(err)
    }
    i := 0
    title := []string{&amp;quot;mysql NOW()&amp;quot;, &amp;quot;go time.Now()&amp;quot;}
    for rows.Next() {
        var datetime, timestamp time.Time
        if err := rows.Scan(&amp;amp;datetime, &amp;amp;timestamp); err != nil {
            panic(err)
        }
        fmt.Printf(&amp;quot;%15s: %s, %s -&amp;gt; %v\n&amp;quot;,
            title[i],
            datetime.Format(format),
            timestamp.Format(format),
            math.Abs(float64(datetime.Unix()-now.Unix())) &amp;lt; 10,
        )
        i++
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;locはtime.Timeのタイムゾーンで、付けないとUTCになる。
これはMySQLサーバーのtime_zoneには影響せず、NOW()の値はLocalと異なりJSTなので値がおかしくなる。
一方、time.Now()の方はタイムゾーンが考慮されているので値自体は正しい。
time_zoneを付けると&lt;code&gt;SET time_zone&lt;/code&gt;してくれてNOW()の値も正しくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go run main.go
        time.Now(): 2018-10-02 03:43:13 -0800
* none
    mysql NOW(): 2018-10-02 20:43:13 Z, 2018-10-02 20:43:13 Z -&amp;gt; false
    go time.Now(): 2018-10-02 11:43:14 Z, 2018-10-02 11:43:14 Z -&amp;gt; true
* loc (mysql&#39;s timezone != Local timezone)
    mysql NOW(): 2018-10-02 20:43:13 -0800, 2018-10-02 20:43:13 -0800 -&amp;gt; false
    go time.Now(): 2018-10-02 03:43:14 -0800, 2018-10-02 03:43:14 -0800 -&amp;gt; true
* loc &amp;amp; time_zone
    mysql NOW(): 2018-10-02 03:43:13 -0800, 2018-10-02 03:43:13 -0800 -&amp;gt; true
    go time.Now(): 2018-10-02 03:43:14 -0800, 2018-10-02 03:43:14 -0800 -&amp;gt; true
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PythonのType Hintsとmypy</title>
          <link>https://www.sambaiz.net/article/188/</link>
          <pubDate>Sun, 30 Sep 2018 14:13:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/188/</guid>
          <description>

&lt;p&gt;動的型付け言語であるPythonで型アノテーションを書けるようにするための構文。
&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/&#34;&gt;PEP 484&lt;/a&gt;で提案され、Python 3.5で実装された。
実行には影響せず、&lt;a href=&#34;https://github.com/python/mypy&#34;&gt;mypy&lt;/a&gt;のようなツールで静的解析したりするために使われる。&lt;/p&gt;

&lt;p&gt;mypyをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python -m pip install -U mypy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のように引数と返り値に型を書くと、型が誤っている場合にmypyで検知できるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat main.py
def foo(n: int) -&amp;gt; str:
  return str(n)

print(foo(3))
print(foo(&#39;3&#39;))

$ python main.py
3
3

$ mypy main.py
main.py:5: error: Argument 1 to &amp;quot;foo&amp;quot; has incompatible type &amp;quot;str&amp;quot;; expected &amp;quot;int&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、Type Hintsがないライブラリなどのために&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/#stub-files&#34;&gt;Stub&lt;/a&gt;ファイルを別に作って型を書くこともできるようにもなっている。デフォルトではStubがないモジュールはエラーになってしまうので必要に応じて&lt;a href=&#34;https://mypy.readthedocs.io/en/latest/running_mypy.html#ignore-missing-imports&#34;&gt;ignore_missing_import&lt;/a&gt;する。
mypy.iniやsetup.cfgに設定を書くと自動で&lt;a href=&#34;https://mypy.readthedocs.io/en/latest/config_file.html#config-file&#34;&gt;使われる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat main.py
import numpy as np

$ mypy main.py
main.py:1: error: No library stub file for module &#39;numpy&#39;
main.py:1: note: (Stub files are from https://github.com/python/typeshed)

$ vi mypy.ini
[mypy]
[mypy-numpy]
ignore_missing_imports = True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VSCode上でもmypyを有効にすると表示されるようになる。FormatterやLintの設定と併せて有効にしておくとよい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/125/&#34;&gt;PythonのLintとFormatter - sambagiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;python.linting.mypyEnabled&amp;quot;: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/188.png&#34; alt=&#34;VSCodeでの表示&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;callable-https-www-python-org-dev-peps-pep-0484-callable&#34;&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/#callable&#34;&gt;Callable&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Callable[[引数], 返り値]のように書く。引数を&amp;hellip;にすると返り値だけをチェックさせることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from typing import Callable

def foo(f: Callable[[int], None]) -&amp;gt; None:
  f(1)

def bar(f: Callable[..., None]) -&amp;gt; None:
  f(1)

def f1(x: int):
  print(x)

def f2(x: str):
  print(x)

foo(f1) # ok
foo(f2) # error: Argument 1 to &amp;quot;foo&amp;quot; has incompatible type &amp;quot;Callable[[str], Any]&amp;quot;; expected &amp;quot;Callable[[int], None]&amp;quot;
bar(f1) # ok
bar(f2) # ok
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;generics-https-www-python-org-dev-peps-pep-0484-generics&#34;&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/#generics&#34;&gt;Generics&lt;/a&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;from typing import Dict
from typing import TypeVar, Generic

T = TypeVar(&#39;T&#39;)

class Foo(Generic[T]):
  def __init__(self, v: T) -&amp;gt; None:
    self.v = v
  
  def getV(self) -&amp;gt; T:
    return self.v

m: Dict[str, Foo[int]] = {&#39;a&#39;: Foo(1)}
m2: Dict[str, Foo[str]] = {&#39;a&#39;: Foo(&#39;1&#39;)}

def bar(m: Dict[str, Foo[int]], key: str) -&amp;gt; Foo[int]:
  return Foo(m[key]).getV()

def bar2(m: Dict[str, Foo[int]], key: str) -&amp;gt; Foo[str]:
  return Foo(m[key]).getV() # error: Incompatible return value type (got &amp;quot;Foo[int]&amp;quot;, expected &amp;quot;Foo[str]&amp;quot;)

bar(m, &#39;a&#39;)
bar(m2, &#39;a&#39;) # error: Argument 1 to &amp;quot;bar&amp;quot; has incompatible type &amp;quot;Dict[str, Foo[str]]&amp;quot;; expected &amp;quot;Dict[str, Foo[int]]&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TypeVarは&lt;code&gt;TypeVar(&#39;T&#39;, int, float)&lt;/code&gt;のように取り得る型を指定したり、
&lt;code&gt;TypeVar(&#39;T&#39;, bound=Employee)&lt;/code&gt;のようにupper boundを指定する(そのサブクラスが取り得る型)こともできる。
また、取った型はデフォルトでinvariant(非変, そのスーパークラスもサブクラスも許容しない)として扱われるが、
&lt;code&gt;covariant=True&lt;/code&gt;にするとcovariant(共変, サブクラスは許容する)として扱うことができる。&lt;/p&gt;

&lt;h3 id=&#34;union-types-https-www-python-org-dev-peps-pep-0484-union-types&#34;&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0484/#union-types&#34;&gt;Union types&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;いずれかの型を取るUnion typeも書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from typing import Union, Sequence

def foo(e: Union[int, Sequence[int]]) -&amp;gt; Sequence[int]:
    if isinstance(e, int):
      return [e]
    return e

print(foo(1))
print(foo([1]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Union[T, None]はOptional[T]と同じ。Noneをデフォルト引数にすると自動でOptional[T]として扱われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def foo(e: int = None):
    if e:
      print(e)
foo(1)
foo()
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>numpyの関数</title>
          <link>https://www.sambaiz.net/article/187/</link>
          <pubDate>Sun, 23 Sep 2018 23:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/187/</guid>
          <description>

&lt;h2 id=&#34;ndarrayの生成&#34;&gt;ndarrayの生成&lt;/h2&gt;

&lt;p&gt;ndarrayはnumpyの多次元の配列を表すオブジェクトで、[start:stop:step, &amp;hellip;]の
&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html&#34;&gt;index&lt;/a&gt;でアクセスできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.array([[1, 2, 3, 4], [2, 4, 6, 8]])
print(x[0, 1]) # 2
print(x[0,1:-1]) # [2 3]
print(x[:,2]) # [3 6]
print(x[:,::2]) # [[1 3] [2 6]]
print(x[1,::-1]) # [8 6 4 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html&#34;&gt;array()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.fromiter.html&#34;&gt;fromiter()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;arrayやiteratableオブジェクトからndarrayを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.array([1, 2, 3])) # [1 2 3]

def generate():
    for x in range(3):
        yield x
x = np.fromiter(generate(), dtype=float)
print(x) # [ 0.  1.  2.]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html&#34;&gt;zeros()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html&#34;&gt;ones()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.full.html&#34;&gt;full()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;引数で渡したshapeを特定の値で埋めたndarrayを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.zeros(5)) # [ 0.  0.  0.  0.  0.]
print(np.ones((2,2))) # [[ 1.  1.] [ 1.  1.]]
print(np.full((2, 3), 2)) # [[2 2 2] [2 2 2]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html&#34;&gt;arange()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html&#34;&gt;linspace()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Python built-inのrange()のndarray版と、startからstopまで等間隔なndarrayを生成する関数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.arange(5)) # [0 1 2 3 4]
print(np.linspace(2.0, 3.0, num=5)) # [ 2.    2.25  2.5   2.75  3.  ]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.identity.html&#34;&gt;identity()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html&#34;&gt;eye()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;diagonal(対角)は1,それ以外は0の単位行列を生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.identity(3)) # [[ 1.  0.  0.] [ 0.  1.  0.] [ 0.  0.  1.]]
print(np.eye(3)) # [[ 1.  0.  0.] [ 0.  1.  0.] [ 0.  0.  1.]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.random.html&#34;&gt;random.random()&lt;/a&gt;: &lt;code&gt;[0.0, 1.0)&lt;/code&gt;で連続一様分布&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html&#34;&gt;random.randint()&lt;/a&gt;: &lt;code&gt;[low, high)&lt;/code&gt;で離散一様分布&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.uniform.html&#34;&gt;random.uniform()&lt;/a&gt;: &lt;code&gt;[low, high)&lt;/code&gt;で連続一様分布&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ランダム値のndarrayを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.random.random((2, 2)) # [[ 0.84157926  0.77701369] [ 0.92937916  0.41447905]]
print(np.random.randint(low=5, high=10, size=(2, 2))) # [[9 5] [7 7]]
print(np.random.uniform(low=5, high=10, size=(2,2))) # [[ 9.72222125  6.07259325] [ 7.24174366  9.27801853]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;加工&#34;&gt;加工&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.astype.html&#34;&gt;astype()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;キャストする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.array([1, 2, 2.5]).astype(int)) # [1 2 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html&#34;&gt;reshape()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.flatten.html&#34;&gt;flatten()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;shapeを変更するのと、1次元にする関数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2, 2))
print(x) # [[0 1] [2 3]]
print(x.flatten()) # [0 1 2 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html&#34;&gt;pad()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;paddingする。modeで埋まる値が決まる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.pad(np.zeros((2, 2)), pad_width=1, mode=&#39;constant&#39;, constant_values=2))
&amp;quot;&amp;quot;&amp;quot;
[[ 2.  2.  2.  2.] 
 [ 2.  0.  0.  2.]
 [ 2.  0.  0.  2.]
 [ 2.  2.  2.  2.]]
&amp;quot;&amp;quot;&amp;quot;

print(np.pad(np.arange(9).reshape(3,3), pad_width=1, mode=&#39;edge&#39;))
&amp;quot;&amp;quot;&amp;quot;
[[0 0 1 2 2]
 [0 0 1 2 2]
 [3 3 4 5 5]
 [6 6 7 8 8]
 [6 6 7 8 8]]
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.diag.html&#34;&gt;diag()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.diagonal.html&#34;&gt;diagonal()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;対角の値を返したり、対角行列にしたりする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(9).reshape((3,3))
print(np.diag(x)) # [0 4 8]
print(np.diag(np.diag(x))) # [[0 0 0] [0 4 0] [0 0 8]]
print(np.diag(np.diag(np.diag(x)))) # [0 4 8]

print(np.diagonal(x)) # [0 4 8]
print(np.diagonal(np.diagonal(x))) # diag requires an array of at least two dimensions
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.sort.html&#34;&gt;sort()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html&#34;&gt;argsort()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argpartition.html&#34;&gt;argpartition()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.permutation.html&#34;&gt;random.permutation()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ソートとシャッフル。argsort()とargpartition()はindexを返す。
argpartition()はkth番目の値で分けるもの(下の例だと4番目に小さいindex 0)で、パーティション内の順序は保証されないが、n番目のindexだけ欲しい場合はargsort()より速い。
random.permutation()はPandasの行をシャッフルするときにも使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/170/&#34;&gt;Pandasの操作 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.random.random((3, 3))
print(np.sort(x)) 
&amp;quot;&amp;quot;&amp;quot;
[[ 0.14366067  0.41558783  0.7584969 ] 
 [ 0.1395897   0.78905376  0.89709119]
 [ 0.3235212   0.82675995  0.95140141]]
&amp;quot;&amp;quot;&amp;quot;

x2 = np.array([3, 1, 2, 1, 4, 5])
print(np.argsort(x2)) # [1 3 2 0 4 5]
print(np.argpartition(x2, 3)) # [3 2 1 0 4 5]

print(np.random.permutation(np.arange(5))) # [3 1 0 4 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html&#34;&gt;repeat()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html&#34;&gt;tile()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html&#34;&gt;unique()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;repeat()は各値を繰り返し、tile()は敷き詰める。unique()はユニークな値にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape(2,2)
print(np.repeat(x, 2)) # [0 0 1 1 2 2 3 3]
print(np.repeat(x, 2, axis=1)) # [[0 0 1 1] [2 2 3 3]]

print(np.tile(x, (3,2)))
&amp;quot;&amp;quot;&amp;quot;
[[0 1 0 1] 
 [2 3 2 3]
 [0 1 0 1]
 [2 3 2 3]
 [0 1 0 1]
 [2 3 2 3]]
&amp;quot;&amp;quot;&amp;quot;

x2 = np.repeat([np.repeat(np.arange(3), 2)], 2, axis=0)
print(x2) #  [[1 1 2 2 3 3] [1 1 2 2 3 3]]
print(np.unique(x2)) # [1 2 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.roll.html&#34;&gt;roll()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ローリングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.roll(np.arange(8).reshape(4, 2), 2, axis=0)) # [[4 5] [6 7] [0 1] [2 3]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.vstack.html&#34;&gt;vstack()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.hstack.html&#34;&gt;hstack()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;縦横に結合する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2, 2))
y = np.identity(2)
print(np.vstack((x, y))) 
&#39;&#39;&#39;
[[ 0.  1.] [ 2.  3.] 
 [ 1.  0.] [ 0.  1.]]
&#39;&#39;&#39;

print(np.hstack((x, y))) 
&#39;&#39;&#39;
[[ 0.  1.  1.  0.] 
 [ 2.  3.  0.  1.]]
&#39;&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.split.html&#34;&gt;split()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_split.html&#34;&gt;array_split()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分割する。array_split()はちょうど分けられなくてもエラーにしない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.split(np.arange(7), 3)) # ValueError: array split does not result in an equal division
print(np.array_split(np.arange(7),3)) # [array([0, 1, 2]), array([3, 4]), array([5, 6])]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html&#34;&gt;meshgrid()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;座標の値からndarrayを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x, y = np.meshgrid(np.linspace(0,1,5), np.linspace(0,1,5))
print(x)
&#39;&#39;&#39;
[[ 0.    0.25  0.5   0.75  1.  ]
 [ 0.    0.25  0.5   0.75  1.  ]
 [ 0.    0.25  0.5   0.75  1.  ]
 [ 0.    0.25  0.5   0.75  1.  ]
 [ 0.    0.25  0.5   0.75  1.  ]]
&#39;&#39;&#39;
print(y)
&#39;&#39;&#39;
[[ 0.    0.    0.    0.    0.  ]
 [ 0.25  0.25  0.25  0.25  0.25]
 [ 0.5   0.5   0.5   0.5   0.5 ]
 [ 0.75  0.75  0.75  0.75  0.75]
 [ 1.    1.    1.    1.    1.  ]]
&#39;&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.unpackbits.html&#34;&gt;unpackbits()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.packbits.html&#34;&gt;packbits()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;uint8のndarrayをバイナリの値に変換するのと、その逆。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.unpackbits(np.array([[8], [23]], dtype=np.uint8), axis=1)
print(x) # [[0 0 0 0 1 0 0 0] [0 0 0 1 0 1 1 1]]
print(np.packbits(x, axis=1)) # [[ 8] [23]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;比較&#34;&gt;比較&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.nonzero.html&#34;&gt;nonzero()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html&#34;&gt;where()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;0でないindexを返す。booleanのndarrayからTrueを抽出するのにも使える。
where()の第1引数は条件式で、第2引数と第3引数を渡すとそれぞれTrueとFalseの場合に置換される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.array([[1,0,0], [0,2,0], [1,1,0]])
print(np.nonzero(x)) # (array([0, 1, 2, 2]), array([0, 1, 0, 1])) =&amp;gt; [0, 0], [1, 1], [2, 0], [2, 1]
print(np.where(x)) # (array([0, 1, 2, 2]), array([0, 1, 0, 1]))
print(x[np.nonzero(x)]) # [1 2 1 1]

print(x &amp;gt; 1) # [[False False False] [False  True False] [False False False]]
print(x[np.nonzero(x &amp;gt; 1)]) # [2]

print(np.where(x == 1, x, 0)) # [[1 0 0] [0 0 0] [1 1 0]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html&#34;&gt;allclose()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_equal.html#numpy.array_equal&#34;&gt;array_equal()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一致する場合はTrueを返す。allclose()は誤差を許容する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [1e10,1e-8]
y = [1.00001e10,1e-9]
print(x == y) # False
print(np.allclose(x, y)) # True
print(np.array_equal(x, y)) # False

o = np.ones(3)
o2 = np.ones(4)
print(o == o2) # comparison failed
print(np.array_equal(o, o2)) # False
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.union1d.html&#34;&gt;union1d()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.intersect1d.html&#34;&gt;intersect1d()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.setdiff1d.html&#34;&gt;setdiff1d()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.setxor1d.html&#34;&gt;setxor1d()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;和、積、差集合と排他的論理和。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [1, 3, 4, 3]
y = [3, 1, 2, 1]
print(np.union1d(x, y)) # [1 2 3 4]
print(np.intersect1d(x, y)) # [1 3]
print(np.setdiff1d(x, y)) # [4]
print(np.setxor1d(x, y)) # [2 4]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.logical_and.html&#34;&gt;logical_and()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.all.html&#34;&gt;all()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.logical_or.html&#34;&gt;logical_or()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.any.html&#34;&gt;any()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.logical_not.html&#34;&gt;logical_not()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.logical_xor.html&#34;&gt;logical_xor()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AND,OR,NOT,XORしたbooleanの値を返す。all()とany()はarrayに対するANDとOR。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [True, False, True]
y = [False, False, True]
print(np.logical_and(x, y)) # [False False  True]
print(np.all([x, y, np.repeat([True], 3)], axis=0)) # [False False  True]
print(np.logical_or(x, y)) # [ True False  True]
print(np.any([x, y, np.repeat([True], 3)], axis=0)) # [ True  True  True]
print(np.logical_not(x)) # [False  True False]
print(np.logical_xor(x, y)) # [ True False False]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html&#34;&gt;bincount()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;正数の出現回数をカウントする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.bincount([0, 1, 2, 1, 2, 6, 1])) # [1 3 2 0 0 0 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;計算&#34;&gt;計算&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.add.html&#34;&gt;add()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html&#34;&gt;dot()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html&#34;&gt;matmul()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;和と内積(a・b)。和は+でも計算できるが、通常のarrayに使うと後ろに結合されてしまうのに注意。
&amp;ldquo;@&amp;ldquo;はmatmul()と同じで数値との積は計算できない。
&amp;ldquo;*&amp;ldquo;は&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.multiply.html&#34;&gt;multiply()&lt;/a&gt;で、要素ごとの積が返る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2, 2))

print([0, 1, 2] + [1, 2, 3]) # [0, 1, 2, 1, 2, 3]
print(x + x) # [[0 2] [4 6]]
print(np.add(x, x)) # [[0 2] [4 6]]

print(np.dot(np.ones((2,2)), np.ones((2,3)))) # [[ 2.  2.  2.] [ 2.  2.  2.]]
print(np.matmul(np.ones((2,2)), np.ones((2,3)))) # [[ 2.  2.  2.] [ 2.  2.  2.]]
print(np.ones((2,2)) @ np.ones((2,3))) # [[ 2.  2.  2.] [ 2.  2.  2.]]
print(np.ones((2,2)) * np.ones((2,3))) # operands could not be broadcast together with shapes (2,2) (2,3) 

print(np.dot(np.ones((2,2)), 2)) # [[ 2.  2.] [ 2.  2.]]
print(np.matmul(np.ones((2,2)), 2)) # Scalar operands are not allowed, use &#39;*&#39; instead
print(np.ones((2,2)) @ 2)  # Scalar operands are not allowed, use &#39;*&#39; instead
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.sqrt.html&#34;&gt;sqrt()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/routines.emath.html&#34;&gt;emath.sqrt()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;平方根を返す。emathの方は複素数が返る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.sqrt([4, 0, -4])) # [  2.   0.  nan]
print(np.emath.sqrt([4, 0, -4])) # [ 2.+0.j  0.+0.j  0.+2.j]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.sin.html&#34;&gt;sin()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.cos.html&#34;&gt;cos()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.tan.html&#34;&gt;tan()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.arcsin.html&#34;&gt;arcsin()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.arccos.html&#34;&gt;arccos()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.arctan.html&#34;&gt;arctan()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;三角関数と逆三角関数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from math import pi
x = np.linspace(-pi, pi, num=5)
print(np.sin(x)) # [ -1.22464680e-16  -1.00000000e+00   0.00000000e+00   1.00000000e+00  1.22464680e-16]
print(np.cos(x)) # [ -1.00000000e+00   6.12323400e-17   1.00000000e+00   6.12323400e-17 -1.00000000e+00]
print(np.tan(x)) # [  1.22464680e-16  -1.63312394e+16   0.00000000e+00   1.63312394e+16 -1.22464680e-16]

x2 = np.linspace(-1, 1, num=5)
print(np.arcsin(x2)) # [-1.57079633 -0.52359878  0.          0.52359878  1.57079633]
print(np.arccos(x2)) # [ 3.14159265  2.0943951   1.57079633  1.04719755  0.        ]
print(np.arctan(x2)) # [-0.78539816 -0.46364761  0.          0.46364761  0.78539816]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html&#34;&gt;exp()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.log.html&#34;&gt;log()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;指数と、eが底の自然対数(ln(x))。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 1, 2]
print(np.exp(x)) # [ 1.10517092  2.71828183  7.3890561 ]
print(np.log(x)) # [-2.30258509  0.          0.69314718]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.clip.html&#34;&gt;clip()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;minより小さな値はminに、maxより大きな値はmaxにする。log()の引数に0が渡るのを避けることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(2)
np.log(x) # RuntimeWarning: divide by zero encountered in log
x2 = np.clip(x, 1e-10, x)
print(x2) # [  1.00000000e-10   1.00000000e+00]
np.log(x2) # ok
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.min.html&#34;&gt;min()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmin.html&#34;&gt;argmin()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.max.html&#34;&gt;max()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html&#34;&gt;argmax()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html&#34;&gt;sum()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html&#34;&gt;mean()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.average.html&#34;&gt;average()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最小、最大、合計、平均。argmin()とargmax()はindexを返し、average()は重みを付けられる。average以外はx.min()のように呼ぶこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2, 2))
print(np.min(x)) # 0 
print(np.max(x)) # 3
print(np.argmax(x)) # 3
print(np.sum(x)) # 6
print(np.mean(x)) # 1.5
print(np.average(x, weights=np.array([[0, 1], [4, 1]]))) # 2.0 &amp;lt;= (1 * 1 + 2 * 4 + 3 * 1) / (1 + 4 + 1) 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.cumsum.html&#34;&gt;cumsum()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.diff.html&#34;&gt;diff()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;累積和と前の値との差。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(9).reshape((3, 3))
print(np.cumsum(x, axis=1)) # [[ 0  1  3] [ 3  7 12] [ 6 13 21]]
print(np.diff(x, axis=1)) # [[1 1] [1 1] [1 1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ceil.html&#34;&gt;ceil()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.floor.html&#34;&gt;floor()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.trunc.html&#34;&gt;trunc()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.absolute.html&#34;&gt;abs()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.copysign.html&#34;&gt;copysign()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;切り上げ、切り捨てと絶対値。floor(-2.5)は-3.0になり、trunc(-2.5)は-2.0になる。
copysign()は第2引数の符号を第1引数にコピーする。
exercisesでは&lt;code&gt;np.copysign(np.ceil(np.abs(Z)), Z)&lt;/code&gt;のようにabsしてから元に戻すために使われていた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.random.uniform(low=-5, high=5, size=(2,2))
print(x) # [[ 2.19861752 -4.22997748] [ 0.15346107  0.62893343]]
print(np.ceil(x)) # [[ 3. -4.] [ 1.  1.]]
print(np.floor(x)) # [[ 2. -5.] [ 0.  0.]]
print(np.trunc(x)) # [[ 2. -4.] [ 0.  0.]]
print(np.abs([-2, 0, 2])) # [2 0 2]
print (np.copysign([1, -2, -1], [-2, 1, -1])) # [-1.  2. -1.]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.det.html&#34;&gt;linalg.det()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;行列式(determinant)を計算する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.linalg.det(np.arange(4).reshape((2, 2)))) # -2.0 &amp;lt;= 0 * 3 - 1 * 2
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html&#34;&gt;percentile()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;パーセンタイルを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.percentile(np.arange(16).reshape((4,4)), 90)) # 13.5
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.convolve.html&#34;&gt;convolve()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1次元の畳み込み。第2引数をずらしながら掛けていく。
畳み込みニューラルネットワークでも使う2次元の畳み込みの関数はnumpyにはないが、scipyの&lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html&#34;&gt;signal.convolve2d()&lt;/a&gt;が使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/6/&#34;&gt;TensorFlow チュートリアル2(Deep MNIST for Experts) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(np.convolve([3, 6, 9], [0, 1, 0.5])) # [0.  1.  2.5 4.  1.5] &amp;lt;= [(0*3), (0*6+1*3), (0*9+1*6+0.5*3), (1*9+0.5*6), (0.5*9)]

from scipy import signal
print(signal.convolve2d(np.arange(9).reshape((3,3)), np.eye(2)))
&#39;&#39;&#39;
[[  0.   1.   2.   0.]
 [  3.   4.   6.   2.]
 [  6.  10.  12.   5.]
 [  0.   6.   7.   8.]]
&#39;&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;その他&#34;&gt;その他&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.reduce.html&#34;&gt;ufunc.reduce()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;その前の関数でreduceする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(4).reshape((2,2))
print(np.add.reduce(x)) # [2 4] &amp;lt;= default axis value is 0
print(np.add.reduce(x, axis=1)) # [1 5]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html&#34;&gt;random.choice()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ランダムに選ぶ。選ばれる確率pを渡すことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(5)
print(np.random.choice(x, 10)) # [3 3 0 4 1 2 0 4 2 1]
print(np.random.choice(x, 10, p=(x / np.sum(x)))) # [3 4 3 4 3 1 3 1 3 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.unravel_index.html&#34;&gt;unravel_index()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;フラットなindexをそのshapeでのindexに変換する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(9).reshape(3,3)
idx = np.unravel_index(5, x.shape)
print(idx) # (1, 2)
print(x[idx]) # 5
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html&#34;&gt;interp()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;線形補間(interpolation)した値を返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.arange(100)
y = np.sin(0.1 * x)
x2 = [10.5, 20.2, 30.4, 60.3, 80.9]
y2 = np.interp(x2, x, y)

import matplotlib.pyplot as plt
plt.plot(x, y)
plt.plot(x2, y2, &#39;o&#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/187.png&#34; alt=&#34;元のグラフと補完補間した点&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>cert-managerで生成した証明書をIstioのGatewayに設定してHTTPS対応する</title>
          <link>https://www.sambaiz.net/article/186/</link>
          <pubDate>Thu, 13 Sep 2018 21:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/186/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/jetstack/cert-manager&#34;&gt;cert-manager&lt;/a&gt;はTLSの証明書を自動で生成し管理するK8sのアドオン。
Istioにも含まれていて、これを使って&lt;a href=&#34;https://letsencrypt.org/&#34;&gt;Let&amp;rsquo;s Encrypt&lt;/a&gt;で証明書を生成しGatewayに設定することでHTTPS対応することができる。&lt;/p&gt;

&lt;p&gt;デフォルトではcert-managerは入らないのでenabled=trueにしてインストールする。
最初に入るLet&amp;rsquo;s EncryptのClusterIssuerはエラーになったので消す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/185/&#34;&gt;IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm install install/kubernetes/helm/istio --name istio --namespace istio-system --set certmanager.enabled=true
$ kubectl delete ClusterIssuer --all
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認用にBookInfoを動かす。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl label namespace default istio-injection=enabled
$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s Encryptで使われている&lt;a href=&#34;https://github.com/ietf-wg-acme/acme&#34;&gt;ACME&lt;/a&gt;プロトコルのドメイン認証(Challenge)には
&lt;code&gt;/.well-known/acme-challenge/{token}&lt;/code&gt;でHTTPレスポンスを返す&lt;a href=&#34;https://github.com/ietf-wg-acme/acme/blob/master/draft-ietf-acme-acme.md#http-challenge&#34;&gt;HTTP Challenge&lt;/a&gt;(http-01)と
DNSのTXTレコードに書き込む&lt;a href=&#34;https://github.com/ietf-wg-acme/acme/blob/master/draft-ietf-acme-acme.md#dns-challenge&#34;&gt;DNS Challenge&lt;/a&gt;(dns-01)がある。
HTTP Challengeは手軽に達成できる一方、CAからアクセスできるようにする必要がある。今回はDNS Challengeでやる。
cert-managerはCloud DNSやRoute53などに&lt;a href=&#34;http://docs.cert-manager.io/en/latest/reference/issuers/acme/dns01.html&#34;&gt;対応&lt;/a&gt;していて、今回はCloudflareを使う。&lt;/p&gt;

&lt;p&gt;DNSに書き込めるようにするためCloudflareのMy ProfileからGlobal API Keyを持ってきてBase64デコードしSecretに入れる。
改行コードが含まれないように&lt;code&gt;-n&lt;/code&gt;を付ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo -n ***** | base64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Secret
metadata:
  name: cloudflare-api-key
  namespace: istio-system
type: Opaque
data:
  api-key: *****
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s EncryptのClusterIssuerと証明書を生成するドメインのCertificateを作成する。
serverのURLは&lt;a href=&#34;https://letsencrypt.status.io/&#34;&gt;Status&lt;/a&gt;のページから確認できる。
本番のURLは&lt;a href=&#34;https://letsencrypt.org/docs/rate-limits/&#34;&gt;レート制限&lt;/a&gt;があるので、まずはFakeの証明書が生成されるstgで試すとよい。&lt;/p&gt;

&lt;p&gt;証明書を書くsecretNameは&lt;code&gt;istio-system&lt;/code&gt;ネームスペースの&lt;code&gt;istio-ingressgateway-certs&lt;/code&gt;にする&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/secure-ingress/#configure-a-tls-ingress-gateway&#34;&gt;必要がある&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: certmanager.k8s.io/v1alpha1
kind: ClusterIssuer
metadata:
  name: letsencrypt-dns01
  namespace: istio-system
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: aaa@example.com
    privateKeySecretRef:
      name: letsencrypt-dns01
    dns01:
      providers:
      - name: cloudflare
        cloudflare:
          email: aaa@example.com
          apiKeySecretRef:
            name: cloudflare-api-key
            key: api-key
---
apiVersion: certmanager.k8s.io/v1alpha1
kind: Certificate
metadata:
  name: xxx-example-com
  namespace: istio-system
spec:
  secretName: istio-ingressgateway-certs
  issuerRef:
    name: letsencrypt-dns01
    kind: ClusterIssuer
  commonName: xxx.example.com
  dnsNames:
  - xxx.example.com
  acme:
    config:
    - dns01:
        provider: cloudflare
      domains:
      - xxx.example.com
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをapplyするとcertmanagerのログが流れ始める。何か間違いがあるとエラーになるのでなんとかする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system logs -f $(kubectl -n istio-system get pods -l app=certmanager -o jsonpath=&#39;{.items[0].metadata.name}&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;証明書と秘密鍵のSecretはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl describe secret istio-ingressgateway-certs -n istio-system
Name:         istio-ingressgateway-certs
Namespace:    istio-system
Labels:       &amp;lt;none&amp;gt;
Annotations:  certmanager.k8s.io/alt-names=xxx.example.com
              certmanager.k8s.io/common-name=xxx.example.com
              certmanager.k8s.io/issuer-kind=ClusterIssuer
              certmanager.k8s.io/issuer-name=letsencrypt-dns01

Type:  kubernetes.io/tls

Data
====
tls.key:  1675 bytes
tls.crt:  3805 bytes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ingressgateway-certs&lt;/code&gt;は自動で&lt;code&gt;/etc/istio/ingressgateway-certs&lt;/code&gt;にマウントされる。
このGatewayをapplyするとHTTPでアクセスした場合はリダイレクトし、HTTPSで正常にアクセスできるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: bookinfo-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - xxx.example.com
    tls:
      httpsRedirect: true
  - port:
      number: 443
      name: https
      protocol: HTTPS
    hosts:
    - xxx.example.com
    tls:
      mode: SIMPLE
      serverCertificate: /etc/istio/ingressgateway-certs/tls.crt
      privateKey: /etc/istio/ingressgateway-certs/tls.key
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する</title>
          <link>https://www.sambaiz.net/article/185/</link>
          <pubDate>Sun, 02 Sep 2018 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/185/</guid>
          <description>

&lt;p&gt;Istioは&lt;a href=&#34;https://www.envoyproxy.io/&#34;&gt;Envoy&lt;/a&gt;というProxyをSidecarとしてPodに入れてトラフィックを通すことでマイクロサービスのRoutingやTelemetryをサービスのコードに手を入れずに行うことができるサービスメッシュ。
もともとEnvoy自体は単体で、コネクションを張りっぱなしのgRPC(HTTP/2)をK8sのServiceのL4ロードバランサーでは分散できない問題の解決方法の一つとして
各PodのIPの一覧を返す&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#headless-services&#34;&gt;Headless Service&lt;/a&gt;と使われていたが、各Manifestに入れたりConfigMapを編集したりする必要があり少し面倒だった。
Istioにするとそれらが省けて、さらに賢いRoutingやモニタリングの仕組みまで付いてくるのでとても便利だ。&lt;/p&gt;

&lt;h2 id=&#34;インストール-https-istio-io-docs-setup-kubernetes-helm-install&#34;&gt;&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/helm-install/&#34;&gt;インストール&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;IstioをダウンロードしてきてHelmでインストールする。Istioには様々なコンポーネントが含まれているが、&lt;a href=&#34;https://github.com/istio/istio/blob/b17b4989699a6d9dc98245c511dc7d544d88e945/install/kubernetes/helm/istio/README.md#configuration&#34;&gt;パラメータ&lt;/a&gt;でインストールするものを選択することができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/122/&#34;&gt;KubernetesのパッケージマネージャーHelmを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今回はデフォルトではfalseになっているGrafana/Jaeger/Kialiをtrueにしてほぼ全て入るようにしている。&lt;/p&gt;

&lt;p&gt;RBACが有効な場合はServiceAccountを作ってcluster-adminあるいは必要なRoleをBindしておく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/160/&#34;&gt;RBACが有効なGKEでHelmを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -L https://git.io/getLatestIstio | sh -
$ cd istio-1.0.1/
# helm init --service-account tiller
$ helm install install/kubernetes/helm/istio --name istio --namespace istio-system --set grafana.enabled=true --set grafana.persist=true --set grafana.storageClassName=standard --set tracing.enabled=true --set kiali.enabled=true
$ kubectl get pod -n istio-system
NAME                                        READY     STATUS    RESTARTS   AGE
grafana-598678cbb-bglbq                     1/1       Running   0          3m
istio-citadel-6f9887d776-tvdg8              1/1       Running   0          3m
istio-egressgateway-84d78d84bf-zpxrq        1/1       Running   0          3m
istio-galley-556f5558f5-hk2r8               1/1       Running   0          3m
istio-ingressgateway-78cccbddbb-gh2xl       1/1       Running   0          3m
istio-pilot-799845f56d-l777d                2/2       Running   0          3m
istio-policy-7666fcd574-nbx8s               2/2       Running   0          3m
istio-sidecar-injector-7b6589c9-m7x77       1/1       Running   0          3m
istio-statsd-prom-bridge-55965ff9c8-s6dmj   1/1       Running   0          3m
istio-telemetry-844c8d6bff-9trcf            2/2       Running   0          3m
istio-tracing-77f9f94b98-g7v6f              1/1       Running   0          3m
kiali-bdf7fdc78-9lpd4                       1/1       Running   0          3m
prometheus-7456f56c96-drhlq                 1/1       Running   0          3m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;default namespaceにラベルを貼って自動でEnvoyが各Podに&lt;a href=&#34;https://github.com/istio/istio/blob/1.0.1/install/kubernetes/helm/istio/templates/sidecar-injector-configmap.yaml#L77&#34;&gt;Injectionされる&lt;/a&gt;ようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get namespace -L istio-injection
NAME           STATUS    AGE       ISTIO-INJECTION
default        Active    27m       
istio-system   Active    16m       
kube-public    Active    27m       
kube-system    Active    27m 

$ kubectl label namespace default istio-injection=enabled
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;併せて&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/init-containers/&#34;&gt;Init Containers&lt;/a&gt;としてInjectionされるistio-initのiptablesで&lt;a href=&#34;https://github.com/istio/istio/blob/1.0.1/tools/deb/istio-iptables.sh#L292&#34;&gt;Envoy以外&lt;/a&gt;のトラフィックが&lt;a href=&#34;https://github.com/istio/istio/blob/1.0.1/tools/deb/istio-iptables.sh#L202&#34;&gt;Envoyのポートに向く&lt;/a&gt;のでサービスのコードでは向き先を変える必要がない。&lt;/p&gt;

&lt;h2 id=&#34;routing&#34;&gt;Routing&lt;/h2&gt;

&lt;h3 id=&#34;pilot-https-istio-io-docs-concepts-traffic-management-pilot-and-envoy&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/traffic-management/#pilot-and-envoy&#34;&gt;Pilot&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;全Envoyを管理するPilotにEnvoy間のトラフィックのルーティングや、リトライやサーキットブレーカーのルールを設定できる。
EnvoyはPilotからサービスディスカバリして他Envoyについて知り、定期的にロードバランシングプールに含まれるインスタンスのヘルスチェックをして失敗数がしきい値を超えたら成功数がしきい値を超えるまでプールから追い出し、ルールに従いトラフィックを制御する。&lt;/p&gt;

&lt;h3 id=&#34;リソース&#34;&gt;リソース&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/reference/config/istio.networking.v1alpha3/#Gateway&#34;&gt;Gateway&lt;/a&gt;: HTTP/TCPロードバランサー。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ingressとは異なりL4-L6のポートやTLSの設定は持つがL7の設定は持たず、VirtualServiceに持つ。
インフラ管理者とサービス開発者が触るであろうリソースが分離されている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/173/&#34;&gt;GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/reference/config/istio.networking.v1alpha3/#VirtualService&#34;&gt;VirtualService&lt;/a&gt;: ルーティングのルール。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/reference/config/istio.networking.v1alpha3/#DestinationRule&#34;&gt;DestinationRule&lt;/a&gt;: ロードバランシングのルール。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;例-https-istio-io-docs-examples-bookinfo&#34;&gt;&lt;a href=&#34;https://istio.io/docs/examples/bookinfo/&#34;&gt;例&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;サンプルアプリケーションBookInfoを動かす。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
$ kubectl get pod
NAME                              READY     STATUS    RESTARTS   AGE
details-v1-7bcdcc4fd6-x92f5       2/2       Running   0          1m
productpage-v1-8584c875d8-jxl68   2/2       Running   0          1m
ratings-v1-54cf9dc8f8-wv9xz       2/2       Running   0          1m
reviews-v1-59cbdd7959-vxf2f       2/2       Running   0          1m
reviews-v2-dccb4cfc9-mc22f        2/2       Running   0          1m
reviews-v3-5465dc97bc-pgvbl       2/2       Running   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GatewayとVirtualServiceを作成して外に開く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/bookinfo-gateway.yaml
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: bookinfo-gateway
spec:
  selector:
    istio: ingressgateway # use istio default controller
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - &amp;quot;*&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: bookinfo
spec:
  hosts:
  - &amp;quot;*&amp;quot;
  gateways:
  - bookinfo-gateway
  http:
  - match:
    - uri:
        exact: /productpage
    - uri:
        exact: /login
    - uri:
        exact: /logout
    - uri:
        prefix: /api/v1/products
    route:
    - destination:
        host: productpage
        port:
          number: 9080

$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml
$ export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.status.loadBalancer.ingress[0].ip}&#39;)
$ export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.spec.ports[?(@.name==&amp;quot;http2&amp;quot;)].port}&#39;)
$ export GATEWAY_URL=http://$INGRESS_HOST:$INGRESS_PORT
$ open $GATEWAY_URL/productpage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-bookinfo.png&#34; alt=&#34;BookInfo&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DestinationRuleを作成する。この時点では各バージョンがラウンドロビンする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/destination-rule-all.yaml
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: productpage
spec:
  host: productpage
  subsets:
  - name: v1
    labels:
      version: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: reviews
spec:
  host: reviews
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
  - name: v3
    labels:
      version: v3
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: ratings
spec:
  host: ratings
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
  - name: v2-mysql
    labels:
      version: v2-mysql
  - name: v2-mysql-vm
    labels:
      version: v2-mysql-vm
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: details
spec:
  host: details
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
---

$ kubectl apply -f samples/bookinfo/networking/destination-rule-all.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VirtualServiceのdestinationでsubsetを指定するとそのバージョンのみに&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/request-routing/&#34;&gt;飛ぶ&lt;/a&gt;ようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/virtual-service-all-v1.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: productpage
spec:
  hosts:
  - productpage
  http:
  - route:
    - destination:
        host: productpage
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
  - reviews
  http:
  - route:
    - destination:
        host: reviews
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ratings
spec:
  hosts:
  - ratings
  http:
  - route:
    - destination:
        host: ratings
        subset: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: details
spec:
  hosts:
  - details
  http:
  - route:
    - destination:
        host: details
        subset: v1
---

$ kubectl apply -f samples/bookinfo/networking/virtual-service-all-v1.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VirtualServiceはheaderの中身をみてルーティングさせることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/virtual-service-reviews-test-v2.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
    - reviews
  http:
  - match:
    - headers:
        end-user:
          exact: jason
    route:
    - destination:
        host: reviews
        subset: v2
  - route:
    - destination:
        host: reviews
        subset: v1

$ kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-test-v2.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/fault-injection/&#34;&gt;Fault Injection&lt;/a&gt;して特定条件や割合で意図的に遅延を生じさせたり、エラーコードを返らせたりできる。バグの発見や調査、Chaos Engineeringもできそうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ratings
spec:
  hosts:
  - ratings
  http:
  - match:
    - headers:
        end-user:
          exact: jason
    fault:
      delay:
        percent: 100
        fixedDelay: 7s
    route:
    - destination:
        host: ratings
        subset: v1
  - route:
    - destination:
        host: ratings
        subset: v1

$ kubectl apply -f samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;routeには複数のdestinationを指定できてweightによって飛ばす割合を&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/traffic-shifting/&#34;&gt;変えられる&lt;/a&gt;。
カナリアリリースやA/Bテストが簡単にできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat samples/bookinfo/networking/virtual-service-reviews-50-v3.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
    - reviews
  http:
  - route:
    - destination:
        host: reviews
        subset: v1
      weight: 50
    - destination:
        host: reviews
        subset: v3
      weight: 50

$ kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-50-v3.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;telemetry&#34;&gt;Telemetry&lt;/h2&gt;

&lt;h3 id=&#34;mixer-https-istio-io-docs-concepts-policies-and-telemetry&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/policies-and-telemetry/&#34;&gt;Mixer&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;MixerはポリシーコントロールとTelemetryを行うコンポーネント。
&lt;a href=&#34;https://istio.io/docs/reference/config/policy-and-telemetry/adapters/&#34;&gt;Adapter&lt;/a&gt;によってStackdriverやCloudWatchなど様々なバックエンドに対応している。&lt;/p&gt;

&lt;p&gt;Envoyは前提条件を確認するためリクエストの前と、Telemetryするためリクエストの後にMixerを呼び出す。ただしキャッシュとバッファを持っていて毎回呼び出しはしない。また、Mixerもキャッシュやバッファを持ちバックエンドの呼び出し回数を減らしている。
MixerがSPOFとなり可用性が下がるのではと思われるが、バックエンドの障害をある程度許容できるのに加えて Mixer自身はステートレスで他のバックエンドよりも可用性が高く設計されているためむしろ&lt;a href=&#34;https://istio.io/blog/2017/mixer-spof-myth/&#34;&gt;SLOが向上する&lt;/a&gt;そうだ。&lt;/p&gt;

&lt;h3 id=&#34;リソース-1&#34;&gt;リソース&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/concepts/policies-and-telemetry/#handlers&#34;&gt;Handler(Adapter)&lt;/a&gt;: Mixerからバックエンドへ送る。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/concepts/policies-and-telemetry/#instances&#34;&gt;Instance&lt;/a&gt;: EnvoyからMixerに送られてきたAttributeをAdapterの入力へマッピングする。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/concepts/policies-and-telemetry/#rules&#34;&gt;Rule&lt;/a&gt;: Handlerが特定のInstancesで呼び出されるルール。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;例-https-istio-io-docs-tasks-telemetry-metrics-logs&#34;&gt;&lt;a href=&#34;https://istio.io/docs/tasks/telemetry/metrics-logs/&#34;&gt;例&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;リクエストの2倍の数を値とするmetric instance。&lt;a href=&#34;https://istio.io/docs/reference/config/policy-and-telemetry/expression-language/&#34;&gt;configuration expression language(CEXL)&lt;/a&gt;が使われている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat new_telemetry.yaml 
# Configuration for metric instances
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: metric
metadata:
  name: doublerequestcount
  namespace: istio-system
spec:
  value: &amp;quot;2&amp;quot; # count each request twice
  dimensions:
    reporter: conditional((context.reporter.kind | &amp;quot;inbound&amp;quot;) == &amp;quot;outbound&amp;quot;, &amp;quot;client&amp;quot;, &amp;quot;server&amp;quot;)
    source: source.workload.name | &amp;quot;unknown&amp;quot;
    destination: destination.workload.name | &amp;quot;unknown&amp;quot;
    message: &#39;&amp;quot;twice the fun!&amp;quot;&#39;
  monitored_resource_type: &#39;&amp;quot;UNSPECIFIED&amp;quot;&#39;
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このmetricを受け取るprometheus handler。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Configuration for a Prometheus handler
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: prometheus
metadata:
  name: doublehandler
  namespace: istio-system
spec:
  metrics:
  - name: double_request_count # Prometheus metric name
    instance_name: doublerequestcount.metric.istio-system # Mixer instance name (fully-qualified)
    kind: COUNTER
    label_names:
    - reporter
    - source
    - destination
    - message
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そしてこれらを紐づけるrule。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Rule to send metric instances to a Prometheus handler
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: rule
metadata:
  name: doubleprom
  namespace: istio-system
spec:
  actions:
  - handler: doublehandler.prometheus
    instances:
    - doublerequestcount.metric
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://istio.io/docs/reference/config/policy-and-telemetry/templates/logentry/&#34;&gt;logentry&lt;/a&gt;はログを表すinstance。
あとはそれを標準出力するhandlerとrule。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Configuration for logentry instances
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: logentry
metadata:
  name: newlog
  namespace: istio-system
spec:
  severity: &#39;&amp;quot;warning&amp;quot;&#39;
  timestamp: request.time
  variables:
    source: source.labels[&amp;quot;app&amp;quot;] | source.workload.name | &amp;quot;unknown&amp;quot;
    user: source.user | &amp;quot;unknown&amp;quot;
    destination: destination.labels[&amp;quot;app&amp;quot;] | destination.workload.name | &amp;quot;unknown&amp;quot;
    responseCode: response.code | 0
    responseSize: response.size | 0
    latency: response.duration | &amp;quot;0ms&amp;quot;
  monitored_resource_type: &#39;&amp;quot;UNSPECIFIED&amp;quot;&#39;
---
# Configuration for a stdio handler
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: stdio
metadata:
  name: newhandler
  namespace: istio-system
spec:
 severity_levels:
   warning: 1 # Params.Level.WARNING
 outputAsJson: true
---
# Rule to send logentry instances to a stdio handler
apiVersion: &amp;quot;config.istio.io/v1alpha2&amp;quot;
kind: rule
metadata:
  name: newlogstdio
  namespace: istio-system
spec:
  match: &amp;quot;true&amp;quot; # match for all requests
  actions:
   - handler: newhandler.stdio
     instances:
     - newlog.logentry
---

$ kubectl apply -f new_telemetry.yaml 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prometheus handlerによってdoublerequestcount metricが届いている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=prometheus -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 9090:9090
$ open http://localhost:9090/graph
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-prometheus.png&#34; alt=&#34;Prometheus&#34; /&gt;&lt;/p&gt;

&lt;p&gt;stdio handlerによってnewlog logentryが出力されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system logs -f $(kubectl -n istio-system get pods -l istio-mixer-type=telemetry -o jsonpath=&#39;{.items[0].metadata.name}&#39;) -c mixer | grep \&amp;quot;instance\&amp;quot;:\&amp;quot;newlog.logentry.istio-system\&amp;quot; 
{&amp;quot;level&amp;quot;:&amp;quot;warn&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2018-09-01T13:53:45.897141Z&amp;quot;,&amp;quot;instance&amp;quot;:&amp;quot;l&amp;quot;,&amp;quot;destination&amp;quot;:&amp;quot;telemetry&amp;quot;,&amp;quot;latency&amp;quot;:&amp;quot;3.817501ms&amp;quot;,&amp;quot;responseCode&amp;quot;:200,&amp;quot;responseSize&amp;quot;:5,&amp;quot;source&amp;quot;:&amp;quot;details&amp;quot;,&amp;quot;user&amp;quot;:&amp;quot;unknown&amp;quot;}
{&amp;quot;level&amp;quot;:&amp;quot;warn&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2018-09-01T13:53:45.899237Z&amp;quot;,&amp;quot;instance&amp;quot;:&amp;quot;newlog.logentry.istio-system&amp;quot;,&amp;quot;destination&amp;quot;:&amp;quot;telemetry&amp;quot;,&amp;quot;latency&amp;quot;:&amp;quot;4.423947ms&amp;quot;,&amp;quot;responseCode&amp;quot;:200,&amp;quot;responseSize&amp;quot;:5,&amp;quot;source&amp;quot;:&amp;quot;productpage&amp;quot;,&amp;quot;user&amp;quot;:&amp;quot;unknown&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;grafana&#34;&gt;Grafana&lt;/h2&gt;

&lt;p&gt;Grafanaを開くと最初からIstioのダッシュボードがいくつか作られている。
Prometheusに送ったmetricをGrafanaで可視化できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=grafana -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 3000:3000
$ open http://localhost:3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-grafana.png&#34; alt=&#34;Grafana&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;jaeger&#34;&gt;Jaeger&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.jaegertracing.io/&#34;&gt;Jaeger&lt;/a&gt;は分散トレーシングツール。
パフォーマンスが問題になったときにどこのサービスがボトルネックになっているかが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl port-forward -n istio-system $(kubectl get pod -n istio-system -l app=jaeger -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 16686:16686
$ open http://localhost:16686
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-jaeger.png&#34; alt=&#34;Jaeger&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;kiali&#34;&gt;Kiali&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.kiali.io/&#34;&gt;Kiali&lt;/a&gt;はサービスメッシュを可視化するツール。v1とv3にリクエストが飛んでいてv2には飛んでいないことが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=kiali -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 20001:20001
$ open http://localhost:20001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/185-kiali.png&#34; alt=&#34;Kiali&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/wataru420/items/a63a8b205308a93e253c&#34;&gt;kubernetesでgRPCするときにenvoy挟んでみたよ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/why-you-should-care-about-istio-gateways/&#34;&gt;Why You Should Care About Istio Gateways - The New Stack&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>nohupし忘れた時間のかかる処理をdisownしてexit後も実行させ続ける</title>
          <link>https://www.sambaiz.net/article/184/</link>
          <pubDate>Thu, 23 Aug 2018 00:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/184/</guid>
          <description>&lt;p&gt;時間がかかるコマンドを実行する場合、通常は&lt;code&gt;nohup&lt;/code&gt;で実行し
ターミナル終了時に飛ぶ&lt;a href=&#34;https://en.wikipedia.org/wiki/SIGHUP&#34;&gt;SIGHUP(SIGnal Hang UP)&lt;/a&gt;を無視させることで
exitしても実行させ続けることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nohup ./foo &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただnohupを付けずに実行し始めてから思ったより時間がかかるということもある。
その場合は、&lt;code&gt;Ctrl+Z&lt;/code&gt;で一旦停止してから&lt;code&gt;bg&lt;/code&gt;でバックラウンドで実行するようにして&lt;code&gt;disown -h&lt;/code&gt;でSIGHUPが送られないようにできる。
&lt;code&gt;disown&lt;/code&gt;はシェルのジョブテーブルから削除するコマンドで、そのままでもSIGHUPが送られないようにできるが、
-hを付けるとジョブテーブルから削除せずに済む。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ jobs
[1]+  停止                  ./foo

$ bg 1
$ jobs
[1]+  実行中                ./foo

$ disown -h %1
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CircleCI 2.0でDocker imageをbuildしてタグを付けてContainer Registryに上げる</title>
          <link>https://www.sambaiz.net/article/183/</link>
          <pubDate>Wed, 22 Aug 2018 23:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/183/</guid>
          <description>

&lt;p&gt;masterにpushしたときと、リリースタグを切ったときにビルドされるようにする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/183-ci.png&#34; alt=&#34;imageとタグ&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: 2
jobs:
  build:
    docker:
      - image: google/cloud-sdk
    environment:
      GCP_PROJECT: &amp;lt;project_name&amp;gt;
      IMAGE_NAME: &amp;lt;image_name&amp;gt;
    steps:
      - checkout
      - setup_remote_docker:
          version: 18.05.0-ce
      - run:
          name: gcloud auth
          command: |
            echo $GCLOUD_SERVICE_KEY | base64 --decode &amp;gt; ${HOME}/gcloud-service-key.json
            gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json
            gcloud --quiet auth configure-docker
      - run:
          name: docker build &amp;amp; push
          command: |
            docker build -t asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} .
            docker tag asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:latest
            if [ -n &amp;quot;${CIRCLE_TAG}&amp;quot; ]; then
              docker tag asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_TAG}
            fi
            docker push asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}

workflows:
  version: 2
  master-build:
    jobs:
      - build:
          filters:
            branches:
              only: master
  release-build:
    jobs:
      - build:
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /^v.*/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;

&lt;p&gt;dockerコマンドを実行できるように&lt;a href=&#34;https://circleci.com/docs/2.0/building-docker-images/&#34;&gt;setup_remote_docker&lt;/a&gt;する。&lt;/p&gt;

&lt;h2 id=&#34;gcpの認証&#34;&gt;GCPの認証&lt;/h2&gt;

&lt;p&gt;Storageのbucketも読み書きできるようにストレージ管理者のService Accountを作成して鍵をJSONでダウンロードし、
base64エンコードしてCircleCIのEnvironment Variablesのところに&lt;code&gt;GCLOUD_SERVICE_KEY&lt;/code&gt;で登録する。
ビルド時にはこれをデコードしてactivate-service-accountする。&lt;/p&gt;

&lt;h2 id=&#34;branchとtagのフィルタ&#34;&gt;branchとtagのフィルタ&lt;/h2&gt;

&lt;p&gt;workflowがなくてもbuildのjobは実行される。
しかし、ブランチのフィルタはjobの方でも設定&lt;a href=&#34;https://circleci.com/docs/2.0/configuration-reference/&#34;&gt;できる&lt;/a&gt;が、タグは設定できないため
workflowを作る必要がある。&lt;/p&gt;

&lt;p&gt;また、tagsを設定しないとタグに反応してビルドが始まらず、branchをignoreしないとタグを切ってないときにも無条件にビルドが走ってしまうので
release-buildではbranchをignoreしている。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KubernetesのCustom Resource Definition(CRD)とCustom Controller</title>
          <link>https://www.sambaiz.net/article/182/</link>
          <pubDate>Thu, 09 Aug 2018 23:59:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/182/</guid>
          <description>

&lt;p&gt;K8sではDeploymentを作成したときにReplicaSetも&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.11.2/pkg/controller/deployment/sync.go#L220&#34;&gt;作成&lt;/a&gt;されるようにしたり、
Load Balancer Serviceを作成したときにGCPなどその環境に応じたLoad Balancerも&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.11.2/pkg/controller/service/service_controller.go#L305&#34;&gt;作成&lt;/a&gt;されるようにしたりするため、Controllerがそれらを監視してAPIを呼んでいる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/173/&#34;&gt;GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Controllerは単なるAPIを呼ぶアプリケーションなので自分でCustom Controllerを作成してDeploymentとしてデプロイすることもできる。
また、監視する対象もpodsやdeploymentsといった標準のAPIだけではなく、
&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#adding-custom-resources&#34;&gt;Custom Resource&lt;/a&gt;
で拡張したものを使うことができる。&lt;/p&gt;

&lt;p&gt;特定のアプリケーションのためのControllerは&lt;a href=&#34;https://coreos.com/blog/introducing-operators.html&#34;&gt;Operator&lt;/a&gt;とも呼ばれる。&lt;/p&gt;

&lt;h2 id=&#34;customresourcedefinition-crd-https-kubernetes-io-docs-tasks-access-kubernetes-api-custom-resources-custom-resource-definitions&#34;&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/&#34;&gt;CustomResourceDefinition(CRD)&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Custom Resourceを定義する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: crontabs.stable.example.com
spec:
  # REST APIで使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;
  group: stable.example.com
  version: v1
  # Namespaced か Cluster
  scope: Namespaced
  names:
    # 複数形 URLに使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;/&amp;lt;plural&amp;gt;
    plural: crontabs
    # 単数形 CLIなどで使われる
    singular: crontab
    # manifestで使う
    kind: CronTab
    shortNames:
    - ct
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f crd.yaml
$ kubectl get crd
NAME                          AGE
crontabs.stable.example.com   8s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;標準のresourceと同様にKindに指定してcreateできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat crontab.yaml
apiVersion: stable.example.com/v1
kind: CronTab
metadata:
  name: test

$ kubectl create -f crontab.yaml
$ kubectl get crontab
NAME      AGE
test      10s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;client&#34;&gt;Client&lt;/h2&gt;

&lt;p&gt;Controllerで使うCustom ResourceのClientを準備する。&lt;/p&gt;

&lt;h3 id=&#34;生成&#34;&gt;生成&lt;/h3&gt;

&lt;p&gt;まず、以下のようにファイルを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tree pkg
pkg
└── apis
    └── mysamplecontroller
        ├── register.go
        └── v1
            ├── doc.go
            ├── register.go
            └── types.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;doc.go&lt;/code&gt;はpackage指定のみ、&lt;code&gt;types.go&lt;/code&gt;にはCustom Resourceのstructを書いて&lt;a href=&#34;https://github.com/kubernetes/code-generator&#34;&gt;code-generator&lt;/a&gt;用のタグを付けている。register.goは&lt;a href=&#34;https://github.com/kubernetes/sample-controller/blob/kubernetes-1.11.1/pkg/apis/samplecontroller/v1alpha1/register.go&#34;&gt;sample&lt;/a&gt;からほとんどコピー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// +k8s:deepcopy-gen=package,register

// +groupName=example.com
package v1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;package v1

import (
	metav1 &amp;quot;k8s.io/apimachinery/pkg/apis/meta/v1&amp;quot;
)

// +genclient
// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object

type SampleResource struct {
	metav1.TypeMeta   `json:&amp;quot;,inline&amp;quot;`
	metav1.ObjectMeta `json:&amp;quot;metadata,omitempty&amp;quot;`

	Spec SampleResourceSpec `json:&amp;quot;spec&amp;quot;`
}

type SampleResourceSpec struct {
	PodImage string `json:&amp;quot;podImage&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;code-generatorを持ってきて&lt;code&gt;generate-groups.sh&lt;/code&gt;を実行すると残りのファイルが生成される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Makefile
.PHONY: codegen
codegen:
	${GOPATH}/src/k8s.io/code-generator/generate-groups.sh &amp;quot;deepcopy,client,informer,lister&amp;quot; \
	github.com/sambaiz/k8s-sample-crd-controller/pkg/client github.com/sambaiz/k8s-sample-crd-controller/pkg/apis \
	mysamplecontroller:v1

$ make codegen
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;zz_generated.deepcopy.go&lt;/code&gt;でCustom Resourceのstructに&lt;code&gt;DeepCopyObject()&lt;/code&gt;関数を追加し、
&lt;a href=&#34;https://github.com/kubernetes/apimachinery/blob/kubernetes-1.11.2/pkg/runtime/interfaces.go#L231&#34;&gt;runtime.Object&lt;/a&gt; interfaceを満たすようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tree pkg
pkg
├── apis
│   └── mysamplecontroller
│       ├── register.go
│       └── v1
│           ├── doc.go
│           ├── register.go
│           ├── types.go
│           └── zz_generated.deepcopy.go
└── client
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;controller&#34;&gt;Controller&lt;/h2&gt;

&lt;p&gt;公式の&lt;a href=&#34;https://github.com/kubernetes/sample-controller&#34;&gt;sample-controller&lt;/a&gt;を見ていく。&lt;/p&gt;

&lt;h3 id=&#34;main-go&#34;&gt;main.go&lt;/h3&gt;

&lt;p&gt;Clientを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
    &amp;quot;k8s.io/client-go/kubernetes&amp;quot;
    clientset &amp;quot;k8s.io/sample-controller/pkg/client/clientset/versioned&amp;quot;
)

cfg, err := clientcmd.BuildConfigFromFlags(masterURL, kubeconfig)
kubeClient, err := kubernetes.NewForConfig(cfg)
exampleClient, err := clientset.NewForConfig(cfg)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にClientからdeploymentsとCustom Resourceであるfoosの&lt;a href=&#34;https://github.com/kubernetes/sample-controller/blob/master/docs/controller-client-go.md#client-go-components&#34;&gt;Informer&lt;/a&gt;を作ってControllerに渡す。Informerは変更があったObjectが入るDeltaFifoQueueを監視して、Event Handlerを呼ぶもの。
ちなみにK8sのAPIを監視してDeltaFifoQueueに入れるのはReflectorがやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
    kubeinformers &amp;quot;k8s.io/client-go/informers&amp;quot;
    informers &amp;quot;k8s.io/sample-controller/pkg/client/informers/externalversions&amp;quot;
)

kubeInformerFactory := kubeinformers.NewSharedInformerFactory(kubeClient, time.Second*30)
exampleInformerFactory := informers.NewSharedInformerFactory(exampleClient, time.Second*30)

controller := NewController(kubeClient, exampleClient,
    kubeInformerFactory.Apps().V1().Deployments(),
    exampleInformerFactory.Samplecontroller().V1alpha1().Foos())

go kubeInformerFactory.Start(stopCh)
go exampleInformerFactory.Start(stopCh)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;controller-go&#34;&gt;controller.go&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;func NewController(
	kubeclientset kubernetes.Interface,
	sampleclientset clientset.Interface,
	deploymentInformer appsinformers.DeploymentInformer,
	fooInformer informers.FooInformer) *Controller {
    ...
    controller := &amp;amp;Controller{
        kubeclientset:     kubeclientset,
        sampleclientset:   sampleclientset,
        deploymentsLister: deploymentInformer.Lister(),
        deploymentsSynced: deploymentInformer.Informer().HasSynced,
        foosLister:        fooInformer.Lister(),
        foosSynced:        fooInformer.Informer().HasSynced,
        workqueue:         workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), &amp;quot;Foos&amp;quot;),
        recorder:          recorder,
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EventHandlerを登録する。fooInformerの方は&amp;rdquo;namespace/name&amp;rdquo;の文字列をControllerのWorkququeに入れる。
deploymentInformerの方は&lt;a href=&#34;https://github.com/kubernetes/apimachinery/blob/kubernetes-1.11.2/pkg/apis/meta/v1/controller_ref.go#L33&#34;&gt;GetControllerOf()&lt;/a&gt;で&lt;a href=&#34;https://github.com/kubernetes/apimachinery/blob/kubernetes-1.11.2/pkg/apis/meta/v1/types.go#L290&#34;&gt;OwnerReference&lt;/a&gt;を見て、それがFooならInformerでObjectを取得し同様の処理を行う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fooInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
    AddFunc: controller.enqueueFoo,
    UpdateFunc: func(old, new interface{}) {
        controller.enqueueFoo(new)
    },
})

deploymentInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
    AddFunc: controller.handleObject,
    UpdateFunc: func(old, new interface{}) {
        newDepl := new.(*appsv1.Deployment)
        oldDepl := old.(*appsv1.Deployment)
        if newDepl.ResourceVersion == oldDepl.ResourceVersion {
            return
        }
        controller.handleObject(new)
    },
    DeleteFunc: controller.handleObject,
})

func (c *Controller) enqueueFoo(obj interface{}) {
	var key string
	var err error
	if key, err = cache.MetaNamespaceKeyFunc(obj); err != nil {
		runtime.HandleError(err)
		return
	}
	c.workqueue.AddRateLimited(key)
}

func (c *Controller) handleObject(obj interface{}) {
	var object metav1.Object
	var ok bool
	if object, ok = obj.(metav1.Object); !ok {
		tombstone, ok := obj.(cache.DeletedFinalStateUnknown)
		if !ok {
			runtime.HandleError(fmt.Errorf(&amp;quot;error decoding object, invalid type&amp;quot;))
			return
		}
		object, ok = tombstone.Obj.(metav1.Object)
		if !ok {
			runtime.HandleError(fmt.Errorf(&amp;quot;error decoding object tombstone, invalid type&amp;quot;))
			return
		}
		glog.V(4).Infof(&amp;quot;Recovered deleted object &#39;%s&#39; from tombstone&amp;quot;, object.GetName())
	}
	glog.V(4).Infof(&amp;quot;Processing object: %s&amp;quot;, object.GetName())
	if ownerRef := metav1.GetControllerOf(object); ownerRef != nil {
		if ownerRef.Kind != &amp;quot;Foo&amp;quot; {
			return
		}

		foo, err := c.foosLister.Foos(object.GetNamespace()).Get(ownerRef.Name)
		if err != nil {
			glog.V(4).Infof(&amp;quot;ignoring orphaned object &#39;%s&#39; of foo &#39;%s&#39;&amp;quot;, object.GetSelfLink(), ownerRef.Name)
			return
		}

		c.enqueueFoo(foo)
		return
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Workqueueから取り出して処理を行う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;obj, shutdown := c.workqueue.Get()
err := func(obj interface{}) error {
    defer c.workqueue.Done(obj)
	if key, ok = obj.(string); !ok {
        c.workqueue.Forget(obj)
        runtime.HandleError(fmt.Errorf(&amp;quot;expected string in workqueue but got %#v&amp;quot;, obj))
        return nil
    }
    if err := c.syncHandler(key); err != nil {
        return fmt.Errorf(&amp;quot;error syncing &#39;%s&#39;: %s&amp;quot;, key, err.Error())
    }
    c.workqueue.Forget(obj)
    glog.Infof(&amp;quot;Successfully synced &#39;%s&#39;&amp;quot;, key)
    return nil
}(obj)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fooを取得し、specのdeploymentNameのdeploymentをclientで生成する。OwnerReferenceを含んでいる。
ここでは省略しているが、既に存在してコントロール下にない場合などのチェックもしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace, name, err := cache.SplitMetaNamespaceKey(key)
foo, err := c.foosLister.Foos(namespace).Get(name)
deploymentName := foo.Spec.DeploymentName
deployment, err := c.deploymentsLister.Deployments(foo.Namespace).Get(deploymentName)
if errors.IsNotFound(err) {
    deployment, err = c.kubeclientset.AppsV1().Deployments(foo.Namespace).Create(newDeployment(foo))
}

func newDeployment(foo *samplev1alpha1.Foo) *appsv1.Deployment {
	labels := map[string]string{
		&amp;quot;app&amp;quot;:        &amp;quot;nginx&amp;quot;,
		&amp;quot;controller&amp;quot;: foo.Name,
	}
	return &amp;amp;appsv1.Deployment{
		ObjectMeta: metav1.ObjectMeta{
			Name:      foo.Spec.DeploymentName,
			Namespace: foo.Namespace,
			OwnerReferences: []metav1.OwnerReference{
				*metav1.NewControllerRef(foo, schema.GroupVersionKind{
					Group:   samplev1alpha1.SchemeGroupVersion.Group,
					Version: samplev1alpha1.SchemeGroupVersion.Version,
					Kind:    &amp;quot;Foo&amp;quot;,
				}),
			},
		},
		Spec: appsv1.DeploymentSpec{
			Replicas: foo.Spec.Replicas,
			Selector: &amp;amp;metav1.LabelSelector{
				MatchLabels: labels,
			},
			Template: corev1.PodTemplateSpec{
				ObjectMeta: metav1.ObjectMeta{
					Labels: labels,
				},
				Spec: corev1.PodSpec{
					Containers: []corev1.Container{
						{
							Name:  &amp;quot;nginx&amp;quot;,
							Image: &amp;quot;nginx:latest&amp;quot;,
						},
					},
				},
			},
		},
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;デプロイ&#34;&gt;デプロイ&lt;/h3&gt;

&lt;p&gt;ローカルで動かすこともできるが、せっかくなのでクラスタにデプロイする。環境はGKE。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Dockerfile
FROM golang:1.10 AS builder
ADD . /go/src/k8s.io/sample-controller
WORKDIR /go/src/k8s.io/sample-controller
RUN CGO_ENABLED=0 go build -o sample-controller .

FROM alpine
WORKDIR /
COPY --from=builder /go/src/k8s.io/sample-controller/sample-controller .
CMD [&amp;quot;/sample-controller&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t asia.gcr.io/*****/sample-controller .
$ gcloud auth configure-docker
$ docker push asia.gcr.io/*****/sample-controller
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RBACが有効になっている場合はAPIを呼ぶため必要なClusterRoleをControllerが動くPodに与える必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=&amp;lt;email&amp;gt;
$ cat role.yaml 
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: sample-controller
rules:
- apiGroups: [&amp;quot;apps&amp;quot;, &amp;quot;samplecontroller.k8s.io&amp;quot;]
  resources: [&amp;quot;*&amp;quot;]
  verbs: [&amp;quot;*&amp;quot;]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sample-controller
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: sample-controller
subjects:
- kind: ServiceAccount
  name: sample-controller
  namespace: default
roleRef:
  kind: ClusterRole
  name: sample-controller
  apiGroup: rbac.authorization.k8s.io

$ kubectl apply -f role.yaml 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初めClusterRoleではなくRoleにしたせいで以下のようなエラーが出て少し悩んだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;k8s.io/sample-controller/pkg/client/informers/externalversions/factory.go:117: Failed to list *v1alpha1.Foo: foos.samplecontroller.k8s.io is forbidden: User &amp;quot;system:serviceaccount:default:sample-controller&amp;quot; cannot list foos.samplecontroller.k8s.io at the cluster scope: Unknown user &amp;quot;system:serviceaccount:default:sample-controller&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作ったServiceAccountをDeploymentのPodSpecに含める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat deployment.yaml
kind: Deployment
metadata:
  name: sample-controller
spec:
  template:
    metadata:
      labels:
        app: sample-controller
    spec:
      serviceAccount: sample-controller
      containers:
      - name: sample-controller
        image: asia.gcr.io/*****/sample-controller

$ kubectl apply -f deployment.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;動作&#34;&gt;動作&lt;/h3&gt;

&lt;p&gt;FooのCRDを作成してcreateするとたしかにdeploymentが作成された。
また、deploymentを削除すると新しいdeploymentが作成され、Fooを削除するとdeploymentも削除されることが確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f artifacts/examples/crd.yaml
$ kubectl create -f artifacts/examples/example-foo.yaml
$ kubectl get foo
NAME          AGE
example-foo   2s

$ kubectl get deployment
NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
example-foo         1         1         1            1           5s
sample-controller   1         1         1            1           1h

$ kubectl delete deployment example-foo
deployment &amp;quot;example-foo&amp;quot; deleted

$ kubectl get deployment
NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
example-foo         1         1         1            1           1s
sample-controller   1         1         1            1           1h

$ kubectl delete foo example-foo
$ kubectl get deployment
No resources found.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/&#34;&gt;Kubernetes Deep Dive: Code Generation for CustomResources – OpenShift Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KubernetesのNetworkPolicy Resource</title>
          <link>https://www.sambaiz.net/article/181/</link>
          <pubDate>Mon, 30 Jul 2018 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/181/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;Network Policies - Kubernetes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PodのトラフィックをラベルやIPアドレスで許可するためのResource。AWSのセキュリティグループやGCPのファイアウォールルールのようなもの。
GKEでは今のところデフォルトでオフになっているので&lt;code&gt;--enable-network-policy&lt;/code&gt;を付けてクラスタを作成する必要がある。&lt;/p&gt;

&lt;p&gt;以前作成したmulti podのアプリケーションで挙動を確認する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/173/&#34;&gt;GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get service
NAME               TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)        AGE
clusterip-app      ClusterIP      10.23.247.54    &amp;lt;none&amp;gt;           80/TCP         48m
loadbalancer-app   LoadBalancer   10.23.244.137   35.224.130.196   80:31508/TCP   48m
nodeport-app       NodePort       10.23.246.215   &amp;lt;none&amp;gt;           80:32181/TCP   48m
...

$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作成するNetworkPolicyは以下の二つで、いずれも対象は&lt;code&gt;app: nodeport-app&lt;/code&gt;のラベルが付いたPod。
一つ目は対象Podへのリクエストを一旦全て拒否する。
二つ目は&lt;code&gt;nodeport-access: &amp;quot;true&amp;quot;&lt;/code&gt;のラベルが付いたPodから対象Podへの8080ポートのリクエストを許可するもの。
今回は設定しないがegressも設定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat networkPolicies.yaml 
---
# Default deny all ingress traffic
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
spec:
  podSelector:
    matchLabels:
      app: nodeport-app
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
spec:
  podSelector:
    matchLabels:
      app: nodeport-app
  ingress:
  - from:
    - podSelector:
        matchLabels:
          nodeport-access: &amp;quot;true&amp;quot;
    ports:
    - port: 8080

$ kubectl apply -f networkPolicies.yaml 
$ kubectl get networkpolicy
NAME                  POD-SELECTOR       AGE
default-deny          app=nodeport-app   5s
test-network-policy   app=nodeport-app   5s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作成後、ラベルが付いていないPodからアクセスできなくなり、ラベルを付けるとアクセスできるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
Get http://nodeport-app: dial tcp 10.23.246.215:80: i/o timeout

$ kubectl label pods loadbalancer-app-6bd554874-**** nodeport-access=true
$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fromにはipBlockやnamespaceSelectorも設定することもでき、複数指定した場合はいずれかの条件を満たすと通る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl delete pod loadbalancer-app-***
$  curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
Get http://nodeport-app: dial tcp 10.23.246.215:80: i/o timeout

$ kubectl label namespaces default aaa=bbb
$ cat networkPolicies.yaml 
...
- from:
    - podSelector:
        matchLabels:
          nodeport-access: &amp;quot;true&amp;quot;
    - namespaceSelector:
        matchLabels:
          aaa: bbb
...

$ kubectl apply -f networkPolicies.yaml 
$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://35.224.130.196/
200
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GCPのCloud Pub/Sub</title>
          <link>https://www.sambaiz.net/article/180/</link>
          <pubDate>Thu, 26 Jul 2018 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/180/</guid>
          <description>&lt;p&gt;スケーラビリティに優れるメッセージングミドルウェア。
データはPullするだけではなくhttpsのエンドポイントにPushすることもでき、Cloud Dataflowを通してBigQueryやCloud MLに繋げることもできる。GAEのTaskQueueのように遅延させる機能は今のところない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/178/&#34;&gt;GAEのTaskQueue - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/pubsub/pricing&#34;&gt;料金&lt;/a&gt;はPublish/Pull/Pushしたデータ容量による。1TB送ると$60くらい。&lt;/p&gt;

&lt;p&gt;Goの&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go&#34;&gt;クライアントライブラリ&lt;/a&gt;で動かしてみる。
まずTopicを作成して50件Publishした後、Subsriptionを作成して、再び50件Publishする。
Publishできるデータは&lt;a href=&#34;https://cloud.google.com/pubsub/docs/publisher#header_1&#34;&gt;10MB未満&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;topic, err := client.CreateTopic(ctx, topicName)
if err != nil {
  panic(err)
}

var wg sync.WaitGroup
for i := 0; i &amp;lt; 50; i++ {
  wg.Add(1)
  go func() {
    if _, err := topic.Publish(ctx, &amp;amp;pubsub.Message{Data: []byte(strconv.Itoa(i))}).Get(ctx); err != nil {
      log.Fatalf(&amp;quot;Publish error: %s&amp;quot;, err.Error())
    } else {
      log.Printf(&amp;quot;Publish successful: %d&amp;quot;, i)
    }
    wg.Done()
  }()
  wg.Wait()
}

log.Printf(&amp;quot;Create Subscription&amp;quot;)
sub := createSubscription(ctx, client, topic, subscriptionName)

for i := 50; i &amp;lt; 100; i++ {
  wg.Add(1)
  go func() {
    if _, err := topic.Publish(ctx, &amp;amp;pubsub.Message{Data: []byte(strconv.Itoa(i))}).Get(ctx); err != nil {
      log.Fatalf(&amp;quot;Publish error: %s&amp;quot;, err.Error())
    } else {
      log.Printf(&amp;quot;Publish successful: %d&amp;quot;, i)
    }
    wg.Done()
  }()
  wg.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2018/07/26 21:42:51 Publish successful: 47
2018/07/26 21:42:51 Publish successful: 48
2018/07/26 21:42:51 Publish successful: 49
2018/07/26 21:42:51 Create Subscription
2018/07/26 21:42:58 Publish successful: 50
2018/07/26 21:42:58 Publish successful: 51
2018/07/26 21:42:58 Publish successful: 52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pull時のHandlerとしてAckを呼ぶackHandlerと、Nackを呼ぶnackHandler、何もしないnothingHandlerを用意した。
AckするとPub/Subからメッセージが消え、Nackまたはタイムアウトするとリトライされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type GotData struct {
	sync.Mutex
	gotData []string
}

var g = GotData{}

func ackHandler(done func()) func(ctx context.Context, m *pubsub.Message) {
	return func(ctx context.Context, m *pubsub.Message) {
		g.Lock()
		g.gotData = append(g.gotData, string(m.Data))
		sort.Slice(g.gotData, func(i, j int) bool {
			return g.gotData[i] &amp;lt; g.gotData[j]
		})
		log.Printf(&amp;quot;ackHandler got message: %s %#v&amp;quot;, m.Data, g.gotData)
		if len(g.gotData) == 50 {
			done()
		}
		g.Unlock()
		m.Ack()
	}
}

func nackHandler(ctx context.Context, m *pubsub.Message) {
	log.Printf(&amp;quot;nackHandler got message: %s&amp;quot;, m.Data)
	m.Nack()
}

func nothingHandler(ctx context.Context, m *pubsub.Message) {
	log.Printf(&amp;quot;nothingHandler got message: %s&amp;quot;, m.Data)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一つのSubscriptionを複数のSubscriberで使うことでメッセージを分散処理することができる。
ただし同じstructを使うとエラーになるのでそれぞれ生成している。&lt;/p&gt;

&lt;p&gt;nothingHandlerではSubscriptionの&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go/blob/f4024bfe9905677af1b3705dc5299b82622933c7/pubsub/subscription.go#L210&#34;&gt;MaxExtension&lt;/a&gt;を&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go/blob/f4024bfe9905677af1b3705dc5299b82622933c7/pubsub/subscription.go#L240&#34;&gt;デフォルト&lt;/a&gt;の10分から10秒にすることでリトライを早めている。&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go/blob/f4024bfe9905677af1b3705dc5299b82622933c7/pubsub/subscription.go#L136&#34;&gt;AckDeadline&lt;/a&gt;というのもあるがPullの場合、結局MaxExtensionまで延長してしまうので意味がないようだ。&lt;/p&gt;

&lt;p&gt;ReceiveSettingsにはほかに&lt;a href=&#34;https://github.com/GoogleCloudPlatform/google-cloud-go/blob/f4024bfe9905677af1b3705dc5299b82622933c7/pubsub/subscription.go#L217&#34;&gt;MaxOutstandingMessages&lt;/a&gt;というのもあり、一度に処理されるメッセージの量を制限することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go func() {
  sub := client.Subscription(subscriptionName)
  if err := sub.Receive(ctx, ackHandler(cancel)); err != nil {
    panic(err)
  }
}()
go func() {
  sub := client.Subscription(subscriptionName)
  if err := sub.Receive(ctx, nackHandler); err != nil {
    panic(err)
  }
}()
go func() {
  sub := client.Subscription(subscriptionName)
  sub.ReceiveSettings.MaxExtension = time.Second * 10
  if err := sub.Receive(ctx, nothingHandler); err != nil {
		panic(err)
  }
}()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;nack/nothingHandlerによっていくつかリトライされた後、ackHandlerにSubscription作成後のメッセージが全て届いた。
データは&lt;a href=&#34;https://cloud.google.com/pubsub/faq#persistent&#34;&gt;7日間&lt;/a&gt;保持される。
メッセージの順序は&lt;a href=&#34;https://cloud.google.com/pubsub/docs/ordering&#34;&gt;保証されず&lt;/a&gt;、今回は1件ずつになっているが重複することがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2018/07/26 21:43:49 nothingHandler got message: 91
2018/07/26 21:44:28 nackHandler got message: 91
2018/07/26 21:44:30 ackHandler got message: 91 []string{&amp;quot;50&amp;quot;, &amp;quot;51&amp;quot;, &amp;quot;52&amp;quot;, &amp;quot;53&amp;quot;, &amp;quot;54&amp;quot;, &amp;quot;55&amp;quot;, &amp;quot;56&amp;quot;, &amp;quot;57&amp;quot;, &amp;quot;58&amp;quot;, &amp;quot;59&amp;quot;, &amp;quot;60&amp;quot;, &amp;quot;61&amp;quot;, &amp;quot;62&amp;quot;, &amp;quot;63&amp;quot;, &amp;quot;64&amp;quot;, &amp;quot;65&amp;quot;, &amp;quot;66&amp;quot;, &amp;quot;67&amp;quot;, &amp;quot;68&amp;quot;, &amp;quot;69&amp;quot;, &amp;quot;70&amp;quot;, &amp;quot;71&amp;quot;, &amp;quot;72&amp;quot;, &amp;quot;73&amp;quot;, &amp;quot;74&amp;quot;, &amp;quot;75&amp;quot;, &amp;quot;76&amp;quot;, &amp;quot;77&amp;quot;, &amp;quot;78&amp;quot;, &amp;quot;79&amp;quot;, &amp;quot;80&amp;quot;, &amp;quot;81&amp;quot;, &amp;quot;82&amp;quot;, &amp;quot;83&amp;quot;, &amp;quot;84&amp;quot;, &amp;quot;85&amp;quot;, &amp;quot;86&amp;quot;, &amp;quot;87&amp;quot;, &amp;quot;88&amp;quot;, &amp;quot;89&amp;quot;, &amp;quot;90&amp;quot;, &amp;quot;91&amp;quot;, &amp;quot;92&amp;quot;, &amp;quot;93&amp;quot;, &amp;quot;94&amp;quot;, &amp;quot;95&amp;quot;, &amp;quot;96&amp;quot;, &amp;quot;97&amp;quot;, &amp;quot;98&amp;quot;, &amp;quot;99&amp;quot;}
2018/07/26 21:44:30 Finished!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;スケールし、複数コンシューマーがそれぞれのタイミングでPullできるログの一時的な貯め先などとしてAWSのKinesis Data Streamsと同じようなユースケースで使われるが、Kinesisでは順序が保証されていたり、シャードの指定やデータの取り出し方といった扱いなど異なる点もある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/67/&#34;&gt;Kinesis Streams/Firehose/Analyticsを試す - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Destributed TensorFlowの流れとSavedModelの出力</title>
          <link>https://www.sambaiz.net/article/179/</link>
          <pubDate>Wed, 25 Jul 2018 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/179/</guid>
          <description>

&lt;h2 id=&#34;distributed-tensorflow-https-www-tensorflow-org-deploy-distributed&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/deploy/distributed&#34;&gt;Distributed TensorFlow&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;クラスタを組んでGraphを分散実行する。&lt;/p&gt;

&lt;p&gt;クラスタは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;master: sessionを作成し、workerを制御する&lt;/li&gt;
&lt;li&gt;worker: 計算を行う&lt;/li&gt;
&lt;li&gt;ps(parameter server): 変数の値を持ち、更新する&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のjobからなり、gRPCの&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/master_service.proto&#34;&gt;Master Service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/worker_service.proto&#34;&gt;Worker Service&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;でやり取りする。&lt;/p&gt;

&lt;h2 id=&#34;tensorflow-serverを立てる&#34;&gt;TensorFlow serverを立てる&lt;/h2&gt;

&lt;p&gt;各jobとURLのmapを&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/ClusterSpec&#34;&gt;ClusterSpec&lt;/a&gt;にして
jobとindexと併せて&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/ServerDef&#34;&gt;ServerDef&lt;/a&gt;を作って
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Server&#34;&gt;Server&lt;/a&gt;を立てる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;master&amp;quot;: [
        &amp;quot;check-tf-config-master-34z8-0:2222&amp;quot;
    ],
    &amp;quot;ps&amp;quot;: [
        &amp;quot;check-tf-config-ps-34z8-0:2222&amp;quot;,
        &amp;quot;check-tf-config-ps-34z8-1:2222&amp;quot;
    ],
    &amp;quot;worker&amp;quot;: [
        &amp;quot;check-tf-config-worker-34z8-0:2222&amp;quot;,
        &amp;quot;check-tf-config-worker-34z8-1:2222&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cluster_spec_object = tf.train.ClusterSpec(cluster_spec)
server_def = tf.train.ServerDef(
    cluster=cluster_spec_object.as_cluster_def(),
    protocol=&amp;quot;grpc&amp;quot;,
    job_name=job_name, # worker, master, ps 
    task_index=0)
server = tf.train.Server(server_def)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;psのjobでは&lt;code&gt;server.join()&lt;/code&gt;して待ち構える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if job_name == &amp;quot;ps&amp;quot;:
    server.join()
else:
    # build model
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;workerにgraphを割り当てる&#34;&gt;WorkerにGraphを割り当てる&lt;/h2&gt;

&lt;p&gt;workerの&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/device&#34;&gt;device&lt;/a&gt;にGraphを割り当てる。
deviceは&lt;code&gt;/job:worker/replica:0/task:0/device:GPU:0&lt;/code&gt;
のような&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/device.py#L130&#34;&gt;フォーマット&lt;/a&gt;で表される。&lt;/p&gt;

&lt;p&gt;Graphの持ち方には一つのGraphの異なる計算箇所をそれぞれのworkerが持つIn-graph replicationと、
それぞれGraphを持つBetween-graph replicationがある。これは後者の例で、&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/replica_device_setter&#34;&gt;replica_device_setter&lt;/a&gt;によってラウンドロビンで各psに変数を配置する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.device(tf.train.replica_device_setter(
    cluster=cluster_spec,
    worker_device=device
)):
    # graph
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;syncreplicasoptimizerのhookを追加&#34;&gt;SyncReplicasOptimizerのhookを追加&lt;/h2&gt;

&lt;p&gt;同期して変数を更新する場合、&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer&#34;&gt;SyncReplicasOptimizer&lt;/a&gt;を使い、make_session_run_hookで作られるhookをMonitoredTrainingSessionに渡す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/175/&#34;&gt;TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;train_op = tf.train.SyncReplicasOptimizer(
    tf.train.AdamOptimizer(self.learning_rate),
    replicas_to_aggregate=self.worker_num,
    total_num_replicas=self.worker_num)

hooks = [
    tf.train.StopAtStepHook(last_step=args.last_step),
    tf.train.CheckpointSaverHook(
        &#39;./ckpt&#39;,
        save_steps=args.save_steps,
        saver=saver),
    train_op.make_session_run_hook(self.is_chief)
]
with tf.train.MonitoredTrainingSession(
    is_chief=is_chief,
    master=master,
    hooks=hooks
) as sess:
    while not sess.should_stop():
    # sess.run()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;savedmodelの出力&#34;&gt;SavedModelの出力&lt;/h2&gt;

&lt;p&gt;実行後、SavedModelを出力する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/172/&#34;&gt;TensorFlowのモデルをsave/loadする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MonitoredTrainingSessionのsessは&lt;code&gt;should_stop()&lt;/code&gt;がtrueになったあとは使えなくなるため、
新しいsessionを作るかhookのendでする必要がある。&lt;/p&gt;

&lt;p&gt;新しいsessionでする例。そのままrestoreするとすでにworkerが終了している場合に、そのdeviceの変数もrestoreしようとして失敗するので
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/import_meta_graph&#34;&gt;import_meta_graph&lt;/a&gt;のclear_devicesをTrueにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
    with tf.Session() as sess:
        ckpt = tf.train.get_checkpoint_state(&amp;quot;ckpt&amp;quot;)
        saver = tf.train.import_meta_graph(
            &#39;{}.meta&#39;.format(ckpt.model_checkpoint_path),
            clear_devices=True)
        saver.restore(sess, ckpt.model_checkpoint_path)
        save.save(sess, &amp;quot;saved&amp;quot;, signature_def_map)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;hookでする例。restoreする必要がなくて良い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class SavedModelBuilderHook(session_run_hook.SessionRunHook):
    def __init__(self, export_dir, signature_def_map, tags):
        self.export_dir = export_dir
        self.signature_def_map = signature_def_map
        self.tags = tags

    def end(self, session):
        session.graph._unsafe_unfinalize()
        builder = tf.saved_model.builder.SavedModelBuilder(self.export_dir)
        builder.add_meta_graph_and_variables(
            session,
            self.tags,
            signature_def_map=self.signature_def_map
        )
        builder.save()
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GAEのTaskQueue</title>
          <link>https://www.sambaiz.net/article/178/</link>
          <pubDate>Sun, 15 Jul 2018 16:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/178/</guid>
          <description>

&lt;p&gt;GCPのマネージドなQueueサービスとしてGAEのTaskQueueがあることを教えてもらったので動かしてみる。
PushQueueとPullQueueがあって、それぞれおおよそAWSのSNSとSQSに相当する。PushQueueの場合はHTTPのリクエストとしてGAEのサービスに投げられる。PullQueueは&lt;a href=&#34;https://cloud.google.com/appengine/docs/standard/python/taskqueue/rest/&#34;&gt;Cloud Tasks API&lt;/a&gt;を使えばGAE外からも使えるらしいがまだalpha。&lt;/p&gt;

&lt;p&gt;設定ファイル&lt;a href=&#34;https://cloud.google.com/appengine/docs/standard/go/config/queueref&#34;&gt;queue.yaml&lt;/a&gt;はこんな感じ。bucket_sizeは最大同時実行数で空いていたらrateで埋められていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;queue:
- name: default
  rate: 10/m
  bucket_size: 5
  retry_parameters:
    min_backoff_seconds: 10
    max_backoff_seconds: 300
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bucket_sizeの最大は500なのでこれ以上の性能が必要な場合は複数のQueueに分けるか
&lt;a href=&#34;https://cloud.google.com/pubsub/&#34;&gt;Cloud Pub/Sub&lt;/a&gt;を使うことになる。ただし、&lt;a href=&#34;https://cloud.google.com/pubsub/faq?hl=ja#duplicates&#34;&gt;At-Least-Once&lt;/a&gt;なのでレコードが重複しても問題ないように作る必要がある。SQSも&lt;a href=&#34;https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html#standard-queues-at-least-once-delivery&#34;&gt;同じ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/180/&#34;&gt;GCPのCloud Pub/Sub - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;アプリケーション&#34;&gt;アプリケーション&lt;/h2&gt;

&lt;p&gt;/にアクセスすると2つのTaskをdefaultのTaskQueueにDelay25秒でPOSTする。
Taskによるリクエストは/workerで受け、30%の確率で500エラーを返すようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;math/rand&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;net/url&amp;quot;
	&amp;quot;strconv&amp;quot;
	&amp;quot;time&amp;quot;

	&amp;quot;google.golang.org/appengine&amp;quot;
	&amp;quot;google.golang.org/appengine/log&amp;quot;
	&amp;quot;google.golang.org/appengine/taskqueue&amp;quot;
)

func main() {
	http.HandleFunc(&amp;quot;/&amp;quot;, handler)
	http.HandleFunc(&amp;quot;/worker&amp;quot;, handlerQueue)
	appengine.Main()
}

func handler(w http.ResponseWriter, r *http.Request) {
	ctx := appengine.NewContext(r)
	// POST body: name=a%26&amp;amp;value=20
	t := taskqueue.NewPOSTTask(&amp;quot;/worker&amp;quot;, map[string][]string{&amp;quot;name&amp;quot;: {&amp;quot;a&amp;amp;&amp;quot;}, &amp;quot;time&amp;quot;: {strconv.FormatInt(time.Now().UnixNano(), 10)}})
	t.Delay = time.Second * 25
	// POST body: name=a&amp;amp;name=b
	t2 := taskqueue.NewPOSTTask(&amp;quot;/worker&amp;quot;, map[string][]string{&amp;quot;name&amp;quot;: {&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;}})
	if _, err := taskqueue.AddMulti(ctx, []*taskqueue.Task{t, t2}, &amp;quot;&amp;quot;); err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	fmt.Fprintln(w, &amp;quot;ok&amp;quot;)
}

func handlerQueue(w http.ResponseWriter, r *http.Request) {
	ctx := appengine.NewContext(r)

	bodyb, err := ioutil.ReadAll(r.Body)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	body := string(bodyb)
	log.Infof(ctx, &amp;quot;%s\n&amp;quot;, body)

	values, err := url.ParseQuery(body)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	log.Infof(ctx, &amp;quot;%#+v\n&amp;quot;, values)
	if rand.Float64() &amp;lt; 0.3 {
		http.Error(w, &amp;quot;random fail&amp;quot;, http.StatusInternalServerError)
		return
	}
	fmt.Fprintln(w, &amp;quot;ok&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デプロイして何度かアクセスする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud app deploy queue.yaml
$ gcloud app deploy
$ gcloud app browse
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TaskがQueueに入り、エラーの場合はリトライしていることが確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/178.png&#34; alt=&#34;PushQueue&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通常Delay経ってETA(Estimate Time of Arrival?)を迎えたものから処理されていくが、bucketやrateが小さい場合リトライが重なって渋滞すると過ぎても処理されず溜まってしまうことがある。リトライ時のDelayはmax_backoff_secondsまでの範囲内でExponential Backoffし、task_retry_limitを指定しないと永遠にリトライし続ける。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/furuyamayuuki/gcp-72165187&#34;&gt;スケーラブル GCP アーキテクチャ&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>WebSocketでの通信内容をWiresharkで見る</title>
          <link>https://www.sambaiz.net/article/177/</link>
          <pubDate>Tue, 10 Jul 2018 23:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/177/</guid>
          <description>

&lt;p&gt;Webで双方向通信するためのプロトコル、WebSocketでの通信内容をWiresharkで見る。&lt;/p&gt;

&lt;h2 id=&#34;アプリケーション&#34;&gt;アプリケーション&lt;/h2&gt;

&lt;h3 id=&#34;サーバー&#34;&gt;サーバー&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io&amp;quot;
	&amp;quot;net/http&amp;quot;

	&amp;quot;golang.org/x/net/websocket&amp;quot;
)

type Payload struct {
	A string
}

func Handler(ws *websocket.Conn) {
	ctx, cancel := context.WithCancel(context.Background())
	go func() {
		var payload Payload
		for {
			err := websocket.JSON.Receive(ws, &amp;amp;payload)
			if err != nil {
				if err == io.EOF {
					fmt.Println(&amp;quot;connection closed&amp;quot;)
				} else {
					fmt.Println(err)
				}
				cancel()
				break
			}
			fmt.Println(payload.A)
		}
	}()
	websocket.JSON.Send(ws, Payload{A: &amp;quot;a&amp;quot;})
	select {
	case &amp;lt;-ctx.Done():
	}
}

func main() {
	http.Handle(&amp;quot;/&amp;quot;, websocket.Handler(Handler))
	http.ListenAndServe(&amp;quot;:12345&amp;quot;, nil)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;クライアント&#34;&gt;クライアント&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
const websocket = new WebSocket(&amp;quot;ws://localhost:12345&amp;quot;);
console.log(websocket)
websocket.onopen = (e) =&amp;gt; { 
    setInterval(() =&amp;gt; {
        console.log(&amp;quot;send&amp;quot;)
        websocket.send(JSON.stringify({A: &amp;quot;あ&amp;quot;.repeat(50)}));
    }, 10000)
};
websocket.onmessage = (e) =&amp;gt; { 
    console.log(`received ${e.data}`);
};
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wireshark-https-www-wireshark-org-のインストール&#34;&gt;&lt;a href=&#34;https://www.wireshark.org/&#34;&gt;Wireshark&lt;/a&gt;のインストール&lt;/h2&gt;

&lt;p&gt;GUIが立ち上がるので&lt;code&gt;tcp.port == 12345&lt;/code&gt;のフィルタで待ち構える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install wireshark --with-qt
$ sudo wireshark
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;通信内容&#34;&gt;通信内容&lt;/h2&gt;

&lt;h3 id=&#34;websocketで通信するまで&#34;&gt;WebSocketで通信するまで&lt;/h3&gt;

&lt;p&gt;まず通常のHTTP通信と同様に3-way handshakeでTCPのコネクションを張った後、
&lt;code&gt;Upgrade: WebSocket&lt;/code&gt;と&lt;code&gt;Connection: Upgrade&lt;/code&gt;を付けたリクエストをサーバーに送ってWebSocketでの通信を要求する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Hypertext Transfer Protocol
    GET / HTTP/1.1\r\n
    Host: localhost:12345\r\n
    Connection: Upgrade\r\n
    Pragma: no-cache\r\n
    Cache-Control: no-cache\r\n
    Upgrade: websocket\r\n
    Sec-WebSocket-Version: 13\r\n
    Sec-WebSocket-Key: vuQHXJAxDEdD9pQ3d7RtOw==\r\n
    Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits\r\n    
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それに対してサーバーはステータスコード101でレスポンスを返す。
送られてきたランダムな&lt;code&gt;Sec-WebSocket-Key&lt;/code&gt;をもとに生成した&lt;code&gt;Sec-WebSocket-Accept&lt;/code&gt;
をヘッダーに付けて、クライアントはこれを見て正しいWebSocketサーバーであることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Hypertext Transfer Protocol
    HTTP/1.1 101 Switching Protocols\r\n
    Upgrade: websocket\r\n
    Connection: Upgrade\r\n
    Sec-WebSocket-Accept: oImbSbalm6WMVbXV5oqmRlHHhWg=\r\n
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;websocketでの通信&#34;&gt;WebSocketでの通信&lt;/h3&gt;

&lt;p&gt;サーバーからクライアントへのデータ。
HTTP/1.1のヘッダーはテキストで記述も多いためデータ量が大きく、毎回それらを送る必要があり効率的ではなかったが、WebSocketではこの場合Payloadを除いた部分が2bytesしかない。&lt;/p&gt;

&lt;p&gt;ちなみにHTTP/2では差分を送るHPACKというフォーマットで圧縮した、バイナリのHEADERSフレームにすることで、この問題を改善している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WebSocket
    1... .... = Fin: True
    .000 .... = Reserved: 0x0
    .... 0001 = Opcode: Text (1)
    0... .... = Mask: False
    .000 1001 = Payload length: 9
    Payload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クライアントからサーバーへのデータ。Payload lengthが125を超えたため拡張されている。
それ以外にMasked payloadが含まれるのでデータ量が少し大きくなっている。これは不正なスクリプトがHTTPリクエストに偽装したデータを送ることでプロキシのキャッシュが汚染されるのを防ぐため。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WebSocket
    1... .... = Fin: True
    .000 .... = Reserved: 0x0
    .... 0001 = Opcode: Text (1)
    1... .... = Mask: True
    .111 1110 = Payload length: 126 Extended Payload Length (16 bits)
    Extended Payload length (16 bits): 158
    Masking-Key: ef17e997
    Masked payload
    Payload
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://plus.google.com/u/0/+TakeshiYoshino/posts/af6Fg972tGQ&#34;&gt;The WebSocket Protocol (RFC 6455) の歴史&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DOMの(next/previous)SiblingとElementSiblingの値</title>
          <link>https://www.sambaiz.net/article/176/</link>
          <pubDate>Wed, 04 Jul 2018 23:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/176/</guid>
          <description>

&lt;p&gt;Siblingは兄弟姉妹という意味&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
&amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt;
&amp;lt;li id=&amp;quot;li2&amp;quot;&amp;gt;2&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;3&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;

&amp;lt;script&amp;gt;
const el = document.querySelector(&amp;quot;li#li2&amp;quot;);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sibling&#34;&gt;Sibling&lt;/h2&gt;

&lt;p&gt;elのpreviousSiblingを取ると&lt;code&gt;&amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt;&lt;/code&gt;になると思いきや、その直前の空白や改行を含むtext nodeが返る。
それらが全くない場合隣のElementが返ることになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const el2 = el.previousSibling;
console.log(`previousSibling: ${el2.nodeName} &amp;quot;${el2.textContent}&amp;quot;`);
/*
#text &amp;quot;
&amp;quot;
*/

const el4 = el.nextSibling;
console.log(`nextSibling: ${el4.nodeName} &amp;quot;${el4.textContent}&amp;quot;`); // LI &amp;quot;3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;elementsibling&#34;&gt;ElementSibling&lt;/h2&gt;

&lt;p&gt;多くの場合で意図した結果が返るのはこっち。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const el3 = el.previousElementSibling;
console.log(`previousElementSibling: ${el3.nodeName} &amp;quot;${el3.textContent}&amp;quot;`); // LI &amp;quot;1&amp;quot;

const el5 = el.nextElementSibling;
console.log(`nextElementSibling: ${el5.nodeName} &amp;quot;${el5.textContent}&amp;quot;`); // LI &amp;quot;3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;firstChildとfirstElementChildなどの関係も同じ。存在を忘れていてひっかかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const el6 = document.querySelector(&amp;quot;ul&amp;quot;).firstChild;
console.log(`firstChild: ${el6.nodeName} &amp;quot;${el6.textContent}&amp;quot;`);
/*
fistChild: #text &amp;quot;
&amp;quot;
*/
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー</title>
          <link>https://www.sambaiz.net/article/175/</link>
          <pubDate>Sun, 01 Jul 2018 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/175/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/MonitoredSession&#34;&gt;MonitoredSession&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;deprecatedになった&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Supervisor&#34;&gt;Supervisor&lt;/a&gt;の後継。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/MonitoredTrainingSession&#34;&gt;MonitoredTrainingSession&lt;/a&gt;で学習用のMonitoredSessionを生成する。
このコンストラクタの引数でcheckpoint_dirを渡すと内部で&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/CheckpointSaverHook&#34;&gt;CheckpointSaverHook&lt;/a&gt;が
&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/monitored_session.py#L396&#34;&gt;追加される&lt;/a&gt;ようになっていて、restoreしたり指定したタイミングでsaveしたりしてくれる。&lt;/p&gt;

&lt;p&gt;なので今回明示的に渡すhooksは
指定したstepに到達したら&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/basic_session_run_hooks.py#L320&#34;&gt;止めてくれる&lt;/a&gt;、&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/StopAtStepHook&#34;&gt;StopAtStepHook&lt;/a&gt;のみ。&lt;/p&gt;

&lt;p&gt;should_stop()がTrueな状態で&lt;code&gt;session.run()&lt;/code&gt;しようとすると&lt;code&gt;Run called even after should_stop requested.&lt;/code&gt;のエラーが出るため、
今回は新しいsessionを作ってAccuracyを返しているが、hookでやった方がrestoreする必要がないので良さそうだ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/179/&#34;&gt;Destributed TensorFlowの流れとSavedModelの出力 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;全体のコードは&lt;a href=&#34;https://gist.github.com/sambaiz/72888520379cff778d6261cd417a3773&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def train(self, learning_rate, variable_default_stddev, bias_default, last_step=800):
  test_images = self.images[:500]
  test_labels = self.labels[:500]
  train_batch = Batch(self.images[500:], self.labels[500:])

  with tf.Graph().as_default():
    global_step=tf.train.get_or_create_global_step()
    g = MNIST_CNN(learning_rate,  variable_default_stddev, bias_default).graph()
    saver = tf.train.Saver()
    savedir = &#39;./ckpt-{}-{}-{}&#39;.format(learning_rate, variable_default_stddev, bias_default)
    hooks = [
      tf.train.StopAtStepHook(last_step=last_step)
    ]
    with tf.train.MonitoredTrainingSession(
      hooks=hooks,
      checkpoint_dir=savedir,
      save_checkpoint_secs = 300,
    ) as sess:
      sess.run(global_step)
      while not sess.should_stop():
        # step = sess.run(global_step)
        images, labels = train_batch.get_next(500)
        sess.run(g[&amp;quot;op&amp;quot;][&amp;quot;train_step&amp;quot;], feed_dict={
          g[&amp;quot;placeholder&amp;quot;][&amp;quot;x&amp;quot;]: list(images), 
          g[&amp;quot;placeholder&amp;quot;][&amp;quot;y&amp;quot;]: list(labels),
        })
    with tf.Session() as sess:
      self._restore(sess, saver, savedir)
      return sess.run(g[&amp;quot;op&amp;quot;][&amp;quot;accuracy&amp;quot;], feed_dict={
        g[&amp;quot;placeholder&amp;quot;][&amp;quot;x&amp;quot;]: list(test_images), 
        g[&amp;quot;placeholder&amp;quot;][&amp;quot;y&amp;quot;]: list(test_labels)
      }), savedir
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;hooksに渡す&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/session_run_hook.py#L103&#34;&gt;SessionRunHook&lt;/a&gt;は以下のメソッドからなる。
&lt;code&gt;before_run()&lt;/code&gt;で返すSessionRunArgsのfeed_dictはrunで渡すfeed_dictとmergeされ、
fetchesはrunするたびに毎回評価される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class MySessionRunHook:
  def __init__(self, feed_dict):
    self.feed_dict = feed_dict
    self.a = tf.placeholder(tf.float32, name=&amp;quot;a&amp;quot;)
      
  def begin(self):
    &amp;quot;&amp;quot;&amp;quot;Called once before using the session.&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;begin&amp;quot;)

  def after_create_session(self, session, coord):
    &amp;quot;&amp;quot;&amp;quot;Called when new TensorFlow session is created.&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;after_create_session&amp;quot;)
      
  def before_run(self, run_context):
    &amp;quot;&amp;quot;&amp;quot;Called before each call to run().&amp;quot;&amp;quot;&amp;quot;
    return SessionRunArgs(fetches={&amp;quot;a&amp;quot;: self.a}, feed_dict=self.feed_dict)
  
  def after_run(self, run_context, run_values):
    &amp;quot;&amp;quot;&amp;quot;Called after each call to run().&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;after_run {} {}&amp;quot;.format(run_values.results[&amp;quot;a&amp;quot;], run_context.session.run(self.a, feed_dict={self.a: 10})))

  def end(self, session):
    &amp;quot;&amp;quot;&amp;quot;Called at the end of session.&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;end&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したがって、hooks内のfetchesにfeedする必要があるものが含まれる場合、
runする対象がfeedする必要がない場合でも&lt;code&gt;You must feed a value for placeholder tensor&lt;/code&gt;のエラーが出ることになる。
また、hooks内とrunの引数のfeed_dictが衝突した場合もエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
  global_step = tf.train.get_or_create_global_step()
  x = tf.placeholder(tf.float32, name=&amp;quot;x&amp;quot;)
  y = tf.placeholder(tf.float32, name=&amp;quot;y&amp;quot;)
  z = x + y
  hook1 = MySessionRunHook({x: 2})
  hook2 = MySessionRunHook({y: 3})
  hooks=[hook1, hook2]
  with tf.train.MonitoredTrainingSession(hooks=hooks) as sess:
    try:
      print(sess.run(global_step))
    except tf.errors.InvalidArgumentError as err:
      print(err) # You must feed a value for placeholder tensor &#39;a_1&#39; with dtype float ...
    print(sess.run([global_step, z], feed_dict={hook1.a: 2, hook2.a: 3})) # [0, 5.0]
    try:
      print(sess.run(y, feed_dict={x: 10}))
    except RuntimeError as err:
      print(err) # Same tensor is fed by a SessionRunHook and user. Conflict(s): [&amp;lt;tf.Tensor &#39;x:0&#39; shape=&amp;lt;unknown&amp;gt; dtype=float32&amp;gt;]     
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上で書いたようにMonitoredTrainingSessionは内部でCheckpointSaverHookを持っていて、
これがfetchesでsummaryを&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/basic_session_run_hooks.py#L689&#34;&gt;返している&lt;/a&gt;ので、一つでもsummaryを入れるとrunするときにそれに必要なfeed_dictを渡さないとエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
  global_step = tf.train.get_or_create_global_step()
  x = tf.placeholder(tf.float32, name=&amp;quot;x&amp;quot;)
  y = tf.placeholder(tf.float32, name=&amp;quot;y&amp;quot;)
  z = x + y
  tf.summary.scalar(&amp;quot;z&amp;quot;, z)
  with tf.train.MonitoredTrainingSession(checkpoint_dir=&amp;quot;./aaa&amp;quot;, save_summaries_steps=1) as sess:
    # ng
    # sess.run(global_step) =&amp;gt; You must feed a value for placeholder tensor &#39;y&#39; with dtype float
    # sess.run(z, feed_dict={x: 10, y:20})
    step, zz = sess.run([global_step, z], feed_dict={x: 10, y:20}) # ok
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GoのgRPC ServerのInterceptor(recovery/auth/zap/prometheus)</title>
          <link>https://www.sambaiz.net/article/174/</link>
          <pubDate>Tue, 26 Jun 2018 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/174/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/grpc/grpc-go&#34;&gt;grpc-go&lt;/a&gt;はInterceptor(Middleware)でhandlerの前後で処理を行うことができる。
UnaryとStreamで&lt;a href=&#34;https://github.com/grpc/grpc-go/blob/master/interceptor.go#L60&#34;&gt;シグネチャ&lt;/a&gt;が異なる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type UnaryServerInterceptor func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (resp interface{}, err error)
type StreamServerInterceptor func(srv interface{}, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func UnaryServerInterceptor(opts ...Option) grpc.UnaryServerInterceptor {
    return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) {
        resp, err := handler(newCtx, req)
        fmt.Println(resp)
        return resp, err
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回は良く使う&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware&#34;&gt;go-grpc-middleware&lt;/a&gt;の&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/tree/master/recovery&#34;&gt;recovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/tree/master/auth&#34;&gt;auth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/tree/master/logging/zap&#34;&gt;zap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-prometheus&#34;&gt;prometehus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Interceptorの挙動を確認する。&lt;/p&gt;

&lt;h2 id=&#34;proto&#34;&gt;proto&lt;/h2&gt;

&lt;p&gt;UnaryなRPCとBidirectional streaming(client, server共にstream)なRPCを一つずつ用意する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat protos/sample/service.proto
syntax = &amp;quot;proto3&amp;quot;;

package sample;

message SampleRequest {
  string sampleInput = 1;
}

message SampleResponse {
  string sampleOutput = 1;
}

service SampleService {
  rpc SampleUnary (SampleRequest) returns (SampleResponse) {}
  rpc SampleStream (stream SampleRequest) returns (stream SampleResponse) {}
}

$ go get -u github.com/golang/protobuf/protoc-gen-go
$ mkdir go
$ protoc --go_out=plugins=grpc:./go --proto_path=./protos protos/*/*.proto
$ ls go/sample
service.pb.go
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;service&#34;&gt;Service&lt;/h2&gt;

&lt;p&gt;Unaryの方でcontextからユーザー名を取り出しているのと、
Streamの方では&amp;rdquo;panic&amp;rdquo;という入力が来たときにpanicになるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type sampleService struct{}

type ctxKey string

var ctxKeyUserName = &amp;quot;userNames&amp;quot;

func (s *sampleService) SampleUnary(ctx context.Context, in *sample.SampleRequest) (*sample.SampleResponse, error) {
	return &amp;amp;sample.SampleResponse{SampleOutput: ctx.Value(ctxKeyUserName).(string)}, nil
}

func (s *sampleService) SampleStream(stream sample.SampleService_SampleStreamServer) error {
	for {
		in, err := stream.Recv()
		if err == io.EOF {
			return nil
		}
		if err != nil {
			return err
		}
		if in.SampleInput == &amp;quot;panic&amp;quot; {
			panic(&amp;quot;received panic&amp;quot;)
		}
		inputRunes := []rune(in.SampleInput)
		for i := 0; i &amp;lt; len(inputRunes); i++ {
			if err := stream.Send(&amp;amp;sample.SampleResponse{
				SampleOutput: string(inputRunes[i]),
			}); err != nil {
				return err
			}
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;server&#34;&gt;Server&lt;/h2&gt;

&lt;p&gt;NewServerでUnary/StreamそれぞれのInterceptorを登録する。
prometheusはさらに&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-prometheus/blob/v1.2.0/server_metrics.go#L63&#34;&gt;EnableHandlingTimeHistogram()&lt;/a&gt;してRegisterしている。&lt;/p&gt;

&lt;p&gt;zapには&lt;a href=&#34;https://github.com/uber-go/zap/blob/v1.8.0/logger.go#L93&#34;&gt;NewProduction()&lt;/a&gt;のloggerをそのまま渡しているのでログはstderrに&lt;a href=&#34;https://github.com/uber-go/zap/blob/7307fae54f855761db01409a36e87fe18ebd8ef4/config.go#L124&#34;&gt;出力される&lt;/a&gt;。
これを&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/blob/91d9dda9fdb0440370fd55356f216a6293cbeb95/logging/zap/grpclogger.go#L15&#34;&gt;ReplaceGrpcLogger()&lt;/a&gt;でも渡しているのでgRPCライブラリ内部のエラーも出る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/104/&#34;&gt;Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io&amp;quot;
	&amp;quot;math&amp;quot;
	&amp;quot;net&amp;quot;
	&amp;quot;net/http&amp;quot;

	&amp;quot;github.com/grpc-ecosystem/go-grpc-middleware&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/go-grpc-middleware/auth&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/go-grpc-middleware/logging/zap&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/go-grpc-middleware/recovery&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/go-grpc-prometheus&amp;quot;
	&amp;quot;github.com/sambaiz/grpc-interceptors/go/sample&amp;quot;
	&amp;quot;github.com/prometheus/client_golang/prometheus/promhttp&amp;quot;
	&amp;quot;go.uber.org/zap&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/codes&amp;quot;
)

func main() {
	zapLogger, err := zap.NewProduction()
	if err != nil {
		panic(err)
	}
	grpc_zap.ReplaceGrpcLogger(zapLogger)
	grpcServer := grpc.NewServer(
		grpc.StreamInterceptor(grpc_middleware.ChainStreamServer(
			grpc_recovery.StreamServerInterceptor(),
			grpc_zap.StreamServerInterceptor(zapLogger),
			grpc_auth.StreamServerInterceptor(auth),
			grpc_prometheus.StreamServerInterceptor,
		)),
		grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer(
			grpc_recovery.UnaryServerInterceptor(),
			grpc_zap.UnaryServerInterceptor(zapLogger),
			grpc_auth.UnaryServerInterceptor(auth),
			grpc_prometheus.UnaryServerInterceptor,
		)),
		grpc.MaxRecvMsgSize(math.MaxInt32))

	grpc_prometheus.EnableHandlingTimeHistogram()
	grpc_prometheus.Register(grpcServer)
	http.Handle(&amp;quot;/metrics&amp;quot;, promhttp.Handler())
	go func() {
		if err := http.ListenAndServe(&amp;quot;:8081&amp;quot;, nil); err != nil {
			panic(err)
		}
	}()

	sample.RegisterSampleServiceServer(grpcServer, &amp;amp;sampleService{})

	port := 8080
	listener, err := net.Listen(&amp;quot;tcp&amp;quot;, fmt.Sprintf(&amp;quot;:%d&amp;quot;, port))
	if err != nil {
		return
	}
	fmt.Printf(&amp;quot;GRPC server started on :%d\n&amp;quot;, port)
	grpcServer.Serve(listener)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;authに渡している関数では&lt;a href=&#34;https://github.com/grpc-ecosystem/go-grpc-middleware/blob/v1.0.0/auth/metadata.go#L24&#34;&gt;AuthFromMD()&lt;/a&gt;でmetadataのauthorizationのトークンを取得しユーザー名に変換してcontextに入れている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func auth(ctx context.Context) (context.Context, error) {
	token, err := grpc_auth.AuthFromMD(ctx, &amp;quot;basic&amp;quot;)
	if err != nil {
		return nil, err
	}
	users := map[string]string{
		&amp;quot;aaaaaa&amp;quot;: &amp;quot;sam&amp;quot;,
	}
	userName, ok := users[token]
	if !ok {
		return nil, grpc.Errorf(codes.Unauthenticated, &amp;quot;invalid auth token&amp;quot;)
	}
	newCtx := context.WithValue(ctx, ctxKeyUserName, userName)
	return newCtx, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;client&#34;&gt;Client&lt;/h2&gt;

&lt;p&gt;UnaryとStreamのRPCにそれぞれリクエストを送る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/grpc/grpc-go/blob/v1.13.0/clientconn.go#L325&#34;&gt;WithPerRPCCredentials()&lt;/a&gt;で各RPCでauthorizationがmetadataとして渡るようにしている。
&lt;a href=&#34;https://github.com/grpc/grpc-go/blob/v1.13.0/metadata/metadata.go#L155&#34;&gt;AppendToOutgoingContext&lt;/a&gt;で都度含めることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ctx = metadata.AppendToOutgoingContext(ctx, key, value)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;メトリクスは出していないがprometheusのClientのInterceptorを付けている。
このようにIntercpetorによってはClient用のものも用意されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;fmt&amp;quot;

	&amp;quot;github.com/grpc-ecosystem/go-grpc-prometheus&amp;quot;
	&amp;quot;github.com/sambaiz/grpc-interceptors/go/sample&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
)

type cred struct{}

func (c *cred) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) {
	return map[string]string{
		&amp;quot;authorization&amp;quot;: &amp;quot;basic aaaaaa&amp;quot;,
	}, nil
}

func (c *cred) RequireTransportSecurity() bool {
	return false
}

func main() {
	conn, err := grpc.Dial(
		&amp;quot;localhost:8080&amp;quot;,
		grpc.WithInsecure(),
		grpc.WithPerRPCCredentials(&amp;amp;cred{}),
		grpc.WithUnaryInterceptor(grpc_prometheus.UnaryClientInterceptor),
		grpc.WithStreamInterceptor(grpc_prometheus.StreamClientInterceptor),
	)
	if err != nil {
		panic(err)
	}
	client := sample.NewSampleServiceClient(conn)

	fmt.Println(&amp;quot;- Unary -&amp;quot;)
	unaryResult, err := client.SampleUnary(context.Background(), &amp;amp;sample.SampleRequest{
		SampleInput: &amp;quot;hello&amp;quot;,
	})
	if err != nil {
		panic(err)
	}
	fmt.Println(unaryResult.SampleOutput)
	streamClient, err := client.SampleStream(context.Background())
	if err != nil {
		panic(err)
	}
	defer streamClient.CloseSend()

	fmt.Println(&amp;quot;- Stream -&amp;quot;)
	if err := streamClient.Send(&amp;amp;sample.SampleRequest{
		SampleInput: &amp;quot;he&amp;quot;,
	}); err != nil {
		panic(err)
	}
	if err := streamClient.Send(&amp;amp;sample.SampleRequest{
		SampleInput: &amp;quot;llo&amp;quot;,
	}); err != nil {
		panic(err)
	}
	if err := streamClient.Send(&amp;amp;sample.SampleRequest{
		SampleInput: &amp;quot;panic&amp;quot;,
	}); err != nil {
		panic(err)
	}
	for {
		response, err := streamClient.Recv()
		if err != nil {
			fmt.Println(err)
			break
		} else {
			fmt.Println(response.SampleOutput)
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行結果&#34;&gt;実行結果&lt;/h2&gt;

&lt;p&gt;authによってユーザー名がcontextに入っている。
recoveryがrecoverしているのでpanicしてもサーバーは落ちていない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go run client.go
- Unary -
sam
- Stream -
h
e
l
l
o
rpc error: code = Internal desc = received panic

$ go run main.go
- Unary -
sam
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;zapでログが出ている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GRPC server started on :8080
{&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1530020624.963142,&amp;quot;caller&amp;quot;:&amp;quot;zap/server_interceptors.go:40&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;finished unary call with code OK&amp;quot;,&amp;quot;grpc.start_time&amp;quot;:&amp;quot;2018-06-26T22:43:44+09:00&amp;quot;,&amp;quot;system&amp;quot;:&amp;quot;grpc&amp;quot;,&amp;quot;span.kind&amp;quot;:&amp;quot;server&amp;quot;,&amp;quot;grpc.service&amp;quot;:&amp;quot;sample.SampleService&amp;quot;,&amp;quot;grpc.method&amp;quot;:&amp;quot;SampleUnary&amp;quot;,&amp;quot;grpc.code&amp;quot;:&amp;quot;OK&amp;quot;,&amp;quot;grpc.time_ms&amp;quot;:0.27799999713897705}
{&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1530020624.9652505,&amp;quot;caller&amp;quot;:&amp;quot;zap/grpclogger.go:41&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;transport: loopyWriter.run returning. connection error: desc = \&amp;quot;transport is closing\&amp;quot;&amp;quot;,&amp;quot;system&amp;quot;:&amp;quot;grpc&amp;quot;,&amp;quot;grpc_log&amp;quot;:true}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;prometheusのInterceptorでCounterのメトリクスが追加されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grpc_server_handled_total{grpc_code=&amp;quot;OK&amp;quot;,grpc_method=&amp;quot;SampleUnary&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;unary&amp;quot;} 1
grpc_server_msg_sent_total{grpc_method=&amp;quot;SampleStream&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;bidi_stream&amp;quot;} 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;EnableHandlingTimeHistogram()&lt;/code&gt;でHistogramsのメトリクスも追加されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grpc_server_handling_seconds_bucket{grpc_method=&amp;quot;SampleUnary&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;unary&amp;quot;,le=&amp;quot;0.005&amp;quot;} 1
grpc_server_handling_seconds_bucket{grpc_method=&amp;quot;SampleUnary&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;unary&amp;quot;,le=&amp;quot;0.01&amp;quot;} 1
grpc_server_handling_seconds_bucket{grpc_method=&amp;quot;SampleUnary&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;unary&amp;quot;,le=&amp;quot;0.025&amp;quot;} 1
grpc_server_handling_seconds_sum{grpc_method=&amp;quot;SampleStream&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;bidi_stream&amp;quot;} 271.267611998
grpc_server_handling_seconds_count{grpc_method=&amp;quot;SampleStream&amp;quot;,grpc_service=&amp;quot;sample.SampleService&amp;quot;,grpc_type=&amp;quot;bidi_stream&amp;quot;} 1
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress</title>
          <link>https://www.sambaiz.net/article/173/</link>
          <pubDate>Sat, 23 Jun 2018 15:02:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/173/</guid>
          <description>

&lt;h2 id=&#34;疎通確認用アプリケーション&#34;&gt;疎通確認用アプリケーション&lt;/h2&gt;

&lt;p&gt;GETでは200を返し、POSTではURLにGETリクエストを送ってステータスコードを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;encoding/json&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;net/http&amp;quot;
)

type PostBody struct {
	URL string `json:&amp;quot;url&amp;quot;`
}

func handler(w http.ResponseWriter, r *http.Request) {
	if r.Method == http.MethodGet {
		fmt.Fprintln(w, &amp;quot;ok&amp;quot;)
	} else if r.Method == http.MethodPost {
		data, err := ioutil.ReadAll(r.Body)
		if err != nil {
			w.WriteHeader(http.StatusInternalServerError)
			fmt.Fprintln(w, err.Error())
			return
		}
		p := PostBody{}
		if err := json.Unmarshal(data, &amp;amp;p); err != nil {
			w.WriteHeader(http.StatusBadRequest)
			fmt.Fprintln(w, err.Error())
			return
		}

		resp, err := http.DefaultClient.Get(p.URL)
		if err != nil {
			fmt.Fprintln(w, err.Error())
			return
		}
		defer resp.Body.Close()
		fmt.Fprintln(w, resp.StatusCode)
	} else {
		w.WriteHeader(http.StatusMethodNotAllowed)
	}
}

func main() {
	http.HandleFunc(&amp;quot;/&amp;quot;, handler)
	fmt.Println(&amp;quot;Listen on :8080&amp;quot;)
	http.ListenAndServe(&amp;quot;:8080&amp;quot;, nil)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;FROM golang:1.10-alpine3.7 AS build-env
WORKDIR /app
ADD . /app
RUN cd /app &amp;amp;&amp;amp; go build -o goapp

FROM alpine:3.7
RUN apk update &amp;amp;&amp;amp; \
   apk add ca-certificates &amp;amp;&amp;amp; \
   update-ca-certificates &amp;amp;&amp;amp; \
   rm -rf /var/cache/apk/*
WORKDIR /app
COPY --from=build-env /app/goapp /app
EXPOSE 8080
ENTRYPOINT ./goapp
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t asia.gcr.io/*****/network-checker .
$ gcloud docker -- push asia.gcr.io/*****/network-checker
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deploymentとserviceを作成&#34;&gt;DeploymentとServiceを作成&lt;/h2&gt;

&lt;p&gt;ksonnetでマニフェストを生成した。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/171/&#34;&gt;ksonnetでkubernetesのmanifestを環境ごとに生成/applyする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ks init try-service
$ cd try-service
$ ks generate deployed-service clusterip-app --image asia.gcr.io/****/network-checker --type ClusterIP
$ ks generate deployed-service nodeport-app --image asia.gcr.io/l****/network-checker --type NodePort
$ ks generate deployed-service loadbalancer-app --image asia.gcr.io/****/network-checker --type LoadBalancer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;containerPortを8080に変更して、PodがPendingしないようにresourcesを絞る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;containers&amp;quot;: [
  {
     ...
     &amp;quot;resources&amp;quot;: {
        &amp;quot;limits&amp;quot;: {
           &amp;quot;cpu&amp;quot;: params.cpu,
           &amp;quot;memory&amp;quot;: params.memory
        },
        &amp;quot;requests&amp;quot;: {
           &amp;quot;cpu&amp;quot;: params.cpu,
           &amp;quot;memory&amp;quot;: params.memory
        }
     }
  }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ ks apply default
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get service
NAME               TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
clusterip-app      ClusterIP      10.11.253.76    &amp;lt;none&amp;gt;            80/TCP         8m
kubernetes         ClusterIP      10.11.240.1     &amp;lt;none&amp;gt;            443/TCP        3h
loadbalancer-app   LoadBalancer   10.11.250.126   130.211.166.214   80:32627/TCP   8m
nodeport-app       NodePort       10.11.253.190   &amp;lt;none&amp;gt;            80:31233/TCP   8m
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;loadbalancer&#34;&gt;LoadBalancer&lt;/h3&gt;

&lt;p&gt;L4のNetwork Load Balancerが立ち、ヘルスチェックが通っていればEXTERNAL-IPでそのままアクセスできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/173-l4lb.png&#34; alt=&#34;Network Load Balancer&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://clusterip-app&amp;quot;}&#39; http://130.211.166.214/
200

$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://nodeport-app&amp;quot;}&#39; http://130.211.166.214/
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クラウドごとに異なるクラスタ外のLoadBalancerの操作は&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.11.2/pkg/cloudprovider/cloud.go#L92&#34;&gt;cloudprovider.LoadBalancer&lt;/a&gt; interfaceになっていて、&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.11.2/pkg/controller/service/service_controller.go#L229&#34;&gt;service_controller&lt;/a&gt;に渡すことができるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/182/&#34;&gt;KubernetesのCustom Resource Definition(CRD)とCustom Controller - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;nodeport&#34;&gt;NodePort&lt;/h3&gt;

&lt;p&gt;ファイアウォールルールでGCEのポートが開いていないのでそのままではアクセスできない。開けばNodeのIPとnodePortでアクセスできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/173-firewallrule.png&#34; alt=&#34;ファイアウォールルール&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get node -o wide
NAME                                          STATUS    ROLES     AGE       VERSION         EXTERNAL-IP       OS-IMAGE                             KERNEL-VERSION   CONTAINER-RUNTIME
gke-test-cluster-default-pool-6601d6a8-07gm   Ready     &amp;lt;none&amp;gt;    53m       v1.8.10-gke.0   130.211.190.139   Container-Optimized OS from Google   4.4.111+         docker://17.3.2
gke-test-cluster-default-pool-6601d6a8-6881   Ready     &amp;lt;none&amp;gt;    4h        v1.8.10-gke.0   35.224.204.110    Container-Optimized OS from Google   4.4.111+         docker://17.3.2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -d &#39;{&amp;quot;url&amp;quot;: &amp;quot;http://clusterip-app&amp;quot;}&#39; 35.224.204.110:31233
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみにNetworkPolicyを使うとPodのトラフィックを制御できる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/181/&#34;&gt;KubernetesのNetworkPolicy Resource - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ingressを作成&#34;&gt;Ingressを作成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt;はホストやパスで異なるServiceにルーティングしたり、
SSL終端にすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local env = std.extVar(&amp;quot;__ksonnet/environments&amp;quot;);
local params = std.extVar(&amp;quot;__ksonnet/params&amp;quot;).components[&amp;quot;ingress&amp;quot;];
[
  {
    &amp;quot;apiVersion&amp;quot;: &amp;quot;extensions/v1beta1&amp;quot;,
    &amp;quot;kind&amp;quot;: &amp;quot;Ingress&amp;quot;,
    &amp;quot;metadata&amp;quot;: {         
      &amp;quot;name&amp;quot;: params.name,
      &amp;quot;annotations&amp;quot;: {
        &amp;quot;ingress.kubernetes.io/rewrite-target&amp;quot;: &amp;quot;/&amp;quot;
        // &amp;quot;kubernetes.io/ingress.allow-http&amp;quot;: &amp;quot;false&amp;quot;
      }
    },
    &amp;quot;spec&amp;quot;: {
      /*
      &amp;quot;tls: {
        &amp;quot;secretName&amp;quot;: &amp;quot;&amp;quot;
      },
      */
      // default backend
      &amp;quot;backend&amp;quot;: {
        &amp;quot;serviceName&amp;quot;: &amp;quot;nodeport-app&amp;quot;,
        &amp;quot;servicePort&amp;quot;: 81 // fail to reach app
      },
      &amp;quot;rules&amp;quot;: [
        {
          &amp;quot;http&amp;quot;: {
            &amp;quot;paths&amp;quot;: [
              {
                &amp;quot;path&amp;quot;: &amp;quot;/aaa&amp;quot;,
                &amp;quot;backend&amp;quot;: {
                  &amp;quot;serviceName&amp;quot;: &amp;quot;nodeport-app&amp;quot;,
                  &amp;quot;servicePort&amp;quot;: 80
                }
              }
            ]
          }
        }
      ]
    }
  }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ ks apply default -c ingress
$ kubectl get ingress
NAME      HOSTS     ADDRESS         PORTS     AGE
ingress   *         35.241.38.159   80        22m

$ curl 35.241.38.159
default backend - 404

$ curl 35.241.38.159/aaa
ok
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;L7のHTTP Load Balancerが立っている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/173-l7lb.png&#34; alt=&#34;HTTP Load Balancer&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのモデルをsave/loadする</title>
          <link>https://www.sambaiz.net/article/172/</link>
          <pubDate>Fri, 22 Jun 2018 01:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/172/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/saved_model/builder/SavedModelBuilder&#34;&gt;SavedModelBuilder&lt;/a&gt;で
モデルを言語に依存しない&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/saved_model.proto&#34;&gt;SavedModel&lt;/a&gt;のprotobufにして保存できる。
SavedModelには&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Saver&#34;&gt;Saver&lt;/a&gt;によって&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/saved_model/builder_impl.py#L418&#34;&gt;出力&lt;/a&gt;される&lt;a href=&#34;https://www.tensorflow.org/get_started/checkpoints&#34;&gt;Checkpoint&lt;/a&gt;を共有する一つ以上の&lt;a href=&#34;https://www.tensohttps://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directoryrflow.org/api_docs/python/tf/MetaGraphDef&#34;&gt;MetaGraphDef&lt;/a&gt;を&lt;a href=&#34;https://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory&#34;&gt;含む&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf

def build_signature(signature_inputs, signature_outputs):
    return tf.saved_model.signature_def_utils.build_signature_def(
        signature_inputs, signature_outputs,
        tf.saved_model.signature_constants.REGRESS_METHOD_NAME)

def save(sess, export_dir, signature_def_map):
    builder = tf.saved_model.builder.SavedModelBuilder(export_dir)
    builder.add_meta_graph_and_variables(
          sess, [tf.saved_model.tag_constants.SERVING],
          signature_def_map=signature_def_map
    )
    builder.save()

import shutil
import os.path
export_dir = &amp;quot;./saved_model&amp;quot;
if os.path.exists(export_dir):
    shutil.rmtree(export_dir)
    
with tf.Graph().as_default():
    a = tf.placeholder(tf.float32, name=&amp;quot;a&amp;quot;)
    b = tf.placeholder(tf.float32, name=&amp;quot;b&amp;quot;)
    c = tf.add(a, b, name=&amp;quot;c&amp;quot;)

    v = tf.placeholder(tf.float32, name=&amp;quot;v&amp;quot;)
    w = tf.Variable(0.0, name=&amp;quot;w&amp;quot;)
    x = w.assign(tf.add(v, w))
    
    sv = tf.train.Supervisor()
    with sv.managed_session() as sess:
        print(sess.run(c, feed_dict={a: 1, b: 2})) # 3.0
        print(sess.run(x, feed_dict={v: 2})) # 2.0
        print(sess.run(x, feed_dict={v: 3})) # 5.0
        # https://github.com/tensorflow/tensorflow/issues/11549
        sess.graph._unsafe_unfinalize()
        save(sess, export_dir, {
            &amp;quot;add&amp;quot;: build_signature({
                &amp;quot;a&amp;quot;: tf.saved_model.utils.build_tensor_info(a),
                &amp;quot;b&amp;quot;:tf.saved_model.utils.build_tensor_info(b)
            }, {
                &amp;quot;c&amp;quot;: tf.saved_model.utils.build_tensor_info(c)
            }),
             &amp;quot;accumulate&amp;quot;: build_signature({
                &amp;quot;v&amp;quot;: tf.saved_model.utils.build_tensor_info(v),
            }, {
                &amp;quot;x&amp;quot;: tf.saved_model.utils.build_tensor_info(x)
            })
        })
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ ls saved_model/
saved_model.pb  variables
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;loadしてsess.runできる。variableの値も保存されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
    with tf.Session() as sess:
        meta_graph_def = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)
        print(sess.run(
            meta_graph_def.signature_def[&amp;quot;accumulate&amp;quot;].outputs[&amp;quot;x&amp;quot;].name, # Assign:0
            feed_dict={
                meta_graph_def.signature_def[&amp;quot;accumulate&amp;quot;].inputs[&amp;quot;v&amp;quot;].name: 3, # v:0
            }
        )) # 8.0
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ksonnetでkubernetesのmanifestを環境ごとに生成/applyする</title>
          <link>https://www.sambaiz.net/article/171/</link>
          <pubDate>Wed, 20 Jun 2018 01:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/171/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://ksonnet.io/&#34;&gt;ksonnet&lt;/a&gt;はJSONのテンプレートエンジン&lt;a href=&#34;https://jsonnet.org/&#34;&gt;jsonnet&lt;/a&gt;からk8sのmanifestを環境ごとに生成してapplyするツール。&lt;a href=&#34;https://github.com/kubeflow/kubeflow&#34;&gt;kubeflow&lt;/a&gt;でも使われている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install ksonnet/tap/ks
$ ks version
ksonnet version: 0.11.0
jsonnet version: v0.10.0
client-go version:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;init&#34;&gt;init&lt;/h2&gt;

&lt;p&gt;まず&lt;code&gt;ks init&lt;/code&gt;してディレクトリを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl config current-context
minikube

$ ks init kstest
$ cd kstest
$ ls
app.yaml	components	environments	lib		vendor

$ cat app.yaml
apiVersion: 0.1.0
environments:
  default:
    destination:
      namespace: default
      server: https://192.168.99.100:8443
    k8sVersion: v1.10.0
    path: default
kind: ksonnet.io/app
name: kstest
registries:
  incubator:
    gitVersion:
      commitSha: 40285d8a14f1ac5787e405e1023cf0c07f6aa28c
      refSpec: master
    protocol: github
    uri: github.com/ksonnet/parts/tree/master/incubator
version: 0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;prototypeのインストール&#34;&gt;Prototypeのインストール&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;app.yaml&lt;/code&gt;にあるように最初はincubatorというregistryが登録されている。追加する場合は&lt;code&gt;ks registry add&lt;/code&gt;。
&lt;code&gt;ks pkg list&lt;/code&gt;でregistryのpackage一覧を見て、&lt;code&gt;ks pkg install&lt;/code&gt;するとpackageに含まれるいくつかのprototypeを持ってくることができる。
prototypeというのはparameterを足してcomponentになるもと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ks registry add *** github.com/***
$ ks pkg list
REGISTRY  NAME      INSTALLED
========  ====      =========
incubator apache
incubator efk
incubator mariadb
incubator memcached
incubator mongodb
incubator mysql
incubator nginx
incubator node
incubator postgres
incubator redis
incubator tomcat

$ ks pkg install incubator/redis@master
$ ks prototype list
NAME                                  DESCRIPTION
====                                  ===========
...
io.ksonnet.pkg.redis-all-features     A Redis deployment with metrics, ingress, and persistent storage.
io.ksonnet.pkg.redis-persistent       A simple Redis deployment, backed by persistent storage.
io.ksonnet.pkg.redis-stateless        A simple, stateless Redis deployment,

$ ls vendor/incubator/redis/
README.md       examples        parts.yaml      prototypes      redis.libsonnet
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;componentの生成&#34;&gt;Componentの生成&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;ks generate&lt;/code&gt;でprototypeからcomponentを生成する。&lt;code&gt;deployed-service&lt;/code&gt;は最初から入っているprototype。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ks generate deployed-service myapp --image gcr.io/google-samples/hello-app:2.0 --type ClusterIP
$ ks generate redis-stateless redis
$ ls components/
myapp.jsonnet           params.libsonnet        redis.jsonnet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;jsonnetではparamsを参照しているが、environmentごとの設定がなければcomponentsの&lt;code&gt;params.libsonnet&lt;/code&gt;の値になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat components/myapp.jsonnet
local env = std.extVar(&amp;quot;__ksonnet/environments&amp;quot;);
local params = std.extVar(&amp;quot;__ksonnet/params&amp;quot;).components.myapp;
[
   {
      &amp;quot;apiVersion&amp;quot;: &amp;quot;v1&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;Service&amp;quot;,
      &amp;quot;metadata&amp;quot;: {
         &amp;quot;name&amp;quot;: params.name
      },
      &amp;quot;spec&amp;quot;: {
         &amp;quot;ports&amp;quot;: [
            {
               &amp;quot;port&amp;quot;: params.servicePort,
               &amp;quot;targetPort&amp;quot;: params.containerPort
            }
         ],
         &amp;quot;selector&amp;quot;: {
            &amp;quot;app&amp;quot;: params.name
         },
         &amp;quot;type&amp;quot;: params.type
      }
   },
   {
      &amp;quot;apiVersion&amp;quot;: &amp;quot;apps/v1beta2&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;Deployment&amp;quot;,
      &amp;quot;metadata&amp;quot;: {
         &amp;quot;name&amp;quot;: params.name
      },
      &amp;quot;spec&amp;quot;: {
         &amp;quot;replicas&amp;quot;: params.replicas,
         &amp;quot;selector&amp;quot;: {
            &amp;quot;matchLabels&amp;quot;: {
               &amp;quot;app&amp;quot;: params.name
            },
         },
         &amp;quot;template&amp;quot;: {
            &amp;quot;metadata&amp;quot;: {
               &amp;quot;labels&amp;quot;: {
                  &amp;quot;app&amp;quot;: params.name
               }
            },
            &amp;quot;spec&amp;quot;: {
               &amp;quot;containers&amp;quot;: [
                  {
                     &amp;quot;image&amp;quot;: params.image,
                     &amp;quot;name&amp;quot;: params.name,
                     &amp;quot;ports&amp;quot;: [
                     {
                        &amp;quot;containerPort&amp;quot;: params.containerPort
                     }
                     ]
                  }
               ]
            }
         }
      }
   }
]

$ cat components/params.libsonnet
{
  global: {
    // User-defined global parameters; accessible to all component and environments, Ex:
    // replicas: 4,
  },
  components: {
    // Component-level parameters, defined initially from &#39;ks prototype use ...&#39;
    // Each object below should correspond to a component in the components/ directory
    redis: {
      name: &amp;quot;redis&amp;quot;,
      redisPassword: &amp;quot;null&amp;quot;,
    },
    myapp: {
      containerPort: 80,
      image: &amp;quot;gcr.io/google-samples/hello-app:2.0&amp;quot;,
      name: &amp;quot;myapp&amp;quot;,
      replicas: 1,
      servicePort: 80,
      type: &amp;quot;ClusterIP&amp;quot;,
    },
  },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;environmentの追加&#34;&gt;Environmentの追加&lt;/h2&gt;

&lt;p&gt;Environmentごとに向き先を変えて、異なるパラメータでapplyできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ks env add prd -n prd
$ ks env list
NAME    OVERRIDE KUBERNETES-VERSION NAMESPACE SERVER
====    ======== ================== ========= ======
default          v1.10.0            default   https://192.168.99.100:8443
prd              v1.10.0            prd       https://192.168.99.100:8443
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--server&lt;/code&gt;フラグでSERVERを指定できる。対象クラスタのIPは&lt;code&gt;kubectl config view&lt;/code&gt;で分かる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ks param set&lt;/code&gt;でパラメータを設定できる。これがcomponentsの&lt;code&gt;params.libsonnet&lt;/code&gt;のものより優先される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ks param set myapp replicas 2 --env prd
$ cat environments/prd/params.libsonnet
local params = std.extVar(&#39;__ksonnet/params&#39;);
local globals = import &#39;globals.libsonnet&#39;;
local envParams = params + {
  components+: {
    myapp+: {
      replicas: 2,
    },
  },
};

{
  components: {
    [x]: envParams.components[x] + globals
    for x in std.objectFields(envParams.components)
  },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;yamlマニフェストを表示&#34;&gt;yamlマニフェストを表示&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ ks show prd
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: redis
  name: redis
spec:
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - env:
        - name: ALLOW_EMPTY_PASSWORD
          value: &amp;quot;yes&amp;quot;
        image: bitnami/redis:3.2.9-r2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          timeoutSeconds: 5
        name: redis
        ports:
        - containerPort: 6379
          name: redis
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 5
          timeoutSeconds: 1
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
        volumeMounts:
        - mountPath: /bitnami/redis
          name: redis-data
      volumes:
      - name: redis-data
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: redis
  name: redis
spec:
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
---
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: myapp
  type: ClusterIP
---
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - image: gcr.io/google-samples/hello-app:2.0
        name: myapp
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;apply&#34;&gt;apply&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ ks apply default -c myapp
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pandasの操作</title>
          <link>https://www.sambaiz.net/article/170/</link>
          <pubDate>Wed, 13 Jun 2018 23:47:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/170/</guid>
          <description>

&lt;h2 id=&#34;seriesとdataframe&#34;&gt;SeriesとDataframe&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import numpy as np

s = pd.Series([1,3])
print(s[1]) # 3
print(s.values) # [1 3] (ndarray)

dates = pd.date_range(&#39;2014-11-01 10:00&#39;,periods=3, freq=&#39;2H&#39;)
print(dates) 
# DatetimeIndex([&#39;2014-11-01 10:00:00&#39;, &#39;2014-11-01 12:00:00&#39;, &#39;2014-11-01 14:00:00&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;2H&#39;)

datestr = lambda d: pd.to_datetime(d).strftime(&#39;%Y-%m-%d %H:%M&#39;)

df = pd.DataFrame({
    &#39;A&#39; : 1.,
    &#39;B&#39; : pd.Series(range(6),  index=pd.date_range(&#39;2014-11-01 10:00&#39;,periods=6, freq=&#39;H&#39;)),
    &#39;C&#39; : [9, 1, 5],
}, index=dates)

df2 = pd.DataFrame({
    &#39;D&#39; : range(3),
}, index=dates)

print(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |A  |B|C|
|-------------------|---|-|-|
|2014-11-01 10:00:00|1.0|0|9|
|2014-11-01 12:00:00|1.0|2|1|
|2014-11-01 14:00:00|1.0|4|5|
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;indexを指定しないと0始まりの数値になる。&lt;/p&gt;

&lt;h2 id=&#34;取得&#34;&gt;取得&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;print(df[&#39;B&#39;].values) # [0 2 4] (列)
print(df.loc[dates[0]].values) # [ 1.  0.  9.] (行)
print(df[&#39;2014-11-01 11:00:00&#39;:&#39;2014-11-01 13:00:00&#39;].values) # [[ 1.  2.  1.]] (index指定で複数行)
print(len(df[df.C &amp;gt; 3])) # 2 (条件で複数行)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ソート&#34;&gt;ソート&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;print(df.sort_index(
    axis=1, # 行
    ascending=False # 降順
).iloc[0].index.values) # [&#39;C&#39; &#39;B&#39; &#39;A&#39;]
print(list(map(datestr, df.sort_values(by=&#39;C&#39;).iloc[:2].index))) # [&#39;2014-11-01 12:00&#39;, &#39;2014-11-01 14:00&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;takeでランダムに取ってreset_indexで振り直せばシャッフルできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/187/&#34;&gt;numpyの関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(df.take(np.random.permutation(df.index)).reset_index(drop=True))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;結合&#34;&gt;結合&lt;/h2&gt;

&lt;p&gt;indexでjoinする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(df.join(df2, how=&#39;outer&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |A  |B|C|D|
|-------------------|---|-|-|-|
|2014-11-01 10:00:00|1.0|0|9|0|
|2014-11-01 12:00:00|1.0|2|1|1|
|2014-11-01 14:00:00|1.0|4|5|2|
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;値でjoinする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(pd.merge(df, df2, left_on=&#39;C&#39;, right_on=&#39;D&#39;, how=&#39;left&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |A  |B|C|D  |
|-------------------|---|-|-|---|
|2014-11-01 10:00:00|1.0|0|9|NaN|
|2014-11-01 12:00:00|1.0|2|1|1.0|
|2014-11-01 14:00:00|1.0|4|5|NaN|
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集計&#34;&gt;集計&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;print(df.mean().values) # [ 1.  2.  5.]
print(df.apply(
    lambda x: x.max(), 
    axis=0 #  列
).values) # [ 1.  4.  9.] (=df.max())
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;加工&#34;&gt;加工&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/166/&#34;&gt;KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(df.drop(
    [&#39;A&#39;, &#39;B&#39;],
    axis=1 # 行
)) # 不要なカラムを削除
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |C|
|-------------------|-|
|2014-11-01 10:00:00|9|
|2014-11-01 12:00:00|1|
|2014-11-01 14:00:00|5|
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;df[&#39;D&#39;] = df[&#39;C&#39;].shift(1) # Cを一列ずらしたDを追加
df[&#39;D&#39;] = df[&#39;D&#39;].fillna(df[&#39;D&#39;].mean()).astype(int) # NaNになる1行目はほかの平均で埋める
print(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;|(index)            |A  |B|C|D|
|-------------------|---|-|-|-|
|2014-11-01 10:00:00|1.0|0|9|5|
|2014-11-01 12:00:00|1.0|2|1|9|
|2014-11-01 14:00:00|1.0|4|5|1|
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ファイル入出力&#34;&gt;ファイル入出力&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;df.to_csv(&#39;df.csv&#39;, header=True, index_label=&#39;date&#39;)
&#39;&#39;&#39;
date,A,B,C
2014-11-01 10:00:00,1.0,0,9
2014-11-01 12:00:00,1.0,2,1
2014-11-01 14:00:00,1.0,4,5
&#39;&#39;&#39;
df3 = pd.read_csv(&#39;df.csv&#39;, index_col=0)
print(df3.index.values) # [&#39;2014-11-01 10:00:00&#39; &#39;2014-11-01 12:00:00&#39; &#39;2014-11-01 14:00:00&#39;]
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す</title>
          <link>https://www.sambaiz.net/article/169/</link>
          <pubDate>Sun, 10 Jun 2018 17:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/169/</guid>
          <description>

&lt;p&gt;機械学習の良いハイパーパラメータを探す方法として、scikit-learnにも&lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html&#34;&gt;ある&lt;/a&gt;グリッドサーチがあるが、これは総当たりで試すもので時間がかかる。&lt;/p&gt;

&lt;p&gt;それに対してベイズ最適化は、まず現在の最大値を超える確率や期待値を出力とする獲得関数を決めて、ガウス過程(GP)に従うと仮定する。
ガウス過程は回帰関数の確率モデルで、任意の入力(x1, x2, &amp;hellip; , xn)に対応する出力(y1, y2, &amp;hellip;, yn)がガウス分布(=正規分布)に従うというもの。
これによって予測されるまだ試していない入力での期待値や分散から次に試す値を決めて効率的に探すことができる。&lt;/p&gt;

&lt;p&gt;今回はKaggleのTitanicのチュートリアルを、チューニングなしのランダムフォレストとXGBoostで解いたときの結果と比較して、ベイズ最適化によるハイパーパラメータで精度が向上するか確認する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/166/&#34;&gt;KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/168/&#34;&gt;KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ランダムフォレスト&#34;&gt;ランダムフォレスト&lt;/h2&gt;

&lt;p&gt;Pythonのベイズ最適化のライブラリ、&lt;a href=&#34;https://github.com/fmfn/BayesianOptimization&#34;&gt;BayesianOptimization&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install bayesian-optimization
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html&#34;&gt;RandomForestClassifier&lt;/a&gt;のハイパーパラメータ&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n_estimators: 木の数&lt;/li&gt;
&lt;li&gt;min_samples_split: ノードを分割するのに必要な最小サンプル数&lt;/li&gt;
&lt;li&gt;max_features: 分割するときに考慮する特徴量の割合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の値を探すため、&lt;code&gt;BayesianOptimization&lt;/code&gt;に最大化したい値(精度)とパラメータの範囲を渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from bayes_opt import BayesianOptimization

import pandas as pd

def preprocess(df):
    df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean())
    df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean())
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;)
    df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0)
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int)
    df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1)
    return df

df = preprocess(pd.read_csv(&#39;./train.csv&#39;))
train_x = df.drop(&#39;Survived&#39;, axis=1)
train_y = df.Survived

def randomforest_cv(n_estimators, min_samples_split, max_features):
    val = cross_val_score(
        RandomForestClassifier(
            n_estimators=int(n_estimators),
            min_samples_split=int(min_samples_split),
            max_features=max_features,
            random_state=0
        ),
        train_x, train_y,
        scoring = &#39;accuracy&#39;,
        cv = 3, # 3-fold
        n_jobs = -1 # use all CPUs
    ).mean()
    return val

randomforest_cv_bo = BayesianOptimization(
    randomforest_cv,
    {&#39;n_estimators&#39;: (10, 250),
    &#39;min_samples_split&#39;: (2, 25),
    &#39;max_features&#39;: (0.1, 0.999)}
)

gp_params = {&amp;quot;alpha&amp;quot;: 1e-5}
randomforest_cv_bo.maximize(n_iter=50, **gp_params)
print(randomforest_cv_bo.res[&#39;max&#39;][&#39;max_val&#39;])
print(randomforest_cv_bo.res[&#39;max&#39;][&#39;max_params&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずinit_points回&lt;a href=&#34;https://github.com/fmfn/BayesianOptimization/blob/0.6.0/bayes_opt/bayesian_optimization.py#L84&#34;&gt;ランダムな値で試して&lt;/a&gt;、
それらの結果を起点にベイズ最適化で探していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Initialization
-------------------------------------------------------------------------------------
 Step |   Time |      Value |   max_features |   min_samples_split |   n_estimators | 
    1 | 00m00s |    0.82267 |         0.7470 |             23.8836 |       103.9041 | 
    2 | 00m00s |    0.81818 |         0.2784 |             12.4106 |       188.5984 | 
    3 | 00m00s |    0.82267 |         0.4745 |              9.1743 |        16.8421 | 
    4 | 00m00s |    0.82267 |         0.6617 |              4.7600 |       222.8920 | 
    5 | 00m00s |    0.81033 |         0.3057 |              9.2044 |        42.1871 | 
Bayesian Optimization
-------------------------------------------------------------------------------------
 Step |   Time |      Value |   max_features |   min_samples_split |   n_estimators | 
    6 | 00m08s |    0.82043 |         0.5444 |             24.5978 |       249.8593 | 
    7 | 00m08s |    0.81033 |         0.3853 |             24.8421 |       249.9177 | 
    8 | 00m07s |    0.79012 |         0.8454 |              2.2098 |        10.0838 | 
    9 | 00m05s |    0.81257 |         0.6389 |             24.9582 |        10.1302 | 
...
   54 | 00m13s |    0.82379 |         0.9751 |             24.9576 |        73.5207 | 
   55 | 00m13s |    0.82043 |         0.9698 |             24.9442 |        65.3054 | 
0.82379349046
{&#39;n_estimators&#39;: 73.520665913948847, &#39;min_samples_split&#39;: 24.957568460557685, &#39;max_features&#39;: 0.97511242524537167}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;少し精度がよくなり、性別の影響がかなり強くなった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.810169491525
Sex             0.445553
Fare            0.180365
Pclass          0.162260
Age             0.147300
Embarked        0.037309
SibSp           0.014159
Parch           0.013054
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;xgboost&#34;&gt;XGBoost&lt;/h2&gt;

&lt;p&gt;XGBoostでは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;learning_rate&lt;/li&gt;
&lt;li&gt;max_depth&lt;/li&gt;
&lt;li&gt;subsample&lt;/li&gt;
&lt;li&gt;colsample_bytree&lt;/li&gt;
&lt;li&gt;min_child_weight&lt;/li&gt;
&lt;li&gt;gamma&lt;/li&gt;
&lt;li&gt;alpha&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を探す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import xgboost as xgb
from bayes_opt import BayesianOptimization

df = preprocess(pd.read_csv(&#39;./train.csv&#39;))
train_x = df.drop(&#39;Survived&#39;, axis=1)
train_y = df.Survived
xgtrain = xgb.DMatrix(train_x, label=train_y)

def xgboost_cv(
    learning_rate,
    max_depth,
    subsample,
    colsample_bytree,
    min_child_weight,
    gamma,
    alpha):
    
    params = {}
    params[&#39;learning_rate&#39;] = learning_rate
    # maximum depth of a tree, increase this value will make the model more complex / likely to be overfitting.
    params[&#39;max_depth&#39;] = int(max_depth) 
    #  subsample ratio of the training instance. Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees and this will prevent overfitting.
    params[&#39;subsample&#39;] = subsample
    # subsample ratio of columns when constructing each tree.
    params[&#39;colsample_bytree&#39;] = colsample_bytree 
    # minimum sum of instance weight (hessian) needed in a child. The larger, the more conservative the algorithm will be.
    params[&#39;min_child_weight&#39;] = min_child_weight
    # minimum loss reduction required to make a further partition on a leaf node of the tree. The larger, the more conservative the algorithm will be.
    params[&#39;gamma&#39;] = gamma 
    # L1 regularization term on weights, increase this value will make model more conservative. 
    params[&#39;alpha&#39;] = alpha 
    params[&#39;objective&#39;] = &#39;binary:logistic&#39;

    cv_result = xgb.cv(
        params,
        xgtrain,
        num_boost_round=10, 
        nfold=3,
        seed=0,
        # Validation error needs to decrease at least every &amp;lt;stopping_rounds&amp;gt; round(s) to continue training.
        # callbacks=[xgb.callback.early_stop(20)]
    )

    return 1.0 - cv_result[&#39;test-error-mean&#39;].values[-1]


xgboost_cv_bo = BayesianOptimization(xgboost_cv, 
                             {
                                 &#39;learning_rate&#39;: (0.1, 0.9),
                                 &#39;max_depth&#39;: (5, 15),
                                 &#39;subsample&#39;: (0.5, 1),
                                 &#39;colsample_bytree&#39;: (0.1, 1),
                                 &#39;min_child_weight&#39;: (1, 20),
                                 &#39;gamma&#39;: (0, 10),
                                 &#39;alpha&#39;: (0, 10),
                             })

xgboost_cv_bo.maximize(n_iter=50)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Initialization
---------------------------------------------------------------------------------------------------------------------------------------------
 Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   learning_rate |   max_depth |   min_child_weight |   subsample | 
    1 | 00m00s |    0.77441 |    5.3061 |             0.4302 |    1.1512 |          0.4484 |      8.4632 |            16.3455 |      0.5688 | 
    2 | 00m00s |    0.79349 |    6.5298 |             0.2519 |    8.8275 |          0.8277 |      9.6443 |             8.1207 |      0.5426 | 
    3 | 00m00s |    0.79349 |    0.4152 |             0.7973 |    7.5153 |          0.7173 |      8.2608 |            12.5433 |      0.7952 | 
    4 | 00m00s |    0.76768 |    3.9047 |             0.9619 |    2.0264 |          0.8893 |      9.8001 |            18.0125 |      0.8254 | 
    5 | 00m00s |    0.77217 |    3.0779 |             0.2957 |    3.1872 |          0.4871 |      8.8120 |            10.6444 |      0.6602 | 
Bayesian Optimization
---------------------------------------------------------------------------------------------------------------------------------------------
 Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   learning_rate |   max_depth |   min_child_weight |   subsample | 
    6 | 00m27s |    0.78676 |    8.5373 |             1.0000 |   10.0000 |          0.9000 |      5.0000 |            20.0000 |      0.5000 | 
    7 | 00m38s |    0.76768 |   10.0000 |             1.0000 |   10.0000 |          0.1000 |      5.0000 |             1.0000 |      1.0000 | 
    8 | 00m16s |    0.67901 |    0.2277 |             0.1000 |   10.0000 |          0.1000 |     15.0000 |            19.9844 |      0.5000 | 
    9 | 00m36s |    0.77666 |    0.0000 |             0.1000 |   10.0000 |          0.9000 |      5.0000 |             1.0000 |      0.5000 | 
...

   55 | 00m20s |    0.81818 |    0.3008 |             1.0000 |    2.5199 |          0.9000 |     13.8205 |             3.3037 |      1.0000 | 
0.833894666667
{&#39;learning_rate&#39;: 0.46665290052625796, &#39;max_depth&#39;: 14.985905144970891, &#39;subsample&#39;: 0.96857695798880505, &#39;colsample_bytree&#39;: 0.74722905651892868, &#39;min_child_weight&#39;: 1.1211600650692968, &#39;gamma&#39;: 0.44876616653489076, &#39;alpha&#39;: 0.13669004333540569}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;精度は微増した。元々のパラメータもそう悪くはなかったのかもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.803389830508
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/hoxo_m/ss-77421091&#34;&gt;機械学習のためのベイズ最適化入門&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ism.ac.jp/~daichi/lectures/H26-GaussianProcess/gp-lecture2-daichi.pdf&#34;&gt;ガウス過程の基礎と教師なし学習&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KaggleのTitanicのチュートリアルをXGBoostで解く</title>
          <link>https://www.sambaiz.net/article/168/</link>
          <pubDate>Sat, 02 Jun 2018 18:16:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/168/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://xgboost.readthedocs.io/en/latest/&#34;&gt;XGBoost&lt;/a&gt;は高性能なGradient Boostingのライブラリ。
Boostingというのはアンサンブル学習の種類の一つで、ランダムフォレストのように弱学習器をそれぞれ並列に学習するBaggingに対して、
順番に前回までの結果を受けながら学習し、結果をまとめる際にそれぞれの重みを掛けるもの。
XGBoostではランダムフォレストと同様に決定木を弱学習器とする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/166/&#34;&gt;KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install xgboost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;データの前処理はランダムフォレストと同じようにした。
&lt;a href=&#34;https://github.com/dmlc/xgboost/blob/master/doc/parameter.md#learning-task-parameters&#34;&gt;パラメータ&lt;/a&gt;の
objective(目的関数)には二値分類なので&lt;code&gt;binary:logistic&lt;/code&gt;を指定し、確率が返るのでroundして出力している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def preprocess(df):
    df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean())
    df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean())
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;)
    df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0)
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int)
    df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1)
    return df

def train(df):
    train_x = df.drop(&#39;Survived&#39;, axis=1)
    train_y = df.Survived
    (train_x, test_x ,train_y, test_y) = train_test_split(train_x, train_y, test_size = 0.6, random_state = 42)
    dtrain = xgb.DMatrix(train_x, label=train_y)
    param = {&#39;max_depth&#39;:3, &#39;learning_rate&#39;: 0.6, &#39;objective&#39;:&#39;binary:logistic&#39; }
    num_round = 2
    bst = xgb.train(param, dtrain, num_round)
    preds = bst.predict(xgb.DMatrix(test_x))
    print(accuracy_score(preds.round(), test_y))

    return bst

def predict(bst, df):
    return bst.predict(xgb.DMatrix(df))

df = pd.read_csv(&#39;./train.csv&#39;)
df_test_origin = pd.read_csv(&#39;./test.csv&#39;)
df = preprocess(df)
df_test = preprocess(df_test_origin)
bst = train(df)
answer = predict(bst, df_test).round().astype(int)
submit_data =  pd.Series(answer, name=&#39;Survived&#39;, index=df_test_origin[&#39;PassengerId&#39;])
submit_data.to_csv(&#39;submit2.csv&#39;, header=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;精度は&lt;code&gt;0.78&lt;/code&gt;ほど。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/169.png&#34; alt=&#34;スコアと順位&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/Retrieva_jp/ss-80724064&#34;&gt;ブースティング入門&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Istio v0.7でEnvoy Proxyを付けるまで</title>
          <link>https://www.sambaiz.net/article/167/</link>
          <pubDate>Tue, 29 May 2018 22:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/167/</guid>
          <description>

&lt;blockquote&gt;
&lt;p&gt;追記(2018-09-01) v1.0となりHelmでのインストールも問題なくできるようになった。Istio-AuthがCitadelという&lt;a href=&#34;https://istio.io/about/notes/0.8/&#34;&gt;名前になっていたり&lt;/a&gt;DeprecatedになってるAPIもある&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/185/&#34;&gt;IstioをHelmでインストールしてRoutingとTelemetryを行いJaeger/Kialiで確認する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;istioとは-https-istio-io-docs-concepts-what-is-istio-overview-html&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html&#34;&gt;Istioとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;マイクロサービス間のネットワークの、ロードバランシングや認証、モニタリングなどを担うサービスメッシュのOSS。
概念は抽象化されていて、Kubernetes以外でもサポートされている。
通信をコントロールするdata-planeのEnvoyと、Envoyを管理するcontrol-planeのPilot, Mixer, Istio-Authからなる。&lt;/p&gt;

&lt;h3 id=&#34;envoy-https-istio-io-docs-concepts-what-is-istio-overview-html-envoy&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html#envoy&#34;&gt;Envoy&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Sidecarとしてデプロイされる、サービスメッシュでの全ての通信を通すプロキシ。
アプリケーションのコードに手を入れる必要がないので言語に縛られない。
&lt;a href=&#34;https://www.cncf.io/&#34;&gt;CNCF&lt;/a&gt;のプロジェクトの一つで、
Istio用に&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/&#34;&gt;オリジナル&lt;/a&gt;から拡張されている。
ロードバランシングやヘルスチェックなどを行い、メトリクスを取る。&lt;/p&gt;

&lt;h3 id=&#34;mixer-https-istio-io-docs-concepts-what-is-istio-overview-html-mixer&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html#mixer&#34;&gt;Mixer&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;サービスメッシュ全体のアクセスコントロールや、Envoyからデータを集めてログに出したりモニタリングしたりする。
プラグインよってAWSやGCPといったインフラバックエンドの差異が吸収される。&lt;/p&gt;

&lt;h3 id=&#34;pilot-https-istio-io-docs-concepts-what-is-istio-overview-html-pilot&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html#pilot&#34;&gt;Pilot&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;サービスディスカバリしてEnvoyのトラフィックを制御する。A/Bテストやカナリアリリースをする場合や、障害に対応して適切にルーティングを行うことができる。&lt;/p&gt;

&lt;h3 id=&#34;istio-auth-https-istio-io-docs-concepts-what-is-istio-overview-html-istio-auth&#34;&gt;&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html#istio-auth&#34;&gt;Istio-Auth&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;サービスやエンドユーザーの認証を行い、ポリシーに従ってアクセス制御する。&lt;/p&gt;

&lt;h2 id=&#34;istioのインストール-https-istio-io-docs-setup-kubernetes-quick-start-html&#34;&gt;&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/quick-start.html&#34;&gt;Istioのインストール&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ローカルのminikubeに環境を作る。
&lt;code&gt;apiserver.Admission.PluginNames&lt;/code&gt;では立ち上がらなかったので&lt;a href=&#34;https://github.com/kubernetes/minikube/issues/2742&#34;&gt;代わりに&lt;/a&gt;
&lt;code&gt;apiserver.admission-control&lt;/code&gt;を指定している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ minikube version
minikube version: v0.27.0
$ minikube start \
--extra-config=apiserver.admission-control=&amp;quot;NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota&amp;quot; \
--kubernetes-version=v1.9.0
$ kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;istioを持ってきてapplyする。
Helmも用意されていて将来的にそっちで入れるのが推奨になりそうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -L https://git.io/getLatestIstio | sh -
$ cd istio-0.7.1/
$ kubectl apply -f install/kubernetes/istio-auth.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作成されたserviceとpodはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get svc -o name -n istio-system
NAME            TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                             AGE
istio-ingress   LoadBalancer   10.96.175.13     &amp;lt;pending&amp;gt;     80:30562/TCP,443:32026/TCP                                          7m
istio-mixer     ClusterIP      10.98.182.172    &amp;lt;none&amp;gt;        9091/TCP,15004/TCP,9093/TCP,9094/TCP,9102/TCP,9125/UDP,42422/TCP    7m
istio-pilot     ClusterIP      10.102.123.144   &amp;lt;none&amp;gt;        15003/TCP,15005/TCP,15007/TCP,15010/TCP,8080/TCP,9093/TCP,443/TCP   7m

$ kubectl get pod -o name -n istio-system
pods/istio-ca-86f55cc46f-5d6vk
pods/istio-ingress-868d5f978b-k4z5m
pods/istio-mixer-65dc5549d6-lh22q
pods/istio-pilot-657cb5ddf7-g8vc6
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;envoyが自動で付くようする-https-istio-io-docs-setup-kubernetes-sidecar-injection-html-automatic-sidecar-injection&#34;&gt;&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/sidecar-injection.html#automatic-sidecar-injection&#34;&gt;Envoyが自動で付くようする&lt;/a&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;追記(2018-06-30): 0.8.0になってsidecar-injectorはデフォルトで入るようになった&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;istio-sidecar-injector&lt;/code&gt;を入れる。これが&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#mutatingadmissionwebhook-beta-in-1-9&#34;&gt;MutatingAdmissionWebhook&lt;/a&gt;でEnvoyを自動で付け足してくれるらしい。Webhookに証明書が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./install/kubernetes/webhook-create-signed-cert.sh \
--service istio-sidecar-injector \
--namespace istio-system \
--secret sidecar-injector-certs
$ kubectl apply -f install/kubernetes/istio-sidecar-injector-configmap-release.yaml
$ cat install/kubernetes/istio-sidecar-injector.yaml | \
./install/kubernetes/webhook-patch-ca-bundle.sh &amp;gt; \
install/kubernetes/istio-sidecar-injector-with-ca-bundle.yaml
$ kubectl apply -f install/kubernetes/istio-sidecar-injector-with-ca-bundle.yaml
$ kubectl -n istio-system get deployment -listio=sidecar-injector
NAME                     DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
istio-sidecar-injector   1         1         1            0           16s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;default namespaceでEnvoyが付くようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl label namespace default istio-injection=enabled
$ kubectl get namespace -L istio-injection
NAME           STATUS    AGE       ISTIO-INJECTION
default        Active    25m       enabled
istio-system   Active    25m       
kube-public    Active    25m       
kube-system    Active    25m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;付いていることが確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl apply -f samples/sleep/sleep.yaml 
$ kubectl get pod
NAME                     READY     STATUS    RESTARTS   AGE
sleep-776b7bcdcd-z567q   2/2       Running   0          26s

$ kubectl describe pod sleep-776b7bcdcd-z567q
Containers:
  sleep:
    ...
  istio-proxy:
    ...
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
          <link>https://www.sambaiz.net/article/166/</link>
          <pubDate>Tue, 29 May 2018 09:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/166/</guid>
          <description>

&lt;p&gt;ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成し並列に学習するアンサンブル学習のBaggingという種類の手法。
決定木なので特徴量の影響が分かりやすく、単一の決定木と比べて過学習を防ぐことができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/168/&#34;&gt;KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;train.csv&lt;/code&gt;と&lt;code&gt;test.csv&lt;/code&gt;をKaggleから&lt;a href=&#34;https://www.kaggle.com/c/titanic/data&#34;&gt;ダウンロード&lt;/a&gt;する。
csvにはタイタニックの乗客者リストが含まれ、&lt;code&gt;test.csv&lt;/code&gt;には生還したかを表す&lt;code&gt;Survived&lt;/code&gt;が抜けている。
これを予測するのがこのコンペティションの目的だ。&lt;/p&gt;

&lt;p&gt;データのうちFareやAge、Embarkedは入っていないものがあって、これらの欠損値をどう扱うという問題がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df = pd.read_csv(&#39;./train.csv&#39;)
print(len(df))
print(df.isnull().sum())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;891
PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;連続値をとるFareとAgeは平均を取り、Embarkedは欠損値用の値にしてみた。数値化できないものについては除いている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def preprocess(df):
    df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean())
    df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean())
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;)
    df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0)
    df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int)
    df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1)
    return df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;scikit-learnのの&lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html&#34;&gt;RandomForestClassifier&lt;/a&gt;で学習させる。
デフォルトの木の数は10で、特徴量の数はsqrt(n_features)となっている。
&lt;code&gt;feature_importances_&lt;/code&gt;で各特徴量の重要度を出すことかできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
import numpy as np
import csv

def train(df):
    train_x = df.drop(&#39;Survived&#39;, axis=1)
    train_y = df.Survived
    (train_x, test_x ,train_y, test_y) = train_test_split(train_x, train_y, test_size = 0.33, random_state = 42)

    clf = RandomForestClassifier(random_state=0)
    clf = clf.fit(train_x, train_y)
    pred = clf.predict(test_x)
    print(accuracy_score(pred, test_y))
    
    features = train_x.columns
    importances = clf.feature_importances_
    indices = np.argsort(importances)
    for i in indices[::-1]:
        print(&amp;quot;{:&amp;lt;15} {:f}&amp;quot;.format(features[i], importances[i]))
    return clf

import pandas as pd
df = pd.read_csv(&#39;./train.csv&#39;)
df = preprocess(df)
clf = train(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;精度は8割ほどで、AgeとFareの影響が大きいようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.803389830508
Age             0.267060
Fare            0.262733
Sex             0.224451
Pclass          0.097958
SibSp           0.058860
Parch           0.048173
Embarked        0.040765
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このモデルで予測したSurvivedのcsvを出力してKaggleにアップロードするとスコアと順位が出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df_test_origin = pd.read_csv(&#39;./test.csv&#39;)
df_test = preprocess(df_test_origin)
submit_data =  pd.Series(clf.predict(df_test), name=&#39;Survived&#39;, index=df_test_origin[&#39;PassengerId&#39;])
submit_data.to_csv(&#39;submit.csv&#39;, header=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/166.png&#34; alt=&#34;スコアと順位&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://techblog.gmo-ap.jp/2017/10/02/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AE%E5%AE%9F%E8%B7%B5%E5%85%A5%E9%96%80%E3%83%BCrandom-forest%E3%81%AE%E8%A6%81%E7%B4%84/&#34;&gt;機械学習の実践入門ーRandom Forestの要約 | GMOアドパートナーズグループ TECH BLOG byGMO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.randpy.tokyo/entry/python_random_forest&#34;&gt;【Pythonで決定木 &amp;amp; Random Forest】タイタニックの生存者データを分析してみた - これで無理なら諦めて！世界一やさしいデータ分析教室&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TerraformでGKEクラスタとBigQueryを立てる</title>
          <link>https://www.sambaiz.net/article/165/</link>
          <pubDate>Tue, 29 May 2018 02:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/165/</guid>
          <description>

&lt;p&gt;GKEクラスタからBigQueryを読み書きすることを想定している。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/121/&#34;&gt;TerraformでVPCを管理するmoduleを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/159/&#34;&gt;Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;gke-https-github-com-hashicorp-terraform-guides-tree-master-infrastructure-as-code-k8s-cluster-gke&#34;&gt;&lt;a href=&#34;https://github.com/hashicorp/terraform-guides/tree/master/infrastructure-as-code/k8s-cluster-gke&#34;&gt;GKE&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/google/r/container_cluster.html&#34;&gt;google_container_cluster&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;oauth_scopeにbigqueryを付けている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_container_cluster&amp;quot; &amp;quot;sample&amp;quot; {
  name               = &amp;quot;${var.cluster_name}&amp;quot;
  description        = &amp;quot;sample k8s cluster&amp;quot;
  zone               = &amp;quot;${var.gcp_zone}&amp;quot;
  initial_node_count = &amp;quot;${var.initial_node_count}&amp;quot;

  master_auth {
    username = &amp;quot;${var.master_username}&amp;quot;
    password = &amp;quot;${var.master_password}&amp;quot;
  }

  node_config {
    machine_type = &amp;quot;${var.node_machine_type}&amp;quot;
    disk_size_gb = &amp;quot;${var.node_disk_size}&amp;quot;

    oauth_scopes = [
      &amp;quot;https://www.googleapis.com/auth/compute&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/logging.write&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/monitoring&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/bigquery&amp;quot;,
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;env&amp;quot; {
  description = &amp;quot;system env&amp;quot;
}
variable &amp;quot;gcp_zone&amp;quot; {
  description = &amp;quot;GCP zone, e.g. us-east1-b&amp;quot;
  default = &amp;quot;us-east1-b&amp;quot;
}

variable &amp;quot;cluster_name&amp;quot; {
  description = &amp;quot;Name of the K8s cluster&amp;quot;
}

variable &amp;quot;initial_node_count&amp;quot; {
  description = &amp;quot;Number of worker VMs to initially create&amp;quot;
  default = 1
}

variable &amp;quot;master_username&amp;quot; {
  description = &amp;quot;Username for accessing the Kubernetes master endpoint&amp;quot;
}

variable &amp;quot;master_password&amp;quot; {
  description = &amp;quot;Password for accessing the Kubernetes master endpoint&amp;quot;
}

variable &amp;quot;node_machine_type&amp;quot; {
  description = &amp;quot;GCE machine type&amp;quot;
  default = &amp;quot;n1-standard-1&amp;quot;
}

variable &amp;quot;node_disk_size&amp;quot; {
  description = &amp;quot;Node disk size in GB&amp;quot;
  default = &amp;quot;20&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bigquery&#34;&gt;BigQuery&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/google/r/bigquery_dataset.html&#34;&gt;google_bigquery_dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/google/r/bigquery_table.html&#34;&gt;google_bigquery_table&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_bigquery_dataset&amp;quot; &amp;quot;sample&amp;quot; {
  dataset_id  = &amp;quot;${var.dataset_id}&amp;quot;
  description = &amp;quot;sample dataset&amp;quot;
  location    = &amp;quot;${var.dataset_location}&amp;quot;

  labels {
    env = &amp;quot;${var.env}&amp;quot;
  }
}

resource &amp;quot;google_bigquery_table&amp;quot; &amp;quot;sample&amp;quot; {
  dataset_id = &amp;quot;${google_bigquery_dataset.sample.dataset_id}&amp;quot;
  table_id   = &amp;quot;sample&amp;quot;
  schema     = &amp;quot;${file(&amp;quot;bigquery/sample/schema.json&amp;quot;)}&amp;quot;

  time_partitioning {
    type  = &amp;quot;DAY&amp;quot;
  }

  labels {
    env = &amp;quot;${var.env}&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;env&amp;quot; {
  description = &amp;quot;system env&amp;quot;
}

variable &amp;quot;dataset_id&amp;quot; {
  description = &amp;quot;dataset ID&amp;quot;
}

variable &amp;quot;dataset_location&amp;quot; {
  description = &amp;quot;dataset location one of [US EU]&amp;quot;
  default     = &amp;quot;US&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;schema.json&lt;/code&gt;はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[
    {
        &amp;quot;name&amp;quot;: &amp;quot;foo&amp;quot;,
        &amp;quot;type&amp;quot;: &amp;quot;FLOAT64&amp;quot;,
        &amp;quot;mode&amp;quot;: &amp;quot;NULLABLE&amp;quot;,
        &amp;quot;description&amp;quot;: &amp;quot;foo&amp;quot;
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;呼び出し元&#34;&gt;呼び出し元&lt;/h2&gt;

&lt;p&gt;IAMからサービスアカウントを作成し、credentialをダウンロードする。
backendはgcs。&lt;code&gt;gcloud auth application-default login&lt;/code&gt;で認証しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;google&amp;quot; {
  credentials = &amp;quot;${file(&amp;quot;sample-credentials.json&amp;quot;)}&amp;quot;
  project     = &amp;quot;sample&amp;quot;
}

terraform {
  backend &amp;quot;gcs&amp;quot; {
    bucket = &amp;quot;sample-tfstate&amp;quot;
    prefix = &amp;quot;prd&amp;quot;
  }
}

module &amp;quot;sample-cluster&amp;quot; {
  source             = &amp;quot;./gke&amp;quot;
  gcp_zone           = &amp;quot;us-west1-a&amp;quot;
  env                = &amp;quot;prd&amp;quot;
  cluster_name       = &amp;quot;sample&amp;quot;
  initial_node_count = 1
  master_username    = &amp;quot;master&amp;quot;
  master_password    = &amp;quot;ae9fqAwfGefeweV&amp;quot;
  node_machine_type  = &amp;quot;n1-standard-2&amp;quot;
  node_disk_size     = &amp;quot;20&amp;quot;
}

module &amp;quot;sample-bigquery&amp;quot; {
  source           = &amp;quot;./bigquery/sample&amp;quot;
  env              = &amp;quot;prd&amp;quot;
  dataset_id       = &amp;quot;sample&amp;quot;
  dataset_location = &amp;quot;US&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>カナダのバンクーバーから南へ5都市周ってGoogleI/Oに行ってきた</title>
          <link>https://www.sambaiz.net/article/164/</link>
          <pubDate>Mon, 28 May 2018 23:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/164/</guid>
          <description>

&lt;p&gt;去年と連続でチケットが当たって2回目の参加。
&lt;a href=&#34;https://www.sambaiz.net/article/103&#34;&gt;前回&lt;/a&gt;はニューヨークで大変な目にあったが、
今回はI/OがGWの次の週だったので日程に余裕があり、カナダのバンクーバーから、ビクトリア、アメリカに入ってポートエンジェルス、シアトル、ポートランドと南下していって会場のマウンテンビューを目指すことにした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-1.png&#34; alt=&#34;地図&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;前回と同じ基本的にExpediaで航空券やホテルは取って、各業者のサイトで都市間の移動に使うフェリーやバスや電車を予約して、
あとアメリカのeSTAのようにカナダにもeTAというのがあって申請した。&lt;/p&gt;

&lt;p&gt;前回は空港からマンハッタンのT-mobileのショップにたどり着くまでネット回線がなく、地図すら空港のwifi頼みで大変な思いをした。
今回はカナダも行くので事前にAmazonでカナダも対応しているプランのSIMを&lt;a href=&#34;https://www.amazon.co.jp/%E3%82%A2%E3%83%A1%E3%83%AA%E3%82%AB-T-Mobile-SIM-%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%8D%E3%83%83%E3%83%88%E7%84%A1%E5%88%B6%E9%99%90%E4%BD%BF%E3%81%84%E6%94%BE%E9%A1%8C-%E3%82%A2%E3%83%A1%E3%83%AA%E3%82%AB%E3%83%BB%E3%82%AB%E3%83%8A%E3%83%80%E3%83%BB%E3%83%A1%E3%82%AD%E3%82%B7%E3%82%B3-%E9%80%9A%E8%A9%B1%E3%81%A8SMS%E3%80%81%E3%83%87%E3%83%BC%E3%82%BF%E9%80%9A%E4%BF%A1%E9%AB%98%E9%80%9F%E7%84%A1%E5%88%B6%E9%99%90%E4%BD%BF%E3%81%84%E6%94%BE%E9%A1%8C/dp/B01NBOQ5AP&#34;&gt;購入して&lt;/a&gt;業者にアクティベートしてもらうことにした。&lt;/p&gt;

&lt;p&gt;今回は夜出発だったので時間に余裕があったが、念のため前日から万札を何枚か財布に入れておいた。つまるところ、現金とネットさえあればなんとでもなるのだ。&lt;/p&gt;

&lt;h2 id=&#34;バンクーバー&#34;&gt;バンクーバー&lt;/h2&gt;

&lt;p&gt;空港から出ても怪しい人を見かけないし、駅の人も愛想良く案内してくれる。
アナウンスもはっきりしているので聞き取りやすく券売機のUIもわかりやすい。
駅の券売機で交通ICカードCompassを手に入れれば、電車・バス共に乗ることができる。
Uberは走っていないがバスが発達していて大体事足りる。バス停の標識も比較的低い位置にあって気付きやすい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-3.jpg&#34; alt=&#34;バス停&#34; /&gt;&lt;/p&gt;

&lt;p&gt;バスから降りるとき皆Thank youと言ってるのは良い感じだ。財布を落としたり傘を忘れたりしても皆で教えてくれるし、人が親切で治安が良くて安心感がある。&lt;/p&gt;

&lt;p&gt;アジア系の飲食店が多い。漢字が併記されているのもよく見る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-2.jpg&#34; alt=&#34;フォー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;朝食は&lt;a href=&#34;https://www.jethrosfinegrub.com/&#34;&gt;Jethro&amp;rsquo;s Fine Grub&lt;/a&gt;という店で取った。ダウンタウンからは少し離れてるのに待ちが発生していた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-4.jpg&#34; alt=&#34;カウボーイブレックファスト&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これを食べてからGranville Islandという店が並んでいるところに行ってきた。
Public Marketにはソーセージやお菓子などが売ってたりするんだけど、腹が一向に空かないし、中には座れず外はとても寒かったので何も買わずに帰ってきた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-5.jpg&#34; alt=&#34;Granville Island&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ビクトリア&#34;&gt;ビクトリア&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://bcfconnector.com/&#34;&gt;BC Ferries Connector&lt;/a&gt;というバスがバンクーバーのPublic Central Stationから出ていて、これに乗るとそのままフェリーに乗り込んでビクトリアまで行くことができる。船内のカフェテリアにカナダらしい食べ物プーティンがあったので頼んでみたら思ったより量が多く、15分前ぐらいのアナウンスでバスに戻らないと普通に置いてかれるので、なんとかコーラで流し込んだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-6.jpg&#34; alt=&#34;プーティン&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ビクトリアのダウンタウンに到着後、バスで1時間くらいかけて北へButchers Gardenという庭園に向かった。
ビクトリアには交通ICカードがないので、車内で5ドル払って1日乗車券をもらって乗る。
この時期は色とりどりのチューリップが咲いていて、歩いているだけで良い香りがする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-7.jpg&#34; alt=&#34;Butchers Garden&#34; /&gt;&lt;/p&gt;

&lt;p&gt;そのほかに鹿おどしのある日本庭園や、イタリア庭園もあったりする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-8.jpg&#34; alt=&#34;Butchers Garden&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このためにビクトリアを訪れてもよいぐらい満足度が高かった。&lt;/p&gt;

&lt;p&gt;朝食は&lt;a href=&#34;http://www.thebluefoxcafe.com/&#34;&gt;BlueFox Caffe&lt;/a&gt;という店でEggs Pacificoというサーモンとアボカドのエッグベネディクトを頼んだ。
付け合わせの芋が多いが、とても美味しい。1日1食の日々がしばらく続く。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-9.jpg&#34; alt=&#34;エッグベネディクト&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ポートエンジェルス-オリンピック半島&#34;&gt;ポートエンジェルス(オリンピック半島)&lt;/h2&gt;

&lt;p&gt;ビクトリアの州議事堂の近くから出ている&lt;a href=&#34;https://www.cohoferry.com/&#34;&gt;Black Ball Ferry Line&lt;/a&gt;に乗ってポートエンジェルスに移動する。
予約しても受付でチケットを受け取る必要がある。乗る前に入国審査を受けて、I-94Aという紙をパスポートに貼ってもらった。
料金が6ドルかかる。カードでも払えるがカナダドルでは払えなかった。&lt;/p&gt;

&lt;p&gt;町の自転車屋で電動自転車を借りて、まずはオリンピック国立公園のビジターセンターを目指した。ここで10ドル払うと入園券みたいなののとマップがもらえる。
どこに行くつもりか、と聞かれたので何も考えてないと答えると、比較的近くにあるHurricane Ridgeという所を教えてもらったのでそこを目指すことにした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-10.jpg&#34; alt=&#34;上り坂&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オフシーズンだからか道を工事していて所々コンディションが悪い。しかもずっと上り坂だ。
それでも電動アシストの力を借りて登っていったのだが、途中でまさかの電池切れ。しょうがないので町に引き返してその日は終わり。返すとき顛末を説明したら割り引いてくれた。&lt;/p&gt;

&lt;p&gt;次の日はバスでMarymere fallsという小さな滝のトレッキングコースに行った。散歩みたいなコースですぐ終わってしまったので、
途中の分岐にあったStormKingというコースにも入ってみたら、傾斜が延々と続く山登りコースだった。終盤&lt;code&gt;END OF MAINTAINED TRAIL&lt;/code&gt;の標識よりあとはいろいろ厳しくなり、勇気と気合いでロープをつかみながら登っていくことになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-12.jpg&#34; alt=&#34;ロープ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;頂上からはCrescent Lakeがその名の通り三日月に見える。景色はよいのだけど足場が狭くて立っているだけで怖い。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-11.jpg&#34; alt=&#34;頂上&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;シアトル&#34;&gt;シアトル&lt;/h2&gt;

&lt;p&gt;ポートエンジェルスからバスでシアトルへ。&lt;a href=&#34;https://olympicbuslines.com/&#34;&gt;Olympic Bus Lines&lt;/a&gt;のバスで、クッキーが配られた。&lt;/p&gt;

&lt;p&gt;シアトルのホテルは高かったのでAirBnbを使ってみた。ナンバーロック式の部屋だったので、ホストとはメッセージのやりとりだけで済んだし、親切にも日本語のガイドブックまで用意しておいてくれた。&lt;/p&gt;

&lt;p&gt;まず、交通ICカードOrcaを手に入れようと、駅の自販機にクレジットカードを入れたところ出てこなくなってしまった。駅員はいないので、なんとか引き抜こうと頑張っていたところ、親切な人がペンチを借りてきてくれてなんとか引き抜くことができた。よかった。
ただ、こんな苦労して手に入れたOrcaも2回ぐらいしか使わなかった。というのもバス停が他の標識と混在して分かりづらく、Uberに迎えに来てもらった方が楽だったからだ。相乗りのUber Poolならバスの倍くらいで乗ることができる。&lt;/p&gt;

&lt;p&gt;気を取り直して、Amazonの本部、Day 1に行ってきた。前から予約すれば社内ツアーもあるみたいだけど、今回の目的はこの1階にある、今年オープンしたレジ無しコンビニのAmazon Goだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-13.jpg&#34; alt=&#34;Amazon Go外観&#34; /&gt;&lt;/p&gt;

&lt;p&gt;アプリをインストールし、入り口で画面のQRコードをかざして入れば、あとは好きに商品を取って、そのまま持って行ってもよいというシステム。画像認識などで判別しているらしく、天井にはそれらしい機材がついている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-14.jpg&#34; alt=&#34;Amazon Go店内&#34; /&gt;&lt;/p&gt;

&lt;p&gt;レジがないので、店内は完全に無人化と思いきや、アルコール売り場のところだけIDを確認する人がいた。&lt;/p&gt;

&lt;p&gt;店を出ると数分でアプリにレシートが届く。意識的にややこしい取り方をしたつもりだけど、数も品物も完全に一致していて驚いた。不気味でさえある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-15.png&#34; alt=&#34;Amazon Goレシート&#34; /&gt;&lt;/p&gt;

&lt;p&gt;シアトルはStarbucksの本部もあって、1号店や旗艦店がある。
1号店はPike Place Marketにあって、隣にあるピロシキ屋が美味しかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-16.jpg&#34; alt=&#34;Starbucks 1号店&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Pike Place Marketの近くにFransという高級チョコレートの店があって、1個単位で買って食べることができる。
ウイスキー入りのものを買ってみたが、初めてこの類のもので美味しいと思ったかもしれない。&lt;/p&gt;

&lt;p&gt;夜はマリナーズのホームグラウンド、セーフコ・フィールドでエンゼルス戦の試合を見た。
2時間前から入れるが、球速測定したり、買い食いしたりなどしているとあっという間に時間が過ぎる。
この日(&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;)はちょうどSTAR WARS DAYで、キャラクターの格好をした人がいたり、演出もSTAR WARS仕様になっていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-17.jpg&#34; alt=&#34;セーフコ・フィールド&#34; /&gt;&lt;/p&gt;

&lt;p&gt;イチローはちょうどこの前日に試合への出場をやめてしまったのだけど、大谷が5番DHで出場して大活躍、結果エンゼルスが勝った。&lt;/p&gt;

&lt;h2 id=&#34;ポートランド-オレゴン&#34;&gt;ポートランド(オレゴン)&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.boltbus.com/&#34;&gt;BoltBus&lt;/a&gt;に乗ってポートランドへ。格安バスなんだけど、革のシートにWifi・電源ありとなかなか快適だった。ただ、電車の方が景色がよくておすすめらしい。&lt;/p&gt;

&lt;p&gt;ポートランドでは住んでいる知り合い家族に、地元の美味しい店やBeacon Rockという登れる岩などに連れてってもらった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-18.jpg&#34; alt=&#34;Beacon Rock&#34; /&gt;&lt;/p&gt;

&lt;p&gt;登っている途中に芝犬を連れた人と何人かすれ違った。オレゴンで人気らしい。知り合いもAiduという芝犬を飼っていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-31.jpg&#34; alt=&#34;Aidu&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オレゴンとワシントン州の境のコロンビア川に沿って走っている途中、木が枯れている区間があった。
なんと50000エーカーもの森が少年の火遊びによって燃えたらしい。
単位もスケールも分かりづらいんだけど、大体200km^2で、八王子くらいが丸々燃えたことになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-29.jpg&#34; alt=&#34;枯れた木&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ポートランドのダウンタウンは小さくて、有名な観光スポットがあるわけではないんだけど、&lt;a href=&#34;http://www.powells.com/&#34;&gt;Powell&amp;rsquo;s Books&lt;/a&gt;というとても大きな本屋はどれだけでもいても飽きない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-30.jpg&#34; alt=&#34;Powell&#39;s Books&#34; /&gt;&lt;/p&gt;

&lt;p&gt;宿は&lt;a href=&#34;https://www.mcmenamins.com/kennedy-school&#34;&gt;Kennedy School&lt;/a&gt;という、古い小学校を使ったホテルをとった。
部屋に黒板があってそれらしい雰囲気がある。バーやシアター、温水プールがあって、地元の人も遊びに来ていた。
泊まった日は廊下でオペラ歌手の演奏があって、ホテルで醸造されたビールを片手にそれを聞きながら夜を過ごした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-32.jpg&#34; alt=&#34;Kennedy School&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;coast-starlight&#34;&gt;Coast Starlight&lt;/h2&gt;

&lt;p&gt;ポートランドのUnion StationからAmtrakのCoast Starlightという夜行列車に乗ってサンノゼまで。
この列車自体はシアトルから出てロサンゼルスまで行くんだけど、その一部ですら17時間乗りっぱなしだ。
寝台の個室席もあるんだけど、食事が込みとはいえ多少値が張るためCoachという普通の席を取った。
乗ってみると意外とこれが快適で足が伸ばせるくらい前の座席との間隔があり、背もたれを倒すのも気を使わなくてよく、
普通に寝られる。ただ、停車時はやや寒いような気がしたので、
ポートランドで買った&lt;a href=&#34;https://www.pendleton-usa.com/&#34;&gt;PENDELTON&lt;/a&gt;のブランケットが早速活躍した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-33.jpg&#34; alt=&#34;PENDELTONのブランケット&#34; /&gt;&lt;/p&gt;

&lt;p&gt;列車内には食堂があるが、朝食以外予約が必要で、席まで時間を聞きにくる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-20.jpg&#34; alt=&#34;食堂車からの風景&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただのCoachにはwifiすら通っていないし、そもそも圏外の区間もあったりしたので、本とか持っていってラウンジで読むのがよいと思う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-21.jpg&#34; alt=&#34;ラウンジ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;google-i-o&#34;&gt;Google I/O&lt;/h2&gt;

&lt;p&gt;サンノゼからUberでマウンテンビューのホテルに向かったところ、Expediaで取ったホテルの日程が変更されておらず、
予約がキャンセルされていた。空いてる部屋も当然ない。しょうがないのでスーツケースを引いてI/Oに向かい、ホテルを探す羽目になった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-22.jpg&#34; alt=&#34;Androidとスーツケース&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今年のI/OはGoogle Asistantが店に電話をかけて予約を取ってくれるGoogle Duplex、Android/iOSでアンカーを共有して同じ場所にARオブジェクトを出すCloud Anchors、アプリで機械学習のモデルを使うFirebaseのML Kit、Androidの開発を効率化するAndroid Jetpackなどが発表された。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-28.jpg&#34; alt=&#34;Developers Keynote&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Cloud AnchorsをSandboxで体験してきた。たしかにAndroidとiOS間で共有できているし、精度も速度も良く見える。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-23.jpg&#34; alt=&#34;Cloud Anchrosを使ったゲーム&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Codelabsで軽く動かしてみた。IDでAnchorを共有するのもスムーズだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-24.jpg&#34; alt=&#34;CodelabsでCloud Anchros&#34; /&gt;&lt;/p&gt;

&lt;p&gt;去年行かなかったOffice HourでARのことについて聞いてきた。初歩的な質問にもGooglerが丁寧に答えてくれた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-25.jpg&#34; alt=&#34;Office Hour&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今回のお土産はGoogle Home miniと、Android Things。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-26.jpg&#34; alt=&#34;お土産&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;サンフランシスコ&#34;&gt;サンフランシスコ&lt;/h2&gt;

&lt;p&gt;バリスタの同期のコーヒー屋めぐりに同行させてもらい、効きコーヒーをやってみた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/164-27.jpg&#34; alt=&#34;利きコーヒー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今回は特に大きな問題もなかった。良かった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Macでの開発環境構築メモ</title>
          <link>https://www.sambaiz.net/article/163/</link>
          <pubDate>Sat, 14 Apr 2018 14:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/163/</guid>
          <description>

&lt;p&gt;新しいMBPを買ったので開発環境の構築でやったことを残しておく&lt;/p&gt;

&lt;h2 id=&#34;設定&#34;&gt;設定&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;アクセシビリティから3本指スクロールを有効にする&lt;/li&gt;
&lt;li&gt;ホットコーナーの左上にLaunchPad、右上にデスクトップを割り当てている&lt;/li&gt;
&lt;li&gt;画面をなるべく広く使うためにDockは左に置いて自動的に隠す&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;bash-profile&#34;&gt;bash_profile&lt;/h2&gt;

&lt;p&gt;パッケージマネージャ以外で持ってきたバイナリは&lt;code&gt;${HOME}/bin&lt;/code&gt;に置くことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;touch ~/.bash_profile
mkdir ${HOME}/bin
echo &amp;quot;export PATH=\$PATH:${HOME}/bin&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;homebrew-https-brew-sh-cask-https-github-com-caskroom-homebrew-cask&#34;&gt;&lt;a href=&#34;https://brew.sh&#34;&gt;HomeBrew&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/caskroom/homebrew-cask&#34;&gt;Cask&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;/usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;
brew tap caskroom/cask
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;一般的なアプリケーション-コマンドのインストール&#34;&gt;一般的なアプリケーション/コマンドのインストール&lt;/h2&gt;

&lt;p&gt;XcodeとUnityとLINEは手動で入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew cask install google-chrome kap visual-studio-code slack kindle
brew install jq gibo mysql wget
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;git&#34;&gt;Git&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;git config --global user.name sambaiz
git config --global user.email godgourd@gmail.com
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker-k8s&#34;&gt;Docker &amp;amp; K8s&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;brew cask install docker virtualbox minikube
brew install docker kubernetes-helm
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fish&#34;&gt;fish&lt;/h2&gt;

&lt;p&gt;bash前提で書かれたスクリプトも多いので、デフォルトシェルにはしない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install fish
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tmux&#34;&gt;tmux&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;~/.tmux.conf&lt;/code&gt;に設定を書く。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/95/&#34;&gt;tmuxのメモ - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install tmux
vi ~/.tmux.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;go&#34;&gt;Go&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/moovweb/gvm&#34;&gt;gvm&lt;/a&gt;でバージョン管理する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/44/&#34;&gt;gvmでGoのバージョン管理 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)
source ${HOME}/.gvm/scripts/gvm
gvm install go1.10 -B
echo &amp;quot;source \${HOME}/.gvm/scripts/gvm&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
echo &amp;quot;gvm use go1.10&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile 
. ~/.bash_profile
go version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/motemen/ghq&#34;&gt;ghq&lt;/a&gt;でリポジトリを管理し、&lt;a href=&#34;https://github.com/peco/peco&#34;&gt;peco&lt;/a&gt;でインクリメンタルサーチして移動したりできるようにする。ghqはデフォルトで&lt;code&gt;~/.ghq&lt;/code&gt;にcloneするが、GOPATHと合わせておくとディレクトリ構造が同じなのでGoのリポジトリをそのまま扱える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get github.com/motemen/ghq
brew install peco
echo &amp;quot;export GHQ_ROOT=\${GOPATH}/src&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
# ghq get git@github.com:sambaiz/puppeteer-lambda-starter-kit.git
# ghq look $(ghq list -p | peco)
echo &#39;alias ghql=&amp;quot;echo \$(ghq list -p | peco)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
# cd `ghql`
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;node-js&#34;&gt;Node.js&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tj/n&#34;&gt;n&lt;/a&gt;でバージョン管理する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/8/&#34;&gt;Node.jsのバージョン管理 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install node yarn
npm install -g n
sudo n stable
node -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serverless frameworkも入れる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install -g serverless
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;python3&#34;&gt;Python3&lt;/h2&gt;

&lt;p&gt;gcloud等がPython2を要求してくるので、aliasは張らない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install python3
python3 --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pip-python2&#34;&gt;pip (python2)&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;wget https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
rm get-pip.py
pip --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;aws-https-docs-aws-amazon-com-ja-jp-cli-latest-userguide-installing-html&#34;&gt;&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/cli/latest/userguide/installing.html&#34;&gt;AWS&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;pip install awscli --upgrade --user
aws configure --profile ${AWS_PROFILE}
echo &amp;quot;export AWS_DEFAULT_PROFILE=${AWS_PROFILE} &amp;gt;&amp;gt; ~/.bash_profile
echo &amp;quot;PATH=\$PATH:~/Library/Python/2.7/bin&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
. ~/.bash_profile
aws --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gcp-https-cloud-google-com-sdk-docs-quickstart-mac-os-x-kubectl&#34;&gt;&lt;a href=&#34;https://cloud.google.com/sdk/docs/quickstart-mac-os-x&#34;&gt;GCP&lt;/a&gt; &amp;amp; kubectl&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;(
  cd ${HOME}/bin \
  &amp;amp;&amp;amp; sudo wget https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-192.0.0-darwin-x86_64.tar.gz \
  &amp;amp;&amp;amp; sudo tar -zxf google-cloud-sdk-192.0.0-darwin-x86_64.tar.gz \
  &amp;amp;&amp;amp; sudo rm google-cloud-sdk-192.0.0-darwin-x86_64.tar.gz \
  &amp;amp;&amp;amp; sudo ./google-cloud-sdk/install.sh \
  &amp;amp;&amp;amp; sudo ./google-cloud-sdk/bin/gcloud init \
)
. ~/.bash_profile
gcloud --version
sudo gcloud components install kubectl
kubectl version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;protobuf-https-github-com-google-protobuf&#34;&gt;&lt;a href=&#34;https://github.com/google/protobuf&#34;&gt;Protobuf&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;(
  mkdir /tmp/protoc \
  &amp;amp;&amp;amp; cd /tmp/protoc \
  &amp;amp;&amp;amp; wget https://github.com/google/protobuf/releases/download/v3.5.1/protoc-3.5.1-osx-x86_64.zip \
  &amp;amp;&amp;amp; unzip protoc-3.5.1-osx-x86_64.zip \
  &amp;amp;&amp;amp; sudo cp bin/protoc ${HOME}/bin \
  &amp;amp;&amp;amp; rm -r /tmp/protoc
)
. ~/.bash_profile
protoc --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;android&#34;&gt;Android&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;brew cask install android-studio
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動してSDKをインストールしてcliツールのパスを通す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo &amp;quot;export PATH=\$PATH:${HOME}/Library/Android/sdk/platform-tools&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
. ~/.bash_profile
adb --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;key&#34;&gt;Key&lt;/h2&gt;

&lt;p&gt;GitHub等に登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh-keygen -t rsa -b 4096
pbcopy &amp;lt; ~/.ssh/id_rsa.pub
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pythonのasyncioで非同期にリクエストを飛ばす</title>
          <link>https://www.sambaiz.net/article/162/</link>
          <pubDate>Sat, 14 Apr 2018 13:37:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/162/</guid>
          <description>&lt;p&gt;Pythonの&lt;a href=&#34;https://docs.python.org/3/library/asyncio.html&#34;&gt;asyncio&lt;/a&gt;はイベントループを回してシングルスレッドで並行に非同期処理を行う。
マルチスレッドで並列に実行するのが&lt;a href=&#34;https://docs.python.jp/3/library/threading.html&#34;&gt;threading&lt;/a&gt;で、
マルチプロセスで並列に実行するのが&lt;a href=&#34;https://docs.python.jp/3/library/multiprocessing.html&#34;&gt;multiprocessing&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import asyncio

async def sleep(s):
    await asyncio.sleep(s)
    print(s)
    return s

loop = asyncio.get_event_loop()

loop.run_until_complete(sleep(5))

coros = [sleep(3), sleep(2)]
futures = asyncio.gather(*coros)
loop.run_until_complete(futures)
print(futures.result())
loop.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ python main.py
5
2
3
[3, 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.python.org/3.6/library/asyncio-eventloops.html#asyncio.AbstractEventLoopPolicy.get_event_loop&#34;&gt;get_event_loop()&lt;/a&gt;
でイベントループを取得し、
&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#asyncio.gather&#34;&gt;gather()&lt;/a&gt;で処理をまとめたりして、
&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#example-future-with-run-until-complete&#34;&gt;run_until_complete()&lt;/a&gt;で
&lt;a href=&#34;https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future&#34;&gt;Future&lt;/a&gt;の完了を待ち、
結果を取得してイベントループを&lt;code&gt;close()&lt;/code&gt;している。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;async def&lt;/code&gt;を付けた関数は&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#coroutines&#34;&gt;Coroutine&lt;/a&gt;となり、
&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#asyncio.ensure_future&#34;&gt;ensure_future()&lt;/a&gt;でFutureのサブクラスの、イベントループで実行させる&lt;a href=&#34;https://docs.python.org/3/library/asyncio-task.html#task&#34;&gt;Task&lt;/a&gt;にすることができる。
&lt;code&gt;run_until_complete()&lt;/code&gt;はそのままCoroutineを投げても&lt;code&gt;ensure_future()&lt;/code&gt;でwrapしてくれる。&lt;/p&gt;

&lt;p&gt;httpクライアント&lt;a href=&#34;https://github.com/requests/requests&#34;&gt;requests&lt;/a&gt;は&lt;a href=&#34;https://github.com/requests/requests/blob/265ef609d5903151374fba480aa81aafe68126ff/docs/user/advanced.rst#blocking-or-non-blocking&#34;&gt;Blockingする&lt;/a&gt;ようなので、asyncioに対応している&lt;a href=&#34;https://github.com/aio-libs/aiohttp&#34;&gt;aiohttp&lt;/a&gt;を使ってリクエストしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import aiohttp
import asyncio
import async_timeout

async def fetch(session, url):
    print(&amp;quot;{} start&amp;quot;.format(url))
    async with async_timeout.timeout(10):
        async with session.get(url) as response:
            text = await response.text()
            print(&amp;quot;{} done&amp;quot;.format(url))
            return text

async def main():
    async with aiohttp.ClientSession() as session:
        urls = [
          &#39;https://www.youtube.com&#39;,
          &#39;https://www.python.org&#39;,
          &#39;https://www.google.co.jp&#39;,
          &#39;https://www.facebook.com&#39;
        ]
        promises = [fetch(session, u) for u in urls]
        await asyncio.gather(*promises)

if __name__ == &#39;__main__&#39;:
    loop = asyncio.get_event_loop()    
    loop.run_until_complete(main())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;非同期にリクエストが飛び、返り次第処理が実行されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python req.py 
https://www.python.org start
https://www.facebook.com start
https://www.youtube.com start
https://www.google.co.jp start
https://www.python.org done
https://www.google.co.jp done
https://www.facebook.com done
https://www.youtube.com done
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes,Helmで負荷試験ツールLocustを立てる</title>
          <link>https://www.sambaiz.net/article/161/</link>
          <pubDate>Sun, 18 Mar 2018 22:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/161/</guid>
          <description>&lt;p&gt;OSSの負荷試験ツール&lt;a href=&#34;https://locust.io/&#34;&gt;Locust&lt;/a&gt;をK8sクラスタに立てる。
K8sならworkerの増減も簡単だし、HelmのChartもあるので立てるのも楽。&lt;/p&gt;

&lt;p&gt;LocustはPython製で、以下のような&lt;a href=&#34;https://docs.locust.io/en/latest/writing-a-locustfile.html&#34;&gt;コード&lt;/a&gt;で処理を書くことができる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@task(10)&lt;/code&gt;のように括弧の中に数字を書いて実行される割合を偏らせることもできる。
異なるTaskSetに対応するユーザーを複数作ることもできて、こちらもweightで重みを付けられる。
ユーザー数はあとでWeb上から入力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir tasks
$ cat tasks/tasks.py
from locust import HttpLocust, TaskSet, task

class ElbTasks(TaskSet):
  @task
  def task1(self):
    with client.get(&amp;quot;/&amp;quot;, catch_response=True) as response:
    if response.content != &amp;quot;Success&amp;quot;:
        response.failure(&amp;quot;Got wrong response&amp;quot;)

class ElbWarmer(HttpLocust):
  task_set = ElbTasks
  min_wait = 1000
  max_wait = 3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stableに&lt;a href=&#34;https://github.com/kubernetes/charts/tree/master/stable/locust&#34;&gt;Chart&lt;/a&gt;はあるが、今のところtasksの中を書き換えなくてはいけないようなので、forkしてきてtasksの中を書き換え、&lt;code&gt;helm repo add&lt;/code&gt;するために&lt;code&gt;package&lt;/code&gt;して、これを参照する&lt;code&gt;index.yaml&lt;/code&gt;を生成した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm package .
$ helm repo index .
$ ls locust-0.1.2.tgz index.yaml 
index.yaml		locust-0.1.2.tgz
$ cat index.yaml
apiVersion: v1
entries:
  locust:
    ...
    urls:
    - locust-0.1.2.tgz
    version: 0.1.2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ helm repo add my-locust &#39;https://raw.githubusercontent.com/sambaiz/charts/my-locust/stable/locust&#39;
$ helm repo list
NAME     	URL                                                                     
stable   	https://kubernetes-charts.storage.googleapis.com
local    	http://127.0.0.1:8879/charts    
my-locust	https://raw.githubusercontent.com/sambaiz/charts/my-locust/stable/locust
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GKEのようなRBACが有効な環境でHelmを使う場合、TillerにServiceAccountを設定しておく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/160/&#34;&gt;RBACが有効なGKEでHelmを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;addしたrepoからinstallする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm install -n my-locust --set master.config.target-host=**** my-locust/locust 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;masterとworker(デフォルトで2つ)が立った。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
my-locust-master-7f7d57f5dc-k966s   1/1       Running   0          1m
my-locust-worker-66cc964748-7ff5w   1/1       Running   0          1m
my-locust-worker-66cc964748-wx5hf   1/1       Running   0          1m
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;port-forwardしてweb-uiにアクセスしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl port-forward $POD_NAME 8089
$ open localhost:8089
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/161.png&#34; alt=&#34;User数と生成速度の設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;実行開始するとRPSなどがリアルタイムで表示される。
1000Users、50spawned/sで始めてみたところ、200Userにも到達せずにリクエスト自体が止まってしまった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/161-2.png&#34; alt=&#34;実行結果&#34; /&gt;&lt;/p&gt;

&lt;p&gt;少なく再設定してもUsersはそのままでよく分からない。
一旦立ち上げ直して100,10で実行してみたら100Userまで行くことは確認できた。&lt;/p&gt;

&lt;p&gt;再び止まるまで上げてみたところ、途中でOOMになっていることが分かった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl describe pod my-locust-worker-****
Containers:
  locust:
    ...
    Last State:     Terminated
      Reason:       OOMKilled
      Exit Code:    137
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;メモリ(割り当て128mi)だけではなく、CPU(割り当て100&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu&#34;&gt;millicores&lt;/a&gt;)もそれなりに使われていて、単純にreplica数を増やせばよさそう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ watch kubectl top node
NAME                                CPU(cores)   MEMORY(bytes)
my-locust-master-7f7d57f5dc-h9mvt   1m           19Mi
my-locust-worker-66cc964748-9dp8n   72m          112Mi
my-locust-worker-66cc964748-h94v9   61m          114Mi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということでworkerを2から5に増やしてみたところUser数を増やしても止まらなくなった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl scale deployment my-locust-worker --replicas=5
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RBACが有効なGKEでHelmを使う</title>
          <link>https://www.sambaiz.net/article/160/</link>
          <pubDate>Sun, 18 Mar 2018 01:04:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/160/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/122/&#34;&gt;k8sのパッケージマネージャーHelmを使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm version
Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.8.2&amp;quot;, GitCommit:&amp;quot;a80231648a1473929271764b920a8e346f6de844&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}
Server: &amp;amp;version.Version{SemVer:&amp;quot;v2.8.2&amp;quot;, GitCommit:&amp;quot;a80231648a1473929271764b920a8e346f6de844&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GKEで&lt;code&gt;helm init&lt;/code&gt;して&lt;code&gt;helm install&lt;/code&gt;したところ以下のエラーが返ってきた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: release my-locust failed: namespaces &amp;quot;default&amp;quot; is forbidden: User &amp;quot;system:serviceaccount:kube-system:default&amp;quot; cannot get namespaces in the namespace &amp;quot;default&amp;quot;: Unknown user &amp;quot;system:serviceaccount:kube-system:default&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GKEではデフォルトでK8sのRBAC(Role-Based Access Control)が&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/role-based-access-control&#34;&gt;有効になっている&lt;/a&gt;ため、&lt;a href=&#34;https://github.com/kubernetes/helm/blob/master/docs/rbac.md&#34;&gt;Tillerインスタンスに権限を与える&lt;/a&gt;必要がある。&lt;/p&gt;

&lt;p&gt;ということでTiller用にnamespaceを切って、その中では好きにできる&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/rbac/#role-and-clusterrole&#34;&gt;Role&lt;/a&gt;と、Tillerが使う&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34;&gt;ServiceAccount&lt;/a&gt;を作成し、RoleBindingで紐づける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: tiller-manager
  namespace: tiller-world
rules:
- apiGroups: [&amp;quot;&amp;quot;, &amp;quot;extensions&amp;quot;, &amp;quot;apps&amp;quot;]
  resources: [&amp;quot;*&amp;quot;]
  verbs: [&amp;quot;*&amp;quot;]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: tiller-world
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: tiller-binding
  namespace: tiller-world
subjects:
- kind: ServiceAccount
  name: tiller
  namespace: tiller-world
roleRef:
  kind: Role
  name: tiller-manager
  apiGroup: rbac.authorization.k8s.io
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Roleを追加するため、自分自身にsuper-user相当の&lt;code&gt;cluster-admin&lt;/code&gt;roleをbindする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=&amp;lt;email&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create namespace tiller-world
$ kubectl create -f tiller-rbac.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;helm init&lt;/code&gt;時に作ったServiceAccountを渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm init --tiller-namespace tiller-world --service-account tiller
$ kubectl get deployment -n tiller-world
NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
tiller-deploy   1         1         1            1           1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prometheusをinstallしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm install --name my-prometheus stable/prometheus --tiller-namespace tiller-world --namespace tiller-world
$ kubectl get pods -n tiller-world
NAME                                                           READY     STATUS    RESTARTS   AGE
my-prometheus-prometheus-alertmanager-85f75879db-9r9z2         2/2       Running   0          1m
my-prometheus-prometheus-kube-state-metrics-65dfc57897-95ts7   1/1       Running   0          1m
my-prometheus-prometheus-server-7c98fb8ffb-s7jpq               2/2       Running   0          1m
tiller-deploy-57dbcb6bbc-6srlt                                 1/1       Running   0          2m
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;ただ、実際のところHelmが特定のnamespaceしか触れないのは不便だし、roleをあとから増やすのも面倒なので最初からcluster-adminのRoleを付けておいてもよいかもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る</title>
          <link>https://www.sambaiz.net/article/159/</link>
          <pubDate>Tue, 13 Mar 2018 01:04:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/159/</guid>
          <description>

&lt;p&gt;Logging AgentをNodeレベルの&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;DaemonSet&lt;/a&gt;として動かすのではなく、Podの中に&lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/logging/#using-a-sidecar-container-with-the-logging-agent&#34;&gt;Sidecar Container&lt;/a&gt;として動かす。その分リソースは食うけど、独自の設定で動かせる。&lt;/p&gt;

&lt;h2 id=&#34;アプリケーション&#34;&gt;アプリケーション&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/go-logging-sample&#34;&gt;https://github.com/sambaiz/go-logging-sample&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Goで定期的にログを出すサンプルコードを書いたのでこれを使う。
&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;viper&lt;/a&gt;で設定を持ち、
&lt;a href=&#34;https://github.com/uber-go/zap&#34;&gt;zap&lt;/a&gt;でログを出力する。
あとSIGINTを拾ってSync()してGraceful Shutdownするようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/104/&#34;&gt;Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/develop/develop-images/multistage-build/#name-your-build-stages&#34;&gt;multistage-build&lt;/a&gt;でビルドして、GKEで動かすのでContainer Registryに上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t go-logging-sample .
$ docker tag go-logging-sample gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1 
$ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fluentdの設定&#34;&gt;Fluentdの設定&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaizenplatform/fluent-plugin-bigquery&#34;&gt;fluent-plugin-bigquery&lt;/a&gt;プラグインを使う。&lt;/p&gt;

&lt;p&gt;projectとdataset、パーティションの&lt;a href=&#34;https://cloud.google.com/bigquery/docs/creating-partitioned-tables&#34;&gt;日付分割テーブル&lt;/a&gt;に入れる場合は、auto_create_table&lt;a href=&#34;https://github.com/kaizenplatform/fluent-plugin-bigquery#date-partitioned-table-support&#34;&gt;できない&lt;/a&gt;のでtableも作成しておく。&lt;/p&gt;

&lt;p&gt;fluentdの設定は&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/&#34;&gt;ConfigMap&lt;/a&gt;で持つ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
data:
  fluent.conf: |
    &amp;lt;source&amp;gt;
      @type tail
      format json
      path /var/log/app.log
      pos_file /var/log/app.log.pos
      tag bigquery 
    &amp;lt;/source&amp;gt;

    &amp;lt;match bigquery&amp;gt;
      @type bigquery

      method load

      &amp;lt;buffer time&amp;gt;
        @type file
        path /var/log/bigquery.*.buffer
        timekey 1d
        flush_at_shutdown true
      &amp;lt;/buffer&amp;gt;

      auth_method	compute_engine

      project &amp;lt;project-name&amp;gt;
      dataset &amp;lt;dataset-name&amp;gt;
      table &amp;lt;table-name&amp;gt;$%Y%m%d
      fetch_schema true 
      ignore_unknown_values true	  
    &amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プラグイン入りのfluentdイメージもビルドして上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM fluent/fluentd:v1.1-onbuild

RUN apk add --update --virtual .build-deps \
        sudo build-base ruby-dev \

 # cutomize following instruction as you wish
 &amp;amp;&amp;amp; sudo gem install \
        bigdecimal fluent-plugin-bigquery:1.2.0 \

 &amp;amp;&amp;amp; sudo gem sources --clear-all \
 &amp;amp;&amp;amp; apk del .build-deps \
 &amp;amp;&amp;amp; rm -rf /var/cache/apk/* \
           /home/fluent/.gem/ruby/*/cache/*.gem

EXPOSE 24284
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ touch fluent.conf
$ mkdir plugins
$ docker build -t fluentd-bigquery .
$ docker tag fluentd-bigquery gcr.io/&amp;lt;project_id&amp;gt;/fluentd-bigquery:v1 
$ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/fluentd-bigquery
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;podの設定&#34;&gt;Podの設定&lt;/h2&gt;

&lt;p&gt;ConfigMapの&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#add-configmap-data-to-a-volume&#34;&gt;Volume&lt;/a&gt;と、ログが書かれるVolumeを定義し、
これを各コンテナでマウントする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: something-collector
spec:
  containers:
  - name: collector
    image: gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1
    env:
    - name: SAMPLE_LOG_PATH
      value: /var/log/app.log
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  - name: fluentd
    image: gcr.io/&amp;lt;project_id&amp;gt;/fluentd-bigquery:v1
    volumeMounts:
    - name: varlog
      mountPath: /var/log
    - name: config-volume
      mountPath: /fluentd/etc
  volumes:
  - name: varlog
    emptyDir: {}
  - name: config-volume
    configMap:
      name: fluentd-config
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;動かす&#34;&gt;動かす&lt;/h2&gt;

&lt;p&gt;BigQueryの権限が付いたGKEのクラスタにデプロイ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/165/&#34;&gt;TerraformでGKEクラスタとBigQueryを立てる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud container clusters get-credentials &amp;lt;cluster-name&amp;gt; --zone &amp;lt;zone&amp;gt; --project &amp;lt;project-name&amp;gt;
$ kubectl config current-context
gke_***

$ kubectl create -f fluentd-configmap.yaml
$ kubectl create -f something-collector-pod.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;立ち上がらないときは&lt;code&gt;-c&lt;/code&gt;でコンテナのnameを指定してログを見る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl logs something-collector -c fluentd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OptionのUse Legacy SQLのチェックを外して&lt;a href=&#34;https://cloud.google.com/bigquery/docs/reference/standard-sql/migrating-from-legacy-sql&#34;&gt;標準SQL&lt;/a&gt;でBigQueryに入っていることを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT
  *
FROM
  `&amp;lt;dataset-name&amp;gt;.&amp;lt;table-name&amp;gt;` 
WHERE
  _PARTITIONTIME BETWEEN 
  TIMESTAMP_TRUNC(TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 * 24 HOUR),DAY)
  AND 
  TIMESTAMP_TRUNC(CURRENT_TIMESTAMP(),DAY);
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQL InnoDBのロックの挙動</title>
          <link>https://www.sambaiz.net/article/158/</link>
          <pubDate>Sat, 03 Mar 2018 19:44:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/158/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html&#34;&gt;https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;トランザクション分離レベルはデフォルトの&lt;code&gt;REPEATABLE-READ&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation;
+-----------------------+-----------------+
| @@GLOBAL.tx_isolation | @@tx_isolation  |
+-----------------------+-----------------+
| REPEATABLE-READ       | REPEATABLE-READ |
+-----------------------+-----------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;DBを立ち上げてテーブルとレコードを入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat schema_and_data.sql
CREATE TABLE a (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(128) NOT NULL
);

CREATE TABLE b (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    a_id BIGINT UNSIGNED NOT NULL,
    FOREIGN KEY (a_id) REFERENCES a (id)
);

INSERT INTO a (id, name) VALUES (1, &#39;1&#39;);
INSERT INTO a (id, name) VALUES (2, &#39;2&#39;);
INSERT INTO a (id, name) VALUES (3, &#39;3&#39;);
INSERT INTO a (id, name) VALUES (8, &#39;8&#39;);
INSERT INTO a (id, name) VALUES (9, &#39;9&#39;);
INSERT INTO a (id, name) VALUES (10, &#39;10&#39;);

$ cat start.sh
docker rm -f try-mysql-lock
docker run --name try-mysql-lock -p 4306:3306 -e &amp;quot;MYSQL_ALLOW_EMPTY_PASSWORD=yes&amp;quot; -e &amp;quot;MYSQL_DATABASE=try-mysql-lock&amp;quot; -e &amp;quot;TZ=Asia/Tokyo&amp;quot; --health-cmd=&#39;mysqladmin ping --silent&#39; -d mysql:5.6 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
while [[ $(docker inspect --format &amp;quot;{{.State.Health.Status}}&amp;quot; try-mysql-lock) != &amp;quot;healthy&amp;quot; ]]; do printf &amp;quot;.&amp;quot;; sleep 1; done
mysql -u root -h 0.0.0.0 -P 4306 -D try-mysql-lock &amp;lt; schema_and_data.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;共有-shared-ロック&#34;&gt;共有(Shared)ロック&lt;/h2&gt;

&lt;p&gt;その行を他がSELECTしたり共有ロックを取ることは許す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id = 2 LOCK IN SHARE MODE;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; SELECT * FROM a WHERE id = 2 LOCK IN SHARE MODE; -- 他も共有ロックは取れる
&amp;gt; UPDATE a SET name=&#39;b&#39; WHERE id = 3; -- これは通る。ロックは行単位なのでid=2だけロックされている。
&amp;gt; UPDATE a SET name=&#39;a&#39; WHERE id = 2; -- これは止まる
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たしかに1行ロックされている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SHOW ENGINE INNODB STATUS \G;
...
---TRANSACTION 2345, ACTIVE 40 sec
2 lock struct(s), heap size 360, 1 row lock(s)
MySQL thread id 4, OS thread handle 0x7f5de21d8700, query id 147 172.17.0.1 root init
SHOW ENGINE INNODB STATUS
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただのSELECTは分離レベルが&lt;code&gt;SERIALIZABLE&lt;/code&gt;でない限りロックをとらない。
ロックしないと、他のトランザクションのCOMMITで
追加されたデータ(ファントム)を読んでしまったりするかというと、
MySQLの&lt;code&gt;REPEATABLE-READ&lt;/code&gt;ではそうはならず、最初にSELECTしたときのスナップショットを返すようになっている。
ただし、&lt;code&gt;LOCK IN SHARE MODE&lt;/code&gt;や&lt;code&gt;FOR UPDATE&lt;/code&gt;を付けると&lt;code&gt;READ-COMMITED&lt;/code&gt;のように最新の結果を返す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://nippondanji.blogspot.jp/2013/12/innodbrepeatable-readlocking-read.html&#34;&gt;漢(オトコ)のコンピュータ道: InnoDBのREPEATABLE READにおけるLocking Readについての注意点&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;排他-exclusive-ロック&#34;&gt;排他(eXclusive)ロック&lt;/h2&gt;

&lt;p&gt;その行に対して他がロックを取ることを許さない。SELECTできるかは分離レベルにより、&lt;code&gt;REPEATABLE READ&lt;/code&gt;では&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_exclusive_lock&#34;&gt;できる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id = 2 FOR UPDATE;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; SELECT * FROM a WHERE id = 2 FOR UPDATE; -- 止まる。同じ行の排他ロックは取れない
&amp;gt; SELECT * FROM a WHERE id = 2 LOCK IN SHARE MODE; -- 止まる。共有ロックも取れない
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;逆に、共有ロックが取られている行に排他ロックも取れない。
ロックを取る順番によってはDeadlockになる。&lt;/p&gt;

&lt;h2 id=&#34;ギャップロック&#34;&gt;ギャップロック&lt;/h2&gt;

&lt;p&gt;存在しない範囲のindexのレコードを一部でもロックすると、行ではなく範囲がロックされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id &amp;gt; 5 FOR UPDATE;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; INSERT a (id, name) VALUE (6, &#39;a&#39;); -- 止まる。
&amp;gt; INSERT a (id, name) VALUE (4, &#39;a&#39;); -- WHEREには含まれないがこれも止まる。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ギャップロックの場合、同じ範囲を排他ロックできてしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id = 5 FOR UPDATE;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; SELECT * FROM a WHERE id = 5 FOR UPDATE; -- 止まらない
&amp;gt; INSERT a (id, name) VALUE (5, &#39;a&#39;); -- 止まる(Tx1でも同じことをやるとDeadlock)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ネクストキーロック&#34;&gt;ネクストキーロック&lt;/h2&gt;

&lt;p&gt;範囲でロックすると一つ先のキーまでロックされる。
ギャップにファントムを発生させないためのもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; SELECT * FROM a WHERE id &amp;lt; 6 FOR UPDATE; -- ギャップロック(id=4~7)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; UPDATE a SET name = &#39;b&#39; WHERE id = 8; -- 止まる
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;更新系クエリでかかるロック-https-dev-mysql-com-doc-refman-5-6-ja-innodb-locks-set-html&#34;&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/innodb-locks-set.html&#34;&gt;更新系クエリでかかるロック&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;insert&#34;&gt;INSERT&lt;/h3&gt;

&lt;p&gt;排他ロックがかかる。重複キーエラーになった場合は共有ロックがかかる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; INSERT INTO a (id, name) VALUE (5, &#39;b&#39;); 
&amp;gt; INSERT INTO a (id, name) VALUE (3, &#39;d&#39;); -- 重複キーエラー
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; INSERT INTO a (id, name) VALUE (5, &#39;c&#39;); -- 止まる
&amp;gt; UPDATE a SET name = &#39;e&#39; WHERE id = 3; -- 止まる
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;INSERT IGNORE&lt;/code&gt;しても同じ。そもそもこれは重複キー以外のエラーも無視した結果、変なデータが入ってしまうことがあるため、使わない方がよい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; INSERT INTO a (name) VALUE (NULL);  -- Column &#39;name&#39; cannot be null
&amp;gt; INSERT IGNORE INTO a (name) VALUE (NULL); -- Query OKで空文字が入ってしまう
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;update-delete&#34;&gt;UPDATE, DELETE&lt;/h3&gt;

&lt;p&gt;排他ネクストキーロックがかかる。INSERTでの&lt;code&gt;ON DUPLICATE KEY UPDATE&lt;/code&gt;も同様。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; UPDATE a SET name=&#39;a&#39; WHERE id BETWEEN 8 AND 9; 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; UPDATE a SET name=&#39;a&#39; WHERE id = 9; -- 止まる
&amp;gt; UPDATE a SET name=&#39;a&#39; WHERE id = 10; -- これも止まる
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;外部キー制約&#34;&gt;外部キー制約&lt;/h3&gt;

&lt;p&gt;さらに外部キー制約がかかるレコードを追加/更新/削除すると、参照するレコードも共有ロックされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- Tx1
&amp;gt; INSERT INTO b (a_id) VALUES (1);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- Tx2
&amp;gt; SELECT * FROM a WHERE id = 1 LOCK IN SHARE MODE; -- 通る
&amp;gt; SELECT * FROM a WHERE id = 1 FOR UPDATE; -- 止まる
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる</title>
          <link>https://www.sambaiz.net/article/157/</link>
          <pubDate>Sun, 25 Feb 2018 23:46:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/157/</guid>
          <description>

&lt;p&gt;UserPoolを作成。デフォルト設定はこんな感じ。
必須項目や、確認メールの文面などを自由にカスタマイズでき、
登録時などのタイミングでLambdaを発火させることもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/157.png&#34; alt=&#34;デフォルト設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作成したUserPoolにアプリクライアントを追加する。
ブラウザで使うのでクライアントシークレットはなし。&lt;/p&gt;

&lt;h2 id=&#34;クライアント側&#34;&gt;クライアント側&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/aws/aws-amplify/tree/master/packages/amazon-cognito-identity-js&#34;&gt;amazon-cognito-identity-js&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;依存するjsを持ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/amazon-cognito-identity.min.js
$ wget https://raw.githubusercontent.com/aws/amazon-cognito-identity-js/master/dist/aws-cognito-sdk.min.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sign UpからAPIを呼ぶところまでのボタンを並べた。
SignInすると&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-with-identity-providers.html&#34;&gt;OIDC標準のトークン&lt;/a&gt;がそのページのドメインのLocal Storageに書かれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/136/&#34;&gt;OpenID ConnectのIDトークンの内容と検証 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.idToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.accessToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.refreshToken
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.&amp;lt;name&amp;gt;.clockDrift
CognitoIdentityServiceProvider.&amp;lt;clientId&amp;gt;.LastAuthUser
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;APIを呼ぶときはidTokenをAuthorization Headerに乗せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&amp;quot;signUp&amp;quot;&amp;gt;Sign Up&amp;lt;/button&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;label&amp;gt;Code:&amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;code&amp;quot;&amp;gt;&amp;lt;/label&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;button id=&amp;quot;confirm&amp;quot;&amp;gt;Confirm&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;signIn&amp;quot;&amp;gt;Sign In&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;whoAmI&amp;quot;&amp;gt;Who am I?&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;requestAPI&amp;quot;&amp;gt;Request API with token&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;signOut&amp;quot;&amp;gt;Sign Out&amp;lt;/button&amp;gt;

&amp;lt;script src=&amp;quot;aws-cognito-sdk.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;amazon-cognito-identity.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script&amp;gt;
const USER_NAME = &amp;quot;*****&amp;quot;;
const USER_PASSWORD = &amp;quot;*****&amp;quot;;
const USER_EMAIL = &amp;quot;*****&amp;quot;;
class CognitoUserPoolAuth {
  constructor(UserPoolId, clientId, apiEndpoint) {
    const poolData = {
      UserPoolId : UserPoolId,
      ClientId : clientId
    };
    this.userPool = new AmazonCognitoIdentity.CognitoUserPool(poolData);
    this.apiEndpoint = apiEndpoint
  }
  
  signUp(userName, password, email) {
    const attributeList = [];
    if (email) {
      attributeList.push(new AmazonCognitoIdentity.CognitoUserAttribute({
        Name : &#39;email&#39;,
        Value : email
      }));
    }

    return new Promise((resolve, reject) =&amp;gt; {
      this.userPool.signUp(userName, password, attributeList, null, (err, result) =&amp;gt; {
        if (err) {
          return reject(err);
        }
        resolve(result);
      });
    });
  }

  confirmCode(userName, confirmCode) {
    const cognitoUser = this.getCognitoUser(userName);
    return new Promise((resolve, reject) =&amp;gt; {
      cognitoUser.confirmRegistration(confirmCode, true, (err, result) =&amp;gt; {
        if (err) {
          return reject(err);
        }
        resolve(result);
      });
    })
  }

 signIn(userName, password) {
    const authenticationData = {
      Username : userName,
      Password : password,
    };
    const authenticationDetails = new AmazonCognitoIdentity.AuthenticationDetails(authenticationData);
    const cognitoUser = this.getCognitoUser(userName);
    return new Promise((resolve, reject) =&amp;gt; {
      cognitoUser.authenticateUser(authenticationDetails, {
        onSuccess: (result) =&amp;gt; {
          resolve(result.getAccessToken().getJwtToken());
        },

        onFailure: function(err) {
          reject(err);
        },
      });
    });
  }

  signOut() {
    const currentUser = this.currentUser();
    if (!currentUser) return;
    const cognitoUser = this.getCognitoUser(currentUser.username);
    if (!cognitoUser) return;
    cognitoUser.signOut();
  }

  getCognitoUser(userName) {
    const userData = {
      Username : userName,
      Pool : this.userPool
    };
    return new AmazonCognitoIdentity.CognitoUser(userData);
  }

  currentUser() {
    return this.userPool.getCurrentUser()
  }
  
  getJwtToken() {
    return new Promise((resolve, reject) =&amp;gt; {
      const cognitoUser = this.currentUser();
      if (!cognitoUser) {
        return reject(&amp;quot;unauthorized&amp;quot;);
      }
      cognitoUser.getSession((err, result) =&amp;gt; {
        if (err) { 
          return reject(err);
        }
        resolve(result.getIdToken().getJwtToken());
      });
    })
  }

  async requestAPIWithToken() {
    const token = await this.getJwtToken().catch(
      (err) =&amp;gt; {
        console.log(err);
      } 
    );
    const headers = token ? { &#39;Authorization&#39;: token } : {};
    return fetch(this.apiEndpoint, {
      headers: headers
    }).then((response) =&amp;gt; {
      return response.json();
    });
  }
}

// -------------
// Handler
// -------------

const auth = new CognitoUserPoolAuth(
    &amp;quot;&amp;lt;poolID&amp;gt;&amp;quot;, 
    &amp;quot;&amp;lt;clientID&amp;gt;&amp;quot;,
    &amp;quot;https://*****.execute-api.us-east-1.amazonaws.com/dev/secret&amp;quot;
)

document.getElementById(&amp;quot;signUp&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const result = await auth.signUp(USER_NAME, USER_PASSWORD, USER_EMAIL).catch((err) =&amp;gt; {
        if (err.code === &amp;quot;UsernameExistsException&amp;quot;) {
        return Promise.reject(&amp;quot;User name is already used&amp;quot;);
        } else {
        return Promise.reject(err);
        }
    });
    console.log(`signUp successfully`);
}, false);

document.getElementById(&amp;quot;confirm&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const code = document.getElementById(&amp;quot;code&amp;quot;).value;
    const result = await auth.confirmCode(USER_NAME, code);
    console.log(`confirm successfully`);
}, false);

document.getElementById(&amp;quot;signIn&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    const result = await auth.signIn(USER_NAME, USER_PASSWORD).catch((err) =&amp;gt; {
        if (err.code === &amp;quot;UserNotConfirmedException&amp;quot;) {
        return Promise.reject(&amp;quot;Confirm your email&amp;quot;);
        } else {
        return Promise.reject(err);
        }
    });
console.log(`signIn successfully`);
}, false);

document.getElementById(&amp;quot;whoAmI&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    console.log(auth.currentUser());
}, false);

document.getElementById(&amp;quot;requestAPI&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    console.log(await auth.requestAPIWithToken());
}, false);

document.getElementById(&amp;quot;signOut&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, async () =&amp;gt; {
    auth.signOut();
    console.log(&amp;quot;signout successfully&amp;quot;);
}, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;api側&#34;&gt;API側&lt;/h2&gt;

&lt;p&gt;Serverless FrameworkでCognitoのJWTを認証に使うには
authorizerのarnにUserPoolのARNを入れる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat serverless.yml
service: cognitoapi

provider:
  name: aws
  runtime: nodejs6.10

functions:
  createTodo:
    handler: handler.secret
    events:
      - http:
          path: secret
          cors: true
          method: get
          authorizer:
            arn: ***** # UserPool&#39;s ARN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JWTのpayloadをdecodeして返してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat handler.js
&#39;use strict&#39;;

module.exports.secret = (event, context, callback) =&amp;gt; {
  const payload = JSON.parse(
    new Buffer(
      event.headers.Authorization.split(&amp;quot;.&amp;quot;)[1], 
      &amp;quot;base64&amp;quot;
    ).toString()
  );
  const response = {
    statusCode: 200,
    body: JSON.stringify({
      userInfo: payload
    }),
    headers: {
      &amp;quot;Access-Control-Allow-Origin&amp;quot;: &amp;quot;*&amp;quot;
    },
  };
  callback(null, response);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。Sign Upしたときにコード付きのメールが送られている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/157.gif&#34; alt=&#34;動作&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ブラウザのwindow間の値渡し</title>
          <link>https://www.sambaiz.net/article/156/</link>
          <pubDate>Fri, 23 Feb 2018 02:01:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/156/</guid>
          <description>

&lt;h2 id=&#34;直接windowを参照する&#34;&gt;直接Windowを参照する&lt;/h2&gt;

&lt;p&gt;オリジン(プロトコル+ポート+ホスト)が同じ場合は、親は&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/window.open&#34;&gt;open()&lt;/a&gt;した返り値で、子はwindow.openerで相手のwindowが取れて、直接参照したりDOMを操作したりすることもできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/194/&#34;&gt;同じ/異なるオリジンのiframeの中からできること - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Open window&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;btn2&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
  let win2;
  const button = document.getElementById(&amp;quot;btn&amp;quot;);
  button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    window.foo = &amp;quot;bar from window1&amp;quot;;
    win2 = window.open(&amp;quot;index2.html&amp;quot;);
  }, false);

  const button2 = document.getElementById(&amp;quot;btn2&amp;quot;);
  button2.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    if (win2) {
      win2.close();
    }
  }, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index2.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Close window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
  console.log(window.aaa);
  const parentWindow = window.opener;
  const view = document.getElementById(&amp;quot;view&amp;quot;);
  view.textContent = parentWindow.foo; // window1 -&amp;gt; window2

  const button = document.getElementById(&amp;quot;btn&amp;quot;);
  button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
    if(!parentWindow) {
      window.close();
    }
    const view = parentWindow.document.getElementById(&amp;quot;view&amp;quot;);
    if (view) {
      view.textContent = &amp;quot;Window2 has been closed by myself&amp;quot;; // window2 -&amp;gt; window1
    }
    window.close();
  }, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認する際は&lt;a href=&#34;https://github.com/cloudhead/node-static&#34;&gt;node-static&lt;/a&gt;などでサーバーを立てる必要がある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-1.gif&#34; alt=&#34;直接Windowを参照する値渡し&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;postmessage-https-developer-mozilla-org-ja-docs-web-api-window-postmessage-を使う&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Window/postMessage&#34;&gt;postMessage()&lt;/a&gt;を使う&lt;/h2&gt;

&lt;p&gt;postMessageで送り、messageのeventで受け取れる。オリジンが異なっていてもよいが、
どこからでも送れてしまうので、ハンドリングする際は&lt;code&gt;event.origin&lt;/code&gt;が意図したものかチェックしなくてはならない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;Open window&amp;lt;/button&amp;gt;
&amp;lt;button id=&amp;quot;btn2&amp;quot;&amp;gt;Post to window&amp;lt;/button&amp;gt;
&amp;lt;div id=&amp;quot;view&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script&amp;gt;
const view = document.getElementById(&amp;quot;view&amp;quot;);
const receiveMessage = (event) =&amp;gt; {
  if (event.origin === &amp;quot;http://localhost:8081&amp;quot;) {
    view.textContent = event.data;
  }
}
window.addEventListener(&amp;quot;message&amp;quot;, receiveMessage, false);

let win2;
const button = document.getElementById(&amp;quot;btn&amp;quot;);
button.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
  win2 = window.open(&amp;quot;http://localhost:8081/index2.html&amp;quot;);
}, false);

const button2 = document.getElementById(&amp;quot;btn2&amp;quot;);
button2.addEventListener(&amp;quot;click&amp;quot;, () =&amp;gt; {
  win2.postMessage(&amp;quot;bar from window1&amp;quot;, &amp;quot;http://localhost:8081&amp;quot;);
}, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index2.html
&amp;lt;script&amp;gt;
const receiveMessage = (event) =&amp;gt; {
  if (event.origin === &amp;quot;http://localhost:8080&amp;quot;) {
    event.source.postMessage(
      `window2 received data: ${event.data}`,
      event.origin
    );
  }
  window.close();
}
window.addEventListener(&amp;quot;message&amp;quot;, receiveMessage, false);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;別のポートでも値が渡されていることが確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-2.gif&#34; alt=&#34;postMessage()での値渡し&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;reactでpostmessageする&#34;&gt;ReactでpostMessageする&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;componentDidMount()&lt;/code&gt;でaddEventListenerして&lt;code&gt;componentWillUnmount()&lt;/code&gt;でremoveする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.jsx
class App extends React.Component {
  constructor(props) {
    super(props);
    this.state = {value: &#39;&#39;};
    this.handleChange = this.handleChange.bind(this);
    this.handleMessage = this.handleMessage.bind(this);
    this.openWindow = this.openWindow.bind(this);
  }
  componentDidMount() {
    window.addEventListener(&#39;message&#39;, this.handleMessage);
  }
  componentWillUnmount() {
    window.removeEventListener(&#39;message&#39;, this.handleMessage);
  }
  handleMessage(event) {
    if (
      (window.opener &amp;amp;&amp;amp; event.origin === &amp;quot;http://localhost:8080&amp;quot;) ||
      (!window.opener &amp;amp;&amp;amp; event.origin === &amp;quot;http://localhost:8081&amp;quot;)
    ) {
      this.setState({value: event.data});
    }
  }
  handleChange(event) {
    this.setState({value: event.target.value});
    if (this.newWindow) {
      this.newWindow.postMessage(this.state.value, &amp;quot;http://localhost:8081&amp;quot;); // window1 -&amp;gt; window2
    } else if (window.opener) {
      window.opener.postMessage(this.state.value, &amp;quot;http://localhost:8080&amp;quot;); // window2 -&amp;gt; window1
    }
  }
  openWindow(event) {
    this.newWindow = window.open(&#39;http://localhost:8081/index.html&#39;, &#39;_blank&#39;, &#39;width=640, height=480&#39;);
  }
  render() {
    return &amp;lt;div&amp;gt;
      { !window.opener ? &amp;lt;button onClick={this.openWindow}&amp;gt;Open Window&amp;lt;/button&amp;gt; : &amp;lt;div&amp;gt;&amp;lt;/div&amp;gt;}
      &amp;lt;input type=&amp;quot;text&amp;quot; value={this.state.value} onChange={this.handleChange} /&amp;gt;
    &amp;lt;/div&amp;gt;;
  }
}

ReactDOM.render(
  &amp;lt;App /&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat index.html
&amp;lt;dic id=&amp;quot;root&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script src=&amp;quot;https://unpkg.com/react@16/umd/react.production.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;https://unpkg.com/react-dom@16/umd/react-dom.production.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev @babel/cli @babel/core @babel/preset-react
$ echo &#39;{ &amp;quot;presets&amp;quot;: [&amp;quot;@babel/preset-react&amp;quot;] }&#39; &amp;gt; .babelrc
$ ./node_modules/.bin/babel index.jsx -o index.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/156-3.gif&#34; alt=&#34;ReactでpostMessage()での値渡し&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Serverless FrameworkでLambdaをデプロイする</title>
          <link>https://www.sambaiz.net/article/155/</link>
          <pubDate>Sun, 11 Feb 2018 23:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/155/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless&#34;&gt;Serverless Framework&lt;/a&gt;でLambda Functionをデプロイする。
Apexが基本的にFunction自体のデプロイしかしないのに対して、こちらはeventの設定なども諸々やってくれて強い。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/140/&#34;&gt;ApexでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g serverless
$ serverless version
1.26.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ApexではFunctionごとにディレクトリが作られたが、Serverlessでは&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/services/#services&#34;&gt;Service&lt;/a&gt;ごとに作られ、
一つのService内で複数のFunctionを定義できる。handlerは同じでも異なっていてもよい。&lt;/p&gt;

&lt;p&gt;Apexの形式の場合、共通の処理をWebpackなどで各Functionに持って来たり、
同じような処理の複数のFunctionを立てる際はコピーする必要があったが、
こちらは必要最小限の変更でそれらを行うことができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless/tree/master/lib/plugins/create/templates&#34;&gt;template&lt;/a&gt;からServiceをcreateする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ serverless create --template aws-nodejs --path testservice
$ ls testservice/
handler.js	serverless.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定ファイル&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/serverless.yml/#serverlessyml-reference&#34;&gt;serverless.yml&lt;/a&gt;
にはLambdaの基本的なもののほかに、VPCやevent、IAM Roleなども書けて、これらはdeploy時に作られるCloudFormationのstackによって管理される。必要なら生のCloudFormationの設定も書ける。&lt;/p&gt;

&lt;p&gt;ApexでもTerraformによって管理することができるが、書くのはこちらの方がはるかに楽。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/144/&#34;&gt;ApexでデプロイしたLambdaのトリガーをTerraformで管理する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat sesrverless.yml
service: testservice

provider:
  name: aws
  profile: foobar
  region: ap-northeast-1
  runtime: nodejs6.10
  memorySize: 512
  timeout: 10
 
functions: 
  hello: 
    handler: handler.hello 
    events:
      - http:
          path: hello/world
          method: get
          cors: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;deployすると&lt;code&gt;{service}-{stage}-{function}&lt;/code&gt;のFunctionが作られる。
今回の場合はtestservice-prd-test。stageをymlでも指定しなかった場合はデフォルト値のdevになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ serverless deploy --stage prd
$ curl https://*****.ap-northeast-1.amazonaws.com/prd/hello/world | jq
{
  &amp;quot;message&amp;quot;: &amp;quot;Go Serverless v1.0! Your function executed successfully!&amp;quot;,
  &amp;quot;input&amp;quot;: {
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;hook&#34;&gt;hook&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/serverless/serverless#v1-plugins&#34;&gt;Plugin&lt;/a&gt;で&lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/plugins/#lifecycle-events&#34;&gt;Lifecycle Events&lt;/a&gt;を拾えるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppeteer-lambda-starter-kit&lt;/a&gt;は以前からpackage scriptsがあったので、これをServerlessのpackage時に呼ぶことでServerless Framework対応した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev serverless-hooks-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;plugins:
  - serverless-hooks-plugin

custom:
  hooks:
    package:initialize:
      - npm run build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とても便利なのでCloudFormationを使いたくないというわけでなければ、Serverless Frameworkを使っておけばよいと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
          <link>https://www.sambaiz.net/article/154/</link>
          <pubDate>Sun, 11 Feb 2018 19:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/154/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/146/&#34;&gt;TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。
全体のコードは&lt;a href=&#34;https://github.com/sambaiz/my_jupyter_notebook/blob/master/rnn-continuous.ipynb&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;入力&#34;&gt;入力&lt;/h3&gt;

&lt;p&gt;以下の関数によって生成した1次元のデータ列。
これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def make_time_series_data(size):
  data = []
  for i in range(size):
    data.append(sin(random.normalvariate(i,0.1)*0.1))
  return np.reshape(np.array(data, dtype=np.float32), (size,1))

def make_batch(data, batch_size, num_steps, num_dimensions, name=None):
  epoch_size =  data.size // (batch_size*num_steps*num_dimensions)
  data = np.lib.stride_tricks.as_strided(
    data, 
    shape=
      (epoch_size,
        batch_size, 
       num_steps+1,
       num_dimensions),
    strides=(
        4*batch_size*num_steps*num_dimensions, 
        4*num_steps*num_dimensions, 
        4*num_dimensions, 
        4 # bytes
    ), 
    writeable=False
  )
  
  return data[:, :, :-1], data[:, :, 1:]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;モデル&#34;&gt;モデル&lt;/h3&gt;

&lt;p&gt;input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。
lossはMSE(Mean squared error)。Optimizerは&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer&#34;&gt;GradientDecentOptimizer&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;チュートリアルでは自力で各time_stepの値を&lt;a href=&#34;https://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/rnn/ptb/ptb_word_lm.py#L141&#34;&gt;入れていた&lt;/a&gt;けど、
今回は&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn&#34;&gt;dynamic_rnn()&lt;/a&gt;に任せている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Model(object):
  def __init__(self, config, is_training=False):
    # config
    self.batch_size = config.batch_size
    self.num_steps = config.num_steps
    self.num_dimensions = config.num_dimensions
    self.keep_prob = config.keep_prob
    self.hidden_size = config.hidden_size
    self.num_layers = config.num_layers
    
    # placeholder
    self.input = tf.placeholder(tf.float32, [None, self.num_steps, self.num_dimensions], name=&amp;quot;input&amp;quot;)
    self.input_strided = tf.placeholder(tf.float32, [self.batch_size, self.num_steps, self.num_dimensions], name=&amp;quot;input_strided&amp;quot;)
    self.lr = tf.placeholder(tf.float32, name=&amp;quot;learning_rate&amp;quot;)
    
    # input layer
    input = tf.reshape(self.input, [-1, self.num_dimensions])
    input_w = tf.get_variable(&amp;quot;input_w&amp;quot;, [self.num_dimensions, self.hidden_size], dtype=tf.float32)
    input_b = tf.get_variable(&amp;quot;input_b&amp;quot;, [self.hidden_size], dtype=tf.float32)
    input = tf.nn.xw_plus_b(input, input_w, input_b)
    input = tf.reshape(input, [self.batch_size, self.num_steps, self.hidden_size])
    
    # LSTM layer
    output, state = self._build_rnn_graph(input, is_training)
    
    # output layer
    output = tf.reshape(output, [-1, self.hidden_size])
    output_w = tf.get_variable(&amp;quot;output_w&amp;quot;, [self.hidden_size, 1], dtype=tf.float32)
    output_b = tf.get_variable(&amp;quot;output_b&amp;quot;, [1], dtype=tf.float32)
    output = tf.nn.xw_plus_b(output, output_w, output_b)
    self.output = tf.reshape(output, [self.batch_size, self.num_steps, 1])
    
    self.cost = tf.reduce_mean(tf.square(self.output[:, -1, :] - self.input_strided[:, -1, :]))
    self.train_op = tf.train.GradientDescentOptimizer(self.lr).minimize(self.cost, global_step=tf.train.get_or_create_global_step())

  def _build_rnn_graph(self, input, is_training):
    def make_cell():
      cell = tf.contrib.rnn.LSTMBlockCell(
        self.hidden_size, forget_bias=0.0)
      if is_training and self.keep_prob &amp;lt; 1:
        cell = tf.contrib.rnn.DropoutWrapper(
          cell, output_keep_prob=self.keep_prob)
      return cell

    cell = tf.contrib.rnn.MultiRNNCell(
      [make_cell() for _ in range(self.num_layers)], state_is_tuple=True)
    initial_state = cell.zero_state(self.batch_size, tf.float32)
    output, state = tf.nn.dynamic_rnn(cell, input, initial_state=initial_state)
    return output, state

  def learn(self, session, input, input_strided, learning_rate):
    fetches = {
      &amp;quot;cost&amp;quot;: self.cost,
      &amp;quot;train_op&amp;quot;: self.train_op
    }
    feed_dict = {
      self.input: input,
      self.input_strided: input_strided,
      self.lr: learning_rate
    }
    vals = session.run(fetches, feed_dict=feed_dict)
    cost = vals[&amp;quot;cost&amp;quot;]
    return cost

  def predict(self, session, input):
    feed_dict = {
      self.input: np.reshape(input, (1, input.shape[0], input.shape[1]))
    }
    return session.run(self.output, feed_dict=feed_dict)[0,-1]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ハイパーパラメータ&#34;&gt;ハイパーパラメータ&lt;/h3&gt;

&lt;p&gt;調整が難しい。&lt;code&gt;max_epoch&lt;/code&gt;は学習率の初期値(&lt;code&gt;learning_rate&lt;/code&gt;)で学習し続けるepochの数なわけなんだけど、
これを大きくして一気にlossを減らしていこうとしたら案外簡単に収束しなくなってしまった。
&lt;code&gt;num_steps&lt;/code&gt;、つまり予測するのに見る数は今回のデータの場合そんなに大きくある必要はなくて、
むしろ大きくすると平たいグラフになって最大値や最小値との誤差が大きくなった。
&lt;code&gt;hidden_size&lt;/code&gt;や&lt;code&gt;num_layers&lt;/code&gt;は増やしても良さそうだけどメモリが足りなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Config(object):
  init_scale = 0.1
  learning_rate = 1.0
  num_layers = 2
  num_steps = 5
  hidden_size = 200
  max_epoch = 3
  batch_size = 3000
  num_dimensions = 1
  keep_prob = 1.0
  lr_decay = 0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;学習結果&#34;&gt;学習結果&lt;/h3&gt;

&lt;p&gt;300000個のデータから学習して予測させたところ
予測値は実際の値と比べて振幅が少なくなってしまった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/154.png&#34; alt=&#34;実際のデータと予測結果のグラフ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>xorm reverseでDBスキーマからGoのstructを生成する</title>
          <link>https://www.sambaiz.net/article/153/</link>
          <pubDate>Sat, 10 Feb 2018 15:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/153/</guid>
          <description>&lt;p&gt;GoのORMの&lt;a href=&#34;https://github.com/go-xorm/xorm&#34;&gt;xorm&lt;/a&gt;にはxorm reverseというDBのスキーマから以下のようなテンプレートに沿ったGoのstructなどを生成する&lt;a href=&#34;https://github.com/go-xorm/cmd&#34;&gt;ツール&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package {{.Model}}

import (
	{{range .Imports}}&amp;quot;{{.}}&amp;quot;{{end}}
)

{{range .Tables}}
type {{Mapper .Name}} struct {
{{$table := .}}
{{range .Columns}}	{{Mapper .Name}}	{{Type .}}
{{end}}
}

{{end}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リポジトリにある&lt;a href=&#34;https://github.com/go-xorm/cmd/tree/master/xorm/templates&#34;&gt;テンプレート&lt;/a&gt;にxorm用テンプレートとgo用のテンプレートが用意されているように、単体で使うこともできる。
また、テンプレートを書く言語としてもGo以外にC++もサポートしている。&lt;/p&gt;

&lt;p&gt;xormのcmdとドライバをインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/go-xorm/cmd/xorm
$ go get github.com/go-sql-driver/mysql
$ xorm
Version:

    0.2.0524
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;様々な型のカラムを含むテーブルで試す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat schema.sql
CREATE TABLE table1 (
  n_tinyint TINYINT,
  n_int INT,
  n_int_unsigned INT UNSIGNED NOT NULL DEFAULT 1,
  n_bigint BIGINT,
  n_float FLOAT,
  n_double DOUBLE,
  d_date DATE,
  d_datetime DATETIME,
  s_char CHAR(64),
  s_varchar VARCHAR(64),
  s_text TEXT,
  s_json JSON,
  b_binary BLOB,
  e_enum ENUM(&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;)
)

$ cat setup.sh
docker run --name mysql-xorm -p 33306:3306 -e &amp;quot;MYSQL_ALLOW_EMPTY_PASSWORD=yes&amp;quot; -e &amp;quot;MYSQL_DATABASE=testdb&amp;quot; 
while [ $(docker inspect --format &amp;quot;{{.State.Health.Status }}&amp;quot; mysql-xorm) != &amp;quot;healthy&amp;quot; ]; do printf &amp;quot;.&amp;quot;; sleep 1; done
mysql -u root -h 0.0.0.0 -P 33306 -D testdb &amp;lt; schema.sql

$ sh setup.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Goのテンプレートをリポジトリから持ってきてxorm reverseを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls xorm-template
config		struct.go.tpl

$ xorm reverse mysql &amp;quot;root:@tcp(0.0.0.0:33306)/testdb&amp;quot; xorm-template
$ cat model/table1.go 
package model

import (
	&amp;quot;time&amp;quot;
)

type Table1 struct {
	NTinyint     int
	NInt         int
	NIntUnsigned int
	NBigint      int64
	NFloat       float32
	NDouble      float64
	DDate        time.Time
	DDatetime    time.Time
	SChar        string
	SVarchar     string
	SText        string
	SJson        string
	BBinary      []byte
	EEnum        string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;概ねうまくいっているが、現状unsignedは無視されてしまう。
これを修正するには依存しているcoreや&lt;a href=&#34;https://github.com/go-xorm/xorm/blob/430fbe866a716bac8e5307d0c5222346f37cf8cf/engine.go#L340&#34;&gt;xorm本体&lt;/a&gt;に手を入れる必要がありそうだ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DatadogのLambda Integrationで気象データを送ってアラートを飛ばす</title>
          <link>https://www.sambaiz.net/article/152/</link>
          <pubDate>Mon, 05 Feb 2018 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/152/</guid>
          <description>&lt;p&gt;最近朝が寒くて布団から出るのがつらい。雨や雪が降っていたら尚更のこと、それならそれで現状を把握する必要がある。
そこで、無料から使える気象API &lt;a href=&#34;http://openweathermap.org/&#34;&gt;OpenWeatherMap&lt;/a&gt;のデータをdatadogに送って、特に寒い日や雨雪が降るような朝にはアラートを飛ばすことにした。&lt;/p&gt;

&lt;p&gt;インスタンスが立っていたらDataDog Agentの&lt;a href=&#34;https://docs.datadoghq.com/ja/guides/dogstatsd/&#34;&gt;DogStatsD&lt;/a&gt;経由で送ることができ、
そうでなければ通常は&lt;a href=&#34;https://docs.datadoghq.com/ja/api/#metrics-post&#34;&gt;API&lt;/a&gt;を呼ぶことになるんだけど、Lambdaでは、AWS Integrationを設定すると有効になる&lt;a href=&#34;https://docs.datadoghq.com/ja/integrations/awslambda/&#34;&gt;Lambda Integration&lt;/a&gt;によって
&lt;code&gt;MONITORING|unix_epoch_timestamp|value|metric_type|my.metric.name|#tag1:value,tag2&lt;/code&gt;のフォーマットでconsole.logするだけでメトリクスが送られるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const axios = require(&#39;axios&#39;);

const CITY = &#39;Shibuya&#39;;
const API_KEY = &#39;*****&#39;;
const WEATHER_API = `http://api.openweathermap.org/data/2.5/weather?q=${CITY}&amp;amp;units=metric&amp;amp;appid=${API_KEY}`;

const METRIC_COUNTER = &#39;counter&#39;;
const METRIC_GAUGE = &#39;gauge&#39;;

const monitor = (metricName, metricType, value, tags) =&amp;gt; {
  const unixEpochTimestamp = Math.floor(new Date().getTime());
  console.log(`MONITORING|${unixEpochTimestamp}|${value}|${metricType}|${metricName}|#${tags.join(&#39;,&#39;)}`);
};

exports.handler = async (event, context, callback) =&amp;gt; {
  const data = (await axios.get(WEATHER_API)).data
  const namePrefix = &#39;livinginfo.weather&#39;
  monitor(`${namePrefix}.temperature`, METRIC_GAUGE, data.main.temp, [])
  monitor(`${namePrefix}.rain`, METRIC_GAUGE, data.rain ? data.rain[&amp;quot;3h&amp;quot;] : 0, []);
  monitor(`${namePrefix}.snow`, METRIC_GAUGE, data.snow ? data.snow[&amp;quot;3h&amp;quot;] : 0, []);
  callback(null, &#39;done&#39;);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;送られた。
あとは0度を下回ったときのThreshold Alertや、前日比で下がったときのChange Alertなどを設定すれば良さそうだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/152.png&#34; alt=&#34;グラフ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ローカルでビルドしたimageをminikubeで使う</title>
          <link>https://www.sambaiz.net/article/151/</link>
          <pubDate>Thu, 01 Feb 2018 22:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/151/</guid>
          <description>&lt;pre&gt;&lt;code&gt;$ minikube version
minikube version: v0.25.0

$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;9&amp;quot;, GitVersion:&amp;quot;v1.9.2&amp;quot;, GitCommit:&amp;quot;5fa2db2bd46ac79e5e00a4e6ed24191080aa463b&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2018-01-18T21:11:08Z&amp;quot;, GoVersion:&amp;quot;go1.9.2&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;}

$ kubectl config current-context
minikube

$ minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;dockerコマンドがminikube VM内で動いているdocker daemonを参照するようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ minikube docker-env
export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
export DOCKER_HOST=&amp;quot;tcp://192.168.99.100:2376&amp;quot;
export DOCKER_CERT_PATH=&amp;quot;/Users/sambaiz/.minikube/certs&amp;quot;

$ eval $(minikube docker-env)
$ docker info --format &#39;{{json .Name}}&#39;
&amp;quot;minikube&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドするDockerfile。nginxが立ち上がるだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;何もタグを付けない(:latest)とcreate時にDockerレジストリからpullしにいって失敗してしまうため、タグ付きでビルドする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t my/myapp:1.0 .
$ docker images my/myapp
my/myapp   1.0   3f8a4339aadd   5 weeks ago   108 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;deploymentとservice。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: my/myapp:1.0
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
 name: my-app
 labels:
   app: my-app
spec:
 type: NodePort
 ports:
 - port: 80
   nodePort: 30001
 selector:
   app: my-app
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f deployment.yml 
$ kubectl create -f service.yml 
$ kubectl get pods
NAME                      READY     STATUS    RESTARTS   AGE
my-app-5f8c46bf95-xjvrg   1/1       Running   0          11s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドしたimageでpodが動いていることを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl $(minikube service my-app --url)
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
...
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Chromeで任意のscriptを読み込まれる前に差し替える</title>
          <link>https://www.sambaiz.net/article/150/</link>
          <pubDate>Thu, 01 Feb 2018 21:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/150/</guid>
          <description>&lt;p&gt;ChromeのDevToolsではSourcesからscriptを書き換えられるようになっているが、
一行目にbreakpointを挟んで更新するとそこで止まるので読み込まれる前に差し替えることができる。
ページの読み込み時に呼ばれるSDKやライブラリの影響範囲を調べたりデバッグしたりするのに便利。&lt;/p&gt;

&lt;p&gt;確認用jsとhtml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;console.log(&amp;quot;original&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&amp;quot;index.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;読み込み時に実行されるconsole.logの文章を変えた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/150.gif&#34; alt=&#34;差し替えているところ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す</title>
          <link>https://www.sambaiz.net/article/149/</link>
          <pubDate>Fri, 19 Jan 2018 09:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/149/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/pressly/goose&#34;&gt;Goose&lt;/a&gt;はGo製のDB Migrationツール。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/149.gif&#34; alt=&#34;mergeされるとボタンが出る&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/mysql-migration-slack&#34;&gt;コード&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;こんなリポジトリを作成し、各自ブランチを切ってGoose形式のup/downのSQLを書き、終わったらPullRequestを出す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;goose/
  .keep
.circleci/config.yml
create_test_table.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat create_test_table.sql
-- +goose Up
-- SQL in this section is executed when the migration is applied.
CREATE TABLE testtable (
  id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT,
  n INT NOT NULL,
  c VARCHAR (20) NOT NULL UNIQUE
);

-- +goose Down
-- SQL in this section is executed when the migration is rolled back.
DROP TABLE testtable;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事Approveされ、mergeされるとCircleCIが走り、
SQLをgooseディレクトリの中にバージョンを付けて移し、
SlackにpostMessageするエンドポイントにリクエストを飛ばす。&lt;/p&gt;

&lt;p&gt;ここでバージョンを作成することによって、並列で作業し、レビューなどの関係で適用順が前後しても修正する必要をなくしている。ただ、pushされる前に複数のブランチを連続でmergeする場合うまく動かないのでそれはなんとかする必要がある。&lt;/p&gt;

&lt;p&gt;CircleCI 2.0ではApprovalボタンが出せるんだけど、
アクセスしにいくのがちょっと面倒なのと、周知も兼ねてSlackに出したかったので使っていない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: 2
jobs:
  build:
    docker:
      - image: circleci/golang:1.8
    branches:
      only:
        - master
    steps:
      - checkout
      - run:
          name: Create new version
          command: |
            if [ -e *.sql ]; then
              VERSION=$(ls -U1 goose | wc -l | xargs expr 1 + | xargs printf %05d)
              FILENAME=$(find . -maxdepth 1 -name &amp;quot;*.sql&amp;quot; | head | xargs basename)
              mv ${FILENAME} goose/${VERSION}_${FILENAME}
              git config --global user.email &amp;quot;circleci@example.com&amp;quot;
              git config --global user.name &amp;quot;CircleCI&amp;quot;
              git add .
              git commit -m &amp;quot;version ${VERSION}&amp;quot;
              git push origin master
              COMMIT=$(git rev-parse HEAD)
              curl -H &amp;quot;Authorization: Basic $(echo -n &#39;foobar:dolphins&#39; | base64)&amp;quot; &amp;quot;https://*****/auth/message?version=${VERSION}&amp;amp;filename=${FILENAME}&amp;amp;commit=${COMMIT}&amp;quot;
            fi
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;goose/
  .keep
  00001_create_test_table.sql
.circleci/config.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Migrationボタンが押されると、まずボタンを消してRunning状態とし、
処理が終わったら結果を上書きするようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/148/&#34;&gt;SlackのInteractive messagesでボタンの入力を受け付ける - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;slackMessages.action(&#39;migrate&#39;, (payload, respond) =&amp;gt; {
  let replacement = payload.original_message; 
  delete replacement.attachments[0].actions; 
  replacement.attachments[0].text = `start migration by ${payload.user.name} at ${moment().format()}`;
  replacement.attachments[0].fields = [
    { 
       &amp;quot;title&amp;quot;: &amp;quot;State&amp;quot;,
       &amp;quot;value&amp;quot;: &amp;quot;Running&amp;quot;,
       &amp;quot;short&amp;quot;: false
    } 
  ]; 

  exec(
    // Attention to command injection
    `rm -rf ${repositoryName} &amp;amp;&amp;amp; git clone git@github.com:${repositoryPath}.git &amp;amp;&amp;amp; cd ${repositoryName}/goose &amp;amp;&amp;amp; goose mysql &amp;quot;${mySQLConf}&amp;quot; up`, 
    (err, stdout, stderr) =&amp;gt; {
      replacement.attachments[0].fields = [
        { 
          &amp;quot;title&amp;quot;: &amp;quot;Result&amp;quot;,
          &amp;quot;value&amp;quot;: (err || stderr) ? `${stderr || err}` : &amp;quot;Success&amp;quot;,
          &amp;quot;short&amp;quot;: false
        }
      ];
      respond(replacement);
    }
  );
  
  return replacement;
});
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SlackのInteractive messagesでボタンの入力を受け付ける</title>
          <link>https://www.sambaiz.net/article/148/</link>
          <pubDate>Tue, 16 Jan 2018 21:59:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/148/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://api.slack.com/interactive-messages&#34;&gt;Interactive messages&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/148.gif&#34; alt=&#34;ボタンを押す&#34; /&gt;&lt;/p&gt;

&lt;p&gt;まずはサーバーを用意する。コードは&lt;a href=&#34;https://github.com/sambaiz/node-slack-interactive-messages-sample&#34;&gt;ここ&lt;/a&gt;にあって、
Interactive messagesのハンドリングはSlack公式の&lt;a href=&#34;https://github.com/slackapi/node-slack-interactive-messages&#34;&gt;node-slack-interactive-messages&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.use(&#39;/slack&#39;, slackMessages.expressMiddleware());

slackMessages.action(&#39;question_button&#39;, (payload) =&amp;gt; {
  let replacement = payload.original_message;
  replacement.text =`${payload.user.name} likes ${payload.actions[0].value}`;
  delete replacement.attachments[0].actions;
  return replacement;
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ボタンの表示はattachmentsを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;web.chat.postMessage(channelId, &#39;Question&#39;, {
  attachments: [
    {
      text: &amp;quot;Which buttons do you like?&amp;quot;,
      color: &amp;quot;#f9a41b&amp;quot;,
      callback_id: &amp;quot;question_button&amp;quot;,
      actions: [
        {
          name: &amp;quot;primary_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          style: &amp;quot;primary&amp;quot;,
          text: &amp;quot;Primary&amp;quot;,
          value: &amp;quot;Primary Button&amp;quot;,
        },
        {
          name: &amp;quot;normal_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          text: &amp;quot;Normal&amp;quot;,
          value: &amp;quot;Normal Button&amp;quot;
        },
        {
          name: &amp;quot;danger_button&amp;quot;,
          type: &amp;quot;button&amp;quot;,
          style: &amp;quot;danger&amp;quot;,
          text: &amp;quot;Danger&amp;quot;,
          value: &amp;quot;Danger Button&amp;quot;,
          confirm: {
            title: &amp;quot;Really?&amp;quot;,
            text: &amp;quot;This is danger&amp;quot;,
            ok_text: &amp;quot;Yes&amp;quot;,
            dismiss_text: &amp;quot;No&amp;quot;
          }
        },
      ]
    }
  ]
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;外に公開する必要があるので、メッセージの送信のエンドポイントはBasic認証をかけてみた。
Interactive messagesのエンドポイントはVerification tokenが一致することを確認している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.use(bodyParser.urlencoded({ extended: false }));
app.all(&#39;/auth/*&#39;, (req, res, next) =&amp;gt; {
  const credentials = auth(req);
  if (!credentials || !check(credentials.name, credentials.pass)) {
    res.status(401).send(&#39;Unauthorized&#39;);
  } else {
    next();
  }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://*****.ngrok.com/auth/message -H &amp;quot;Authorization: Basic $(echo -n &#39;foobar:dolphins&#39; | base64)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://api.slack.com/apps&#34;&gt;Build&lt;/a&gt;からWorkspaceを選択してAppを作成し、
Appに紐づくBot Userを追加後、Install Appすると&lt;code&gt;Bot User OAuth Access Token&lt;/code&gt;
が表示されるので、これで&lt;a href=&#34;https://api.slack.com/methods/chat.postMessage&#34;&gt;postMessage&lt;/a&gt;し、Basic InformationのApp Credentialsにある&lt;code&gt;Verification Token&lt;/code&gt;をInteractive messagesのチェックに使う。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://tech.mercari.com/entry/2017/05/23/095500&#34;&gt;GolangでSlack Interactive Messageを使ったBotを書く - Mercari Engineering Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorBoardでsummaryやグラフを見る</title>
          <link>https://www.sambaiz.net/article/147/</link>
          <pubDate>Sun, 07 Jan 2018 21:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/147/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/146/&#34;&gt;TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;で読んだコードをTensorboardでみてみる。&lt;/p&gt;

&lt;p&gt;8888がJupyter、6006がTensorboard。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コードをuploadするかJupyterからterminalを開いてcloneしてくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# apt-get update
# apt-get install -y git wget
# git clone https://github.com/tensorflow/models.git
# cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logdirを指定して実行し、Tensorboardを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;flags.DEFINE_string(&amp;quot;save_path&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;Model output directory.&amp;quot;)
sv = tf.train.Supervisor(logdir=FLAGS.save_path)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;追記(2018-11-14): Supervisorはdeprecatedなので以下の記事でやっているようにMonitoredTrainingSessionを使うとよい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/198/&#34;&gt;Deep LearningのBatch Normalizationの効果をTensorFlowで確認する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;# tensorboard --logdir=models/tutorials/rnn/ptb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)&lt;/code&gt;による値がリアルタイムに表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard.png&#34; alt=&#34;summaryの推移&#34; /&gt;&lt;/p&gt;

&lt;p&gt;グラフのつながりや、各Operationの入出力やそのshapeを確認できる。
name_scopeで分けておくと見やすい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard3.png&#34; alt=&#34;グラフ全体&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/147-tensorboard2.png&#34; alt=&#34;Operationの入出力&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
          <link>https://www.sambaiz.net/article/146/</link>
          <pubDate>Wed, 03 Jan 2018 21:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/146/</guid>
          <description>

&lt;p&gt;TensorflowのRNN(Recurrent Neural Networks)の&lt;a href=&#34;https://www.tensorflow.org/tutorials/recurrent&#34;&gt;チュートリアル&lt;/a&gt;の&lt;a href=&#34;https://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/rnn/ptb/ptb_word_lm.py&#34;&gt;コード&lt;/a&gt;を読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。&lt;/p&gt;

&lt;h2 id=&#34;rnn-lstmとは&#34;&gt;RNN/LSTMとは&lt;/h2&gt;

&lt;p&gt;RNNは入力に対して出力のほかに情報を次のステップに渡すことで時系列データで学習できるようにするネットワーク。
展開すると同じネットワークに単語を一つずつ入れていくように表現できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/146-rnn.png&#34; alt=&#34;RNN&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これを単純にMLPで実装しようとすると逆誤差伝搬する際に過去の層にも伝搬させる(BPTT: Backpropagation through time)必要があり、
時間を遡るほど活性化関数の微分係数が再帰的に繰り返し掛けられるため勾配が消失や爆発しやすくなってしまう。
また、時系列データのうちに発火したいものと発火したくないものが混在している場合、同じ重みにつながっているため更新を打ち消しあってしまう入力/出力重み衝突という問題もある。&lt;/p&gt;

&lt;p&gt;これらを解決するのがLSTM(Long Short Term Memory networks)で、
勾配消失は活性化関数がxで重みが単位行列のニューロンのCEC(Constant Error Carousel)によって常に誤差に掛けられる係数を1にすることで防ぎ、
入力/出力重み衝突は必要な入出力を通したり不必要な情報は忘れさせるために値域(0,1)の値を掛けるinput gate、forget gate、output gateによって回避する。gateは入力と前回の出力によって制御される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/146-lstm.png&#34; alt=&#34;RNN&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TensorflowではいくつかLSTMの実装が用意されていて、&lt;code&gt;CudnnLSTM&lt;/code&gt;や&lt;code&gt;BasicLSTMCell&lt;/code&gt;、&lt;code&gt;LSTMBlockCell&lt;/code&gt;などがある。
&lt;a href=&#34;https://developer.nvidia.com/cudnn&#34;&gt;cuDNN&lt;/a&gt;というのはNVIDIAのCUDAのDNNライブラリのこと。
&lt;code&gt;LSTMBlockCell&lt;/code&gt;はもう少し複雑なLSTMで&lt;code&gt;BasicLSTMCell&lt;/code&gt;よりも速い。&lt;/p&gt;

&lt;h2 id=&#34;動かしてみる&#34;&gt;動かしてみる&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/tensorflow/models.git
$ cd models/tutorials/rnn/ptb/
$ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz
$ tar xvf simple-examples.tgz 
$ python3 -m venv env
$ . ./env/bin/activate
$ pip install numpy tensorflow
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 5534.452 speed: 894 wps
0.104 perplexity: 845.383 speed: 1277 wps
...
0.803 perplexity: 316.808 speed: 1195 wps
0.903 perplexity: 298.087 speed: 1205 wps
Epoch: 1 Train Perplexity: 283.825
Epoch: 1 Valid Perplexity: 182.132
Epoch: 2 Learning rate: 1.000
...
Epoch: 4 Learning rate: 1.000
...
Epoch: 5 Learning rate: 0.500
...
Epoch: 6 Learning rate: 0.250
...
Epoch: 7 Learning rate: 0.125
...
Epoch: 13 Learning rate: 0.002
...
Test Perplexity: 121.759
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;reader&#34;&gt;reader&lt;/h2&gt;

&lt;p&gt;readerにはテストがあったので、これを使って実際にどんな出力をしているか見てみる。&lt;/p&gt;

&lt;h3 id=&#34;ptb-raw-data&#34;&gt;ptb_raw_data&lt;/h3&gt;

&lt;p&gt;単語をIDに変換したものと語彙数が返る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def setUp(self):
  self._string_data = &amp;quot;\n&amp;quot;.join(
    [&amp;quot; hello there i am&amp;quot;,
     &amp;quot; rain as day&amp;quot;,
     &amp;quot; want some cheesy puffs ?&amp;quot;])

def testPtbRawData(self):
  tmpdir = tf.test.get_temp_dir()
  for suffix in &amp;quot;train&amp;quot;, &amp;quot;valid&amp;quot;, &amp;quot;test&amp;quot;:
    filename = os.path.join(tmpdir, &amp;quot;ptb.%s.txt&amp;quot; % suffix)
    with tf.gfile.GFile(filename, &amp;quot;w&amp;quot;) as fh:
    fh.write(self._string_data)
  # Smoke test
  output = reader.ptb_raw_data(tmpdir)
  print(&#39;output: {0}&#39;.format(output))
  # output: (
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # train
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # valid
  #   [5, 10, 6, 1, 8, 2, 4, 11, 9, 3, 7, 0], # test
  #   12 # vocabulary
  # )
  self.assertEqual(len(output), 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;print(word_to_id)
=&amp;gt; {&#39;?&#39;: 0, &#39;am&amp;lt;eos&amp;gt;&#39;: 1, &#39;as&#39;: 2, &#39;cheesy&#39;: 3, &#39;day&amp;lt;eos&amp;gt;&#39;: 4, &#39;hello&#39;: 5, &#39;i&#39;: 6, &#39;puffs&#39;: 7, &#39;rain&#39;: 8, &#39;some&#39;: 9, &#39;there&#39;: 10, &#39;want&#39;: 11}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ptb-producer&#34;&gt;ptb_producer&lt;/h3&gt;

&lt;p&gt;session.runする度に時系列順に[batch_size, num_steps]のTensorを出力する。
二つ目の返り値は一つ右にずらしたもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def testPtbProducer(self):
  raw_data = [
  # t=0↓  t=1↓
    4, 3, 2, 1, 0, 
    5, 6, 1, 1, 1, 
    1, 0, 3, 4, 1
  ]
  batch_size = 3
  num_steps = 2
  x, y = reader.ptb_producer(raw_data, batch_size, num_steps)
  with self.test_session() as session:
    coord = tf.train.Coordinator()
    tf.train.start_queue_runners(session, coord=coord)
    try:
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[4, 3], [5, 6], [1, 0]])
      self.assertAllEqual(yval, [[3, 2], [6, 1], [0, 3]])
      xval, yval = session.run([x, y])
      self.assertAllEqual(xval, [[2, 1], [1, 1], [3, 4]])
      self.assertAllEqual(yval, [[1, 0], [1, 1], [4, 1]])
    finally:
      coord.request_stop()
      coord.join()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実装はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()
x = tf.strided_slice(data, [0, i * num_steps],
                        [batch_size, (i + 1) * num_steps])
x.set_shape([batch_size, num_steps])
y = tf.strided_slice(data, [0, i * num_steps + 1],
                        [batch_size, (i + 1) * num_steps + 1])
y.set_shape([batch_size, num_steps])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;range_input_producerはその名の通りrangeのように0から値を生成するが、
Threadを調整する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Coordinator&#34;&gt;Coordinator&lt;/a&gt;を生成し、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/start_queue_runners&#34;&gt;start_queue_runners&lt;/a&gt;に渡す必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# example of range_input_producer
with self.test_session() as session:
  i = tf.train.range_input_producer(100, shuffle=False).dequeue()
  coord = tf.train.Coordinator()
  tf.train.start_queue_runners(session, coord=coord)
  try:
    print(session.run(i)) # =&amp;gt; 0
    print(session.run(i)) # =&amp;gt; 1
    print(session.run(i)) # =&amp;gt; 2
  finally:
    coord.request_stop()
    coord.join() # Wait for all the threads to terminate.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;

&lt;h3 id=&#34;入力の準備&#34;&gt;入力の準備&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup&#34;&gt;embedding_lookup&lt;/a&gt;で
embeddingから各stepの単語のものを抽出する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.device(&amp;quot;/cpu:0&amp;quot;):
  embedding = tf.get_variable(
    &amp;quot;embedding&amp;quot;, [vocab_size, size], dtype=data_type())
  # shape=(batch_size, num_steps, size), dtype=float32
  inputs = tf.nn.embedding_lookup(embedding, input_.input_data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;embedding_lookupの挙動はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# example of embedding_lookup
with tf.Session() as session:
  print(session.run(tf.nn.embedding_lookup(
    [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]],
    [[0,1,2], [3,4,5], [6,7,8]]
  ))) 
  # =&amp;gt; [[ 0  2  4]
  #     [ 6  8 10]
  #     [ 1  3  5]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;学習中の場合、過学習を防ぐためkeep_prob残してDropoutし、RNNのグラフを作り始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if is_training and config.keep_prob &amp;lt; 1:
  inputs = tf.nn.dropout(inputs, config.keep_prob)

output, state = self._build_rnn_graph(inputs, config, is_training)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rnnのグラフ&#34;&gt;RNNのグラフ&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;rnn_mode&lt;/code&gt;で実装を選べるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def _build_rnn_graph(self, inputs, config, is_training):
  if config.rnn_mode == CUDNN:
    return self._build_rnn_graph_cudnn(inputs, config, is_training)
  else:
    return self._build_rnn_graph_lstm(inputs, config, is_training)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cellは&lt;code&gt;LSTMBlockCell&lt;/code&gt;をDroopoutWrapperでラップしたもの。
さらにこれをCellの出力が次のCellの入力になる&lt;code&gt;MultiRNNCell&lt;/code&gt;で&lt;code&gt;num_layers&lt;/code&gt;重ねている。&lt;/p&gt;

&lt;p&gt;最初に&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell#zero_state&#34;&gt;zero_state&lt;/a&gt;の
初期状態から&lt;code&gt;num_steps&lt;/code&gt;まわして各stepでのoutputと最後のstateを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def _get_lstm_cell(self, config, is_training):
  if config.rnn_mode == BASIC:
    return tf.contrib.rnn.BasicLSTMCell(
      config.hidden_size, forget_bias=0.0, state_is_tuple=True,
      reuse=not is_training)
  if config.rnn_mode == BLOCK:
    return tf.contrib.rnn.LSTMBlockCell(
      config.hidden_size, forget_bias=0.0)
  raise ValueError(&amp;quot;rnn_mode %s not supported&amp;quot; % config.rnn_mode)

def _build_rnn_graph_lstm(self, inputs, config, is_training):
  def make_cell():
    cell = self._get_lstm_cell(config, is_training)
    if is_training and config.keep_prob &amp;lt; 1:
      cell = tf.contrib.rnn.DropoutWrapper(
        cell, output_keep_prob=config.keep_prob)
    return cell

  cell = tf.contrib.rnn.MultiRNNCell(
    [make_cell() for _ in range(config.num_layers)], state_is_tuple=True)

  self._initial_state = cell.zero_state(config.batch_size, data_type())
  state = self._initial_state

  # [shape=(batch_size, hidden_size) dtype=float32, ...]
  outputs = []
  with tf.variable_scope(&amp;quot;RNN&amp;quot;):
    for time_step in range(self.num_steps):
      if time_step &amp;gt; 0: tf.get_variable_scope().reuse_variables()
      (cell_output, state) = cell(inputs[:, time_step, :], state)
      outputs.append(cell_output)

  # shape=(batch_size * num_steps, hidden_size), dtype=float32
  output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])
  return output, state
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;コスト&#34;&gt;コスト&lt;/h3&gt;

&lt;p&gt;出力層を通したのをlogits(&lt;code&gt;log(p/(1-p)) (0≦p≦1)&lt;/code&gt;)のシーケンスとして扱い、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss&#34;&gt;sequence_loss&lt;/a&gt;で
それぞれ交差エントロピーを求め、その和をコストとする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;output, state = self._build_rnn_graph(inputs, config, is_training)

softmax_w = tf.get_variable(
    &amp;quot;softmax_w&amp;quot;, [size, vocab_size], dtype=data_type())
softmax_b = tf.get_variable(&amp;quot;softmax_b&amp;quot;, [vocab_size], dtype=data_type())
logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)
# shape=(batch_size, num_steps, vocab_size), dtype=float32
logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])

loss = tf.contrib.seq2seq.sequence_loss(
    # logits: [batch_size, sequence_length=num_steps, num_decoder_symbols=vocab_size] and dtype float
    # The logits correspond to the prediction across all classes at each timestep.
    logits,

    # targets: [batch_size, sequence_length=num_steps] and dtype int
    # The target represents the true class at each timestep.
    input_.targets,

    # weights: [batch_size, sequence_length] and dtype float
    # When using weights as masking, set all valid timesteps to 1 and all padded timesteps to 0
    tf.ones([self.batch_size, self.num_steps], dtype=data_type()),

    average_across_timesteps=False,
    average_across_batch=True)

# Update the cost
self._cost = tf.reduce_sum(loss)
self._final_state = state
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;勾配&#34;&gt;勾配&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/trainable_variables&#34;&gt;trainable_variables&lt;/a&gt;で
&lt;code&gt;trainable=True&lt;/code&gt;(つまり_lr以外)のvariableを取得し、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/gradients&#34;&gt;gradients&lt;/a&gt;で各variableに対しての勾配を求め、
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/clip_by_global_norm&#34;&gt;clip_by_global_norm&lt;/a&gt;で大きさを抑える。
これはgradient clippingと呼ばれる勾配爆発を防ぐための手法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if not is_training:
    return

self._lr = tf.Variable(0.0, trainable=False)
tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(self._cost, tvars),
                                    config.max_grad_norm)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# example of trainable_variables
with tf.Session() as session:
  a = tf.Variable(10.0, trainable=False)
  b = tf.Variable(20.0)
  c = tf.get_variable(&amp;quot;c&amp;quot;, [2, 2])
  d = tf.get_variable(&amp;quot;d&amp;quot;, [3, 3], trainable=False)
  session.run(tf.global_variables_initializer())
  print(session.run(tf.trainable_variables()))
  # [20.0, array([[ 1.10110056,  0.6373167 ],
  # [ 0.44673324, -0.11995673]], dtype=float32)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# example of gradients &amp;amp; clip_by_global_norm
with tf.Session() as session:
  xs = tf.Variable([10., 20., 30.])
  ys = [xs ** 2 + 123, xs * 5]
  grad = tf.gradients(ys,xs)
  session.run(tf.global_variables_initializer())
  print(session.run(grad)) # [20 + 5, 40 + 5, 60 + 5]

  list_clipped, global_norm = session.run(tf.clip_by_global_norm(grad,2))
  # global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))
  # = sqrt(25 ** 2 + 45 ** 2 + 65 ** 2)
  print(global_norm) # 82.9156

  # t_list[i] * clip_norm / max(global_norm, clip_norm)
  # = [25, 45, 65] * 2 / global_norm
  print(list_clipped) # [0.60302269, 1.08544087, 1.56785905]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;optimize&#34;&gt;Optimize&lt;/h3&gt;

&lt;p&gt;学習率_lrの&lt;code&gt;GradientDescenetOptimizer&lt;/code&gt;でoptimizeする。
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer#apply_gradients&#34;&gt;apply_gradients&lt;/a&gt;するたびに
global_stepがインクリメントされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;optimizer = tf.train.GradientDescentOptimizer(self._lr)
self._train_op = optimizer.apply_gradients(
  zip(grads, tvars),
  global_step=tf.train.get_or_create_global_step())

self._new_lr = tf.placeholder(
  tf.float32, shape=[], name=&amp;quot;new_learning_rate&amp;quot;)
self._lr_update = tf.assign(self._lr, self._new_lr)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;run-epoch&#34;&gt;run_epoch&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;session.run&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fetches = {
  &amp;quot;cost&amp;quot;: model.cost,
  &amp;quot;final_state&amp;quot;: model.final_state,
}
if eval_op is not None:
  fetches[&amp;quot;eval_op&amp;quot;] = eval_op

for step in range(model.input.epoch_size):
  feed_dict = {}
  for i, (c, h) in enumerate(model.initial_state):
    feed_dict[c] = state[i].c
    feed_dict[h] = state[i].h

  vals = session.run(fetches, feed_dict)
  cost = vals[&amp;quot;cost&amp;quot;]
  state = vals[&amp;quot;final_state&amp;quot;]

  costs += cost
  iters += model.input.num_steps

  if verbose and step % (model.input.epoch_size // 10) == 10:
    print(&amp;quot;%.3f perplexity: %.3f speed: %.0f wps&amp;quot; %
      (step * 1.0 / model.input.epoch_size, np.exp(costs / iters),
       iters * model.input.batch_size * max(1, FLAGS.num_gpus) /
       (time.time() - start_time)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;main&#34;&gt;main&lt;/h3&gt;

&lt;p&gt;起点。学習率はmax_epochまで初期値で、それ以後のepochでは指数的に減少させていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Supervisor&#34;&gt;Supervisor&lt;/a&gt;は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Threadを調整する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Coordinator&#34;&gt;Corrdinator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;variableを保存する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Saver&#34;&gt;Saver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;チェックポイントからセッションを再開する&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/SessionManager&#34;&gt;SessionManager&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のラッパー。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;追記(2018-07-01): Supervisorはdeprecatedになったので代わりにMonitoredSessionを使うべき。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/175/&#34;&gt;TensorFlowのMonitoredSession - sambaiz-net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;with tf.Graph().as_default():
  tf.train.import_meta_graph(metagraph)
  for model in models.values():
    model.import_ops()
  sv = tf.train.Supervisor(logdir=FLAGS.save_path)
  config_proto = tf.ConfigProto(allow_soft_placement=soft_placement)
  with sv.managed_session(config=config_proto) as session:
    for i in range(config.max_max_epoch):
      lr_decay = config.lr_decay ** max(i + 1 - config.max_epoch, 0.0)
      m.assign_lr(session, config.learning_rate * lr_decay)

      print(&amp;quot;Epoch: %d Learning rate: %.3f&amp;quot; % (i + 1, session.run(m.lr)))
      train_perplexity = run_epoch(session, m, eval_op=m.train_op,
                                    verbose=True)
      print(&amp;quot;Epoch: %d Train Perplexity: %.3f&amp;quot; % (i + 1, train_perplexity))
      valid_perplexity = run_epoch(session, mvalid)
      print(&amp;quot;Epoch: %d Valid Perplexity: %.3f&amp;quot; % (i + 1, valid_perplexity))

    test_perplexity = run_epoch(session, mtest)
    print(&amp;quot;Test Perplexity: %.3f&amp;quot; % test_perplexity)

    if FLAGS.save_path:
      print(&amp;quot;Saving model to %s.&amp;quot; % FLAGS.save_path)
      sv.saver.save(session, FLAGS.save_path, global_step=sv.global_step)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/154/&#34;&gt;TensorFlow/RNNで連続的な値を取る時系列データを予測する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3-%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0-TensorFlow%E3%83%BBKeras%E3%81%AB%E3%82%88%E3%82%8B%E6%99%82%E7%B3%BB%E5%88%97%E3%83%87%E3%83%BC%E3%82%BF%E5%87%A6%E7%90%86-%E5%B7%A3%E7%B1%A0-%E6%82%A0%E8%BC%94/dp/4839962510&#34;&gt;詳解 ディープラーニング ~TensorFlow・Kerasによる時系列データ処理~&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&#34;&gt;Understanding LSTM Networks &amp;ndash; colah&amp;rsquo;s blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/t_Signull/items/21b82be280b46f467d1b&#34;&gt;わかるLSTM ～ 最近の動向と共に - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://returnn.readthedocs.io/en/latest/tf_lstm_benchmark.html&#34;&gt;TensorFlow LSTM benchmark — RETURNN 1.0-dev documentation&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
          <link>https://www.sambaiz.net/article/145/</link>
          <pubDate>Sun, 24 Dec 2017 23:31:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/145/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/athena-admin&#34;&gt;https://github.com/sambaiz/athena-admin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/athena/pricing/&#34;&gt;料金&lt;/a&gt;はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。
データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだけど都度locationを指定して&lt;code&gt;ADD PARTITION&lt;/code&gt;を実行するのは大変。さらにスキーマを変更するのにも&lt;code&gt;ALTER TABLE ADD COLUMNS&lt;/code&gt;などはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。&lt;/p&gt;

&lt;p&gt;ではどうしようもないかというと&lt;code&gt;MSCK REPAIR TABLE&lt;/code&gt;というのがあって、
これはS3のObjectの&lt;code&gt;dt=YYYY-MM-DD&lt;/code&gt;のようなkey=valueのprefixを認識してパーティションを作るもの。作り直す際もこれ1クエリで終わる。それなら最初からそういう風に置けばよいのではというところだけど、勝手に&lt;code&gt;YYYY/MM/DD/HH&lt;/code&gt;のprefixを付けてしまうFirehoseのようなのもある。&lt;/p&gt;

&lt;p&gt;今回作った&lt;a href=&#34;https://github.com/sambaiz/athena-admin&#34;&gt;athena-admin&lt;/a&gt;は以下のような定義ファイルから、
パーティションのkey=valueのprefixが付くように置き換えたり、変更があったらmigrationする。
このファイルを書き換えるだけで基本的にどうにかなるし、バージョン管理すればテーブル定義の変更を追うことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;general&amp;quot;: {
    &amp;quot;athenaRegion&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;,
    &amp;quot;databaseName&amp;quot;: &amp;quot;aaaa&amp;quot;,
    &amp;quot;saveDefinitionLocation&amp;quot;: &amp;quot;s3://saveDefinitionBucket/aaaa.json&amp;quot;
  },
  &amp;quot;tables&amp;quot;: {
    &amp;quot;sample_data&amp;quot;: {
      &amp;quot;columns&amp;quot;: {
        &amp;quot;user_id&amp;quot;: &amp;quot;int&amp;quot;,
        &amp;quot;value&amp;quot;: {
          &amp;quot;score&amp;quot;: &amp;quot;int&amp;quot;,
          &amp;quot;category&amp;quot;: &amp;quot;string&amp;quot;
        } /* &amp;quot;struct&amp;lt;score:int,category:string&amp;gt;&amp;quot; のように書くこともできる */
      },
      &amp;quot;srcLocation&amp;quot;: &amp;quot;s3://src/location/&amp;quot;,
      &amp;quot;partition&amp;quot;: {
        &amp;quot;prePartitionLocation&amp;quot;: &amp;quot;s3://pre/partition/&amp;quot;, /* optional */
        &amp;quot;regexp&amp;quot;: &amp;quot;(\\d{4})/(\\d{2})/(\\d{2})/&amp;quot;, /* optional */
        &amp;quot;keys&amp;quot;: [
          {
            &amp;quot;name&amp;quot;: &amp;quot;dt&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,
            &amp;quot;format&amp;quot;: &amp;quot;{1}-{2}-{3}&amp;quot;, /* optional */
          }
        ]
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使い方はこんな感じ。使い方によっては&lt;code&gt;migrate()&lt;/code&gt;だけ呼ぶこともあると思う。
&lt;code&gt;replaceObjects()&lt;/code&gt;にはmatchedHandlerというのを渡すこともできて、
UTCからJSTに変換するといったこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install athena-admin
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const AthenaAdmin = require(&#39;athena-admin&#39;).AthenaAdmin;
const dbDef = require(&#39;./sampledatabase.json&#39;);
const admin = new AthenaAdmin(dbDef);
await admin.replaceObjects();
await admin.migrate();
await admin.partition();
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ApexでデプロイしたLambdaのトリガーをTerraformで管理する</title>
          <link>https://www.sambaiz.net/article/144/</link>
          <pubDate>Sun, 12 Nov 2017 22:23:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/144/</guid>
          <description>

&lt;p&gt;Apexでfunctionをデプロイするとトリガーが登録されないのであとで追加することになる。
これを手作業で行うこともできるのだけど、せっかくなのでアプリケーションと一緒に管理したい。
そんなときのために&lt;code&gt;terraform&lt;/code&gt;コマンドをラップした&lt;a href=&#34;http://apex.run/#managing-infrastructure&#34;&gt;apex infra&lt;/a&gt;が用意されている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/121/&#34;&gt;TerraformでVPCを管理するmoduleを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;functionsと同列にinfrastructureディレクトリを作成してtfファイルを置く。
その下に環境ごとのディレクトリを作成することもできて、その場合は&lt;code&gt;--env&lt;/code&gt;で指定した環境のものが使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- functions
- infrastructure
  main.tf
  variables.tf
  - modules
    - cloudwatch_schedule
      main.tf
      variables.tf
project.json 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;functionをデプロイするとそのARNが変数で取れるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex list --tfvars
apex_function_hello=&amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回設定するトリガーはCloudwatch Eventのスケジューリング。作成するリソースは以下の通り。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/cloudwatch_event_rule.html&#34;&gt;aws_cloudwatch_event_rule&lt;/a&gt;でイベントルール(今回はschedule)を作成&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/cloudwatch_event_target.html&#34;&gt;aws_cloudwatch_event_target&lt;/a&gt;でルールにターゲット(今回はLambda)を設定&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/lambda_permission.html&#34;&gt;aws_lambda_permission&lt;/a&gt;でルールに対象Lambdaをinvokeする権限を付ける&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ cat infrastructure/modules/cloudwatch_schefule/variables.tf
variable &amp;quot;lambda_function_name&amp;quot; {}
variable &amp;quot;lambda_function_arn&amp;quot; {}
variable &amp;quot;schedule_expression&amp;quot; {
    description = &amp;quot;cloudwatch schedule expression e.g. \&amp;quot;cron(0/5 * * * ? *)\&amp;quot;&amp;quot;
}

$ cat infrastructure/modules/cloudwatch_schefule/main.tf
resource &amp;quot;aws_cloudwatch_event_rule&amp;quot; &amp;quot;lambda&amp;quot; {
  name        = &amp;quot;lambda_rule_${var.lambda_function_name}&amp;quot;
  description = &amp;quot;invoke lambda ${var.lambda_function_name}&amp;quot;
  schedule_expression = &amp;quot;${var.schedule_expression}&amp;quot;
}
 
resource &amp;quot;aws_cloudwatch_event_target&amp;quot; &amp;quot;lambda&amp;quot; {
  target_id = &amp;quot;lambda_target_${var.lambda_function_name}&amp;quot;
  rule      = &amp;quot;${aws_cloudwatch_event_rule.lambda.name}&amp;quot;
  arn       = &amp;quot;${var.lambda_function_arn}&amp;quot;
}
 
resource &amp;quot;aws_lambda_permission&amp;quot; &amp;quot;lambda&amp;quot; {
  statement_id  = &amp;quot;AllowExecutionFromCloudWatch&amp;quot;
  action        = &amp;quot;lambda:InvokeFunction&amp;quot;
  function_name = &amp;quot;${aws_cloudwatch_event_target.lambda.arn}&amp;quot;
  principal     = &amp;quot;events.amazonaws.com&amp;quot;
  source_arn    = &amp;quot;${aws_cloudwatch_event_rule.lambda.arn}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat infrastructure/variables.tf 
variable &amp;quot;apex_function_names&amp;quot; {
    type=&amp;quot;map&amp;quot;
}
variable &amp;quot;apex_function_hello&amp;quot; {}

$ cat infrastructure/main.tf
terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;sambaiz-terraform&amp;quot;
    key    = &amp;quot;usetf.tfstate&amp;quot;
    region = &amp;quot;ap-northeast-1&amp;quot;
  }
}

module &amp;quot;hello_trigger&amp;quot; {
  source = &amp;quot;./modules/cloudwatch_schedule&amp;quot;
  lambda_function_name = &amp;quot;${var.apex_function_names[&amp;quot;hello&amp;quot;]}&amp;quot;
  lambda_function_arn = &amp;quot;${var.apex_function_hello}&amp;quot;
  schedule_expression = &amp;quot;cron(0/5 * * * ? *)&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;init&lt;/code&gt;してbackendを初期化してmoduleを準備する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra init
$ ls infrastructure/.terraform/modules/*****
main.tf		variables.tf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;plan&lt;/code&gt;するとこんな感じ。ApexによってfunctionのARNが渡っていることが分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra plan
+ module.hello_trigger.aws_cloudwatch_event_rule.lambda
    arn:                 &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    description:         &amp;quot;invoke lambda usetf_hello&amp;quot;
    is_enabled:          &amp;quot;true&amp;quot;
    name:                &amp;quot;lambda_rule_usetf_hello&amp;quot;
    schedule_expression: &amp;quot;cron(0/5 * * * ? *)&amp;quot;

+ module.hello_trigger.aws_cloudwatch_event_target.lambda
    arn:       &amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
    rule:      &amp;quot;lambda_rule_usetf_hello&amp;quot;
    target_id: &amp;quot;lambda_target_usetf_hello&amp;quot;

+ module.hello_trigger.aws_lambda_permission.lambda
    action:        &amp;quot;lambda:InvokeFunction&amp;quot;
    function_name: &amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;
    principal:     &amp;quot;events.amazonaws.com&amp;quot;
    source_arn:    &amp;quot;${aws_cloudwatch_event_rule.lambda.arn}&amp;quot;
    statement_id:  &amp;quot;AllowExecutionFromCloudWatch&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apply&lt;/code&gt;するとトリガーが登録される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex infra apply
$ apex logs hello
...
/aws/lambda/usetf_hello 2017-11-12T13:20:14.561Z	37e75818-c7ac-11e7-a333-111863808b13	processing event:
...
/aws/lambda/usetf_hello 2017-11-12T13:25:15.182Z	eb178941-c7ac-11e7-bde0-998ea9659640 processing event:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://dev.classmethod.jp/cloud/aws/ami-and-snapshot-delete-with-apex-and-terraform/&#34;&gt;ApexとTerraformでCloudWatch EventsによりInvokeされるLambda関数をデプロイする ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>JavaScriptのrequire/importの歴史</title>
          <link>https://www.sambaiz.net/article/143/</link>
          <pubDate>Sat, 11 Nov 2017 20:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/143/</guid>
          <description>

&lt;h2 id=&#34;scriptタグを並べる&#34;&gt;scriptタグを並べる&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;body&amp;gt;
&amp;lt;script src=&amp;quot;a.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;b.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先に書かれた&lt;code&gt;a.js&lt;/code&gt;で定義された内容は&lt;code&gt;b.js&lt;/code&gt;で読むことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat a.js 
const a = &#39;a is defined&#39;;
const divA = document.createElement(&#39;div&#39;);
divA.textContent = (typeof b !== &#39;undefined&#39;) ? b : &#39;b is undefined&#39;;
document.body.appendChild(divA);

$ cat b.js 
const b = &#39;b is defined&#39;;
const divB = document.createElement(&#39;div&#39;);
divB.textContent = (typeof a !== &#39;undefined&#39;) ? a : &#39;a is undefined&#39;;
document.body.appendChild(divB);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;依存が増えてくると順番を考えるのが大変。さらにグローバルな名前空間を汚染してしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b is undefined
a is defined
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;amdとcommonjs&#34;&gt;AMDとCommonJS&lt;/h2&gt;

&lt;p&gt;というのも、かつてのJSにはモジュールを読み込む仕組みがなかった。
そこで考えられたのがAMDやCommonJSというフォーマット。
AMD(Asynchronous module definition)は&lt;a href=&#34;http://requirejs.org/&#34;&gt;RequireJS&lt;/a&gt;によって提供される&lt;code&gt;require()&lt;/code&gt;で動的にscriptタグを埋める。CommonJSはNodeでもおなじみの&lt;code&gt;require()&lt;/code&gt;で、これにWebpackを通して一つのファイルにまとめておく。同じ関数名が使われているが全くの別物。&lt;/p&gt;

&lt;h2 id=&#34;es-modules&#34;&gt;ES Modules&lt;/h2&gt;

&lt;p&gt;今は言語仕様にECMAScript Modulesが追加され、普通に&lt;code&gt;import&lt;/code&gt;でモジュールを読み込めるようになったが、
対応ブラウザがまだ少ないこともあり基本的にはWebpackをかけることになる。
Nodeにも実装されつつあるがStableになるのは&lt;a href=&#34;https://nodejs.org/api/esm.html&#34;&gt;まだ先&lt;/a&gt;のようだ。&lt;/p&gt;

&lt;h2 id=&#34;requirejs-http-requirejs-org&#34;&gt;&lt;a href=&#34;http://requirejs.org/&#34;&gt;RequireJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;define()&lt;/code&gt;でモジュールを定義し、&lt;code&gt;require()&lt;/code&gt;で読み込む。
エントリーポイントは&lt;code&gt;data-main&lt;/code&gt;に指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/b.js
require([&#39;a&#39;], (a) =&amp;gt; {
  const divB = document.createElement(&#39;div&#39;);
  divB.textContent = a.a();
  document.body.appendChild(divB);
});

$ cat src/a.js
define({
  a: () =&amp;gt; &#39;a is defined&#39;
});

$ cat src/index.html
&amp;lt;body&amp;gt;
&amp;lt;script data-main=&amp;quot;b.js&amp;quot; src=&amp;quot;require.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CommonJSのモジュールを読み込もうとするとエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/c.js 
const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

$ cat src/d.js 
exports.d = () =&amp;gt; &#39;d is defined&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Uncaught Error: Module name &amp;quot;d&amp;quot; has not been loaded yet for context: _. Use require([])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RequireJSのNode版、&lt;a href=&#34;https://github.com/requirejs/r.js&#34;&gt;r.js&lt;/a&gt;でCommonJSのモジュールをAMDに変換することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g requirejs
$ r.js -convert src out
$ cat c.js 
define(function (require, exports, module) {const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

});

$ cat d.js 
define(function (require, exports, module) {exports.d = () =&amp;gt; &#39;d is defined&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、Webpackのようにコードを一つのjsファイルにbundleすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ r.js -o baseUrl=out name=b out=bundle.js optimize=none
$ cat bundle.js 
define(&#39;a&#39;,{
  a: () =&amp;gt; &#39;a is defined&#39;
});

define(&#39;d&#39;,[&#39;require&#39;,&#39;exports&#39;,&#39;module&#39;],function (require, exports, module) {exports.d = () =&amp;gt; &#39;d is defined&#39;;


});

define(&#39;c&#39;,[&#39;require&#39;,&#39;exports&#39;,&#39;module&#39;,&#39;d&#39;],function (require, exports, module) {const d = require(&#39;d&#39;);
exports.c = () =&amp;gt; {
  return d.d();
};

});

require([&#39;a&#39;,&#39;c&#39;], (a,c) =&amp;gt; {
  const divB = document.createElement(&#39;div&#39;);
  divB.textContent = a.a();
  document.body.appendChild(divB);

  const divB2 = document.createElement(&#39;div&#39;);
  divB2.textContent = c.c();
  document.body.appendChild(divB2);
});

define(&amp;quot;b&amp;quot;, function(){});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに&lt;code&gt;optimize=none&lt;/code&gt;を付けているのはES6のコードに対応していないため。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;If the source uses ES2015 or later syntax, please pass &amp;quot;optimize: &#39;none&#39;&amp;quot; to r.js and use an ES2015+ compatible minifier after running r.js. The included UglifyJS only understands ES5 or earlier syntax.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/guybedford/require-css&#34;&gt;guybedford/require-css&lt;/a&gt;を使うと
cssも依存に含めることができ、scriptタグと同様にstyleタグが動的に入る。&lt;/p&gt;

&lt;h2 id=&#34;webpack-https-webpack-js-org&#34;&gt;&lt;a href=&#34;https://webpack.js.org/&#34;&gt;Webpack&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;webpack.config.js&lt;/code&gt;の
&lt;code&gt;entry&lt;/code&gt;にエントリーポイント、
&lt;code&gt;output&lt;/code&gt;に出力場所、
&lt;code&gt;module&lt;/code&gt;にJS以外のファイルをbundleするloader、
&lt;code&gt;plugins&lt;/code&gt;に全体を処理するpluginの
設定を書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev webpack html-webpack-plugin
$ cat webpack.config.js 
const HtmlWebpackPlugin = require(&#39;html-webpack-plugin&#39;);
const webpack = require(&#39;webpack&#39;);
const path = require(&#39;path&#39;);

const config = {
  entry: &#39;./src/main.js&#39;,
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;bundle.js&#39;
  },
  module: {},
  plugins: [
    // new webpack.optimize.UglifyJsPlugin(),
    new HtmlWebpackPlugin({template: &#39;./src/index.html&#39;})
  ]
};

module.exports = config;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ES Modulesの記法を使っている。CommonJSにも対応しているが今はこちらが&lt;a href=&#34;https://webpack.js.org/api/module-methods/&#34;&gt;推奨&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js 
import { bar } from &#39;./foo&#39;;
const div = document.createElement(&#39;div&#39;);
div.textContent = bar();
document.body.appendChild(div);

$ cat src/foo.js 
export function bar() {
  return &#39;bar&#39;;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行するとこんな感じにbundleされる。実際はUglifyJsPluginによってもう少しサイズが小さくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ node_modules/.bin/webpack 
$ cat dist/index.html 
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;Test&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
  &amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;

$ z$ cat dist/bundle.js 
/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
...
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ([
/* 0 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

&amp;quot;use strict&amp;quot;;
Object.defineProperty(__webpack_exports__, &amp;quot;__esModule&amp;quot;, { value: true });
/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__foo__ = __webpack_require__(1);

const div = document.createElement(&#39;div&#39;);
div.textContent = Object(__WEBPACK_IMPORTED_MODULE_0__foo__[&amp;quot;a&amp;quot; /* bar */])();
document.body.appendChild(div);


/***/ }),
/* 1 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

&amp;quot;use strict&amp;quot;;
/* harmony export (immutable) */ __webpack_exports__[&amp;quot;a&amp;quot;] = bar;
function bar() {
  return &#39;bar&#39;;
};


/***/ })
/******/ ]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/webpack-contrib/css-loader&#34;&gt;css-loader&lt;/a&gt;でCSSをbundleする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev style-loader css-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CSS Moduleを有効にして、ほかの同名のクラスに影響を及ぼさないようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module: {
    rules: [
      {
        test: /\.css$/,
        use: [ 
          &#39;style-loader&#39;, 
          {
            loader: &#39;css-loader&#39;,
            options: {
              modules: true,
            }
          }
        ]
      }
    ]
  },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;importするとCSSに書かれたクラスと変換後の対応が取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js 
import { bar } from &#39;./foo&#39;;
import css from &#39;./style.css&#39;;

const div = document.createElement(&#39;div&#39;);
div.textContent = bar();
div.className = css[&#39;bg&#39;]; /* {&amp;quot;bg&amp;quot;:&amp;quot;_2T2hBh3FkCro4-BOuqaGg5&amp;quot;} */
document.body.appendChild(div);

$ cat src/style.css 
.bg {
  background-color: #22ee22;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じでbundleされている。動的にstyleタグが入るのは同じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat dist/bundle.js | grep &amp;quot;#22ee22&amp;quot;
exports.push([module.i, &amp;quot;._2T2hBh3FkCro4-BOuqaGg5 {\n  background-color: #22ee22;\n}\n&amp;quot;, &amp;quot;&amp;quot;]);
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>圧縮アルゴリズムZopfliとBrotli</title>
          <link>https://www.sambaiz.net/article/142/</link>
          <pubDate>Fri, 03 Nov 2017 15:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/142/</guid>
          <description>

&lt;p&gt;どちらもGoogleが開発した圧縮アルゴリズム。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppetter-lambda-starter-kit&lt;/a&gt;
の&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/issues/2&#34;&gt;issue&lt;/a&gt;に
現在使っているgzipと、Zopfli、Brotliを比較したデータが上がっていたので調べてみた。&lt;/p&gt;

&lt;h2 id=&#34;zopfli-https-github-com-google-zopfli&#34;&gt;&lt;a href=&#34;https://github.com/google/zopfli&#34;&gt;Zopfli&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;出力としてDeflateに対応している。&lt;/p&gt;

&lt;h3 id=&#34;deflate&#34;&gt;Deflate&lt;/h3&gt;

&lt;p&gt;LZ77(実際は改良版のLZSS)とハフマン記号による可逆圧縮アルゴリズム。
zip、zlib、gzip、pngなどで使われていて、これらはヘッダーやフッターが異なる。
LZSSはバイト列を見ていって同じ部分を発見したらそこを参照するように置き換えていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a b c a b c a b c d d d
=&amp;gt; a b c (距離3, 長さ6) d (距離１, 長さ2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このLZSSにあたる部分をZopfliはがんばってやるので圧縮時間が結構かかるがサイズは小さくなるらしい。
展開は通常のDeflate通り。上げてくれたデータを見ても大体そんな感じだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/google/zopfli
$ cd zopfli
$ make zopfli
$ ./zopfli aaaa
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;brotli-https-github-com-google-brotli&#34;&gt;&lt;a href=&#34;https://github.com/google/brotli&#34;&gt;Brotli&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;LZ77、ハフマン記号に加えて2nd order context modelingというのを使って圧縮する
Deflateではない可逆圧縮アルゴリズム。
Safari以外のモダンなブラウザで既に対応しているか対応しているところ。
対応している場合、&lt;code&gt;Accept-Encoding&lt;/code&gt;や&lt;code&gt;Content-Encoding&lt;/code&gt;ヘッダに含まれるのは&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Content-Encoding&#34;&gt;br&lt;/a&gt;。
圧縮率も展開時間もかなり良さそう。&lt;/p&gt;

&lt;p&gt;Nodeにもblotliのライブラリが&lt;a href=&#34;https://github.com/devongovett/brotli.js&#34;&gt;あって&lt;/a&gt;、
圧縮はEmscriptenで&lt;a href=&#34;https://github.com/google/brotli&#34;&gt;本家のC++コード&lt;/a&gt;から変換し、
展開は手で移植しているようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install blotli
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
const brotli = require(&#39;brotli&#39;);
const TARGET = process.env.TARGET;
const MODE = process.env.MODE;

const compress = () =&amp;gt; {
  const target = fs.readFileSync(TARGET);
  const compressed = brotli.compress(target, {
    quality: 11,
  });
  fs.writeFileSync(`${TARGET}.br`, compressed);
};

const decompress = () =&amp;gt; {
  const target = fs.readFileSync(TARGET);
  const decompressed = brotli.decompress(target);
  fs.writeFileSync(`${TARGET.replace(&#39;.br&#39;, &#39;&#39;)}`, decompressed);
};

(async () =&amp;gt; {
    if (MODE === &#39;decompress&#39;) {
        decompress();
    } else {
        compress();
    }
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただ、これで大きなファイルを圧縮しようとすると以下のようなエラーが出て失敗する。
設定を変えてコンパイルするのも面倒なので、圧縮はCLIでやることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ TARGET=headless_shell node compress.js 
Cannot enlarge memory arrays. Either (1) compile with  -s TOTAL_MEMORY=X  with X higher than the current value 318767104, (2) compile with  -s ALLOW_MEMORY_GROWTH=1  which adjusts the size at runtime but prevents some optimizations, (3) set Module.TOTAL_MEMORY to a higher value before the program runs, or if you want malloc to return NULL (0) instead of this abort, compile with  -s ABORTING_MALLOC=0 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リポジトリをcloneしてきてmake installする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/google/brotli.git
$ cd brotli
$ mkdir out &amp;amp;&amp;amp; cd out
$ ../configure-cmake
$ make
$ make test
$ make install
$ brotli --version
brotli 1.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトで最高レベル(11)で圧縮することもあり、かなり時間がかかる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ time brotli headless_shell
$ time brotli headless_shell

real	18m41.814s
user	18m6.485s
sys	0m7.906s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;gzipだと最高レベルで圧縮しても43MBまでのところ、33MBまで圧縮できた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;131M headless_shell
33M  headless_shell.br
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;展開はすぐ。むしろgzipより速い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ time TARGET=aaaa.br MODE=decompress node compress.js

real	0m5.850s
user	0m4.626s
sys	0m1.030s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということで、brotli対応版を出そうとしたが、Lambdaでdecompressしたら&lt;code&gt;JavaScript heap out of memory&lt;/code&gt;になってしまった。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/7shi/deflate&#34;&gt;Deflate&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/jkr_2255/items/f3dfdf08267f2a8b590a&#34;&gt;Zopfliで高圧縮gzip・PNGほか - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Redashでデータを可視化する</title>
          <link>https://www.sambaiz.net/article/141/</link>
          <pubDate>Mon, 23 Oct 2017 23:59:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/141/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/getredash/redash&#34;&gt;Redash&lt;/a&gt;はOSSのデータ可視化ツール。
BIツールのようにパラメータを変えながら指標を探っていくというよりは、分かっている指標を見るのに使うイメージ。
比較的機能が少ない分処理がわかりやすく、
クエリが自動生成されないため時間がかかるものを実行する前にある程度気づけるのが良いと思う。&lt;/p&gt;

&lt;p&gt;docker-composeで立ち上げることもできるけど、
AWSの各リージョンに&lt;a href=&#34;https://redash.io/help-onpremise/setup/setting-up-redash-instance.html&#34;&gt;AMIが用意されている&lt;/a&gt;のでそれで立ち上げる。&lt;/p&gt;

&lt;p&gt;sshで入って以下のようなのを必要に応じて設定する。
メールを送る場合はSESでメールアドレスをVerifyしてやるのが簡単。
GSuiteを使っている場合、OAuthのClientID、Secretを発行しドメインを登録するとそれで認証できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh ubuntu@*****
$ sudo vi /opt/redash/.env
export REDASH_MAIL_SERVER=&amp;quot;email-smtp.us-east-1.amazonaws.com&amp;quot;
export REDASH_MAIL_USE_TLS=&amp;quot;true&amp;quot;
export REDASH_MAIL_USERNAME=&amp;quot;*****&amp;quot;
export REDASH_MAIL_PASSWORD=&amp;quot;*****&amp;quot;
export REDASH_MAIL_DEFAULT_SENDER=&amp;quot;*****&amp;quot; # Email address to send from

export REDASH_GOOGLE_CLIENT_ID=&amp;quot;&amp;quot;
export REDASH_GOOGLE_CLIENT_SECRET=&amp;quot;&amp;quot;

$ cd /opt/redash/current
$ sudo -u redash bin/run ./manage.py org set_google_apps_domains {{domains}}
$ sudo supervisorctl restart all
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTTPS対応するのに&lt;code&gt;/etc/nginx/sites-available/redash&lt;/code&gt;を編集する。crtとkeyの場所は変える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;upstream rd_servers {
  server 127.0.0.1:5000;
}

server {

  server_tokens off;

  listen 80 default;

  access_log /var/log/nginx/rd.access.log;

  gzip on;
  gzip_types *;
  gzip_proxied any;

  location /ping {
    proxy_set_header Host $http_host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_pass       http://rd_servers;
  }
  
  location / {
    return 301 https://$host$request_uri; 
  }
}

server {
  listen 443 ssl;

  # Make sure to set paths to your certificate .pem and .key files.
  ssl on;
  ssl_certificate /path-to/cert.pem; # or crt
  ssl_certificate_key /path-to/cert.key;

  # Specifies that we don&#39;t want to use SSLv2 (insecure) or SSLv3 (exploitable)
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
  # Uses the server&#39;s ciphers rather than the client&#39;s
  ssl_prefer_server_ciphers on;
  # Specifies which ciphers are okay and which are not okay. List taken from https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html
  ssl_ciphers &amp;quot;EECDH+AESGCM:EDH+AESGCM:ECDHE-RSA-AES128-GCM-SHA256:AES256+EECDH:DHE-RSA-AES128-GCM-SHA256:AES256+EDH:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4&amp;quot;;

  access_log /var/log/nginx/redash.access.log;

  gzip on;
  gzip_types *;
  gzip_proxied any;

  location / {
    proxy_set_header Host $http_host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_pass       http://rd_servers;
    proxy_redirect   off;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;諸々のデータはローカルで動いているPostgreSQLに入っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redash-# \d
                       List of relations
 Schema |               Name               |   Type   | Owner  
--------+----------------------------------+----------+--------
 public | access_permissions               | table    | redash
 public | access_permissions_id_seq        | sequence | redash
 public | alembic_version                  | table    | redash
 public | alert_subscriptions              | table    | redash
 public | alert_subscriptions_id_seq       | sequence | redash
 public | alerts                           | table    | redash
 public | alerts_id_seq                    | sequence | redash
 public | api_keys                         | table    | redash
 public | api_keys_id_seq                  | sequence | redash
 public | changes                          | table    | redash
 public | changes_id_seq                   | sequence | redash
 public | dashboards                       | table    | redash
 public | dashboards_id_seq                | sequence | redash
 public | data_source_groups               | table    | redash
 public | data_source_groups_id_seq        | sequence | redash
 public | data_sources                     | table    | redash
 public | data_sources_id_seq              | sequence | redash
 public | events                           | table    | redash
 public | events_id_seq                    | sequence | redash
 public | groups                           | table    | redash
 public | groups_id_seq                    | sequence | redash
 public | notification_destinations        | table    | redash
 public | notification_destinations_id_seq | sequence | redash
 public | organizations                    | table    | redash
 public | organizations_id_seq             | sequence | redash
 public | queries                          | table    | redash
 public | queries_id_seq                   | sequence | redash
 public | query_results                    | table    | redash
 public | query_results_id_seq             | sequence | redash
 public | query_snippets                   | table    | redash
 public | query_snippets_id_seq            | sequence | redash
 public | users                            | table    | redash
 public | users_id_seq                     | sequence | redash
 public | visualizations                   | table    | redash
 public | visualizations_id_seq            | sequence | redash
 public | widgets                          | table    | redash
 public | widgets_id_seq                   | sequence | redash
(37 rows)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なので&lt;a href=&#34;https://redash.io/help-onpremise/misc/backup-your-redash-database-and-restore-it-on-a-different-server.html&#34;&gt;他の環境に移すとき&lt;/a&gt;はこのdumpを取ってリストアする。バックアップを取っておくと良い。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-start.png&#34; alt=&#34;最初の画面&#34; /&gt;&lt;/p&gt;

&lt;p&gt;データソースを登録する。MySQLやRedshift、AthenaやBigQueryのほかにHive、ElasticSearchなども選べる。
今回はMySQL(Amazon RDS)を選択した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-datasource.png&#34; alt=&#34;データソースの登録&#34; /&gt;&lt;/p&gt;

&lt;p&gt;適当なデータをいれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const mysql = require(&#39;mysql&#39;);
const connection = mysql.createConnection({
  host     : &#39;*****&#39;,
  user     : &#39;*****&#39;,
  password : &#39;*****&#39;,
  database : &#39;*****&#39;
});

const query = (connection, query, params) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {
    connection.query(query, params, (error, results, fields) =&amp;gt; {
      if (error) reject(error);
      resolve(results);
    });
  });
};

(async () =&amp;gt; {
  connection.connect();

  await query(connection,
    `DROP TABLE IF EXISTS hoge`
  );

  await query(connection, 
    `CREATE TABLE hoge (
      id int,
      fuga_id int,
      piyo_id int,
      value int,
      created_at datetime
    )`
  );

  for (let i = 0; i &amp;lt; 100; i++) {
    console.log(i);
    await query(connection,
      `INSERT INTO hoge SET ?`,
      {
       id: i, 
       fuga_id: Math.floor(Math.random() * 3), 
       piyo_id: Math.floor(Math.random() * 10),
       value: Math.floor(Math.random() * 100),
       created_at: new Date(),
      }
    );
  };

  connection.end();
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリを登録する。エディタがあってフォーマットもしてくれる。
毎分や特定の時刻に実行するスケジュール機能もあるので、
重いクエリも事前に実行しておいて必要なときにすぐに見られるようにすることができる。
&lt;code&gt;{{name}}&lt;/code&gt;のようにパラメータを入れることもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-query.png&#34; alt=&#34;クエリの登録&#34; /&gt;&lt;/p&gt;

&lt;p&gt;実行して得られたデータからChartを作る。データはCSVでダウンロードもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-visualization.png&#34; alt=&#34;Chart&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このChartをDashboardに貼る。
パラメータがある場合は入力するフォームが出るので、クエリを書かない人に使ってもらうこともできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-dashboard.png&#34; alt=&#34;Dashbord&#34; /&gt;&lt;/p&gt;

&lt;p&gt;あとは簡単なAlertも登録することができて、
飛ばす先はSettingsのALERT DISTINATIONSに
SlackのWebhookなどを設定できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-alert.png&#34; alt=&#34;Alert&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/141-slack.png&#34; alt=&#34;Slackに飛ぶメッセージ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ApexでLambdaをデプロイする</title>
          <link>https://www.sambaiz.net/article/140/</link>
          <pubDate>Sun, 22 Oct 2017 16:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/140/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/apex/apex&#34;&gt;Apex&lt;/a&gt;でLambdaをデプロイする。
とても簡単に使えるし、変なこともしないので良い感じ。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Serverless Frameworkだとeventの設定までカバーできてより便利。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/155/&#34;&gt;Serverless FrameworkでLambdaをデプロイする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;インストール。ダウンロードして実行できるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;IAMFullAccess&lt;/li&gt;
&lt;li&gt;AWSLambdaFullAccess&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を付けたIAMのプロファイルを登録しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws configure --profile apex
$ aws configure list --profile apex
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                     apex           manual    --profile
access_key     ****************OVGQ shared-credentials-file    
secret_key     ****************oi5t shared-credentials-file    
    region           ap-northeast-1      config-file    ~/.aws/config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apex init&lt;/code&gt;してnameとdescriptionを入れるとIAMが登録され、
ディレクトリ構造が作られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex init --profile apex
Project name: try-apex
Project description: test  
[+] creating IAM try-apex_lambda_function role
[+] creating IAM try-apex_lambda_logs policy
[+] attaching policy to lambda_function role.
[+] creating ./project.json
[+] creating ./functions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;package.jsonで環境変数などの設定ができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls -R
functions	project.json

./functions:
hello

./functions/hello:
index.js

$ cat project.json 
{
  &amp;quot;name&amp;quot;: &amp;quot;try-apex&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;test&amp;quot;,
  &amp;quot;memory&amp;quot;: 128,
  &amp;quot;timeout&amp;quot;: 5,
  &amp;quot;role&amp;quot;: &amp;quot;arn:aws:iam::524580158183:role/try-apex_lambda_function&amp;quot;,
  &amp;quot;environment&amp;quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;apex deploy&lt;/code&gt;するとlambdaが作られる。&lt;code&gt;--dry-run&lt;/code&gt;もできる。
バージョン管理されているので&lt;code&gt;rollback&lt;/code&gt;もできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex deploy hello --profile apex
   • creating function         env= function=hello
   • created alias current     env= function=hello version=1
   • function created          env= function=hello name=try-apex_hello version=1

$ apex list

  hello
    runtime: nodejs6.10
    memory: 128mb
    timeout: 5s
    role: arn:aws:iam::*****:role/try-apex_lambda_function
    handler: index.handle
    arn: arn:aws:lambda:ap-northeast-1:*****:function:try-apex_hello:current
    aliases: current@v1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マネジメントコンソールではここでバージョンが確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/140.png&#34; alt=&#34;バージョンの確認&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;apex invoke&lt;/code&gt;で実行。標準入力でイベントを渡せる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apex invoke hello
{&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パッケージに含めないファイルは.apexignoreに書く。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsのコードをPrettierでフォーマットしてESLintにかける</title>
          <link>https://www.sambaiz.net/article/139/</link>
          <pubDate>Thu, 19 Oct 2017 00:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/139/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/prettier/prettier&#34;&gt;Prettier&lt;/a&gt;はJSやTSのコードフォーマッタで、
ReactやBabel、Yarnなどの開発にも使われている。&lt;/p&gt;

&lt;p&gt;今回はPrettierでフォーマットしたものを
&lt;code&gt;eslint --fix&lt;/code&gt;する&lt;a href=&#34;https://github.com/prettier/prettier-eslint-cli&#34;&gt;prettier-eslint-cli&lt;/a&gt;を使う。役割が被っているけどPrettierは&lt;code&gt;eslint --fix&lt;/code&gt;よりも強力にフォーマットしてくれるようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git init
$ yarn add --dev eslint eslint-config-google prettier-eslint-cli husky lint-staged
$ cat .eslintrc.js 
module.exports = {
    &amp;quot;extends&amp;quot;: &amp;quot;google&amp;quot;,
    &amp;quot;parserOptions&amp;quot;: {
    	&amp;quot;ecmaVersion&amp;quot;: 2017,
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;対象のコードはこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat src/main.js
/**
 * hoge function
 */
function hoge() {

  const f = (aaaaaaaaaaaaaaa, bbbbbbbbbb, ccccccccc, dddddddddddd, eeeeeeeeeeeeee) =&amp;gt;
    console.log(&#39;a&#39;);


  f(1, 2, 3, 4, 5);
}


hoge();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prettierのドキュメントでも紹介されているように&lt;a href=&#34;https://github.com/okonet/lint-staged&#34;&gt;lint-staged&lt;/a&gt;を使うとCommit時にフォーマットし、Lintをかけることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;precommit&amp;quot;: &amp;quot;lint-staged&amp;quot;,
    &amp;quot;lint&amp;quot;: &amp;quot;eslint src&amp;quot;,
    &amp;quot;format&amp;quot;: &amp;quot;prettier-eslint --write \&amp;quot;src/**/*.js\&amp;quot;&amp;quot;
  },
  &amp;quot;lint-staged&amp;quot;: {
    &amp;quot;*.js&amp;quot;: [
      &amp;quot;prettier-eslint --write&amp;quot;,
      &amp;quot;eslint&amp;quot;,
      &amp;quot;git add&amp;quot;
    ]
  },
  &amp;quot;devDependencies&amp;quot;: {
    &amp;quot;eslint&amp;quot;: &amp;quot;^4.9.0&amp;quot;,
    &amp;quot;eslint-config-google&amp;quot;: &amp;quot;^0.9.1&amp;quot;,
    &amp;quot;husky&amp;quot;: &amp;quot;^0.14.3&amp;quot;,
    &amp;quot;lint-staged&amp;quot;: &amp;quot;^4.2.3&amp;quot;,
    &amp;quot;prettier-eslint-cli&amp;quot;: &amp;quot;^4.4.0&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ git commit -m &amp;quot;test&amp;quot;
husky &amp;gt; npm run -s precommit (node v8.2.1)

 ✔ Running tasks for *.js
[master e325ea3] test

$ cat src/main.js 
/**
 * hoge function
 */
function hoge() {
  const f = (
    aaaaaaaaaaaaaaa,
    bbbbbbbbbb,
    ccccccccc,
    dddddddddddd,
    eeeeeeeeeeeeee
  ) =&amp;gt; console.log(&#39;a&#39;);

  f(1, 2, 3, 4, 5);
}

hoge();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prettierは&lt;code&gt;eslint --fix&lt;/code&gt;で修正されないmax-lenも良い感じにしてくれる。
なのでESLintのフォーマットに関するところはほとんど修正いらないはず。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git commit -m &amp;quot;test&amp;quot;
husky &amp;gt; npm run -s precommit (node v8.2.1)

 ❯ Running tasks for *.js
   ✖ eslint --fix
     git add
✖ eslint --fix found some errors. Please fix them and try committing again.

***/src/main.js
  5:1  error  Line 5 exceeds the maximum line length of 80  max-len

✖ 1 problem (1 error, 0 warnings)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>確率分布(二項分布/ポアソン分布/正規分布)</title>
          <link>https://www.sambaiz.net/article/138/</link>
          <pubDate>Sun, 15 Oct 2017 01:53:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/138/</guid>
          <description>

&lt;h2 id=&#34;二項分布&#34;&gt;二項分布&lt;/h2&gt;

&lt;p&gt;確率pで起きる事象がn回の試行でx回起きる確率関数の離散的確率分布。記号で書くと&lt;code&gt;B[n,p]&lt;/code&gt;。
期待値は&lt;code&gt;np&lt;/code&gt;で、分散は&lt;code&gt;np(1-p)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-binormal-distribution.png&#34; alt=&#34;二項分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-bi-graph.png&#34; alt=&#34;二項分布のグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ポアソン分布&#34;&gt;ポアソン分布&lt;/h2&gt;

&lt;p&gt;二項分布において、起きる確率pが少なく、試行回数nが多いときに代わりに適用できる確率分布。
具体的にはnが50ぐらいだったら、npが5以下のとき。
試行回数が多いとき、二項分布だとCの部分の計算が困難になってしまうのを解決できる。
期待値も分散も&lt;code&gt;np=μ&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-poisson.png&#34; alt=&#34;ポアソン分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-poisson-graph.png&#34; alt=&#34;ポアソン分布のグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;正規分布&#34;&gt;正規分布&lt;/h2&gt;

&lt;p&gt;正規分布は平均値&lt;code&gt;μ&lt;/code&gt;を最大値とし、左右対称な釣鐘型をしている連続的確率分布。記号で書くと&lt;code&gt;N[μ,σ^2]&lt;/code&gt;。
二項分布のnを大きくしていくと正規分布に近づいていく。
p=0.5であれば、n=10の二項分布&lt;code&gt;B[10,0.5]&lt;/code&gt;でも良い近似が得られる(&lt;code&gt;N[5,2.5]&lt;/code&gt;)。
逆にnが大きな二項分布の近似として正規分布を使うこともできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-normal.png&#34; alt=&#34;正規分布の式&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-normal-graph.png&#34; alt=&#34;正規分布のグラプ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;N[0,1]&lt;/code&gt;の正規分布を標準正規分布と呼ぶ。
ある正規分布に従う確率変数xを、標準正規分布に従うzに変換することを標準化変換という。
標準正規分布にすると正規分布表の値を使って計算できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/137-std.png&#34; alt=&#34;標準化変換&#34; /&gt;&lt;/p&gt;

&lt;p&gt;また、平均&lt;code&gt;μ&lt;/code&gt;、分散&lt;code&gt;σ^2&lt;/code&gt;の任意な分布からn個の標本をとったときの平均は&lt;code&gt;N[μ, σ^2/n]&lt;/code&gt;に従う。
言い換えれば、標本の平均と真の平均の誤差は&lt;code&gt;N[0, σ^2/n]&lt;/code&gt;。これを中心極限定理という。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://ruby.kyoto-wu.ac.jp/~konami/Text/&#34;&gt;統計学入門&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Lpノルムと正則化</title>
          <link>https://www.sambaiz.net/article/137/</link>
          <pubDate>Thu, 12 Oct 2017 23:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/137/</guid>
          <description>

&lt;h2 id=&#34;ノルムとは&#34;&gt;ノルムとは&lt;/h2&gt;

&lt;p&gt;ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;p(av) = |a| p(v)&lt;/code&gt;: スケーラブル&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(u + v) ≦ p(u) + p(v)&lt;/code&gt;: 三角不等式を満たす&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(v) ≧ 0&lt;/code&gt;: 負の値を取らない&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p(v) = 0 &amp;lt;=&amp;gt; v=0&lt;/code&gt;: 距離が0 &amp;lt;=&amp;gt; 零ベクトル&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下の式で表されるノルムをLpノルムと呼ぶ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-norm.png&#34; alt=&#34;Lpノルム&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;l1ノルム-マンハッタン距離&#34;&gt;L1ノルム(マンハッタン距離)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-l1norm.png&#34; alt=&#34;L1ノルムの距離1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;絶対値の和。座標軸方向にしか移動できない縛りでの距離。
StreetとAvenueが格子状になっているマンハッタンではタクシーが移動する距離はL1ノルムのようになる。&lt;/p&gt;

&lt;h3 id=&#34;l2ノルム-ユークリッド距離&#34;&gt;L2ノルム(ユークリッド距離)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-l2norm.png&#34; alt=&#34;L2ノルムの距離1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2乗の和の平方根。普通の距離。&lt;/p&gt;

&lt;h2 id=&#34;正則化-regularization&#34;&gt;正則化(regularization)&lt;/h2&gt;

&lt;p&gt;機械学習で過学習を防ぐためのもの。
Lp正則化は重みのLpノルムをp乗してハイパーパラメータΛを掛けたものを正則化項として
素の損失関数に加える。これを最小化するのだから重みがペナルティとしてはたらく。
L1正則化ではΛが大きければいくつかの重みが0になって次元削減できるが、
L2正則化では重みに比例して小さくなるだけ。それぞれLasso回帰、Ridge回帰ともいう。
また、これらを割合で足して使うElasticNetというものもある。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Norm_(mathematics)&#34;&gt;Norm (mathematics) - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tjo.hatenablog.com/entry/2015/03/03/190000&#34;&gt;RでL1 / L2正則化を実践する - 六本木で働くデータサイエンティストのブログ&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OpenID ConnectのIDトークンの内容と検証</title>
          <link>https://www.sambaiz.net/article/136/</link>
          <pubDate>Mon, 09 Oct 2017 20:01:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/136/</guid>
          <description>

&lt;p&gt;OpenID Connectは認可(AuthoriZation)のプロトコルであるOAuth 2.0を正しく認証(AutheNtication)に使うためのプロトコル。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://openid-foundation-japan.github.io/openid-connect-core-1_0.ja.html&#34;&gt;OpenID Connect Core 1.0(日本語訳)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/48/&#34;&gt;OAuth2.0のメモ - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;OpenID ConnectではOAuthのアクセストークンに加えて
Issuer(IdP)によって署名されたJWT(JSON Web Token)形式のIDトークンも返す。
このIDトークンの署名を検証し、含まれるIssuerとクライアントの情報を参照することで
OAuthのImplicit flowでのトークン置き換え攻撃を防ぐことができる。&lt;/p&gt;

&lt;h2 id=&#34;jwt-idトークン&#34;&gt;JWT/IDトークン&lt;/h2&gt;

&lt;p&gt;JWTは&lt;a href=&#34;https://tools.ietf.org/html/rfc7519&#34;&gt;RFC7519&lt;/a&gt;で定義されている、
パーティ間で安全にClaim(エンドユーザーのようなエンティティの情報)を受け渡すための表現方法。
JSONにエンコードしたClaimは、JOSE(Javascript Object Signing and Encryption)のサブセットである&lt;a href=&#34;https://tools.ietf.org/html/rfc7515&#34;&gt;JWS&lt;/a&gt;(JSON Web Signature)のペイロードとして署名を付与されるか、&lt;a href=&#34;https://tools.ietf.org/html/rfc7519&#34;&gt;JWE&lt;/a&gt;(JSON Web Encryption)で暗号化される。
以下のJWTはJWSのもの。&lt;/p&gt;

&lt;p&gt;JWSには&lt;code&gt;(ヘッダ).(ペイロード).(署名)&lt;/code&gt;の文字列で表現されるCompact SerializationとJSONで表現されるJSON Serializationがあるが、JWTではCompact Serializationを使う。&lt;/p&gt;

&lt;p&gt;ヘッダには署名に使うアルゴリズム&lt;code&gt;alg&lt;/code&gt;が含まれる。
JWTを受け取った際、不正なalgになっていないかチェックする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
  &amp;quot;kid&amp;quot;: &amp;quot;5b0924f6f83c719514987954cf66683b370677d4&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ペイロードには以下のようなClaimが含まれる。これ以外のClaimを含めることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;iss&amp;quot;: &amp;quot;https://server.example.com&amp;quot;, # IssuerのIdentifier。httpsのURL
    &amp;quot;sub&amp;quot;: &amp;quot;24400320&amp;quot;, # Subject Identifier。Issuerでユニークなエンドユーザーの識別子。
    &amp;quot;aud&amp;quot;: &amp;quot;s6BhdRkqt3&amp;quot;, # audience。OAuth2.0のclient_id
    &amp;quot;nonce&amp;quot;: &amp;quot;n-0S6_WzA2Mj&amp;quot;, # リクエストで送ったのがそのまま返ってくる。リプレイ攻撃を防ぐため
    &amp;quot;exp&amp;quot;: 1311281970, # IDトークンの有効期限。時間はすべてUNIXエポック秒
    &amp;quot;iat&amp;quot;: 1311280970, # IDトークンの発行時刻
    &amp;quot;auth_time&amp;quot;: 1311280969 # エンドユーザーの認証時刻
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;idトークンを取得する&#34;&gt;IDトークンを取得する&lt;/h2&gt;

&lt;p&gt;Googleの&lt;a href=&#34;https://developers.google.com/identity/protocols/OpenIDConnect&#34;&gt;OAuth 2.0 API&lt;/a&gt;はOpenID Connectに対応している。これのIDトークンを取得する。&lt;/p&gt;

&lt;p&gt;エンドポイント等は&lt;a href=&#34;https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig&#34;&gt;OpenID Connect Discovery 1.0&lt;/a&gt;の
&lt;code&gt;/.well-known/openid-configuration&lt;/code&gt;で取得できるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://accounts.google.com/.well-known/openid-configuration | jq
{
  &amp;quot;issuer&amp;quot;: &amp;quot;https://accounts.google.com&amp;quot;,
  &amp;quot;authorization_endpoint&amp;quot;: &amp;quot;https://accounts.google.com/o/oauth2/v2/auth&amp;quot;,
  &amp;quot;token_endpoint&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v4/token&amp;quot;,
  &amp;quot;userinfo_endpoint&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v3/userinfo&amp;quot;,
  &amp;quot;revocation_endpoint&amp;quot;: &amp;quot;https://accounts.google.com/o/oauth2/revoke&amp;quot;,
  &amp;quot;jwks_uri&amp;quot;: &amp;quot;https://www.googleapis.com/oauth2/v3/certs&amp;quot;,
  &amp;quot;response_types_supported&amp;quot;: [
    &amp;quot;code&amp;quot;,
    &amp;quot;token&amp;quot;,
    &amp;quot;id_token&amp;quot;,
    &amp;quot;code token&amp;quot;,
    &amp;quot;code id_token&amp;quot;,
    &amp;quot;token id_token&amp;quot;,
    &amp;quot;code token id_token&amp;quot;,
    &amp;quot;none&amp;quot;
  ],
  &amp;quot;subject_types_supported&amp;quot;: [
    &amp;quot;public&amp;quot;
  ],
  &amp;quot;id_token_signing_alg_values_supported&amp;quot;: [
    &amp;quot;RS256&amp;quot;
  ],
  &amp;quot;scopes_supported&amp;quot;: [
    &amp;quot;openid&amp;quot;,
    &amp;quot;email&amp;quot;,
    &amp;quot;profile&amp;quot;
  ],
  &amp;quot;token_endpoint_auth_methods_supported&amp;quot;: [
    &amp;quot;client_secret_post&amp;quot;,
    &amp;quot;client_secret_basic&amp;quot;
  ],
  &amp;quot;claims_supported&amp;quot;: [
    &amp;quot;aud&amp;quot;,
    &amp;quot;email&amp;quot;,
    &amp;quot;email_verified&amp;quot;,
    &amp;quot;exp&amp;quot;,
    &amp;quot;family_name&amp;quot;,
    &amp;quot;given_name&amp;quot;,
    &amp;quot;iat&amp;quot;,
    &amp;quot;iss&amp;quot;,
    &amp;quot;locale&amp;quot;,
    &amp;quot;name&amp;quot;,
    &amp;quot;picture&amp;quot;,
    &amp;quot;sub&amp;quot;
  ],
  &amp;quot;code_challenge_methods_supported&amp;quot;: [
    &amp;quot;plain&amp;quot;,
    &amp;quot;S256&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テスト用にcodeを受け取ってトークンをリクエストするサーバーを書いた。コードは&lt;a href=&#34;https://github.com/sambaiz/openid-connect-test-client&#34;&gt;ここ&lt;/a&gt;。client_idとclient_secretは&lt;a href=&#34;https://console.developers.google.com/&#34;&gt;API Console&lt;/a&gt;で発行できる。&lt;/p&gt;

&lt;p&gt;立ち上げて&lt;code&gt;https://localhost:3000/auth&lt;/code&gt;にアクセスするとリダイレクトし、以下のような情報が出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;code&amp;quot;: {
    &amp;quot;state&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;code&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;authuser&amp;quot;: &amp;quot;0&amp;quot;,
    &amp;quot;session_state&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;prompt&amp;quot;: &amp;quot;none&amp;quot;
  },
  &amp;quot;token&amp;quot;: {
    &amp;quot;access_token&amp;quot;: &amp;quot;*****.*****.*****&amp;quot;
  },
  &amp;quot;id_token_header&amp;quot;: {
    &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
    &amp;quot;kid&amp;quot;: &amp;quot;5b0924f6f83c719514987954cf66683b370677d4&amp;quot;
  },
  &amp;quot;id_token_payload&amp;quot;: {
    &amp;quot;azp&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;aud&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;sub&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;email&amp;quot;: &amp;quot;****@gmail.com&amp;quot;,
    &amp;quot;email_verified&amp;quot;: true,
    &amp;quot;at_hash&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;nonce&amp;quot;: &amp;quot;*****&amp;quot;,
    &amp;quot;iss&amp;quot;: &amp;quot;https://accounts.google.com&amp;quot;,
    &amp;quot;iat&amp;quot;: 1506613038,
    &amp;quot;exp&amp;quot;: 1506616638
  },
  &amp;quot;id_token_verify_signature&amp;quot;: &amp;quot;*****&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このIDトークンのiss, audを見て署名も&lt;a href=&#34;https://developers.google.com/identity/protocols/OpenIDConnect#validatinganidtoken&#34;&gt;検証する&lt;/a&gt;ことで、
たしかに発行元と先が正しいことを確認し、expも過ぎていなければ、
subに示されるIDのエンティティとして認証できる。&lt;/p&gt;

&lt;h2 id=&#34;idトークンの署名を検証する&#34;&gt;IDトークンの署名を検証する&lt;/h2&gt;

&lt;p&gt;検証もやってみた。urlは&lt;code&gt;https://localhost:3000/verify?token=****&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;GoogleのIDトークンのalgを見ると、RS256(RSASSA-PKCS1-v1_5 using SHA-256)で署名されていることがわかる。対象となるデータはJWSの&lt;code&gt;(ヘッダ).(ペイロード)&lt;/code&gt;まで。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/135/&#34;&gt;RSA暗号とPEM/DERの構造 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;公開鍵はDiscoveryのjwks_uriで取得でき、1日に1回更新される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://www.googleapis.com/oauth2/v3/certs
{
 &amp;quot;keys&amp;quot;: [
  {
   &amp;quot;kty&amp;quot;: &amp;quot;RSA&amp;quot;,
   &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
   &amp;quot;use&amp;quot;: &amp;quot;sig&amp;quot;,
   &amp;quot;kid&amp;quot;: &amp;quot;23e255c65b234549cc0fe3073bce15e59bd4d4b0&amp;quot;,
   &amp;quot;n&amp;quot;: &amp;quot;w5i-jGiwEyuPewnvR-lFceBRYh4gx91-OFLaJwwr8yCrSVczAgyc1wywFBCsUBDBhHpKSVilqIGG2fIqhdX2_IFJ-OxYvXDmJtYF69kWTafZjFtnAl8EdIqj1X-y31Pm9gYD_rYeLG3CZhNLjIE_y9fk5_MbOOc0Z-br4_wzing6HfERITbAOAfCd8Ri0_tXDqYgi-C1C_gs2HheYEIWqpZ2se8UsGvIg2uePOCV8G3a0fuvh6hgjutspfJ_VH3eeHwYwyYzieq-sDWcyV5qGlnJp9TZlZ9z242WdYHj3C2kudNTUg76p6svbs6cu1ZiZA9WZkaL9d8hWeJ4tLQg3Q&amp;quot;,
   &amp;quot;e&amp;quot;: &amp;quot;AQAB&amp;quot;
  },
  {
   &amp;quot;kty&amp;quot;: &amp;quot;RSA&amp;quot;,
   &amp;quot;alg&amp;quot;: &amp;quot;RS256&amp;quot;,
   &amp;quot;use&amp;quot;: &amp;quot;sig&amp;quot;,
   &amp;quot;kid&amp;quot;: &amp;quot;db15c5e7c1b82b93388459602e4852bfd9b95931&amp;quot;,
   &amp;quot;n&amp;quot;: &amp;quot;lZUcUSL9piIsbwP_Y84683P7-vX_Y9CEvqpeCNpI4p55HFCDnp9xtnvc5mBEOrFP-vwk6sjlkLVbl74d1CR-jKX-z8zPg3T0qQzYWgedAddfQL1zFUyo2BLbCg2JeYDZF6IHv6qfwzM3hgQIMJMa29izyAyZ2T0zhXf5fU311LEKWCdpemQsNj5V4r5Z52vsTuOhm16Xt7LWx_iWb-_VdYxhDYoQ87pZIVaCdnKDwGON0MPoI4eQJdb-ABrcz290mbGJ8kiI4BU_iA98HCc3ifWDe8eatpV9LK54eYansDTMQJXoYZ6a7C-0-Mh1-g6qaxYjpymJXbJjYitiMejYFQ&amp;quot;,
   &amp;quot;e&amp;quot;: &amp;quot;AQAB&amp;quot;
  },
  ...
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;signature,n,eをそれぞれbase64デコードしたのを整数として扱い、&lt;code&gt;m ≡ (signature)^e (mod n)&lt;/code&gt;で複合するとdigestInfoのDERの前に&lt;code&gt;00 01 ff ff .. 00&lt;/code&gt;のパディングがついたものになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;digestInfo ::= SEQUENCE {
     digestAlgorithm DigestAlgorithmIdentifier,
     digest Digest 
}

Digest ::= OCTET STRING
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const digestInfoDERFromSignature = (signature, e, n) =&amp;gt; {
  const signatureHex = Buffer.from(signature, &#39;base64&#39;).toString(&#39;hex&#39;)
  const eHex  = Buffer.from(e, &#39;base64&#39;).toString(&#39;hex&#39;)
  const nHex = Buffer.from(n, &#39;base64&#39;).toString(&#39;hex&#39;)

  const signatureNum = bigInt(signatureHex, 16)
  const eNum = bigInt(eHex, 16)
  const nNum = bigInt(nHex, 16)  

  const m = signatureNum.modPow(eNum, nNum); // c^e (mod n)
  const decrypted = m.toString(16);
  const paddingRemoved = decrypted.replace(/^1f*00/g, &amp;quot;&amp;quot;);
  return paddingRemoved;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この中のdigestと&lt;code&gt;(ヘッダ).(ペイロード)&lt;/code&gt;のsha256 hashが一致することを確認する。
digestは末尾にくるので簡易的にendsWithで比較している。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RSA暗号とPEM/DERの構造</title>
          <link>https://www.sambaiz.net/article/135/</link>
          <pubDate>Sun, 01 Oct 2017 21:02:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/135/</guid>
          <description>

&lt;h2 id=&#34;rsa暗号とは&#34;&gt;RSA暗号とは&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;暗号化: &lt;code&gt;c ≡ m^e (mod n)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;複合: &lt;code&gt;m ≡ c^d (mod n)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;公開鍵がe,nで秘密鍵がd。nはとても大きく近くない素数p,qの積で、
これを公開しても素因数分解できないのがこの暗号の前提になっている。
768bit(10進数で232桁)では既に解読されているので、少なくとも1024bit以上にする。&lt;/p&gt;

&lt;p&gt;eは&lt;a href=&#34;https://en.wikipedia.org/wiki/Euler%27s_totient_function&#34;&gt;Euler totient function&lt;/a&gt;(1~nまでの整数でnと互いに素なものの個数。今回の場合は&lt;code&gt;φ(n)=(p-1)(q-1)&lt;/code&gt;)未満で互いに素な正の整数で、小さすぎても大きすぎてもだめ。&lt;code&gt;2^16 + 1 = 65537&lt;/code&gt;がよく使われる。&lt;/p&gt;

&lt;p&gt;dは&lt;code&gt;ed ≡ 1 (mod φ(n))&lt;/code&gt;を満たすd。&lt;/p&gt;

&lt;h2 id=&#34;例&#34;&gt;例&lt;/h2&gt;

&lt;p&gt;例として(p,q)=(193,709)とするとこんな感じ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n = p * q = 136837&lt;/li&gt;
&lt;li&gt;φ(n) = (p-1)(q-1) = 135936&lt;/li&gt;
&lt;li&gt;e = 65537 &amp;lt; φ(n)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;秘密鍵dは&lt;code&gt;65537*d ≡ 1 (mod 135936)&lt;/code&gt;の式を変形した
&lt;code&gt;65537*d - 135936*x = gcd(65537,135936) = 1&lt;/code&gt;を、拡張されたユークリッドの互除法で解く。
以下のように135936と65537を残しながら展開していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;135936 = 65537 * 2 + 4862 
=&amp;gt; 4862 = 135936 * 1 + 65537 * -2

65537 = 4862 * 13 + 2331 
=&amp;gt; 2331 = 65537 - (135936 * 1 + 65537 * -2) * 13
        = 135936 * -13 + 65537 * 27

4862 = 2331 * 2 + 200 
=&amp;gt; 200 = (135936 * 1 + 65537 * -2) - (135936 * -13 + 65537 * 27) * 2
       = 135936 * 27 + 65537 * -56

2331 = 200 * 11 + 131 
=&amp;gt; 131 = (135936 * -13 + 65537 * 27) - (135936 * 27 + 65537 * -56) * 11
       = 135936 * -310 + 65537 * 643 
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをコードに表したのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const d = (phi,e) =&amp;gt; {
    let history = {[phi]: [1,0], [e]:[0,1]} // [x,y] =&amp;gt; φ * x + e * y
    let x = phi
    let y = e
    while(y &amp;gt; 1){
        const nextY = x % y
        history[x % y] = history[x].map((vx,index) =&amp;gt; vx - history[y][index] * Math.floor(x/y))
        x = y
        y = nextY;
    }
    return history;
}

const phi = (193-1) * (709-1)
const e = 65537
const result = d(phi,e);
console.log(result);
console.log(`1 = ${phi}*${result[1][0]} + ${e}*${result[1][1]}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{ &#39;1&#39;: [ 9503, -19711 ],
  &#39;6&#39;: [ -8519, 17670 ],
  &#39;7&#39;: [ 984, -2041 ],
  &#39;62&#39;: [ -647, 1342 ],
  &#39;69&#39;: [ 337, -699 ],
  &#39;131&#39;: [ -310, 643 ],
  &#39;200&#39;: [ 27, -56 ],
  &#39;2331&#39;: [ -13, 27 ],
  &#39;4862&#39;: [ 1, -2 ],
  &#39;65537&#39;: [ 0, 1 ],
  &#39;135936&#39;: [ 1, 0 ] }
1 = 135936*9503 + 65537*-19711
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;135936*-65537 + 65537*135936 = 0&lt;/code&gt;より
&lt;code&gt;1 = 135936*(9503-65537) + 65537*(-19711 + 135936)&lt;/code&gt;なので
&lt;code&gt;d=116225&lt;/code&gt;。実際&lt;code&gt;(65537*116225) % 135936 = 1&lt;/code&gt;が成り立つ。&lt;/p&gt;

&lt;p&gt;平文が12345とすると、公開鍵で暗号化したのが&lt;code&gt;(12345 ** 65537) % 136837 = 6964&lt;/code&gt;。
これを秘密鍵で複合すると&lt;code&gt;(6964 ** 116225) % 136837 = 12345&lt;/code&gt;のように平文が得られる。&lt;/p&gt;

&lt;h2 id=&#34;鍵ファイルの生成&#34;&gt;鍵ファイルの生成&lt;/h2&gt;

&lt;p&gt;ssh-keygenで生成されるようなPEMファイルを作る。&lt;/p&gt;

&lt;h3 id=&#34;用語&#34;&gt;用語&lt;/h3&gt;

&lt;p&gt;DER(Distinguished Encoding Rules)は
&lt;a href=&#34;https://ja.wikipedia.org/wiki/Abstract_Syntax_Notation_One&#34;&gt;ASN.1(Abstract Syntax Notation One)&lt;/a&gt;記法で定義されたデータを
エンコードするルールの一つ。
&lt;code&gt;1a(INTEGER) 0b(byte) 68 65 6c 6c 6f 20 77 6f 72 6c 64(&amp;quot;hello world&amp;quot;))&lt;/code&gt;
のようなtype-length-valueで表す。&lt;/p&gt;

&lt;p&gt;PEM(Privacy-enhanced Electronic Mail)は
公開鍵のフォーマットの定義&lt;a href=&#34;https://en.wikipedia.org/wiki/X.509&#34;&gt;X.509&lt;/a&gt;で
定められている拡張子で、Base64でエンコードされたDER。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/PKCS&#34;&gt;PKCS(Public-Key Cryptography Standards)&lt;/a&gt;は公開鍵暗号における標準仕様を定めたもの。PKCS#1(&lt;a href=&#34;https://tools.ietf.org/html/rfc2313&#34;&gt;RFC2313&lt;/a&gt;)にはRSA暗号の方式やASN.1表現などが含まれている。&lt;/p&gt;

&lt;p&gt;RFC2313に書かれているASN.1を見ながらPEMの内容を確認する。&lt;/p&gt;

&lt;h3 id=&#34;rsaprivatekey&#34;&gt;RSAPrivateKey&lt;/h3&gt;

&lt;p&gt;n,e,dに加えて生成に使った素数まで含んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RSAPrivateKey ::= SEQUENCE {
     version Version,
     modulus INTEGER, -- n
     publicExponent INTEGER, -- e
     privateExponent INTEGER, -- d
     prime1 INTEGER, -- p
     prime2 INTEGER, -- q
     exponent1 INTEGER, -- d mod (p-1)
     exponent2 INTEGER, -- d mod (q-1)
     coefficient INTEGER -- (inverse of q) mod p }

   Version ::= INTEGER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pemを生成し、Base64デコードしてDERにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa 1024 &amp;gt; secret.pem
$ cat secret.pem 
-----BEGIN RSA PRIVATE KEY-----
(内容)
-----END RSA PRIVATE KEY-----

$ echo (内容) | base64 -D | xxd
00000000: 3082 025c 0201 0002 8181 .... .... .... 
00000080: .... .... .... .... .... ..02 0301 0001
00000090: 0281 80..
00000110: .... ..02 41.. 
00000150: .... .... .... 0241 ....
00000190: .... .... .... .... ..02 40.. 
000001d0: .... .... .... .... .... ..02 41.. ....  
00000210: .... .... .... .... .... .... .... 0240 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;整理するとこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[0000] 30 82 02 5c       
(30-&amp;gt;Type=SEQUENCE 82-&amp;gt;先頭bitが1なのでlengthに使うバイト数(2bytes) 025c-&amp;gt;Length=605bytes)

  [0000] 02 01 00
  (version: 02-&amp;gt;Type=INTEGER, 01-&amp;gt;先頭が0なのでそのままLength=3bytes, Value=0)

  [0000] 02 81 81 .. 
  (modulus: Type=INTEGER, Length=129bytes)

  [0080] 02 03 01 00 01 
  (publicExponent: Type=INTEGER, Length=3bytes, Value=65537)

  [0090] 02 81 80 ..
  (privateExponent: Type=INTEGER, Length=128bytes)

  [0110] 02 41 ..
  (prime1: Type=INTEGER, Length=65bytes)

  [0150] 02 41 .. 
  (prime2: Type=INTEGER, Length=65bytes)

  [0190] 02 40 ..
  (exponent1: Type=INTEGER, Length=64bytes)

  [01d0] 02 41 ..
  (exponent2: Type=INTEGER, Length=65bytes)

  [0210] 02 40 ..
  (coefficient: Type=INTEGER, Length=64bytes)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rsapublickey&#34;&gt;RSAPublicKey&lt;/h3&gt;

&lt;p&gt;nとeだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RSAPublicKey ::= SEQUENCE {
     modulus INTEGER, -- n
     publicExponent INTEGER -- e }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秘密鍵から公開鍵を生成して同様にDERにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl rsa -pubout &amp;lt; secret.pem &amp;gt; public.pem
$ cat public.pem 
-----BEGIN PUBLIC KEY-----
(内容)
-----END PUBLIC KEY-----

$ echo (内容) | base64 -D | xxd
00000000: 3081 9f30 0d06 092a 8648 86f7 0d01 0101
00000010: 0500 0381 8d00 3081 8902 8181 .... ....
00000090: .... .... .... .... .... .... ..02 0301 
000000a0: 0001
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[0000] 30 81 9f
(Type=SEQUENCE, Length=159bytes)
  [0000] 30 0d
  (Type=SEQUENCE, Length=13bytes)
    [0000] 06 09 2a 86 48 86 f7 0d 01 01 01
    (Type=OBJECT IDENTIFIER, Length=9bytes, 
    value=http://www.oid-info.com/get/1.2.840.113549.1.1.1
          最上位ビットは区切りのサイン
          2a ((0)010 1010) =&amp;gt; 40 * 1 + 2 =&amp;gt; 1(iso) 2(member-body)
          86 48 ((1)000 0110 (0)100 1000) =&amp;gt; 840(us)
          86 f7 0d ((1)000 0110 (1)111 0111 (0)000 1101) =&amp;gt; 113549(rsadsi)
          01 ((0)000 0001) =&amp;gt; 1(pkcs)
          01 ((0)000 0001) =&amp;gt; 1(pcks-1)
          01 ((0)000 0001) =&amp;gt; 1(rsaEncryption)

    [0010] 05 00
    (アルゴリズムパラメータ: Type=Null 0byte)

    [0010] 03 81 8d 00 
    (Type=BIT STRING, 141bytes, 最終byteの切り捨て0bit)

      [0010] 30 81 89
      (Type=SEQUENCE, 137bytes)

        [0010] 02 81 81 ..
        (modulus: Type=INTEGER, Length=129bytes)

        [0090] 02 03 01 00 01
        (publicExponent: Type=INTEGER, Length=3bytes, Value=65537)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;digestinfo&#34;&gt;digestInfo&lt;/h3&gt;

&lt;p&gt;署名に使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;digestInfo ::= SEQUENCE {
     digestAlgorithm DigestAlgorithmIdentifier,
     digest Digest 
}

Digest ::= OCTET STRING
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;digestAlgorithmでデータをハッシュ化したものをdigestInfoに詰め、秘密鍵で暗号化したものを署名とし、
公開鍵で複合してdigestと実際のハッシュ値が一致することを確認する。
RSASSA-PKCS1-v1_5では暗号化の前に&lt;code&gt;00 01 ff ff ff .. 00&lt;/code&gt;のパディングを加える。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://people.csail.mit.edu/rivest/Rsapaper.pdf&#34;&gt;A Method for Obtaining Digital Signatures and Public-Key Cryptosystems&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.livedoor.jp/k_urushima/archives/979220.html&#34;&gt;自堕落な技術者の日記 : 図説RSA署名の巻&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bearmini.hatenablog.com/entry/2014/02/05/143510&#34;&gt;RSA 秘密鍵/公開鍵ファイルのフォーマット - bearmini&amp;rsquo;s blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://crypto.stackexchange.com/questions/29115/how-is-oid-2a-86-48-86-f7-0d-parsed-as-1-2-840-113549&#34;&gt;openssl - How is OID 2a 86 48 86 f7 0d parsed as 1.2.840.113549? - Cryptography Stack Exchange&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数</title>
          <link>https://www.sambaiz.net/article/134/</link>
          <pubDate>Mon, 25 Sep 2017 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/134/</guid>
          <description>

&lt;h2 id=&#34;自己情報量&#34;&gt;自己情報量&lt;/h2&gt;

&lt;p&gt;P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-self-information.png&#34; alt=&#34;自己情報量の定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-self-information-graph.png&#34; alt=&#34;自己情報量のグラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;log(P)+log(Q)=log(P*Q)&lt;/code&gt;より加法性がある。
例えば、サイコロで1の目が2回連続で出る(P=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;36&lt;/sub&gt;)情報量(5.16bits)はサイコロで1の目が出る(P=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;)情報量(2.58bits)の2倍と等しい。
確率が高ければ高いほど自己情報量は小さくなり、&lt;code&gt;P(ω)=1&lt;/code&gt;では0bitになる。&lt;/p&gt;

&lt;h2 id=&#34;エントロピー&#34;&gt;エントロピー&lt;/h2&gt;

&lt;p&gt;確率分布Pに従う確率変数Xのエントロピーは以下の式で定義される。情報量の平均。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-entropy.png&#34; alt=&#34;エントロピーの定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これは情報を送る際に必要なビット数の平均の下限になっている。
例えば、Xが1~4の値を(0.8, 0.1, 0.06, 0.04)の確率でとるとする。
4通りなのだからそれぞれ2bits(00, 01, 10, 11)のコードで表すこともできるが、
ほとんど3や4は出ないのだからbit数を偏らせて(0, 10, 110, 111)のコードで表すと
&lt;code&gt;0.8*1 + 0.1*2 + 0.06*3 + 0.04*3 = 1.3bits&lt;/code&gt;まで減らすことができる。
この場合のエントロピーは1.01bitsで、これより小さくすることはできない。&lt;/p&gt;

&lt;h2 id=&#34;カルバック-ライブラー情報量&#34;&gt;カルバック・ライブラー情報量&lt;/h2&gt;

&lt;p&gt;離散確率分布PのQに対するカルバック・ライブラー情報量は以下の式で定義される。連続確率分布では積分する。
Qの自己情報量からPの自己情報量を引いて平均を取ったもの。非負の値を取る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-kl.png&#34; alt=&#34;KL情報量の定義&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;交差エントロピー&#34;&gt;交差エントロピー&lt;/h2&gt;

&lt;p&gt;離散確率分布PとQの交差エントロピーは以下の式で定義される。連続確率分布では積分する。
PのエントロピーにPのQに対するKL情報量を足したもの。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/134-cross-entropy.png&#34; alt=&#34;交差エントロピーの定義&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これはQの分布に最適化されたコードでPの分布の確率変数の情報を送ってしまった際に必要なビット数の平均の下限になっている。KL情報量が余分な分。機械学習の損失関数に使われる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/191/&#34;&gt;ロジスティック回帰と尤度関数/交差エントロピー誤差と勾配降下法 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Self-information&#34;&gt;Self-information - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&#34;&gt;Kullback–Leibler divergence - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://postd.cc/visual-information-theory-3/&#34;&gt;情報理論を視覚的に理解する (&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;) | コンピュータサイエンス | POSTD&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ニューラルネットワークと活性化関数</title>
          <link>https://www.sambaiz.net/article/133/</link>
          <pubDate>Mon, 18 Sep 2017 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/133/</guid>
          <description>

&lt;p&gt;活性化関数というのは各層での重み掛けバイアス足しのあとに適用する非線形の関数。
これはカーネル法のように空間を変換して線形分離できないデータを線形分離できるようにするはたらきをする。
線形な関数を使うと層を重ねても結局線形のままで、空間もそのまま伸縮するだけなので目的を果たさない。&lt;/p&gt;

&lt;p&gt;バックプロバゲーション(誤差逆伝播法)するために微分できる必要がある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/192/&#34;&gt;MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tensorflowでは以下の活性化関数が&lt;a href=&#34;https://www.tensorflow.org/api_guides/python/nn#Activation_Functions&#34;&gt;用意されている&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;sigmoid-https-www-tensorflow-org-api-docs-python-tf-sigmoid&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/sigmoid&#34;&gt;sigmoid&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-sigmoid.png&#34; alt=&#34;シグモイド関数&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-sigmoid-f.png&#34; alt=&#34;シグモイド関数の式と微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;値域は(0,1)で&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89&#34;&gt;シグマの語末系ςに似たS字を描く&lt;/a&gt;。
微分係数がそれほど大きくないので何層もこの関数を適用すると、バックプロバゲーションで微分係数を掛けていった結果、勾配が消失する問題がありあまり使われない。値域が(-1,1)で似たグラフを描く&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/tanh&#34;&gt;tanh&lt;/a&gt;(Hyperbolic tangent)もある。&lt;/p&gt;

&lt;h3 id=&#34;softsign-https-www-tensorflow-org-api-docs-python-tf-nn-softsign&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/softsign&#34;&gt;softsign&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softsign.png&#34; alt=&#34;softsign&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softsign-f.png&#34; alt=&#34;softsign関数の式と微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;tanhと比べて漸近線に近づく速度が遅くなっている。
それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。&lt;/p&gt;

&lt;h3 id=&#34;softplus-https-www-tensorflow-org-api-docs-python-tf-nn-softplus&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/softplus&#34;&gt;softplus&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softplus.png&#34; alt=&#34;softplus&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-softplus-f.png&#34; alt=&#34;softplus関数の式と微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ReLUに続く。&lt;/p&gt;

&lt;h3 id=&#34;relu-https-www-tensorflow-org-api-docs-python-tf-nn-relu-rectified-linear-unit&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/relu&#34;&gt;ReLU&lt;/a&gt;(Rectified Linear Unit)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-relu.png&#34; alt=&#34;ReLU&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-relu-f.png&#34; alt=&#34;ReLU関数の式と微分&#34; /&gt;&lt;/p&gt;

&lt;p&gt;単純だけど最有力。勾配消失も起きにくい。x=0で微分できないが0か1として扱われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def deriv_relu(x):
    return np.where(x &amp;gt; 0, 1, 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;softplusと比べてexpやlogを含まない分高速に計算できるので、
膨大で複雑なデータセットに対して多くの層を用いることができる。&lt;/p&gt;

&lt;p&gt;0以下は等しく0になるため、学習中に落ちてしまうとニューロンが死んでしまう。
これを避けるため0以下のとき&lt;code&gt;y = exp(x) - 1&lt;/code&gt;にする&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/nn/elu&#34;&gt;ELU&lt;/a&gt;(Exponential Linear Unit)
というのもある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/133-elu.png&#34; alt=&#34;ELU&#34; /&gt;&lt;/p&gt;

&lt;p&gt;比較的起きにくいとはいえ、層を深くすると勾配消失する可能性は高まる。
活性化関数ごとに異なる重みの初期値によってこれを緩和でき、ReLUでは入力次元数によるHe Initializationというのが提案されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rng = np.random.RandomState(1234)
n_in = 10 # 入力次元数
rng.uniform(
    low=-np.sqrt(6/n_in),
    high=+np.sqrt(6/n_in),
    size=5
) # He Initialization
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/towards-data-science/activation-functions-and-its-types-which-is-better-a9a5310cc8f&#34;&gt;Activation functions and it’s types-Which is better?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.orsj.or.jp/archive2/or60-4/or60_4_191.pdf&#34;&gt;最適化から見たディープラーニングの考え方&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf&#34;&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Rectifier_(neural_networks)&#34;&gt;Rectifier (neural networks) - Wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った</title>
          <link>https://www.sambaiz.net/article/132/</link>
          <pubDate>Sun, 10 Sep 2017 23:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/132/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34;&gt;Puppeteer&lt;/a&gt;でHeadless Chromeを動かすコードを
Lambda上で動かすStarter Kitを作った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit&#34;&gt;puppeteer-lambda-starter-kit&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;chromeの準備&#34;&gt;Chromeの準備&lt;/h2&gt;

&lt;p&gt;Puppeteerのインストール時に落としてくるChromeをLambda上で動かそうとしても
Lambdaにないshared libraryに依存しているため失敗する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;error while loading shared libraries: libpangocairo-1.0.so.0: cannot open shared object file: No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lambda上でHeadless Chromeを動かす例がないか調べたら&lt;a href=&#34;https://github.com/adieuadieu/serverless-chrome&#34;&gt;serverless-chrome&lt;/a&gt;というのがあって、
Headless用の設定でChromeをビルドしていた。
ほかには&lt;a href=&#34;https://github.com/graphcool/chromeless&#34;&gt;chromeless&lt;/a&gt;というのもあるけど
これはserverless-chromeに
&lt;a href=&#34;https://github.com/graphcool/chromeless/blob/master/serverless/serverless.yml#L46&#34;&gt;依存している&lt;/a&gt;。
最小構成でPuppeteerを使いたかったので、今回はこれらを使わず一から作ることにした。&lt;/p&gt;

&lt;p&gt;serverless-chromeにもビルドしたものが置いてあるが、少しバージョンが古いようだったので最新版でビルドした。
基本的には&lt;a href=&#34;https://github.com/adieuadieu/serverless-chrome/tree/master/chrome&#34;&gt;書いてある&lt;/a&gt;
通りやればうまくいく。他のプロセスとのshared memoryとして/dev/shmを使っているのを、/tmpに&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/blob/master/chrome/buildChrome.sh#L20&#34;&gt;置き換える&lt;/a&gt;
ようにしないと、実行時の&lt;code&gt;page.goto()&lt;/code&gt;で&lt;code&gt;Failed Provisional Load: ***, error_code: -12&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;ビルドしたheadless_shellには問題になった依存は含まれていないようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ldd headless_shell 
	linux-vdso.so.1 =&amp;gt;  (0x00007ffcb6fed000)
	libpthread.so.0 =&amp;gt; /lib64/libpthread.so.0 (0x00007f5f17dbe000)
	libdl.so.2 =&amp;gt; /lib64/libdl.so.2 (0x00007f5f17bba000)
	librt.so.1 =&amp;gt; /lib64/librt.so.1 (0x00007f5f179b1000)
	libnss3.so =&amp;gt; /usr/lib64/libnss3.so (0x00007f5f17692000)
	libnssutil3.so =&amp;gt; /usr/lib64/libnssutil3.so (0x00007f5f17466000)
	libsmime3.so =&amp;gt; /usr/lib64/libsmime3.so (0x00007f5f1723e000)
	libnspr4.so =&amp;gt; /lib64/libnspr4.so (0x00007f5f17001000)
	libexpat.so.1 =&amp;gt; /lib64/libexpat.so.1 (0x00007f5f16dd8000)
	libfontconfig.so.1 =&amp;gt; not found
	libfreetype.so.6 =&amp;gt; /usr/lib64/libfreetype.so.6 (0x00007f5f16b3b000)
	libm.so.6 =&amp;gt; /lib64/libm.so.6 (0x00007f5f16839000)
	libstdc++.so.6 =&amp;gt; /usr/lib64/libstdc++.so.6 (0x00007f5f16533000)
	libgcc_s.so.1 =&amp;gt; /lib64/libgcc_s.so.1 (0x00007f5f1631d000)
	libc.so.6 =&amp;gt; /lib64/libc.so.6 (0x00007f5f15f5b000)
	/lib64/ld-linux-x86-64.so.2 (0x000055ba0af5e000)
	libplc4.so =&amp;gt; /lib64/libplc4.so (0x00007f5f15d55000)
	libplds4.so =&amp;gt; /lib64/libplds4.so (0x00007f5f15b51000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Puppetterで落としてくる普通のChromeは&lt;a href=&#34;http://docs.aws.amazon.com/lambda/latest/dg/limits.html&#34;&gt;Lambdaの制限&lt;/a&gt;の50MBを超えていたが、
ビルドしたものはぎりぎり超えていないのでパッケージに含められるようになった。
PuppeteerのChromeは環境変数&lt;code&gt;PUPPETEER_SKIP_CHROMIUM_DOWNLOAD&lt;/code&gt;を設定することで&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/blob/2817130fe099a7431e98c20ce1f44c6e547d4ca9/docs/api.md#puppeteer&#34;&gt;含めないようにできる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;他のパッケージのサイズによっては50MBを超えてしまうこともあるので、
パッケージに含めず&lt;a href=&#34;https://github.com/sambaiz/puppeteer-lambda-starter-kit/blob/v0.9.0/src/util.js#L62&#34;&gt;S3からダウンロード&lt;/a&gt;できるようにもした。&lt;/p&gt;

&lt;p&gt;いずれの場合も最終的な置き先はLambdaで唯一書き込める&lt;code&gt;/tmp&lt;/code&gt;になる。
この領域は512MBまで使えるので展開してもまだ余裕がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: EROFS: read-only file system, open &#39;node_modules/puppeteer/.local-chromium&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chromeのlaunch時のoption&#34;&gt;ChromeのLaunch時のOption&lt;/h2&gt;

&lt;p&gt;いろいろ試した結果、最低限必要だったのはこのあたり。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;exports.launchOptionForLambda = [
    // error when launch(); No usable sandbox! Update your kernel
    &#39;--no-sandbox&#39;,
    // error when launch(); Failed to load libosmesa.so
    &#39;--disable-gpu&#39;, 
    // freeze when newPage()
    &#39;--single-process&#39;
];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーは分かりづらいものが多く、ときにはエラーすら出ずに止まってしまうこともある。
デバッグの際はdumpioを有効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const browser = await puppeteer.launch({
    ...
    dumpio: !!util.DEBUG,
});  
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;babel&#34;&gt;Babel&lt;/h2&gt;

&lt;p&gt;現在のLambdaのNodeのバージョンはv6.10.3。
&lt;a href=&#34;http://node.green/&#34;&gt;node.green&lt;/a&gt;によるとES2015は99%対応していて、ES2016もべき乗演算子(2 ** 3 = 8)以外は対応しているが、ES2017のasync/awaitは7.6からなので、8系に対応するまではbabelにかける必要がある。
ちなみにPuppeteerは6.4以降で&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/tree/master/utils/node6-transform&#34;&gt;動く&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev babel-cli babel-preset-env
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/babel/babel-preset-env&#34;&gt;babel-preset-env&lt;/a&gt;
.babelrcはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat .babelrc
{
  &amp;quot;presets&amp;quot;: [
    [&amp;quot;env&amp;quot;, {
      &amp;quot;targets&amp;quot;: {
        &amp;quot;node&amp;quot;: &amp;quot;6.10&amp;quot;
      }
    }]
  ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Headless Chromeでファイルをダウンロードする</title>
          <link>https://www.sambaiz.net/article/131/</link>
          <pubDate>Sun, 03 Sep 2017 18:51:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/131/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://chromedevtools.github.io/devtools-protocol/&#34;&gt;Chrome DevTools Protocol&lt;/a&gt;に
Experimentalだけど&lt;a href=&#34;https://chromedevtools.github.io/devtools-protocol/tot/Page#method-setDownloadBehavior&#34;&gt;Page.setDownloadBehavior&lt;/a&gt;
というのがあったので、これを呼んでファイルをダウンロードしてみた。&lt;/p&gt;

&lt;p&gt;今回は公式のDevToolsのNode API、&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34;&gt;Puppeteer&lt;/a&gt;を使うけど、
setDownloadBehaviorを送るAPIはまだ&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/blob/64124df62f4e81999fe1a0ab45c6fb9718a0e413/lib/Page.js#L29&#34;&gt;なく&lt;/a&gt;、直接clientを取ってsendするので他のライブラリでもやることは変わらないと思う。
Puppeteerのインストールの際にChromiumも入る。setDownloadBehaviorは現行Chromeの60では&lt;a href=&#34;https://bugs.chromium.org/p/chromium/issues/detail?id=696481&#34;&gt;対応していない&lt;/a&gt;ようだけど、62が入ったのでなんとかなりそう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add puppeteer
$ find . -name &amp;quot;*chrome*&amp;quot;
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_100_percent.pak
./node_modules/puppeteer/.local-chromium/mac-497674/chrome-mac/Chromium.app/Contents/Versions/62.0.3198.0/Chromium Framework.framework/Versions/A/Resources/chrome_200_percent.pak
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、このChromeをLambda上で実行しようとすると失敗する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/132/&#34;&gt;Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ChromeでChromeをダウンロードしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const puppeteer = require(&#39;puppeteer&#39;),
      fs        = require(&#39;fs&#39;);

const headless     = true,
      downloadPath = &#39;./Download&#39;;

(async () =&amp;gt; {
  const browser = await puppeteer.launch({headless: headless});
  
  const page = await browser.newPage();
  await page._client.send(
    &#39;Page.setDownloadBehavior&#39;,
    {behavior : &#39;allow&#39;, downloadPath: downloadPath}
  );

  await page.goto(&#39;https://www.google.co.jp/chrome/browser/desktop/index.html&#39;, {waitUntil: &#39;networkidle&#39;});
  await page.click(&#39;a.download-button&#39;);  /* Chromeをダウンロード         */
  await page.click(&#39;button#eula-accept&#39;); /* 利用規約に同意してインストール */

  await waitDownloadComplete(downloadPath)
        .catch((err) =&amp;gt; console.error(err));
 
  console.log(&#39;finished&#39;);
  browser.close();  
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイルがダウンロードできたかどうかは.crdownloadのありなしで判定している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const waitDownloadComplete = async (path, waitTimeSpanMs = 1000, timeoutMs = 60 * 1000) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {

    const wait = (waitTimeSpanMs, totalWaitTimeMs) =&amp;gt; setTimeout(
      () =&amp;gt; isDownloadComplete(path).then(
        (completed) =&amp;gt; {
          if (completed) { 
            resolve();
          } else {

            const nextTotalTime = totalWaitTimeMs + waitTimeSpanMs;
            if (nextTotalTime &amp;gt;= timeoutMs) {
              reject(&#39;timeout&#39;);
            }

            const nextSpan = Math.min(
              waitTimeSpanMs,
              timeoutMs - nextTotalTime
            );
            wait(nextSpan, nextTotalTime);
          }           
        }
      ).catch(
        (err) =&amp;gt; { reject(err); }
      ),
      waitTimeSpanMs
    );
    
    wait(waitTimeSpanMs, 0);
  }); 
}

const isDownloadComplete = async (path) =&amp;gt; {
  return new Promise((resolve, reject) =&amp;gt; {
    fs.readdir(path, (err, files) =&amp;gt; {
      if (err) {
        reject(err);
      } else {
        if (files.length === 0) {
          resolve(false);
          return;
        }
        for(let file of files){

          // .crdownloadがあればダウンロード中のものがある
          if (/.*\.crdownload$/.test(file)) { 
            resolve(false);
            return;
          }
        }
        resolve(true);
      }
    });
  });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Headlessだと何もでてこないのでうまくいったか良くわからないけど、
指定したパスを見にいったらちゃんと保存されていた。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;機能的には近い立ち位置の&lt;a href=&#34;http://www.nightmarejs.org/&#34;&gt;NightmareJS&lt;/a&gt;の方も、
v1の&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;、現行v2の&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;を経て
v3ではHeadless Chromeに&lt;a href=&#34;https://github.com/segmentio/nightmare/issues/1092&#34;&gt;なるかもしれない&lt;/a&gt;。
速いし、ウィンドウがないので&lt;a href=&#34;https://en.wikipedia.org/wiki/Xvfb&#34;&gt;xvfb(X virtual framebuffer)&lt;/a&gt;も&lt;a href=&#34;https://developers.google.com/web/updates/2017/04/headless-chrome&#34;&gt;必要ない&lt;/a&gt;し良さそうなんだけど、
現在のChrome DevTools ProtocolではNightmareの既存APIをサポートできなかったり、
Puppeteerとの住み分けはどうするのって話になっているみたいだ。&lt;/p&gt;

&lt;p&gt;現状Nightmare自体にダウンロード機能は含まれていないが、
Electronの&lt;a href=&#34;https://github.com/electron/electron/blob/master/docs-translations/jp/api/download-item.md&#34;&gt;will-download&lt;/a&gt;イベントを
ハンドリングする
&lt;a href=&#34;https://github.com/rosshinkley/nightmare-download-manager&#34;&gt;nightmare-download-manager&lt;/a&gt;や
&lt;a href=&#34;https://github.com/rosshinkley/nightmare-inline-download&#34;&gt;nightmare-inline-download&lt;/a&gt;
といったライブラリがある。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>floatとdoubleの表現と精度</title>
          <link>https://www.sambaiz.net/article/130/</link>
          <pubDate>Sat, 02 Sep 2017 12:47:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/130/</guid>
          <description>

&lt;p&gt;IEEE754の仕様。記憶が薄れていたのでまとめておく。&lt;/p&gt;

&lt;p&gt;float(32bit)は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1bit: 符号&lt;/li&gt;
&lt;li&gt;8bit: 指数部(exponent)&lt;/li&gt;
&lt;li&gt;23bit: 仮数部(fraction)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;double(64bit)は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1bit: 符号&lt;/li&gt;
&lt;li&gt;11bit: 指数部&lt;/li&gt;
&lt;li&gt;52bit: 仮数部&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;で表される。&lt;/p&gt;

&lt;p&gt;例えば-5.25(2進で-101.01)を表す場合、
&lt;code&gt;-1.0101 * 2^2&lt;/code&gt;のように&lt;code&gt;±1.xxxx * 2^n&lt;/code&gt;の形にして、負なら符号を1に、指数部を正(1~254or2046)にするため
nに127or1023のバイアスを足した数を入れ、仮数部にはxxxxの部分の後ろに0を詰めたのをそのまま入れる。
したがって、-5.25のfloatは&lt;code&gt;1 10000001 01010000000000000000000&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;ただし、指数部が0のときは仮数部xxxxに対して&lt;code&gt;0.xxxx * 2^-126or1022&lt;/code&gt;のように解釈し、
0や指数部で表すことができる数(2^-126or1022)より絶対値が小さい非正規化数を表すことができるようになっている。
また、Infinityはそれぞれ(255or2047,0)、NaNは(255or2047,0以外)で表す。&lt;/p&gt;

&lt;p&gt;精度は仮数部の大きさに依存し、floatが10進で&lt;code&gt;Math.log10(2 ** 23) = 6.92&lt;/code&gt;桁で、doubleが&lt;code&gt;Math.log10(2 ** 52) = 15.65&lt;/code&gt;桁。JavaScriptの数値はdoubleなので
&lt;code&gt;1234567890.1234569&lt;/code&gt;が&lt;code&gt;1234567890.123457&lt;/code&gt;になり16~17桁目で値がおかしくなることが確認できる。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/IEEE_754&#34;&gt;IEEE 754 - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Double-precision_floating-point_format&#34;&gt;Double-precision floating-point format - Wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pythonのインタラクティブな可視化ライブラリBokehでグラフを描く</title>
          <link>https://www.sambaiz.net/article/129/</link>
          <pubDate>Sat, 26 Aug 2017 18:02:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/129/</guid>
          <description>

&lt;p&gt;Pythonの可視化というと&lt;a href=&#34;https://github.com/matplotlib/matplotlib&#34;&gt;matplotlib&lt;/a&gt;や、
そのラッパーの&lt;a href=&#34;https://github.com/mwaskom/seaborn&#34;&gt;seaborn&lt;/a&gt;、
データ解析ライブラリの&lt;a href=&#34;https://github.com/pandas-dev/pandas&#34;&gt;Pandas&lt;/a&gt;にもそういう機能があるけど、
これらが表示するのが静止画なのに対して、&lt;a href=&#34;https://github.com/bokeh/bokeh&#34;&gt;Bokeh&lt;/a&gt;はD3.jsで描画し、
拡大したりスクロールしたり、動的に何か表示することができる。Bokehはカメラのボケ。
似たようなのに&lt;a href=&#34;https://github.com/plotly/plotly.py&#34;&gt;Plotly&lt;/a&gt;というのもあるけど、
こちらはPandasと同じpydata.orgドメインで、スターが多い。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/jupyter/datascience-notebook/&#34;&gt;jupyter/datascience-notebook&lt;/a&gt;イメージにもBokehがインストールされている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d -p 8888:8888 jupyter/datascience-notebook start-notebook.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;簡単なグラフを描く&#34;&gt;簡単なグラフを描く&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;output_notebook&lt;/code&gt;でJupytor Notebokに出力する。ファイルに出力する場合は&lt;code&gt;ouput_file&lt;/code&gt;を呼ぶ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from bokeh.plotting import figure
from bokeh.io import output_notebook, show
output_notebook()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.figure&#34;&gt;figure()&lt;/a&gt;でplotするFigureオブジェクトを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p = figure(
    title=&amp;quot;Hoge&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;,
    y_axis_type=&amp;quot;log&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.line&#34;&gt;line()&lt;/a&gt;で線をつないで&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.circle&#34;&gt;circle()&lt;/a&gt;で円を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
y0 = [i**2 for i in x]
y1 = [10**i for i in x]
y2 = [10**(i**2) for i in x]

p.line(x, x, legend=&amp;quot;y=x&amp;quot;)
p.circle(x, x, legend=&amp;quot;y=x&amp;quot;, fill_color=&amp;quot;white&amp;quot;, size=8)

p.line(x, y0, legend=&amp;quot;y=x^2&amp;quot;, line_width=3)

p.line(x, y1, legend=&amp;quot;y=10^x&amp;quot;, line_color=&amp;quot;red&amp;quot;)
p.circle(x, y1, legend=&amp;quot;y=10^x&amp;quot;, fill_color=&amp;quot;red&amp;quot;, line_color=&amp;quot;red&amp;quot;, size=6)

p.line(x, y2, legend=&amp;quot;y=10^x^2&amp;quot;, line_color=&amp;quot;orange&amp;quot;, line_dash=&amp;quot;4 4&amp;quot;)

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129.png&#34; alt=&#34;折れ線グラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.vbar&#34;&gt;vbar()&lt;/a&gt;で
縦棒を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]

p.vbar(x, top=x, width=0.2, bottom=0, color=&amp;quot;#CAB2D6&amp;quot;)

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-vbar.png&#34; alt=&#34;棒グラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.annular_wedge&#34;&gt;annular_wedge()&lt;/a&gt;で弧を描く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import math
from collections import namedtuple

Data = namedtuple(&#39;Data&#39;, (&#39;name&#39;, &#39;value&#39;, &#39;color&#39;))
rates = [Data(&amp;quot;A&amp;quot;, 0.6, &amp;quot;#7FC97F&amp;quot;), Data(&amp;quot;B&amp;quot;, 0.4, &amp;quot;#DD1C77&amp;quot;)]

start_angle = 0

for rate in rates:
    p.annular_wedge(
            x=0, 
            y=0,
            inner_radius=0.2, 
            outer_radius=0.5, 
            start_angle=math.pi * 2 * start_angle, 
            end_angle=math.pi * 2 * (start_angle + rate.value),
            color=rate.color,
            legend=rate.name
    )
    start_angle += rate.value

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-c.png&#34; alt=&#34;円グラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;複数のグラフを連動させる&#34;&gt;複数のグラフを連動させる&lt;/h2&gt;

&lt;p&gt;複数のfigureでrangeを合わせると連動する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]

left = figure(
    title=&amp;quot;Left&amp;quot;, 
    width=400,
    y_axis_type=&amp;quot;log&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;
)

right = figure(
    title=&amp;quot;Right&amp;quot;, 
    width=400,
    x_range=left.x_range,
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;
)

left.line(x, x, legend=&amp;quot;y=x&amp;quot;)
right.line(x, x, legend=&amp;quot;y=x&amp;quot;)

p = gridplot([[left, right]])

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129.gif&#34; alt=&#34;連動するグラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ホバーで情報を表示する&#34;&gt;ホバーで情報を表示する&lt;/h2&gt;

&lt;p&gt;figureのtoolsにhoverを追加し、sourceに&lt;code&gt;CoulumnDataSource&lt;/code&gt;を渡して、
以下のように&lt;code&gt;select_one(HoverTool)&lt;/code&gt;するとホバーで情報を表示できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import math
from bokeh.models import HoverTool, ColumnDataSource
from collections import namedtuple

p = figure(
    title=&amp;quot;Hoge&amp;quot;, 
    x_axis_label=&#39;x&#39;, 
    y_axis_label=&#39;y&#39;,
    tools=&amp;quot;hover,save&amp;quot;
)

Data = namedtuple(&#39;Data&#39;, (&#39;name&#39;, &#39;value&#39;, &#39;color&#39;))
rates = [Data(&amp;quot;A&amp;quot;, 0.6, &amp;quot;#7FC97F&amp;quot;), Data(&amp;quot;B&amp;quot;, 0.4, &amp;quot;#DD1C77&amp;quot;)]

start_angle = 0

for rate in rates:
    
    source = ColumnDataSource(
        data=dict(
            value=[rate.value],
        )
    )
    
    p.annular_wedge(
            x=0, 
            y=0,
            inner_radius=0.2, 
            outer_radius=0.5, 
            start_angle=math.pi * 2 * start_angle, 
            end_angle=math.pi * 2 * (start_angle + rate.value),
            color=rate.color,
            legend=rate.name,
            source=source
    )
    start_angle += rate.value

p.select_one(HoverTool).tooltips = [
    (&amp;quot;value&amp;quot;, &amp;quot;@value&amp;quot;)
]

show(p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/129-c2.png&#34; alt=&#34;Tooltips&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
          <link>https://www.sambaiz.net/article/128/</link>
          <pubDate>Thu, 24 Aug 2017 09:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/128/</guid>
          <description>

&lt;h2 id=&#34;hiveとは-https-cwiki-apache-org-confluence-display-hive-home-home-apachehive&#34;&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/Home#Home-ApacheHive&#34;&gt;Hiveとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Hadoop上で動くデータウェアハウスソフトウェア。
SQLを拡張したHiveQLを書くとデータを処理するMapReduceやSpark、Tezのジョブが生成される。
クエリの実行に時間がかかり、耐障害性があるのでDailyやHourlyのバッチで使われる。&lt;/p&gt;

&lt;p&gt;ちなみにAthenaにも使われている&lt;a href=&#34;https://prestodb.io/&#34;&gt;Presto&lt;/a&gt;
はタスクを並列に実行し、中間データをメモリ上に持つことで数分以内に結果が得られるので
ダッシュボードなどの用途でアドホックに使える。中間データが大きいと&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/top-10-performance-tuning-tips-for-amazon-athena/&#34;&gt;時間がかかったり失敗する&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/5-5-x/topics/impala.html&#34;&gt;Impala&lt;/a&gt;はさらに速いけどメモリの消費が激しいらしい。&lt;/p&gt;

&lt;h2 id=&#34;cloudera-docker-imageを起動する-https-www-cloudera-com-documentation-enterprise-latest-topics-quickstart-docker-container-html&#34;&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/latest/topics/quickstart_docker_container.html&#34;&gt;Cloudera Docker Imageを起動する&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Cloudera Docker Imageには&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html&#34;&gt;CDH&lt;/a&gt;: Clouderaのディストリビューション。Hadoop、Hive、SparkなどのOSSで構成されている。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/latest/topics/cloudera_manager.html&#34;&gt;Cloudera Manager&lt;/a&gt;: CDHクラスタを管理する。無料のExpressと有料のEnterpriseで使える機能に&lt;a href=&#34;https://www.cloudera.com/content/dam/www/static/documents/datasheets/cloudera-enterprise-datasheet.pdf&#34;&gt;差がある&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;が含まれていて、これを起動すると諸々立ち上がる。CDHクラスタを組むのはサポートされていないようなのでテスト用らしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull cloudera/quickstart:latest
$ docker run --hostname=quickstart.cloudera --privileged=true -itd -p 8888 -p 7180 -p 80 cloudera/quickstart /usr/bin/docker-quickstart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;80がチュートリアルで、8888がHadoopのWeb UIの&lt;a href=&#34;https://github.com/cloudera/hue&#34;&gt;Hue&lt;/a&gt;、7180がCloudera Manager。Dockerに割り当てるメモリが2GBだと&lt;code&gt;Failed to contact an active Resource Manager&lt;/code&gt;になってしまったので4GBにした。&lt;/p&gt;

&lt;h2 id=&#34;hiveのテーブルを作成して実行する&#34;&gt;Hiveのテーブルを作成して実行する&lt;/h2&gt;

&lt;p&gt;チュートリアルでは&lt;a href=&#34;http://sqoop.apache.org/&#34;&gt;Sqoop&lt;/a&gt;を使ってDBから取り込んでいるんだけど、
今回はjsonのログのテーブルを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sqoop import-all-tables \
    -m 1 \
    --connect jdbc:mysql://localhost:3306/retail_db \
    --username=retail_dba \
    --password=cloudera \
    --compression-codec=snappy \
    --as-parquetfile \
    --warehouse-dir=/user/hive/warehouse \
    --hive-import
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JSONを扱うにはStringから&lt;code&gt;LATERAL VIEW json_tuple(json_str, &amp;quot;field1&amp;quot;, &amp;quot;field2&amp;quot;) j AS field1, field2&lt;/code&gt;のように実行時にパースする方法と、&lt;a href=&#34;https://github.com/rcongiu/Hive-JSON-Serde&#34;&gt;JSON SerDe&lt;/a&gt;で最初から別カラムにいれる方法があるが、今回はSerDeでやる。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;json_tupleを使う場合、配列はStringになってしまうのでこれをArrayにするには便利なUDF(User-Defined Functions)をまとめた&lt;a href=&#34;https://github.com/klout/brickhouse&#34;&gt;brickhouse&lt;/a&gt;のjson_splitが使える。例えば、&lt;code&gt;SELECT col1 FROM table LATERAL VIEW explode(json_split(&#39;[&amp;quot;a&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;c&amp;quot; ]&#39;)) a as ja&lt;/code&gt;のようにするとArrayになったStringがexplodeしてtableの各列に3種のカラムjaが並ぶ。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;col1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;ja&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;x&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;c&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;c&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Arrayが空の場合にexplodeすると消滅してしまうので、LEFT JOINのように残すにはarray(null)に加工してやるとよい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CASE WHEN size(json_split(arr)) &amp;gt; 0 THEN json_split(arr) ELSE array(null) END AS arr
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;JSON SerDeのjarを持ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://www.congiu.net/hive-json-serde/1.3.8/cdh5/json-serde-1.3.8-jar-with-dependencies.jar &amp;gt; /usr/lib/hive/lib/json-serde-1.3.8-jar-with-dependencies.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリはHueから実行できて、初期ユーザー名とパスワードはどちらもcloudera。&lt;/p&gt;

&lt;p&gt;CREATE TABLEはこんな感じ。スキーマ情報はmetastoreに入る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ADD JAR /usr/lib/hive/lib/json-serde-1.3.8-jar-with-dependencies.jar;

CREATE EXTERNAL TABLE jinrou (
        participant ARRAY&amp;lt;STRUCT&amp;lt;user_id:INT,role:STRING,team:STRING&amp;gt;&amp;gt;,
        win_team    STRING,
        ts          STRING
      )
      ROW FORMAT SERDE &#39;org.openx.data.jsonserde.JsonSerDe&#39;
      WITH SERDEPROPERTIES ( &amp;quot;mapping.ts&amp;quot; = &amp;quot;timestamp&amp;quot; )
      LOCATION &#39;/user/cloudera/jinrou&#39;;
      
ADD JAR /usr/lib/hive/lib/hive-contrib.jar;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指定したLOCATIONにログをアップロードする。これもHueからできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;participant&amp;quot;:[{&amp;quot;user_id&amp;quot;:1,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:2,&amp;quot;role&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;wolf&amp;quot;},{&amp;quot;user_id&amp;quot;:3,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:4,&amp;quot;role&amp;quot;:&amp;quot;medium&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:5,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:6,&amp;quot;role&amp;quot;:&amp;quot;fortune-teller&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;}],&amp;quot;win_team&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;timestamp&amp;quot;:&amp;quot;2017-08-21T01:23:45.678+0900&amp;quot;}
{&amp;quot;participant&amp;quot;:[{&amp;quot;user_id&amp;quot;:3,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:4,&amp;quot;role&amp;quot;:&amp;quot;wolf&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;wolf&amp;quot;},{&amp;quot;user_id&amp;quot;:1,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:2,&amp;quot;role&amp;quot;:&amp;quot;medium&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:6,&amp;quot;role&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;},{&amp;quot;user_id&amp;quot;:5,&amp;quot;role&amp;quot;:&amp;quot;fortune-teller&amp;quot;,&amp;quot;team&amp;quot;:&amp;quot;villager&amp;quot;}],&amp;quot;win_team&amp;quot;:&amp;quot;villager&amp;quot;,&amp;quot;timestamp&amp;quot;:&amp;quot;2017-08-21T02:34:56.789+0900&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SELECT文を実行すると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT user_id, role, SUM(is_win)/COUNT(1) AS wp FROM (
  SELECT 
    par.user_id,
    par.role, 
    CASE WHEN par.role = win_team THEN 1 ELSE 0 END AS is_win
    FROM jinrou
  LATERAL VIEW explode(participant) p AS par
) j GROUP BY user_id, role;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参照できている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;user_id,role,wp
1,villager,0.5
2,medium,0.0
2,wolf,1.0
3,villager,0.5
4,medium,0.0
4,wolf,0.0
5,fortune-teller,0.0
5,villager,0.0
6,fortune-teller,0.0
6,villager,1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テーブルの定義よりjsonのフィールドが多いと無視されて、ないものはNULLになる。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog-jp.treasuredata.com/entry/2014/07/10/150250&#34;&gt;『Prestoとは何か，Prestoで何ができるか』 - トレジャーデータ（Treasure Data）公式ブログ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://recruit.gmo.jp/engineer/jisedai/blog/presto_spark_hive/&#34;&gt;スケールアウト可能なSQLエンジンのベンチマークテスト：Presto vs Spark SQL vs Hive on Tez | GMOインターネット 次世代システム研究室&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CloudflareでカスタムドメインのGitHub PagesにHTTPSでアクセスできるようにする</title>
          <link>https://www.sambaiz.net/article/127/</link>
          <pubDate>Mon, 21 Aug 2017 23:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/127/</guid>
          <description>

&lt;p&gt;このサイトはGitHub Pagesでカスタムドメインsambaiz.netを設定して、
Apex Domain(sambaiz.net)に&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain/&#34;&gt;Aレコード&lt;/a&gt;を登録して運用していたのだけれど、これだとカスタムドメインの証明書を置けないのでHTTPSでアクセスすると警告が出てしまう。
いい加減HTTPだと許されない風潮になってきたのでCloudflareを前に挟んでHTTPSでアクセスできるようにした。
ついでにCNAMEを登録できないApex Domain(sambaiz.net)をやめてwww.sambaiz.netに向ける。&lt;/p&gt;

&lt;h2 id=&#34;dnsの設定をする&#34;&gt;DNSの設定をする&lt;/h2&gt;

&lt;p&gt;Cloudflareでドメインを入れると既存のDNS Recordsを読み込むので必要に応じて修正する。
Cloudflareでは&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/200169056-CNAME-Flattening-RFC-compliant-support-for-CNAME-at-the-root&#34;&gt;CNAME Flattening&lt;/a&gt;によってApex Domainにも設定上ではCNAMEを与えることができ、内部でAレコードに解決してくれる。
そのためApex Domainをそのまま使っても実は問題ないのだけど、今後のために変えておく。
www.sambaiz.netにGitHub PagesのCNAMEを設定し、sambaiz.net(@)にはwww.sambaiz.netをCNAMEとして設定した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/127.png&#34; alt=&#34;DNS設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;あとGitHub Pagesの方のカスタムドメインもwww.sambaiz.netにした。
wwwを設定するとApex Domainでアクセスしたときにリダイレクトするように&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain-and-www-subdomain/&#34;&gt;なっている&lt;/a&gt;ので
既存のリンクが切れたり混在することはない。&lt;/p&gt;

&lt;p&gt;指示された&lt;code&gt;*.ns.cloudflare.com&lt;/code&gt;のようなCloudflareのネームサーバーをドメインに設定する。
さくらの場合、Apex Domainのネームサーバーはゾーン表示ではなくWHOIS情報のところから変更できる。
設定してしばらくするとCloudflareを通してアクセスが飛び警告なくHTTPSでアクセスできるようになる。
証明書は共有のものになっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/127-2.png&#34; alt=&#34;共有証明書&#34; /&gt;&lt;/p&gt;

&lt;p&gt;正常にアクセスできることを確認できたら今HTTPになっている画像やリンクもHTTPSにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ find . -name &#39;.git*&#39; -prune -o -name &#39;public&#39; -prune -o -name &#39;static&#39; -prune -o -type d -o -print | xargs sed -i &amp;quot;&amp;quot; &amp;quot;s/http:\/\/sambaiz.net/https:\/\/www.sambaiz.net/g&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cloudflareの機能&#34;&gt;Cloudflareの機能&lt;/h2&gt;

&lt;p&gt;Cloudflareにはいくつか&lt;a href=&#34;https://www.cloudflare.com/plans/&#34;&gt;プラン&lt;/a&gt;があって、今回はFreeプランにした。&lt;/p&gt;

&lt;h3 id=&#34;analytics&#34;&gt;Analytics&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;キャッシュされている/ないリクエスト数や帯域、それによる節約量&lt;/li&gt;
&lt;li&gt;ブロックした&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/204191238-What-are-the-types-of-Threats-&#34;&gt;脅威&lt;/a&gt;の数&lt;/li&gt;
&lt;li&gt;何人/どこの国からアクセスが来たか&lt;/li&gt;
&lt;li&gt;コンテンツ(HTML/CSS/PNG)ごとのリクエストの割合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;などがわかる。FreeだとWeb TrafficやGeographyが直近24時間より短いスパンで取れない。&lt;/p&gt;

&lt;h3 id=&#34;crypto&#34;&gt;Crypto&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudflare.com/ssl/&#34;&gt;SSL&lt;/a&gt;まわりの設定。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Flexible: クライアントとCloudflareはHTTPS、CloudflareとオリジンサーバーはHTTPで通信する。&lt;/li&gt;
&lt;li&gt;Full: デフォルト。Cloudflareとオリジンサーバーの通信もHTTPSで行うが、証明書の検証は行われない。&lt;/li&gt;
&lt;li&gt;Full(Strict) 証明書の検証も行う。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;から選択する。Business以上のPlanだと共有の証明書ではなく独自のものを上げることもできる。&lt;/p&gt;

&lt;p&gt;HTTPで来たらHTTPSにリダイレクトさせるのと、ブラウザでHTTPをHTTPSに置き換える&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/Security/HTTP_Strict_Transport_Security&#34;&gt;HTTP Strict Transport Security(HSTS)&lt;/a&gt;
の設定もある。
HSTSを設定するときに出るように
将来HTTPSをサポートしなくなった場合、HSTSの期限が残っているブラウザからはアクセスできなくなるので注意。
まあ今後HTTPのみに戻すということは考えにくいのだけど、推奨の有効期限は6ヶ月になっている。
あとNo-Sniff Headerの設定もここにあって、これをオンのままにしておくとContent-Typeがtext/cssでない
styleやJavaScriptのMIME Typeでないscriptのリクエストは&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options&#34;&gt;ブロック&lt;/a&gt;しXSSを防ぐ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Strict-Transport-Security: max-age=15552000
X-Content-Type-Options: nosniff
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;firewall&#34;&gt;Firewall&lt;/h3&gt;

&lt;p&gt;IPアドレスや国でブロックしたりとか。Pro以上のプランだと&lt;a href=&#34;https://www.cloudflare.com/waf/&#34;&gt;Web Application Firewall&lt;/a&gt;を有効にできる。&lt;/p&gt;

&lt;h3 id=&#34;speed&#34;&gt;Speed&lt;/h3&gt;

&lt;p&gt;JS/CSS/HTMLを自動でMinifyしたり、モバイルの場合リダイレクトさせたりできる。
Proプランでは画像を最適化してくれる。&lt;/p&gt;

&lt;h3 id=&#34;caching&#34;&gt;Caching&lt;/h3&gt;

&lt;p&gt;キャッシュをパージしたり、どのレベルでキャッシュするかの設定など。&lt;/p&gt;

&lt;h3 id=&#34;page-rules&#34;&gt;Page Rules&lt;/h3&gt;

&lt;p&gt;URL単位でルールを設定できる。example.com/hoge/*は静的なページなのでHTMLもキャッシュするとか。
3つルールが作れて、5つ追加するのに月5ドル。&lt;/p&gt;

&lt;h3 id=&#34;network&#34;&gt;Network&lt;/h3&gt;

&lt;p&gt;最大アップロードサイズやWebSocketを有効にするかなどの設定。
ユーザーのIPアドレスをTrue-Client-IPに乗せるのはEnterpriseプランが必要。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HDFS(Hadoop Distributed File System)とは</title>
          <link>https://www.sambaiz.net/article/126/</link>
          <pubDate>Mon, 14 Aug 2017 22:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/126/</guid>
          <description>

&lt;h2 id=&#34;hdfsとは&#34;&gt;HDFSとは&lt;/h2&gt;

&lt;p&gt;Hadoopの分散ファイルシステム。
Hadoopの抽象化されたファイルシステム実装の一つで、他の実装にはLocal fileやS3などがある。
データのサイズが大きい場合に特に問題になるディスクI/Oを分散させ、
読み書きする最小の単位であるブロックサイズを大きくしシークのコストを減らすことで
スループットを高めている。
ディスクI/Oがどれくらい遅いかというと、
シークがデータセンター内での往復の通信の20倍(10ms)、
1MBの読み込みが40倍の時間(20ms)&lt;a href=&#34;https://gist.github.com/jboner/2841832&#34;&gt;かかる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;一方、小さなデータに低レイテンシでアクセスするというのは得意でなく、
また、1ファイルあたり150バイトのメタデータがNameNodeのメモリ上に乗っかるため大量のファイルを扱うのは大変。
あとデータは追記しかできない。&lt;/p&gt;

&lt;h3 id=&#34;namenodeとdatanode&#34;&gt;NameNodeとDataNode&lt;/h3&gt;

&lt;p&gt;クラスタの中にはおおよそ2種類のノードがあって、
ブロックがあるいくらかのDataNodeと、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ファイルの階層とメタデータ&lt;/li&gt;
&lt;li&gt;どのDataNodeにそのファイルのブロックがあるか&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の情報が含まれる&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;fsimage(メタデータのスナップショット)&lt;/li&gt;
&lt;li&gt;edit log(fsimageに含まれていない変更ログ)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を保存する、名前空間に単一のNameNodeがある。
もう一つSecondary NameNodeというのがあって、これはedit logが大きくならないよう
定期的にedit logをfsimageにマージするもの。&lt;/p&gt;

&lt;p&gt;NameNodeが機能停止すると読み書きできなくなってしまうので、
新しいNameNodeを立てる必要がある。
その際fsimageにedit logを適用して状態を復元するため
これらのファイルを別のファイルシステムにバックアップなどして失われないようにする。&lt;/p&gt;

&lt;p&gt;巨大なクラスタだとNameNodeを立ち上げるのに30分以上かかることもあるため、
Secondary NameNodeの代わりにStandby NameNodeを立ててHigh Availabilityにすることもできる。
Standby NameNodeはNameNodeと共有ストレージでedit logを共有し、最新の状態がメモリ上に乗っているので
NameNodeが死んだと判断されてから数十秒ほどで切り替えることができる。&lt;/p&gt;

&lt;h2 id=&#34;書き込みと読み込み&#34;&gt;書き込みと読み込み&lt;/h2&gt;

&lt;h3 id=&#34;書き込み&#34;&gt;書き込み&lt;/h3&gt;

&lt;p&gt;ファイルシステムがNameNodeとやりとりして、ファイルが存在しているか、パーミッションがあるかを確認し、問題なければFSDataOutputStreamをクライアントに返す。
書き込むデータはdata queueにまず入って、
どのDataNodeに書き込むかはDataStreamerというのがNameNodeとやりとりして決める。
レプリカの設定数分DataNodeが選ばれ、順に書き込まれるようDataNode間でパイプラインを作る。
正常に書き込まれたDetaNodeからはack packetが返ってくるのでこれはack queryに入れて
全て正しく書き込まれたことが確認できたら消す。
失敗したDataNodeがあったら、そこに中途半端に書き込まれた分を復活したら消すようにして、パイプラインから除き
新しいパイプラインを作る。&lt;/p&gt;

&lt;h3 id=&#34;読み込み&#34;&gt;読み込み&lt;/h3&gt;

&lt;p&gt;ファイルシステムがNameNodeにファイルのブロックがどこにあるかを聞く。
NameNodeは、ブロックがあるDataNodeをクライアントからネットワークトポロジ的に近い順にソートしてアドレスを返す。
ファイルシステムはそのアドレスが含まれたFSDataInputStreamをクライアントに返して、クライアントが順にreadしていく。&lt;/p&gt;

&lt;h2 id=&#34;singlenode-clusterで動かす-http-hadoop-apache-org-docs-current-hadoop-project-dist-hadoop-common-singlecluster-html&#34;&gt;&lt;a href=&#34;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html&#34;&gt;SingleNode Clusterで動かす&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ yum --enablerepo=epel -y install pdsh
$ echo $JAVA_HOME
/usr/lib/jvm/jre
$ wget http://ftp.jaist.ac.jp/pub/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz
$ tar xvzf hadoop-2.7.3.tar.gz 
$ cd hadoop-2.7.3
$ bin/hadoop version
Hadoop 2.7.3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デフォルトのファイルシステムをHDFSにしてレプリカを1にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vi etc/hadoop/core-site.xml
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
...
&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;

$ vi etc/hadoop/hdfs-site.xml
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
...
&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hadoopデーモンを起動/終了させるためにsshできるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa
$ cat ~/.ssh/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
$ ssh localhost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs namenode -format
$ sbin/start-dfs.sh
localhost: starting namenode, ...
localhost: starting datanode, ...
0.0.0.0: starting secondarynamenode, ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ディレクトリやファイルを作成して参照する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs dfs -mkdir /home
$ bin/hdfs dfs -mkdir /user/ec2-user
$ echo &#39;aaaaa&#39; &amp;gt; hoge
$ bin/hdfs dfs -put hoge ./
$ bin/hdfs dfs -put hoge ./
put: `hoge&#39;: File exists

$ bin/hdfs dfs -appendToFile hoge hoge
$ bin/hdfs dfs -ls ./
Found 1 items
-rw-r--r--   1 ec2-user supergroup         12 2017-08-14 13:44 hoge

$ bin/hdfs dfs -cat hoge
aaaaa
aaaaa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Filesystem check utilityを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/hdfs fsck ./ -files -blocks
Connecting to namenode via http://localhost:50070/fsck?ugi=ec2-user&amp;amp;files=1&amp;amp;blocks=1&amp;amp;path=%2Fuser%2Fec2-user
FSCK started by ec2-user (auth:SIMPLE) from /127.0.0.1 for path /user/ec2-user at Mon Aug 14 13:44:48 UTC 2017
/user/ec2-user &amp;lt;dir&amp;gt;
/user/ec2-user/hoge 12 bytes, 1 block(s):  OK
0. BP-478671077-172.31.3.159-1502715364675:blk_1073741825_1002 len=12 repl=1

Status: HEALTHY
 Total size:	12 B
 Total dirs:	1
 Total files:	1
 Total symlinks:		0
 Total blocks (validated):	1 (avg. block size 12 B)
 Minimally replicated blocks:	1 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	0 (0.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	1
 Average block replication:	1.0
 Corrupt blocks:		0
 Missing replicas:		0 (0.0 %)
 Number of data-nodes:		1
 Number of racks:		1
FSCK ended at Mon Aug 14 13:44:48 UTC 2017 in 2 milliseconds
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://shop.oreilly.com/product/0636920033448.do&#34;&gt;Hadoop: The Definitive Guide, 4th Edition&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.cloudera.com/blog/2014/03/a-guide-to-checkpointing-in-hadoop/&#34;&gt;A Guide to Checkpointing in Hadoop – Cloudera Engineering Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PythonのLintとFormatter</title>
          <link>https://www.sambaiz.net/article/125/</link>
          <pubDate>Fri, 11 Aug 2017 14:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/125/</guid>
          <description>

&lt;h2 id=&#34;yapf-https-github-com-google-yapf&#34;&gt;&lt;a href=&#34;https://github.com/google/yapf&#34;&gt;YAPF&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;スタイルに沿って整形してくれる、Goでいう&lt;code&gt;go fmt&lt;/code&gt;みたいなもの。
デフォルトはPython公式のスタイルガイド&lt;a href=&#34;https://www.python.org/dev/peps/pep-0008/&#34;&gt;PEP8&lt;/a&gt;でフォーマットされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install yapf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VSCodeでPythonを書くときは、
&lt;a href=&#34;https://github.com/DonJayamanne/pythonVSCode/wiki&#34;&gt;Pythonプラグイン&lt;/a&gt;
を入れてこんな設定をWorkspaceのconfigに入れておいて、
保存した時にフォーマットがかかるようにすると快適。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;editor.formatOnSave&amp;quot;: true,
&amp;quot;python.formatting.provider&amp;quot;: &amp;quot;yapf&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lint&#34;&gt;Lint&lt;/h2&gt;

&lt;p&gt;YAPFでフォーマットされた以下のコードにLintをかける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class FizzBuzz:
    def __init__(self, start=0):
        self.num = start

    def __iter__(self):
        return self

    def __next__(self):
        self.num += 1
        if self.num % 15 == 0:
            return &amp;quot;FizzBuzz&amp;quot;
        if self.num % 3 == 0:
            return &amp;quot;Fizz&amp;quot;
        if self.num % 5 == 0:
            return &amp;quot;Buzz&amp;quot;
        return self.num


if __name__ == &amp;quot;__main__&amp;quot;:
    fizzBuzz = FizzBuzz()
    for i in range(100):
        print(next(fizzBuzz))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pylint&#34;&gt;Pylint&lt;/h3&gt;

&lt;p&gt;Pythonプラグインではデフォルトで&lt;a href=&#34;https://github.com/PyCQA/pylint/&#34;&gt;Pylint&lt;/a&gt;が使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install pylint
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必要ならパスをUserのconfigでパスを指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;python.linting.pylintPath&amp;quot;: &amp;quot;***&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コマンドライン上で実行するとこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pylint main.py 
No config file found, using default configuration
************* Module main
C: 22, 0: Final newline missing (missing-final-newline)
C:  1, 0: Missing module docstring (missing-docstring)
C:  1, 0: Missing class docstring (missing-docstring)
R:  1, 0: Too few public methods (0/2) (too-few-public-methods)
C: 20, 4: Invalid constant name &amp;quot;fizzBuzz&amp;quot; (invalid-name)

-----------------------------------
Your code has been rated at 7.22/10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指摘された項目を見ると下の二つは余計かなと感じる。
そんな場合、コメントで&lt;code&gt;# pylint: disable=invalid-name&lt;/code&gt;のように書くか、
設定ファイル&lt;code&gt;pylintrc&lt;/code&gt;のdisableに追加すれば無視できる。
&lt;code&gt;--generate-rc-file&lt;/code&gt;でとても長い設定ファイルが生成される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pylint --generate-rcfile &amp;gt; pylintrc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;10点満点にしたのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot;
FizzBuzz main
&amp;quot;&amp;quot;&amp;quot;

class FizzBuzz: # pylint: disable=too-few-public-methods
    &amp;quot;&amp;quot;&amp;quot;
    FizzBuzz is incrementing a number and
    if the number is divisible by both 3 and 5, output &amp;quot;FizzBuzz&amp;quot;,
    if divisible by 3, &amp;quot;Fizz&amp;quot;,
    if divisible by 5, &amp;quot;Buzz&amp;quot;,
    Otherwise, output the number.
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(self, start=0):
        self.num = start

    def __iter__(self):
        return self

    def __next__(self):
        self.num += 1
        if self.num % 15 == 0:
            return &amp;quot;FizzBuzz&amp;quot;
        if self.num % 3 == 0:
            return &amp;quot;Fizz&amp;quot;
        if self.num % 5 == 0:
            return &amp;quot;Buzz&amp;quot;
        return self.num

if __name__ == &amp;quot;__main__&amp;quot;:
    fizzBuzz = FizzBuzz() # pylint: disable=invalid-name
    for i in range(100):
        print(next(fizzBuzz))
        
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;flake8-https-github-com-pycqa-flake8&#34;&gt;&lt;a href=&#34;https://github.com/PyCQA/flake8&#34;&gt;Flake8&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;他のLintとしてFlake8を使うこともできる。これは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/PyCQA/pyflakes&#34;&gt;PyFlakes&lt;/a&gt;: エラー&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/PyCQA/pycodestyle&#34;&gt;pycodestyle&lt;/a&gt;(元pep8): PEP8&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pycqa/mccabe&#34;&gt;Ned Batchelder&amp;rsquo;s McCabe script&lt;/a&gt;: &lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%BE%AA%E7%92%B0%E7%9A%84%E8%A4%87%E9%9B%91%E5%BA%A6&#34;&gt;循環的複雑度&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のチェッカーを合わせたもの。
&lt;a href=&#34;https://github.com/PyCQA/flake8-docstrings&#34;&gt;docstring&lt;/a&gt;は別に入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install flake8 flake8_docstrings
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VSCodeでの設定はこんな感じ。Pylintと同時に使うこともできなくはない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;python.linting.pylintEnabled&amp;quot;: false
&amp;quot;python.linting.flake8Enabled&amp;quot;: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同じコードにLintをかけてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ flake8 main.py
main.py:1:1: D100 Missing docstring in public module
main.py:1:1: D101 Missing docstring in public class
main.py:2:1: D102 Missing docstring in public method
main.py:5:1: D105 Missing docstring in magic method
main.py:8:1: D105 Missing docstring in magic method
main.py:22:30: W292 no newline at end of file
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;flake8-docstringは&lt;a href=&#34;https://www.python.org/dev/peps/pep-0257/&#34;&gt;PEP257&lt;/a&gt;に忠実にチェックしているのでちょっと厳しめ。&lt;code&gt;# flake8: noqa:D105&lt;/code&gt;のように無視することもできるし、
設定ファイル&lt;code&gt;.flake8&lt;/code&gt;に書くこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[flake8]
ignore = D105
exclude =
    .git,
    __pycache__,
    build,
    dist
max-complexity = 10
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;加えてmypyを使うとType Hintsによる型の整合性をチェックできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/188/&#34;&gt;PythonのType Hintsとmypy - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
          <link>https://www.sambaiz.net/article/124/</link>
          <pubDate>Sun, 06 Aug 2017 23:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/124/</guid>
          <description>

&lt;p&gt;AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリ&lt;a href=&#34;https://github.com/deepmind/sonnet&#34;&gt;Sonnet&lt;/a&gt;を使う。
当初はPython2しか対応していないようだったけど、今は3にも対応している。&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;TensorFlowを使うライブラリはほかにもいくつかあるのだけど、
&lt;a href=&#34;https://github.com/fchollet/keras&#34;&gt;Keras&lt;/a&gt;と比較してみると、
KerasがTensorFlowの部分を完全にラップしているのに対して、
Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。&lt;/p&gt;

&lt;p&gt;SonnetとTensorFlowとPython3入りイメージをDockerHubに&lt;a href=&#34;https://hub.docker.com/r/sambaiz/sonnet/&#34;&gt;上げた&lt;/a&gt;。
Dockerfileは&lt;a href=&#34;https://github.com/sambaiz/docker-sonnet&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;内容は基本的にREADME通りだけど、
configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。
あとは、&lt;a href=&#34;https://github.com/deepmind/sonnet/issues/25&#34;&gt;TensorFlowのビルドに使われているGCCのバージョンが古い&lt;/a&gt;ようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに&lt;code&gt;--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;&lt;/code&gt;を付けている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet
$ docker logs sonnet
...
   Copy/paste this URL into your browser when you connect for the first time,
    to login with a token:
        http://localhost:8888/?token=*****
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sonnet as snt
import tensorflow as tf
snt.resampler(tf.constant([0.]), tf.constant([0.]))
# =&amp;gt; &amp;lt;tf.Tensor &#39;resampler/Resampler:0&#39; shape=(1,) dtype=float32&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mnist&#34;&gt;MNIST&lt;/h2&gt;

&lt;p&gt;TensorFlowのチュートリアルのデータを使って、畳み込みを行わない簡単なMNISTをやってみる。
このデータはtrain、validation、test用に最初から&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/contrib/learn/python/learn/datasets/base.py#L37&#34;&gt;分かれていて&lt;/a&gt;、
それぞれピクセル濃度配列の画像データと、その画像がどの数字なのかを表すone-hot vectorのラベルを&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/contrib/learn/python/learn/datasets/mnist.py#L105&#34;&gt;含んでいる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)
train, validation, test = mnist
print(train.images[0]) # ピクセルの濃度を[0,1]の値で表した配列: [0, 0, ..., 0.41568631  0.6156863, 0.99607849, ...]
print(len(train.images[0])) # 28 * 28 = 784
print(train.labels[0]) # 正解のみ1のone-hot vector: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]
images, labels = mnist.train.next_batch(100)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sonnetではニューラルネットワークの一部をModuleとして表現し、それらをTensorFlowの計算グラフに接続していく。
Moduleはグラフに複数回接続することができ、中の変数は共有される。
素のTensorFlowだと&lt;a href=&#34;https://www.tensorflow.org/programmers_guide/variable_scope&#34;&gt;変数のスコープ&lt;/a&gt;を作って共有するのに
reuse=Trueで&lt;code&gt;tf.variable_scope&lt;/code&gt;して&lt;code&gt;tf.get_variable&lt;/code&gt;したりするけど、そのあたりは抽象化されているので
&lt;code&gt;tf.Variable&lt;/code&gt;を含むような処理はModuleで行う。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/deepmind/sonnet/blob/v1.8/sonnet/python/modules/basic.py&#34;&gt;Linear Module&lt;/a&gt;は
重みの乗算とバイアスの加算をするもの。
これに&lt;code&gt;tf.Sigmoid&lt;/code&gt;のような活性化関数を適用するのを繰り返し、最後に出力層とつなげるとMulti Layer Perceptronを構築できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sonnet as snt
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

FLAGS = tf.flags.FLAGS

tf.flags.DEFINE_integer(&amp;quot;hidden_size&amp;quot;, 100, &amp;quot;Size of hidden layer.&amp;quot;)
tf.flags.DEFINE_integer(&amp;quot;output_size&amp;quot;, 10, &amp;quot;Size of output layer.&amp;quot;)

mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)

x = tf.placeholder(tf.float32, [None, 784])
y_ = tf.placeholder(tf.float32, [None, 10])
lin_to_hidden = snt.Linear(output_size=FLAGS.hidden_size, name=&#39;inp_to_hidden&#39;)
hidden_to_out = snt.Linear(output_size=FLAGS.output_size, name=&#39;hidden_to_out&#39;)
mlp = snt.Sequential([lin_to_hidden, tf.sigmoid, hidden_to_out, tf.nn.softmax])
y = mlp(x)
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(1000):
        images, labels = mnist.train.next_batch(100)
        sess.run(train_step, feed_dict={x: mnist.train.images, y_: mnist.train.labels})
    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
    # =&amp;gt; 0.9307
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;moduleを作る&#34;&gt;Moduleを作る&lt;/h2&gt;

&lt;p&gt;Moduleを作るには&lt;code&gt;snt.AbstractModule&lt;/code&gt;を継承し、
スーパークラスのコンストラクタを呼んで、グラフに接続されるたびに呼ばれる&lt;code&gt;_build&lt;/code&gt;メソッドを実装する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class MyMLP(snt.AbstractModule):
  &amp;quot;&amp;quot;&amp;quot;test mlp module&amp;quot;&amp;quot;&amp;quot;
  def __init__(self, hidden_size, output_size,
               nonlinearity=tf.sigmoid, name=&amp;quot;my_mlp&amp;quot;):
    &amp;quot;&amp;quot;&amp;quot;hidden_size &amp;amp; output_size is required&amp;quot;&amp;quot;&amp;quot;
    super(MyMLP, self).__init__(name=name)
    self._hidden_size = hidden_size
    self._output_size = output_size
    self._nonlinearity = nonlinearity
  
  def _build(self, inputs):
    &amp;quot;&amp;quot;&amp;quot;Compute output Tensor from input Tensor.&amp;quot;&amp;quot;&amp;quot;
    lin_to_hidden = snt.Linear(output_size=self._hidden_size, name=&#39;inp_to_hidden&#39;)
    hidden_to_out = snt.Linear(output_size=self._output_size, name=&#39;hidden_to_out&#39;)
    return snt.Sequential([lin_to_hidden, self._nonlinearity, hidden_to_out, tf.nn.softmax])(inputs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このModuleを使うとこんな感じ。
&lt;a href=&#34;https://github.com/deepmind/sonnet/blob/v1.8/sonnet/examples/dataset_shakespeare.py#L177&#34;&gt;example&lt;/a&gt;のように
データセットもModuleにすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)

mymlp = MyMLP(hidden_size=FLAGS.hidden_size, output_size=FLAGS.output_size)

x = tf.placeholder(tf.float32, [None, 784])
y_ = tf.placeholder(tf.float32, [None, 10])
y = mymlp(x)
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(1000):
        images, labels = mnist.train.next_batch(100)
        sess.run(train_step, feed_dict={x: mnist.train.images, y_: mnist.train.labels})
    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
    # =&amp;gt; 0.9307
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsをTypeScriptで書く</title>
          <link>https://www.sambaiz.net/article/123/</link>
          <pubDate>Sat, 29 Jul 2017 19:34:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/123/</guid>
          <description>

&lt;p&gt;公式の&lt;a href=&#34;https://github.com/Microsoft/TypeScript-Node-Starter&#34;&gt;TypeScript-Node-Starter&lt;/a&gt;から始めてもいいけど、依存が少し余分なので一から作ることにした。&lt;/p&gt;

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/typescript-nodejs-sample&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev typescript tslint tslint-microsoft-contrib jest ts-jest @types/jest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;package-json&#34;&gt;package.json&lt;/h2&gt;

&lt;p&gt;scriptsとテストフレームワーク&lt;a href=&#34;https://facebook.github.io/jest/&#34;&gt;Jest&lt;/a&gt;の設定を追加。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;devDependencies&amp;quot;: {
    ...
    &amp;quot;typescript&amp;quot;: &amp;quot;^2.4.2&amp;quot;
  },
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;start&amp;quot;: &amp;quot;npm run build &amp;amp;&amp;amp; node dist/app.js&amp;quot;,
    &amp;quot;build&amp;quot;: &amp;quot;npm run lint &amp;amp;&amp;amp; tsc&amp;quot;,
    &amp;quot;test&amp;quot;: &amp;quot;jest --forceExit&amp;quot;,
    &amp;quot;lint&amp;quot;: &amp;quot;tslint -c tslint.json -p tsconfig.json --type-check&amp;quot;
  },
  &amp;quot;jest&amp;quot;: {
    &amp;quot;transform&amp;quot;: {
      &amp;quot;^.+\\.ts$&amp;quot;: &amp;quot;./node_modules/ts-jest/preprocessor.js&amp;quot;
    },
    &amp;quot;testRegex&amp;quot;: &amp;quot;/test/.*\\.test\\.(ts|js)$&amp;quot;,
    &amp;quot;moduleFileExtensions&amp;quot;: [
      &amp;quot;ts&amp;quot;,
      &amp;quot;js&amp;quot;
    ],
    &amp;quot;testEnvironment&amp;quot;: &amp;quot;node&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tsconfig-json-https-www-typescriptlang-org-docs-handbook-tsconfig-json-html&#34;&gt;&lt;a href=&#34;https://www.typescriptlang.org/docs/handbook/tsconfig-json.html&#34;&gt;tsconfig.json&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;公式のそのまま。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;compilerOptions&amp;quot;: {
        &amp;quot;module&amp;quot;: &amp;quot;commonjs&amp;quot;,
        &amp;quot;target&amp;quot;: &amp;quot;es6&amp;quot;,
        &amp;quot;noImplicitAny&amp;quot;: true,
        &amp;quot;moduleResolution&amp;quot;: &amp;quot;node&amp;quot;,
        &amp;quot;sourceMap&amp;quot;: true,
        &amp;quot;outDir&amp;quot;: &amp;quot;dist&amp;quot;,
        &amp;quot;baseUrl&amp;quot;: &amp;quot;.&amp;quot;,
        &amp;quot;paths&amp;quot;: {
            &amp;quot;*&amp;quot;: [
                &amp;quot;node_modules/*&amp;quot;,
                &amp;quot;src/types/*&amp;quot;
            ]
        }
    },
    &amp;quot;include&amp;quot;: [
        &amp;quot;src/**/*&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tslint-json-https-palantir-github-io-tslint-usage-tslint-json&#34;&gt;&lt;a href=&#34;https://palantir.github.io/tslint/usage/tslint-json/&#34;&gt;tslint.json&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;MSでも使われているらしいルールを使うことにする。
結構厳しくて&lt;code&gt;console.log&lt;/code&gt;なんかもエラーになるので必要に応じてruleを追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;extends&amp;quot;: &amp;quot;tslint-microsoft-contrib&amp;quot;,
    &amp;quot;rules&amp;quot;: {
        &amp;quot;no-console&amp;quot;: [&amp;quot;&amp;quot;],
        &amp;quot;no-relative-imports&amp;quot;: false,
        &amp;quot;no-http-string&amp;quot;: false,
        &amp;quot;no-backbone-get-set-outside-model&amp;quot;: false
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使うパッケージをインストール&#34;&gt;使うパッケージをインストール&lt;/h2&gt;

&lt;p&gt;本体と型。&lt;/p&gt;

&lt;p&gt;以前は型ファイルを持ってくるのにtsdとかtypingsが使われていたけど
今は&lt;a href=&#34;https://github.com/DefinitelyTyped/DefinitelyTyped&#34;&gt;DefinelyTyped&lt;/a&gt;の内容が
npmの@types/~に&lt;a href=&#34;https://github.com/Microsoft/types-publisher&#34;&gt;上がる&lt;/a&gt;ようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add express
$ yarn add --dev @types/express
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;コードを書く&#34;&gt;コードを書く&lt;/h2&gt;

&lt;p&gt;VSCodeだったらtslintプラグインがあるので入れる。tsとtslintをglobal installする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import * as express from &#39;express&#39;;

/**
 * GET /echo
 * Return a string same as &amp;quot;say&amp;quot; query param.
 */
export function echoApi(req: express.Request, res: express.Response): void {

    const query: { say: string } = &amp;lt;{ say: string }&amp;gt; req.query;
    if (query.say === undefined) {
        res.send(echo(query.say));
    } else {
        res.status(400).send(&#39;&amp;quot;say&amp;quot; query param is required&#39;);
    }
}

/**
 * return a string same as input
 * @param say input (= output)
 */
export function echo(say: string): string {
    return say;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;テストを書く&#34;&gt;テストを書く&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/visionmedia/superagent&#34;&gt;superagent&lt;/a&gt;を使って
HTTPサーバーのテストを行う&lt;a href=&#34;https://github.com/visionmedia/supertest&#34;&gt;supertest&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yarn add --dev supertest @types/supertest
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import * as supertest from &#39;supertest&#39;;
import { app } from &#39;../src/app&#39;;
import { echo } from &#39;../src/echo&#39;;

let request: supertest.SuperTest&amp;lt;supertest.Test&amp;gt;;
beforeAll(() =&amp;gt; {
  request = supertest(app);
});

/**
 * integration test
 */
describe(&#39;GET /echo&#39;, () =&amp;gt; {
  it(&#39;should return a string same as &amp;quot;say&amp;quot; query param&#39;, (): {} =&amp;gt; {
    const say: string = &#39;Aa 1あ&#39;;

    return request
    .get(&#39;/echo&#39;)
    .query({ say: say })
    .expect(200, say);
  });

  it(&#39;is bad request that &amp;quot;say&amp;quot; query param is not given&#39;, (): {} =&amp;gt; {
    return request
    .get(&#39;/echo&#39;)
    .expect(400);
  });
});

/**
 * unit test
 */
describe(&#39;echo&#39;, () =&amp;gt; {
  it(&#39;should return a string same as input&#39;, () =&amp;gt; {
    const say: string = &#39;Aa 1あ&#39;;
    expect(echo(say)).toBe(say);
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;requestしたのをreturnするのを忘れるとテストが無条件で通ってしまうので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm test
...
 PASS  test/echo.test.ts
  GET /echo
    ✓ should return a string same as &amp;quot;say&amp;quot; query param (34ms)
    ✓ is bad request that &amp;quot;say&amp;quot; query param is not given (4ms)
  echo
    ✓ should return a string same as input (1ms)

Test Suites: 1 passed, 1 total
Tests:       3 passed, 3 total
Snapshots:   0 total
Time:        1.601s, estimated 2s
Ran all test suites.
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>KubernetesのパッケージマネージャーHelmを使う</title>
          <link>https://www.sambaiz.net/article/122/</link>
          <pubDate>Wed, 26 Jul 2017 01:33:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/122/</guid>
          <description>&lt;p&gt;Kubernatesが操舵手なのに対して、Helmは舵。
パッケージは&lt;a href=&#34;https://github.com/kubernetes/charts&#34;&gt;Chart&lt;/a&gt;(海図)と呼ばれている。&lt;/p&gt;

&lt;p&gt;ChartにはデフォルトでGoのtemplateで書かれた&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/deployment.yaml&#34;&gt;Manifest&lt;/a&gt;が含まれ、&lt;a href=&#34;https://github.com/helm/charts/blob/master/stable/mysql/values.yaml&#34;&gt;values.yaml&lt;/a&gt;の値を&lt;code&gt;-f values.yaml&lt;/code&gt;や&lt;code&gt;--set key=value&lt;/code&gt;フラグで上書きして適用しインストールすることができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/helm&#34;&gt;Helm&lt;/a&gt;コマンドをインストールする。
今回は&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;minikube&lt;/a&gt;に入れるので立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install kubernetes-helm
$ helm version
Client: &amp;amp;version.Version{SemVer:&amp;quot;v2.5.0&amp;quot;, GitCommit:&amp;quot;012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}

# brew cask install virtualbox minikube
$ minikube version
minikube version: v0.20.0

$ minikube start
Kubectl is now configured to use the cluster.

$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.2&amp;quot;, GitCommit:&amp;quot;922a86cfcd65915a9b2f69f3f193b8907d741d9c&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2017-07-21T19:06:19Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;darwin/amd64&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;6&amp;quot;, GitVersion:&amp;quot;v1.6.4&amp;quot;, GitCommit:&amp;quot;d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-06-22T04:31:09Z&amp;quot;, GoVersion:&amp;quot;go1.7.5&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}

$ kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずk8sクラスタ上にHelmの管理サーバーTillerをインストールする必要がある。
ついでにリポジトリをupdateする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm init
$ ls ~/.helm/
cache		plugins		repository	starters

$ helm repo update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-search&#34;&gt;search&lt;/a&gt;でChartを検索する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm search mysql
NAME                  	VERSION	DESCRIPTION                                       
stable/mysql          	0.2.6  	Fast, reliable, scalable, and easy to use open-...
stable/percona        	0.2.0  	free, fully compatible, enhanced, open source d...
stable/gcloud-sqlproxy	0.1.0  	Google Cloud SQL Proxy                            
stable/mariadb        	0.6.3  	Fast, reliable, scalable, and easy to use open-...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-inspect&#34;&gt;inspect&lt;/a&gt;でChartの情報を見ることができる。
&lt;code&gt;---&lt;/code&gt;の上がChartの情報のChart.yamlで、下がvalues.yaml。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm inspect stable/mysql
description: Fast, reliable, scalable, and easy to use open-source relational database
  system.
engine: gotpl
home: https://www.mysql.com/
icon: https://www.mysql.com/common/logos/logo-mysql-170x115.png
keywords:
- mysql
- database
- sql
maintainers:
- email: viglesias@google.com
  name: Vic Iglesias
name: mysql
sources:
- https://github.com/kubernetes/charts
- https://github.com/docker-library/mysql
version: 0.2.6

---
## mysql image version
## ref: https://hub.docker.com/r/library/mysql/tags/
##
image: &amp;quot;mysql&amp;quot;
imageTag: &amp;quot;5.7.14&amp;quot;

## Specify password for root user
##
## Default: random 10 character string
# mysqlRootPassword: testing

## Create a database user
##
# mysqlUser:
# mysqlPassword:

## Allow unauthenticated access, uncomment to enable
##
# mysqlAllowEmptyPassword: true

## Create a database
##
# mysqlDatabase:

## Specify an imagePullPolicy (Required)
## It&#39;s recommended to change this to &#39;Always&#39; if the image tag is &#39;latest&#39;
## ref: http://kubernetes.io/docs/user-guide/images/#updating-images
##
imagePullPolicy: IfNotPresent

## Persist data to a persitent volume
persistence:
  enabled: true
  ## If defined, volume.beta.kubernetes.io/storage-class: &amp;lt;storageClass&amp;gt;
  ## Default: volume.alpha.kubernetes.io/storage-class: default
  ##
  # storageClass:
  accessMode: ReadWriteOnce
  size: 8Gi

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 256Mi
    cpu: 100m

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mysqlDatabaseの値を渡してinstallしてみる。
パスワードなどをを保持する&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret/&#34;&gt;Secret&lt;/a&gt;、
&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;Persistent Volumes&lt;/a&gt;(PV)を要求する&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;PersistentVolumeClaim&lt;/a&gt;(PVC)と
ServiceとDeploymentが作成された。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{mysqlDatabase: user0db}&#39; &amp;gt; config.yaml
$ helm install -f config.yaml stable/mysql
...
RESOURCES:
==&amp;gt; v1/Secret
NAME                    TYPE    DATA  AGE
pioneering-hydra-mysql  Opaque  2     1s

==&amp;gt; v1/PersistentVolumeClaim
NAME                    STATUS  VOLUME                                    CAPACITY  ACCESSMODES  STORAGECLASS  AGE
pioneering-hydra-mysql  Bound   pvc-9649c097-7088-11e7-8dd5-0800270629d8  8Gi       RWO          standard      1s

==&amp;gt; v1/Service
NAME                    CLUSTER-IP  EXTERNAL-IP  PORT(S)   AGE
pioneering-hydra-mysql  10.0.0.216  &amp;lt;none&amp;gt;       3306/TCP  1s

==&amp;gt; v1beta1/Deployment
NAME                    DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
pioneering-hydra-mysql  1        1        1           0          1s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pods
NAME                                      READY     STATUS    RESTARTS   AGE
pioneering-hydra-mysql-3456603420-0pldk   1/1       Running   0          4m
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/secrets.yaml#L15&#34;&gt;生成された&lt;/a&gt;Secretの値は&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/mysql/templates/deployment.yaml#L44&#34;&gt;secretKeyRef&lt;/a&gt;で参照できる。&lt;/p&gt;

&lt;p&gt;PVというのはクラスタにプロビジョニングされる、Podとは独立したライフサイクルを持つVolume。&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#storageclasses&#34;&gt;StorageClass&lt;/a&gt;、ReadWriteOnceのようなアクセスモード、容量を含むPVCでリクエストする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get storageclasses
NAME                 TYPE
standard (default)   k8s.io/minikube-hostpath 
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Secretからrootパスワードを取得し、他のpodから接続できるのとDBが作成されていることを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get secret --namespace default pioneering-hydra-mysql -o jsonpath=&amp;quot;{.data.mysql-root-password}&amp;quot; | base64 --decode; echo
******

$ kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il
$ apt-get update &amp;amp;&amp;amp; apt-get install mysql-client -y
$ mysql -h pioneering-hydra-mysql -p
mysql&amp;gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
| user0db            |
+--------------------+
5 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.helm.sh/helm/#helm-list&#34;&gt;ls&lt;/a&gt;でインストールしたものを確認でき、
&lt;a href=&#34;https://docs.helm.sh/helm/#helm-delete&#34;&gt;delete&lt;/a&gt;で削除できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm ls
NAME            	REVISION	UPDATED                 	STATUS CHART      	NAMESPACE
pioneering-hydra	1       	Tue Jul 25 00:55:59 2017	DEPLOYEmysql-0.2.6	default  

$ helm delete pioneering-hydra
$ kubectl get secret --namespace default pioneering-hydra-mysql -o jsonpath=&amp;quot;{.data.mysql-root-password}&amp;quot; | base64 --decode; echo
Error from server (NotFound): secrets &amp;quot;pioneering-hydra-mysql&amp;quot; not found
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TerraformでVPCを管理するmoduleを作る</title>
          <link>https://www.sambaiz.net/article/121/</link>
          <pubDate>Sun, 23 Jul 2017 02:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/121/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install terraform
$ terraform -v
Terraform v0.9.11
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;terraformの設定要素&#34;&gt;Terraformの設定要素&lt;/h2&gt;

&lt;h3 id=&#34;provider-https-www-terraform-io-docs-providers-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/index.html&#34;&gt;provider&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;IaaS(e.g. AWS)、PaaS(e.g. Heroku)、SaaS(e.g. CloudFlare)など。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/&#34;&gt;AWS Provider&lt;/a&gt;はこんな感じ。
ここに直接access_keyやsecret_keyを書くこともできるけど、誤って公開されてしまわないように環境変数か
variableで渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;aws&amp;quot; {
  # access_key = &amp;quot;${var.access_key}&amp;quot;
  # secret_key = &amp;quot;${var.secret_key}&amp;quot;
  region = &amp;quot;us-east-1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ export AWS_ACCESS_KEY_ID=&amp;quot;anaccesskey&amp;quot;
$ export AWS_SECRET_ACCESS_KEY=&amp;quot;asecretkey&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;varibale-https-www-terraform-io-docs-configuration-variables-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/variables.html&#34;&gt;varibale&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;CLIでオーバーライドできるパラメーター。typeにはstringのほかにmapやlistを渡すことができ、
何も渡さないとdefault値のものが、それもなければstringになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;key&amp;quot; {
  type    = &amp;quot;string&amp;quot;
  default = &amp;quot;value&amp;quot;
  description = &amp;quot;description&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;値を渡す方法はTF_VAR_をprefixとする環境変数、-var、-var-fileがある。
また、moduleのinputとして渡されることもある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export TF_VAR_somelist=&#39;[&amp;quot;ami-abc123&amp;quot;, &amp;quot;ami-bcd234&amp;quot;]&#39;
$ terraform apply -var foo=bar -var foo=baz
$ terraform apply -var-file=foo.tfvars -var-file=bar.tfvars
$ cat foo.tfvars
foo = &amp;quot;bar&amp;quot;
xyz = &amp;quot;abc&amp;quot;

somelist = [
  &amp;quot;one&amp;quot;,
  &amp;quot;two&amp;quot;,
]

somemap = {
  foo = &amp;quot;bar&amp;quot;
  bax = &amp;quot;qux&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;output-https-www-terraform-io-docs-configuration-outputs-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/outputs.html&#34;&gt;output&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;variableがinputなのに対して、こちらはoutput。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;output &amp;quot;ip&amp;quot; {
  value = &amp;quot;${aws_eip.ip.public_ip}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行した後に取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform apply
...

$ terraform output ip
50.17.232.209
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;resource-https-www-terraform-io-docs-configuration-resources-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/resources.html&#34;&gt;resource&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;物理サーバーやVMのような低レベルのものからDNSレコードのような高レベルのものまで含むインフラのコンポーネント。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_instance&amp;quot; &amp;quot;web&amp;quot; {
  ami           = &amp;quot;ami-408c7f28&amp;quot;
  instance_type = &amp;quot;t1.micro&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;provisioner-https-www-terraform-io-docs-provisioners-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/provisioners/index.html&#34;&gt;provisioner&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;デフォルトでは作成されたときに実行されるコマンド。&lt;code&gt;when = &amp;quot;destroy&amp;quot;&lt;/code&gt;で終了時に実行させることもできる。
on_failureで失敗したときの挙動を設定することができ、デフォルトはコマンド自体が失敗する&amp;rdquo;fail&amp;rdquo;になっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_instance&amp;quot; &amp;quot;web&amp;quot; {
  # ...

  provisioner &amp;quot;local-exec&amp;quot; {
    command = &amp;quot;echo ${self.private_ip_address} &amp;gt; file.txt&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;data-https-www-terraform-io-docs-configuration-data-sources-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/configuration/data-sources.html&#34;&gt;data&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;情報を取得する。Terraform以外で作られたリソースのものも取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data &amp;quot;aws_ami&amp;quot; &amp;quot;web&amp;quot; {
  filter {
    name   = &amp;quot;state&amp;quot;
    values = [&amp;quot;available&amp;quot;]
  }

  filter {
    name   = &amp;quot;tag:Component&amp;quot;
    values = [&amp;quot;web&amp;quot;]
  }

  most_recent = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;module-https-www-terraform-io-docs-modules-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/modules/index.html&#34;&gt;module&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;設定をまとめたもの。variableの値を渡すことができ、再利用することができる。
GitHubのurlをsourceに指定することもできる。最初に&lt;code&gt;terraform get&lt;/code&gt;する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module &amp;quot;assets_bucket&amp;quot; {
  source = &amp;quot;./publish_bucket&amp;quot;
  name   = &amp;quot;assets&amp;quot;
}

module &amp;quot;media_bucket&amp;quot; {
  source = &amp;quot;./publish_bucket&amp;quot;
  name   = &amp;quot;media&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# publish_bucket/bucket-and-cloudfront.tf
variable &amp;quot;name&amp;quot; {} # this is the input parameter of the module
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;backend-https-www-terraform-io-docs-backends-index-html&#34;&gt;&lt;a href=&#34;https://www.terraform.io/docs/backends/index.html&#34;&gt;backend&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;0.9.0から&lt;code&gt;terraform remote&lt;/code&gt;の代わりに使われるようになったもの。
管理下のresourceと今の状態を表すtfstateファイルを各自のローカルではなくリモートで一元的に管理する。
オプションではあるけど、applyしたあとにtfstateを上げるのを忘れたりするのを防ぐこともできるため
相当変わった用途でもない限り使わない理由がないと思う。最初に&lt;code&gt;terraform init&lt;/code&gt;する必要がある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/docs/backends/types/s3.html&#34;&gt;S3&lt;/a&gt;に置く場合はこんな感じ。
DynamoDBでロックをかけられる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;mybucket&amp;quot;
    key    = &amp;quot;path/to/my/key&amp;quot;
    region = &amp;quot;us-east-1&amp;quot;
    dynamodb_table = &amp;quot;tflocktable&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;vpcのmoduleを作る&#34;&gt;VPCのmoduleを作る&lt;/h2&gt;

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/terraform-example-vpc&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;community-moduleにも&lt;a href=&#34;https://github.com/terraform-community-modules/tf_aws_vpc&#34;&gt;VPCのモジュール&lt;/a&gt;があるんだけど、今回は自分で作ってみる。&lt;/p&gt;

&lt;p&gt;variableはこんな感じ。同じファイルに書くこともできるが別に分けた方が見やすい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;vpc_name&amp;quot; {
    description = &amp;quot;vpc&#39;s name, e.g. main-vpc&amp;quot;
}

variable &amp;quot;vpc_cidr_block&amp;quot; {
    description = &amp;quot;vpc&#39;s cidr block, e.g. 10.0.0.0/16&amp;quot;
}

variable &amp;quot;public_subnet_cidr_blocks&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;10.0.0.0/24\&amp;quot;, \&amp;quot;10.0.1.0/24\&amp;quot;]&amp;quot;
}

variable &amp;quot;public_subnet_availability_zones&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;ap-northeast-1a\&amp;quot;,\&amp;quot;ap-northeast-1c\&amp;quot;]&amp;quot;
}

variable &amp;quot;private_subnet_cidr_blocks&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;private subnets&#39; cidr blocks, e.g. [\&amp;quot;10.0.2.0/24\&amp;quot;, \&amp;quot;10.0.3.0/24\&amp;quot;]&amp;quot;
}

variable &amp;quot;private_subnet_availability_zones&amp;quot; {
    type = &amp;quot;list&amp;quot;
    description = &amp;quot;public subnets&#39; cidr blocks, e.g. [\&amp;quot;ap-northeast-1a\&amp;quot;,\&amp;quot;ap-northeast-1c\&amp;quot;]&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/vpc.html&#34;&gt;VPC&lt;/a&gt;を作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_vpc&amp;quot; &amp;quot;vpc&amp;quot; {
    cidr_block = &amp;quot;${var.vpc_cidr_block}&amp;quot;
    enable_dns_hostnames = true
    tags {
        Name = &amp;quot;${var.vpc_name}&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にVPCにpublicとprivate用の&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/subnet.html&#34;&gt;サブネット&lt;/a&gt;を、
それぞれcidr_block分作成する。&lt;/p&gt;

&lt;p&gt;vpc_idでvpcのresourceを参照している。したがって、これを実行するためには既にvpcが作られている必要がある。
&lt;code&gt;depends_on&lt;/code&gt;で明示的に依存関係を示すこともできるのだけど、
大抵はそうする必要がなくて&lt;a href=&#34;https://www.terraform.io/intro/getting-started/dependencies.html#implicit-and-explicit-dependencies&#34;&gt;暗黙的な依存関係&lt;/a&gt;をterraformが解決してくれる。
これは&lt;a href=&#34;https://www.terraform.io/docs/commands/graph.html&#34;&gt;terraform graph&lt;/a&gt;で確認できる。&lt;/p&gt;

&lt;p&gt;AZで使われている&lt;a href=&#34;https://www.terraform.io/docs/configuration/interpolation.html#element-list-index-&#34;&gt;element(list, index)&lt;/a&gt;
は要素数以上のindexを渡してもmodの要領で選ぶので数を合わせなくてもよい。&lt;/p&gt;

&lt;p&gt;複数作ったものは&lt;code&gt;aws_subnet.public-subnet.0&lt;/code&gt;のように0から始まるindexで&lt;a href=&#34;https://www.terraform.io/docs/configuration/interpolation.html#attributes-of-other-resources&#34;&gt;参照でき&lt;/a&gt;、
&lt;code&gt;aws_subnet.public-subnet.*.id&lt;/code&gt;のようにすると要素のリストを得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-subnet&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    count = &amp;quot;${length(var.public_subnet_cidr_blocks)}&amp;quot;
    cidr_block = &amp;quot;${var.public_subnet_cidr_blocks[count.index]}&amp;quot;
    availability_zone = &amp;quot;${element(var.public_subnet_availability_zones, count.index)}&amp;quot;
    map_public_ip_on_launch = true
    tags {
        Name = &amp;quot;${var.vpc_name}-public-${element(var.public_subnet_availability_zones, count.index)}&amp;quot;
    }
}

resource &amp;quot;aws_subnet&amp;quot; &amp;quot;private-subnet&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    count = &amp;quot;${length(var.private_subnet_cidr_blocks)}&amp;quot;
    cidr_block = &amp;quot;${var.private_subnet_cidr_blocks[count.index]}&amp;quot;
    availability_zone = &amp;quot;${element(var.private_subnet_availability_zones, count.index)}&amp;quot;
    tags {
        Name = &amp;quot;${var.vpc_name}-private-${element(var.private_subnet_availability_zones, count.index)}&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;public用のサブネットが外と通信できるように&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/internet_gateway.html&#34;&gt;インターネットゲートウェイ&lt;/a&gt;をVPCにアタッチし、
これを登録した&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/d/route_table.html&#34;&gt;カスタムルートテーブル&lt;/a&gt;
をサブネットに&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/route_table_association.html&#34;&gt;関連付ける&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_internet_gateway&amp;quot; &amp;quot;igw&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    tags {
        Name = &amp;quot;${var.vpc_name}-igw&amp;quot;
    }
}

resource &amp;quot;aws_route_table&amp;quot; &amp;quot;public-route-table&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    route {
        cidr_block = &amp;quot;0.0.0.0/0&amp;quot;
        gateway_id = &amp;quot;${aws_internet_gateway.igw.id}&amp;quot;
    }
    tags {
        Name = &amp;quot;${var.vpc_name}-public-route-table&amp;quot;
    }
}

resource &amp;quot;aws_route_table_association&amp;quot; &amp;quot;route-table-association&amp;quot; {
    count          = &amp;quot;${length(var.public_subnet_cidr_blocks)}&amp;quot;
    subnet_id      = &amp;quot;${element(aws_subnet.public-subnet.*.id, count.index)}&amp;quot;
    route_table_id = &amp;quot;${aws_route_table.public-route-table.id}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;privateのサブネットからはNATして外に出られるようにする。
publicなサブネットにNATする&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-comparison.html&#34;&gt;インスタンス&lt;/a&gt;を立ててもいいけど、&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html&#34;&gt;NATゲートウェイ&lt;/a&gt;を使うと自分でメンテする必要がなくて楽。
&lt;a href=&#34;https://aws.amazon.com/jp/vpc/pricing/&#34;&gt;料金&lt;/a&gt;は時間と通信量による。&lt;/p&gt;

&lt;p&gt;ということで、&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/eip.html&#34;&gt;EIP&lt;/a&gt;を割り当て、
適当なpublicのサブネットに&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/nat_gateway.html&#34;&gt;NATゲートウェイ&lt;/a&gt;を作成する。
ドキュメントに書いてある通り、明示的にigwを依存に入れている。&lt;/p&gt;

&lt;p&gt;NATゲートウェイを&lt;a href=&#34;https://www.terraform.io/docs/providers/aws/r/main_route_table_assoc.html&#34;&gt;メインルートテーブル&lt;/a&gt;に登録する。
これは&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html#nat-gateway-basics&#34;&gt;AWSのドキュメント&lt;/a&gt;に書いてある通りの構成で、
明示的にルートテーブルと関連付けていないサブネットは
メインルートテーブルに
&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#RouteTables&#34;&gt;関連付けられる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_eip&amp;quot; &amp;quot;nat&amp;quot; {
    vpc = true
}

resource &amp;quot;aws_nat_gateway&amp;quot; &amp;quot;ngw&amp;quot; {
    allocation_id = &amp;quot;${aws_eip.nat.id}&amp;quot;
    subnet_id     = &amp;quot;${aws_subnet.public-subnet.0.id}&amp;quot;
    depends_on = [&amp;quot;aws_internet_gateway.igw&amp;quot;]
}

resource &amp;quot;aws_route_table&amp;quot; &amp;quot;main-route-table&amp;quot; {
    vpc_id = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
    route {
        cidr_block = &amp;quot;0.0.0.0/0&amp;quot;
        nat_gateway_id = &amp;quot;${aws_nat_gateway.ngw.id}&amp;quot;
    }
    tags {
        Name = &amp;quot;${var.vpc_name}-main-route-table&amp;quot;
    }
}

resource &amp;quot;aws_main_route_table_association&amp;quot; &amp;quot;main-route-table-association&amp;quot; {
  vpc_id         = &amp;quot;${aws_vpc.vpc.id}&amp;quot;
  route_table_id = &amp;quot;${aws_route_table.main-route-table.id}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行&#34;&gt;実行&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  backend &amp;quot;s3&amp;quot; {
    bucket = &amp;quot;terraform&amp;quot;
    key    = &amp;quot;terraform.tfstate&amp;quot;
    region = &amp;quot;ap-northeast-1&amp;quot;
  }
}

provider &amp;quot;aws&amp;quot; {
  region = &amp;quot;ap-northeast-1&amp;quot;
}

module &amp;quot;test-vpc&amp;quot; {
  source                            = &amp;quot;./vpc&amp;quot;
  vpc_name                          = &amp;quot;test-vpc&amp;quot;
  vpc_cidr_block                    = &amp;quot;10.0.0.0/16&amp;quot;
  public_subnet_cidr_blocks         = [&amp;quot;10.0.0.0/24&amp;quot;, &amp;quot;10.0.1.0/24&amp;quot;]
  public_subnet_availability_zones  = [&amp;quot;ap-northeast-1a&amp;quot;, &amp;quot;ap-northeast-1c&amp;quot;]
  private_subnet_cidr_blocks        = [&amp;quot;10.0.2.0/24&amp;quot;, &amp;quot;10.0.3.0/24&amp;quot;]
  private_subnet_availability_zones = [&amp;quot;ap-northeast-1a&amp;quot;, &amp;quot;ap-northeast-1c&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;planして問題なければapplyする流れ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform init
$ terraform get
$ terraform plan
+ module.test-vpc.aws_eip.nat
    allocation_id:     &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    association_id:    &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    domain:            &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    instance:          &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface: &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    private_ip:        &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    public_ip:         &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    vpc:               &amp;quot;true&amp;quot;

+ module.test-vpc.aws_internet_gateway.igw
    tags.%:    &amp;quot;1&amp;quot;
    tags.Name: &amp;quot;test-vpc-igw&amp;quot;
    vpc_id:    &amp;quot;${aws_vpc.vpc.id}&amp;quot;

...
Plan: 13 to add, 0 to change, 0 to destroy.

$ terraform apply
...
Apply complete! Resources: 13 added, 0 changed, 0 destroyed.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;applyするとresourceが作成・更新され、tfstateファイルがbackendまたはローカルに出力される。
次回以降はこのtfstateとの差分を取って変更されるので、このファイルがないとまた同じものが作成されてしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;version&amp;quot;: 3,
    &amp;quot;terraform_version&amp;quot;: &amp;quot;0.9.11&amp;quot;,
    &amp;quot;serial&amp;quot;: 1,
    &amp;quot;lineage&amp;quot;: &amp;quot;f97ad997-5a19-4a3d-9921-b553c5f2532b&amp;quot;,
    &amp;quot;modules&amp;quot;: [
        {
            &amp;quot;path&amp;quot;: [
                &amp;quot;root&amp;quot;
            ],
            &amp;quot;outputs&amp;quot;: {},
            &amp;quot;resources&amp;quot;: {},
            &amp;quot;depends_on&amp;quot;: []
        },
        {
            &amp;quot;path&amp;quot;: [
                &amp;quot;root&amp;quot;,
                &amp;quot;test-vpc&amp;quot;
            ],
            &amp;quot;outputs&amp;quot;: {},
            &amp;quot;resources&amp;quot;: {
                &amp;quot;aws_eip.nat&amp;quot;: {
                    &amp;quot;type&amp;quot;: &amp;quot;aws_eip&amp;quot;,
                    &amp;quot;depends_on&amp;quot;: [],
                    &amp;quot;primary&amp;quot;: {
                        &amp;quot;id&amp;quot;: &amp;quot;eipalloc-3046f054&amp;quot;,
                        &amp;quot;attributes&amp;quot;: {
                            &amp;quot;association_id&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;domain&amp;quot;: &amp;quot;vpc&amp;quot;,
                            &amp;quot;id&amp;quot;: &amp;quot;eipalloc-3046f054&amp;quot;,
                            &amp;quot;instance&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;network_interface&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;private_ip&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;public_ip&amp;quot;: &amp;quot;13.114.59.186&amp;quot;,
                            &amp;quot;vpc&amp;quot;: &amp;quot;true&amp;quot;
                        },
                        &amp;quot;meta&amp;quot;: {},
                        &amp;quot;tainted&amp;quot;: false
                    },
                    &amp;quot;deposed&amp;quot;: [],
                    &amp;quot;provider&amp;quot;: &amp;quot;&amp;quot;
                },
                &amp;quot;aws_internet_gateway.igw&amp;quot;: {
                    &amp;quot;type&amp;quot;: &amp;quot;aws_internet_gateway&amp;quot;,
                    &amp;quot;depends_on&amp;quot;: [
                        &amp;quot;aws_vpc.vpc&amp;quot;
                    ],
                    &amp;quot;primary&amp;quot;: {
                        &amp;quot;id&amp;quot;: &amp;quot;igw-d2659bb6&amp;quot;,
                        &amp;quot;attributes&amp;quot;: {
                            &amp;quot;id&amp;quot;: &amp;quot;igw-d2659bb6&amp;quot;,
                            &amp;quot;tags.%&amp;quot;: &amp;quot;1&amp;quot;,
                            &amp;quot;tags.Name&amp;quot;: &amp;quot;test-vpc-igw&amp;quot;,
                            &amp;quot;vpc_id&amp;quot;: &amp;quot;vpc-3cf6a358&amp;quot;
                        },
                        &amp;quot;meta&amp;quot;: {},
                        &amp;quot;tainted&amp;quot;: false
                    },
                    &amp;quot;deposed&amp;quot;: [],
                    &amp;quot;provider&amp;quot;: &amp;quot;&amp;quot;
                },
                ...
            },
            &amp;quot;depends_on&amp;quot;: []
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;planすると変更なしになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan
...
No changes. Infrastructure is up-to-date.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;terafform destroy&lt;/code&gt;で管理下のresourceを消すことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan -destroy
...
Plan: 0 to add, 0 to change, 13 to destroy.

$ terraform destroy
...
Destroy complete! Resources: 13 destroyed.

$ terraform plan
...
Plan: 13 to add, 0 to change, 0 to destroy.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/CkReal/items/1dbbc78888e157a80668&#34;&gt;お金をかけずに、TerraformでAWSのVPC環境を準備する - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensでのUnityアプリケーションのフレームレート</title>
          <link>https://www.sambaiz.net/article/120/</link>
          <pubDate>Sun, 16 Jul 2017 23:32:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/120/</guid>
          <description>

&lt;h2 id=&#34;hololensディスプレイのフレームレート-https-developer-microsoft-com-en-us-windows-mixed-reality-hologram-stability-frame-rate&#34;&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/mixed-reality/hologram_stability#frame_rate&#34;&gt;HoloLensディスプレイのフレームレート&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;HoloLensのディスプレイは60fpsでリフレッシュされるので、アプリケーションもこれに合わせて60fps、
つまり16msごとにOSにイメージを渡せるのがベスト。
ただし、安定して60fpsが実現できないような重いアプリケーションの場合、
変動してしまうよりは下げて安定させる方が良い。&lt;/p&gt;

&lt;p&gt;フレームレートはDevice Portalから確認することができ、キャプチャする際は30fpsに制限される。&lt;/p&gt;

&lt;h2 id=&#34;unityアプリケーションのフレームレート&#34;&gt;Unityアプリケーションのフレームレート&lt;/h2&gt;

&lt;p&gt;Unityでのフレームレートは
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Application-targetFrameRate.html&#34;&gt;Application.targetFrameRate&lt;/a&gt;
で設定できる。デフォルト値は-1で、その場合プラットフォームごとのデフォルト設定が使われる。
何も設定しない状態でHoloLensで動かしたところ60fpsになった。&lt;/p&gt;

&lt;h2 id=&#34;debugビルドでのフレームレートの低下&#34;&gt;Debugビルドでのフレームレートの低下&lt;/h2&gt;

&lt;p&gt;Debugビルドだと&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/4696&#34;&gt;Space Robot Kyle&lt;/a&gt;
だけ描画するだけでもフレームレートが20まで下がってしまった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/119/&#34;&gt;HoloLensで剣振ってみた - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/120-frame.png&#34; alt=&#34;フレームレートの低下&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DebugビルドだったのをRelasseビルドに変えたら60fpsになった。
Relaseビルドではコードの最適化にチェックが入っていたりするんだけど、
その辺りを外してみても特に変わらなかったのでそれではないらしい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensで剣振ってみた</title>
          <link>https://www.sambaiz.net/article/119/</link>
          <pubDate>Sun, 09 Jul 2017 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/119/</guid>
          <description>&lt;p&gt;かつてCardboardでやったようにHoloLensでも剣を振ってみた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/29/&#34;&gt;剣を振るVRゲームを作った - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/119-ss.png&#34; alt=&#34;スクリーンショット&#34; /&gt;&lt;/p&gt;

&lt;p&gt;剣を振ってロボットに当てると爆発する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_gt6ePsqrRc&#34;&gt;動画&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;剣の方は前回と同じくiOSアプリから傾きをBLEで送信している。今回は傘がなかったのでペットボトルにくくりつけた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/119-sword.jpg&#34; alt=&#34;ミニッツメイドソード&#34; /&gt;&lt;/p&gt;

&lt;p&gt;HoloLensのアプリの方はUWPのネイティブプラグインを作った。
Creater&amp;rsquo;s UpdateのAPIがまだ使えなかったので一つ前のAPIを使ってビルドしている。
なお、ペアリングはアプリ内ではなくOSの設定画面から行なっている。
エラーについては原因が分からずハンドリングできていないものもあるけど、つなぎ直すと大抵どうにかなった。
つなぎ直す際はHoloLens側だけではなくiOS側の方の設定も削除する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/105/&#34;&gt;Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ロボットを小さくしているのは近づいても視野角に収まるようにするため。
小さいとどこにいるか分からないので目印を出したほうが良い。
近接武器じゃなきゃ敵に近づかなくてよくなるのでましになるかも。&lt;/p&gt;

&lt;p&gt;上の動画を見れば分かるように、全体的に動きが重くて素でframerateが20ぐらいしか出ていない。
これはReleaseビルドにすると改善された。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/120/&#34;&gt;HoloLensでのUnityアプリケーションのフレームレート - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensのSpartial MappingでNavMeshを生成してランダムにAgentを出現・移動させる</title>
          <link>https://www.sambaiz.net/article/118/</link>
          <pubDate>Sun, 02 Jul 2017 23:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/118/</guid>
          <description>&lt;pre&gt;&lt;code&gt;Unity 5.6.2f1
HoloToolkit v1.5.7.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unity 5.6から動的にNavMeshを生成できるようになったので
HoloLensのSpartial MappingしたものをNavMeshにしてAgentを動かしてみる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/117/&#34;&gt;Unityで動的にNavMeshを生成する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Spartial MappingしたものをNavMeshにするのは以下の記事の&lt;a href=&#34;https://gist.github.com/tarukosu/7bc78c189d8a7de8e94ca3fcfc8f7738#file-spatialmappingnavmesh-cs&#34;&gt;スクリプト&lt;/a&gt;を使った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tarukosu.hatenablog.com/entry/2017/04/23/183546&#34;&gt;HoloLens の空間マップで NavMesh を使ってみる - たるこすの日記&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents&#34;&gt;Unity-Technologies/NavMeshComponents&lt;/a&gt;から
&lt;code&gt;LocalNavMeshBuilder&lt;/code&gt;と&lt;code&gt;NavMeshSourceTag&lt;/code&gt;を持ってきてLocalNavMeshBuilderのObjectを置いておき、
Spartial MappingしたものにNavMeshSourceTagを付けられればExampleと同様にNavMeshにできる。
そこで、このスクリプトではSpatialMappingSourceを取得し、イベントハンドラでNavMeshSourceTagが追加されるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using HoloToolkit.Unity.SpatialMapping;
using UnityEngine;
using HoloToolkit.Unity;

public class SpatialMappingNavMesh : MonoBehaviour
{
    public GameObject SpatialMapping;

    private void Awake()
    {
        var spatialMappingSources = SpatialMapping.GetComponents&amp;lt;SpatialMappingSource&amp;gt;();
        foreach (var source in spatialMappingSources)
        {
            source.SurfaceAdded += SpatialMappingSource_SurfaceAdded;
            source.SurfaceUpdated += SpatialMappingSource_SurfaceUpdated;
        }
    }

    private void SpatialMappingSource_SurfaceAdded(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceObject&amp;gt; e)
    {
        e.Data.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;();
    }

    private void SpatialMappingSource_SurfaceUpdated(object sender, DataEventArgs&amp;lt;SpatialMappingSource.SurfaceUpdate&amp;gt; e)
    {
        var navMeshSourceTag = e.Data.New.Object.GetComponent&amp;lt;NavMeshSourceTag&amp;gt;();
        if (navMeshSourceTag == null)
        {
            e.Data.New.Object.AddComponent&amp;lt;NavMeshSourceTag&amp;gt;();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NavMeshのランダムな場所を取得するには、適当なPointを取り、
&lt;a href=&#34;https://docs.unity3d.com/ja/540/ScriptReference/NavMesh.SamplePosition.html&#34;&gt;NavMesh.SamplePosition&lt;/a&gt;で
そこから最も近いNavMeshのPointを取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bool RandomPoint(Vector3 center, float range, out Vector3 result) {
    for (int i = 0; i &amp;lt; 30; i++) {
        Vector3 randomPoint = center + Random.insideUnitSphere * range;
        NavMeshHit hit;
        if (NavMesh.SamplePosition(randomPoint, out hit, 1.0f, NavMesh.AllAreas)) {
            result = hit.position;
            return true;
        }
    }
    result = Vector3.zero;
    return false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;動かすAgentはこんな感じ。こけないようにFreeze Rotationしている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/118.png&#34; alt=&#34;Agentの設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このAgentを出現させて移動させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using UnityEngine;
using UnityEngine.AI;

public class RandomSpawn : MonoBehaviour {

    public GameObject player;
    public GameObject agent;
    public GameObject counter;

    private List&amp;lt;GameObject&amp;gt; spawnedAgents = new List&amp;lt;GameObject&amp;gt;();
    private float interval = 0.0f;

    static int MAX_SPAWN_NUM = 10;
    static float SPAWN_RANGE = 10.0f;

	// Use this for initialization
	void Start () {
        counter.GetComponent&amp;lt;TextMesh&amp;gt;().text = spawnedAgents.Count + &amp;quot;&amp;quot;;
    }

    // Update is called once per frame
    void Update () {

        interval += Time.deltaTime;
        if(interval &amp;gt; 5.0f)
        {
            if (spawnedAgents.Count &amp;lt; MAX_SPAWN_NUM)
            {
                Spawn();
            }
            Move();
            interval = 0.0f;
        }
    }

    void Spawn()
    {
        Vector3 spawnPoint;
        if (GetRandomPosition(player.transform.position, SPAWN_RANGE, out spawnPoint))
        {
            var obj = Instantiate(agent, spawnPoint, Quaternion.identity);
            counter.GetComponent&amp;lt;TextMesh&amp;gt;().text = spawnedAgents.Count + &amp;quot;&amp;quot;;
            spawnedAgents.Add(obj);
        }
    }

    void Move()
    {
        foreach(var agent in spawnedAgents)
        {
            Vector3 next;
            if(GetRandomPosition(agent.transform.position, SPAWN_RANGE, out next)){
                agent.GetComponent&amp;lt;NavMeshAgent&amp;gt;().destination = next;
            }
        }
        
    }

    bool GetRandomPosition(Vector3 center, float range, out Vector3 result)
    {
        for (int i = 0; i &amp;lt; 30; i++)
        {
            Vector3 randomPoint = center + UnityEngine.Random.insideUnitSphere * range;
            NavMeshHit hit;
            if (NavMesh.SamplePosition(randomPoint, out hit, 1.0f, NavMesh.AllAreas))
            {
                result = hit.position;
                return true;
            }
        }
        result = Vector3.zero;
        return false;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと床や壁を認識して移動している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/118.gif&#34; alt=&#34;移動するAgent&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityで動的にNavMeshを生成する</title>
          <link>https://www.sambaiz.net/article/117/</link>
          <pubDate>Sat, 01 Jul 2017 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/117/</guid>
          <description>&lt;p&gt;Unity5.6から動的にNavMeshを生成できるようになった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents&#34;&gt;Unity-Technologies/NavMeshComponents&lt;/a&gt;の
Exampleの2_drop_blankのsceneを開く。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample.png&#34; alt=&#34;Exampleの2_drop_blank&#34; /&gt;&lt;/p&gt;

&lt;p&gt;分断されたCubeの床と、その上に黄色いCylindarと赤いCubeがあって、
クリックしたところに黄色いCylindarが動くんだけど、床がつながっていないのでそのままでは赤いCubeまではたどり着けない。
スペースを押すと目の前に板が出てくるのでこの上を渡って移動することができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample2.png&#34; alt=&#34;スペースを押すと板が出てくる&#34; /&gt;&lt;/p&gt;

&lt;p&gt;板の上がNavMeshとして認識されている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/117-sample3.png&#34; alt=&#34;スペースを押すと板が出てくる&#34; /&gt;&lt;/p&gt;

&lt;p&gt;床のCubeと追加される板には&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents/blob/5.6.0b4/Assets/Examples/Scripts/NavMeshSourceTag.cs&#34;&gt;NavMeshSourceTag.cs&lt;/a&gt;が付いていて、staticな&lt;code&gt;m_Meshes&lt;/code&gt;と&lt;code&gt;m_Terrains&lt;/code&gt;にそれぞれ追加している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static List&amp;lt;MeshFilter&amp;gt; m_Meshes = new List&amp;lt;MeshFilter&amp;gt;();
public static List&amp;lt;Terrain&amp;gt; m_Terrains = new List&amp;lt;Terrain&amp;gt;();

void OnEnable()
{
    var m = GetComponent&amp;lt;MeshFilter&amp;gt;();
    if (m != null)
    {
        m_Meshes.Add(m);
    }

    var t = GetComponent&amp;lt;Terrain&amp;gt;();
    if (t != null)
    {
        m_Terrains.Add(t);
    }
}

void OnDisable()
{
    var m = GetComponent&amp;lt;MeshFilter&amp;gt;();
    if (m != null)
    {
        m_Meshes.Remove(m);
    }

    var t = GetComponent&amp;lt;Terrain&amp;gt;();
    if (t != null)
    {
        m_Terrains.Remove(t);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらはCollectメソッドでNavMeshBuildSourceのリストを生成するのに使われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void Collect(ref List&amp;lt;NavMeshBuildSource&amp;gt; sources)
{
    sources.Clear();

    for (var i = 0; i &amp;lt; m_Meshes.Count; ++i)
    {
        var mf = m_Meshes[i];
        if (mf == null) continue;

        var m = mf.sharedMesh;
        if (m == null) continue;

        var s = new NavMeshBuildSource();
        s.shape = NavMeshBuildSourceShape.Mesh;
        s.sourceObject = m;
        s.transform = mf.transform.localToWorldMatrix;
        s.area = 0;
        sources.Add(s);
    }

    for (var i = 0; i &amp;lt; m_Terrains.Count; ++i)
    {
       ...
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;a href=&#34;https://github.com/Unity-Technologies/NavMeshComponents/blob/5.6.0b4/Assets/Examples/Scripts/LocalNavMeshBuilder.cs&#34;&gt;LocalNavMeshBuilder.cs&lt;/a&gt;から呼び、&lt;a href=&#34;https://docs.unity3d.com/ScriptReference/AI.NavMeshBuilder.UpdateNavMeshData.html&#34;&gt;NavMeshBuilder.UpdateNavMeshData&lt;/a&gt;に渡してNavMeshDataを更新している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NavMeshData m_NavMesh;
AsyncOperation m_Operation;
NavMeshDataInstance m_Instance;
List&amp;lt;NavMeshBuildSource&amp;gt; m_Sources = new List&amp;lt;NavMeshBuildSource&amp;gt;();

IEnumerator Start()
{
    while (true)
    {
        UpdateNavMesh(true);
        yield return m_Operation;
    }
}

void UpdateNavMesh(bool asyncUpdate = false)
{
    NavMeshSourceTag.Collect(ref m_Sources);
    var defaultBuildSettings = NavMesh.GetSettingsByID(0);
    var bounds = QuantizedBounds();

    if (asyncUpdate)
        m_Operation = NavMeshBuilder.UpdateNavMeshDataAsync(m_NavMesh, defaultBuildSettings, m_Sources, bounds);
    else
        NavMeshBuilder.UpdateNavMeshData(m_NavMesh, defaultBuildSettings, m_Sources, bounds);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Fluentdのout_copyのstoreのエラーは他のstoreに影響する</title>
          <link>https://www.sambaiz.net/article/116/</link>
          <pubDate>Sat, 01 Jul 2017 18:53:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/116/</guid>
          <description>&lt;p&gt;Fluentdの&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/out_copy&#34;&gt;out_copy&lt;/a&gt;プラグインは
一つのeventを複数のoutputに渡すために使われる。
ただ、複数設定した中のstoreでエラーが起きると他のstoreにも影響してしまう。&lt;/p&gt;

&lt;p&gt;例えばこんなの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fileの方で&lt;code&gt;queue size exceeds limit&lt;/code&gt;になるとstdoutも出力されなくなってしまう。&lt;/p&gt;

&lt;p&gt;ちなみに一旦relabelしてもだめ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store&amp;gt;
    @type relabel
    @label @file
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;label @file&amp;gt;
  &amp;lt;match dummy&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/match&amp;gt;
&amp;lt;/label&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ドキュメントでも紹介されている、sonots氏の&lt;a href=&#34;https://github.com/sonots/fluent-plugin-copy_ex&#34;&gt;out_copy_ex&lt;/a&gt;では
storeにignore_errorを付けるとrescueするようになっているので他に巻き込まれなくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-copy_ex
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1
&amp;lt;/source&amp;gt;

&amp;lt;match dummy&amp;gt;
  @type copy_ex

  &amp;lt;store ignore_error&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;

  &amp;lt;store ignore_error&amp;gt;
    @type file
    path /var/log/td-agent/dummy
    buffer_queue_limit 0
    buffer_chunk_limit 1k
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;dummy: {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
[error]:  error_class=Fluent::BufferQueueLimitError error=&amp;quot;queue size exceeds limit&amp;quot;
dummy: {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
[error]:  error_class=Fluent::BufferQueueLimitError error=&amp;quot;queue size exceeds limit&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityの経路探索: NavMeshとAgentとObstacle</title>
          <link>https://www.sambaiz.net/article/115/</link>
          <pubDate>Thu, 29 Jun 2017 00:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/115/</guid>
          <description>

&lt;h2 id=&#34;navmeshと経路探索-https-docs-unity3d-com-jp-540-manual-nav-innerworkings-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-InnerWorkings.html&#34;&gt;NavMeshと経路探索&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;NavMeshというのはエージェントが移動できる面についてのデータ構造で、凸ポリゴンの面と位置関係を含んでいる。
経路探索は2点間を一番近いポリゴンにマッピングし、&lt;a href=&#34;https://ja.wikipedia.org/wiki/A*&#34;&gt;A*アルゴリズム&lt;/a&gt;を用いて行われる。あとからオブジェクトが追加されるなどして道を塞いでしまってもCarvingしてNavMeshに穴をあければ別の経路で移動することができるが、このようなグローバルの経路探索に影響を及ぼす操作は計算にコストがかかるので、各エージェントローカルの衝突回避で済むならそのほうがよい。&lt;/p&gt;

&lt;h2 id=&#34;navmeshをbakeする-https-docs-unity3d-com-jp-540-manual-nav-buildingnavmesh-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-BuildingNavMesh.html&#34;&gt;NavMeshをbakeする&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;こんな感じで床に適当なオブジェクトを置いてみた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-stage.png&#34; alt=&#34;stage&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-stageh.png&#34; alt=&#34;階層&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Window -&amp;gt; Navigation&lt;/code&gt;でBakeするのを選択してNavigation Staticし(StaticになってBakeの対象になる)、
Bakeボタンを押すとこんな感じでBakeされる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-bake.png&#34; alt=&#34;bake&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトの上がNavMeshに含まれていないのはAgent sizeのStep Heightよりも高いため。
段差を移動するときに浮いてしまうのを避けるためにはAdvancedの&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-HeightMesh.html&#34;&gt;Height Mesh&lt;/a&gt;をオンにする。
また、端が含まれていないのはこのAgentの中心が入れる位置を表しているためで、
Agent Radiusを変更すると広がったり狭まったりするのを確認できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-agentsize.png&#34; alt=&#34;Agent size&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;navmesh-agent-https-docs-unity3d-com-jp-540-manual-nav-createnavmeshagent-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/nav-CreateNavMeshAgent.html&#34;&gt;NavMesh Agent&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Radius0.5, Height2のCylindarを作成し、Nav Mesh Agentを追加する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-navmesh-agent.png&#34; alt=&#34;NavMesh Agent&#34; /&gt;&lt;/p&gt;

&lt;p&gt;で、ゴールにオブジェクトを置いてそこまで移動させてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine.AI;

public GameObject goal;

void Start () {
    var agent = GetComponent&amp;lt;NavMeshAgent&amp;gt;();
    agent.destination = goal.transform.position;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move.gif&#34; alt=&#34;ゴールまでたどり着くNavMesh Agent&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;navmesh-obstacle&#34;&gt;NavMesh Obstacle&lt;/h2&gt;

&lt;p&gt;障害物。上で通った経路上にNavMesh Obstacleを追加したCubeを置いたところうまく避けてゴールまでたどり着いた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move2.gif&#34; alt=&#34;Obstacleを置いた&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただ、完全に道をふさいでしまうと立ち往生してしまうので
Carveにチェックを入れるとCarvingされ、他の経路でゴールまで進むようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/115-move3.gif&#34; alt=&#34;Carvingした&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/117/&#34;&gt;Unityで動的にNavMeshを生成する - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityの物理エンジン・衝突: RigidbodyとCollidarとJoint</title>
          <link>https://www.sambaiz.net/article/114/</link>
          <pubDate>Sun, 25 Jun 2017 23:26:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/114/</guid>
          <description>

&lt;h2 id=&#34;rigidbody-https-docs-unity3d-com-ja-current-manual-rigidbodiesoverview-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/RigidbodiesOverview.html&#34;&gt;Rigidbody&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GameObjectを物理特性によって制御し、力の影響を受けるようにする。
&lt;code&gt;Mass(質量)&lt;/code&gt;や&lt;code&gt;Drag(空気抵抗)&lt;/code&gt;、&lt;code&gt;Use Gravity&lt;/code&gt;などのプロパティがある。&lt;/p&gt;

&lt;p&gt;移動させるのに自分でTransformは変更せず力をかけて物理演算に任せる。
&lt;code&gt;Is Kinematic&lt;/code&gt;にチェックを入れると物理エンジンによって移動しないようになるので、
Transformを直接変更する場合は有効にする。
ただし、スクリプトで動的にIs Kinematicを切り替えるのはパフォーマンスが良くない。&lt;/p&gt;

&lt;h2 id=&#34;collidar-https-docs-unity3d-com-ja-current-manual-collidersoverview-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/CollidersOverview.html&#34;&gt;Collidar&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;RigidBodyの物理特性の境界を定義する。衝突させるには両方にCollidarが設定されている必要がある。
RigidBodyなしのCollidarを静的Collidarといって、無効にしたり移動しないことを前提に最適化される。
移動したりするものについてはRigidBodyを付けて、必要ならIs Kinematicを有効にする。&lt;/p&gt;

&lt;p&gt;衝突時には&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionEnter.html&#34;&gt;OnCollisionEnter()&lt;/a&gt;
が呼ばれる。ほかに離れたときの&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionExit.html&#34;&gt;OnCollisionExit()&lt;/a&gt;、
触れている間、毎フレーム呼ばれる&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnCollisionStay.html&#34;&gt;OnCollisionStay()&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void OnCollisionEnter(Collision collision)
{
    foreach (ContactPoint contact in collision.contacts)
    {
        if (contact.otherCollider.tag == &amp;quot;Player&amp;quot;)
        {
            Debug.Log(collision.relativeVelocity.magnitude);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Is Trigger&lt;/code&gt;にチェックを入れると物理エンジンには無視されてすり抜け、侵入に対してトリガーイベントが呼ばれる。
OnCollistionと同様に
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerEnter.html&#34;&gt;OnTriggerEnter()&lt;/a&gt;、
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerExit.html&#34;&gt;OnTriggerExit()&lt;/a&gt;、
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Collider.OnTriggerStay.html&#34;&gt;OnTriggerStay()&lt;/a&gt;
がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void OnTriggerEnter(Collider other)
{
    Debug.Log(other.tag);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;joint-https-docs-unity3d-com-ja-current-manual-joints-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/Joints.html&#34;&gt;Joint&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Rigitbodyを他のRigitbodyとつなげるもの。
例えばSprint Jointだとオブジェクト間がばねのように伸縮する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/114-joint.png&#34; alt=&#34;Spring Joint&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする</title>
          <link>https://www.sambaiz.net/article/113/</link>
          <pubDate>Sun, 25 Jun 2017 00:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/113/</guid>
          <description>

&lt;p&gt;デプロイやスループットの調整を簡単にするため、BeanstalkでAggregatorを立ち上げた。&lt;/p&gt;

&lt;h2 id=&#34;負荷分散&#34;&gt;負荷分散&lt;/h2&gt;

&lt;p&gt;TCPの24224(設定による)が通るようにEC2,ELBのSGとリスナーの設定をする必要があって、
ELBのSGのアウトバウンドの設定が見落とされがち。ELBのクロスゾーン分散は有効になっている。&lt;/p&gt;

&lt;p&gt;まず、ELBに3台、それぞれ別のAZ(1b, 1c, 1d)に配置されている状態でログを送り始めるとそれぞれ均等にログが届いた。
その状態から4台(1b * 2, 1c, 1d)にすると、2つのインスタンス(1b, 1c)のみに均等にログが届くようになった。
4台になると(1b, 1c)と(1b, 1d)に分けられてELBのノードがそれらの組に紐づいたということだと思う。
各ノードにはDNSラウンドロビンするようになっている。実際restartすると今度は別の組の方に送られた。&lt;/p&gt;

&lt;p&gt;では、なぜ一度送り始めると同じ方にしか飛ばないかというと、forwardプラグインの&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/out_forward#expirednscache&#34;&gt;expire_dns_cache&lt;/a&gt;がデフォルトでnilになっていて、
heartbeatが届いている間は&lt;a href=&#34;https://github.com/fluent/fluentd/blob/v0.14.18/lib/fluent/plugin/out_forward.rb#L688&#34;&gt;無期限にDNSキャッシュする&lt;/a&gt;ようになっているため。これに0(キャッシュしない)か秒数を指定すると、
その間隔で他の組のインスタンスにもログが届くようになった。
&lt;code&gt;expire_dns_cache&lt;/code&gt;しなくても複数のインスタンスからラウンドロビンされるため全体でいえば分散される。&lt;/p&gt;

&lt;h2 id=&#34;heartbeat&#34;&gt;heartbeat&lt;/h2&gt;

&lt;p&gt;ELB配下のEC2を全て落としても&lt;a href=&#34;https://github.com/fluent/fluentd/blob/v0.14.18/lib/fluent/plugin/out_forward.rb#L665&#34;&gt;heartbeat&lt;/a&gt;に失敗しないため、standyに移行せずELBのバックエンド接続エラーになってログがロストしてしまうようだ。
ログにも出ず、以下のようにactive-standbyの設定をしてもstandbyに移行しない。
全てのインスタンスが同時に落ちるというのは滅多に起きないだろうけど、少なくとも検知できるようにはしておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;server&amp;gt;
    name td1
    host autoscale-td1.us-east-1.elasticbeanstalk.com
    port 24224
&amp;lt;/server&amp;gt;
&amp;lt;server&amp;gt;
    name td2
    host autoscale-td2.us-east-1.elasticbeanstalk.com
    port 24224
    standby
&amp;lt;/server&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;blue-green-deployment&#34;&gt;Blue/Green Deployment&lt;/h2&gt;

&lt;p&gt;Blue-Green Deploymentというのは、2つの系を用意し、activeでない方にデプロイし、
スワップして反映させるもの。ダウンタイムなしで問題が起きた際にもすぐに切り戻すことができる。
スワップして向き先を変えるには&lt;code&gt;expire_dns_cache&lt;/code&gt;を設定する必要がある。&lt;/p&gt;

&lt;h2 id=&#34;auto-scaling&#34;&gt;Auto Scaling&lt;/h2&gt;

&lt;p&gt;増えるのはいいとして減るときに、
送り先で一時的に障害が起きていたりするとバッファをflushできずにログがロストする可能性がある。
それでいうとログの送り元でも同じことが起こりうるんだけど、通常Aggregatorにしか送らないので比較的問題になりにくい。&lt;/p&gt;

&lt;p&gt;これを避けたい場合、Auto Scalingグループの設定で
&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/autoscaling/latest/userguide/as-instance-termination.html#instance-protection&#34;&gt;スケールインから保護&lt;/a&gt;を有効にして
これから立ち上がるインスタンスはスケールインしなくすることができる。
それまでに立ち上がっていたインスタンスには適用されないので注意。&lt;/p&gt;

&lt;p&gt;スケールインしないということは最大の台数で止まってしまうので、
ピークを過ぎたらスワップしてバッファが全て掃けたことを確認してからTerminateすることになる。
これを日常的にやるのは面倒なので、実際は予期しない流量の増加に備えて一応設定しておき、
普段はしきい値にひっかからないような最低台数で待ち構えておくことにするかな。&lt;/p&gt;

&lt;p&gt;あとはヘルスチェックによって潰される可能性はなくもないけど、それはもうやむなし・・・。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/elb-configuration-guide-1&#34;&gt;AWS ELBの社内向け構成ガイドを公開してみる 負荷分散編 – Cross-Zone Routingを踏まえて ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのMecanimでヒューマノイドアニメーションさせる</title>
          <link>https://www.sambaiz.net/article/112/</link>
          <pubDate>Tue, 20 Jun 2017 23:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/112/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/4696&#34;&gt;Space Robot Kyle&lt;/a&gt;を動かす。&lt;/p&gt;

&lt;h2 id=&#34;アバターの作成&#34;&gt;アバターの作成&lt;/h2&gt;

&lt;p&gt;Assetsの&lt;code&gt;Model/Robot Kyle&lt;/code&gt;を選択し、RigのAnimation TypeをHumanoidにすると、
自動的にボーン構造を解析して人型にマッピングしたアバターが設定される。
Configure Avatarで確認すると正しく設定されているようだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-rig.png&#34; alt=&#34;アバター&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;モーションの設定&#34;&gt;モーションの設定&lt;/h2&gt;

&lt;p&gt;KyleのAnimatorのAnimationに設定するAnimation Controllerを作成する。
まずは2つCreate Stateし、それぞれMotionに適当なモーション(今回は&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/36286&#34;&gt;Fighter Pack Bundle FREE&lt;/a&gt;を使った)を設定し、
Make Transitionで相互に結ぶと、オレンジになっているデフォルトステートから交互にモーションする。
ステートには&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/StateMachineBehaviour.html&#34;&gt;StateMachineBehaviour&lt;/a&gt;のScriptを設定することもできる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-animation.png&#34; alt=&#34;モーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次にParametersでモーションを変化させる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-animation2.png&#34; alt=&#34;分岐したモーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Animatorの左上、parametersタブからBoolのWalkを追加する。
そして片方のTransitionのConditionにWalkがfalse、もう片方にはWalkがtrueを追加すると、
状態によって違うモーションをするようになる。
ちなみに、AnyStateからConditionを設定したTransitionを設定すると、どこのStateからでもそれで遷移させることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-parameters.png&#34; alt=&#34;パラメータ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このParameterはこんな感じに値を設定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Update () {
	GetComponent&amp;lt;Animator&amp;gt; ().SetBool (&amp;quot;Walk&amp;quot;, Random.value &amp;lt; 0.5);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;一部だけモーションさせる&#34;&gt;一部だけモーションさせる&lt;/h2&gt;

&lt;p&gt;人体の一部だけをモーションさせるにはAvatar Maskを使う。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-avatar-mask.png&#34; alt=&#34;Avatar Mask&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-avatar-mask-motion.png&#34; alt=&#34;Avatar Maskしたモーション&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Animationで複数のレイヤーを作成すれば、異なるMaskでそれぞれステートを持たせることができる。&lt;/p&gt;

&lt;h2 id=&#34;animation-override-controller&#34;&gt;Animation Override Controller&lt;/h2&gt;

&lt;p&gt;作ったAnimationを違うモーションで再利用することができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/112-override.png&#34; alt=&#34;Animator Override Controller&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>NorikraでログをJOINする</title>
          <link>https://www.sambaiz.net/article/111/</link>
          <pubDate>Thu, 15 Jun 2017 00:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/111/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/109/&#34;&gt;NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;適当なログを出すコードを書いた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/lottery-log&#34;&gt;sambaiz/lottery-log&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。
広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// lottery.log
{&amp;quot;ts&amp;quot;:1497453504.6818597,&amp;quot;uid&amp;quot;:&amp;quot;b18c0d98-19b2-4e37-8fc4-6b00a4b728c3&amp;quot;,&amp;quot;prize&amp;quot;:855,&amp;quot;isWin&amp;quot;:true}
// received.log
{&amp;quot;ts&amp;quot;:1497453515.932101,&amp;quot;uid&amp;quot;:&amp;quot;bc4f578f-4a5f-47f1-a4e0-1ef0b43c316e&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリはこんな感じ。一つはlotteryログとreceivedログをuidでJOINするもので、
received_rateの計算にはサブクエリも使っている。
received_rateの計算で分母に小さな値を足しているのはNaNやInfinityにならないようにするため。
receivedログは最大30秒遅れて出力されるため、40秒前までのreceivedログをwin:timeで見ている。
これをtime_batchにしてしまうと期待通りの結果にならないので注意。&lt;/p&gt;

&lt;p&gt;もう一つはJavaの関数でboolを0/1にして平均をとることでisWinがtrueである割合を出している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec norikra norikra-client query add lottery_agg &#39;
SELECT COUNT(*) as received_count, (COUNT(*) / (SELECT COUNT(*) + 0.00001 FROM lottery.win:time_batch(1 sec, 0).std:unique(uid))) as received_rate, AVG(prize) as prize_avg, SUM(prize) as prize_sum FROM lottery.win:time(40 sec).std:unique(uid) as a, received.win:time_batch(1 sec, 0).std:unique(uid) as b WHERE a.uid = b.uid&#39;

$ docker exec norikra norikra-client query add lottery_win_rate &#39;SELECT avg(Boolean.compare(isWin, false)) as win_rate FROM lottery.win:time_batch(1 sec)&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、このクエリの結果をElasticsearchに送って可視化してみたのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type tail
  path /var/log/lottery.log
  pos_file /etc/td-agent/log.pos
  tag event.lottery
  format json
&amp;lt;/source&amp;gt;

&amp;lt;source&amp;gt;
  @type tail
  path /var/log/received.log
  pos_file /etc/td-agent/log.pos
  tag event.received
  format json
&amp;lt;/source&amp;gt;

&amp;lt;match event.*&amp;gt;
  @type   norikra
  norikra localhost:26571
  
  remove_tag_prefix event # event.*の部分が
  target_map_tag    yes   # targetになる

  &amp;lt;default&amp;gt;
    auto_field false 
  &amp;lt;/default&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;source&amp;gt;
  @type   norikra
  norikra localhost:26571
  &amp;lt;fetch&amp;gt;
    method   event
    target   lottery_agg
    tag      string data.lottery_agg
    interval 1m
  &amp;lt;/fetch&amp;gt;
  &amp;lt;fetch&amp;gt;
    method   event
    target   lottery_win_rate
    tag      string data.lottery_win_rate
    interval 1m
  &amp;lt;/fetch&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match data.lottery_agg&amp;gt;
  @type elasticsearch
  host 172.31.5.20
  port 9200
  logstash_prefix lottery
  type_name lottery_agg
  logstash_format true
&amp;lt;/match&amp;gt;

&amp;lt;match data.lottery_win_rate&amp;gt;
  @type elasticsearch
  host 172.31.5.20
  port 9200
  logstash_prefix lottery
  type_name lottery_win_rate
  logstash_format true
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;received_rateを計算するときのウィンドウが1secと小さく、タイミングによってはreceivedの数がlotteryの数を上回ることがあるため1以下で絞っている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/111v.png&#34; alt=&#34;可視化したもの&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>VSでのネイティブプラグインのビルドからUnityでのWSAのビルドまでをバッチでする</title>
          <link>https://www.sambaiz.net/article/110/</link>
          <pubDate>Tue, 13 Jun 2017 00:32:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/110/</guid>
          <description>

&lt;h2 id=&#34;vsでのネイティブプラグインのビルド&#34;&gt;VSでのネイティブプラグインのビルド&lt;/h2&gt;

&lt;p&gt;VSが使っているビルドツール
&lt;a href=&#34;https://docs.microsoft.com/ja-jp/visualstudio/msbuild/msbuild&#34;&gt;MSBuild&lt;/a&gt;を使う。
VSのプロジェクトファイルにはMSBuildのXMLが含まれている。
これ自体はVSに依存していないため、単体で動かすこともできる。&lt;/p&gt;

&lt;p&gt;パスが通ってなかったらパスを通す。管理者権限が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; MSBuild
&#39;MSBuild&#39; は、内部コマンドまたは外部コマンド、
操作可能なプログラムまたはバッチ ファイルとして認識されていません。

&amp;gt;　SETX /M PATH &amp;quot;%PATH%;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\Bin&amp;quot;

成功: 指定した値は保存されました。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;別プロセスから適用されるので立ち上げ直すとパスが通っていることを確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; MSBuild /version
Microsoft (R) Build Engine バージョン 15.1.1012.6693
Copyright (C) Microsoft Corporation.All rights reserved.

15.1.1012.6693
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルドして&lt;code&gt;Assets\Plugins&lt;/code&gt;に配置する。これは前作ったBLEのネイティブプラグインのもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/105/&#34;&gt;Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; git clone git@github.com:sambaiz/UnityBLE_UWP.git
&amp;gt; cd UnityBLE_UWP
&amp;gt; MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;quot;x86&amp;quot;
&amp;gt; MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release
&amp;gt; copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA
&amp;gt; copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.dll ..\Assets\Plugins
&amp;gt; cd ..
&amp;gt; rmdir /S /Q UnityBLE_UWP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなエラーが出てきたらmscorlib.dllをインポートできていないのが原因のようで、
restoreしたらうまくいった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;error CS0518: 定義済みの型 &#39;System.Object&#39; は定義、またはインポートされていません
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;unityでのwsaのビルド&#34;&gt;UnityでのWSAのビルド&lt;/h2&gt;

&lt;p&gt;同様にUnityもパスが通ってなかったら通す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; Unity
&#39;Unity&#39; は、内部コマンドまたは外部コマンド、
操作可能なプログラムまたはバッチ ファイルとして認識されていません。

&amp;gt;　SETX /M PATH &amp;quot;%PATH%;C:\Program Files\Unity\Editor&amp;quot;

成功: 指定した値は保存されました。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/BuildPipeline.BuildPlayer.html&#34;&gt;スクリプト&lt;/a&gt;
をAssets/Editorの中に置く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEditor;

public class Build {

    static void PerformBuild()
    {
        string[] scenes = { &amp;quot;Assets/main.unity&amp;quot; };
        BuildPipeline.BuildPlayer(scenes, &amp;quot;build&amp;quot;,
            BuildTarget.WSAPlayer, BuildOptions.None);

    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このstaticメソッドを&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/CommandLineArguments.html&#34;&gt;executeMethod&lt;/a&gt;
で渡してビルドする。Unityを開いたままだと失敗するので閉じる必要がある。&lt;/p&gt;

&lt;p&gt;この例だとbuildディレクトリに出力される。もし出力されなかったらEditorログを見る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; Unity -quit -batchmode -executeMethod Build.PerformBuild
&amp;gt; type C:\Users\(username)\AppData\Local\Unity\Editor\Editor.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;まとめたもの&#34;&gt;まとめたもの&lt;/h2&gt;

&lt;p&gt;ということでこんなバッチをUnityプロジェクトの直下に置いておくことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone git@github.com:sambaiz/UnityBLE_UWP.git
cd UnityBLE_UWP
MSBuild UnityBLE_UWP\UnityBLE_UWP.csproj /t:restore;build /p:Configuration=Release;Platform=&amp;quot;x86&amp;quot;
MSBuild UnityBLE_Editor\UnityBLE_Editor.csproj /t:restore;build /p:Configuration=Release
copy /Y UnityBLE_UWP\bin\x86\Release\UnityBLE_UWP.dll ..\Assets\Plugins\WSA
copy /Y UnityBLE_Editor\bin\Release\UnityBLE_Editor.dll ..\Assets\Plugins
cd ..
rmdir /S /Q UnityBLE_UWP

rmdir /S /Q build
Unity -quit -batchmode -executeMethod Build.PerformBuild
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://sh-yoshida.hatenablog.com/entry/2017/05/27/012755&#34;&gt;MSBuildでコマンドラインからビルドする - 1.21 jigowatts&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
          <link>https://www.sambaiz.net/article/109/</link>
          <pubDate>Sat, 10 Jun 2017 12:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/109/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://norikra.github.io/&#34;&gt;Norikra&lt;/a&gt;はTD社の&lt;a href=&#34;https://github.com/tagomoris&#34;&gt;tagomoris&lt;/a&gt;氏が作った、
スキーマレスのストリーミングデータを処理するOSS。&lt;/p&gt;

&lt;p&gt;モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだけど、
流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。&lt;/p&gt;

&lt;h2 id=&#34;norikraを立ち上げてクエリを実行する&#34;&gt;Norikraを立ち上げてクエリを実行する&lt;/h2&gt;

&lt;p&gt;公式で紹介されているDockerイメージがあったのでこれで動かしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -e &amp;quot;TZ=Asia/Tokyo&amp;quot; -p 26578:26578 -p 26571:26571 -v `pwd`:/var/tmp/norikra:rw -d myfinder/docker-norikra norikra start --stats /var/tmp/norikra/stats.json -l /var/tmp/norikra 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほかの&lt;a href=&#34;https://github.com/norikra/norikra/blob/master/lib/norikra/cli.rb&#34;&gt;オプション&lt;/a&gt;として&lt;code&gt;-Xms&lt;/code&gt;や&lt;code&gt;-Xmx&lt;/code&gt;でJVMのヒープメモリの量を設定したり、Experimentalではあるけど&lt;code&gt;--shutoff&lt;/code&gt;でヒープメモリが一杯になる前に弾いて
OutOfMemoryを防ぐことができる。
また、Norikraのコアエンジンで使われているOSSの
&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%A4%87%E5%90%88%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E5%87%A6%E7%90%86&#34;&gt;CEP&lt;/a&gt;
(Complex event processing)エンジン、
&lt;a href=&#34;http://www.espertech.com/products/esper.php&#34;&gt;Esper&lt;/a&gt;
のパフォーマンスチューニングとして&lt;code&gt;--micro&lt;/code&gt;や&lt;code&gt;--small&lt;/code&gt;などを渡すこともできるけど試していない。&lt;/p&gt;

&lt;p&gt;公式サイトの例に従ってクライアントからデータを入れてクエリを実行してみる。&lt;/p&gt;

&lt;p&gt;まずはtargetをopenする。targetというのはスキーマレスのイベントストリームのこと。
ここで定義したフィールドは必須になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client target open www path:string status:integer referer:string agent:string userid:integer
$ norikra-client target list
TARGET	AUTO_FIELD
www	true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にクエリを追加する。一見普通のSQLのように見えるけど、EsperのクエリであるEPL(Event Processing Language)。
ただしSELECTしか使えないのも含めてクエリにいくらかの制限がある。&lt;/p&gt;

&lt;p&gt;このクエリでは&lt;code&gt;win:time_batch&lt;/code&gt;で10秒のWindowを定義し、eventをgroup byして、その数をeventとして出力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client query add www.toppageviews &#39;SELECT count(*) AS cnt FROM www.win:time_batch(10 sec) WHERE path=&amp;quot;/&amp;quot; AND status=200&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;eventを流す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/login&amp;quot;, &amp;quot;status&amp;quot;:301, &amp;quot;referer&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリの値をfetchする。送るのが遅くてgroup byされなかったけどこんな感じ。
eventがこなかったはじめのWindowは0が出力されるが、それ以降のWindowでは出力されない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client event fetch www.toppageviews
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 20:58:13&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:42:33&amp;quot;,&amp;quot;cnt&amp;quot;:1}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:42:43&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:13&amp;quot;,&amp;quot;cnt&amp;quot;:1}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:23&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:33&amp;quot;,&amp;quot;cnt&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとWeb-uiが用意されていて、クエリを追加したり、targetやクエリの一覧、メモリの使用量やサーバーログなどが取得できる。デフォルトでは26578ポート。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/109-norikra.png&#34; alt=&#34;web-ui&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;クエリ-epl-http-norikra-github-io-query-html&#34;&gt;&lt;a href=&#34;http://norikra.github.io/query.html&#34;&gt;クエリ(EPL)&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;windowなし&#34;&gt;Windowなし&lt;/h3&gt;

&lt;p&gt;上の例では&lt;code&gt;time_batch&lt;/code&gt;でWindowを定義したけど、定義しないクエリを追加してみる。
以下のようなクエリを登録し、再びeventを流してfetchすると流した分が全てとれる。
ただし、このようなクエリはfetchされないと大量のoutput eventが溜まる可能性がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT path, status AS cnt FROM www WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-nowin
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 23:06:12&amp;quot;,&amp;quot;cnt&amp;quot;:200,&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 23:09:10&amp;quot;,&amp;quot;cnt&amp;quot;:200,&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-time-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-time-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-time-batch&#34;&gt;win:time_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;10 sec&lt;/code&gt;のように秒以外にも&lt;code&gt;msec&lt;/code&gt;、&lt;code&gt;min&lt;/code&gt;、&lt;code&gt;hour&lt;/code&gt;、どう使うか想像できないけど&lt;code&gt;year&lt;/code&gt;まで指定でき、
&lt;code&gt;10 minutes 30 seconds&lt;/code&gt;みたいに組み合わせることも&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl_clauses.html#epl-syntax-time-periods&#34;&gt;できる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;また、第二引数にミリ秒を渡すと出力するタイミングを指定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) AS cnt FROM www.win:time_batch(1min, 0L) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-tb-opts
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 00:43:00&amp;quot;,&amp;quot;cnt&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-ext-timed-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-ext-time-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-ext-time-batch&#34;&gt;win:ext_timed_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;来た時間ではなくフィールドのUNIXミリ秒を参照するWindow。時系列順にソートされている必要があって、
tagomoris氏いわく&lt;a href=&#34;https://twitter.com/tagomoris/status/486851407140507648&#34;&gt;おすすめしない&lt;/a&gt;とのこと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) AS cnt FROM www.win:ext_timed_batch(timestamp, 1 min) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3, &amp;quot;timestamp&amp;quot;:1496852100000 }&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3, &amp;quot;timestamp&amp;quot;:1496852200000 }&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-ext_timed
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 01:19:02&amp;quot;,&amp;quot;cnt&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-length-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-length-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-length-batch&#34;&gt;win:length_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;event数のWindow。毎回渡した数ずつ集計できると思いきや、数が集まらなければfetchできず、
それ以上集まったらfetchできるようだ。使いづらいような気がする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT avg(userid) as nosense FROM www.win:length_batch(2) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat

$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat

$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:2}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:42:20&amp;quot;,&amp;quot;nosense&amp;quot;:2.0}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-length-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-length&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-length&#34;&gt;win:length&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;こっちは渡した数スライドして集計するもの。Windowなしのときと同様、大量に溜まる可能性がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT avg(userid) as nosense FROM www.win:length(2) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:5}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:4}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-len
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:11&amp;quot;,&amp;quot;nosense&amp;quot;:3.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:22&amp;quot;,&amp;quot;nosense&amp;quot;:2.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:32&amp;quot;,&amp;quot;nosense&amp;quot;:3.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:45&amp;quot;,&amp;quot;nosense&amp;quot;:4.5}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他にもいろいろあるし、JOINやサブクエリも使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/111/&#34;&gt;NorikraでログをJOINする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;fluentdとやり取りする&#34;&gt;fluentdとやり取りする&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/norikra/fluent-plugin-norikra&#34;&gt;fluent-plugin-norikra&lt;/a&gt;でNorikraサーバーにeventを送り、
eventを受け取ってファイルに出力する。&lt;/p&gt;

&lt;p&gt;c4.large(2コア,メモリ3.75GiB)でDockerでNorikraを立ち上げ、以下の設定でtd-agentを実行した。
&lt;code&gt;auto_field&lt;/code&gt;は来たeventのフィールドを自動でtargetに登録するかの設定で、
true(デフォルト)にするとどんなフィールドが来ているかNorikra上で確認することができる。
falseにしてもクエリで使う分は自動で登録される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag event.dummy
  rate 1000
&amp;lt;/source&amp;gt;
   
&amp;lt;match event.*&amp;gt;
  @type   norikra
  norikra localhost:26571
  
  remove_tag_prefix event # event.*の部分が
  target_map_tag    yes   # targetになる

  &amp;lt;default&amp;gt;
    auto_field false 
  &amp;lt;/default&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;source&amp;gt;
  @type   norikra
  norikra localhost:26571
  &amp;lt;fetch&amp;gt;
    method   event
    # norikra-client query add dummy_count_1sec &#39;SELECT COUNT(*) AS count FROM dummy.win:time_batch(1 sec)&#39;
    target   dummy_count_1sec
    tag      string data.dummy_count_1sec
 #  tag      field FIELDNAME : tag by value with specified field name in output event
    interval 1m
  &amp;lt;/fetch&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match data.*&amp;gt;
  @type file
  path /var/log/td-agent/dummy_count
  time_slice_format %Y%m%d%H
  time_slice_wait 10s
  time_format %Y%m%dT%H%M%S%z
  compress gzip
  symlink_path /var/log/td-agent/dummy_count
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Norikraのスループットは以下の要素が影響する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;number of targets
number of queries
how complex queries are
how complex UDFs are
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、目安としてはこんな感じらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10 queries
2,000 events per seconds
5% usage of 4core CPU
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1target、単純な1クエリなら秒間10000送ってみても問題なかった。
あまり現実的なケースではないけど限界を目指してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail -f dummy_count
20170609T212717+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212718+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212719+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212720+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212721+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212722+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212723+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212724+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212725+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212726+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 8256 root      20   0 1878m 249m  19m S 29.3  6.6   6:46.94 java
 9812 root      20   0  296m  68m 6288 S 20.0  1.8   2:38.08 ruby  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秒間40000送ってみるとカウントがおかしい。
dummyの方の限界かと思ってnorikraを外してみたらおおよそ数が合ったので
Norikraサーバーかやり取りの部分で処理が追いついていないようだ。
一旦rateを下げてみたところ20000あたりを境目にこうなってしまった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail -f dummy_count
20170609T222018+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:31248}
20170609T222019+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:27468}
20170609T222020+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:35309}
20170609T222021+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:31944}
20170609T222022+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:22805}
20170609T222023+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:30716}
20170609T222024+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:33617}
20170609T222025+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:28740}
20170609T222026+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:32058}
20170609T222027+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:27253}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CPUの使用量をみてみると、ほぼ限界まで使用されていた。
fluentdはrubyの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B0%E3%83%AD%E3%83%BC%E3%83%90%E3%83%AB%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%97%E3%83%AA%E3%82%BF%E3%83%AD%E3%83%83%E3%82%AF&#34;&gt;GIL&lt;/a&gt;
(Global Interpreter Lock = GVL(Giant VM Lock))のため同時に&lt;a href=&#34;https://docs.ruby-lang.org/ja/2.3.0/doc/spec=2fthread.html&#34;&gt;1ネイティブスレッドしか動かせず&lt;/a&gt;、1コアしかCPUを使えないが、
jrubyで動くNorikraは残りのコアを使うことができる。
今回はtargetもクエリも一つだし、データ量も小さいためかメモリにはまだ余裕があった。
ログのサイズやウィンドウサイズが大きければメモリを使う量が増えるため、実際のログをしばらく
流してどちらが問題になりそうか確認するべき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
11378 root      20   0  350m 111m 6336 S 96.1  3.0   1:53.03 ruby
8256 root      20   0 1892m 642m  19m S 84.2 17.1  34:36.38 java   
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;HEAP MEMORY USED: 244MB (55.8%), COMMITTED: 437MB, MAX: 437MB
NON-HEAP MEMORY USED: 51MB (23.8%), COMMITTED: 81MB, MAX: 214MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1Gbps、1Mevent/sを超えるような高トラフィックではStormなどのフレームワークを使えとのこと。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでKinesis streamsに送るときの性能確認</title>
          <link>https://www.sambaiz.net/article/108/</link>
          <pubDate>Mon, 05 Jun 2017 23:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/108/</guid>
          <description>

&lt;h2 id=&#34;localでのstreamsとproducerのbenchmark&#34;&gt;localでのstreamsとproducerのbenchmark&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;の
&lt;code&gt;make benchmark&lt;/code&gt;はlocalにDummyServerを&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis/blob/v1.1.3/benchmark/task.rake#L18&#34;&gt;立ち上げて&lt;/a&gt;送っている。&lt;/p&gt;

&lt;p&gt;空でもいいのでroleをつけておく必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/awslabs/aws-fluent-plugin-kinesis.git
$ cd aws-fluent-plugin-kinesis
$ yum install -y ruby-devel gcc
$ echo &#39;gem &amp;quot;io-console&amp;quot;&#39; &amp;gt;&amp;gt; Gemfile
$ make
$ make benchmark
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATEを指定しなければデフォルトで&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis/blob/v1.1.3/benchmark/task.rake#L19&#34;&gt;秒間1000レコード&lt;/a&gt;が送られる設定。
fluentdを起動してから10秒後にプロセスをkillし、そのレコード数などを出力している。&lt;/p&gt;

&lt;p&gt;t2.microでデフォルト(RATE=1000)で実行した結果がこれ。
固める分producerの方はややパフォーマンスが落ちる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 20, raw_records: 9400, records: 9400
bundle exec rake benchmark TYPE=producer
Results: requets: 14, raw_records: 1005, records: 8900
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATE=3000のとき。producerではraw_recordsが1/100、リクエスト数は1/5。
streamsだとシャードを増やしていく必要があるけど、producerの方は当分大丈夫そうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 57, raw_records: 27600, records: 27600
bundle exec rake benchmark TYPE=producer
Results: requets: 12, raw_records: 241, records: 25200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATE=10000のとき。raw_records, requestの圧縮率はさらに上がり、
パフォーマンスの差が大きくなってきている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 177, raw_records: 88000, records: 88000
bundle exec rake benchmark TYPE=producer
Results: requets: 26, raw_records: 385, records: 75000
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実際にkinesis-streamsに送ってみる&#34;&gt;実際にkinesis streamsに送ってみる&lt;/h2&gt;

&lt;p&gt;ap-northeast-1でシャードは3のKinesis streamsにt2.microインスタンス1台から送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1000
&amp;lt;/source&amp;gt;

&amp;lt;source&amp;gt;
  @type monitor_agent
  bind 0.0.0.0
  port 24220
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type kinesis_streams
  region ap-northeast-1
  stream_name test

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秒間3000まではほとんどキューにたまらず送れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:24220/api/plugins.json | jq
{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 0,
      &amp;quot;buffer_total_queued_size&amp;quot;: 17500,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4000にするとそのうちretryが発生してしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
     &amp;quot;buffer_queue_length&amp;quot;: 60,
      &amp;quot;buffer_total_queued_size&amp;quot;: 56544178,
      &amp;quot;retry_count&amp;quot;: 5,
      &amp;quot;retry&amp;quot;: {
        &amp;quot;steps&amp;quot;: 5,
        &amp;quot;next_time&amp;quot;: &amp;quot;2017-06-05 14:05:38 +0000&amp;quot;
      }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たしかにスループットが超過している。スペック通りだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/108.png&#34; alt=&#34;書き込みスループットの超過&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次に30シャードにしてみる。一度にシャード数は倍から半分にしかできないので作り直し。&lt;/p&gt;

&lt;p&gt;これに秒間30000を送ってみると、キューにいくらか溜まった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 7,
      &amp;quot;buffer_total_queued_size&amp;quot;: 7752600,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに倍にして60シャード。これに秒間60000で送ってみる。キューに溜まるものの増え続けはしないのでなんとか送れてそうだ。
td-agentのプロセスがCPUを99%使っているので、このインスタンスではこの辺が限界かもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 15,
      &amp;quot;buffer_total_queued_size&amp;quot;: 16105807,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ついでにus-east-1にも30シャードのStreamsを作成して30000送ってみたところ、キューに溜まる量が格段に増えた。
早くFirehoseやAnalyticsが東京リージョンにも来てほしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 50,
      &amp;quot;buffer_total_queued_size&amp;quot;: 52432436,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>td-agent2.3.5のfluentdが0.14系になってしまっているのでソースからビルドする</title>
          <link>https://www.sambaiz.net/article/107/</link>
          <pubDate>Sun, 04 Jun 2017 23:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/107/</guid>
          <description>&lt;blockquote&gt;
&lt;p&gt;追記(2016-06-25): 現在は普通に入れても0.12系の2.3.5-1が入るようになっている。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;$ curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh
$ td-agent --version
td-agent 0.14.16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.12系じゃない！？&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yum list installed | grep td-agent
td-agent.x86_64                       2.3.5-0.el2017               @treasuredata
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どうやら2.3.5では0.14系になってしまっているよう。
そのあとにリリースされた2.3.5-1では直ってるみたいだけど、現時点ではrpmリポジトリに上がっていない。&lt;/p&gt;

&lt;p&gt;しょうがないのでソースからビルドすることにした。
いずれにせよ各環境で同じバージョンのビルドに合わせるべきだとは思う。
Beanstalk環境の場合、AMIに固めていたとしても非Beanstalk AMIではyum updateされてしまうので注意が必要だ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/106/&#34;&gt;BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;前UbuntuでやったようにDockerでビルドする。今回はAmazon Linux向け。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/32/&#34;&gt;td-agentをビルドしてfluentdのバージョンを上げる - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/sambaiz/docker-td-agent-build-amazon-linux/&#34;&gt;https://hub.docker.com/r/sambaiz/docker-td-agent-build-amazon-linux/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM amazonlinux:2017.03

WORKDIR /tmp

RUN yum -y update &amp;amp;&amp;amp; \
    yum groupinstall -y &amp;quot;Development Tools&amp;quot; &amp;amp;&amp;amp; \
    yum install -y ruby23 ruby23-devel &amp;amp;&amp;amp; \
    gem install bundler io-console &amp;amp;&amp;amp; \
    git clone https://github.com/treasure-data/omnibus-td-agent

WORKDIR /tmp/omnibus-td-agent

RUN bundle install --binstubs &amp;amp;&amp;amp; \
    bin/gem_downloader core_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader plugin_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader ui_gems.rb &amp;amp;&amp;amp; \
    mkdir -p /opt/td-agent /var/cache/omnibus &amp;amp;&amp;amp; \
    bin/omnibus build td-agent2 &amp;amp;&amp;amp; \
    mv ./pkg/*.rpm /
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t amazon-linux-td-agent .
$ docker run --name altd -itd amazon-linux-td-agent sh
$ docker cp altd:/td-agent-2.3.5-1.el2017.x86_64.rpm .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとはこれをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ yum install -y redhat-lsb-core
$ rpm -ivh td-agent-2.3.5-1.el2017.x86_64.rpm 
$ td-agent --version
td-agent 0.12.36
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因</title>
          <link>https://www.sambaiz.net/article/106/</link>
          <pubDate>Sun, 04 Jun 2017 23:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/106/</guid>
          <description>

&lt;h2 id=&#34;user-dataとは-http-docs-aws-amazon-com-ja-jp-awsec2-latest-userguide-user-data-html&#34;&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/user-data.html&#34;&gt;User-Dataとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;EC2インスタンス起動時に、シェルスクリプトを走らせたりcloud-initディレクティブを適用できる機能。
コンソールではインスタンスの詳細の設定の、高度な詳細のところから設定できる。&lt;/p&gt;

&lt;h2 id=&#34;beanstalkでのuser-data&#34;&gt;BeanstalkでのUser-Data&lt;/h2&gt;

&lt;p&gt;実はBeanstalkでも使われていて、CloudFormationで設定されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;    /bin/bash /tmp/ebbootstrap.sh &amp;quot;,

...

&amp;quot;Fn::FindInMap&amp;quot;: [
    &amp;quot;AWSEBOptions&amp;quot;,
    &amp;quot;options&amp;quot;,
    &amp;quot;UserDataScript&amp;quot;
]
&amp;quot; &amp;gt; /tmp/ebbootstrap.sh &amp;quot;,

...

&amp;quot;AWSEBOptions&amp;quot;: {
    &amp;quot;options&amp;quot;: {
        &amp;quot;UserDataScript&amp;quot;: &amp;quot;https://s3-ap-northeast-1.amazonaws.com/elasticbeanstalk-env-resources-ap-northeast-1/stalks/eb_node_js_4.0.1.90.2/lib/UserDataScript.sh&amp;quot;,
        &amp;quot;guid&amp;quot;: &amp;quot;f08557fc43ac&amp;quot;,
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このshellの中では、時計を同期させたり、awsebユーザーを作成したりするほかに、
非Beanstalk AMI(is_baked=false)ではyum updateが走るようになっている。
そのため、AMIでのバージョンとBeanstalkで立ち上がったときのバージョンが異なることがあるようだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GUID=$7

function update_yum_packages
{
  if is_baked update_yum_packages_$GUID; then
    log yum update has already been done.
  else
    log Updating yum packages.
    yum --exclude=aws-cfn-bootstrap update -y || echo Warning: cannot update yum packages. Continue...
    mark_installed update_yum_packages_$GUID

    # Update system-release RPM package will reset the .repo files
    # Update the mirror list again after yum update
    update_mirror_list

    log Completed updating yum packages. 
  fi
}

function is_baked
{
	if [[ -f /etc/elasticbeanstalk/baking_manifest/$1 ]]; then
    true
	else
    false
	fi
}

function mark_installed
{
    mkdir -p /etc/elasticbeanstalk/baking_manifest/
    echo `date -u` &amp;gt; /etc/elasticbeanstalk/baking_manifest/$1-manifest
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Beanstalk AMIでのログ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /var/log/messages | grep yum
[eb-cfn-init]: yum repo has already been locked to f08557fc43ac.
[eb-cfn-init]: yum update has already been done.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;非Beanstalk AMIでのログ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /var/log/messages | grep yum
[eb-cfn-init]: Completed yum repo version locking.
[eb-cfn-init]: Updating yum packages.
yum[1597]: Updated: *****
...
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unity/UWPでBLEを扱うプラグインを作る</title>
          <link>https://www.sambaiz.net/article/105/</link>
          <pubDate>Sun, 04 Jun 2017 11:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/105/</guid>
          <description>&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/UnityBLE_UWP&#34;&gt;ここ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/aonishi/2013/12/04/unity-on-windows-8-1/&#34;&gt;この動画&lt;/a&gt;の
50:00あたりから説明があるように、
ビルドされたWSAが読むUWPのdllのほかに、
Unityエディタ上から読むための.NET Framework3.5のdllを用意する。
こうすることで実行環境ごとの違いをUnityコード上で気にしなくてもよくなる。&lt;/p&gt;

&lt;p&gt;新しいプロジェクトで&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Visual C# から.NET Framework 3.5にしてクラスライブラリ(.NET Framework)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Visual C# -&amp;gt;　Windows -&amp;gt; ユニバーサルからクラスライブラリ(ユニバーサルWindows)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の2つのプロジェクトを同じソリューションに作成する。
VS2017で.NET Frameworkのクラスライブラリプロジェクトを作成するためには
Visual Studio Installerで.NET Coreのワークロードをインストールする必要がある。
また、これとは別に動作確認用のUWPアプリケーションプロジェクトを作成した。&lt;/p&gt;

&lt;p&gt;UWPの方のプロジェクトにあるClass1.csを削除し、追加 -&amp;gt; 既存の項目から、
もう片方のClass1.csをリンクとして追加して、この共通のcsにUWPのコードを書いていくんだけど、
そのまま書くと当然.NET Frameworkの方でビルドできないので
実装部分を&lt;a href=&#34;https://docs.unity3d.com/Manual/PlatformDependentCompilation.html&#34;&gt;#if WINDOWS_UWP ~ #endif&lt;/a&gt;
で囲む。UWPの方のプロジェクトにはプロパティ -&amp;gt; ビルドの条件付きコンパイルにWINDOWS_UWPが含まれているので有効になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void Start()
{
#if WINDOWS_UWP
    ...
#endif
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;UWPでBLEを扱うのは前書いた通り。
ただし、なぜかXAMLに依存しているようでD3Dビルドすると失敗する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/101&#34;&gt;UWPでBLEデバイスとペアリングして値を取得する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ビルドするとdllができるので.NET Frameworkの方をAssets/Pluginsに置いてInspectorからEditorにだけチェックを入れる。
UWPの方は&lt;a href=&#34;https://docs.unity3d.com/Manual/PluginInspector.html&#34;&gt;Assets/Plugins/WSA&lt;/a&gt;に置くとWSA Playerにだけチェックが入る。&lt;/p&gt;

&lt;p&gt;あとは普通にusingして使うだけ。Edit-&amp;gt;Project Settings-&amp;gt;PlayerからBluetoothのcapabilityを有効にするのを忘れずに。
Package.appxmanifestは上書きされないようなので前にビルドしたやつがあったら一旦消す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityBLE;
  
public class BLE : MonoBehaviour {

    string value = &amp;quot;no connection&amp;quot;;

    public GameObject text;

    private string serviceUUID = &amp;quot;***&amp;quot;;
    private string characteristicUUID = &amp;quot;***&amp;quot;;

    void Start() {
        var ble = new UnityBLE.BLE();
        ble.DeviceAdded += (sender, obj) =&amp;gt; {
            value = &amp;quot;DeviceID: &amp;quot; + obj.DeviceID;
            ble.Listen(obj.DeviceID, serviceUUID, characteristicUUID);
            ble.Stop();
        };
        ble.CharacteristicReceived += (sender, obj) =&amp;gt;
        {
            if (sender == ble)
            {
                if (obj.ex == null)
                {
                    value = Encoding.UTF8.GetString(obj.Value);
                }
                else
                {
                    value = obj.ex.Message;
                }
            }
        };
        ble.Start();
    }

    void Update() {
        text.GetComponent&amp;lt;TextMesh&amp;gt;().text = value;
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる</title>
          <link>https://www.sambaiz.net/article/104/</link>
          <pubDate>Sat, 27 May 2017 16:35:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/104/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/uber-go/zap&#34;&gt;https://github.com/uber-go/zap&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u go.uber.org/zap
$ go get -u gopkg.in/natefinch/lumberjack.v2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;速さの秘訣&#34;&gt;速さの秘訣&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://techblog.ca-reward.co.jp/2016/06/post-33.html&#34;&gt;Go言語のLogger「zap」は何故高速に構造化されたログを出力する事が出来るのか｜株式会社CAリワード&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;reflectionとallocationの回避。&lt;/p&gt;

&lt;p&gt;一度allocateしたBufferやEncoderは
&lt;a href=&#34;https://golang.org/pkg/sync/#Pool&#34;&gt;sync.Pool&lt;/a&gt;で使い回している。
このPoolはまさにallocateされたアイテムを再利用するためのもので、GCの負担を緩和させることができる。
Poolのアイテムは勝手に削除されることがあり、もし参照しか持っていなかったらそのままdeallocateされる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/uber-go/zap/blob/v1.4.0/buffer/pool.go#L34&#34;&gt;https://github.com/uber-go/zap/blob/v1.4.0/buffer/pool.go#L34&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewPool() Pool {
	return Pool{p: &amp;amp;sync.Pool{
		New: func() interface{} {
			return &amp;amp;Buffer{bs: make([]byte, 0, _size)}
		},
	}}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;

&lt;p&gt;現状ドキュメントが乏しいのでコードから探っていく必要がある。
まずはQuick Startから。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;zap.NewProduction()&lt;/code&gt;は&lt;code&gt;NewProductionConfig().Build(options...)&lt;/code&gt;の&lt;a href=&#34;https://github.com/uber-go/zap/blob/master/logger.go#L87&#34;&gt;ショートカット&lt;/a&gt;。
ConfigをBuildしてLoggerを取得し、InfoやErrorで書く流れ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;logger, _ := zap.NewProduction()
defer logger.Sync()
logger.Info(&amp;quot;Hoge&amp;quot;,
  // Structured context as strongly-typed Field values.
  zap.Int(&amp;quot;attempt&amp;quot;, 3),
  zap.Duration(&amp;quot;backoff&amp;quot;, time.Second),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1495870212.3378785,&amp;quot;caller&amp;quot;:&amp;quot;zap-log/main.go:36&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;Hoge&amp;quot;,&amp;quot;attempt&amp;quot;:3,&amp;quot;backoff&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;NewProductionConfig()&lt;/code&gt;の内容はこんな感じ。ここからOutputPathを書き換えるとファイルに出力されるようにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;config := zap.Config{
    Level:       zap.NewAtomicLevelAt(zap.ErrorLevel),
    Development: false,
    Sampling: &amp;amp;zap.SamplingConfig{
        Initial:    100,
        Thereafter: 100,
    },
    Encoding: &amp;quot;json&amp;quot;,
    EncoderConfig: zapcore.EncoderConfig{
        TimeKey:        &amp;quot;ts&amp;quot;,
        LevelKey:       &amp;quot;level&amp;quot;,
        NameKey:        &amp;quot;logger&amp;quot;,
        CallerKey:      &amp;quot;caller&amp;quot;,
        MessageKey:     &amp;quot;msg&amp;quot;,
        StacktraceKey:  &amp;quot;stacktrace&amp;quot;,
        LineEnding:     zapcore.DefaultLineEnding,
        EncodeLevel:    zapcore.LowercaseLevelEncoder,
        EncodeTime:     zapcore.EpochTimeEncoder,
        EncodeDuration: zapcore.SecondsDurationEncoder,
        EncodeCaller:   zapcore.ShortCallerEncoder,
    },
    OutputPaths:      []string{&amp;quot;stderr&amp;quot;},
    ErrorOutputPaths: []string{&amp;quot;stderr&amp;quot;},
}
config.OutputPaths = []string{&amp;quot;./aaaa.log&amp;quot;}
logger, _ = config.Build()
defer logger.Sync()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Buildの引数にも渡せるOptionというのは&lt;code&gt;apply(logger)&lt;/code&gt;でloggerを操作するインタフェース。
&lt;a href=&#34;https://github.com/uber-go/zap/blob/74ca5ef91c08e5eafb5ab9739df05d66f1b5d8da/options.go#L55&#34;&gt;zap.Fields&lt;/a&gt;は
フィールドを追加するもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;logger = logger.WithOptions(zap.Fields(zap.String(&amp;quot;hoge&amp;quot;, &amp;quot;fuga&amp;quot;)))
defer logger.Sync()
logger.Error(&amp;quot;aaa&amp;quot;,
    zap.String(&amp;quot;eee&amp;quot;, &amp;quot;eee&amp;quot;),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/uber-go/zap/blob/v1.4.0/config.go#L154&#34;&gt;Build&lt;/a&gt;の実装をみると、
中では&lt;code&gt;zapcore.NewCore(enc, sink, cfg.Level)&lt;/code&gt;とOptionを引数として取る&lt;code&gt;New()&lt;/code&gt;でloggerを生成している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;enc, err := cfg.buildEncoder()
if err != nil {
    return nil, err
}

sink, errSink, err := cfg.openSinks()
if err != nil {
    return nil, err
}

log := New(
    zapcore.NewCore(enc, sink, cfg.Level),
    cfg.buildOptions(errSink)...,
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このsinkは&lt;code&gt;io.Writer&lt;/code&gt;をwrapした&lt;a href=&#34;https://github.com/uber-go/zap/blob/179e456766f6ba6d1006f432f90d52ecb6296e84/zapcore/write_syncer.go#L32&#34;&gt;WriteSyncer&lt;/a&gt;
で、&lt;code&gt;AddSync(w io.Writer)&lt;/code&gt;で変換できる。
これに&lt;a href=&#34;https://github.com/natefinch/lumberjack&#34;&gt;lumberjack&lt;/a&gt;を渡してやるとrotateできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;config := zap.NewProductionConfig()
enc := zapcore.NewJSONEncoder(config.EncoderConfig)
sink := zapcore.AddSync(
    &amp;amp;lumberjack.Logger{
        Filename:   &amp;quot;./aaaa.log&amp;quot;,
        MaxSize:    500, // megabytes
        MaxBackups: 3,
        MaxAge:     28, //days
    },
)
logger := zap.New(
    zapcore.NewCore(enc, sink, config.Level),
)
defer logger.Sync()
logger.Error(&amp;quot;aaa&amp;quot;,
    zap.String(&amp;quot;eeef&amp;quot;, &amp;quot;eefe&amp;quot;),
)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>夜のNY郊外を無一文で彷徨い、Google I/OとMaker Faire Bay Areaに行ってきた</title>
          <link>https://www.sambaiz.net/article/103/</link>
          <pubDate>Mon, 22 May 2017 23:44:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/103/</guid>
          <description>

&lt;p&gt;Googleが毎年やっているイベント、Google I/Oのチケットが当たったのでアメリカに行ってきた。
海外に行くのはこれが3回目でアメリカははじめて。一人での海外もはじめて。&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;チケットが当たってからExpediaで航空券やホテルを取った。航空券の流れで保険にも加入した。
アメリカの医療費は相当高いそうなので何かしらの保険に入っておかないと不安だ。&lt;/p&gt;

&lt;p&gt;会期中は会場近辺のサンフランシスコ/マウンテンビューのホテルがとんでもなく値上がりしている模様。
多分通常の倍ぐらいにはなっているので早めに取っておくとよいと思われる。&lt;/p&gt;

&lt;p&gt;GoogleI/Oは週末にかけての3日間だったので、その前の週末から出発し、前半はニューヨークに行くことにして、
マンハッタンに宿を取った。&lt;/p&gt;

&lt;p&gt;アメリカに入国するのには&lt;a href=&#34;https://esta.cbp.dhs.gov/esta/application.html&#34;&gt;ESTA&lt;/a&gt;を申請する必要がある。
申請自体は72時間以内に通るのだけど、パスポート番号が必要がなので持っていなければ先に作っておく必要がある。
ESTAが通っていないと本当に入れないらしい。怖い。&lt;/p&gt;

&lt;p&gt;現地での通信手段はT-mobileの&lt;a href=&#34;https://prepaid-phones.t-mobile.com/prepaid-international-tourist-plan&#34;&gt;Tourist plan&lt;/a&gt;($30プリペイドでSIM+2GB LTE+国内通話+SMS)
を購入することにした。
日本にはsimを送ってくれないので現地で調達する必要がある。モバイルルータはちょっと高いような気がして借りなかった。&lt;/p&gt;

&lt;p&gt;あとは英語力をなんとかしようと付け焼刃でDMM英会話をはじめてみたが、準備期間が短すぎたかなと思う。&lt;/p&gt;

&lt;h2 id=&#34;出国&#34;&gt;出国&lt;/h2&gt;

&lt;p&gt;チェックインの締め切りが出発の1時間前だったので、
余裕を持って2時間前ぐらいには着くはずだったんだけど、こんなときに限って財布を落とすわ成田エクスプレスは突然運休するわで大ピンチ。
日暮里から京急のスカイライナーに乗ってスーツケースをかついで走ってなんとか飛行機には間に合ったが、
両替などする時間はなく、財布に1000円しか入っていない状態で出発することになってしまった。&lt;/p&gt;

&lt;p&gt;距離にして11000km、12時間のフライトの末、ニューヨークのジョン・F・ケネディ国際空港(JFK)に到着。
時差で-13時間になるため出発よりも早い時刻に到着することになって得した気分だ。
ついにアメリカに来た。&lt;/p&gt;

&lt;h2 id=&#34;ニューヨーク&#34;&gt;ニューヨーク&lt;/h2&gt;

&lt;p&gt;当初はニューヨーク観光しつつ、アムトラック(電車)でワシントンD.C.にも行っちゃおうかと考えてチケットまで買っていた。
しかし現実は厳しい。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;現地に到着し、通信手段を調達するためT-mobileのショップに向かおうとしたが、肝心のショップの場所がわからない。
もちろん日本のsimカードはすでに機能停止しているので空港のWifiで調べたところ、そこから一番近いところでも数km離れていることがわかった。
タイムズスクエアの近くにはあるようだったので、まずはなんとかしてホテルに向かうことにしたが、
JFKからマンハッタンまでは直線距離で20km以上離れている。ホテルの送迎サービスはなかった。
それでもGoogle mapに従って、途中free wifiを乗り継いでいけばこのときはなんとかなるかなと思っていた。&lt;/p&gt;

&lt;p&gt;空港から電車で行こうと思っていたところ、うかつにも謎タクシーに誘導されて乗ってしまった。
47ドルでホテルまで行ってくれると思いきや、それはJamaica駅までの料金で、ホテルまでは100ドルという。調べていた相場の倍だ。
傷口を広げないようJamaicaで降ろしてもらうことにした。
乗る前に現金はないからクレジットカードで払う旨を伝えたのだけど、
支払いの段になってクレジットカードの機械が壊れたから現金でと言い出して困った。なにせ1ドルも持っていないのだから。
近くのATMで現金を下ろすよう言われたのでクレジットカードを入れたのだけれど
2枚ともアウト。そこからどうやって払うんだって問いつめられるもののどうしようもない。
結局解放してもらえたが、初っ端からほとんど心が折れてしまって国に帰りたかった。&lt;/p&gt;

&lt;p&gt;それでもなんとかしてホテルにはたどり着かなくてはならないので、LIRRという電車でJamaicaからWoodside駅に向かった。
空港で調べたGoogle mapの経路に出たからそうしたのだけど、
マンハッタンにあるハブ駅、Pensilvania(Penn) stationまで行くほうが行き先表示に出ているので分かりやすかった。
改札はなくて切符は車内で確認される。&lt;/p&gt;

&lt;p&gt;案内の人に聞いて電車に乗ったんだけど、切符の確認の際にこの電車ではないと言われる。
乗り間違えると、引き返すためにホームで割と長く待つことになる。5月も半ばなのに白い息が出るぐらい寒い。
Googleで調べようにも、駅にあるWifiはどうも契約していないと使えなさそうなものしかなかった。
地下鉄にはfree wifiが通っていたが、それも全ての駅で使えるというわけではなさそうだった。&lt;/p&gt;

&lt;p&gt;Woodsideからは地下鉄に乗るのだけれど、この券売機がなぜかクレジットカードのPINをうけつけてくれずチケットを買えなかった。
カードが止まったかと思い、しょうがないので6kmほど歩いてマンハッタンまで向かうことにした。雨が降っていて、寒くて泣きたくなった。
空港でマップのデータを読んでいたのでGPSと合わせればオフラインでも自分の位置はわかるのが唯一の救いだ。
電話もなかったので、道中あったスタバなどのfree wifiを外から使わせてもらって、
家族に連絡をとって日本からクレジットカード会社に問い合わせてもらったが、
本人からの連絡じゃないとだめとのことでどうしようもなかった。&lt;/p&gt;

&lt;p&gt;マンハッタンに行くためにはイースト川を越える必要があったので、
地図上で橋になっているところを順番に見てまわったが、車や電車でないとだめなところばかりで暗雲がただこめる。
あとから調べたら、マンハッタンの南側、ブルックリンとマンハッタン橋は歩いて渡れたらしい。
あの向こうがマンハッタンなのになと沿岸を眺めながら、この時点で夜中の0時を回っていて、野宿の可能性を考え始める。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-manhattan.jpg&#34; alt=&#34;マンハッタンを眺める&#34; /&gt;&lt;/p&gt;

&lt;p&gt;途方に暮れて彷徨っていたところ、歩いていたおじさんとたまたま目が合って、
お金がなくて電車には乗れないんだけど、徒歩でマンハッタンに渡る方法はあるか聞いたら、
なんと地下鉄の駅まで案内してくれて運賃を出してくれた。
お礼するために連絡先を聞こうとしたのにすぐいなくなってしまわれた。命の恩人だ。&lt;/p&gt;

&lt;p&gt;なんとかホテルに到着し、電話を借りてカード会社に連絡したところ、
カードは普通に使える状態で電車の明細はこちらには届いていない、キャッシングは枠がないからできない、
というまさかの事実が発覚した。
カードが使えるとはいえ現金がないと困ることが分かったので、キャッシング枠の審査を急いでもらうよう頼んでみた。&lt;/p&gt;

&lt;p&gt;もはや遠出する気が全くなくなったのでアムトラックのチケットをキャンセルしようと思ったら、システムメンテナンスでできずに諦める。
雨の中歩き回ったのでスーツケースの中の服はほとんどびしょ濡れだった。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;次の日は昼をまわったころ目覚めて、だらだらして風呂に入ってT-mobileのショップに向かってsimを購入。
設定は向こうの人がやってくれるので、言語を英語にしておくとスムーズだ。
念願の通信手段を得て、Google mapがいつでも使えるようになった。つまり無敵。
とはいえ、いまだ現金がないのでマンハッタンの中で過ごすことにした。&lt;/p&gt;

&lt;p&gt;マンハッタンは高いビルが多く、GPSが大きくずれる。縦横のStreetとAvenueに番号が振られているのでそれに従うと動きやすかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-stav.jpg&#34; alt=&#34;StreetとAvenueの表示&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Shake Shackのハンバーガーを食べて、チェルシーマーケットでロブスターを食べた。これでもsmall。
身はぎっしり入っていてレモンをかけて食べるとおいしい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-bigebi.jpg&#34; alt=&#34;チェルシーマーケットのロブスター&#34; /&gt;&lt;/p&gt;

&lt;p&gt;それと、なぜかカードが使えなかった地下鉄に再チャレンジしてみた。
問題になったのはこういう券売機。クレジットカードを抜き差し(dip)してPINを入力する。やっぱり買えない。
いろいろ試して見たところPINを入力せずにENTERだけ押したら買えることがわかった。意味わからん・・・。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-ny-subway-machine.jpg&#34; alt=&#34;NYの地下鉄の券売機&#34; /&gt;&lt;/p&gt;

&lt;p&gt;夜にキャッシングができるようになったのでタクシードライバーに連絡をとって代金を支払って2日目も終わり。
3日目は空港に向かう日なので、これがNY滞在の全て。次来るときはもう少しなんとかしたい。&lt;/p&gt;

&lt;p&gt;到着はJFKだったけど、出発はニューアーク・リバティー空港(EWR)からで、Penn stationからNJ TRANSIT(電車)一本で行ける。
Penn stationは上にも書いたとおりハブ駅で、アムトラック、LIRR、NJ TRANSITの駅が入っている。
ワシントンD.C.に行くときもこの駅から出るはずだった。
最初、画面にTrack(ホーム)が書いてなくてちょっと焦ったが、STATUSがBOARDINGになると表示される。&lt;/p&gt;

&lt;p&gt;EWRの飲食店にはタブレットが置いてあって、そこで注文しカードを通すと注文される。現金は使えない。
最初にboarding passのバーコードをかざすと乗る便の情報が表示されるので乗り遅れる心配がない。乗り遅れるどころか2時間遅延してたけど。
終わったらtabをcloseする。チップの割合も選択できるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-ewr.jpg&#34; alt=&#34;EWRの飲食店のタブレット&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ここから西海岸、サンフランシスコへ。
国内ながら3時間の時差があって、6時間のフライトなのに3時間しか進まない。&lt;/p&gt;

&lt;h2 id=&#34;googlei-o&#34;&gt;GoogleI/O&lt;/h2&gt;

&lt;p&gt;I/Oに参加する同僚2人と合流した。一人でないのは心強い限りだ。&lt;/p&gt;

&lt;p&gt;GoogleI/O自体は3日間なのだけれど、前日に登録ができ、先着順でKeynoteの前の方の席が割り当てられる。
今年の会場は去年と同じマウンテンビューのShoreline Amphitheatreというところで、Googleの近くにある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-shoreline.jpg&#34; alt=&#34;Shoreline Amphitheatre&#34; /&gt;&lt;/p&gt;

&lt;p&gt;サンフランシスコからもサンノゼからもそれなりに離れていて、最寄りの電車の駅も少し離れているので、バスか車で来ることになると思う。
同僚がレンタカーを借りてくれていたのでそれで向かったが、フリーウェイの、特に出口が渋滞して結構時間がかかる。
駐車場が一杯なのではないか心配していたけど、普通の駐車場の他に滅茶苦茶広いオーバーフロー駐車場があるので問題なかった。
どこまで駐車場なのかわからないぐらい広い。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-parking.jpg&#34; alt=&#34;オーバーフロー駐車場&#34; /&gt;&lt;/p&gt;

&lt;p&gt;受付を済ませると首からかけるバッジと、水筒、日焼け止め、Tシャツ、サングラスがもらえた。
会場は基本屋外なのでかなり実用的なセットだ。一方夜は相当寒いので上着を持っていったほうがよい。
バッジはNFCタグになっていて、セッション予約の確認に使われる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-ioset.jpg&#34; alt=&#34;もらったもの&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ついでに近くのGoogleも見にいってきた。ショップがある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-google.jpg&#34; alt=&#34;Google&#34; /&gt;&lt;/p&gt;

&lt;p&gt;その後サンフランシスコ市内の北、フィッシャーマンズワーフのBOUDINという店でパンの器のクラムチャウダーを食べた。
おいしかった。海の方を眺めるとアルカトラズが見える。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-boudin.jpg&#34; alt=&#34;クラムチャウダー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;夜はIntel&amp;rsquo;s Google I/O Day Zero Partyという非公式の前夜祭みたいなのに行ってきた。
I/Oに比べると規模はそんなに大きくはないけど、それでも多くの人が集まっていて、日本勢にも出会った。
飲み放題食べ放題で、IntelやGoogleのテクノロジーに絡んだデモが行われている。
体験したりしてトークンを集めることで賞品と交換でき、アンドロイドのTシャツをもらった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-zero-day.jpg&#34; alt=&#34;アンドロイドのTシャツ&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Keynoteは一番広いアンフィシアターで行われ、内側の椅子エリアと外側の芝のエリアがある。
遅れてしまったため芝エリアしか入れなくて午前中はそこで聞くことしたら、暑いけど寝転がりながら聞くことができるので案外悪くなかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-keynote.jpg&#34; alt=&#34;芝席&#34; /&gt;&lt;/p&gt;

&lt;p&gt;食事は指定の場所で配られているので取っていって適当な場所で食べる。
朝食も含めて食事や飲み物やお菓子は全て提供されるが、朝食は数がそんなに多くないのか、遅い時間に行くとなくなっていることがあった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-food.jpg&#34; alt=&#34;食事のリスト&#34; /&gt;&lt;/p&gt;

&lt;p&gt;午後のDeveloper Keynoteでは主な新機能などがざっくり発表されて、What&amp;rsquo;s newなどのセッションではそれが詳細に説明されたりする形になっている。&lt;/p&gt;

&lt;p&gt;Androidは、GooglePlay Protectや、地味に長いブート時間が2倍速くなったりするAndroid Oが発表された。あと、嬉しそうにもう一つあるよって言い出して
何かなと思ったらKotlin公式サポート。Android勢歓喜。よかったね。&lt;/p&gt;

&lt;p&gt;Daydream(VR)はスマホ不要のStandaloneヘッドセットと、位置トラッキングのWorldSense。
Tango(AR)はGPSに対して、室内で位置を知ることができるVPS(Visual Positioning Service)というのが発表されていた。これを使うと店内でナビできるすごく便利そうなやつだ。
VR/ARは教育分野、&lt;a href=&#34;https://edu.google.com/expeditions/&#34;&gt;Google Expeditions&lt;/a&gt;でも使われているらしい。
ARで教室に火山や竜巻を出したりできる。後のセッションで言っていたのは、どこにでもVRで行って何でもARで見れるだったかな。&lt;/p&gt;

&lt;p&gt;あとはGoogle photoのサジェスト機能や、なんかすごいGoogle lensなどなど。
Keynoteを通して、Googleっていろんなことをやっていて、世界が便利になるイメージが湧いた。&lt;/p&gt;

&lt;p&gt;最後に突然のGoogle Home+GCPクレジット配布の発表。うれしい。
日本での発売も発表されたが、一足早く手に入れることができた。何か作ってみたい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-home.jpg&#34; alt=&#34;Google Home&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Keynoteが終わると並行してセッション、展示やオフィスアワーなどが行われる。
セッションは1時間区切りになっていて、移動の時間が用意されていないように見えるが、
実際は30~40分ほどで終わるので一杯に入れても問題はない。
ただ、一日中ずっとセッションを聞いているというのも疲れるので、
割とみんなその辺りにある椅子や芝生に座ったり寝転がったりしてPCを開いてたり、歓談してたりする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-relax.jpg&#34; alt=&#34;会場風景&#34; /&gt;&lt;/p&gt;

&lt;p&gt;セッションはAR(Tango)/VR(Daydream)、Firebase、Android Thingsなどいろいろな種類のを聞きにいった。
全てのセッションはライブストリーミングされているので日本でも聞けるけど、
現地だと会場の雰囲気を楽しめるのはもちろん、しなかったけどセッションの後やオフィスアワーで質問したりすることができる。
次来るときは質問できるぐらい使い込んでいきたい。&lt;/p&gt;

&lt;p&gt;Firebaseもいくつか機能追加があって、そのうちの一つがPhone number auth。早速ためしてみた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/102/&#34;&gt;io17で発表されたFirebaseのphone number authをwebで試してみた&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AndroidThingsはIoTのためのOS。
Androidのエコシステムに乗れることと、プロトタイプから本番までのスケーリングしやすさ、セキュリティが特長として挙げられていた。
せっかくなのでcodelabsで触ってきた。codelabsでは、Googleのテクノロジーのチュートリアルのコースを質問しながら進められる。
Android端末など必要な機材は用意されているので、それらを持っていなくても問題ない。IoTはなかなかの人気コンテンツで2時間待つことになった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-codelabs.jpg&#34; alt=&#34;IOT codelab&#34; /&gt;&lt;/p&gt;

&lt;p&gt;コースを最後まで終えるとAndroid Things対応のハードウェアセットがもらえた。
codelabsはwebに&lt;a href=&#34;https://codelabs.developers.google.com/io2017&#34;&gt;公開されている&lt;/a&gt;ので家でも試すことができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-iot-omiyage.jpg&#34; alt=&#34;IOTおみやげ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;1,2日目のセッションが終わるとAfter Hourというパーティーがある。
朝から夜まで楽しめる、とても良いイベントだった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-party.jpg&#34; alt=&#34;After Hour&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;maker-faire-bay-area&#34;&gt;Maker Faire Bay Area&lt;/h2&gt;

&lt;p&gt;Google I/Oが終わった翌日、同僚を空港で見送ってSan mateoで行われるMaker Faire Bay Areaにいってきた。&lt;/p&gt;

&lt;p&gt;Maker Faireは、ものづくりが好きな人たちが集まり、作ったものを展示発表したり体験したりするお祭り。
このBay Areaからはじまり、世界中に広がっている。
東京でも行われているんだけど、行ったことがないためこれが初参加。&lt;/p&gt;

&lt;p&gt;空港から会場のSan Mateo Event Centerまではバス(SamTrans)で向かった。
運賃は現金で払うこともできるけど、Clipperという日本のSuicaみたいなやつがあると便利。空港のInformationで買えた。
バスの運賃は2ドルちょっと。&lt;/p&gt;

&lt;p&gt;バス停は柱の上の方にある行き先が書いてある札が目印。待合所があるところもあれば、ただの柱にくっついているところもあってちょっと気づきにくい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-busstop.jpg&#34; alt=&#34;バス停&#34; /&gt;&lt;/p&gt;

&lt;p&gt;乗ったらClipperをピッとやって席に座り、降りたければ黄色い紐を引くとSTOP REQUESTEDされる。
バス停に近づいても特にアナウンスなく通過してしまうのでGPSの位置を注意して見ていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-stop-requested.jpg&#34; alt=&#34;STOP REUESTEDの紐&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;会場はとても広い。何も考えずにうろうろしていたのだけど、あとでマップを見返したら、見てない場所とかがあったりしたので、最初にマップで行く場所に目星をつけておいたほうがよいと思う。
展示のジャンルごとにテントがあって、ほかにはアクティビティやステージ、食べ物の屋台、体験コーナーなどがある。
屋台は基本現金払いだけど、ATMが会場内にもある。
子供連れもたくさんいて、大人子供ともに楽しめるイベントになっていた。&lt;/p&gt;

&lt;p&gt;展示物は、子供が作ったものから、こんなの個人で作れるのかというようなものまで、ジャンルも電子工作からガーデニングまでいろいろ。
日本から出している人もいて、ロボットのところにデイリーポータルZや個人のブースがいくつかあった。&lt;/p&gt;

&lt;p&gt;すごい勢いで燃えながら回転する球。日本だと消防法的にまずそう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-burning.jpg&#34; alt=&#34;燃える球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;自転車をこいで電力を賄うステージ。ステージもいくつかあって、他では化学の実験をやっていた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-you-are-the-power.jpg&#34; alt=&#34;YOU ARE THE POWER!&#34; /&gt;&lt;/p&gt;

&lt;p&gt;アクティビティをやるには自己責任的な誓約書にサインしてリストバンドをもらう必要がある。
これは音楽に合わせて対応するところを踏んだり引いたりするゲーム。アクションは5つしかないんだけど、なかなか難しかった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-make-act.jpg&#34; alt=&#34;音ゲー&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ドローンレースをやっているテントもあった。モニターにはドローン視点の映像が流れていて迫力がある。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-drone.jpg&#34; alt=&#34;ドローンレース&#34; /&gt;&lt;/p&gt;

&lt;p&gt;R2D2がいた。もちろん動く。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/104-r2d2.jpg&#34; alt=&#34;R2D2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;せっかくAndroid Thingsのハードウェアも手に入ったことだし、何か作って出展してみたい。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;これでアメリカでの予定も終わり。
9日間ながら内容が濃い滞在だった。また行きたい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>io17で発表されたFirebaseのphone number authをwebで試してみた</title>
          <link>https://www.sambaiz.net/article/102/</link>
          <pubDate>Wed, 17 May 2017 23:34:00 -0700</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/102/</guid>
          <description>&lt;p&gt;今日のdeveloper keynoteで発表されたphone number authを試してみた。
Firebaseだと他にはPerformance Monitoringも発表されている。
あとSDKをオープンソースにするとか。&lt;/p&gt;

&lt;p&gt;firebase-toolsを最新版にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# npm install -g firebase-tools
$ firebase -V
3.9.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FirebaseUIを使う場合、これも最新版にしないと出てこない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&amp;quot;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;link type=&amp;quot;text/css&amp;quot; rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://cdn.firebase.com/libs/firebaseui/2.0.0/firebaseui.css&amp;quot; /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;firebase.auth.PhoneAuthProvider.PROVIDER_ID&lt;/code&gt;がphone number authの
&lt;a href=&#34;https://github.com/firebase/firebaseui-web#starting-the-sign-in-flow&#34;&gt;オプション&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const uiConfig = {
    signInOptions: [
        firebase.auth.PhoneAuthProvider.PROVIDER_ID
    ],
    ...
}

const ui = new firebaseui.auth.AuthUI(firebase.auth());
ui.start(&#39;#firebaseui-auth-container&#39;, uiConfig);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなボタンを押すと&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/102-1.png&#34; alt=&#34;ボタン&#34; /&gt;&lt;/p&gt;

&lt;p&gt;電話番号とCAPTCHAが入り、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/102-2.png&#34; alt=&#34;電話番号とCAPTCHA&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SMSに書かれた番号を入力すると認証される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/102-3.png&#34; alt=&#34;番号入力&#34; /&gt;&lt;/p&gt;

&lt;p&gt;二段階認証のようなものだと思っていたけど、そうではないみたい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UWPでBLEデバイスとペアリングして値を取得する</title>
          <link>https://www.sambaiz.net/article/101/</link>
          <pubDate>Sat, 13 May 2017 10:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/101/</guid>
          <description>

&lt;p&gt;ManifestからBluetoothを許可しておく。&lt;/p&gt;

&lt;h2 id=&#34;bleデバイスを見つける-https-github-com-microsoft-windows-universal-samples-blob-dev-samples-bluetoothleclient-cs-scenario1-discoverserver-xaml-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/Windows-universal-samples/blob/dev/Samples/BluetoothLEClient/cs/Scenario1_DiscoverServer.xaml.cs&#34;&gt;BLEデバイスを見つける&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;CreateWatcher&lt;/code&gt;にBluetooth LEプロトコルの&lt;a href=&#34;https://docs.microsoft.com/ja-jp/windows/uwp/devices-sensors/aep-service-class-ids&#34;&gt;AEP(Association EndPoint)サービスクラスID&lt;/a&gt;と
requestPropaertiesで必要なデバイス情報を渡している。
最後の&lt;code&gt;AssociationEndpoint&lt;/code&gt;は&lt;code&gt;System.Devices.Aep.ProtocolId&lt;/code&gt;のAepと&lt;a href=&#34;https://docs.microsoft.com/ja-jp/windows/uwp/devices-sensors/enumerate-devices-over-a-network&#34;&gt;対応している&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using Windows.Devices.Enumeration;

string[] requestedProperties = { &amp;quot;System.Devices.Aep.DeviceAddress&amp;quot;, &amp;quot;System.Devices.Aep.IsConnected&amp;quot; };

deviceWatcher = DeviceInformation.CreateWatcher(
                        &amp;quot;(System.Devices.Aep.ProtocolId:=\&amp;quot;{bb7bb05e-5972-42b5-94fc-76eaa7084d49}\&amp;quot;)&amp;quot;,
                        requestedProperties,
                        DeviceInformationKind.AssociationEndpoint);

deviceWatcher.Start();
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;deviceWatcher.Added += DeviceWatcher_Added;
deviceWatcher.Removed += DeviceWatcher_Removed;
deviceWatcher.Updated += DeviceWatcher_Updated;
/*
deviceWatcher.EnumerationCompleted += DeviceWatcher_EnumerationCompleted;
deviceWatcher.Stopped += DeviceWatcher_Stopped;
*/

Dictionary&amp;lt;string, DeviceInformation&amp;gt; deviceInfos = new Dictionary&amp;lt;string, DeviceInformation&amp;gt;();

private void DeviceWatcher_Added(DeviceWatcher sender, DeviceInformation deviceInfo)
{

    if (sender == deviceWatcher)
    {
        if (deviceInfo.Name != string.Empty)
        {
            deviceInfos.Add(deviceInfo.Id, deviceInfo);   
        }
    }
}

private void DeviceWatcher_Updated(DeviceWatcher sender, DeviceInformationUpdate deviceInfoUpdate)
{
    if (sender == deviceWatcher)
    {
        deviceInfos[deviceInfoUpdate.id].Update(deviceInfoUpdate);
    }
}

 private void DeviceWatcher_Removed(DeviceWatcher sender, DeviceInformationUpdate deviceInfoUpdate)
{
    if (sender == deviceWatcher)
    {
        deviceInfos.Remove(deviceInfoUpdate.id);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ペアリング&#34;&gt;ペアリング&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;DevicePairingResult result = await deviceInfo.Pairing.PairAsync();
if (result.Status == DevicePairingResultStatus.Paired || result.Status == DevicePairingResultStatus.AlreadyPaired){
    // success
} else{
    // fail
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなウィンドウが出てくる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/101.png&#34; alt=&#34;ペアリング確認&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OSの設定からペアリングすることもできる。&lt;/p&gt;

&lt;h2 id=&#34;serviceのcharacteristicを取得する&#34;&gt;serviceのcharacteristicを取得する&lt;/h2&gt;

&lt;p&gt;ペアリングしたらこんな感じで値を取得できる。
&lt;a href=&#34;https://docs.microsoft.com/en-us/uwp/api/Windows.Devices.Bluetooth.BluetoothLEDevice#Windows_Devices_Bluetooth_BluetoothLEDevice_GetGattServicesForUuidAsync_&#34;&gt;GetGattServicesForUuidAsyc&lt;/a&gt;
などはCreaters Update(15063)から追加されたAPI。
Anniversary Edition(14393)まで&lt;a href=&#34;https://github.com/sambaiz/UnityBLE_UWP/tree/build_For_14393&#34;&gt;対応する場合&lt;/a&gt;
は&lt;code&gt;GetGattService&lt;/code&gt;を使う。いずれにしても最小バージョンをそれ以上にしておく。
deviceの値が取得できない場合はBluetoothが許可されているか確認する。
あと、characteristicが一つも取れない場合、他のアプリケーションからアクセスしていないか注意。
ドキュメントにも書いてあるけど、一つのサービスには一つのアプリケーションしかアクセスできない。
そもそも接続できない場合、一旦お互いの接続設定を消して再ペアリングするとよくなることがある。
ペアリングもできないようだったらBluetoothをオフにしてみるとか。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var device = await BluetoothLEDevice.FromIdAsync(deviceInfo.Id);

var services = await device.GetGattServicesForUuidAsync(serviceUUID);

var characteristics = await services.Services[0].GetCharacteristicsForUuidAsync(characteristicUUID);

characteristics.Characteristics[0].ValueChanged += characteristicChanged;

await characteristics.Characteristics[0].WriteClientCharacteristicConfigurationDescriptorAsync(
    GattClientCharacteristicConfigurationDescriptorValue.Notify
);

void characteristicChanged(
    GattCharacteristic sender,
    GattValueChangedEventArgs eventArgs
){
    byte[] data = new byte[eventArgs.CharacteristicValue.Length];
    Streams.DataReader.FromBuffer(eventArgs.CharacteristicValue).ReadBytes(data);
    var str = System.Text.Encoding.ASCII.GetString(data)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/105&#34;&gt;Unity/UWPでBLEを扱うプラグインを作る - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RxJSでObservableを結合する(merge, forkJoin, concat, combineLatest)</title>
          <link>https://www.sambaiz.net/article/100/</link>
          <pubDate>Tue, 09 May 2017 20:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/100/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/85/&#34;&gt;RxJSでRxをはじめる - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;merge-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-merge&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-merge&#34;&gt;merge&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;2つのstreamの両方の値がemitされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.merge(
  stream1,
  stream2
).subscribe(
  data =&amp;gt; console.log(`merge ${data}`),
  err =&amp;gt; console.log(`merge ${err}`)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;forkjoin-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-forkjoin&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-forkJoin&#34;&gt;forkJoin&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;completeしたときの最後の値を配列としてemitする。
非同期で一つ値をemitするようなstreamで、Promise.allのようなことをしたいときはこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.forkJoin(
  stream1,
  stream2
).subscribe(
  data =&amp;gt; console.log(`      forkJoin: ${data}`),
  err =&amp;gt; console.log(`      forkJoin: ${err}`)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;concat-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-concat&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-concat&#34;&gt;concat&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;前のstreamがcompleteしたら次のstreamの値がemitされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.concat(
  stream1,
  stream2
).subscribe(
  data =&amp;gt; console.log(`  concat ${data}`),
  err =&amp;gt; console.log(`  concat ${err}`)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;combinelatest-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-combinelatest&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-combineLatest&#34;&gt;combineLatest&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;stream自体を結合するのではなく値を結合する。
この例だと、streamでemitされた値がa、stream2で最後のemitされた値がbになる。
combineする値がない場合はemitされない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stream1.combineLatest(stream2, (a, b) =&amp;gt; a + b).subscribe(
  data =&amp;gt; console.log(`    combineLatest ${data}`),
  err =&amp;gt; console.log(`    combineLatest ${err}`)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;同時に実行したときの結果&#34;&gt;同時に実行したときの結果&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;const stream1 = Rx.Observable.interval(100).map(v =&amp;gt; `stream 1-${v+1}`).take(3);
const stream2 = Rx.Observable.interval(100).map(v =&amp;gt; `stream 2-${v+1}`).take(3).delay(150);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/100.png&#34; alt=&#34;stream1とstream2&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;merge stream 1-1
  concat stream 1-1
merge stream 1-2
  concat stream 1-2
merge stream 2-1 &amp;lt;- mergeではstream1はcompleteしていないが、stream2がemitされる
merge stream 1-3
  concat stream 1-3
    combineLatest stream 1-3stream 2-1 &amp;lt;- stream2の値がemitされたのでcombineする
merge stream 2-2
    combineLatest stream 1-3stream 2-2
      forkJoin: stream 1-3,stream 2-3 &amp;lt;- stream1とstream2がcompleteしたのでforkJoinでemitされる
    combineLatest stream 1-3stream 2-3
merge stream 2-3
  concat stream 2-1 &amp;lt;- concatではstream1がcompleteしたので、stream2がemitされる
  concat stream 2-2
  concat stream 2-3
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>angular/material2でフォームを作る</title>
          <link>https://www.sambaiz.net/article/99/</link>
          <pubDate>Sat, 06 May 2017 22:16:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/99/</guid>
          <description>

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99.gif&#34; alt=&#34;フォーム&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/angular4-form&#34;&gt;コード&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;angular-material2-https-github-com-angular-material2-の準備&#34;&gt;&lt;a href=&#34;https://github.com/angular/material2&#34;&gt;angular/material2&lt;/a&gt;の準備&lt;/h2&gt;

&lt;p&gt;現時点で
&lt;a href=&#34;https://github.com/angular/material2/issues/675&#34;&gt;DatePicker&lt;/a&gt;や
&lt;a href=&#34;https://github.com/angular/material2/issues/581&#34;&gt;Table&lt;/a&gt;など
開発中のコンポーネントが多いため足りないものを他のライブラリで補うなどする必要がある。
DatePickerはもう少しで出そう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save @angular/material
$ npm install --save hammerjs # gesture用
$ npm install --save @angular/animations
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Moduleで&lt;code&gt;import &#39;hammerjs&#39;;&lt;/code&gt;して、以下のModuleをimportに加える。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BrowserAnimationsModule&lt;/code&gt;(&lt;code&gt;from &#39;@angular/platform-browser/animations&#39;&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MdButtonModule&lt;/code&gt;など使うもの(&lt;code&gt;from &#39;@angular/material&#39;&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;スタイルとアイコン(md-icon)を追加。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;link href=&amp;quot;../node_modules/@angular/material/prebuilt-themes/indigo-pink.css&amp;quot; rel=&amp;quot;stylesheet&amp;quot;&amp;gt;
&amp;lt;link href=&amp;quot;https://fonts.googleapis.com/icon?family=Material+Icons&amp;quot; rel=&amp;quot;stylesheet&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;フォームを作る-https-angular-io-docs-ts-latest-guide-forms-html&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/forms.html&#34;&gt;フォームを作る&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;とりあえずコンポーネントを作成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g component TodoForm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Formの値をバインドするためのクラスを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export class TodoForm {
  constructor(
    public id: number,
    public title: string,
    public active: boolean,
    public priority?: number,
  ) {  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずは&lt;a href=&#34;https://material.angular.io/components&#34;&gt;material2の&lt;/a&gt;mdInput, mdSelect, mdButtonでフォームを作る。
&lt;code&gt;#todoForm&lt;/code&gt;のように頭についている#は
&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/template-syntax.html#!#ref-vars&#34;&gt;reference variable&lt;/a&gt;で、
titleはrequiredとしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&amp;quot;root&amp;quot;&amp;gt;
  &amp;lt;form (ngSubmit)=&amp;quot;onSubmit()&amp;quot; #todoForm=&amp;quot;ngForm&amp;quot;&amp;gt;

    &amp;lt;div *ngIf=&amp;quot;model.id !== 0&amp;quot; class=&amp;quot;form-item&amp;quot;&amp;gt;
      ID: {{model.id}}
    &amp;lt;/div&amp;gt;

    &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
      &amp;lt;md-input-container&amp;gt;
        &amp;lt;input mdInput name=&amp;quot;title&amp;quot; required placeholder=&amp;quot;やること&amp;quot; 
          [(ngModel)]=&amp;quot;model.title&amp;quot;&amp;gt;
      &amp;lt;/md-input-container&amp;gt;
    &amp;lt;/div&amp;gt;
    
    &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
      &amp;lt;md-select placeholder=&amp;quot;優先度&amp;quot; name=&amp;quot;priority&amp;quot; 
        [(ngModel)]=&amp;quot;model.priority&amp;quot;&amp;gt;
        &amp;lt;md-option [value]=&amp;quot;1&amp;quot;&amp;gt;高&amp;lt;/md-option&amp;gt;
        &amp;lt;md-option [value]=&amp;quot;2&amp;quot;&amp;gt;中&amp;lt;/md-option&amp;gt;
        &amp;lt;md-option [value]=&amp;quot;3&amp;quot;&amp;gt;低&amp;lt;/md-option&amp;gt;        
      &amp;lt;/md-select&amp;gt;
    &amp;lt;/div&amp;gt;

    &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
      &amp;lt;md-slide-toggle name=&amp;quot;active&amp;quot; [(ngModel)]=&amp;quot;model.active&amp;quot;&amp;gt;
        有効にする
      &amp;lt;/md-slide-toggle&amp;gt;
    &amp;lt;/div&amp;gt;

    &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
      &amp;lt;button type=&amp;quot;submit&amp;quot; md-raised-button [disabled]=&amp;quot;!todoForm.form.valid&amp;quot;&amp;gt;
        Submit
      &amp;lt;/button&amp;gt;
    &amp;lt;/div&amp;gt;
    
  &amp;lt;/form&amp;gt;
&amp;lt;/div&amp;gt;

&amp;lt;table&amp;gt;
  &amp;lt;thead&amp;gt;
    &amp;lt;tr&amp;gt;
      &amp;lt;th&amp;gt;ID&amp;lt;/th&amp;gt;
      &amp;lt;th&amp;gt;Title&amp;lt;/th&amp;gt;
      &amp;lt;th&amp;gt;Active&amp;lt;/th&amp;gt;
      &amp;lt;th&amp;gt;Priority&amp;lt;/th&amp;gt;
  &amp;lt;/thead&amp;gt;
  &amp;lt;tbody&amp;gt;
    &amp;lt;tr li *ngFor=&amp;quot;let todo of todos&amp;quot;&amp;gt;
      &amp;lt;td&amp;gt;{{todo.id}}&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;{{todo.title}}&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;{{todo.active}}&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;{{todo.priority}}&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;&amp;lt;button md-button (click)=&amp;quot;onEdit(todo.id)&amp;quot;&amp;gt;編集&amp;lt;/button&amp;gt;&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
  &amp;lt;/tbody&amp;gt;
&amp;lt;/table&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンポーネントはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Component({
  selector: &#39;app-todo-form&#39;,
  templateUrl: &#39;./todo-form.component.html&#39;,
  styleUrls: [&#39;./todo-form.component.css&#39;]
})
export class TodoFormComponent implements OnInit {

  constructor() { }

  todos: TodoForm[] = [];
  model = new TodoForm(0, &amp;quot;&amp;quot;, false);

  ngOnInit() {
  }

  onSubmit() {
    if(this.model.id === 0) {
      this.model.id = this.todos.length + 1;
      this.todos.push(this.model);
    }else{
      this.todos[this.model.id - 1] = this.model;
    }
    this.model = new TodoForm(0, &amp;quot;&amp;quot;, false);
  }

  onEdit(id: number) {
    this.model = Object.assign({}, this.todos[id - 1]);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;autocomplete-https-material-angular-io-components-component-autocomplete&#34;&gt;&lt;a href=&#34;https://material.angular.io/components/component/autocomplete&#34;&gt;AutoComplete&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;次に人を登録するためのtextフォームを作る。これは前もって登録されている人の中からAutoCompleteさせる。&lt;/p&gt;

&lt;p&gt;mdAutocompleteに候補を渡してmdInputのmdAutoCompleteにmdAutoCompleteの参照を渡す。
&lt;a href=&#34;https://angular.io/docs/ts/latest/api/forms/index/FormControl-class.html&#34;&gt;FormControl&lt;/a&gt;を扱うためには&lt;code&gt;@angular/forms&lt;/code&gt;の&lt;code&gt;ReactiveFormsModule&lt;/code&gt;をimportする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
    &amp;lt;md-input-container&amp;gt;
      &amp;lt;input mdInput name=&amp;quot;assignee&amp;quot; required placeholder=&amp;quot;やるひと&amp;quot; 
        [(ngModel)]=&amp;quot;model.assignee&amp;quot;
        [mdAutocomplete]=&amp;quot;autoAssignee&amp;quot;
        [formControl]=&amp;quot;assigneeFormControl&amp;quot;
      &amp;gt;
    &amp;lt;/md-input-container&amp;gt;

    &amp;lt;md-autocomplete #autoAssignee=&amp;quot;mdAutocomplete&amp;quot; [displayWith]=&amp;quot;displayAssignee&amp;quot;&amp;gt;
      &amp;lt;md-option *ngFor=&amp;quot;let p of filteredAssignee | async&amp;quot; [value]=&amp;quot;p&amp;quot;&amp;gt;
          {{ p.name }}
      &amp;lt;/md-option&amp;gt;
    &amp;lt;/md-autocomplete&amp;gt;
  &amp;lt;/div&amp;gt;
  
  &amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
    &amp;lt;md-select placeholder=&amp;quot;優先度&amp;quot; name=&amp;quot;priority&amp;quot; 
      [(ngModel)]=&amp;quot;model.priority&amp;quot;&amp;gt;
      &amp;lt;md-option [value]=&amp;quot;1&amp;quot;&amp;gt;高&amp;lt;/md-option&amp;gt;
      &amp;lt;md-option [value]=&amp;quot;2&amp;quot;&amp;gt;中&amp;lt;/md-option&amp;gt;
      &amp;lt;md-option [value]=&amp;quot;3&amp;quot;&amp;gt;低&amp;lt;/md-option&amp;gt;        
    &amp;lt;/md-select&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;people: Person[] = [
  {id: 1, name: &amp;quot;taro&amp;quot;},
  {id: 2, name: &amp;quot;jiro&amp;quot;},
  {id: 3, name: &amp;quot;ichiro&amp;quot;}
];
assigneeFormControl = new FormControl();
filteredAssignee: Observable&amp;lt;Person[]&amp;gt;;

ngOnInit() {
  this.filteredAssignee = this.assigneeFormControl.valueChanges
        .startWith(null)
        .map(val =&amp;gt; val ? this.assigneeFilter(val) : this.people.slice());

  this.assigneeFormControl.asyncValidator
}

assigneeFilter(val: string): Person[] {
  return this.people.filter(p =&amp;gt; new RegExp(`^${val}`, &#39;gi&#39;).test(p.name)); 
}

displayAssignee(person: Person): string {
  return person ? person.name : &#39;&#39;;
}

export class TodoForm {
  constructor(
    public id: number,
    public title: string,
    public active: boolean,
    public priority?: number,
    public assignee?: Person,
  ) {  }
}

interface Person { id: number, name: string };
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;datepicker&#34;&gt;DatePicker&lt;/h2&gt;

&lt;p&gt;最後に目標日を設定するためにDatePickerを用意する。
上にも書いた通り、material2にはまだDatepickerがないので他のライブラリで代用する。
今回はAngular v4に対応していて見た目がシンプルな&lt;a href=&#34;https://github.com/koleary94/Angular-2-Datepicker&#34;&gt;koleary94/Angular-2-Datepicker&lt;/a&gt;を使った。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save angular2-material-datepicker
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&amp;quot;form-item&amp;quot;&amp;gt;
  &amp;lt;material-datepicker placeholder=&amp;quot;終了予定日&amp;quot; [(date)]=&amp;quot;model.deadline&amp;quot;&amp;gt;&amp;lt;/material-datepicker&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CSSのdisplayとposition</title>
          <link>https://www.sambaiz.net/article/98/</link>
          <pubDate>Sat, 06 May 2017 14:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/98/</guid>
          <description>

&lt;h2 id=&#34;display-https-developer-mozilla-org-ja-docs-web-css-display&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/display&#34;&gt;display&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;レンダリングに使うボックスを指定する。&lt;/p&gt;

&lt;h3 id=&#34;outer-display-type&#34;&gt;outer display type&lt;/h3&gt;

&lt;p&gt;pのようなブロックレベル要素やspanのようなインラインレベル要素に関わらず、指定したボックスにレンダリングする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99.png&#34; alt=&#34;outer display type&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:none&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;none&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt;

&amp;lt;div&amp;gt;this is &amp;lt;p style=&amp;quot;display:inline&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline&amp;lt;/p&amp;gt; desu&amp;lt;/div&amp;gt;

&amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt;

&amp;lt;div&amp;gt;this is &amp;lt;span style=&amp;quot;display:inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block&amp;lt;/span&amp;gt; desu&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;中央寄せ&#34;&gt;中央寄せ&lt;/h3&gt;

&lt;p&gt;中央寄せはblockにwidthを設定して&lt;code&gt;margin auto&lt;/code&gt;するか、
親要素で&lt;code&gt;text-align: center&lt;/code&gt;してinline(-block)にする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-center.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  background-color: #22ee22;
  height: 80px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div style=&amp;quot;margin: 5 auto&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block margin&amp;lt;/div&amp;gt;

&amp;lt;div style=&amp;quot;margin: 5 auto; width: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block margin width&amp;lt;/div&amp;gt;

&amp;lt;div style=&amp;quot;margin: 5 auto; display: inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block margin&amp;lt;/div&amp;gt;

&amp;lt;div style=&amp;quot;text-align: center&amp;quot;&amp;gt;
  
  &amp;lt;div style=&amp;quot;display: inline-block&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;inline-block align-center&amp;lt;/div&amp;gt;
  
  &amp;lt;div style=&amp;quot;width: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;block align-center width&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;flex-https-developer-mozilla-org-ja-docs-web-css-css-flexible-box-layout-using-css-flexible-boxes&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/CSS_Flexible_Box_Layout/Using_CSS_flexible_boxes&#34;&gt;flex&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;displayでflexを指定するとflex containerになる。
&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-flow&#34;&gt;flex-flow&lt;/a&gt;は
表示する方向の&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-direction&#34;&gt;flex-direction&lt;/a&gt;と
折り返しの&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-wrap&#34;&gt;flex-wrap&lt;/a&gt;のショートハンドプロパティ。&lt;/p&gt;

&lt;p&gt;子要素の&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex&#34;&gt;flex&lt;/a&gt;は
伸びるときの倍率の&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-grow&#34;&gt;flex-grow&lt;/a&gt;(default: 0)と
縮むときの倍率の&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-shrink&#34;&gt;flex-shrink&lt;/a&gt;(default: 1)、
初期サイズの&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/flex-basis&#34;&gt;flex-basis&lt;/a&gt;(default: auto)の
ショートハンドプロパティ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-flex.png&#34; alt=&#34;flex&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div&amp;gt;
  this is
  &amp;lt;div style=&amp;quot;display:flex; flex-flow: row wrap&amp;quot;&amp;gt;
    &amp;lt;div style=&amp;quot;flex: auto; margin: 2px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;flex-item1&amp;lt;/div&amp;gt;

    &amp;lt;!-- flex-basis --&amp;gt;
    &amp;lt;div style=&amp;quot;flex: 300px; margin: 2px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;flex-item2&amp;lt;/div&amp;gt;

    &amp;lt;!-- flex-grow | flex-shrink | flex-basis --&amp;gt;
    &amp;lt;div style=&amp;quot;flex: 0 1 30%; margin: 2px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;flex-item3&amp;lt;/div&amp;gt;
  &amp;lt;/div&amp;gt;
  desu
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;position-https-developer-mozilla-org-ja-docs-web-css-position&#34;&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/position&#34;&gt;position&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;relative&#34;&gt;relative&lt;/h3&gt;

&lt;p&gt;この設定を考慮せずにすべての要素を配置した後に設定を適用する。
そのため、この例の3つ目のdivの&lt;code&gt;left: 30px&lt;/code&gt;は2つ目のdivの元々の位置から30px右になっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-relative.png&#34; alt=&#34;relative&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  display: inline-block;
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div&amp;gt;
  &amp;lt;div class=&amp;quot;bg&amp;quot;&amp;gt;aaa&amp;lt;/div&amp;gt;
  &amp;lt;div style=&amp;quot;position: relative; top: 30px; left: 30px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;bbb&amp;lt;/div&amp;gt;
  &amp;lt;div style=&amp;quot;position: relative; left: 30px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;ccc&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;absolute&#34;&gt;absolute&lt;/h3&gt;

&lt;p&gt;絶対位置で指定する。位置指定された祖先要素の相対的な位置になる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-absolute.png&#34; alt=&#34;absolute&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  display: inline-block;
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div&amp;gt;
  &amp;lt;div class=&amp;quot;bg&amp;quot;&amp;gt;aaa&amp;lt;/div&amp;gt;
  &amp;lt;div style=&amp;quot;position: relative; top: 50px&amp;quot;&amp;gt;
    &amp;lt;div style=&amp;quot;background-color: #eeeeee&amp;quot;&amp;gt;relative top 50px&amp;lt;/div&amp;gt;
    &amp;lt;div style=&amp;quot;position: absolute; top: 50px; left: 300px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;top 50px; left: 300px&amp;lt;/div&amp;gt;
    &amp;lt;div style=&amp;quot;position: absolute; left: 100px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;left 100px&amp;lt;/div&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;fixed&#34;&gt;fixed&lt;/h3&gt;

&lt;p&gt;ビューポートに対して絶対的な位置を指定する。この例では2つ目のfixedなdivはスクロールしてもビューポートに対して位置が固定される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/99-fixed.png&#34; alt=&#34;fixed&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.bg {
  display: inline-block;
  background-color: #22ee22;
  width: 150px;
  height: 50px;
}
&amp;lt;/style&amp;gt;

&amp;lt;div style=&amp;quot;height: 3000px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;aaa&amp;lt;/div&amp;gt;
&amp;lt;div style=&amp;quot;position: fixed; top: 50px; left: 300px&amp;quot; class=&amp;quot;bg&amp;quot;&amp;gt;top 50px; left: 300px&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AngularのRouter</title>
          <link>https://www.sambaiz.net/article/97/</link>
          <pubDate>Sun, 30 Apr 2017 22:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/97/</guid>
          <description>

&lt;pre&gt;&lt;code&gt;@angular/core&amp;quot;: 4.1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/40/&#34;&gt;Angular2とangular-cliでTODOを作る - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;angular-cli&lt;/code&gt;は&lt;code&gt;@angular/cli&lt;/code&gt;に&lt;a href=&#34;https://github.com/angular/angular-cli/commit/601f9b38f8ce53052d623a4b8a2dc5bb30f9eee1&#34;&gt;変更された&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;routingを行うのでnewで&lt;code&gt;--routing&lt;/code&gt;オプションを付けている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g @angular/cli
$ ng -v
@angular/cli: 1.0.1

$ ng new angular4-routing --routing
$ cd angular4-routing/
$ cat package.json | grep @angular/core
    &amp;quot;@angular/core&amp;quot;: &amp;quot;^4.0.0&amp;quot;,

$ ng serve
** NG Live Development Server is running on http://localhost:4200 **     
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--routing&lt;/code&gt;を付けたので&lt;code&gt;app-routing.module.ts&lt;/code&gt;が作成され、&lt;code&gt;app.module.ts&lt;/code&gt;にAppRoutingModuleが追加される。
&lt;code&gt;index.html&lt;/code&gt;のheadにはpushStateのroutingが働くように
&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base&#34;&gt;base&lt;/a&gt;要素が
&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#base-href&#34;&gt;追加されている&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { NgModule } from &#39;@angular/core&#39;;
import { Routes, RouterModule } from &#39;@angular/router&#39;;

const routes: Routes = [
  {
    path: &#39;&#39;,
    children: []
  }
];

@NgModule({
  imports: [RouterModule.forRoot(routes)],
  exports: [RouterModule]
})
export class AppRoutingModule { }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、&lt;code&gt;app.component.html&lt;/code&gt;に&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#router-outlet&#34;&gt;router-outlet&lt;/a&gt;が置かれていてroutingによるComponentはこの下に描画される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;h1&amp;gt;
  {{title}}
&amp;lt;/h1&amp;gt;
&amp;lt;router-outlet&amp;gt;&amp;lt;/router-outlet&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;動的に追加されるコンポーネントのstyleは&lt;code&gt;@HostBinding&lt;/code&gt;で設定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export class TodoMainComponent implements OnInit {

  @HostBinding(&#39;style.width&#39;)   width = &#39;100%&#39;;

  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ルーティング定義-https-angular-io-docs-ts-latest-guide-router-html-route-config&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#route-config&#34;&gt;ルーティング定義&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;children&lt;/code&gt;で&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#child-routing-component&#34;&gt;child route&lt;/a&gt;を設定しているが、
これは親コンポーネントの&lt;code&gt;router-outlet&lt;/code&gt;の下に描画される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g component todo/todo-main
$ ng g component todo/todo-list
$ ng g component todo/todo-item
$ ng g component not-found
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import { NgModule } from &#39;@angular/core&#39;;
import { Routes, RouterModule } from &#39;@angular/router&#39;;

import { TodoMainComponent } from &#39;./todo/todo-main/todo-main.component&#39;
import { TodoListComponent } from &#39;./todo/todo-list/todo-list.component&#39;
import { TodoItemComponent } from &#39;./todo/todo-item/todo-item.component&#39;
import { NotFoundComponent } from &#39;./not-found/not-found.component&#39;

const routes: Routes = [
  {
    path: &#39;todo&#39;,
    component: TodoMainComponent,
    children: [
          {
            path: &#39;:id&#39;,
            component: TodoItemComponent
          },
          {
            path: &#39;&#39;,
            component: TodoListComponent
          }
    ]
  },
  {
    path: &#39;**&#39;,
    component: NotFoundComponent,
  }
];

@NgModule({
  imports: [RouterModule.forRoot(routes)],
  exports: [RouterModule]
})
export class AppRoutingModule { }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;
  todo-main works!
&amp;lt;/p&amp;gt;
&amp;lt;router-outlet&amp;gt;&amp;lt;/router-outlet&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで &lt;a href=&#34;http://localhost:4200/todo&#34;&gt;http://localhost:4200/todo&lt;/a&gt; にアクセスすると、&lt;code&gt;TodoMainComponent&lt;/code&gt;と&lt;code&gt;TodoListComponent&lt;/code&gt;が表示される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app works!

todo-main works!

todo-list works!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;パラメータの取得-https-angular-io-docs-ts-latest-guide-router-html-route-parameters-activated-route&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#route-parameters-activated-route&#34;&gt;パラメータの取得&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;ActivatedRoute&lt;/code&gt;をDIしてObservableなparamsをSubscribeする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component, OnInit, HostBinding } from &#39;@angular/core&#39;;
import { Router, ActivatedRoute, Params } from &#39;@angular/router&#39;;

@Component({
  selector: &#39;app-todo-item&#39;,
  templateUrl: &#39;./todo-item.component.html&#39;,
  styleUrls: [&#39;./todo-item.component.css&#39;]
})
export class TodoItemComponent implements OnInit {

  id: number;

  constructor(
    private route: ActivatedRoute,
  ) { }

  ngOnInit() {  
    this.route.params.subscribe(
      (params: Params) =&amp;gt; this.id = +params[&#39;id&#39;]
    );
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;
  todo-item ({{id}}) works!
&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;遷移&#34;&gt;遷移&lt;/h2&gt;

&lt;p&gt;タグなら&lt;code&gt;&amp;lt;a routerLink&amp;gt;&lt;/code&gt;を、コードなら&lt;code&gt;Router.navigate&lt;/code&gt;を使って遷移できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;
  todo-item ({{id}}) works!
  &amp;lt;button (click)=&amp;quot;onClickNext()&amp;quot;&amp;gt;Next&amp;lt;/button&amp;gt;
  &amp;lt;a routerLink=&amp;quot;/todo&amp;quot;&amp;gt;todos&amp;lt;/a&amp;gt;
&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
export class TodoItemComponent implements OnInit {

  constructor(
    private route: ActivatedRoute,
    private router: Router
  ) { }

  ...

  onClickNext() {
    if(typeof this.id !== &#39;undefined&#39;){
      this.router.navigate([`/todo/${this.id+1}`, {hoge: &amp;quot;fuga&amp;quot;}]);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;navigateでhogeという適当なパラメータを付けているが、呼ぶと&lt;code&gt;http://localhost:4200/todo/10;hoge=fuga&lt;/code&gt;のように
クエリパラメータが&lt;code&gt;?, &amp;amp;&lt;/code&gt;ではなく&lt;code&gt;;&lt;/code&gt;で区切られたURLに遷移する。
これをmatrix URL notationといって、&lt;a href=&#34;https://www.w3.org/DesignIssues/MatrixURIs.html&#34;&gt;結構由緒正しい&lt;/a&gt;ものらしい。&lt;/p&gt;

&lt;h2 id=&#34;guard-https-angular-io-docs-ts-latest-guide-router-html-guards&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#guards&#34;&gt;Guard&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;routeの遷移時に何かするためのもの。
具体的にはログインしているかどうかをチェックしたりとか、
遷移する前にデータを一時保存したりとかそういうのに使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g guard auth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/api/router/index/CanActivate-interface.html&#34;&gt;canActivate()&lt;/a&gt;
はrouteに遷移するときに呼ばれ、trueを返すとそのまま続行され、falseを返すと中断される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Injectable } from &#39;@angular/core&#39;;
import { CanActivate, ActivatedRouteSnapshot, RouterStateSnapshot } from &#39;@angular/router&#39;;
import { Observable } from &#39;rxjs/Observable&#39;;

@Injectable()
export class AuthGuard implements CanActivate {
  canActivate(
    next: ActivatedRouteSnapshot,
    state: RouterStateSnapshot): Observable&amp;lt;boolean&amp;gt; | Promise&amp;lt;boolean&amp;gt; | boolean {
    console.log(`canActivate(): ${state.url}`);
    return true;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;AppModuleのprovidersにAuthGuardを入れて、routesにも&lt;code&gt;canActivate&lt;/code&gt;としてAuthGuardを設定すると呼ばれるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { AuthGuard } from &#39;./auth.guard&#39;

const routes: Routes = [
  {
    path: &#39;todo&#39;,
    component: TodoMainComponent,
    canActivate: [AuthGuard],
    children: [
          {
            path: &#39;:id&#39;,
            component: TodoItemComponent
          },
          {
            path: &#39;&#39;,
            component: TodoListComponent
          }
    ]
  },
  {
    path: &#39;**&#39;,
    component: NotFoundComponent,
  }
];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この設定だと上で追加したNextボタンを押してchild routeに遷移したときには呼ばれない。
&lt;code&gt;canActivateChild()&lt;/code&gt;にするとchild routeに遷移したときにも呼ばれるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;canActivateChild(route: ActivatedRouteSnapshot, state: RouterStateSnapshot): Observable&amp;lt;boolean&amp;gt; | Promise&amp;lt;boolean&amp;gt; | boolean {
  return this.canActivate(route, state);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
    path: &#39;todo&#39;,
    component: TodoMainComponent,
    canActivateChild: [AuthGuard],
    children: [
          {
            path: &#39;:id&#39;,
            component: TodoItemComponent
          },
          {
            path: &#39;&#39;,
            component: TodoListComponent
          }
    ]
} 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらの他には&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/api/router/index/CanDeactivate-interface.html&#34;&gt;canDeactivate()&lt;/a&gt;: 今のrouteから離れるとき&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/api/router/index/Resolve-interface.html&#34;&gt;resolve()&lt;/a&gt;: コンポーネントを表示する前。pre-fetchのため。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/api/router/index/CanLoad-interface.html&#34;&gt;canLoad()&lt;/a&gt;: &lt;code&gt;loadChildren&lt;/code&gt;で指定したModuleを&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#lazy-loading-route-config&#34;&gt;lazy load&lt;/a&gt;
するとき。ドキュメントではAdminModuleに対して、認証されていなかったらロードしないようにしている。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;のGuardがある。&lt;/p&gt;

&lt;h2 id=&#34;アニメーション-https-angular-io-docs-ts-latest-guide-router-html-route-animation&#34;&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/router.html#!#route-animation&#34;&gt;アニメーション&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;app.module.ts&lt;/code&gt;に&lt;code&gt;BrowserAnimationsModule&lt;/code&gt;を追加。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save @angular/animations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import { BrowserAnimationsModule } from &#39;@angular/platform-browser/animations&#39;;

@NgModule({
  ...
  imports: [
    ...
    BrowserAnimationsModule
  ],
  ...
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;animations.ts&lt;/code&gt;を作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { animate, AnimationEntryMetadata, state, style, transition, trigger } from &#39;@angular/core&#39;;

// Component transition animations
export const slideInDownAnimation: AnimationEntryMetadata =
  trigger(&#39;routeAnimation&#39;, [
    state(&#39;*&#39;,
      style({
        opacity: 1,
        transform: &#39;translateX(0)&#39;
      })
    ),
    transition(&#39;:enter&#39;, [
      style({
        opacity: 0,
        transform: &#39;translateX(-100%)&#39;
      }),
      animate(&#39;0.2s ease-in&#39;)
    ]),
    transition(&#39;:leave&#39;, [
      animate(&#39;0.5s ease-out&#39;, style({
        opacity: 0,
        transform: &#39;translateY(100%)&#39;
      }))
    ])
  ]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを@Componentのanimationsに入れて&lt;code&gt;@HostBinding&lt;/code&gt;でanimationのトリガー(routeAnimation)を発火させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component, OnInit, HostBinding } from &#39;@angular/core&#39;;
import { Router, ActivatedRoute, Params } from &#39;@angular/router&#39;;
import { slideInDownAnimation } from &#39;../../animations&#39;;

@Component({
  selector: &#39;app-todo-item&#39;,
  templateUrl: &#39;./todo-item.component.html&#39;,
  styleUrls: [&#39;./todo-item.component.css&#39;],
  animations: [ slideInDownAnimation ]
})
export class TodoItemComponent implements OnInit {

  @HostBinding(&#39;@routeAnimation&#39;) routeAnimation = true;
  @HostBinding(&#39;style.display&#39;)   display = &#39;block&#39;;
  @HostBinding(&#39;style.position&#39;)  position = &#39;absolute&#39;;

  id: number;

  constructor(
    private route: ActivatedRoute,
    private router: Router
  ) { }

  ngOnInit() {  
    this.route.params.subscribe(
      (params: Params) =&amp;gt; this.id = +params[&#39;id&#39;]
    );
  }

  onClickNext() {
    this.router.navigate([&#39;/todo&#39;, {id: this.id + 1, hoge: &amp;quot;fuga&amp;quot;}])
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じにアニメーションする。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/97.gif&#34; alt=&#34;アニメーション&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsのStream API</title>
          <link>https://www.sambaiz.net/article/96/</link>
          <pubDate>Sat, 22 Apr 2017 19:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/96/</guid>
          <description>

&lt;h2 id=&#34;stream-apiとは-https-nodejs-org-docs-v7-9-0-api-stream-html&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html&#34;&gt;Stream APIとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;NodeでStreamデータを扱うためのもの。
例えばサイズが大きいファイルの入出力をStreamとして扱うことでバッファを最小限にできる。&lt;/p&gt;

&lt;p&gt;Streamは&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/events.html&#34;&gt;EventEmitter&lt;/a&gt;で、
Readable streamやWritable stream、ReadableとWritableを合わせたDuplex streamと
Readしたものを加工してWriteするTransform streamの種類があり、
それぞれ特定の関数が&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_api_for_stream_implementers&#34;&gt;実装&lt;/a&gt;されている必要がある。&lt;/p&gt;

&lt;h2 id=&#34;readable-stream-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-readable-streams&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_readable_streams&#34;&gt;Readable stream&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Readable streamには&lt;code&gt;flowing&lt;/code&gt;と&lt;code&gt;paused&lt;/code&gt;の
&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_two_modes&#34;&gt;二つのモード&lt;/a&gt;がある。
最初は&lt;code&gt;paused&lt;/code&gt;モードで、readableになってからread()することで読むことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;sample.txt&#39;);
var i = 0;
readable.on(&#39;readable&#39;, () =&amp;gt; {
  let chunk;
  while (null !== (chunk = readable.read(10))) {
    console.log(`${i++}: ${chunk}`);
  }
});
dable.on(&#39;end&#39;, () =&amp;gt; {
  console.log(&#39;end&#39;);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat sample.txt
abcdefghijklmnopqrstuvwxyz
1234567890
あいうえお

$ node main.js
0: abcdefghij
1: klmnopqrst
2: uvwxyz
123
3: 4567890
あい
4: うえお

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;dataのイベントハンドラーを追加するか、後で書くpipeを使うと&lt;code&gt;flowing&lt;/code&gt;モードになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;sample.txt&#39;);
var i = 0;
readable.on(&#39;data&#39;, (chunk) =&amp;gt; {
  console.log(`${i++}: ${chunk}`);
});
readable.on(&#39;end&#39;, () =&amp;gt; {
  console.log(&#39;end&#39;);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0: abcdefghijklmnopqrstuvwxyz
1234567890
あいうえお

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーハンドリングはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;error.txt&#39;);
readable.on(&#39;data&#39;, (chunk) =&amp;gt; {
  console.log(`${i++}: ${chunk}`);
});
readable.on(&#39;error&#39;, (error) =&amp;gt; {
  console.log(error);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ node main.js
{ Error: ENOENT: no such file or directory, open &#39;error.txt&#39;
    at Error (native) errno: -2, code: &#39;ENOENT&#39;, syscall: &#39;open&#39;, path: &#39;error.txt&#39; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;実装-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-implementing-a-readable-stream&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_implementing_a_readable_stream&#34;&gt;実装&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;実装する関数は&lt;code&gt;_read&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const Readable = require(&#39;stream&#39;).Readable;

class Random extends Readable {
  constructor(opt) {
    super(opt); 
  }
  
  _read() {
    
    // error handling
    // if(err){ 
    //   this.emit(&#39;error&#39;, err)
    //   return
    // }
    
    this.push(Math.random()+&#39;&#39;);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;writable-stream-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-class-stream-writable&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_class_stream_writable&#34;&gt;Writable stream&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;output.txtに出力するWritable stream。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let writable = fs.createWriteStream(&#39;output.txt&#39;)

writable.write(&#39;hoge\n&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat output.txt
hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入力の流量が多く、Writable streamのバッファが&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_constructor_new_stream_writable_options&#34;&gt;highWaterMark&lt;/a&gt;を超えてしまうと、write()はfalseを返す。そのまま書き込み続けるとメモリを食いつぶしてしまうので、
全てのバッファが捌けて&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_event_drain&#34;&gt;drain&lt;/a&gt;イベントが発行されるまで書き込みを止めてback-pressureとする必要がある。
ただし、pipeを使う場合このあたりはやってくれるので、あまり気にすることはない。&lt;/p&gt;

&lt;h3 id=&#34;実装-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-implementing-a-writable-stream&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_implementing_a_writable_stream&#34;&gt;実装&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;実装する関数は&lt;code&gt;_write&lt;/code&gt;と、バッファされているchunkをまとめて扱うなら&lt;code&gt;_writev&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const Writable = require(&#39;stream&#39;).Writable;

class DummyWritable extends Writable {
  constructor(opt) {
    super(opt);
  }

  _write(chunk, encoding, callback) {
    const chunkStr = chunk.toString()
    if (chunkStr == &#39;this is error&#39;) {
      callback(new Error(&#39;chunk is invalid&#39;));
    } else {
      console.log(chunkStr);
      callback();
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pipe-https-nodejs-org-docs-v7-9-0-api-stream-html-stream-readable-pipe-destination-options&#34;&gt;&lt;a href=&#34;https://nodejs.org/docs/v7.9.0/api/stream.html#stream_readable_pipe_destination_options&#34;&gt;pipe&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Readable streamをWritable streamとつなげる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;sample.txt&#39;);
let writable = fs.createWriteStream(&#39;output.txt&#39;);
readable.pipe(writable);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ cat output.txt
abcdefghijklmnopqrstuvwxyz
1234567890
あいうえお
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意すべきなのは、pipeしたものをまとめてエラーハンドリングすることはできないこと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;error.txt&#39;);
let writable = fs.createWriteStream(&#39;output.txt&#39;);
let piped = readable.pipe(writable);

piped.on(&#39;error&#39;, (error) =&amp;gt; {
  console.log(error);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;events.js:160
      throw er; // Unhandled &#39;error&#39; event
      ^

Error: ENOENT: no such file or directory, open &#39;error.txt&#39;
    at Error (native)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;面倒だけど、毎度エラーハンドリングする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
let readable = fs.createReadStream(&#39;error.txt&#39;);
let writable = fs.createWriteStream(&#39;output.txt&#39;);
const errorHandling = (err) =&amp;gt; { console.log(err) }
let piped = readable.on(&#39;error&#39;, errorHandling).pipe(writable);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pipeを組み合わせると、こんな風にcsvをfetchして加工し、文字コードを変えて出力するといったこともStreamでできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fetch = require(&#39;node-fetch&#39;);
const Iconv = require(&#39;iconv&#39;).Iconv;
const iconv = new Iconv(&#39;UTF-8&#39;, &#39;SHIFT_JIS//IGNORE&#39;);
const csv = require(&#39;csv&#39;);
const fs = require(&#39;fs&#39;);

const errorHandling = (err) =&amp;gt; { console.log(err); };

const outputFile = fs.createWriteStream(&#39;output.csv&#39;);

fetch(&#39;http://example.com/test.csv&#39;).then((res) =&amp;gt; {

  res.body
  .pipe(csv.parse({columns : true}))
  .on(&#39;error&#39;, errorHandling)
  .pipe(csv.transform(function(record){
    if(record[&#39;hoge&#39;] &amp;lt; 100000){
      return null;
    }
    return record;
  }))
  .on(&#39;error&#39;, errorHandling)
  .pipe(csv.stringify({header: true}))
  .on(&#39;error&#39;, errorHandling)
  .pipe(iconv)
  .on(&#39;error&#39;, errorHandling)
  .pipe(outputFile)
  .on(&#39;error&#39;, errorHandling);

}).then(() =&amp;gt; console.log(&amp;quot;done&amp;quot;)).catch((err) =&amp;gt; console.log(err));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pipeではないけど、readlineのcreateInterfaceに入力と出力のStreamを渡すと、
行ごとに処理することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
const readline = require(&#39;readline&#39;);

let readable = fs.createReadStream(&#39;sample.txt&#39;);
const rl = readline.createInterface({
  input: readable,
  output: process.stdout
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;abcdefghijklmnopqrstuvwxyz
1234567890
あいうえお
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rxjsで扱う&#34;&gt;RxJSで扱う&lt;/h2&gt;

&lt;p&gt;StreamはEventEmitterなのでRxJSのfromEvent()でObservableとして扱うこともできる。ただし&lt;a href=&#34;https://github.com/ReactiveX/rxjs&#34;&gt;v5&lt;/a&gt;にはpipeがない(v4には&lt;a href=&#34;https://github.com/Reactive-Extensions/RxJS/blob/8fa95ac884181fb6cbff8ce7c1d669ffb190f5e4/src/core/linq/observable/pipe.js#L6&#34;&gt;ある&lt;/a&gt;)ので、pipeする場合は自分でSubscribeしてwriteする必要がありそう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/85/&#34;&gt;RxJSでRxをはじめる - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const fs = require(&#39;fs&#39;);
const Rx = require(&#39;rxjs/Rx&#39;);
const writable = fs.createWriteStream(&#39;output.txt&#39;)

Rx.Observable.fromEvent(process.stdin, &#39;data&#39;)
.map((v) =&amp;gt; `- ${v}`)
.subscribe((v) =&amp;gt; write(v));

function write(v){
  // TODO: back-pressure
  writable.write(v);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ node main.js 
aiueo
kakikukeko
^C

$ cat output.txt 
- aiueo
- kakikukeko
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>tmuxのメモ</title>
          <link>https://www.sambaiz.net/article/95/</link>
          <pubDate>Fri, 21 Apr 2017 00:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/95/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://tmux.github.io/&#34;&gt;https://tmux.github.io/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;セッションを立ち上げてその中で複数のウィンドウやペインからコマンドを実行できるやつ。
サーバーでの作業中にネットワークが切断されてしまってもセッションをattachすることで再開することができる。
ローカル環境でもコマンドキーでのウィンドウ作成やペインの分割、
複数のサーバーにsshで入って調査するようなときにペインの同時入力は便利。
もちろんターミナルを閉じてしまっても再開できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install tmux
$ tmux
$ tmux ls
$ tmux a # sessionをattachする
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bind key(デフォルトで&lt;code&gt;Ctrl + b&lt;/code&gt;)を入れてからコマンドキーを入れる。よく使うもの。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;c: 新しいウインドウをCreateする&lt;/li&gt;
&lt;li&gt;d: 今のクライアントをDetachする&lt;/li&gt;
&lt;li&gt;n: Nextウィンドウに移動する&lt;/li&gt;
&lt;li&gt;p: Previousウィンドウに戻る&lt;/li&gt;
&lt;li&gt;w: Windowを一覧表示して選択する&lt;/li&gt;
&lt;li&gt;x: ペインを削除する&lt;/li&gt;
&lt;li&gt;,: ウィンドウの名前を変更する&lt;/li&gt;
&lt;li&gt;z: ウィンドウ一杯にペインをzoomする/解除&lt;/li&gt;
&lt;li&gt;[: ペイン内をスクロールできるようになる。qで解除&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;~/.tmux.conf&lt;/code&gt;はこんな感じにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# bind keyをC-tに変更してC-bを解除
set -g prefix C-t
unbind C-b

# Vimのキーバインドでペインを移動する
bind h select-pane -L
bind j select-pane -D
bind k select-pane -U
bind l select-pane -R

# - でペインを横に分割する(縦に切る)
bind - split-window -h

# | でペインを縦に分割する(横に切る)
bind | split-window -v

# 同時入力
bind s set-window-option synchronize-panes on
bind S set-window-option synchronize-panes off
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Firebaseをwebで使う(Hosting, Authentication, Realtime Database, Storage)</title>
          <link>https://www.sambaiz.net/article/94/</link>
          <pubDate>Sun, 16 Apr 2017 20:03:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/94/</guid>
          <description>

&lt;h2 id=&#34;firebase-https-firebase-google-com-hl-ja-とは&#34;&gt;&lt;a href=&#34;https://firebase.google.com/?hl=ja&#34;&gt;Firebase&lt;/a&gt;とは&lt;/h2&gt;

&lt;p&gt;GoogleのmBaaS。Android/iOSアプリの開発に使う認証、データストア、クラッシュレポート、分析、通知、広告などなど全部入りサービス。
今年のGoogleI/Oでも&lt;a href=&#34;https://events.google.com/io/schedule/?section=may-19&#34;&gt;毎時間のように&lt;/a&gt;
Firebaseのセッションがあって大分推している印象。&lt;/p&gt;

&lt;p&gt;基本的にはアプリで使うのだけれど、webで使える機能も結構ある。今回は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Hosting&lt;/li&gt;
&lt;li&gt;Authentication&lt;/li&gt;
&lt;li&gt;Realtime Database&lt;/li&gt;
&lt;li&gt;Storage&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を使ってみる。&lt;/p&gt;

&lt;h2 id=&#34;料金-https-firebase-google-com-pricing&#34;&gt;&lt;a href=&#34;https://firebase.google.com/pricing/&#34;&gt;料金&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;プランは無料のSPARKと25ドル/月のFLAME、従量課金のBLAZEがある。
試す分にはSPARKで十分だけど、Realtime Databaseの同時接続数が100なので注意。&lt;/p&gt;

&lt;h2 id=&#34;セットアップ-https-firebase-google-com-docs-web-setup&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/web/setup&#34;&gt;セットアップ&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://firebase.google.com/docs/cli/&#34;&gt;firebase-cli&lt;/a&gt;をインストール、ログインして初期化する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g firebase-tools
$ firebase login
$ mkdir firebase-chat &amp;amp;&amp;amp; cd firebase-chat
$ firebase init
...
? What Firebase CLI features do you want to setup for this folder? 
❯◉ Database: Deploy Firebase Realtime Database Rules
 ◉ Functions: Configure and deploy Cloud Functions
 ◉ Hosting: Configure and deploy Firebase Hosting sites

? What Firebase project do you want to associate as default? *****

? What file should be used for Database Rules? database.rules.json

? Do you want to install dependencies with npm now? Yes

? What do you want to use as your public directory? public

? Configure as a single-page app (rewrite all urls to /index.html)? Yes

✔  Firebase initialization complete!

$ ls
database.rules.json	firebase.json		functions		public
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;firebase.jsonはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat firebase.json
{
  &amp;quot;database&amp;quot;: {
    &amp;quot;rules&amp;quot;: &amp;quot;database.rules.json&amp;quot;
  },
  &amp;quot;hosting&amp;quot;: {
    &amp;quot;public&amp;quot;: &amp;quot;public&amp;quot;,
    &amp;quot;rewrites&amp;quot;: [
      {
        &amp;quot;source&amp;quot;: &amp;quot;**&amp;quot;,
        &amp;quot;destination&amp;quot;: &amp;quot;/index.html&amp;quot;
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ローカルでサーバーを立ち上げて確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ firebase serve
Server listening at: http://localhost:5000

$ curl http://localhost:5000 # Firebase SDK loaded with auth, database, messaging, storage
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;hosting-https-firebase-google-com-docs-hosting-hl-ja&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/hosting/?hl=ja&#34;&gt;Hosting&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;静的サイトのホスティング。もちろん独自ドメインも使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ firebase deploy --only hosting
...
✔  Deploy complete!

Project Console: https://console.firebase.google.com/project/*****/overview
Hosting URL: https://*****.firebaseapp.com
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;authentication-https-firebase-google-com-docs-auth&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/auth/&#34;&gt;Authentication&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ユーザー認証。Googleだけではなく、TwitterやFacebook、Githubといったプロバイダや、メールとパスワードでの認証が用意されていて、
コンソールから有効にする必要がある。&lt;/p&gt;

&lt;p&gt;実装はFirebase SDKで自分でやるか、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const provider = new firebase.auth.GoogleAuthProvider();
firebase.auth().signInWithPopup(provider).then((result) =&amp;gt; {
    console.log(`sign in successfully. ${result.user.displayName}`)
}).catch((error) =&amp;gt; {
    console.log(`fail to sign in. ${error.message}`)
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/firebase/FirebaseUI-Web&#34;&gt;FirebaseUI Auth&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script defer src=&amp;quot;https://cdn.firebase.com/libs/firebaseui/1.0.1/firebaseui.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;link type=&amp;quot;text/css&amp;quot; rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://cdn.firebase.com/libs/firebaseui/1.0.1/firebaseui.css&amp;quot; /&amp;gt;

&amp;lt;div id=&amp;quot;firebaseui-auth-container&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;// FirebaseUI config.
var uiConfig = {
  signInOptions: [
    // Leave the lines as is for the providers you want to offer your users.
    firebase.auth.GoogleAuthProvider.PROVIDER_ID
  ],
  callbacks: {
    signInSuccess: function(currentUser, credential, redirectUrl) {
      // リダイレクトさせない
      return false;
    }
  },
  // Terms of service url.
  tosUrl: &#39;&amp;lt;your-tos-url&amp;gt;&#39;
};

// Initialize the FirebaseUI Widget using Firebase.
var ui = new firebaseui.auth.AuthUI(firebase.auth());
// The start method will wait until the DOM is loaded.
ui.start(&#39;#firebaseui-auth-container&#39;, uiConfig);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じにボタンが並ぶ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/93-firebase-authentication.png&#34; alt=&#34;Firebase authentication&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;onAuthStateChanged()&lt;/code&gt;でsign in/outをハンドリングでき、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;firebase.auth().onAuthStateChanged((user) =&amp;gt; {
    if (user) {
      console.log(`${user.displayName} sign in`);
    } else {
      console.log(&#39;sign out&#39;);
    }
  }, (error) =&amp;gt; {
    console.log(error);
  }
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;currentUserでsign inしてるユーザーを取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if(firebase.auth().currentUser){
  console.log(firebase.auth().currentUser.displayName);
}else{
  // need to sign in
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;realtime-database-https-firebase-google-com-docs-database&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/database/&#34;&gt;Realtime Database&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;NoSQLなデータベース。直接読み書きするのではなく、
ローカルにデータを保存してリアルタイムに同期するため一時的にオフライン状態になっても読み書きできる。&lt;/p&gt;

&lt;h3 id=&#34;読み書き-https-firebase-google-com-docs-database-web-read-and-write&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/database/web/read-and-write&#34;&gt;読み書き&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;データベースへの書き込みと更新。refで&lt;code&gt;users/1&lt;/code&gt;のように参照を取って操作する。
&lt;a href=&#34;https://firebase.google.com/docs/reference/js/firebase.database.Reference?hl=ja#push&#34;&gt;push()&lt;/a&gt;で
&lt;code&gt;hoge/-Khp36CCygw5AI6G8L1B&lt;/code&gt;のようなユニークなキーを発行することができ、これは時系列にソートされるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const database = firebase.database();

for(let i = 0; i &amp;lt; 10; i++){
    
    const newHogeRef = database.ref(&#39;hoge&#39;).push();
    console.log(`newHogeRef: ${newHogeRef.toString()}`);
    
    newHogeRef.set({
        idx: i,
        aaa: &amp;quot;bbb123&amp;quot;,
    });

    newHogeRef.update({
        aaa: &amp;quot;bbb456&amp;quot;,
        eee: &amp;quot;fff&amp;quot;
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;newHogeRef: https://test-3a363.firebaseio.com/hoge/-Khp36CCygw5AI6G8L1B
newHogeRef: https://test-3a363.firebaseio.com/hoge/-Khp36CLyJ9BQVefW-l5
newHogeRef: https://test-3a363.firebaseio.com/hoge/-Khp36CMs9-jJoKUUgr0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://firebase.google.com/docs/reference/js/firebase.database.Reference?hl=ja#on&#34;&gt;on()&lt;/a&gt;で
value eventを拾うと、
呼んだときとデータに変更があったときに&lt;a href=&#34;https://firebase.google.com/docs/reference/js/firebase.database.DataSnapshot?hl=ja&#34;&gt;snapshot&lt;/a&gt;が取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;database.ref(&amp;quot;hoge&amp;quot;).orderByKey().limitToLast(3).on(&amp;quot;value&amp;quot;, (snapshot) =&amp;gt; {
    snapshot.forEach((data) =&amp;gt; console.log(data.val()));
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
Object {aaa: &amp;quot;bbb456&amp;quot;, eee: &amp;quot;fff&amp;quot;, idx: 7}
Object {aaa: &amp;quot;bbb456&amp;quot;, eee: &amp;quot;fff&amp;quot;, idx: 8}
Object {aaa: &amp;quot;bbb456&amp;quot;, eee: &amp;quot;fff&amp;quot;, idx: 9}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;アクセス権限-バリデーション-https-firebase-google-com-docs-database-security-securing-data&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/database/security/securing-data&#34;&gt;アクセス権限・バリデーション&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;firebase.jsonで指定しているdatabase ruleファイル(database.rules.json)でルールを設定する。
デフォルトで認証していれば読み書きできる設定になっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;rules&amp;quot;: {
    &amp;quot;.read&amp;quot;: &amp;quot;auth != null&amp;quot;,
    &amp;quot;.write&amp;quot;: &amp;quot;auth != null&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;read/writeだけではなくバリデーションの設定もこんな感じでできる。
これは&lt;code&gt;users/${ユーザーのuid}&lt;/code&gt;への読み書きを本人のみができるようにするもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;rules&amp;quot;: {
    &amp;quot;users&amp;quot;: {
      &amp;quot;$uid&amp;quot;: {
        &amp;quot;.read&amp;quot;: &amp;quot;$uid === auth.uid&amp;quot;,
        &amp;quot;.write&amp;quot;: &amp;quot;$uid === auth.uid&amp;quot;,
        &amp;quot;.validate&amp;quot;: &amp;quot;newData.hasChildren([&#39;age&#39;, &#39;name&#39;]) &amp;amp;&amp;amp; newData.child(&#39;age&#39;).isNumber() &amp;amp;&amp;amp; newData.child(&#39;age&#39;).val() &amp;gt;= 0 &amp;amp;&amp;amp; newData.child(&#39;age&#39;).val() &amp;lt; 200 &amp;amp;&amp;amp; newData.child(&#39;name&#39;).isString() &amp;amp;&amp;amp; newData.child(&#39;name&#39;).val().length &amp;lt; 50&amp;quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ firebase deploy --only database
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上の設定を適用したデータベースに読み書きしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const uid = firebase.auth().currentUser.uid;

database.ref(`users/${uid}`).set({
    age: 20,
    name: &amp;quot;taro&amp;quot;
});

// ok: Object {age: 20, name: &amp;quot;taro&amp;quot;}
database.ref(`users/${uid}`).on(&amp;quot;value&amp;quot;, (snapshot) =&amp;gt; {
    console.log(snapshot.val()); // Object {age: 20, name: &amp;quot;taro&amp;quot;}
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のような不正なデータや不正なキーに書き込もうとすると
&lt;code&gt;PERMISSION_DENIED: Permission denied&lt;/code&gt;になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// ageがおかしい
database.ref(`users/${uid}`).set({
    age: &amp;quot;aaaa&amp;quot;,
    name: &amp;quot;jiro&amp;quot;
});

// 本人じゃない
database.ref(`users/hogehoge`).set({
    age: 20,
    name: &amp;quot;jiro&amp;quot;
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、さっきまでアクセスできていたhogeにもアクセスできなくなっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// PERMISSION_DENIED: Permission denied
database.ref(&amp;quot;hoge&amp;quot;).orderByKey().limitToLast(3).on(&amp;quot;value&amp;quot;, (snapshot) =&amp;gt; {
    snapshot.forEach((data) =&amp;gt; console.log(data.val()));
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを解決するためにrulesのルートに&lt;code&gt;auth != null&lt;/code&gt;の設定を入れてしまうと、
&lt;a href=&#34;https://firebase.google.com/docs/database/security/securing-data#read_and_write_rules_cascade&#34;&gt;浅い階層のルールが深い階層のルールより優先される&lt;/a&gt;
ためusersのread/writeの設定が無効になってしまうので注意。ただしvalidateはそれぞれの階層でチェックされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;rules&amp;quot;: {
    &amp;quot;.read&amp;quot;: &amp;quot;auth != null&amp;quot;,
    &amp;quot;.write&amp;quot;: &amp;quot;auth != null&amp;quot;,
    &amp;quot;users&amp;quot;: {
      &amp;quot;$uid&amp;quot;: {
        &amp;quot;.read&amp;quot;: &amp;quot;$uid === auth.uid&amp;quot;,
        &amp;quot;.write&amp;quot;: &amp;quot;$uid === auth.uid&amp;quot;,
        &amp;quot;.validate&amp;quot;: &amp;quot;newData.hasChildren([&#39;age&#39;, &#39;name&#39;]) &amp;amp;&amp;amp; newData.child(&#39;age&#39;).isNumber() &amp;amp;&amp;amp; newData.child(&#39;age&#39;).val() &amp;gt;= 0 &amp;amp;&amp;amp; newData.child(&#39;age&#39;).val() &amp;lt; 200 &amp;amp;&amp;amp; newData.child(&#39;name&#39;).isString() &amp;amp;&amp;amp; newData.child(&#39;name&#39;).val().length &amp;lt; 50&amp;quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;storage-https-firebase-google-com-docs-storage&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/storage/&#34;&gt;Storage&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;画像などを保存しておくために使う。
Realtime Databaseと同様、
ネットワーク品質が良くない環境でも使えるように、処理が中断されても途中から処理を再開するようになっている。
裏側ではGoogle Cloud Storageが使われている。&lt;/p&gt;

&lt;h3 id=&#34;アップロード-https-firebase-google-com-docs-storage-web-upload-files&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/storage/web/upload-files&#34;&gt;アップロード&lt;/a&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;input type=&amp;quot;file&amp;quot; id=&amp;quot;file-upload&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const storage = firebase.storage();

const inputFile = document.getElementById(&#39;file-upload&#39;);

inputFile.addEventListener(&#39;change&#39;, (e) =&amp;gt; {
  const files = e.target.files;
  const user = firebase.auth().currentUser;
  if(user){
    const ref = storage.ref(`images/${user.uid}`);
    const uploadTask = ref.put(files[0]);
  }
}, false);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;中断、再開、キャンセル。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;uploadTask.pause();
uploadTask.resume();
uploadTask.cancel();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アップロードの状態はstage_changed eventで確認し、完了するとダウンロードURLを取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;uploadTask.on(&#39;state_changed&#39;, (snapshot) =&amp;gt; {

  const progress = (snapshot.bytesTransferred / snapshot.totalBytes) * 100;
  console.log(&#39;Upload is &#39; + progress + &#39;% done&#39;);

  switch (snapshot.state) {
    case firebase.storage.TaskState.PAUSED: // or &#39;paused&#39;
      console.log(&#39;Upload is paused&#39;);
      break;
    case firebase.storage.TaskState.RUNNING: // or &#39;running&#39;
      console.log(&#39;Upload is running&#39;);
      break;
  }
}, (error) =&amp;gt; {
  // Handle unsuccessful uploads
  console.log(error);
}, () =&amp;gt; {
  // Handle successful uploads on complete
  // For instance, get the download URL: https://firebasestorage.googleapis.com/...
  console.log(uploadTask.snapshot.downloadURL);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;アクセス制限-バリデーション-https-firebase-google-com-docs-storage-security-hl-ja&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/storage/security/?hl=ja&#34;&gt;アクセス制限・バリデーション&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Realtime Databaseと同様にアクセス制限やバリデーションをかけることができる。
設定はコンソールから。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/93-firebase-storage-rule.png&#34; alt=&#34;Storageのルール&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service firebase.storage {
  match /b/*****.appspot.com/o {
    match /images/{imageId} {
      // Only allow uploads of any image file that&#39;s less than 5MB
      allow write: if request.resource.size &amp;lt; 5 * 1024 * 1024
                   &amp;amp;&amp;amp; request.resource.contentType.matches(&#39;image/.*&#39;)
                   &amp;amp;&amp;amp; request.auth != null;
      allow read: if request.auth != null;             
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ダウンロード-https-firebase-google-com-docs-storage-web-download-files&#34;&gt;&lt;a href=&#34;https://firebase.google.com/docs/storage/web/download-files&#34;&gt;ダウンロード&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;getDownloadURL()&lt;/code&gt;でURLを取得する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;img id=&amp;quot;myimg&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const ref = storage.ref(`images/${user.uid}`).getDownloadURL().then((url) =&amp;gt; {
  
  const img = document.getElementById(&#39;myimg&#39;);
  img.src = url;

}).catch((error) =&amp;gt; {

  switch (error.code) {
    case &#39;storage/object-not-found&#39;:
      console.log(&amp;quot;not found&amp;quot;);
      break;

    default:
      console.log(error);
  }
});;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLのALTER TABLEのメモ</title>
          <link>https://www.sambaiz.net/article/93/</link>
          <pubDate>Sat, 15 Apr 2017 19:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/93/</guid>
          <description>&lt;p&gt;しばらく書かないとどういう構文だったか忘れてしまう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/alter-table.html&#34;&gt;MySQL :: MySQL 5.6 リファレンスマニュアル :: 13.1.7 ALTER TABLE 構文&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE t0 (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    c1 VARCHAR(30),
    c2 VARCHAR(30)
);
CREATE TABLE t2 (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ALTER TABLE t0 RENAME t1;
ALTER TABLE t1
  ADD COLUMN t2_id BIGINT UNSIGNED AFTER id,
  ADD COLUMN c3 INTEGER NOT NULL AFTER t2_id,
  MODIFY COLUMN c1 VARCHAR(30) NOT NULL,
  DROP COLUMN c2,
  ADD INDEX (c3),
  ADD FOREIGN KEY (t2_id) REFERENCES t2(id) ON UPDATE RESTRICT ON DELETE RESTRICT
;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SHOW CREATE TABLE t1 \G;
*************************** 1. row ***************************
       Table: t1
Create Table: CREATE TABLE `t1` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `t2_id` bigint(20) unsigned DEFAULT NULL,
  `c3` int(11) NOT NULL,
  `c1` varchar(30) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `c3` (`c3`),
  KEY `t2_id` (`t2_id`),
  CONSTRAINT `t1_ibfk_1` FOREIGN KEY (`t2_id`) REFERENCES `t2` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE=InnoDB DEFAULT CHARSET=utf8
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ALTER TABLE t1
  DROP INDEX c3,
  DROP FOREIGN KEY t1_ibfk_1,
  DROP INDEX t2_id
;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SHOW CREATE TABLE t1 \G
*************************** 1. row ***************************
       Table: t1
Create Table: CREATE TABLE `t1` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `t2_id` bigint(20) unsigned DEFAULT NULL,
  `c3` int(11) NOT NULL,
  `c1` varchar(30) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityのパーティクル設定(Shuriken)</title>
          <link>https://www.sambaiz.net/article/92/</link>
          <pubDate>Thu, 13 Apr 2017 17:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/92/</guid>
          <description>

&lt;p&gt;Unityには&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/class-ParticleSystem.html&#34;&gt;Shuriken&lt;/a&gt;というパーティクルシステムがある。&lt;/p&gt;

&lt;p&gt;Sphereを置いてParticle Systemを追加すると、Particleが出始める。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-1.png&#34; alt=&#34;Particleの初期状態&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;モジュール&#34;&gt;モジュール&lt;/h2&gt;

&lt;p&gt;設定項目が多いためモジュールに分かれている。ひとまずデフォルトで有効になっている&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(メインモジュール)&lt;/li&gt;
&lt;li&gt;Emission&lt;/li&gt;
&lt;li&gt;Shape&lt;/li&gt;
&lt;li&gt;Renderer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;について見ていく。&lt;/p&gt;

&lt;h3 id=&#34;メインモジュール-https-docs-unity3d-com-550-documentation-manual-partsysmainmodule-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/PartSysMainModule.html&#34;&gt;メインモジュール&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Duration: 5&lt;/li&gt;
&lt;li&gt;Looping: true&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;デフォルトだとLoopingにチェックが入っているのでずっと出ているが、チェックを外すとDurationで止まる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Delay: 0&lt;/li&gt;
&lt;li&gt;Play On Awake: true&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PlayOnAwakeがtrueでStartDelayが0なので実行してからすぐにParticleが出始める。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Lifetime: 5&lt;/li&gt;
&lt;li&gt;Max Particles: 1000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;StartLifetimeはParticleが消えるまでの時間。ただしMaxParticlesに達したら消される。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Speed: 5&lt;/li&gt;
&lt;li&gt;Simulation Speed: 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;StartSpeedはParticleの初速で、上げると勢い良く飛んでいく。
SimulationSpeedを上げるとParticleが出るのも含めて全体のスピードが上がる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Size: 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleの初期サイズ。小さくすると塵みたいになる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Rotation: 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleの初期角度。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Gravity Modifier: 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;重力値。0だと無重力。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Simulation Space: Local&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleをlocal座標かworld座標で動かすか。
Localだとオブジェクトが移動したときに一緒に移動する。Worldだと置いてかれる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Scaling Mode: Local&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ParticleのScale。LocalだとそのオブジェクトのScaleだけを見る。Hierarchyだと親も考慮したScale。Shapeだと開始位置だけ。&lt;/p&gt;

&lt;h3 id=&#34;emissionモジュール-https-docs-unity3d-com-550-documentation-manual-partsysemissionmodule-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/PartSysEmissionModule.html&#34;&gt;Emissionモジュール&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Rate over time: 10&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;単位時間あたりにParticleを出す数。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Rate over Distance: 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;オブジェクトが移動するときにParticleを出す数。Simulation SpaceがWorldのときのみ有効。&lt;/p&gt;

&lt;h3 id=&#34;shapeモジュール-https-docs-unity3d-com-550-documentation-manual-partsysshapemodule-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/PartSysShapeModule.html&#34;&gt;Shapeモジュール&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Shape: Corn&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleを出す形。Cornだと特定方向に向けた円錐状に出る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-shape-corn.png&#34; alt=&#34;ShapeがCorn&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Spehreで全方向に出したり、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-shape-sphere.png&#34; alt=&#34;ShapeがSphere&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hemisphereで片側だけ出したり、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-shape-hemisphere.png&#34; alt=&#34;ShapeがHemisphere&#34; /&gt;&lt;/p&gt;

&lt;p&gt;EdgeでY方向に直線上に出したりすることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-particle-shape-edge.png&#34; alt=&#34;ShapeがEdge&#34; /&gt;&lt;/p&gt;

&lt;p&gt;そのほかのパラメータはShapeに応じて設定する。&lt;/p&gt;

&lt;h3 id=&#34;rendererモジュール-https-docs-unity3d-com-550-documentation-manual-partsysrenderermodule-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/PartSysRendererModule.html&#34;&gt;Rendererモジュール&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Render Mode: Billboard&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleがどのようにレンダリングされるか。Billboardは常にカメラに向くようにレンダリングされる。&lt;/p&gt;

&lt;p&gt;Stretched Billboardにするとカメラの方向に向きながら、&lt;a href=&#34;https://en.wikipedia.org/wiki/Squash_and_stretch&#34;&gt;stretch and squash&lt;/a&gt;させる。つまり速度を強調するように変形させる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-stretched-billboard.png&#34; alt=&#34;Render ModeがStretched Billboard&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Material: None&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Particleのmaterial。これにDefault-Particleを指定するとこうなる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-default-particle.png&#34; alt=&#34;MaterialがDefault Particle&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;afterburner&#34;&gt;AfterBurner&lt;/h2&gt;

&lt;p&gt;Standard AssetsにあるAfterBurnerの設定を見てみる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-after-burner.png&#34; alt=&#34;AfterBurner&#34; /&gt;&lt;/p&gt;

&lt;p&gt;中央の濃い部分と、そのまわりの薄い部分の2つの設定を組み合わせている。
Explosionとかは9個組み合わせているので比較的シンプル。&lt;/p&gt;

&lt;p&gt;濃い部分ではEmissionのRate over Timeを80にすることで続いているように見えるようにして、
Size over LifetimeモジュールのSizeを徐々に小さくすることによって尾の方にかけて細くなるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-after-burner-size.png&#34; alt=&#34;AfterBurnerのSize over Lifetime&#34; /&gt;&lt;/p&gt;

&lt;p&gt;さらにColor over LifetimeモジュールのColorで両端のAlphaを0、Location 6.0%のAlphaを30に設定することで、
素早くフェードインし、徐々にフェードアウトするようにしている。&lt;/p&gt;

&lt;p&gt;また、Start SizeをRandom Between Two Constantsの(1.2, 1.4)に設定することで多少揺らいでいるように見せている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/92-after-burner-gradient.png&#34; alt=&#34;AfterBurnerのSize over Lifetime&#34; /&gt;&lt;/p&gt;

&lt;p&gt;薄い部分ではEmissionのRate over Timeを60、ColorのLocation 6.0%のAlphaを8に設定して薄く見せている。
あとはSize over Lifetimeを設定し、Start SizeはRandom Between Two Constantsの(4,6)と大きく設定してある。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>godocのメモ</title>
          <link>https://www.sambaiz.net/article/91/</link>
          <pubDate>Wed, 05 Apr 2017 22:11:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/91/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/tools/cmd/godoc&#34;&gt;https://godoc.org/golang.org/x/tools/cmd/godoc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;コメントからドキュメントを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ godoc cmd/fmt Printf
func Printf(format string, a ...interface{}) (n int, err error)
    Printf formats according to a format specifier and writes to standard
    output. It returns the number of bytes written and any write error
    encountered.

$ godoc -src cmd/fmt Printf
// Printf formats according to a format specifier and writes to standard output.
// It returns the number of bytes written and any write error encountered.
func Printf(format string, a ...interface{}) (n int, err error) {
    return Fprintf(os.Stdout, format, a...)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;記述対象の要素の名前から始まる、完全な文として&lt;a href=&#34;https://blog.golang.org/godoc-documenting-go-code&#34;&gt;コメントを書く&lt;/a&gt;。
インデントすれば整形した文になり、&lt;code&gt;Bug(ユーザー名):&lt;/code&gt;から始めればバグセクションにまとめられる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// foo bar package
package foo

import &amp;quot;fmt&amp;quot;

// Hoge returns &amp;quot;HOGE (input num)&amp;quot; string.
//   Hoge
//   Fuga
//   Piyo
// BUG(sambaiz): when passed 2, it panic.
func Hoge(num int) string {
	if num == 2 {
		panic(&amp;quot;AAAAAAAAHHHH&amp;quot;)
	}
	return fuga(&amp;quot;HOGE&amp;quot;, num)
}

// returns &amp;quot;(keyword) (num)&amp;quot; string
func fuga(keyword string, num int) string {
	return fmt.Sprintf(&amp;quot;%s %d&amp;quot;, keyword, num)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/testing/#hdr-Examples&#34;&gt;例&lt;/a&gt;を&lt;code&gt;ExampleXXX&lt;/code&gt;のような関数に書いておくと、これもドキュメントに追加される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package foo

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;testing&amp;quot;
)

func TestHoge(t *testing.T){
	...
}

func ExampleHoge() {
	fmt.Println(Hoge(1))
	// Output: HOGE 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Webサーバーを立ち上げてブラウザで確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ godoc -http=:6060 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じでfooパッケージのドキュメントが表示される。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:6060/pkg/github.com/sambaiz/godoctest/foo/&#34;&gt;http://localhost:6060/pkg/github.com/sambaiz/godoctest/foo/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/91_godoc.png&#34; alt=&#34;godoc&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Nightmareでブラウザでの操作を自動化する</title>
          <link>https://www.sambaiz.net/article/90/</link>
          <pubDate>Wed, 29 Mar 2017 23:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/90/</guid>
          <description>&lt;p&gt;最近、&lt;a href=&#34;http://postwash.net/&#34;&gt;POSTWASH&lt;/a&gt;という洗濯代行サービスを使っている。
専用のカバンに詰めて集荷にきた人に渡すと、きれいに畳まれた洗濯ものが届く便利なサービスだ。
注文時にはWebのフォームから集荷、配達時間や支払い方法などを選ぶ必要があるんだけど、毎週のことなのでこれを自動化してみる。&lt;/p&gt;

&lt;p&gt;ブラウザの操作を自動化するのに&lt;a href=&#34;https://github.com/segmentio/nightmare&#34;&gt;Nightmare&lt;/a&gt;を使う。
&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;を使っていて、&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PahntomJS&lt;/a&gt;より2倍くらい速く、簡潔に書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install nightmare
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Nightmare()&lt;/code&gt;の引数に&lt;code&gt;show: true&lt;/code&gt;を渡すとウィンドウが開いて実行し始める。
これで確認画面までいくのであとは注文ボタンを押すだけ。
ウィンドウが閉じないように最後に&lt;code&gt;nightmare.end()&lt;/code&gt;を呼んでいない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const co = require(&#39;co&#39;);
const moment = require(&#39;moment&#39;)
const jst = +9
const Nightmare = require(&#39;nightmare&#39;);		
const nightmare = Nightmare({ 
  show: true,
  waitTimeout: 3000,
  gotoTimeout: 3000
});
const loginID = process.env.LOGIN_ID;
const loginPassword = process.env.LOGIN_PASSWORD;

moment.locale(&#39;ja&#39;);
const now = moment().utcOffset(jst)
const dayAfterTomorrow = now.add(2, &#39;days&#39;).format(&amp;quot;YYYY年M月D日(ddd)&amp;quot;);
const nextWeek = now.add(7, &#39;days&#39;).format(&amp;quot;YYYY年M月D日(ddd)&amp;quot;)
console.log(`${dayAfterTomorrow}~${nextWeek}`);

// IDとパスワードを入れてログイン
const login = () =&amp;gt; nightmare
  .goto(&#39;https://sv359.xserver.jp/~postwash/postwash.net/accounts/&#39;)
  .type(&#39;#loginid&#39;, loginID)
  .insert(&#39;#loginpw&#39;, loginPassword) // .insert() is faster than .type() but does not trigger the keyboard events.
  .click(&#39;#submit&#39;)
  .wait(&#39;#yokoso&#39;)
  .evaluate(() =&amp;gt; document.querySelector(&#39;#yokoso h5&#39;).textContent);

// 注文フォームを埋めていく
const order = () =&amp;gt; nightmare
  .goto(&#39;https://sv359.xserver.jp/~postwash/postwash.net/mypage/order.html&#39;)
  .wait(&#39;#item\\[4\\]&#39;)
  .check(&#39;#item\\[4\\]&#39;)
  .insert(&#39;#itemnum\\[4\\]&#39;, &#39;1&#39;)
  .select(&#39;#pickup_date_request&#39;, dayAfterTomorrow)
  .select(&#39;#pickup_time_request&#39;, &#39;午前中（8時～12時）&#39;)
  .wait(500) // #delivery_date_request が切り替わってしまうので少し待つ
  .select(&#39;#delivery_date_request&#39;, nextWeek)
  .select(&#39;#delivery_time_request&#39;, &#39;午前中（8時～12時）&#39;)
  .select(&#39;#payment&#39;, &#39;代金引換&#39;)
  .check(&#39;#agreement&#39;)
  .click(&#39;#submit&#39;)

co(function *(){
    yield login().then(
        (result) =&amp;gt; console.log(result), // ようこそ
        (err) =&amp;gt; console.log(err)
    );
    yield order();
    // yield nightmare.end();
});
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsでの文字コードの変換</title>
          <link>https://www.sambaiz.net/article/89/</link>
          <pubDate>Tue, 28 Mar 2017 21:36:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/89/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/bnoordhuis/node-iconv&#34;&gt;node-iconv&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install iconv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SHIFT_JISからUTF-8への変換はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const Iconv  = require(&#39;iconv&#39;).Iconv;

const before = new Buffer([
    0x8b, 0x8d, 
    0x8e, 0x4d, 
    0x26,
    0x82, 0xb2,
    0x94, 0xd1
]);

const iconv = new Iconv(&#39;SHIFT_JIS&#39;, &#39;UTF-8&#39;);
console.log(`before: ${before.toString(&#39;hex&#39;)} ${before.toString()}`)
const after = iconv.convert(before);
console.log(`after:  ${after.toString(&#39;hex&#39;)} ${after.toString()}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;before: 8b8d8e4d2682b294d1 ���M&amp;amp;����
after:  e7899be79abf26e38194e9a3af 牛皿&amp;amp;ご飯
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文字コードによっては変換後に表せないことがある。
例えば、UTF-8からSHIFT_JISへの変換でサロゲートペア🍚を渡すと変換できず、エラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;throw errnoException(&#39;EILSEQ&#39;, &#39;Illegal character sequence.&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;//IGNORE&lt;/code&gt;を&lt;a href=&#34;https://www.npmjs.com/package/iconv#dealing-with-untranslatable-characters&#34;&gt;付ける&lt;/a&gt;ことで
そのような文字があった場合でもエラーにしないようにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const Iconv  = require(&#39;iconv&#39;).Iconv;

const before = &amp;quot;牛皿&amp;amp;🍚&amp;quot;;

const iconv = new Iconv(&#39;UTF-8&#39;, &#39;SHIFT_JIS//IGNORE&#39;);
console.log(`before: ${new Buffer(before).toString(&#39;hex&#39;)} ${before.toString()}`)
const conv = iconv.convert(before);
const iconv2 = new Iconv(&#39;SHIFT_JIS&#39;, &#39;UTF-8&#39;);
const after = iconv2.convert(conv);
console.log(`after:  ${after.toString(&#39;hex&#39;)} ${after.toString()}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;変換できないものは無視される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;before: e7899be79abf26f09f8d9a 牛皿&amp;amp;🍚
after:  e7899be79abf26 牛皿&amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lambdaでは&#34;&gt;Lambdaでは&lt;/h2&gt;

&lt;p&gt;Lambdaではインストールされているiconvコマンドを使うことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return new Promise((resolve, reject) =&amp;gt; {
    let filePath = &amp;quot;/tmp/shiftjis&amp;quot;;
    fs.writeFileSync(filePath, shiftjis);
    var exec = require(&#39;child_process&#39;).exec;
    var cmd = `iconv -c -f sjis -t utf-8 ${filePath}`;
    var child = exec(cmd, (err, stdout, stderr) =&amp;gt; {
      if (err) reject(err);
      else resolve(stdout);
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bokukoko.info/entry/2015/08/30/AWS_Lambda%E5%86%85%E3%81%A7%E6%96%87%E5%AD%97%E3%82%B3%E3%83%BC%E3%83%89%E3%82%92%E5%A4%89%E6%8F%9B%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95&#34;&gt;AWS Lambda内で文字コードを変換する方法 - ボクココ&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensのSharing</title>
          <link>https://www.sambaiz.net/article/88/</link>
          <pubDate>Sat, 25 Mar 2017 22:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/88/</guid>
          <description>

&lt;ul&gt;
&lt;li&gt;HoloToolkit-Unity v1.5.5.0&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サーバー&#34;&gt;サーバー&lt;/h2&gt;

&lt;p&gt;SharingService.exeを
&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/tree/v1.5.5.0/External/HoloToolkit/Sharing/Server&#34;&gt;ここ&lt;/a&gt;
からとってきて実行する。開発に使っているHoloToolkitと同じリリースバージョンのものを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SharingService.exe -local
...
SharingService: Listening for session list connections on port 20602 of all network devices of the local machine.
SharingService: Local IP addresses are:
SharingService:         xxx.xxx.xxx.xxx
SharingService: Created Session &amp;quot;Default&amp;quot; with ID 0 on port 20601
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今日のTokyo Hololens Meetup Vol.2の開発者セッションで、
ちょうどSharingの話があったのだけれど、残念ながら先着順で出遅れて聞けなかった。&lt;/p&gt;

&lt;p&gt;Tweetを見る限りだとカスタマイズできず、スケーリングできないSharingService.exeは使わずに
&lt;a href=&#34;https://github.com/neuecc/MagicOnion&#34;&gt;MagicOnion&lt;/a&gt;というのを自前で作ったらしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://togetter.com/li/1094037&#34;&gt;Tokyo Hololens MeetuUp Vol.2 Session5 #HoloLensJP #TMCN - Togetterまとめ&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;クライアント-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing&#34;&gt;クライアント&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Assets/HoloToolkit/Sharing/Tests&lt;/code&gt;のSceneで試してみる。&lt;/p&gt;

&lt;p&gt;以下のcapabilitiesを設定し、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SpatialPerception&lt;/li&gt;
&lt;li&gt;InternetClient&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SharingのServer Addressを設定してビルド。ほかにはこんな設定がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Scripts/SharingStage.cs#L15&#34;&gt;Client Role&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Primary: 直接セッションサーバーに接続し、セッションを管理する&lt;/li&gt;
&lt;li&gt;Secondary: Primaryクライアントに接続して、セッション管理は任せる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Server Address&lt;/li&gt;
&lt;li&gt;Port&lt;/li&gt;
&lt;li&gt;Auto Discover Server&lt;/li&gt;
&lt;li&gt;Session Name&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;起動して以下のようなエラーが出たらSharingService.exeがHoloToolkitのバージョンと合っていない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;List Server Handshake Failed: Invalid schema version.
Expected: 17, got 15
Please sync to latest XTools
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接続と離脱のメッセージはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SharingService: User UnknownUser at address xxx.xxx.xxx.xxx joined session Default
SharingService: User UnknownUser left session Default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2つ以上クライアントを立ち上げると、他のクライアントの、球からの相対的な頭の位置にCubeが映った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/88-sharing.jpg&#34; alt=&#34;他のクライアントの頭の位置にCubeがある&#34; /&gt;&lt;/p&gt;

&lt;p&gt;が、球の場所が空間に対して同期されない・・・。&lt;/p&gt;

&lt;p&gt;原因を探るために、
TestsのSceneと同様に、SharingのPrefabにCustomMessage.csを、
適当なGameObjectにImportExportAnchorManager.csとRemoteHeadManager.csと
目印になるオブジェクトを追加し、
ImportExportAnchorManager.csにこんな感じのを追加してcurrentStateを表示してみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public GameObject statusText;
private void Update()
{
    statusText.GetComponent&amp;lt;TextMesh&amp;gt;().text = currentState.ToString();
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果、起動してからまだReady状態になっていなかったことが分かった。
少し待ってみるといろんな状態を経て、Ready状態になると、
目印のオブジェクトが物理的に同じところに移動し、頭の位置も正しいところに移動した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/88-sharing2.png&#34; alt=&#34;Sharingしている状態&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;なにをやっているか見ていく。&lt;/p&gt;

&lt;p&gt;まずは拾えるevent。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/83/&#34;&gt;C#のdelegateとevent - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;sharingsessiontracker-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-scripts-sharingsessiontracker-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Scripts/SharingSessionTracker.cs&#34;&gt;SharingSessionTracker&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;public event EventHandler&lt;SessionJoinedEventArgs&gt; SessionJoined;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ユーザーがセッションに入ったとき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class SessionJoinedEventArgs : EventArgs
{
    public User joiningUser;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;public event EventHandler&lt;SessionLeftEventArgs&gt; SessionLeft;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;セッションから出たとき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class SessionLeftEventArgs : EventArgs
{
    public long exitingUserId;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sharingstage-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-scripts-sharingstage-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Scripts/SharingStage.cs&#34;&gt;SharingStage&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;public event EventHandler SharingManagerConnected;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SharingManagerが接続されたとき。ArgsはEmpty。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;connectedEvent(this, EventArgs.Empty);
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;これらのeventをsubscribeしているTestsの中のコード。&lt;/p&gt;

&lt;h2 id=&#34;custommessages-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-tests-custommessages-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Tests/CustomMessages.cs&#34;&gt;CustomMessages&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;データを送受信するところ。&lt;/p&gt;

&lt;h3 id=&#34;初期化-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-tests-custommessages-cs-l57&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Tests/CustomMessages.cs#L57&#34;&gt;初期化&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;SharingManagerが接続されたら初期化がはじまる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Start()
{
    SharingStage.Instance.SharingManagerConnected += SharingManagerConnected;
}

private void SharingManagerConnected(object sender, EventArgs e)
{
    InitializeMessageHandlers();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず、ServerとのConnectionを取得し、Messageを受信したときのeventをsubscribeしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SharingStage sharingStage = SharingStage.Instance;
serverConnection = sharingStage.Manager.GetServerConnection();
connectionAdapter = new NetworkConnectionAdapter();
connectionAdapter.MessageReceivedCallback += OnMessageReceived;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それから自分自身のユーザーIDも保存してある。これはMessageを送るときに使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;localUserID = SharingStage.Instance.Manager.GetLocalUser().GetID();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後に&lt;code&gt;MessageHandlers&lt;/code&gt;にnullを詰めて終わり。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (byte index = (byte)TestMessageID.HeadTransform; index &amp;lt; (byte)TestMessageID.Max; index++)
{
    if (MessageHandlers.ContainsKey((TestMessageID)index) == false)
    {
        MessageHandlers.Add((TestMessageID)index, null);
    }

    serverConnection.AddListener(index, connectionAdapter);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後からこういう風にhandlerを設定している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CustomMessages.Instance.MessageHandlers[CustomMessages.TestMessageID.HeadTransform] = this.UpdateHeadTransform;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;受信&#34;&gt;受信&lt;/h3&gt;

&lt;p&gt;messageTypeに対応したhandlerに渡す。初期状態では全てnullなので何もしない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void OnMessageReceived(NetworkConnection connection, NetworkInMessage msg)
{
    byte messageType = msg.ReadByte();
    MessageCallback messageHandler = MessageHandlers[(TestMessageID)messageType];
    if (messageHandler != null)
    {
        messageHandler(msg);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;送信&#34;&gt;送信&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;CustomMessages.Instance.SendStageTransform(transform.localPosition, transform.localRotation);
CustomMessages.Instance.SendHeadTransform(headPosition, headRotation);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じにBroadcastしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void SendHeadTransform(Vector3 position, Quaternion rotation)
{
    // If we are connected to a session, broadcast our head info
    if (serverConnection != null &amp;amp;&amp;amp; serverConnection.IsConnected())
    {
        // Create an outgoing network message to contain all the info we want to send
        NetworkOutMessage msg = CreateMessage((byte)TestMessageID.HeadTransform);

        AppendTransform(msg, position, rotation);

        // Send the message as a broadcast, which will cause the server to forward it to all other users in the session.
        serverConnection.Broadcast(
            msg,
            MessagePriority.Immediate,
            MessageReliability.UnreliableSequenced,
            MessageChannel.Avatar);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;importexportanchormanager-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-tests-importexportanchormanager-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Tests/ImportExportAnchorManager.cs&#34;&gt;ImportExportAnchorManager&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;オブジェクトのpositionを物理的に固定する&lt;a href=&#34;https://docs.unity3d.com/ScriptReference/VR.WSA.WorldAnchor.html&#34;&gt;WorldAnchor&lt;/a&gt;を共有する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;currentState&lt;/code&gt;は最初&lt;code&gt;AnchorStore_Initializing&lt;/code&gt;で、
&lt;code&gt;anchorStore&lt;/code&gt;が取得できたら&lt;code&gt;AnchorStore_Initialized&lt;/code&gt;になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private ImportExportState currentState = ImportExportState.Start;

// インスタンスがロードされたときに呼ばれる。コンストラクターの代わり
protected override void Awake()
{
    base.Awake();
    Debug.Log(&amp;quot;Import Export Manager starting&amp;quot;);
    // We need to get our local anchor store started up.
    currentState = ImportExportState.AnchorStore_Initializing;
    WorldAnchorStore.GetAsync(AnchorStoreReady);
}

private void AnchorStoreReady(WorldAnchorStore store)
{
    anchorStore = store;
    currentState = ImportExportState.AnchorStore_Initialized;
}

private void Start()
{
    SharingStage.Instance.SharingManagerConnected += SharingManagerConnected;
    SharingSessionTracker.Instance.SessionJoined += Instance_SessionJoined;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SharingManagerが接続されたら、RoomManagerのインスタンスを取得して、
Anchorのダウンロードとアップロードしたときのeventをsubscribeしている。&lt;/p&gt;

&lt;p&gt;Uploaded時は&lt;code&gt;currentState&lt;/code&gt;を&lt;code&gt;Ready&lt;/code&gt;にし、
Downloaded時は&lt;code&gt;rawAnchorData&lt;/code&gt;に保存し、&lt;code&gt;currentState&lt;/code&gt;を&lt;code&gt;DataReady&lt;/code&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void SharingManagerConnected(object sender, EventArgs e)
{
    // Setup the room manager callbacks.
    roomManager = SharingStage.Instance.Manager.GetRoomManager();
    roomManagerCallbacks = new RoomManagerAdapter();

    roomManagerCallbacks.AnchorsDownloadedEvent += RoomManagerCallbacks_AnchorsDownloaded;
    roomManagerCallbacks.AnchorUploadedEvent += RoomManagerCallbacks_AnchorUploaded;
    roomManager.AddListener(roomManagerCallbacks);
}

private void RoomManagerCallbacks_AnchorUploaded(bool successful, XString failureReason)
{
    if (successful)
    {
        currentState = ImportExportState.Ready;
    }
    else
    {
        Debug.Log(&amp;quot;Upload failed &amp;quot; + failureReason);
        currentState = ImportExportState.Failed;
    }
}

private byte[] rawAnchorData = null;

private void RoomManagerCallbacks_AnchorsDownloaded(bool successful, AnchorDownloadRequest request, XString failureReason)
{
    // If we downloaded anchor data successfully we should import the data.
    if (successful)
    {
        int datasize = request.GetDataSize();
        Debug.Log(datasize + &amp;quot; bytes &amp;quot;);
        rawAnchorData = new byte[datasize];

        request.GetData(rawAnchorData, datasize);
        currentState = ImportExportState.DataReady;
    }
    else
    {
        // If we failed, we can ask for the data again.
        Debug.Log(&amp;quot;Anchor DL failed &amp;quot; + failureReason);
        MakeAnchorDataRequest();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SessionJoin時には、&lt;code&gt;sharingServiceReady&lt;/code&gt;をtrueにする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;InitRoomApi()&lt;/code&gt;では&lt;code&gt;currentRoom&lt;/code&gt;にJoin(あるいは新しく作る)し、Roomを代入している。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;currentState&lt;/code&gt;は新しくRoomを作った場合&lt;code&gt;InitialAnchorRequired&lt;/code&gt;で、すでにあるRoomに入った場合&lt;code&gt;RoomApiInitialized&lt;/code&gt;になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private bool sharingServiceReady = false;
private Room currentRoom;

private void Instance_SessionJoined(object sender, SharingSessionTracker.SessionJoinedEventArgs e)
{
    SharingSessionTracker.Instance.SessionJoined -= Instance_SessionJoined;

    // ほかの処理が落ち着くまで5秒待って実行する
    Invoke(&amp;quot;MarkSharingServiceReady&amp;quot;, 5);
}

private void MarkSharingServiceReady()
{
    sharingServiceReady = true;

#if UNITY_EDITOR || UNITY_STANDALONE
    InitRoomApi();
#endif
}

private void InitRoomApi()
{
    if (roomManager.GetRoomCount() == 0)
    {
        if (LocalUserHasLowestUserId())
        {
            Debug.Log(&amp;quot;Creating room &amp;quot;);            
            currentRoom = roomManager.CreateRoom(new XString(&amp;quot;DefaultRoom&amp;quot;), roomID, false);
            currentState = ImportExportState.InitialAnchorRequired;
        }
    }
    else
    {
        Debug.Log(&amp;quot;Joining room &amp;quot;);
        currentRoom = roomManager.GetRoom(0);
        roomManager.JoinRoom(currentRoom);
        currentState = ImportExportState.RoomApiInitialized;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Update。ここで&lt;code&gt;currentState&lt;/code&gt;を見ている。ここまでの&lt;code&gt;currentState&lt;/code&gt;をまとめると、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AnchorStore_Initializing: 初期状態&lt;/li&gt;
&lt;li&gt;AnchorStore_Initialized: AnchorStore取得完了&lt;/li&gt;
&lt;li&gt;InitialAnchorRequired: 新しくRoomを作った(のでWorldAnchorを生成する)&lt;/li&gt;
&lt;li&gt;RoomApiInitialized: すでにあるRoomに入った&lt;/li&gt;
&lt;li&gt;Ready: Upload完了&lt;/li&gt;
&lt;li&gt;DataReady: Download完了&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void Update()
{
    switch (currentState)
    {
        case ImportExportState.AnchorStore_Initialized:
            if (sharingServiceReady)
            {
                InitRoomApi();
            }
            break;
        case ImportExportState.RoomApiInitialized:
            StartAnchorProcess();
            break;
        case ImportExportState.DataReady:
            // DataReady is set when the anchor download completes.
            currentState = ImportExportState.Importing;
            WorldAnchorTransferBatch.ImportAsync(rawAnchorData, ImportComplete);
            break;
        case ImportExportState.InitialAnchorRequired:
            currentState = ImportExportState.CreatingInitialAnchor;
            CreateAnchorLocally();
            break;
        case ImportExportState.ReadyToExportInitialAnchor:
            // We&#39;ve created an anchor locally and it is ready to export.
            currentState = ImportExportState.UploadingInitialAnchor;
            Export();
            break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Roomを新しく作ったならWorldAnchorを作成する必要がある。
&lt;a href=&#34;https://docs.unity3d.com/ScriptReference/VR.WSA.WorldAnchor-isLocated.html&#34;&gt;isLocated&lt;/a&gt;がtrueになったら
&lt;code&gt;OnTrackingChanged_InitialAnchor&lt;/code&gt;にし、AnchorをUploadする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void CreateAnchorLocally()
{
    WorldAnchor anchor = GetComponent&amp;lt;WorldAnchor&amp;gt;();
    if (anchor == null)
    {
        anchor = gameObject.AddComponent&amp;lt;WorldAnchor&amp;gt;();
    }

    if (anchor.isLocated)
    {
        currentState = ImportExportState.ReadyToExportInitialAnchor;
    }
    else
    {
        anchor.OnTrackingChanged += Anchor_OnTrackingChanged_InitialAnchor;
    }
}

private void Anchor_OnTrackingChanged_InitialAnchor(WorldAnchor self, bool located)
{
    if (located)
    {
        Debug.Log(&amp;quot;Found anchor, ready to export&amp;quot;);
        currentState = ImportExportState.ReadyToExportInitialAnchor;
    }
    else
    {
        Debug.Log(&amp;quot;Failed to locate local anchor (super bad!)&amp;quot;);
        currentState = ImportExportState.Failed;
    }

    self.OnTrackingChanged -= Anchor_OnTrackingChanged_InitialAnchor;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;anchorStore&lt;/code&gt;に保存して、SerializeしてUploadする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void Export()
{
    WorldAnchor anchor = GetComponent&amp;lt;WorldAnchor&amp;gt;();

    string guidString = Guid.NewGuid().ToString();
    exportingAnchorName = guidString;

    // Save the anchor to our local anchor store.
    if (anchorStore.Save(exportingAnchorName, anchor))
    {
        sharedAnchorInterface = new WorldAnchorTransferBatch();
        sharedAnchorInterface.AddWorldAnchor(guidString, anchor);
        WorldAnchorTransferBatch.ExportAsync(sharedAnchorInterface, WriteBuffer, ExportComplete);
    }
    else
    {
        Debug.Log(&amp;quot;This anchor didn&#39;t work, trying again&amp;quot;);
        currentState = ImportExportState.InitialAnchorRequired;
    }
}

public void ExportComplete(SerializationCompletionReason status)
{
    if (status == SerializationCompletionReason.Succeeded &amp;amp;&amp;amp; exportingAnchorBytes.Count &amp;gt; minTrustworthySerializedAnchorDataSize)
    {
        Debug.Log(&amp;quot;Uploading anchor: &amp;quot; + exportingAnchorName);
        roomManager.UploadAnchor(
            currentRoom,
            new XString(exportingAnchorName),
            exportingAnchorBytes.ToArray(),
            exportingAnchorBytes.Count);
    }
    else
    {
        Debug.Log(&amp;quot;This anchor didn&#39;t work, trying again&amp;quot;);
        currentState = ImportExportState.InitialAnchorRequired;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もしすでにあるRoomにJoinしている(&lt;code&gt;RoomApiInitialized&lt;/code&gt;)なら、Anchorをダウンロードし始め、&lt;code&gt;DataRequested&lt;/code&gt;になる。
ダウンロードしたら&lt;code&gt;DataReady&lt;/code&gt;になって、AnchorデータをImportする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void StartAnchorProcess()
{
    // First, are there any anchors in this room?
    int anchorCount = currentRoom.GetAnchorCount();

    // If there are anchors, we should attach to the first one.
    if (anchorCount &amp;gt; 0)
    {
        // Extract the name of the anchor.
        XString storedAnchorString = currentRoom.GetAnchorName(0);
        string storedAnchorName = storedAnchorString.GetString();

        // Attempt to attach to the anchor in our local anchor store.
        if (AttachToCachedAnchor(storedAnchorName) == false)
        {
            MakeAnchorDataRequest();
        }
    }
}

private void MakeAnchorDataRequest()
{
    if (roomManager.DownloadAnchor(currentRoom, currentRoom.GetAnchorName(0)))
    {
        currentState = ImportExportState.DataRequested;
    }
    else
    {
        Debug.Log(&amp;quot;Couldn&#39;t make the download request.&amp;quot;);
        currentState = ImportExportState.Failed;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Import完了したら&lt;code&gt;anchorStore&lt;/code&gt;に保存し、&lt;code&gt;Ready&lt;/code&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void ImportComplete(SerializationCompletionReason status, WorldAnchorTransferBatch wat)
{
    if (status == SerializationCompletionReason.Succeeded &amp;amp;&amp;amp; wat.GetAllIds().Length &amp;gt; 0)
    {
        Debug.Log(&amp;quot;Import complete&amp;quot;);

        string first = wat.GetAllIds()[0];
        Debug.Log(&amp;quot;Anchor name: &amp;quot; + first);

        WorldAnchor anchor = wat.LockObject(first, gameObject);
        anchorStore.Save(first, anchor);
        currentState = ImportExportState.Ready;
    }
    else
    {
        Debug.Log(&amp;quot;Import fail&amp;quot;);
        currentState = ImportExportState.DataReady;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;remoteheadmanager-https-github-com-microsoft-holotoolkit-unity-blob-v1-5-5-0-assets-holotoolkit-sharing-tests-remoteheadmanager-cs&#34;&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/v1.5.5.0/Assets/HoloToolkit/Sharing/Tests/RemoteHeadManager.cs&#34;&gt;RemoteHeadManager&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;他のユーザーの頭の位置にオブジェクトを表示させる。&lt;/p&gt;

&lt;p&gt;受信時のhandlerを設定し、eventをsubscribeする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Start()
{
    CustomMessages.Instance.MessageHandlers[CustomMessages.TestMessageID.HeadTransform] = this.UpdateHeadTransform;

    SharingSessionTracker.Instance.SessionJoined += Instance_SessionJoined;
    SharingSessionTracker.Instance.SessionLeft += Instance_SessionLeft;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;joinしたのが自分自身じゃないかチェック。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void Instance_SessionJoined(object sender, SharingSessionTracker.SessionJoinedEventArgs e)
{
    if (e.joiningUser.GetID() != SharingStage.Instance.Manager.GetLocalUser().GetID())
    {
        GetRemoteHeadInfo(e.joiningUser.GetID());
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;remoteHeads&lt;/code&gt;になければ、HeadObjectを作成し、追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public RemoteHeadInfo GetRemoteHeadInfo(long userID)
{
    RemoteHeadInfo headInfo;

    // Get the head info if its already in the list, otherwise add it
    if (!this.remoteHeads.TryGetValue(userID, out headInfo))
    {
        headInfo = new RemoteHeadInfo();
        headInfo.UserID = userID;
        headInfo.HeadObject = CreateRemoteHead();

        this.remoteHeads.Add(userID, headInfo);
    }

    return headInfo;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sessionから離れたときはオブジェクトを削除し、remoteHeadsから取り除く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void Instance_SessionLeft(object sender, SharingSessionTracker.SessionLeftEventArgs e)
{
    if (e.exitingUserId != SharingStage.Instance.Manager.GetLocalUser().GetID())
    {
        RemoveRemoteHead(this.remoteHeads[e.exitingUserId].HeadObject);
        this.remoteHeads.Remove(e.exitingUserId);
    }
}

void RemoveRemoteHead(GameObject remoteHeadObject)
{
    DestroyImmediate(remoteHeadObject);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;受信時のhandlerではMessageからpositionとquarternionを取得し、オブジェクトの位置を動かしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void UpdateHeadTransform(NetworkInMessage msg)
{
    // Parse the message
    long userID = msg.ReadInt64();

    Vector3 headPos = CustomMessages.Instance.ReadVector3(msg);

    Quaternion headRot = CustomMessages.Instance.ReadQuaternion(msg);

    RemoteHeadInfo headInfo = GetRemoteHeadInfo(userID);
    headInfo.HeadObject.transform.localPosition = headPos;
    headInfo.HeadObject.transform.localRotation = headRot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自分の頭の位置はUpdate()で送信している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void Update()
{
    // Grab the current head transform and broadcast it to all the other users in the session
    Transform headTransform = Camera.main.transform;

    // Transform the head position and rotation from world space into local space
    Vector3 headPosition = this.transform.InverseTransformPoint(headTransform.position);
    Quaternion headRotation = Quaternion.Inverse(this.transform.rotation) * headTransform.rotation;

    CustomMessages.Instance.SendHeadTransform(headPosition, headRotation);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ライセンス&#34;&gt;ライセンス&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;MIT License

Copyright (c) 2016 Microsoft Corporation

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &amp;quot;Software&amp;quot;), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED &amp;quot;AS IS&amp;quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unixのパイプをmkfifo()で作ってdup2()で標準出力にコピーして書き込む</title>
          <link>https://www.sambaiz.net/article/87/</link>
          <pubDate>Fri, 24 Mar 2017 22:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/87/</guid>
          <description>

&lt;h2 id=&#34;パイプとは&#34;&gt;パイプとは&lt;/h2&gt;

&lt;p&gt;Unixでプロセス間通信するためのもの。シェルで使う&lt;code&gt;|&lt;/code&gt;は無名パイプ。
&lt;code&gt;mkfifo()&lt;/code&gt;システムコールで名前付きパイプを作成でき、これを読み書きすることで任意のプロセス間でやりとりできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkfifo hoge
$ ls -lh
$ prw-r--r-- ... 0B ... hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常のファイルと同様に読み書きすることができ、読み書きどちらかを行おうとすると待つことになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo hoge &amp;amp; # 読まれるまで待つ
$ cat hoge
aaaaa
[1]+  Done                    echo &amp;quot;aaaaa&amp;quot; &amp;gt; hoge

$ cat hoge &amp;amp; # 書かれるまで待つ
$ echo &amp;quot;bbbbb&amp;quot; &amp;gt; hoge
bbbbb
[1]+  Done                    cat hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイルディスクリプタをコピーするシステムコール&lt;code&gt;dup2()&lt;/code&gt;でopenしたパイプを標準出力(1)にコピーしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;

int main(){
  int fd = open(&amp;quot;./hoge&amp;quot;, O_WRONLY);
  if(fd &amp;lt; 0){
    printf(&amp;quot;fail to open\n&amp;quot;);
    return 1;
  }

  printf(&amp;quot;OPEN %d \n&amp;quot;, fd);

  if(dup2(fd, 1) &amp;lt; 0){
    printf(&amp;quot;fail to dup2\n&amp;quot;);
    return 2;
  }

  printf(&amp;quot;WRITE\n&amp;quot;); // これがどこに書き込まれるか

  close(fd);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後のprintfの内容は標準出力ではなく、パイプに書き込まれていることがわかる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./a.out &amp;amp;
$ echo &amp;quot;read `cat hoge` from pipe&amp;quot;
OPEN 3 
read WRITE from pipe
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%83%97_(%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF)#.E3.83.97.E3.83.AD.E3.82.B0.E3.83.A9.E3.83.A0.E3.81.AB.E3.82.88.E3.82.8B.E3.83.91.E3.82.A4.E3.83.97.E3.81.AE.E4.BD.9C.E6.88.90&#34;&gt;パイプ (コンピュータ) - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/richmikan@github/items/bb660a58690ac01ec295&#34;&gt;mkfifoコマンドって使ってますか？ - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/stc1988/items/9354204d3c2ff210512b&#34;&gt;リダイレクトの挙動 - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CuratorでElasticsearchの古いindexを削除する</title>
          <link>https://www.sambaiz.net/article/86/</link>
          <pubDate>Wed, 22 Mar 2017 00:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/86/</guid>
          <description>

&lt;h2 id=&#34;curatorとは-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-index-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html&#34;&gt;Curatorとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;indexやsnapshotを管理するのに使えるツール。&lt;/p&gt;

&lt;h2 id=&#34;インストール-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-installation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/installation.html&#34;&gt;インストール&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;インストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/yum.repos.d/curator.repo
[curator-4]
name=CentOS/RHEL 7 repository for Elasticsearch Curator 4.x packages
baseurl=http://packages.elastic.co/curator/4/centos/7
gpgcheck=1
gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch
enabled=1

$ yum install -y elasticsearch-curator
$ curator --version
curator, version 4.2.6
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;config-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-configfile-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/configfile.html&#34;&gt;config&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;configファイルを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;client:
  hosts:
    - 127.0.0.1
  port: 9200

logging:
  loglevel: INFO
  logfile:
  logformat: default
  blacklist: [&#39;elasticsearch&#39;, &#39;urllib3&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;action-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-actions-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/actions.html&#34;&gt;action&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;今回はindexを削除するので&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/ex_delete_indices.html&#34;&gt;delete_indices&lt;/a&gt;。
対象は&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/filters.html&#34;&gt;filter&lt;/a&gt;で指定する。
logstash formatだとhogehoge-2017.01.01のようなindex名になるので&lt;code&gt;%Y.%m.%d&lt;/code&gt;。&lt;code&gt;okder than 3 days&lt;/code&gt;のものを削除する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;actions:
  1:
    action: delete_indices
    description: &amp;gt;-
      3日前より古いhogehoge-* indexを消す
    filters:
    - filtertype: pattern
      kind: prefix
      value: hogehoge-
    - filtertype: age
      source: name
      direction: older
      timestring: &#39;%Y.%m.%d&#39;
      unit: days
      unit_count: 3
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-command-line-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/client/curator/current/command-line.html&#34;&gt;実行&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;configとactionファイルを指定して実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curator --config curator_config.yml curator_action.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;毎日00:05に実行するようにしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ crontab -l
5 0 * * * curator --config curator_config.yml curator_action.yml
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>RxJSでRxをはじめる</title>
          <link>https://www.sambaiz.net/article/85/</link>
          <pubDate>Sat, 18 Mar 2017 21:36:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/85/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/ReactiveX/rxjs&#34;&gt;https://github.com/ReactiveX/rxjs&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;rx-reactivex-とは-http-reactivex-io-intro-html&#34;&gt;&lt;a href=&#34;http://reactivex.io/intro.html&#34;&gt;Rx(ReactiveX)とは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;非同期処理をうまく扱えるようにするライブラリ。いろんな言語で実装されている。
非同期処理の結果はObservableなStreamに流される。
ObservableはIteratableのように扱うことができる。&lt;/p&gt;

&lt;p&gt;Rxは&lt;a href=&#34;https://en.wikipedia.org/wiki/Observer_pattern&#34;&gt;Observer pattern&lt;/a&gt;
を拡張したもの。
Observer patternというのは、Subjectが、Observeしている全てのObserverに対して通知を送るデザインパターン。
C#などのeventのそれ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/83/&#34;&gt;C#のdelegateとevent - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;試してみる&#34;&gt;試してみる&lt;/h2&gt;

&lt;p&gt;inputのkeyupイベントのObservableを作成し、それを&lt;code&gt;subscribe()&lt;/code&gt;して出力している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;script src=&amp;quot;https://cdnjs.cloudflare.com/ajax/libs/rxjs/5.0.1/Rx.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;

&amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;input&amp;quot; /&amp;gt;

&amp;lt;script&amp;gt;

const inputForm = document.querySelector(&#39;#input&#39;);

const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;);

keyups.subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; console.log(err)
);

&amp;lt;/script&amp;gt;

&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入力するとこんなのが出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;KeyboardEvent {isTrusted: true, key: &amp;quot;a&amp;quot;, code: &amp;quot;KeyA&amp;quot;, location: 0, ctrlKey: false…}
KeyboardEvent {isTrusted: true, key: &amp;quot;b&amp;quot;, code: &amp;quot;KeyB&amp;quot;, location: 0, ctrlKey: false…}
KeyboardEvent {isTrusted: true, key: &amp;quot;c&amp;quot;, code: &amp;quot;KeyC&amp;quot;, location: 0, ctrlKey: false…}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;observable-http-reactivex-io-rxjs-class-es6-observable-js-observable-html&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html&#34;&gt;Observable&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;create-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-create&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-create&#34;&gt;create&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;next()&lt;/code&gt;でObservableに値をemitし、&lt;code&gt;complete()&lt;/code&gt;で終了させる。
&lt;code&gt;error()&lt;/code&gt;でエラーをemitするとそれ以後の値はemitされない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.create(function (observer) {
    observer.next(&amp;quot;AAAAA&amp;quot;);
    observer.next(&amp;quot;BBBBB&amp;quot;);
    observer.next(&amp;quot;CCCCC&amp;quot;);
    observer.complete();
}).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;AAAA
BBBB
CCCC
completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;from-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-from&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-from&#34;&gt;from&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;配列などのIteratableをObservableに変換する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.from([1,2,3]).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1
2
3
completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;fromevent-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-fromevent&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-fromEvent&#34;&gt;fromEvent&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;上で使ったやつ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.fromEvent(document.querySelector(&#39;#input&#39;), &#39;keyup&#39;).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;KeyboardEvent {isTrusted: true, key: &amp;quot;a&amp;quot;, code: &amp;quot;KeyA&amp;quot;, location: 0, ctrlKey: false…}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;frompromise-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-frompromise&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-fromPromise&#34;&gt;fromPromise&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;PromiseもObservableに変換できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.fromPromise(Promise.resolve(&amp;quot;ok&amp;quot;)).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ok
completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;interval-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-static-method-interval&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#static-method-interval&#34;&gt;interval&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;一定時間ごとにemitし続ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rx.Observable.interval(1000).subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0
1
2
3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/100/&#34;&gt;RxJSでObservableを結合する(merge, forkJoin, concat, combineLatest) - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;operator-http-reactivex-io-rxjs-manual-overview-html-operators&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/manual/overview.html#operators&#34;&gt;Operator&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Observableのメソッド。新しいObservableを作って返す。&lt;/p&gt;

&lt;p&gt;上で試したkeyupのObservableにいろいろやってみる。&lt;/p&gt;

&lt;h3 id=&#34;pluck-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-pluck&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-pluck&#34;&gt;pluck&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;nestされたプロパティを指定する。この例だと&lt;code&gt;.target.value&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;)
  .pluck(&#39;target&#39;, &#39;value&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;h
ho
hog
hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;filter-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-filter&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-filter&#34;&gt;filter&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;フィルタリングする。この例だと長さが2より大きいものだけがemitされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;)
  .pluck(&#39;target&#39;, &#39;value&#39;)
  .filter(text =&amp;gt; text.length &amp;gt; 2 );
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;hog
hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;map-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-map&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-map&#34;&gt;map&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;map。この例だと&lt;code&gt;value: ${text}&lt;/code&gt;のフォーマットでemitされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;)
  .pluck(&#39;target&#39;, &#39;value&#39;)
  .filter(text =&amp;gt; text.length &amp;gt; 2 )
  .map(text =&amp;gt; `value: ${text}`);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;value: hog
value: hoge
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;reduce-http-reactivex-io-rxjs-class-es6-observable-js-observable-html-instance-method-reduce&#34;&gt;&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-reduce&#34;&gt;reduce&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;reduce。emitされるのはcompleteされたときなので、&lt;a href=&#34;http://reactivex.io/rxjs/class/es6/Observable.js~Observable.html#instance-method-takeUntil&#34;&gt;takeUntil()&lt;/a&gt;で
渡したObservableが何かemitしたときにcompleteさせるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const keyups = Rx.Observable.fromEvent(inputForm, &#39;keyup&#39;)
  .takeUntil(Rx.Observable.interval(5000))
  .pluck(&#39;target&#39;, &#39;value&#39;)
  .filter(text =&amp;gt; text.length &amp;gt; 2 )
  .map(text =&amp;gt; `value: ${text}`)
  .reduce((acc, curr) =&amp;gt; `${acc} ${curr}`, &amp;quot;&amp;quot;);

keyups.subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; console.log(err),
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; value: aaa value: aaaa value: aaaaa value: aaaaaa value: aaaaaaa value: aaaaaaaa value: aaaaaaaaa value: aaaaaaaaaa value: aaaaaaaaaaa
 completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;subject-http-reactivex-io-documentation-subject-html&#34;&gt;&lt;a href=&#34;http://reactivex.io/documentation/subject.html&#34;&gt;Subject&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Observerでもあり、Observableでもあるブリッジのようなもの。&lt;/p&gt;

&lt;p&gt;これまでのObservableはSubscribeされるまでemitしない&amp;rdquo;Cold&amp;rdquo;なものだったが、
SubjectはそんなObservableをSubscribeし、それをトリガーにemitするので、
&amp;ldquo;Cold&amp;rdquo;なObservableを常にemitし得る&amp;rdquo;Hot&amp;rdquo;なものに変えることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// ColdなObservable
const cold = Rx.Observable.from([1,2,3]);

// Coldだと、いつから、何回読んでも同じ値が得られる

// 1, 2, 3, completed
cold.subscribe(
  data =&amp;gt; console.log(data),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);

// 1, 2, 3, completed
cold.subscribe(
  data =&amp;gt; console.log(data), 
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;publish-subject&#34;&gt;(Publish)Subject&lt;/h3&gt;

&lt;p&gt;Subscribeした時点からemitされたアイテムをemitする。それまでにemitされたアイテムはしない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const subject = new Rx.Subject(); 

subject.subscribe(
  data =&amp;gt; console.log(`1: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;1: completed&amp;quot;)
);

subject.next(&amp;quot;AAA&amp;quot;) // 1: AAA

subject.subscribe(
  data =&amp;gt; console.log(`2: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;2: completed&amp;quot;)
);

subject.next(&amp;quot;BBB&amp;quot;); 

subject.complete(); 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1: AAA
1: BBB
2: BBB
1: completed
2: completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;asyncsubject&#34;&gt;AsyncSubject&lt;/h3&gt;

&lt;p&gt;complete時に最後にemitされた値だけをemitする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const subject = new Rx.AsyncSubject();

subject.subscribe(
  data =&amp;gt; console.log(`1: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;1: completed&amp;quot;)
);

subject.next(&amp;quot;AAA&amp;quot;); 
subject.next(&amp;quot;BBB&amp;quot;);

subject.complete();

subject.subscribe(
  data =&amp;gt; console.log(`2: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;2: completed&amp;quot;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1: BBB
1: completed
2: BBB
2: completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;behaviorsubject&#34;&gt;BehaviorSubject&lt;/h3&gt;

&lt;p&gt;Subscribeしたとき、最近のアイテムをemitする。あとはSubjectと同じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const subject = new Rx.BehaviorSubject(&amp;quot;ZZZ&amp;quot;)

subject.subscribe(
  data =&amp;gt; console.log(`1: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;1: completed&amp;quot;)
);

subject.next(&amp;quot;AAA&amp;quot;);
subject.next(&amp;quot;BBB&amp;quot;);

subject.subscribe(
  data =&amp;gt; console.log(`2: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;2: completed&amp;quot;)
);

subject.next(&amp;quot;CCC&amp;quot;); 

subject.complete(); 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1: ZZZ
1: AAA
1: BBB
2: BBB
1: CCC
2: CCC
1: completed
2: completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;replaysubject&#34;&gt;ReplaySubject&lt;/h3&gt;

&lt;p&gt;いつSubscribeしてもbufferにある全てのアイテムをemitする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const subject = new Rx.ReplaySubject(2) // buffer size = 2

subject.subscribe(
  data =&amp;gt; console.log(`1: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;1: completed&amp;quot;)
);

subject.next(&amp;quot;AAA&amp;quot;);
subject.next(&amp;quot;BBB&amp;quot;);
subject.next(&amp;quot;CCC&amp;quot;);
subject.next(&amp;quot;DDD&amp;quot;);

subject.subscribe(
  data =&amp;gt; console.log(`2: ${data}`),
  err =&amp;gt; {},
  () =&amp;gt; console.log(&amp;quot;2: completed&amp;quot;)
);

subject.complete(); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;buffer size = 2 なので2がSubscribeしたときにはAAAとBBBはもうない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1: AAA
1: BBB
1: CCC
1: DDD
2: CCC
2: DDD
1: completed
2: completed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/wilfrem/tech-rxjs&#34;&gt;歌舞伎座tech発表資料 RxJSの中を追う&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ</title>
          <link>https://www.sambaiz.net/article/84/</link>
          <pubDate>Wed, 15 Mar 2017 23:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/84/</guid>
          <description>

&lt;h2 id=&#34;kpl-kinesis-producer-library-とは&#34;&gt;KPL(Kinesis Producer Library)とは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-kpl.html&#34;&gt;Developing Amazon Kinesis Streams Producers Using the Amazon Kinesis Producer Library - Amazon Kinesis Streams&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kinesisに送るとき、自動リトライしてくれたり、レコードをまとめてスループットを向上してくれたりするアプリケーション。Protobufを使っている。
普通に送るとどんなに小さくてもシャード*1000レコード/秒しか最大でPUTできないのを、KPLを使ってまとめることで増やすことができる。&lt;/p&gt;

&lt;h2 id=&#34;fluentdで送る&#34;&gt;fluentdで送る&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;で&lt;code&gt;kinesis_producer&lt;/code&gt;を指定するとKPLを使って送信する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;kinesis_producer&amp;gt;&lt;/code&gt;の中にKPLの設定を書くことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;kinesis_producer&amp;gt;
    record_max_buffered_time 10
&amp;lt;/kinesis_producer&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L239&#34;&gt;record_max_bufferd_time&lt;/a&gt;
はバッファされたレコードが送られるまでの最大時間(ms)。デフォルトは100ms。この時間が経つか、他のリミットに当たったらレコードは送られる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L30&#34;&gt;AggregationMaxCount&lt;/a&gt;: 一つのレコードにまとめる最大レコード数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L44&#34;&gt;AggregationMaxSize&lt;/a&gt;: まとめたレコードの最大バイト数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L54&#34;&gt;CollectionMaxCount&lt;/a&gt;: PutRecordsで送る最大アイテム数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L67&#34;&gt;CollectionMaxSize&lt;/a&gt;: PutRecordsで送るデータ量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CloudWatchに送る&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L158&#34;&gt;metrics_level&lt;/a&gt;はデフォルトでdetailedになっていて、
コンソールのメトリクスからstream名で検索すると
&lt;code&gt;KinesisProducerLibrary&lt;/code&gt;に&lt;code&gt;UserRecordsPerKinesisRecord&lt;/code&gt;や、&lt;code&gt;UserRecordsDataPut&lt;/code&gt;、&lt;code&gt;BufferingTime&lt;/code&gt;、&lt;code&gt;RequestTime&lt;/code&gt;などいろいろ表示される。&lt;/p&gt;

&lt;p&gt;とりあえず試しにこんな設定で送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match hoge.log&amp;gt;
  @type kinesis_producer
  region ap-northeast-1
  stream_name teststream
  include_time_key true

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lambdaで読む&#34;&gt;Lambdaで読む&lt;/h2&gt;

&lt;p&gt;まとめられたレコードを&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation&#34;&gt;kinesis-aggregation&lt;/a&gt;で分解して読む。
今回は&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation/tree/master/node&#34;&gt;Node.js&lt;/a&gt;でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save aws-kinesis-agg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意する必要があるのは&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation/issues/16&#34;&gt;ドキュメントの情報が古く&lt;/a&gt;て、
関数の引数が足りないこと。第二引数のcomputeChecksumsが抜けているので気付かないと一つずつずれていくことになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;use strict&#39;;

const agg = require(&#39;aws-kinesis-agg&#39;);

exports.handler = (event, context, callback) =&amp;gt; {
    Promise.all(
        event.Records.map(
            (record) =&amp;gt; deaggregate(record)
        )
    ).then(
        (records) =&amp;gt; {
            // LambdaのNode.jsはまだ4.3なのでSpread operatorが使えない・・・
            // const message = `${[].concat(...records).length} came in`; 
            let sumCount = 0;
            records.forEach((r) =&amp;gt; sumCount += r.length);
            const message = `${records.length} aggregated records and ${sumCount} records come in`; 
            console.log(message);
            callback(null, message);
        },
        (err) =&amp;gt; callback(err)
    );
};

function deaggregate(record){
    return new Promise((resolve, reject) =&amp;gt; {
        agg.deaggregateSync(record.kinesis, true, (err, userRecords) =&amp;gt; {
            if (err) {
                reject(err);
            } else {
                resolve(userRecords);
            }
        });
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;175レコードが10レコードにまとめられた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10 aggregated records and 175 records come in
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/high-throughput-messaging-system-with-kinesis-kpl-fluentd-lambda/&#34;&gt;Kinesis Producer Library(KPL)とfluentdとLambdaを連携してKinesisのスループットを上げる ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>C#のdelegateとevent</title>
          <link>https://www.sambaiz.net/article/83/</link>
          <pubDate>Sun, 12 Mar 2017 21:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/83/</guid>
          <description>

&lt;h2 id=&#34;delegate-https-msdn-microsoft-com-ja-jp-library-900fyy8e-aspx&#34;&gt;&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/900fyy8e.aspx&#34;&gt;delegate&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;カプセル化するためのdelegate(移譲)メソッドに使う型。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Converter{

	private static double defaultConvert(double num){
		return num;
	}

	public delegate double Convert(double num);
	public Convert convert = defaultConvert;

	public double run(double num){
		return convert (num);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;匿名メソッドやラムダ式を渡すこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var conv = new Converter ();

print (conv.run (2)); // 2

// 匿名メソッドの例
conv.convert = delegate(double input)
{
    return input + 1;
};
print (conv.run (2)); // 2 + 1 = 3

// ラムダ式の例
conv.convert = s =&amp;gt; s * s;
print (conv.run(2)); // 2 * 2 = 4
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;event-https-msdn-microsoft-com-ja-jp-library-8627sbea-aspx&#34;&gt;&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/8627sbea.aspx&#34;&gt;event&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;宣言元でしか呼べないマルチキャストデリゲート。&lt;code&gt;+=&lt;/code&gt;でsubscribeして&lt;code&gt;-=&lt;/code&gt;で解除する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public delegate void RunEventHandler(double num);
public event RunEventHandler RunEvent;

public double run(double num){
    if (RunEvent != null) {
        RunEvent (num);
    }
    return convert (num);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;subscribeしたものは全て呼ばれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void runHook(double num){
    print(&amp;quot;b: &amp;quot; +  num);
}

var conv = new Converter ();
conv.RunEvent += s =&amp;gt; print (&amp;quot;a: &amp;quot; +  s); // Subscribe a
conv.run (2); // a: 2

conv.RunEvent += runHook; // Subscribe b
conv.run (3); // a: 3, b: 3

conv.RunEvent -= runHook; // Unsubscribe b
conv.run (4); // a: 4

// error
// conv.RunEvent (); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.NET Frameworkのクラスライブラリの全てのイベントでは
&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/db0etb8x.aspx&#34;&gt;EventHandler&lt;TEventArgs&gt;&lt;/a&gt;を使っていて、
ユーザー定義のコードでもこのパターンを使うのが&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/w369ty8x.aspx&#34;&gt;推奨されている&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public delegate void EventHandler&amp;lt;TEventArgs&amp;gt;(
	object sender,
	TEventArgs e
)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのMaterial</title>
          <link>https://www.sambaiz.net/article/82/</link>
          <pubDate>Sat, 11 Mar 2017 20:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/82/</guid>
          <description>

&lt;h2 id=&#34;materialとshaderとtexture-https-docs-unity3d-com-550-documentation-manual-shaders-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/Shaders.html&#34;&gt;MaterialとShaderとTexture&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Materialは表面がどのようにレダリングされるかを定義するもの。
Shaderを指定し、Textureなどのパラメーターを設定する。&lt;/p&gt;

&lt;p&gt;Shaderは光と、Materialの設定から、ピクセルの色を計算するスクリプト。
大体&lt;a href=&#34;https://docs.unity3d.com/550/Documentation/Manual/shader-StandardShader.html&#34;&gt;Standard Shader&lt;/a&gt;
で事足りるらしい。&lt;/p&gt;

&lt;p&gt;Textureはビットマップイメージ。色(Albedo)だけではなく、反射率や粗さなど、いろんな要素に使える。&lt;/p&gt;

&lt;h2 id=&#34;standard-shader&#34;&gt;Standard Shader&lt;/h2&gt;

&lt;h3 id=&#34;rendering-mode-https-docs-unity3d-com-manual-standardshadermaterialparameterrenderingmode-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/Manual/StandardShaderMaterialParameterRenderingMode.html&#34;&gt;Rendering Mode&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Albedoは(255, 255, 255, 255)で、テクスチャにはDefault Particleを指定している。
透明度はテクスチャのアルファチャンネルとAlbedoのアルファ値に基づく。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-defaultparticle.png&#34; alt=&#34;Default Particle&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Opaque: デフォルト。すべて不透明。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-opaque.png&#34; alt=&#34;Opaque&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CutOut: 閾値を境に、完全に透明か、不透明になる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Alpha Cutoffを0.1にした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-cutout.png&#34; alt=&#34;CutOut&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Transparent: 透明度が適用される。現実世界の透明なマテリアルのように、反射のハイライトは完全に表示される。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-transparent.png&#34; alt=&#34;Transparent&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fade: ハイライトにも透明度を適用する。フェードイン/アウトしたいときに使う。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-fade.png&#34; alt=&#34;Fade&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;metallic&#34;&gt;Metallic&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/StandardShaderMaterialCharts.html&#34;&gt;マテリアルチャート&lt;/a&gt;をもとにAlbedoとMetallicとSmoothnessを設定する。&lt;/p&gt;

&lt;p&gt;これは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Albedo: (255, 255, 255, 255)&lt;/li&gt;
&lt;li&gt;Metallic: 1&lt;/li&gt;
&lt;li&gt;Smoothness: 0.68&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;を設定している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/82-metal.png&#34; alt=&#34;Metallic&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのUI</title>
          <link>https://www.sambaiz.net/article/81/</link>
          <pubDate>Wed, 08 Mar 2017 16:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/81/</guid>
          <description>

&lt;h2 id=&#34;canvas-https-docs-unity3d-com-ja-540-scriptreference-canvas-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/540/ScriptReference/Canvas.html&#34;&gt;Canvas&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;UI要素を配置するための領域。&lt;/p&gt;

&lt;h3 id=&#34;rendermode-https-docs-unity3d-com-jp-540-manual-uicanvas-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/UICanvas.html&#34;&gt;renderMode&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Overlay: スクリーンに対してオーバーレイするように表示&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Camera: Cameraから指定した距離(planeDistance)離れた前方に表示&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;World Space 他のオブジェクトと同じように表示&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;canvas-scaler-https-docs-unity3d-com-jp-540-manual-script-canvasscaler-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/script-CanvasScaler.html&#34;&gt;Canvas Scaler&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;UI Scale Mode (World Space以外)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Constant Pixel Size: 画面サイズに関わらず同じピクセル数にする&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Scale With Screen Size: 画面サイズでスケールさせる&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Constant Physical Size 解像度や画面サイズによらず物理的に同じサイズにする&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dynami Pixels Per Unit (World Spaceのみ): Textなどの動的に生成されたビットマップの解像度&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1と3でそれぞれこんな感じになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/81-ppu1.png&#34; alt=&#34;Dynamic Pixels Per Unitが1のとき&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/81-ppu3.png&#34; alt=&#34;Dynamic Pixels Per Unitが3のとき&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;autolayout-https-docs-unity3d-com-ja-540-manual-comp-uiautolayout-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/comp-UIAutoLayout.html&#34;&gt;AutoLayout&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/script-VerticalLayoutGroup.html&#34;&gt;Vertical Layout Group&lt;/a&gt;や
&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/script-GridLayoutGroup.html&#34;&gt;Grid Layout Group&lt;/a&gt;
など。これらのComponentを追加すると子要素のTransform(の一部)が自動で設定される。&lt;/p&gt;

&lt;h3 id=&#34;content-size-fitter-https-docs-unity3d-com-ja-540-manual-script-contentsizefitter-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/540/Manual/script-ContentSizeFitter.html&#34;&gt;Content Size Fitter&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Layout Component要素に合うように自動で調整される。&lt;/p&gt;

&lt;h2 id=&#34;レイアウトを作る-https-docs-unity3d-com-jp-540-manual-uibasiclayout-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/Manual/UIBasicLayout.html&#34;&gt;レイアウトを作る&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;RectTool(ツールバーボタンの一番右の四角いやつ)を選択して、Pivot, Localにするとよい。
Canvasにいろいろ置いていって、Anchorを選んでRect Transformを設定していく。
あとはPrefabにしてInstantiateするなりして表示する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine.UI;

public GameObject dialogWindow;
var obj = Instantiate(obj, new Vector3(0, 0, 200), Quaternion.identity);

var hogeText = obj.transform.Find(&amp;quot;panel/hoge&amp;quot;).gameObject.GetComponent&amp;lt;Text&amp;gt;();
hogeText.text = &amp;quot;fuga&amp;quot;;

var fugaButton = obj.transform.Find(&amp;quot;panel/fuga&amp;quot;).gameObject.GetComponent&amp;lt;Button&amp;gt;();
fugaButton.onClick.AddListener (() =&amp;gt; {
    Debug.Log (&amp;quot;onClick&amp;quot;);
});
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityのTransform</title>
          <link>https://www.sambaiz.net/article/80/</link>
          <pubDate>Tue, 07 Mar 2017 02:11:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/80/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/current/ScriptReference/Transform.html&#34;&gt;https://docs.unity3d.com/jp/current/ScriptReference/Transform.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトの位置、スケール、回転を保持する。親子関係を持つ。&lt;/p&gt;

&lt;h2 id=&#34;position&#34;&gt;Position&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-position.html&#34;&gt;position&lt;/a&gt;がワールド空間の、
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-localPosition.html&#34;&gt;localPosition&lt;/a&gt;
が親から見た相対的なローカル空間の位置。localPositionの1unitはscaleに依存する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.position = new Vector3(0, 0, 0);
transform.localPosition = new Vector3(0, 0, 0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;徐々に移動するには&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.Translate.html&#34;&gt;Translate()&lt;/a&gt;を使う。
最後の引数はデフォルトで&lt;code&gt;Space.Self&lt;/code&gt;になっていて、&lt;code&gt;Space.World&lt;/code&gt;を指定するとワールド座標を基準にする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Time-deltaTime.html&#34;&gt;Time.deltaTime&lt;/a&gt;は最後のフレームを完了するのにかかった秒数。
なのでフレームレートにかかわらず同じ速度で移動させることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.Translate(0, Time.deltaTime, 0, Space.World);
transform.Translate(Vector3.up * Time.deltaTime, Space.World); // 軸に沿って移動
transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform); // 最後の引数のローカル座標を基準にする
transform.Translate(Time.deltaTime, 0, 0, Camera.main.transform);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;scale&#34;&gt;Scale&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-localScale.html&#34;&gt;localScale&lt;/a&gt;
はローカル空間のスケール。ワールド空間のScaleはない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.localScale = new Vector3(0.1f, 1f, 1f);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rotation&#34;&gt;Rotation&lt;/h2&gt;

&lt;p&gt;ワールド空間の
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-rotation.html&#34;&gt;rotation&lt;/a&gt;と
ローカル空間の
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform-localRotation.html&#34;&gt;localRoation&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Unityは&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Quaternion.html&#34;&gt;Quarternion&lt;/a&gt;(四元数)で回転を持っている。
実際はQuarternionそのものを自分で計算することはなく、
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Quaternion.LookRotation.html&#34;&gt;Quaternion.LookRotation()&lt;/a&gt;や
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Quaternion.Euler.html&#34;&gt;Quaternion.Euler()&lt;/a&gt;などを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Vector3 relativePos;
transform.rotation = Quaternion.LookRotation(relativePos); // そのPointを向くように回転
transform.localRotation = Quaternion.Euler(0, 30, 0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Transformを向くように回転する場合は
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.LookAt.html&#34;&gt;LookAt()&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Transform target;
transform.LookAt(target);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;徐々に回転させるには&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.Rotate.html&#34;&gt;Rotate()&lt;/a&gt;を使う。
最後の引数はデフォルトで&lt;code&gt;Space.Self&lt;/code&gt;で、&lt;code&gt;Space.World&lt;/code&gt;を指定すると回転の軸がワールドの軸になる。指定するのは角度。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.Rotate(0, Time.deltaTime, 0, Space.World);
transform.Rotate(Vector3.up, Time.deltaTime, Space.World);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ワールド座標のあるPointを中心として回転させる場合は
&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.RotateAround.html&#34;&gt;RotateAround()&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transform.RotateAround(Vector3.zero, Vector3.up, 20 * Time.deltaTime);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;parent-https-docs-unity3d-com-jp-current-scriptreference-transform-parent-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/current/ScriptReference/Transform-parent.html&#34;&gt;parent&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;親を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var fuga = GameObject.CreatePrimitive (PrimitiveType.Cube);
fuga.transform.parent = hoge.transform;
fuga.transform.parent = null; // detach
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;find-https-docs-unity3d-com-jp-540-scriptreference-transform-find-html&#34;&gt;&lt;a href=&#34;https://docs.unity3d.com/jp/540/ScriptReference/Transform.Find.html&#34;&gt;Find&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;子の名前で検索する。
FindChildもあるけどドキュメントに書いてないので使わない方がよさそう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var child = transform.Find(&amp;quot;hoge/fuga&amp;quot;)
if(child != null){
    child.gameObject
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Moment.jsでNode.jsのDateを任意のフォーマットの文字列にする</title>
          <link>https://www.sambaiz.net/article/79/</link>
          <pubDate>Mon, 06 Mar 2017 20:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/79/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://momentjs.com/&#34;&gt;Moment.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;相対時間(&lt;code&gt;5 years ago&lt;/code&gt;)を出したり、日付の計算(&lt;code&gt;add(3, &#39;days&#39;)&lt;/code&gt;)もできる便利なライブラリ。
ブラウザでも使える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install moment
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;const moment = require(&#39;moment&#39;)
const jst = +9
let now = moment().utcOffset(jst).format(&amp;quot;YYYY-MM-DD HH:mm:ss.SSSZ&amp;quot;);
console.log(now);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ TZ=Africa/Ouagadougou node main.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mutableなのでadd()などの操作で元の値が変わってしまうのに注意。
変わると困る場合clone()する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let now2 = moment();
let now3 = now2.clone();
console.log(now2);
console.log(now2.add(1, &#39;days&#39;));
console.log(now2);
console.log(now3);
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Unityと.NETとMono</title>
          <link>https://www.sambaiz.net/article/78/</link>
          <pubDate>Sun, 05 Mar 2017 18:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/78/</guid>
          <description>

&lt;p&gt;.NETとかよくわからなかったのでまとめてみた。&lt;/p&gt;

&lt;h2 id=&#34;net-framework&#34;&gt;.NET Framework&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/.NET_Framework&#34;&gt;.NET Framework - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Microsoftが開発したアプリケーション開発、実行環境。&lt;/p&gt;

&lt;p&gt;各言語のコンパイラによって言語、環境によらない共通の中間言語(CIL, Common Intermediate Language)バイナリ(exeやdll)に変換し、
実行時に共通言語基盤(CLI, Common Language Infrastructure)の仮想実行システム(VES)が環境依存の機械語を動的に生成(JIT, Just in time)する。
CLIの仕様はECMAで標準化されていて、Microsoftが実装したCLIが共通言語ランタイム(CLR)。Windowsでしか動かない。&lt;/p&gt;

&lt;h2 id=&#34;net-core&#34;&gt;.NET Core&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/magazine/mt694084.aspx&#34;&gt;.NET Core - .NET Core による .NET のクロスプラットフォームへの移行&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Microsoft/dotnet&#34;&gt;Microsoft/dotnet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;オープンソースで、クロスプラットフォームに対応した.NET。CoreCLRはWindowsだけではなくMacやLinuxでも動く。
.NET Frameworkと共通のAPIもあるが、GUIまわりでどちらかにしかないAPIが存在する。&lt;/p&gt;

&lt;h2 id=&#34;mono-http-www-mono-project-com&#34;&gt;&lt;a href=&#34;http://www.mono-project.com/&#34;&gt;Mono&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;オープンソースで、クロスプラットフォームな.NET Framework互換ソフトウェア。C#のコンパイラとCLIが実装されている。
Unityはこれを使っているが、バージョンが古くて使えないライブラリがある。&lt;/p&gt;

&lt;h2 id=&#34;net-coreでhello-world&#34;&gt;.NET CoreでHello World&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/net/core#macos&#34;&gt;インストール手順&lt;/a&gt;に沿って
&lt;code&gt;dotnet&lt;/code&gt;コマンドを使えるようにする。&lt;/p&gt;

&lt;p&gt;Hello Worldまで。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ dotnet console -o hwapp
$ cd hwapp
$ ls
Program.cs	hwapp.csproj

$ dotnet restore
$ ls
Program.cs	hwapp.csproj	obj

$ ls obj
hwapp.csproj.nuget.g.props	project.assets.json
hwapp.csproj.nuget.g.targets

# dotnet build
$ dotnet run
Hello World!

$ dotnet bin/Debug/netcoreapp1.1/hwapp.dll 
Hello World!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;特に.NET CoreにしかないAPIも使っていないのでmono(.NET Framework)ででも実行できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Program.cs 
using System;

namespace hwapp
{
    class Program
    {
        static void Main(string[] args)
        {
            Console.WriteLine(&amp;quot;Hello World!&amp;quot;);
        }
    }
}

$ mono bin/Debug/netcoreapp1.1/hwapp.dll 
Hello World!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/AimingStudy/unitynet&#34;&gt;Unityと.NET&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Elasticsearchで期間ごとの集計値を出す</title>
          <link>https://www.sambaiz.net/article/77/</link>
          <pubDate>Sun, 05 Mar 2017 01:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/77/</guid>
          <description>

&lt;p&gt;Bucket(SQLでいうGROUP BY)にまとめて(Bucket Aggreagtion)、集計(Metric Aggregation)する。&lt;/p&gt;

&lt;p&gt;使うデータは&lt;a href=&#34;https://www.sambaiz.net/article/76/&#34;&gt;作ったツール&lt;/a&gt;で生成したこんなの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bucket-aggregations-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-bucket-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket.html&#34;&gt;Bucket Aggregations&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;date-range-aggregation-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-bucket-daterange-aggregation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket-daterange-aggregation.html&#34;&gt;Date Range Aggregation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;date_range&lt;/code&gt;で期間のBucketを作る。この例だと今から10分前の00秒~今の分の00秒まで。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d&#39;
{
    &amp;quot;aggs&amp;quot;: {
        &amp;quot;range_10minutes&amp;quot;: {
            &amp;quot;date_range&amp;quot;: {
                &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;,
                &amp;quot;format&amp;quot;: &amp;quot;HH-mm-ssZ&amp;quot;,
                &amp;quot;ranges&amp;quot;: [                               
                    { &amp;quot;to&amp;quot;: &amp;quot;now/m&amp;quot;, &amp;quot;from&amp;quot;: &amp;quot;now-10m/m&amp;quot; }
                ]
            }
        }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;range_10minutes&amp;quot;: {
    &amp;quot;buckets&amp;quot;: [
      {
        &amp;quot;key&amp;quot;: &amp;quot;15-17+0000-15-27+0000&amp;quot;,
        &amp;quot;from&amp;quot;: 1488640620000,
        &amp;quot;from_as_string&amp;quot;: &amp;quot;15-17+0000&amp;quot;,
        &amp;quot;to&amp;quot;: 1488641220000,
        &amp;quot;to_as_string&amp;quot;: &amp;quot;15-27+0000&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 600
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;date-histogram-aggregation-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-bucket-datehistogram-aggregation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket-datehistogram-aggregation.html&#34;&gt;Date Histogram Aggregation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;date_histogram&lt;/code&gt;で日付の間隔でBucketを作る。この例だと1分ごとにBucketが作られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d&#39;
{
    &amp;quot;aggs&amp;quot;: {   
        &amp;quot;histogram_1minute&amp;quot;: {                  
            &amp;quot;date_histogram&amp;quot;: {
                &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;,
                &amp;quot;interval&amp;quot;: &amp;quot;1m&amp;quot;
            }
        }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;histogram_1minute&amp;quot;: {
    &amp;quot;buckets&amp;quot;: [
      ...
      {
        &amp;quot;key_as_string&amp;quot;: &amp;quot;1488640560&amp;quot;,
        &amp;quot;key&amp;quot;: 1488640560000,
        &amp;quot;doc_count&amp;quot;: 60
      },
      {
        &amp;quot;key_as_string&amp;quot;: &amp;quot;1488640620&amp;quot;,
        &amp;quot;key&amp;quot;: 1488640620000,
        &amp;quot;doc_count&amp;quot;: 31
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;terms-aggregation-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-bucket-terms-aggregation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket-terms-aggregation.html&#34;&gt;Terms Aggregation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;terms&lt;/code&gt;で値ごとにBucketを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d&#39;
{
    &amp;quot;aggs&amp;quot;: {   
        &amp;quot;os_names&amp;quot;:{                  
            &amp;quot;terms&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;os_name&amp;quot; }
        }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;os_names&amp;quot;: {
    &amp;quot;doc_count_error_upper_bound&amp;quot;: 0,
    &amp;quot;sum_other_doc_count&amp;quot;: 0,
    &amp;quot;buckets&amp;quot;: [
      {
        &amp;quot;key&amp;quot;: &amp;quot;windows&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 458
      },
      {
        &amp;quot;key&amp;quot;: &amp;quot;android&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 456
      },
      {
        &amp;quot;key&amp;quot;: &amp;quot;mac&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 455
      },
      {
        &amp;quot;key&amp;quot;: &amp;quot;linux&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 447
      },
      {
        &amp;quot;key&amp;quot;: &amp;quot;ios&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 404
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;metrics-aggregations-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-metrics-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-metrics.html&#34;&gt;Metrics Aggregations&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;avg-aggregation-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-search-aggregations-metrics-avg-aggregation-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-metrics-avg-aggregation.html&#34;&gt;Avg Aggregation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;avg&lt;/code&gt;で平均を出す。&lt;code&gt;max&lt;/code&gt;、&lt;code&gt;min&lt;/code&gt;、&lt;code&gt;sum&lt;/code&gt;も同様。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d &#39;
{
    &amp;quot;aggs&amp;quot;: {      
        &amp;quot;avg_score&amp;quot;: { &amp;quot;avg&amp;quot;: { &amp;quot;field&amp;quot; : &amp;quot;score&amp;quot; } }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;avg_score&amp;quot;: {
    &amp;quot;value&amp;quot;: 50.34639639639639
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集計する&#34;&gt;集計する&lt;/h2&gt;

&lt;p&gt;aggsを組み合わせて集計する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/hoge/_search -d&#39;
{             
    &amp;quot;aggs&amp;quot;: {
        &amp;quot;range&amp;quot;: {
            &amp;quot;date_range&amp;quot;: {
                &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;,
                &amp;quot;format&amp;quot;: &amp;quot;HH-mm-ssZ&amp;quot;,
                &amp;quot;ranges&amp;quot;: [                               
                    { &amp;quot;to&amp;quot;: &amp;quot;now/m&amp;quot;, &amp;quot;from&amp;quot;: &amp;quot;now-10m/m&amp;quot; }
                ]
            },
            &amp;quot;aggs&amp;quot;: {
                &amp;quot;histogram&amp;quot;: {                  
                    &amp;quot;date_histogram&amp;quot;: {
                        &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;,
                        &amp;quot;interval&amp;quot;: &amp;quot;1m&amp;quot;
                    },
                    &amp;quot;aggs&amp;quot;: {
                        &amp;quot;os_names&amp;quot;:{
                            &amp;quot;terms&amp;quot;: { &amp;quot;field&amp;quot; : &amp;quot;os_name&amp;quot; },
                            &amp;quot;aggs&amp;quot;: {
                                &amp;quot;avg_score&amp;quot;: { &amp;quot;avg&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;score&amp;quot; }}
                            }
                        }
                    }
                }
            }
        }
    }
}&#39; | jq .aggregations
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;range&amp;quot;: {
    &amp;quot;buckets&amp;quot;: [
      {
        &amp;quot;key&amp;quot;: &amp;quot;15-55-00+0000-16-05-00+0000&amp;quot;,
        &amp;quot;from&amp;quot;: 1488642900000,
        &amp;quot;from_as_string&amp;quot;: &amp;quot;15-55-00+0000&amp;quot;,
        &amp;quot;to&amp;quot;: 1488643500000,
        &amp;quot;to_as_string&amp;quot;: &amp;quot;16-05-00+0000&amp;quot;,
        &amp;quot;doc_count&amp;quot;: 25,
        &amp;quot;histogram&amp;quot;: {
          &amp;quot;buckets&amp;quot;: [
            {
              &amp;quot;key_as_string&amp;quot;: &amp;quot;1488643440&amp;quot;,
              &amp;quot;key&amp;quot;: 1488643440000,
              &amp;quot;doc_count&amp;quot;: 25,
              &amp;quot;os_names&amp;quot;: {
                &amp;quot;doc_count_error_upper_bound&amp;quot;: 0,
                &amp;quot;sum_other_doc_count&amp;quot;: 0,
                &amp;quot;buckets&amp;quot;: [
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;linux&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 9,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 41.44444444444444
                    }
                  },
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;ios&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 5,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 63.6
                    }
                  },
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;mac&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 5,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 53.6
                    }
                  },
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;android&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 4,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 41.25
                    }
                  },
                  {
                    &amp;quot;key&amp;quot;: &amp;quot;windows&amp;quot;,
                    &amp;quot;doc_count&amp;quot;: 2,
                    &amp;quot;avg_score&amp;quot;: {
                      &amp;quot;value&amp;quot;: 67
                    }
                  }
                ]
              }
            }
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>一定間隔でjsonデータを作って送り続けるCLIツールを作った</title>
          <link>https://www.sambaiz.net/article/76/</link>
          <pubDate>Sat, 04 Mar 2017 23:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/76/</guid>
          <description>&lt;p&gt;Elasticsearchにリアルタイムなテストデータを投入するために、一定間隔でjsonを作って送り続けるCLIツールを作った。Go製。
&lt;a href=&#34;https://github.com/urfave/cli&#34;&gt;urfave/cli&lt;/a&gt;を使った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/sendjson&#34;&gt;sambaiz/sendjson&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;こんなindexにデータを入れてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;http://localhost:9200/hoge&#39; -d&#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;test_type&amp;quot;: { 
      &amp;quot;_all&amp;quot;:       { &amp;quot;enabled&amp;quot;: false  }, 
      &amp;quot;properties&amp;quot;: { 
        &amp;quot;os_name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; },
        &amp;quot;score&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;byte&amp;quot; },
        &amp;quot;@timestamp&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;epoch_second&amp;quot; }
      }
    }
  }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じでキーに対してtypeと入る値を定義するとそれっぽいデータができて送られていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go install github.com/sambaiz/sendjson
$ sendjson --interval 0.5s --duration 10s --url http://localhost:9200/hoge/test_type &#39;
{
    &amp;quot;os_name&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;or&amp;quot;: [&amp;quot;windows&amp;quot;, &amp;quot;mac&amp;quot;, &amp;quot;linux&amp;quot;, &amp;quot;ios&amp;quot;, &amp;quot;android&amp;quot;]},
    &amp;quot;score&amp;quot;:  {&amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;, &amp;quot;min&amp;quot;: 0, &amp;quot;max&amp;quot;: 100},
    &amp;quot;@timestamp&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;time&amp;quot;, &amp;quot;time_format&amp;quot;: &amp;quot;unix_epoch&amp;quot;}
}&#39;

{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82}
{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:9}
{&amp;quot;@timestamp&amp;quot;:1488635131,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:73}
{&amp;quot;@timestamp&amp;quot;:1488635131,&amp;quot;os_name&amp;quot;:&amp;quot;ios&amp;quot;,&amp;quot;score&amp;quot;:50}
{&amp;quot;@timestamp&amp;quot;:1488635132,&amp;quot;os_name&amp;quot;:&amp;quot;windows&amp;quot;,&amp;quot;score&amp;quot;:69}
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと入っていることを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:9200/hoge/_search | jq
{
  &amp;quot;took&amp;quot;: 2,
  &amp;quot;timed_out&amp;quot;: false,
  &amp;quot;_shards&amp;quot;: {
    &amp;quot;total&amp;quot;: 5,
    &amp;quot;successful&amp;quot;: 5,
    &amp;quot;failed&amp;quot;: 0
  },
  &amp;quot;hits&amp;quot;: {
    &amp;quot;total&amp;quot;: 29,
    &amp;quot;max_score&amp;quot;: 1,
    &amp;quot;hits&amp;quot;: [
      {
        &amp;quot;_index&amp;quot;: &amp;quot;hoge&amp;quot;,
        &amp;quot;_type&amp;quot;: &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot;: &amp;quot;AVqZpCjjFTc9Q_rmmMn7&amp;quot;,
        &amp;quot;_score&amp;quot;: 1,
        &amp;quot;_source&amp;quot;: {
          &amp;quot;@timestamp&amp;quot;: 1488636356,
          &amp;quot;os_name&amp;quot;: &amp;quot;android&amp;quot;,
          &amp;quot;score&amp;quot;: 38
        }
      },
      {
        &amp;quot;_index&amp;quot;: &amp;quot;hoge&amp;quot;,
        &amp;quot;_type&amp;quot;: &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot;: &amp;quot;AVqZpE-kFTc9Q_rmmMoN&amp;quot;,
        &amp;quot;_score&amp;quot;: 1,
        &amp;quot;_source&amp;quot;: {
          &amp;quot;@timestamp&amp;quot;: 1488636366,
          &amp;quot;os_name&amp;quot;: &amp;quot;android&amp;quot;,
          &amp;quot;score&amp;quot;: 87
        }
      },
      ...
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>H2OでHTTPS-&gt;HTTPのリバースプロキシを立てる</title>
          <link>https://www.sambaiz.net/article/75/</link>
          <pubDate>Thu, 02 Mar 2017 20:50:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/75/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://qiita.com/cubicdaiya/items/235777dc401ec419b14e&#34;&gt;良くチューニングされたNginxと同じくらい速い&lt;/a&gt;と
評判のHTTP/2サーバー&lt;a href=&#34;https://h2o.examp1e.net/&#34;&gt;H2O&lt;/a&gt;でリバースプロキシを立ててみる。
HTTP/2だけではなく1.xにも対応しているので古い環境などでも大丈夫。&lt;/p&gt;

&lt;p&gt;設定は
&lt;a href=&#34;https://github.com/h2o/h2o/wiki/Reverse-Proxy&#34;&gt;Reverse Proxy&lt;/a&gt;と
&lt;a href=&#34;https://github.com/h2o/h2o/wiki/redirect-HTTP-to-HTTPS&#34;&gt;HTTP to HTTPS&lt;/a&gt;の
サンプルをもとにして書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hosts:
  &amp;quot;*&amp;quot;:
    listen:
      port: 443
      ssl:
        certificate-file: /etc/h2o/oreore.crt
        key-file:         /etc/h2o/server.key
    paths:
      &amp;quot;/&amp;quot;:
        proxy.reverse.url: http://127.0.0.1:3000/

access-log: /dev/stdout
error-log: /dev/stderr
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とりあえずオレオレ証明書で試してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa 2048 &amp;gt; server.key # private key
$ openssl req -new -key server.key &amp;gt; server.csr # certificate signing request 
$ openssl x509 -days 365000 -req -signkey server.key &amp;lt; server.csr &amp;gt; oreore.crt # oreore certificate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerで動かす。&lt;a href=&#34;https://github.com/lkwg82/h2o.docker&#34;&gt;lkwg82/h2o.docker&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vi h2o.conf
$ docker run -v $(pwd):/etc/h2o --net=host --name h2o --restart=always -itd lkwg82/h2o-http2-server
$ curl --insecure https://127.0.0.1 # -&amp;gt; :3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chromeでアクセスして、Developer ToolsのNetworkで右クリックでProtocolにチェックを入れてh2と表示されていたら
HTTP/2で通信している。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goroutineの数をworkerで抑制する</title>
          <link>https://www.sambaiz.net/article/74/</link>
          <pubDate>Mon, 27 Feb 2017 23:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/74/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/61/&#34;&gt;Goのnet/httpとKeep-Alive - sambaiz.net&lt;/a&gt;でやったように、
あるエンドポイントに連続してGoroutineでリクエストを投げると、リクエスト数を増やしたときにタイムアウトが頻発するようになった。&lt;/p&gt;

&lt;p&gt;まず、2000リクエストを投げてみた結果。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[RESULT] request: 2000, ok: 2000, ng: 0, time(ms) 138
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一応全部捌けてはいるけど、おおよそ同時にリクエストを送っているのにタイムアウト(100ms)時間を超えてしまっている。これをさらに3000に増やしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[RESULT] request: 3000, ok: 13, ng: 2987, time(ms) 372
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほぼ全滅してしまった・・・。時間もおかしいのでGoroutineでの処理に遅延が発生しているようだ。
そこで、都度Goroutineを生成してリクエストを投げるのではなく、
一定数のWorkerに処理させることで、同時に作られるGoroutineの数を抑制する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Req struct {
	Okch chan int
	Ngch chan int
}

func startWorker(ctx context.Context, num int) (requestch chan *Req) {

	requestch = make(chan *Req)

	for i := 0; i &amp;lt; num; i++ {
		go func() {
			for {
				select {
				case req := &amp;lt;-requestch:
					request(req.Okch, req.Ngch)
				case &amp;lt;-ctx.Done():
					return
				}
			}
		}()
	}

	return
}

func main(){
    ...
    ctx, cancel := context.WithCancel(context.Background())
	defer cancel()
	requestch := startWorker(ctx, 1000)

    requestch &amp;lt;- req
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果、すべてのリクエストをタイムアウトせずに送れるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[RESULT] request: 3000, ok: 3000, ng: 0, time(ms) 157
[RESULT] request: 5000, ok: 5000, ng: 0, time(ms) 239
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上のコードではWorkerを作るにあたって単純にWorkerの数分goroutineを生成して共通のチャネルに入ってきたものを読んで処理させているが、
以下の記事のようにDispatcherを用意してWorkerPool(chan chan Job)からWorkerのjobChannel(chan Job)を取り出して送る方法も紹介されていたので
これとも比較してみた。今回は入力するチャネルだけ分けて終了方法はStartで渡したcontextに一任しているので上の方法とさほど変わらず、むしろ冗長に見えるが、
実際はWorkerそれぞれがquitするチャネルなどを持っていて、独立して終了させることができるため、Workerの数を動的にコントロールしやすいのが特長だと思う。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://marcio.io/2015/07/handling-1-million-requests-per-minute-with-golang/&#34;&gt;Handling 1 Million Requests per Minute with Go  · marcio.io&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Dispatcher struct{
	Requestch chan *Req
	workerPool chan chan *Req
	workerNum int
}

func NewDispatcher(workerNum int) *Dispatcher{
	return &amp;amp;Dispatcher{
		Requestch: make(chan *Req),
		workerPool: make(chan chan *Req, workerNum),
		workerNum: workerNum,
	}
}


func (d *Dispatcher) Start(ctx context.Context) error{
	poolLength := len(d.workerPool)
	if poolLength != 0{
		return errors.New(&amp;quot;already started&amp;quot;)
	}
	for i := 0; i &amp;lt; d.workerNum; i++{
		startWorker(ctx, 1, d.workerPool)
	}

	go d.dispatch(ctx)

	return nil
}

func (d *Dispatcher) dispatch(ctx context.Context){
	for{
		select{
		case req := &amp;lt;- d.Requestch:
            // workerPoolからchanを取り出しreqを入れる
			worker := &amp;lt;- d.workerPool
			worker &amp;lt;- req
		case &amp;lt;-ctx.Done():
			return 
		}
	}
}

func startWorker(ctx context.Context, num int, workerPool chan chan *Req) {

	requestch := make(chan *Req)

	for i := 0; i &amp;lt; num; i++ {
		go func() {
			for {
                // workerPoolにchanを入れる(終わったらまだ戻る)
				workerPool &amp;lt;- requestch
				select {
				case req := &amp;lt;-requestch:
					request(req.Okch, req.Ngch)
				case &amp;lt;-ctx.Done():
					return
				}
			}
		}()
	}

	return
}

func main(){
    ...
    dispatcher := NewDispatcher(1000)
	if err := dispatcher.Start(ctx); err != nil{
		panic(err)
	}

    dispatcher.requestch &amp;lt;- req
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほとんど変わらず。WorkerPoolからチャネルを取り出す分、わずかに遅いかな。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[RESULT] request: 3000, ok: 3000, ng: 0, time(ms) 169
[RESULT] request: 5000, ok: 5000, ng: 0, time(ms) 246
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
          <link>https://www.sambaiz.net/article/73/</link>
          <pubDate>Sun, 26 Feb 2017 18:56:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/73/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;でKinesis Streamsに送り、Lambdaで読んでS3に保存する。
要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。&lt;/p&gt;

&lt;h2 id=&#34;fluentdで送る&#34;&gt;fluentdで送る&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-kinesis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;try_flush_interval&lt;/code&gt;と&lt;code&gt;queued_chunk_flush_interval&lt;/code&gt;はドキュメントには載っていないが、
以下のページによるとそれぞれqueueに次のchunkがないときとあるときのflushする間隔。
いずれもデフォルトは1だが、これを減らすことでもっと頻繁に吐き出されるようになるらしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sonots/fluentd-scr/blob/master/02_out_forward_buffered.md&#34;&gt;Fluentd の out_forward と BufferedOutput&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;あとシャードに振り分けるための&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis#partition_key&#34;&gt;partition_key&lt;/a&gt;
を指定できる。デフォルトはランダム。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type tail
  path /var/log/td-agent/hoge.log
  pos_file /etc/td-agent/log.pos
  tag hoge.log
  format json

  time_key timestamp
  # 2017-01-01T01:01:01+0900
  time_format %Y-%m-%dT%H:%M:%S%z
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type kinesis_streams
  region ap-northeast-1
  stream_name teststream
  include_time_key true

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;いくつか送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in `seq 1 1000`
do
  echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;, &amp;quot;timestamp&amp;quot;: &amp;quot;2017-01-01T01:01:01+0900&amp;quot;}&#39; &amp;gt;&amp;gt; /var/log/td-agent/hoge.log
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kinesisのシャードが足りないと詰まってしまうので注意。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/84/&#34;&gt;FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;lambdaで読む&#34;&gt;Lambdaで読む&lt;/h2&gt;

&lt;p&gt;Lambdaのトリガーの設定でKinesisを選ぶと、バッチサイズや開始位置を設定できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/73-lambda-kinesis.png&#34; alt=&#34;トリガーの設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;コードはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;use strict&#39;;

const zlib = require(&#39;zlib&#39;);
const aws = require(&#39;aws-sdk&#39;);
const s3 = new aws.S3({ apiVersion: &#39;2006-03-01&#39; });
const BUCKET_NAME = process.env.BUCKET_NAME; // 環境変数で設定する

exports.handler = (event, context, callback) =&amp;gt; {

    const data = event.Records.map((record) =&amp;gt; new Buffer(record.kinesis.data, &#39;base64&#39;).toString()).join(&amp;quot;\n&amp;quot;);
    const key = new Date().toISOString();
    
    putS3(key, data, true).then(
        (data) =&amp;gt; callback(null, `Successfully processed ${event.Records.length} records.`),
        (err) =&amp;gt; callback(err, null)
    );
};

function putS3(key, data, gzip){    
    return new Promise((resolve, reject) =&amp;gt; {
        
        const params = {
            Bucket: BUCKET_NAME,
            Key: key
        };

        if(gzip){
            params.Body = zlib.gzipSync(data);
            params.ContentEncoding = &amp;quot;gzip&amp;quot;;
        }else{
            params.Body = data;
        }
        
        s3.putObject(params, (err, data) =&amp;gt; {
            if (err) reject(err);
            else resolve(data);
        });
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;トリガーを有効にするとイベントが発火してS3に保存されるようになった。&lt;/p&gt;

&lt;p&gt;ただ、Kinesisをイベントトリガーにして都度出力すると、1ファイルのサイズが非常に小さくなってしまう。
なんとかして都度出力しないようにするか、あるいは時間トリガーで実行するか、いずれにしてもどこまで読んだか記録しておかなくちゃいけないのでちょっと面倒だ。バッファリングしてくれるFirehoseが早く日本にも来て欲しい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AWSのAssumeRole</title>
          <link>https://www.sambaiz.net/article/72/</link>
          <pubDate>Sat, 25 Feb 2017 20:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/72/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/id_credentials_temp.html&#34;&gt;AWS Security Token Service&lt;/a&gt;による、
RoleArn(&lt;code&gt;arn:aws:iam::&amp;lt;account id&amp;gt;:role/&amp;lt;role name&amp;gt;&lt;/code&gt;)から一時的なCredentialを取得する仕組み。
前もって発行したAPIキーとは違い、有効期限が存在するため続けて呼ぶ場合は失効する前に再発行する必要がある。&lt;/p&gt;

&lt;p&gt;ではRoleArnを知っていたら誰でも取得できるかというと、もちろんそうではなく、
ロールの信頼関係、&lt;code&gt;&amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;&lt;/code&gt;のPrincipalのところで信頼する対象を設定する。
例えば、&lt;code&gt;Service&lt;/code&gt;で&lt;code&gt;ec2.amazonaws.com&lt;/code&gt;を指定してEC2がAssumeRoleするのを許可したり、
&lt;code&gt;AWS&lt;/code&gt;で(他の)アカウントやユーザーを指定してそのAPIキーでこのRoleのCredentialを取得できるようにしたりといった感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Principal&amp;quot;: {
        &amp;quot;Service&amp;quot;: &amp;quot;ec2.amazonaws.com&amp;quot;
      },
      &amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EC2にロールを設定すると、実はそのロールについてAssumeRoleして自動でCredentialを取得している。
EC2にロールを設定するにはロールとは別に
&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html&#34;&gt;インスタンスプロファイルを作成&lt;/a&gt;
する必要があるが、コンソールでEC2のサービスロールを作ると同名のインスタンスプロファイルが自動で作成される。
さらに、AssumeRoleのServiceとして&lt;code&gt;ec2.amazonaws.com&lt;/code&gt;が追加されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://169.254.169.254/latest/meta-data/iam/info
{
  &amp;quot;Code&amp;quot; : &amp;quot;Success&amp;quot;,
  &amp;quot;LastUpdated&amp;quot; : &amp;quot;2017-02-25T10:56:33Z&amp;quot;,
  &amp;quot;InstanceProfileArn&amp;quot; : &amp;quot;arn:aws:iam::*****:instance-profile/assume_role_test&amp;quot;,
  &amp;quot;InstanceProfileId&amp;quot; : &amp;quot;*****&amp;quot;
}

$ curl http://169.254.169.254/latest/meta-data/iam/security-credentials/assume_role_test
{
  &amp;quot;Code&amp;quot; : &amp;quot;Success&amp;quot;,
  &amp;quot;LastUpdated&amp;quot; : &amp;quot;2017-02-25T10:56:23Z&amp;quot;,
  &amp;quot;Type&amp;quot; : &amp;quot;AWS-HMAC&amp;quot;,
  &amp;quot;AccessKeyId&amp;quot; : &amp;quot;*****&amp;quot;,
  &amp;quot;SecretAccessKey&amp;quot; : &amp;quot;*****&amp;quot;,
  &amp;quot;Token&amp;quot; : &amp;quot;*****&amp;quot;,
  &amp;quot;Expiration&amp;quot; : &amp;quot;2017-02-25T17:26:07Z&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/iam-role-and-assumerole/&#34;&gt;IAMロール徹底理解 〜 AssumeRoleの正体 ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/id_credentials_temp_use-resources.html&#34;&gt;一時的なセキュリティ認証情報を使用して AWS リソースへのアクセスをリクエストする - AWS Identity and Access Management&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ElasticsearchのCircuit Breaker</title>
          <link>https://www.sambaiz.net/article/71/</link>
          <pubDate>Fri, 24 Feb 2017 21:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/71/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/52/&#34;&gt;ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。
表示されたエラーはこういうの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;root_cause&amp;quot;: [
    {
        &amp;quot;type&amp;quot;: &amp;quot;circuit_breaking_exception&amp;quot;,
        &amp;quot;reason&amp;quot;: &amp;quot;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;quot;,
        &amp;quot;bytes_wanted&amp;quot;: 10464007168,
        &amp;quot;bytes_limit&amp;quot;: 8998512230
    }
],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは1リクエストの集計などで使うメモリ量がしきい値をこえて
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/circuit-breaker.html&#34;&gt;Circuit Breaker&lt;/a&gt;が発動したということ。
メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。&lt;/p&gt;

&lt;p&gt;情報は&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/cluster-nodes-stats.html&#34;&gt;stats&lt;/a&gt;のapiでも取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request
{
  &amp;quot;limit_size_in_bytes&amp;quot;: 8998512230,
  &amp;quot;limit_size&amp;quot;: &amp;quot;8.3gb&amp;quot;,
  &amp;quot;estimated_size_in_bytes&amp;quot;: 10348347504,
  &amp;quot;estimated_size&amp;quot;: &amp;quot;9.6gb&amp;quot;,
  &amp;quot;overhead&amp;quot;: 1,
  &amp;quot;tripped&amp;quot;: 470
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回ひっかかったのは&lt;code&gt;indices.breaker.request.limit&lt;/code&gt;。デフォルトではJVMのヒープメモリの60%になっているが、
これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{
    &amp;quot;persistent&amp;quot; : {
        &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;,
        &amp;quot;indices.breaker.total.limit&amp;quot;: &amp;quot;80%&amp;quot;
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{
    &amp;quot;persistent&amp;quot; : {
        &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;,
        &amp;quot;indices.breaker.total.limit&amp;quot;: &amp;quot;80%&amp;quot;
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必要なメモリ量を上回ったのでひとまずは返せるようになった。
これは一時しのぎで、定常的に大量にメモリが必要なリクエストを処理する必要があるなら、そもそもメモリが足りないので増やさなければならない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request
{
  &amp;quot;limit_size_in_bytes&amp;quot;: 11998016307,
  &amp;quot;limit_size&amp;quot;: &amp;quot;11.1gb&amp;quot;,
  &amp;quot;estimated_size_in_bytes&amp;quot;: 10473078896,
  &amp;quot;estimated_size&amp;quot;: &amp;quot;9.7gb&amp;quot;,
  &amp;quot;overhead&amp;quot;: 1,
  &amp;quot;tripped&amp;quot;: 470
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>crontabのメモ</title>
          <link>https://www.sambaiz.net/article/70/</link>
          <pubDate>Fri, 24 Feb 2017 21:40:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/70/</guid>
          <description>

&lt;p&gt;各ユーザーごとのcron設定。&lt;code&gt;crontab -e&lt;/code&gt;でも編集できるけど、間違えて&lt;code&gt;-r&lt;/code&gt;にすると全部消えてしまうのでこういう風に一旦取り出してから編集すると安全。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ crontab -l &amp;gt; ~/crontab
$ echo &amp;quot;*/1 * * * * /hoge/fuga.sh&amp;quot; &amp;gt;&amp;gt; ~/crontab
$ crontab &amp;lt; ~/crontab
$ crontab -l
*/1 * * * * /hoge/fuga.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://vividcode.hatenablog.com/entry/man-cron-and-crontab&#34;&gt;cron 設定ファイル (crontab ファイル) の置き場所と書式について - ひだまりソケットは壊れない&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Cookieのメモ</title>
          <link>https://www.sambaiz.net/article/69/</link>
          <pubDate>Wed, 22 Feb 2017 20:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/69/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies&#34;&gt;https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;レスポンスに&lt;code&gt;Set-Cookie&lt;/code&gt;ヘッダーが含まれていればブラウザはcookieに保存する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;HTTP/1.0 200 OK
Content-type: text/html
Set-Cookie: yummy_cookie=choco
Set-Cookie: tasty_cookie=strawberry
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リクエスト時には&lt;code&gt;Cookie&lt;/code&gt;ヘッダーにcookieを入れて送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GET /sample_page.html HTTP/1.1
Host: www.example.org
Cookie: yummy_cookie=choco; tasty_cookie=strawberry
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CookieにExpire(ある期間まで有効)またはMax-Age(特定の期間の間有効)を設定するとPermanent cookieとなる。
いずれも設定しなかった場合Session cookieとなり、ブラウザを閉じると削除されることになっているが、
ブラウザのセッション復元機能が有効になっていれば永続化される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Secureを付けるとHTTPSでのみ送られる。
また、HttpOnlyはjsから&lt;code&gt;document.cookie&lt;/code&gt;などでアクセスすることができなくなる。
サイトにXSSの脆弱性があるとき、cookieが盗まれてしまうのを防ぐことができるので問題なければ設定するべき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Domainを指定するとそのドメインとサブドメインへのリクエストのときに送られる。しないとそのドメインだけ。Pathも指定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Domain=example.com; Path=/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リクエストが飛び、&lt;code&gt;Set-Cookie&lt;/code&gt;ヘッダーを受け取ればCookieに書かれるので、アクセスしたサイトのドメイン以外のCookieが書かれることがある。
このようなCookieを3rd party cookieといって、広告のトラッキングによく使われるが、
Safariなどのデフォルト設定では書き込めなくなっている。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ELBのスケーリングとsurge queue</title>
          <link>https://www.sambaiz.net/article/68/</link>
          <pubDate>Tue, 21 Feb 2017 19:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/68/</guid>
          <description>

&lt;p&gt;バックエンドだけではなくELB自体もスケーリングし、内部node数はdigで調べることができる。
このnode数は自分ではコントロールできず、基本的に意識することはない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ dig ****.ap-northeast-1.elb.amazonaws.com

;; ANSWER SECTION:
*****.elb.amazonaws.com. 60 IN A xxx.xxx.xxx.xxx
*****.elb.amazonaws.com. 60 IN A yyy.yyy.yyy.yyy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;nodeが増えるのにはある程度時間がかかるので、
アクセスが急増(5分間で50%以上のトラフィック増加が&lt;a href=&#34;http://aws.typepad.com/sajp/2015/05/aws-black-belt-elb.html&#34;&gt;目安&lt;/a&gt;)
したら捌ききれず、503を返すことがある。
前もって多量のアクセスが来ることが分かっていて、
&lt;a href=&#34;https://aws.amazon.com/jp/premiumsupport/signup/&#34;&gt;AWSサポート&lt;/a&gt;がBusiness以上なら
pre-warming申請することでnodeが増えた状態で待ち構えられる。&lt;/p&gt;

&lt;p&gt;バックエンドのアプリケーションがリクエストを処理できない場合、ELBのsurge queueに溜まっていく。
この数はCloudWatchのSurgeQueueLength(キュー長の急増)メトリクスで確認できる。
また、SurgeQueueLengthの最大値1024を超えるとリクエストは拒否され、その数はSpoiloverCount(過剰数)メトリクスに出る。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/elb-and-cloudwatch-metrics-in-depth/&#34;&gt;ELBの挙動とCloudWatchメトリクスの読み方を徹底的に理解する ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/premiumsupport/knowledge-center/elb-latency-troubleshooting/&#34;&gt;Elastic Load Balancing でのレイテンシーのトラブルシューティング&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kinesis Streams/Firehose/Analyticsを試す</title>
          <link>https://www.sambaiz.net/article/67/</link>
          <pubDate>Mon, 20 Feb 2017 21:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/67/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/&#34;&gt;https://aws.amazon.com/jp/kinesis/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;リアルタイムのストリーミングデータを扱うサービス群。
いまのところTokyoリージョンではKinesis Streamsしか使えない。&lt;/p&gt;

&lt;h3 id=&#34;kinesis-firehose-https-aws-amazon-com-jp-kinesis-firehose&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/&#34;&gt;Kinesis Firehose&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;AWSのデータストアに送るストリーム。自分でデータを読む処理を書かなくてよく、スケーリングも勝手にやってくれるので簡単に使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/faqs/&#34;&gt;https://aws.amazon.com/jp/kinesis/firehose/faqs/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: 送信先とは何ですか?
送信先はデータが配信されるデータストアです。Amazon Kinesis Firehose では、
現在送信先として Amazon S3、Amazon Redshift、Amazon Elasticsearch Service がサポートされています。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/pricing/&#34;&gt;料金&lt;/a&gt;は取り込まれたデータ量による。
一見そんなに高くならないように見えるが、5KB単位で切り上げられるのでレコードのサイズが小さくて数が多い場合に注意が必要。&lt;/p&gt;

&lt;p&gt;今回はS3に送ってみる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-create-firehose.png&#34; alt=&#34;firehose作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;圧縮方法を設定したり、Lambdaを噛ませたりすることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-create-firehose2.png&#34; alt=&#34;firehose作成2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;StatusがActiveになったら&lt;a href=&#34;http://docs.aws.amazon.com/firehose/latest/dev/writing-with-agents.html&#34;&gt;Kinesis Agent&lt;/a&gt;で送ってみる。
CloudWatchとFirehoseにPutする権限が必要。Firehoseはkinesis:ではなくfirehose:なので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install –y aws-kinesis-agent
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/etc/aws-kinesis/agent.json&lt;/code&gt;を編集する。リージョンごとのエンドポイントは
&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/general/latest/gr/rande.html#fh_region&#34;&gt;ここ&lt;/a&gt;
にある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;awsAccessKeyId&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;awsSecretAccessKey&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;firehose.endpoint&amp;quot;: &amp;quot;https://firehose.us-east-1.amazonaws.com&amp;quot;, 
    &amp;quot;flows&amp;quot;: [
        {
            &amp;quot;filePattern&amp;quot;: &amp;quot;/tmp/hoge.log&amp;quot;, 
            &amp;quot;deliveryStream&amp;quot;: &amp;quot;hogefugastream&amp;quot;
        }
    ] 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service aws-kinesis-agent start
$ sudo chkconfig aws-kinesis-agent on
$ echo &amp;quot;aaa&amp;quot; &amp;gt;&amp;gt; /tmp/hoge.log
$ tail /var/log/aws-kinesis-agent/aws-kinesis-agent.log
com.amazon.kinesis.streaming.agent.Agent [INFO] Agent: Progress: 2 records parsed (168 bytes), 
and 2 records sent successfully to destinations. Uptime: 300044ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;S3に保存されているのを確認。&lt;/p&gt;

&lt;h3 id=&#34;kinesis-streams-https-aws-amazon-com-jp-kinesis-streams&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/streams/&#34;&gt;Kinesis Streams&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;用途を制限しないストリーム。データは保持期間の間、何度でも読むことができるので、
とりあえず必要なだけシャードを増やしてデータを入れておけばどうにかなる。
データを扱う側はそれぞれ独立に必要なタイミングで必要なだけpullするため、スケールするにあたってその先は別に考えることができ、
高負荷なシステムのlog aggregatorとして使われる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/streams/pricing/&#34;&gt;料金&lt;/a&gt;は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;時間単位のシャード速度： 1シャードは最大1000件/秒の1MB/秒の入力と2MB/秒の出力能力がある。&lt;/li&gt;
&lt;li&gt;PUTペイロードユニット: 追加する25KBのチャンクの数。5KBでも1チャンク。&lt;/li&gt;
&lt;li&gt;データ保持期間: デフォルトで24時間。7日まで延長可能。シャード時間ごとに課金。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;による。&lt;/p&gt;

&lt;p&gt;ストリーム作成時はシャード数を入れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-create-streams.png&#34; alt=&#34;streams作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Firehoseと同じくKinesis Agentで送ってみる。
エンドポイントは&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/general/latest/gr/rande.html#ak_region&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;awsAccessKeyId&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;awsSecretAccessKey&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;kinesis.endpoint&amp;quot;: &amp;quot;https://kinesis.us-east-1.amazonaws.com&amp;quot;, 
    &amp;quot;flows&amp;quot;: [
        {
            &amp;quot;filePattern&amp;quot;: &amp;quot;/tmp/hoge.log&amp;quot;, 
            &amp;quot;kinesisStream&amp;quot;: &amp;quot;fugafugastream&amp;quot;
        }
    ] 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;aws-cliでデータを&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/streams/latest/dev/fundamental-stream.html#get-records&#34;&gt;取得する&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;まず、シャードイテレーターを取得する。有効時間は300秒。
&lt;a href=&#34;http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax&#34;&gt;TRIM_HORIZON&lt;/a&gt;
で最も古い方からデータを取得していく。SequenceNumberを指定して途中から読むこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws kinesis get-shard-iterator --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON --stream-name fugafugastream
{
    &amp;quot;ShardIterator&amp;quot;: &amp;quot;AAAAAAAAAAFjKI0neNqY2N5HzGljYFCzoFqpQsdncdC6xE+ylnqvZpmusNfyViY3hBSS8WQXa67gvtkF0f2eKzxQ/Fd7SXZG8Inkb8l1UDF5t+jHgErA28gVSWyT4uYxTzzbnhm9AhcbztyQrjqehYcjEfpWIz5XmhY9K3Kjp0Crygy+OYNSS5PoQFcB1PZ7xMFE8zLTxJXLv1ANRu0Q+1m/JFxKQ3WS&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このシャードイテレータを使ってget-recordsする。データはBase64で入っているのでデコードして確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws kinesis get-records --shard-iterator AAAAAAAAAAFjKI0neNqY2N5HzGljYFCzoFqpQsdncdC6xE+ylnqvZpmusNfyViY3hBSS8WQXa67gvtkF0f2eKzxQ/Fd7SXZG8Inkb8l1UDF5t+jHgErA28gVSWyT4uYxTzzbnhm9AhcbztyQrjqehYcjEfpWIz5XmhY9K3Kjp0Crygy+OYNSS5PoQFcB1PZ7xMFE8zLTxJXLv1ANRu0Q+1m/JFxKQ3WS
{
    &amp;quot;Records&amp;quot;: [
        {
            &amp;quot;Data&amp;quot;: &amp;quot;YWFhCg==&amp;quot;, 
            &amp;quot;PartitionKey&amp;quot;: &amp;quot;999679.8130737302&amp;quot;, 
            &amp;quot;ApproximateArrivalTimestamp&amp;quot;: 1487082145.518, 
            &amp;quot;SequenceNumber&amp;quot;: &amp;quot;49570460043263608661463102123405561406360875697772167170&amp;quot;
        }, 
        ...
    ], 
    &amp;quot;NextShardIterator&amp;quot;: &amp;quot;AAAAAAAAAAE08GRdLF1d76L1wCyLIiuAgpSEkKZSkUEO0VdUt3EOfdm1oOSXA1Xc4+tJPkSmB8g5NaQqDPRS/67u5IXermTUiAj6g2lgvDCGCqWFcYMAxIwIKZjKluCPQjL9kRaUqfVAaElRoKjp4Gv7JmuBDjKpxsbF2yk4uJJDAcevqH/VVkala8UbdhTweGyFgf9VhP/ljzXlrqkZ8wbD0eFwtZ3x&amp;quot;, 
    &amp;quot;MillisBehindLatest&amp;quot;: 0
}

$ echo &amp;quot;YWFhCg==&amp;quot; | base64 -d
aaa
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kinesis-analytics-https-aws-amazon-com-jp-kinesis-analytics&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/analytics/&#34;&gt;Kinesis Analytics&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;SourceとなるKinesis Streamsか、Firehoseを指定し、SQLを実行できる。そして必要なら次のストリームに入れることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-create-analytics.png&#34; alt=&#34;analytics作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今回はSourceとしてjsonで株価のデータが入っているDemo streamを使う。
いくつかSQLテンプレートが用意されていて、その中のContinuous Filterを選択。
Streamに入ってきたものをTECHで絞って出力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- ** Continuous Filter ** 
-- Performs a continuous filter based on a WHERE condition.
--          .----------.   .----------.   .----------.              
--          |  SOURCE  |   |  INSERT  |   |  DESTIN. |              
-- Source--&amp;gt;|  STREAM  |--&amp;gt;| &amp;amp; SELECT |--&amp;gt;|  STREAM  |--&amp;gt;Destination
--          |          |   |  (PUMP)  |   |          |              
--          &#39;----------&#39;   &#39;----------&#39;   &#39;----------&#39;               
-- STREAM (in-application): a continuously updated entity that you can SELECT from and INSERT into like a TABLE
-- PUMP: an entity used to continuously &#39;SELECT ... FROM&#39; a source STREAM, and INSERT SQL results into an output STREAM
-- Create output stream, which can be used to send to a destination
CREATE OR REPLACE STREAM &amp;quot;DESTINATION_SQL_STREAM&amp;quot; (ticker_symbol VARCHAR(4), sector VARCHAR(12), change REAL, price REAL);
-- Create pump to insert into output 
CREATE OR REPLACE PUMP &amp;quot;STREAM_PUMP&amp;quot; AS INSERT INTO &amp;quot;DESTINATION_SQL_STREAM&amp;quot;
-- Select all columns from source stream
SELECT STREAM ticker_symbol, sector, change, price
FROM &amp;quot;SOURCE_SQL_STREAM_001&amp;quot;
-- LIKE compares a string to a string pattern (_ matches all char, % matches substring)
-- SIMILAR TO compares string to a regex, may use ESCAPE
WHERE sector SIMILAR TO &#39;%TECH%&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/64-run-analytics.png&#34; alt=&#34;analytics実行&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する</title>
          <link>https://www.sambaiz.net/article/66/</link>
          <pubDate>Sun, 19 Feb 2017 23:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/66/</guid>
          <description>

&lt;h2 id=&#34;fluentdのmonitor-agent-http-docs-fluentd-org-v0-12-articles-monitoring&#34;&gt;&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/monitoring&#34;&gt;fluentdのmonitor_agent&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;メトリクスをjsonで返すAPIを提供する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type monitor_agent
  bind 0.0.0.0
  port 24220
&amp;lt;/source&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:24220/api/plugins.json | jq
{
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d8c250&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;forward&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;forward&amp;quot;,
        &amp;quot;port&amp;quot;: &amp;quot;24222&amp;quot;,
        &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: false,
      &amp;quot;retry_count&amp;quot;: null
    },
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d894c4&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;monitor_agent&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;monitor_agent&amp;quot;,
        &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot;,
        &amp;quot;port&amp;quot;: &amp;quot;24220&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: false,
      &amp;quot;retry_count&amp;quot;: null
    },
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590dc1f2c&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;file&amp;quot;,
        &amp;quot;path&amp;quot;: &amp;quot;/var/log/td-agent/hoge.log&amp;quot;,
        &amp;quot;buffer_path&amp;quot;: &amp;quot;/var/log/td-agent/hoge.log.*&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: true,
      &amp;quot;buffer_queue_length&amp;quot;: 0,
      &amp;quot;buffer_total_queued_size&amp;quot;: 0,
      &amp;quot;retry_count&amp;quot;: 0
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをもとにStackdriverで異常を検知できるようにする。&lt;/p&gt;

&lt;h2 id=&#34;google-stackdriver-https-cloud-google-com-stackdriver&#34;&gt;&lt;a href=&#34;https://cloud.google.com/stackdriver/&#34;&gt;Google Stackdriver&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GoogleがStackdriverを買収して改造したもの。GCPだけではなくAWSのリソースも監視できる。
まだBeta。&lt;/p&gt;

&lt;h2 id=&#34;ec2インスタンスを監視する-https-cloud-google-com-monitoring-quickstart-aws-configure-sd-acct&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/quickstart-aws#configure-sd-acct&#34;&gt;EC2インスタンスを監視する&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GCPのメニューのSTACKDRIVER -&amp;gt; モニタリングで、プロジェクトを指定してStackdriverアカウントを作成する。&lt;/p&gt;

&lt;p&gt;今回はEC2で動いているfluentdを監視するので指示に従ってクロスアカウントアクセスのロールを作成、
Role ARNを入力してAWSアカウントと接続すると、
StackdriverのResouces-&amp;gt;InstancesでCPUの使用率などは確認できるが、
EC2にAgentを入れると詳細な情報を取得できる。&lt;/p&gt;

&lt;p&gt;GCPのメニューのサービスアカウントから接続したAWSアカウントを選択し、
Project-&amp;gt;編集者とLogging-&amp;gt;ログ書き込みロールのサービスアカウントを作成する。
新しい秘密鍵の提供にチェックを入れて、JSONのキーをダウンロードする。
これをEC2の&lt;code&gt;/etc/google/auth/application_default_credentials.json&lt;/code&gt;に置いて
&lt;code&gt;chown root:root&lt;/code&gt;、&lt;code&gt;chmod 400&lt;/code&gt;する。&lt;/p&gt;

&lt;p&gt;Monitoring AgentとLogging Agentをインストールし、
&lt;code&gt;stackdriver-collectd&lt;/code&gt;と&lt;code&gt;google-fluentd&lt;/code&gt;のプロセスがあれば正常。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -O https://repo.stackdriver.com/stack-install.sh
sudo bash stack-install.sh --write-gcm

curl -sSO https://dl.google.com/cloudagents/install-logging-agent.sh
sudo bash install-logging-agent.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;メモリの使用量やTCPコネクション数などがとれていることを確認する。
Googleのドキュメントには見つからなかったけど、
旧Stackdriverと同様、&lt;code&gt;stackdriver_monitor: false&lt;/code&gt;のタグを付けると
&lt;a href=&#34;https://support.stackdriver.com/customer/portal/articles/1491785-collecting-data-from-specific-resources-only&#34;&gt;監視対象から外れる&lt;/a&gt;
っぽい。&lt;/p&gt;

&lt;h2 id=&#34;カスタムメトリクスを送る-https-cloud-google-com-monitoring-custom-metrics&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/&#34;&gt;カスタムメトリクスを送る&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;MetricDescriptorを作成し、これにTimeSeriesデータを書き込んでいく。&lt;/p&gt;

&lt;h3 id=&#34;metricdescriptorの作成-https-cloud-google-com-monitoring-custom-metrics-creating-metrics-monitoring-create-metric-protocol&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#monitoring-create-metric-protocol&#34;&gt;MetricDescriptorの作成&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors&#34;&gt;MetricDescriptor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;typeは&lt;code&gt;custom.googleapis.com/&lt;/code&gt;
から&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#custom_metric_names&#34;&gt;始める&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors#MetricKind&#34;&gt;metricKind&lt;/a&gt;
にはGAUGEのほかに変化量をとるDELTA、累積するCUMULATIVEを指定できる。&lt;/p&gt;

&lt;p&gt;labelはフィルタリングのためのもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;fluentd buffer_queue_length&amp;quot;,
  &amp;quot;displayName&amp;quot;: &amp;quot;fluentd-buffer_queue_length&amp;quot;,
  &amp;quot;type&amp;quot;: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
  &amp;quot;metricKind&amp;quot;: &amp;quot;GAUGE&amp;quot;,
  &amp;quot;valueType&amp;quot;: &amp;quot;INT64&amp;quot;,
  &amp;quot;labels&amp;quot;: [
    {
      &amp;quot;key&amp;quot;: &amp;quot;plugin_type&amp;quot;,
      &amp;quot;valueType&amp;quot;: &amp;quot;STRING&amp;quot;,
      &amp;quot;description&amp;quot;: &amp;quot;The type of the plugin&amp;quot;
    },
  ],
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをGoで登録する。&lt;/p&gt;

&lt;p&gt;gcpのほうのprojectでProject-&amp;gt;編集者のサービスアカウントを作成してパスを
環境変数&lt;code&gt;GOOGLE_APPLICATION_CREDENTIALS&lt;/code&gt;に入れて
&lt;a href=&#34;https://developers.google.com/identity/protocols/application-default-credentials&#34;&gt;Default Credential&lt;/a&gt;
にする。&lt;/p&gt;

&lt;p&gt;必要なパッケージをgo get。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get google.golang.org/api/monitoring/v3
$ go get golang.org/x/oauth2/google
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		panic(err)
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		panic(err)
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/*****&amp;quot;

		requestBody = &amp;amp;monitoring.MetricDescriptor{
			Description: &amp;quot;fluentd buffer_queue_length&amp;quot;,
			DisplayName: &amp;quot;fluentd-buffer_queue_length&amp;quot;,
			Type:        &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
			MetricKind:  &amp;quot;GAUGE&amp;quot;,
			ValueType:   &amp;quot;INT64&amp;quot;,
			Labels: []*monitoring.LabelDescriptor{
				&amp;amp;monitoring.LabelDescriptor{
					Key:         &amp;quot;plugin_type&amp;quot;,
					ValueType:   &amp;quot;STRING&amp;quot;,
					Description: &amp;quot;The type of the plugin&amp;quot;,
				},
			},
		}
	)

	response, err := client.Projects.MetricDescriptors.Create(name, requestBody).Context(ctx).Do()
	if err != nil {
		panic(err)
	}

	fmt.Println(&amp;quot;done&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;登録されたことをlistで確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;response, err := client.Projects.MetricDescriptors.List(name).Context(ctx).Do()
if err != nil {
  panic(err)
}

for _, v := range response.MetricDescriptors {
  fmt.Println(v.DisplayName)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;API Request Count
Agent Memory Usage
Stream Space Used
...
fluentd-buffer_queue_length
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;timeseriesの書き込み-https-cloud-google-com-monitoring-custom-metrics-creating-metrics-monitoring-write-timeseries-protocol&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#monitoring-write-timeseries-protocol&#34;&gt;TimeSeriesの書き込み&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/TimeSeries&#34;&gt;TimeSeries&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;metricのtypeはMetricDescriptorのtypeと対応する。
pointsのendTimeはRFC3339のUTC文字列で渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
 &amp;quot;timeSeries&amp;quot;: [
  {
   &amp;quot;metric&amp;quot;: {
    &amp;quot;type&amp;quot;: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
    &amp;quot;labels&amp;quot;: {
     &amp;quot;plugin_type&amp;quot;: &amp;quot;file&amp;quot;
    }
   },
   &amp;quot;resource&amp;quot;: {
    &amp;quot;type&amp;quot;: &amp;quot;aws_ec2_instance&amp;quot;,
    &amp;quot;labels&amp;quot;: {
     &amp;quot;project_id&amp;quot;: &amp;quot;*****&amp;quot;,
     &amp;quot;instance_id&amp;quot;: &amp;quot;*****&amp;quot;,
     &amp;quot;region&amp;quot;: &amp;quot;aws:ap-northeast-1&amp;quot;,
     &amp;quot;aws_account&amp;quot;: &amp;quot;*****&amp;quot;
    }
   },
   &amp;quot;points&amp;quot;: [
    {
     &amp;quot;interval&amp;quot;: {
      &amp;quot;endTime&amp;quot;: &amp;quot;2016-06-01T10:00:00-04:00&amp;quot;
     },
     &amp;quot;value&amp;quot;: {
      &amp;quot;int64Value&amp;quot;: 0
     }
    }
   ]
  }
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;resourceのtypeは
&lt;a href=&#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/monitoredResourceDescriptors/list#MonitoredResourceDescriptor&#34;&gt;MonitoredResourceDescriptor&lt;/a&gt;
と対応していて、
&lt;a href=&#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/monitoredResourceDescriptors/list&#34;&gt;list&lt;/a&gt;で確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
 &amp;quot;resourceDescriptors&amp;quot;: [
   {
   &amp;quot;type&amp;quot;: &amp;quot;aws_ec2_instance&amp;quot;,
   &amp;quot;displayName&amp;quot;: &amp;quot;Amazon EC2 Instance&amp;quot;,
   &amp;quot;description&amp;quot;: &amp;quot;A VM instance in Amazon EC2.&amp;quot;,
   &amp;quot;labels&amp;quot;: [
    {
     &amp;quot;key&amp;quot;: &amp;quot;project_id&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The identifier of the GCP project under which data is stored for the AWS account specified in the aws_account label (e.g., my-project).&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;instance_id&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The VM instance identifier assigned by AWS.&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;region&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The AWS region in which the VM is running. Supported AWS region values are listed by service at http://docs.aws.amazon.com/general/latest/gr/rande.html. The value supplied for this label must be prefixed with &#39;aws:&#39; (for example, &#39;aws:us-east-1&#39; is a valid value while &#39;us-east-1&#39; is not).&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;aws_account&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The AWS account number under which the VM is running.&amp;quot;
    }
   ]
  },
  ...
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;書くコード。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func writeFluentdBufferQueueLength() error {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		return err
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		return err
	}

	now := time.Now().UTC().Format(time.RFC3339)

	resource := &amp;amp;monitoring.MonitoredResource{
		Type: &amp;quot;aws_ec2_instance&amp;quot;,
		Labels: map[string]string{
			&amp;quot;project_id&amp;quot;:  &amp;quot;*****&amp;quot;,
			&amp;quot;instance_id&amp;quot;: &amp;quot;*****&amp;quot;,
			&amp;quot;region&amp;quot;:      &amp;quot;aws:ap-northeast-1&amp;quot;,
			&amp;quot;aws_account&amp;quot;: &amp;quot;*****&amp;quot;,
		},
	}

	metrics, err := fetchFluentdMetrics()
	if err != nil {
		return err
	}

	timeSeries := []*monitoring.TimeSeries{}

	for _, v := range metrics.Plugins {
		if v.OutputPlugin {

			fmt.Printf(&amp;quot;send %s\n&amp;quot;, v.Type)

			timeSeries = append(
				timeSeries,
				&amp;amp;monitoring.TimeSeries{
					Metric: &amp;amp;monitoring.Metric{
						Type: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
						Labels: map[string]string{
							&amp;quot;plugin_type&amp;quot;: v.Type,
						},
					},
					Resource: resource,
					Points: []*monitoring.Point{
						&amp;amp;monitoring.Point{
							Interval: &amp;amp;monitoring.TimeInterval{
								EndTime: now,
							},
							Value: &amp;amp;monitoring.TypedValue{
								Int64Value: int64p(v.BufferQueueLength),
							},
						},
					},
				},
			)
		}
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/try-stackdriver-159110&amp;quot;

		requestBody = &amp;amp;monitoring.CreateTimeSeriesRequest{
			TimeSeries: timeSeries,
		}
	)

	_, err = client.Projects.TimeSeries.Create(name, requestBody).Context(ctx).Do()
	if err != nil {
		return err
	}

	fmt.Println(&amp;quot;done&amp;quot;)

	return nil
}

const fluentdMonitorEndpoint = &amp;quot;http://localhost:24220/api/plugins.json&amp;quot;

type fluentdMetrics struct {
	Plugins []fluentdMetricsPlugin `json:&amp;quot;plugins&amp;quot;`
}
type fluentdMetricsPlugin struct {
	Type              string `json:&amp;quot;type&amp;quot;`
	OutputPlugin      bool   `json:&amp;quot;output_plugin&amp;quot;`
	BufferQueueLength int64  `json:&amp;quot;buffer_queue_length&amp;quot;`
}

// monitor_agentからfluentdのメトリクスを取得する
func fetchFluentdMetrics() (*fluentdMetrics, error) {

	resp, err := http.Get(fluentdMonitorEndpoint)
	if err != nil {
		return nil, err
	}

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}

	var ret fluentdMetrics

	if err := json.Unmarshal(body, &amp;amp;ret); err != nil {
		return nil, err
	}

	return &amp;amp;ret, nil
}

// int64 -&amp;gt; *int64
func int64p(n int64) *int64 {
	return &amp;amp;n
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;a href=&#34;https://github.com/jasonlvhit/gocron&#34;&gt;gocron&lt;/a&gt;などで定期的に実行させる。&lt;/p&gt;

&lt;p&gt;読むコード。確認用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func readFluentdBufferQueueLength() error {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		return err
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		return err
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/*****&amp;quot;
	)

	start := time.Now().Add(time.Hour * -3).UTC().Format(time.RFC3339)
	now := time.Now().UTC().Format(time.RFC3339)

	filter := &amp;quot;metric.type = \&amp;quot;custom.googleapis.com/fluentd/buffer_queue_length\&amp;quot;&amp;quot;
	resp, err := client.Projects.TimeSeries.List(name).
		IntervalStartTime(start).
		IntervalEndTime(now).
		Filter(filter).Context(ctx).Do()
	if err != nil {
		return err
	}

	for _, v := range resp.TimeSeries {
		fmt.Println(v.Metric.Type)
		for _, p := range v.Points {
			fmt.Println(*(p.Value.Int64Value))
		}
	}

	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと届いていれば
Resource-&amp;gt;Metrics Explorerでもcustom/fluentd/buffer_queue_lengthを確認できる。&lt;/p&gt;

&lt;p&gt;これでAlertを設定できるようになった。TargetのResource TypeはCustom Metrics。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/66.png&#34; alt=&#34;Alertの設定&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのselectの中断処理(close, context)</title>
          <link>https://www.sambaiz.net/article/65/</link>
          <pubDate>Thu, 16 Feb 2017 20:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/65/</guid>
          <description>

&lt;h2 id=&#34;close-chan&#34;&gt;close(chan)&lt;/h2&gt;

&lt;p&gt;closeしたチャネルを読むとゼロ値になるので、selectで待っているやつにまとめて送れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	done := make(chan bool)

	wg := new(sync.WaitGroup)

	waitTillDone(wg, done)
	waitTillDone(wg, done)

    // こんなことしなくていい
	// done &amp;lt;- true
	// done &amp;lt;- true

	close(done)

	wg.Wait()
}

func waitTillDone(wg *sync.WaitGroup, done &amp;lt;-chan bool) {
	wg.Add(1)
	go func() {
		select {
		case v := &amp;lt;-done:
			fmt.Println(v) // false (ゼロ値)
			wg.Done()
		}
	}()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;context-https-godoc-org-golang-org-x-net-context&#34;&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/net/context&#34;&gt;context&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;key-valueの値を渡せるほかにキャンセルやタイムアウトの仕組みをもつ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ctx := context.Background() // empty context
ctx, cancel = context.WithCancel(ctx)
ctx, cancel = context.WithDeadline(ctx, time.Now().Add(time.Second * 10))
ctx, cancel = context.WithTimeout(ctx, time.Second * 10)
ctx = context.WithValue(ctx, key, value)
ctx.Value(key).(Data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さっきdoneで待ってたところを&lt;code&gt;ctx.Done()&lt;/code&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	finished := make(chan interface{})
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel() // キャンセルしないとリークする

	go func() {
		if err := f1(ctx); err != nil {
			fmt.Printf(&amp;quot;main: %s\n&amp;quot;, err)
		} else {
			fmt.Println(&amp;quot;ok&amp;quot;)
		}
		close(finished)
	}()

	fmt.Println(&amp;quot;I will cancel!&amp;quot;)
	cancel()

	select {
	case &amp;lt;-finished:
		fmt.Println(&amp;quot;finished&amp;quot;)
	}
}

func f1(ctx context.Context) error {
	f2(ctx)
	select {
	case &amp;lt;-ctx.Done():
		fmt.Printf(&amp;quot;f1: %s\n&amp;quot;, ctx.Err())
		return ctx.Err()
	}
}

func f2(ctx context.Context) error {
	select {
	case &amp;lt;-ctx.Done():
		fmt.Printf(&amp;quot;f2: %s\n&amp;quot;, ctx.Err())
		return ctx.Err()
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;I will cancel!
f2: context canceled
f1: context canceled
main: context canceled
finished
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、key-valueを受けわたすために使う場合は
type-safeにするために
NewContextで値を詰めて、FromContextで値を取り出すということがコメントに書いてある。
また、Contextはctxという名前で第一引数として渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type User struct {
	name string
}

type key int

var userKey key = 0

func NewContext(ctx context.Context, u *User) context.Context {
	return context.WithValue(ctx, userKey, u)
}

func FromContext(ctx context.Context) (*User, bool) {
	u, ok := ctx.Value(userKey).(*User)
	return u, ok
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/pipelines&#34;&gt;Go Concurrency Patterns: Pipelines and cancellation - The Go Blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://deeeet.com/writing/2016/07/22/context/&#34;&gt;Go1.7のcontextパッケージ | SOTA&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentd自身のログを拾う</title>
          <link>https://www.sambaiz.net/article/64/</link>
          <pubDate>Tue, 14 Feb 2017 21:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/64/</guid>
          <description>

&lt;p&gt;fluentdは自身のログも&lt;code&gt;fluent.error&lt;/code&gt;のようなタグでイベントとして流す。&lt;/p&gt;

&lt;p&gt;バッファを0にして意図的にエラーを発生させてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

# throw away
&amp;lt;match fluent.info&amp;gt;
  @type null
&amp;lt;/match&amp;gt;

&amp;lt;match fluent.**&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;

# error!
&amp;lt;match **&amp;gt;
  @type file
  path /var/log/td-agent/hoge.log
  buffer_chunk_limit 0
  buffer_queue_limit 0
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;すると、こんなのがtd-agent.logに出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fluent.error: {&amp;quot;error&amp;quot;:&amp;quot;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;quot;,&amp;quot;error_class&amp;quot;:&amp;quot;Fluent::BufferQueueLimitError&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただ、これだとaggregatorに集めたときにどのサーバーのfluentdに問題が発生してるのか分からない。
そこでホスト名を追加する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/55/&#34;&gt;fluentdのrecord_transformerでログを加工する - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;filter fluent.**&amp;gt;
  @type record_transformer
  enable_ruby

  &amp;lt;record&amp;gt;
    hostname &amp;quot;#{Socket.gethostname}&amp;quot;
    tag ${tag}
  &amp;lt;/record&amp;gt;
&amp;lt;/filter&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;fluent.error: {&amp;quot;error&amp;quot;:&amp;quot;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;quot;,&amp;quot;error_class&amp;quot;:&amp;quot;Fluent::BufferQueueLimitError&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;quot;,
&amp;quot;hostname&amp;quot;:&amp;quot;*****&amp;quot;,&amp;quot;tag&amp;quot;:&amp;quot;fluent.error&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://chopl.in/post/2013/04/27/fluentd_internal_log/&#34;&gt;fluentd自身のログにまつわるノウハウ - still deeper&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GoでDynamoDBを使う</title>
          <link>https://www.sambaiz.net/article/63/</link>
          <pubDate>Sun, 12 Feb 2017 23:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/63/</guid>
          <description>

&lt;h2 id=&#34;テーブルを作成する&#34;&gt;テーブルを作成する&lt;/h2&gt;

&lt;h3 id=&#34;プライマリキー&#34;&gt;プライマリキー&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/GuidelinesForTables.html&#34;&gt;テーブルの操作のガイドライン - Amazon DynamoDB&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;プライマリキーとしてパーティションキー(ハッシュキー)とオプションのソートキー(レンジキー)を設定する。
DynamoDBはこのパーティションキーに基づいて、複数のパーティションに分散して保存する。
テーブルにプロビジョニングされたスループット性能はパーティション間で均等に使われるので、
ソートキーを設定する場合にこれを最大限に活用するためには、
あるパーティションにリクエストが集中しないよう、パーティションキーに特定の値ばかり集中しないようなフィールドを
選ぶ必要がある。&lt;/p&gt;

&lt;h3 id=&#34;セカンダリインデックス&#34;&gt;セカンダリインデックス&lt;/h3&gt;

&lt;p&gt;パーティションキーのグローバルセカンダリインデックス(GSI)と
ソートキーのローカルセカンダリインデックス(LSI)がある。
射影されるフィールドを選択でき、ここに含まれないフィールドは返さない。
ただし、すべてをインデックスに書き込むのはコストが高いのでなるべく絞る。&lt;/p&gt;

&lt;h3 id=&#34;キャパシティユニット-http-docs-aws-amazon-com-ja-jp-amazondynamodb-latest-developerguide-limits-html-limits-capacity-units-provisioned-throughpu&#34;&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/Limits.html#limits-capacity-units-provisioned-throughpu&#34;&gt;キャパシティユニット&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1読み込みキャパシティユニット: 4kbを超えないデータを1秒に1~2回(整合性による)読み込める&lt;/li&gt;
&lt;li&gt;1書き込みキャパシティユニット: 1kbを超えないデータを1秒に1回書き込める&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ユニットに応じて1時間あたりで&lt;a href=&#34;https://aws.amazon.com/jp/dynamodb/pricing/&#34;&gt;課金&lt;/a&gt;される。&lt;/p&gt;

&lt;p&gt;未使用のキャパシティがある場合、最大5分保持して&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/GuidelinesForTables.html#GuidelinesForTables.Bursting&#34;&gt;バーストに備えてくれる&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;読み書きする&#34;&gt;読み書きする&lt;/h2&gt;

&lt;p&gt;aws-sdk-goを直接使ってもいいけど、簡単に扱えるラッパー
&lt;a href=&#34;https://github.com/guregu/dynamo&#34;&gt;guregu/dynamo&lt;/a&gt;
を使うことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Data struct {
	ID   int64 `dynamo:&amp;quot;id&amp;quot;`
	Name string
	Age  int
}

db := dynamo.New(session.New(), &amp;amp;aws.Config{Region: aws.String(&amp;quot;ap-northeast-1&amp;quot;)})
table := db.Table(&amp;quot;testtable&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;create-update&#34;&gt;Create &amp;amp; Update&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;d := Data{ID: 1, Name: &amp;quot;hogefuga&amp;quot;, Age: 123}
if err := table.Put(d).Run(); err != nil {
    return err
}

if err := table.Update(&amp;quot;id&amp;quot;, 1).Set(&amp;quot;name&amp;quot;, &amp;quot;fugafuga&amp;quot;).Run(); err != nil {
    return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get&#34;&gt;Get&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;var data Data
// 結果整合性がある読み込み(1秒に2回/ユニット)　.Consistent(true)で強い整合性のある読み込み(1秒に1回/ユニット)にできる
if err := table.Get(&amp;quot;id&amp;quot;, 1).One(&amp;amp;data); err != nil {
    return err
}
fmt.Println(data)

if err := table.Get(&amp;quot;id&amp;quot;, 2).One(&amp;amp;data); err != nil {
    return err // dynamo: no item found
}
fmt.Println(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/AmazonWebServicesJapan/20150805-aws-blackbeltdynamodb&#34;&gt;AWS Black Belt Tech シリーズ 2015 - Amazon DynamoDB&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Elasticsearchのmapping</title>
          <link>https://www.sambaiz.net/article/62/</link>
          <pubDate>Thu, 09 Feb 2017 21:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/62/</guid>
          <description>

&lt;p&gt;Dynamic mappingがあるので、自分で設定しなくてもデータは入るけど、
自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。
バージョンは5.2。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: 0 
}
&#39;

$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot;
}
&#39;

{
  &amp;quot;error&amp;quot; : {
    &amp;quot;root_cause&amp;quot; : [
      {
        &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;,
        &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;
      }
    ],
    &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;,
    &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;,
    &amp;quot;caused_by&amp;quot; : {
      &amp;quot;type&amp;quot; : &amp;quot;number_format_exception&amp;quot;,
      &amp;quot;reason&amp;quot; : &amp;quot;For input string: \&amp;quot;sambaiz\&amp;quot;&amp;quot;
    }
  },
  &amp;quot;status&amp;quot; : 400
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mapping-parameters-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-params-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-params.html&#34;&gt;Mapping parameters&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;index-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-index-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-index.html&#34;&gt;index&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;falseにするとindexしない。クエリで必要ないものはfalseにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;index&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;store-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-store-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-store.html&#34;&gt;store&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;デフォルトでフィールドはindexされるがstoreはされず、metaの&lt;code&gt;_source&lt;/code&gt;としてオリジナルのJSONがstoreされている。
サイズの大きなフィールドがあるなど、選んでstoreする場合はtrueにする。stored_fieldsで必要なものだけとってくることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;store&amp;quot;: true }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;meta-fields-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-fields-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-fields.html&#34;&gt;Meta fields&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;all-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-all-field-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-all-field.html&#34;&gt;_all&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;全てのフィールドをスペースでつなげた一つの文字列にしてanalyzeし、indexする。storeはされない。&lt;/p&gt;

&lt;p&gt;フィールドの区別なく検索できたりするけどindexするのにコストがかかるので必要ないならfalseにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;_all&amp;quot;: { &amp;quot;enabled&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;source-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-source-field-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-source-field.html&#34;&gt;_source&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;オリジナルのJSONを含み、indexはされずstoreされる。&lt;/p&gt;

&lt;p&gt;無効にするとストレージを節約できるが、
まずは&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/index-modules.html#index-codec&#34;&gt;compression level&lt;/a&gt;を上げてみる。
無効にするとupdateやreindexができなくなったりするので有効のままにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;_source&amp;quot;: { &amp;quot;enabled&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;analysis-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-analysis-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analysis.html&#34;&gt;analysis&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;textをどのようにanalyzeするか。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analyzer-anatomy.html&#34;&gt;Analyzer&lt;/a&gt;は
Character filtersで文字列を加工してTokenizerでトークンに分割してからToken filtersでトークンを取り除いたり変更したりするもの。
自分でこれらを組み合わせて&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analysis-custom-analyzer.html&#34;&gt;定義する&lt;/a&gt;こともできる。&lt;/p&gt;

&lt;p&gt;日本語のAnalyzerとして&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/plugins/5.2/analysis-kuromoji.html&#34;&gt;kuromoji&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/elasticsearch-plugin install analysis-kuromoji
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;kuromoji&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XGET &#39;localhost:9200/_analyze?pretty&#39; -d &#39;
{
  &amp;quot;analyzer&amp;quot; : &amp;quot;kuromoji&amp;quot;,
  &amp;quot;text&amp;quot; : &amp;quot;Character filtersで文字列を加工します&amp;quot;
}&#39;

{
  &amp;quot;tokens&amp;quot; : [
    {
      &amp;quot;token&amp;quot; : &amp;quot;character&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 0,
      &amp;quot;end_offset&amp;quot; : 9,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 0
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;filters&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 10,
      &amp;quot;end_offset&amp;quot; : 17,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 1
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;文字&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 18,
      &amp;quot;end_offset&amp;quot; : 20,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 3
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;列&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 20,
      &amp;quot;end_offset&amp;quot; : 21,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 4
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;加工&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 22,
      &amp;quot;end_offset&amp;quot; : 24,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 6
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;datatype-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-types-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-types.html&#34;&gt;datatype&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;文字列-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-string-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/string.html&#34;&gt;文字列&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;5.Xからstringは廃止され
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/text.html&#34;&gt;text&lt;/a&gt;と
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/keyword.html&#34;&gt;keyword&lt;/a&gt;になった。&lt;/p&gt;

&lt;p&gt;textはメールの文章のようなfull-textの値で、ある単語がそれぞれの文章に含まれるかということを調べることができる。
メールアドレスのようなデータの場合はkeywordを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;email&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;数値-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-number-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/number.html&#34;&gt;数値&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;long(64bit), integer(32bit), short(16bit, ~32767), byte(8bit, ~127), double, floatとか。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;age&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;short&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;日付-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-date-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/date.html&#34;&gt;日付&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;date&amp;quot;: {
  &amp;quot;type&amp;quot;:   &amp;quot;date&amp;quot;,
  &amp;quot;format&amp;quot;: &amp;quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;boolean-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-boolean-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/boolean.html&#34;&gt;Boolean&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;success&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;object-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-object-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/object.html&#34;&gt;Object&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;propertiesの中に書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: {
  &amp;quot;properties&amp;quot;: {
    &amp;quot;fuga&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;nested-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-nested-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/nested.html&#34;&gt;nested&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;objectの配列。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: {
  &amp;quot;type&amp;quot;: &amp;quot;nested&amp;quot;
  &amp;quot;properties&amp;quot;: {
    &amp;quot;fuga&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: [{&amp;quot;fuga&amp;quot;: true}]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;登録&#34;&gt;登録&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/test_index?pretty&#39; -d&#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;test_type&amp;quot;: { 
      &amp;quot;_all&amp;quot;:       { &amp;quot;enabled&amp;quot;: false  }, 
      &amp;quot;properties&amp;quot;: { 
        &amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;, &amp;quot;store&amp;quot;: true },
        &amp;quot;description&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;kuromoji&amp;quot; },
        &amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;index&amp;quot;: false }
      }
    }
  }
}
&#39;

$ curl -XPOST &#39;localhost:9200/test_index/test_type?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot;,
    &amp;quot;description&amp;quot;: &amp;quot;青い海&amp;quot;,
    &amp;quot;memo&amp;quot;: &amp;quot;白い空&amp;quot;
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logstashのようにindex名に日付が付いているような場合は
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/indices-templates.html&#34;&gt;indices-template&lt;/a&gt;で設定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_template/hogefuga-template -d &#39;
{
  &amp;quot;template&amp;quot; : &amp;quot;hogefuga-*&amp;quot;,
  &amp;quot;mappings&amp;quot; : {
    ...
  }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;取得&#34;&gt;取得&lt;/h2&gt;

&lt;p&gt;まずはデータが入っていることを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/test_index/test_type/_search?pretty&#39;
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVodMAubr8EtIroFs0eP&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;name&amp;quot; : &amp;quot;sambaiz&amp;quot;,
          &amp;quot;description&amp;quot; : &amp;quot;青い海&amp;quot;,
          &amp;quot;memo&amp;quot; : &amp;quot;白い空&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stored_fieldsを付けてリクエスト。_sourceが含まれず、storeがtrueなnameだけが返ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/test_index/_search?pretty&amp;amp;stored_fields=name,description,memo&#39;
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVodMAubr8EtIroFs0eP&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;fields&amp;quot; : {
          &amp;quot;name&amp;quot; : [
            &amp;quot;sambaiz&amp;quot;
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリを付けてリクエスト。indexされてないmemoではひっかからない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_index/test_type/_search?pretty&#39; -d &#39;
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;query_string&amp;quot;:{
      &amp;quot;default_field&amp;quot; : &amp;quot;description&amp;quot;,
      &amp;quot;query&amp;quot;: &amp;quot;青い海&amp;quot;
    }
  }
}&#39;

{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_index/test_type/_search?pretty&#39; -d &#39;
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;query_string&amp;quot;:{
      &amp;quot;default_field&amp;quot; : &amp;quot;memo&amp;quot;,
      &amp;quot;query&amp;quot;: &amp;quot;白い空&amp;quot;
    }
  }
}&#39;

{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 0,
    &amp;quot;max_score&amp;quot; : null,
    &amp;quot;hits&amp;quot; : [ ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing/&#34;&gt;Elasticsearchのインデキシングに関するパフォーマンス検討 - @johtaniの日記 2nd&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのnet/httpとKeep-Alive</title>
          <link>https://www.sambaiz.net/article/61/</link>
          <pubDate>Tue, 07 Feb 2017 22:42:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/61/</guid>
          <description>

&lt;p&gt;Keep-AliveするとTCPコネクションを使い回し、名前解決やコネクション(3 way handshake)を毎回行わなくてよくなる。
Goの&lt;code&gt;net/http&lt;/code&gt;ではデフォルトでKeep-Aliveが
&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L129&#34;&gt;有効になっている&lt;/a&gt;が、
全体と同一ホストでそれぞれKeep-Aliveするコネクション数が制限される。
これらの値は&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36&#34;&gt;Client&lt;/a&gt;のTransportが持っていて、
これがnullだと&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/transport.go#L39&#34;&gt;DefaultTransport&lt;/a&gt;が参照されるので、意識しなければこの値が使われる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L143&#34;&gt;MaxIdleConns&lt;/a&gt;: DefaultTransportでは&lt;a href=&#34;https://github.com/golang/go/blob/master/src/net/http/transport.go#L46&#34;&gt;100になっている&lt;/a&gt;。0にすると無制限。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L148&#34;&gt;MaxIdleConnsPerHost&lt;/a&gt;: &lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L54&#34;&gt;デフォルト値は2&lt;/a&gt;。0にするとデフォルト値が使われる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;同一のホストに同時にたくさんリクエストする場合、2だとほとんど意味を持たない。これを増やして比較してみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;time&amp;quot;
)

var client = http.Client{
	Timeout: time.Millisecond * 100,
}

const TOTAL_REQUEST_NUM = 3000
const TARGET_URL = &amp;quot;*****&amp;quot;

func main() {

	http.DefaultTransport.(*http.Transport).MaxIdleConns = 0
	http.DefaultTransport.(*http.Transport).MaxIdleConnsPerHost = 3000

	okChan := make(chan int, TOTAL_REQUEST_NUM)
	ngChan := make(chan int, TOTAL_REQUEST_NUM)

	var okCount = 0
	var ngCount = 0

	// connect and keep-alive
	for i := 0; i &amp;lt; TOTAL_REQUEST_NUM; i++ {
		go request(okChan, ngChan)
	}

	for {
		select {
		case &amp;lt;-okChan:
			okCount++
		case &amp;lt;-ngChan:
			ngCount++
		}

		if okCount+ngCount == TOTAL_REQUEST_NUM {
			break
		}
	}

	okCount = 0
	ngCount = 0

	startNs := time.Now().UnixNano()

	for i := 0; i &amp;lt; TOTAL_REQUEST_NUM; i++ {
		go request(okChan, ngChan)
	}

	for {
		select {
		case &amp;lt;-okChan:
			okCount++
		case &amp;lt;-ngChan:
			ngCount++
		}

		if okCount+ngCount == TOTAL_REQUEST_NUM {
			break
		}
	}

	endNs := time.Now().UnixNano()

	fmt.Printf(&amp;quot;[RESULT] request: %d, ok: %d, ng: %d, time(ms) %d\n&amp;quot;,
		TOTAL_REQUEST_NUM, okCount, ngCount, (endNs-startNs)/(1000*1000))
}

func request(okch chan int, ngch chan int) {
	req, err := http.NewRequest(&amp;quot;GET&amp;quot;, TARGET_URL, nil)
	if err != nil {
		panic(err.Error())
	}

	resp, err := client.Do(req)
	if err != nil {
		fmt.Println(err.Error())
		ngch &amp;lt;- 1
		return
	}
	defer resp.Body.Close()

	_, err = ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Println(err.Error())
		ngch &amp;lt;- 1
		return
	}

	okch &amp;lt;- 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;デフォルト設定: &lt;code&gt;[RESULT] request: 3000, ok: 530, ng: 2470, time(ms) 173&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;MaxIdleConnsPerHostを3000に: &lt;code&gt;[RESULT] request: 3000, ok: 3000, ng: 0, time(ms) 88&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;全てのリクエストが時間内に捌けるようになったので効果があったようだ。&lt;/p&gt;

&lt;p&gt;ただ、このコードのようにgoroutineを無尽蔵に生成すると、限界を超えたときにタイムアウトが頻発してしまうので注意。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/74&#34;&gt;Goroutineの数をworkerで抑制する - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ちなみに、&lt;a href=&#34;https://github.com/tcnksm/go-httpstat&#34;&gt;tcnksm/go-httpstat&lt;/a&gt;でnet/http/httptraceすると各処理にかかっている時間が分かる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;req, err := http.NewRequest(&amp;quot;GET&amp;quot;, TARGET_URL, nil)
if err != nil {
	panic(err.Error())
}

result := new(httpstat.Result)
ctx := httpstat.WithHTTPStat(req.Context(), result)
req = req.WithContext(ctx)

resp, err := client.Do(req)
if err != nil {
	fmt.Println(err.Error())
	ngch &amp;lt;- 1
	return
}
defer resp.Body.Close()

_, err = ioutil.ReadAll(resp.Body)
if err != nil {
	fmt.Println(err.Error())
	ngch &amp;lt;- 1
	return
}

result.End(time.Now())
fmt.Printf(&amp;quot;%+v\n&amp;quot;, result)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Start Transfer:   85 ms
Total:            86 ms

DNS lookup:           0 ms
TCP connection:       0 ms
TLS handshake:        0 ms
Server processing:   64 ms
Content transfer:     1 ms

Name Lookup:       0 ms
Connect:           0 ms
Pre Transfer:      0 ms
Start Transfer:   64 ms
Total:            65 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://shogo82148.github.io/blog/2017/01/14/re-golang-dns-cache/&#34;&gt;Re:golang の http.Client を速くする - Shogo&amp;rsquo;s Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>iftopでネットワークの帯域を見る</title>
          <link>https://www.sambaiz.net/article/60/</link>
          <pubDate>Tue, 07 Feb 2017 20:30:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/60/</guid>
          <description>&lt;pre&gt;&lt;code&gt;$ yum install --enablerepo=epel iftop
$ iftop -f &amp;quot;not dst net 10.0.0.0/8&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;-i eth0&lt;/code&gt;のようにしてインタフェースを指定し、&lt;code&gt;-f&lt;/code&gt;でフィルタをかけられる。フィルタの詳細は&lt;code&gt;man pcap-filter&lt;/code&gt;で。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                          12.5Kb                     25.0Kb                     37.5Kb                     50.0Kb		62.5Kb
└─────────────────────────┴──────────────────────────┴──────────────────────────┴──────────────────────────┴──────────────────────────
ip-172-31-9-9.ap-northeast-1.compute.internal         =&amp;gt; 61-121-217-66.dh-connect.net                          1.72Kb  6.57Kb  2.40Kb
                                                      &amp;lt;=                                                        416b   2.13Kb   702b
...
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
TX:             cum:   22.6KB   peak:   13.2Kb                                                        rates:   1.22Kb  1.27Kb  2.46Kb
RX:                    6.63KB           5.03Kb                                                                  208b    330b    748b
TOTAL:                 29.2KB           18.2Kb                                                                 1.42Kb  1.59Kb  3.19Kb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;左から2, 10, 40秒間の平均kbps。TXが送信量、RXが受信量で、cumが総量、peakが最大。&lt;/p&gt;

&lt;p&gt;実行中に&lt;code&gt;S&lt;/code&gt;でソースのポートを&lt;code&gt;D&lt;/code&gt;でディスティネーションのポートが表示される。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>vmstatのメモ</title>
          <link>https://www.sambaiz.net/article/59/</link>
          <pubDate>Mon, 06 Feb 2017 22:45:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/59/</guid>
          <description>

&lt;pre&gt;&lt;code&gt;$ vmstat 間隔(秒)
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 118588  80388 2516284    0    0     2    77  141   85  1  0 98  0  0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;procs&#34;&gt;procs&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;r: 実行待ちプロセス数。CPUの処理が追いついていない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;b: 割り込み不可能なスリープ中のプロセス数。I/O待ちらしい。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;memory&#34;&gt;memory&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;swpd: バーチャルメモリの使用量。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;free: 空きメモリ量。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;buff: バッファに使われてるメモリ量。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cache: キャッシュに使われているメモリ量。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;swap&#34;&gt;swap&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;si: 秒あたりのスワップイン量。メモリが足りていない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;so: 秒あたりのスワップアウト量。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;io&#34;&gt;io&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;bi: 秒あたりのブロックデバイスから受け取ったブロック数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;bo: 秒あたりのブロックデバイスに送ったブロック数。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;system&#34;&gt;system&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;in: 秒あたりの割り込み回数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cs: 秒あたりの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B3%E3%83%B3%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%82%B9%E3%82%A4%E3%83%83%E3%83%81&#34;&gt;コンテキストスイッチ&lt;/a&gt;の回数。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cpu&#34;&gt;cpu&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;us: カーネル以外のコードでかかっている時間。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;sy: カーネルコードでかかっている時間。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;id: アイドルタイム。0だとCPUが全力で仕事中。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;wa: IO待ち時間。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;st: 要求したがCPUリソースを割り当ててもらえなかった時間。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://orebibou.com/2015/07/vmstat%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7%E8%A6%9A%E3%81%88%E3%81%A6%E3%81%8A%E3%81%8D%E3%81%9F%E3%81%84%E4%BD%BF%E3%81%84%E6%96%B98%E5%80%8B/&#34;&gt;vmstatコマンドで覚えておきたい使い方8個(+1個) | 俺的備忘録 〜なんかいろいろ〜&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.oracle.com/yappri/entry/vmstat&#34;&gt;vmstat コマンドの読み方 (やっぱり Sun がスキ！)&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>EC2のインスタンスストア</title>
          <link>https://www.sambaiz.net/article/58/</link>
          <pubDate>Mon, 06 Feb 2017 21:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/58/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/InstanceStorage.html&#34;&gt;http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/InstanceStorage.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;EC2ではインスタンスタイプによってはEBSに加えてインスタンスストアが使える。しかも追加料金なし。
対象はストレージが&amp;rdquo;EBSのみ&amp;rdquo;でないもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/ec2/instance-types/&#34;&gt;https://aws.amazon.com/jp/ec2/instance-types/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;インスタンスストアはインスタンスが停止したり、障害が起きると消える一時ストレージ。再起動では消えない。
ホストに物理的にアタッチされているので、バッファやキャッシュなどの頻繁に読み書きされ、消えてもいいデータに最適。
他のインスタンスにアタッチすることはできない。容量や性能もインスタンスタイプに依存する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/add-instance-store-volumes.html&#34;&gt;インスタンスストアボリュームの追加&lt;/a&gt;は
インスタンスの起動時に、新しいボリュームを追加し、ボリュームタイプをインスタンスストアにすることで行うことができる。&lt;/p&gt;

&lt;p&gt;今回はSSDストレージ1 x 4のm3.mediumで試す。これは4gbのボリュームが一つ追加できるという意味。&lt;/p&gt;

&lt;p&gt;まずはインスタンスストアを追加してないインスタンス。
lsblkというのはlist block devicesの略。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ df -h
ファイルシス   サイズ  使用  残り 使用% マウント位置
/dev/xvda1       7.8G  1.2G  6.6G   15% /
...
$ dd if=/dev/zero of=hoge bs=1M count=1000
$ ls -sh
合計 1001M
1001M hoge

$ df -h
ファイルシス   サイズ  使用  残り 使用% マウント位置
/dev/xvda1       7.8G  2.2G  5.6G   28% /
...

$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk 
└─xvda1 202:1    0   8G  0 part /
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それに対してインスタンスストア(/dev/xvdb)を追加したインスタンス。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ df -h
ファイルシス   サイズ  使用  残り 使用% マウント位置
/dev/xvda1       7.8G  1.2G  6.6G   15% /
/dev/xvdb        4.0G   73M  3.7G    2% /media/ephemeral0

$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk 
└─xvda1 202:1    0   8G  0 part /
xvdb    202:16   0   4G  0 disk /media/ephemeral0

$ dd if=/dev/zero of=/media/ephemeral0/hoge bs=1M count=1000
$ df -h
ファイルシス   サイズ  使用  残り 使用% マウント位置
/dev/xvda1       7.8G  1.2G  6.6G   15% /
/dev/xvdb        4.0G  1.1G  2.7G   29% /media/ephemeral0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/imaifactory/ephemeral-ssd&#34;&gt;EC2のストレージどう使う? -Instance Storageを理解して高速IOを上手に活用!-&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensでGaze, Click, Hold, Voiceイベントを拾う</title>
          <link>https://www.sambaiz.net/article/57/</link>
          <pubDate>Sun, 05 Feb 2017 20:01:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/57/</guid>
          <description>

&lt;p&gt;こんなの。SparitalMappingを有効にしているので球が床で止まっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/57.png&#34; alt=&#34;こんなの&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://youtu.be/wQLn_SO9Ics&#34;&gt;動画&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity&#34;&gt;HoloToolKit&lt;/a&gt;
のインタフェースを実装することでイベントを拾えるようになっている。&lt;/p&gt;

&lt;h2 id=&#34;ifocusable&#34;&gt;IFocusable&lt;/h2&gt;

&lt;p&gt;Gazeしたとき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void OnFocusEnter（）
{
    gazing = true;
}

public void OnFocusExit()
{
    gazing = false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;iinputclickhandler&#34;&gt;IInputClickHandler&lt;/h2&gt;

&lt;p&gt;クリックしたとき。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void OnInputClicked(InputEventData eventData)
{
    if (!clicked)
    {
        clicked = true;
        clickedRotationFrame = 0;
    }
    countUp();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;iholdhandler&#34;&gt;IHoldHandler&lt;/h2&gt;

&lt;p&gt;Hold(指を下げたまま維持する)したとき。
指を上げたときがCompletedで、Objectを外れたときCanceledになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void OnHoldStarted(HoldEventData eventData)
{
    holding = true;
    clicked = true;
}

public void OnHoldCompleted(HoldEventData eventData)
{
    holding = false;
}

public void OnHoldCanceled(HoldEventData eventData)
{
    holding = false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ispeechhandler&#34;&gt;ISpeechHandler&lt;/h2&gt;

&lt;p&gt;声の入力。
InspectorからSpeech Input Source(Script)を追加して反応するキーワードを設定して使う。
MicrophoneのCapabilitiesが必要。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void OnSpeechKeywordRecognized(SpeechKeywordRecognizedEventData eventData)
{
    switch (eventData.RecognizedText)
    {
        case &amp;quot;reset&amp;quot;:
            count = 0;
            num.GetComponent&amp;lt;TextMesh&amp;gt;().text = count.ToString();
            break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;全体。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using HoloToolkit.Unity.InputModule;
using UnityEngine;

public class CounterCube : MonoBehaviour, IFocusable, IInputClickHandler, IHoldHandler, ISpeechHandler
{
    // rotate ANIMATION_FRAME * ANIMATION_PER_FRAME degrees
    private const int ANIMATION_FRAME = 30;
    private const float ANIMATION_ROTATE_PER_FRAME = 60f / ANIMATION_FRAME;

    public GameObject cube;
    public GameObject num;

    private int count = 0;

    private bool gazing = false;
    private bool clicked = false;
    private int clickedRotationFrame = 0;
    private bool holding = false;
	
	// Update is called once per frame
	void Update ()
    {
        if(clicked)
        {
            if(clickedRotationFrame &amp;lt; ANIMATION_FRAME)
            {
                clickedRotationFrame++;
                cube.transform.localRotation = Quaternion.Euler(clickedRotationFrame * ANIMATION_ROTATE_PER_FRAME, clickedRotationFrame * ANIMATION_ROTATE_PER_FRAME, 0);
            }
            else if (holding)
            {
                // continue to count up
                clickedRotationFrame = 0;
                countUp();
            }
            else
            {
                clicked = false;
            }

        }

        if (holding)
        {
            cube.GetComponent&amp;lt;Renderer&amp;gt;().material.color = Color.green;
        }
        else if (gazing)
        {
            cube.GetComponent&amp;lt;Renderer&amp;gt;().material.color = Color.blue;
        }
        else
        {
            cube.GetComponent&amp;lt;Renderer&amp;gt;().material.color = Color.gray;
        }
    }

    public void OnFocusEnter()
    {
        gazing = true;
    }

    public void OnFocusExit()
    {
        gazing = false;
    }

    public void OnInputClicked(InputEventData eventData)
    {
        if (!clicked)
        {
            clicked = true;
            clickedRotationFrame = 0;
        }
        countUp();
    }

    public void OnHoldStarted(HoldEventData eventData)
    {
        holding = true;
        clicked = true;
    }

    public void OnHoldCompleted(HoldEventData eventData)
    {
        holding = false;
    }

    public void OnHoldCanceled(HoldEventData eventData)
    {
        holding = false;
    }

    private void countUp()
    {
        num.GetComponent&amp;lt;TextMesh&amp;gt;().text = (++count).ToString();
        var sphere = GameObject.CreatePrimitive(PrimitiveType.Sphere);
        sphere.transform.position = transform.position;
        sphere.transform.localScale = Vector3.one * 0.1f;
        sphere.AddComponent&amp;lt;Rigidbody&amp;gt;();
    }

    public void OnSpeechKeywordRecognized(SpeechKeywordRecognizedEventData eventData)
    {
        switch (eventData.RecognizedText)
        {
            case &amp;quot;reset&amp;quot;:
                count = 0;
                num.GetComponent&amp;lt;TextMesh&amp;gt;().text = count.ToString();
                break;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HoloLensの開発を始める</title>
          <link>https://www.sambaiz.net/article/56/</link>
          <pubDate>Sat, 04 Feb 2017 21:28:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/56/</guid>
          <description>

&lt;h2 id=&#34;hololensでのアプリケーション&#34;&gt;HoloLensでのアプリケーション&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/app_model&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/app_model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ある点を見るGazeと指で選択するGesture、声で入力するVoiceで操作する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/hololens_shell_overview&#34;&gt;HoloLens shell&lt;/a&gt;
では壁などにタイルを配置することでアプリケーションが起動する。&lt;/p&gt;

&lt;p&gt;一度に動くアプリケーションは一つ。
他にアクティブなアプリケーションがあれば中断され、タイルは最後の状態のスクリーンショットになる。
タイルを削除するとプロセスが終了する。&lt;/p&gt;

&lt;p&gt;Viewには空間全体を使うHolographic Viewと、通常のウィンドウのような2D Viewがある。&lt;/p&gt;

&lt;h2 id=&#34;開発を始める&#34;&gt;開発を始める&lt;/h2&gt;

&lt;p&gt;Unityを使ってHolographic Viewのアプリケーションを開発する。&lt;/p&gt;

&lt;p&gt;必要なツールをインストールする。エミュレーターは空きメモリが2GB以上ないと立ち上がらない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/install_the_tools&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/install_the_tools&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;チュートリアル&#34;&gt;チュートリアル&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/holograms_100&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/holograms_100&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;QualityのところでWindows Storeのマークがなかったら、
UnityのFile-&amp;gt;Build SettingsからWindows Storeモジュールをダウンロードする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/holograms_101e&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/holograms_101e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;エミュレーターはWASDキーで移動してカーソルキーで向きを変え、エンターキーで選択できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/56-hololens.PNG&#34; alt=&#34;エミュレーターで実行した画面&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;エミュレーターで動かしてみる&#34;&gt;エミュレーターで動かしてみる&lt;/h2&gt;

&lt;p&gt;UnityProjectを作成してHolograms 100のように設定していく。&lt;/p&gt;

&lt;p&gt;まずはCamera。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Position: (0,0,0)&lt;/li&gt;
&lt;li&gt;Clear Flags: Solid Color&lt;/li&gt;
&lt;li&gt;Background: (0,0,0,0)&lt;/li&gt;
&lt;li&gt;Clipping Planes Near: 0.85&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;とりあえず動くことを確認するため適当なオブジェクトを置いてビルドしてみる。&lt;/p&gt;

&lt;p&gt;Edit-&amp;gt;Project Settings-&amp;gt;QualityでWindows StoreをFastestにする。&lt;/p&gt;

&lt;p&gt;Build Settings-&amp;gt;Windows Storeで&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SDK: Universal: 10&lt;/li&gt;
&lt;li&gt;Target device: HoloLens&lt;/li&gt;
&lt;li&gt;UWP Build Type: D3D&lt;/li&gt;
&lt;li&gt;Unity C# Projectにチェック&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;にする。&lt;/p&gt;

&lt;p&gt;BuildSettingsにあるPlayer Settingsボタンを押して
Other SettingsのVirtual Reality Supportedにチェックを入れ、
SDKsにWindows Holographicが出るのを確認する。&lt;/p&gt;

&lt;p&gt;あとはBuild SettingsでAdd Open ScenesしてBuild。適当なディレクトリを作って選ぶとUWPのVSプロジェクトができるので
上のところでRelease,x86,HoloLens Emulatrorにしてデバッグメニューからデバッグなしで開始する。
エミュレーターが立ち上がって置いたオブジェクトが見えたらうまくいっている。&lt;/p&gt;

&lt;h3 id=&#34;uwp-ユニバーサル-windows-プラットフォーム-とは-https-docs-microsoft-com-ja-jp-windows-uwp-get-started-universal-application-platform-guide&#34;&gt;&lt;a href=&#34;https://docs.microsoft.com/ja-jp/windows/uwp/get-started/universal-application-platform-guide&#34;&gt;UWP(ユニバーサル Windows プラットフォーム)とは&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Windows 8でWindowsランタイム(WinRT)として導入された、
PCだけではなく、タブレット、Xbox、HoloLensなど、様々なWindowsデバイス共通のアプリプラットフォーム。&lt;/p&gt;

&lt;p&gt;PCではデスクトップデバイスファミリ、タブレットではモバイルデバイスファミリといったような、デバイスファミリに基づいたOSが実行される。
UWPアプリでは、共通のWinRT APIだけではなく各デバイスファミリ固有のAPIも呼び出すこともでき、
アプリのターゲットとするデバイスファミリを選択することができる。&lt;/p&gt;

&lt;h2 id=&#34;holotoolkitを使う&#34;&gt;HoloToolKitを使う&lt;/h2&gt;

&lt;p&gt;実装やビルドを楽にするやつ。上のような初期設定はやらなくていい。&lt;/p&gt;

&lt;h3 id=&#34;準備&#34;&gt;準備&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/blob/master/GettingStarted.md&#34;&gt;https://github.com/Microsoft/HoloToolkit-Unity/blob/master/GettingStarted.md&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Microsoft/HoloToolkit-Unity/releases&#34;&gt;ここ&lt;/a&gt;からunitypackageをダウンロードして
UnityのAssetsメニューからインポートする。&lt;/p&gt;

&lt;p&gt;HoloToolKitメニューができるのでConfigureする。&lt;/p&gt;

&lt;p&gt;Main CameraとDirectional Lightを消して
&lt;code&gt;HoloToolkit/Input/Prefabs/HoloLensCamera.prefab&lt;/code&gt;と、
&lt;code&gt;HoloToolkit/Input/Prefabs/Cursor/DefaultCursor.prefab&lt;/code&gt;を置く。&lt;/p&gt;

&lt;p&gt;Create Emptyして&amp;rdquo;Managers&amp;rdquo;にリネームし、この中に
&lt;code&gt;HoloToolkit/Input/Prefabs/InputManager.prefab&lt;/code&gt;を入れる。&lt;/p&gt;

&lt;p&gt;Managersの中にUI -&amp;gt; EventSystemを作成する。&lt;/p&gt;

&lt;p&gt;SparitalMappingする場合は、
&lt;code&gt;HoloToolkit/SpartialMapping/Prefabs/SpartialMapping.prefab&lt;/code&gt;をMangersに入れて
Editor -&amp;gt;　Project Settings -&amp;gt;　PlayerのPublishing Settingsから
SpartialPerceptionにチェックを入れる。&lt;/p&gt;

&lt;p&gt;HoloToolkitメニューからBuild Window -&amp;gt; Build Visual Studio SLNで
ビルドし、Open SLNでVisual Studioが立ち上がる。
ビルドの際にクラッシュしたらWindows Storeモジュールが入っているか確認する。&lt;/p&gt;

&lt;h2 id=&#34;実機での実行&#34;&gt;実機での実行&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/Using_Visual_Studio.html#deploying_an_app_over_wi-fi&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/Using_Visual_Studio.html#deploying_an_app_over_wi-fi&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Visual StudioでDeviceをHoloLens EmulatorからRemote Deviceに変更する。
HoloLensのIPアドレスはSettings -&amp;gt; Network &amp;amp; Internet -&amp;gt; Advanced Optionで確認して、
認証モードはユニバーサルにしてデバッグなしで開始する。&lt;/p&gt;

&lt;p&gt;PINコードを要求されるので、Settings -&amp;gt;Update &amp;amp; Security -&amp;gt; For developersから
Developer modeをonにし、その下のPaired devicesで表示されるPINコードを入力する。&lt;/p&gt;

&lt;h2 id=&#34;スクリーンショットの撮り方&#34;&gt;スクリーンショットの撮り方&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/using_mixed_reality_capture&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/using_mixed_reality_capture&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;カメラで撮れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/56-hololens2.jpg&#34; alt=&#34;実機で実行した画面&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;windows-device-portal&#34;&gt;Windows Device Portal&lt;/h2&gt;

&lt;p&gt;PCのブラウザからいろいろできるツール。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/holographic/Using_the_Windows_Device_Portal.html#mixed_reality_capture&#34;&gt;https://developer.microsoft.com/en-us/windows/holographic/Using_the_Windows_Device_Portal.html#mixed_reality_capture&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Settings -&amp;gt;Update &amp;amp; Security -&amp;gt; For developersからDevice Portalをonにすると
&lt;a href=&#34;https://HoloLensのIPアドレス&#34;&gt;https://HoloLensのIPアドレス&lt;/a&gt;
でアクセスできる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのrecord_transformerでログを加工する</title>
          <link>https://www.sambaiz.net/article/55/</link>
          <pubDate>Fri, 03 Feb 2017 21:14:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/55/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/filter_record_transformer&#34;&gt;http://docs.fluentd.org/v0.12/articles/filter_record_transformer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;追加したり、編集したり、削除したりできるフィルタ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;filter hoge.log&amp;gt;
  @type record_transformer
  enable_ruby
  auto_typecast true
  remove_keys b,d

  &amp;lt;record&amp;gt;
    what_is_tag ${tag}
    what_is_a ${record[&amp;quot;a&amp;quot;]}
    what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1}
  &amp;lt;/record&amp;gt;
&amp;lt;/filter&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この例だとタグを値に持つ&amp;rdquo;what_is_tag&amp;rdquo;、aを値に持つ&amp;rdquo;what_is_a&amp;rdquo;、b.cの値に1を足す&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;が追加され、
bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。&lt;/p&gt;

&lt;p&gt;auto_typecastをtrueにしないと&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;の値がstringになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: 1}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ tail /var/log/td-agent/td-agent.log
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーが起きるとnullになるが、それ以外の処理はされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: &amp;quot;error!&amp;quot;}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ tail /var/log/td-agent/td-agent.log
[warn]: failed to expand `record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1` error_class=TypeError error=&amp;quot;no implicit conversion of Fixnum into String&amp;quot;
...
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:null}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;フィルタ適用前と後をそれぞれoutputしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match hoge.log&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;
 
  &amp;lt;store&amp;gt;
    @type relabel
    @label @fuga
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;label @fuga&amp;gt;
  &amp;lt;filter hoge.log&amp;gt;
    @type record_transformer
    enable_ruby
    auto_typecast true
    remove_keys b,d
  
    &amp;lt;record&amp;gt;
      what_is_tag ${tag}
      what_is_a ${record[&amp;quot;a&amp;quot;]}
      what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1}
    &amp;lt;/record&amp;gt;
  &amp;lt;/filter&amp;gt;

  &amp;lt;match hoge.log&amp;gt;
    @type stdout
  &amp;lt;/match&amp;gt;
&amp;lt;/label&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;b&amp;quot;:{&amp;quot;c&amp;quot;:1},&amp;quot;d&amp;quot;:&amp;quot;fuga&amp;quot;}
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでElasticsearchに送る</title>
          <link>https://www.sambaiz.net/article/54/</link>
          <pubDate>Wed, 01 Feb 2017 21:51:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/54/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/uken/fluent-plugin-elasticsearch&#34;&gt;uken/fluent-plugin-elasticsearch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;必要なものをいれていく。Amazon LinuxのAMIから。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Failed to build gem native extension.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ yum install -y ruby-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;serverengine requires Ruby version &amp;gt;= 2.1.0.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/rbenv/rbenv&#34;&gt;rbenv&lt;/a&gt;でバージョンを上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv
$ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src
$ echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
$ ~/.rbenv/bin/rbenv init
$ echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
$ source ~/.bash_profile
$ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ rbenv -v
rbenv 1.1.0-2-g4f8925a
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Ruby install aborted due to missing extensions&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ yum install -y openssl-devel readline-devel zlib-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ rbenv install -l
1.8.5-p113
1.8.5-p114
1.8.5-p115
...

$ rbenv install 2.4.0
$ rbenv global 2.4.0
$ ruby -v
ruby 2.4.0p0 (2016-12-24 revision 57164) [x86_64-linux]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;td-agent.confはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type elasticsearch
  host *****
  port 9200
  index_name test_index
  type_name test_type
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ curl *****:9200/test_index/test_type/_search?pretty
{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVn5puy79PEDL_x5e_u3&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;a&amp;quot; : &amp;quot;b&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logstash formatでも入れてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type elasticsearch
  host *****
  port 9200
  logstash_format true
  logstash_prefix aaaa
  type_name test_type
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ curl *****:9200/aaaa-2017.02.02/_search?pretty
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;aaaa-2017.02.02&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVn_FyQP7q9Gyu5HC4Mq&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;a&amp;quot; : &amp;quot;b&amp;quot;,
          &amp;quot;@timestamp&amp;quot; : &amp;quot;2017-02-02T22:49:33+09:00&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;forwardと同じく
&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/buffer-plugin-overview&#34;&gt;Buffered Output plugin&lt;/a&gt;を
&lt;a href=&#34;https://github.com/uken/fluent-plugin-elasticsearch#buffered-output-options&#34;&gt;継承しているので&lt;/a&gt;
buffer_typeのデフォルトはmemory。必要ならfileにする。いずれにせよスパイクなどでbuffer_queue_limitを超えないように余裕をもっておく。
また、buffer_chunk_limitがElasticsearchのhttp.max_content_length(デフォルト100mb)を超えないようにする。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのnet/http.Client.Doの内部実装をたどったメモ</title>
          <link>https://www.sambaiz.net/article/53/</link>
          <pubDate>Mon, 30 Jan 2017 20:55:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/53/</guid>
          <description>

&lt;pre&gt;&lt;code&gt;package main

import (
        &amp;quot;fmt&amp;quot;
        &amp;quot;net/http&amp;quot;
        &amp;quot;io/ioutil&amp;quot;
)

var client = http.Client{}

func main() {

        req, err := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;http://example.com&amp;quot;, nil)
        if err != nil{
                panic(err)
        }

        resp, err := client.Do(req)
        if err != nil{
                panic(err)
        }
        defer resp.Body.Close()

        body, err := ioutil.ReadAll(resp.Body)
        if err != nil{
                panic(err)
        }

        fmt.Println(string(body))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;client&#34;&gt;Client&lt;/h3&gt;

&lt;p&gt;TransportがTCPコネクションをキャッシュするのでClientは使い回すべき。複数のgoroutineでコンカレントに使っても大丈夫。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Client struct {

        // nilならDefaultTransportが使われる        
    	Transport RoundTripper

        // nilなら10回で止まる
        CheckRedirect func(req *Request, via []*Request) error

        // nilならcookieは無視される
        Jar CookieJar

        Timeout time.Duration
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MaxIdleConnsとは別に、ホストごとの制限がある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/61/&#34;&gt;Goのnet/httpとKeep-Alive - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L39&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L39&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var DefaultTransport RoundTripper = &amp;amp;Transport{
	Proxy: ProxyFromEnvironment,
	DialContext: (&amp;amp;net.Dialer{
		Timeout:   30 * time.Second,
		KeepAlive: 30 * time.Second,
		DualStack: true,
	}).DialContext,
	MaxIdleConns:          100,
	IdleConnTimeout:       90 * time.Second,
	TLSHandshakeTimeout:   10 * time.Second,
	ExpectContinueTimeout: 1 * time.Second,
}

const DefaultMaxIdleConnsPerHost = 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;request&#34;&gt;Request&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/request.go#L690&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/request.go#L690&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewRequest(method, urlStr string, body io.Reader) (*Request, error) {
    ...
    
    u, err := url.Parse(urlStr)
    
    ...
    
    rc, ok := body.(io.ReadCloser)
    req := &amp;amp;Request{
            Method:     method,
            URL:        u,
            Proto:      &amp;quot;HTTP/1.1&amp;quot;,
            ProtoMajor: 1,
            ProtoMinor: 1,
            Header:     make(Header),
            Body:       rc,
            Host:       u.Host,
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;do&#34;&gt;Do&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L181&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L181&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Requestを渡してResponseを受け取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) Do(req *Request) (*Response, error) {
    method := valueOrDefault(req.Method, &amp;quot;GET&amp;quot;)
    if method == &amp;quot;GET&amp;quot; || method == &amp;quot;HEAD&amp;quot; {
        return c.doFollowingRedirects(req, shouldRedirectGet)
    }
    if method == &amp;quot;POST&amp;quot; || method == &amp;quot;PUT&amp;quot; {
        return c.doFollowingRedirects(req, shouldRedirectPost)
    }
    return c.send(req, c.deadline())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dofollowingredirects&#34;&gt;doFollowingRedirects&lt;/h3&gt;

&lt;p&gt;リクエストを送り、リダイレクトする場合はして、そうでない場合はレスポンスを返す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L440&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L440&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) doFollowingRedirects(req *Request, shouldRedirect func(int) bool) (*Response, error) {
    ...

    for{

        ...
        
        if resp, err = c.send(req, deadline); err != nil {
            if !deadline.IsZero() &amp;amp;&amp;amp; !time.Now().Before(deadline) {
                err = &amp;amp;httpError{
                    err:     err.Error() + &amp;quot; (Client.Timeout exceeded while awaiting headers)&amp;quot;,
                    timeout: true,
                }
            }
            return nil, uerr(err)
        }

        if !shouldRedirect(resp.StatusCode) {
            return resp, nil
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;send&#34;&gt;send&lt;/h3&gt;

&lt;p&gt;ClientのTransportのRoundTripを呼ぶ。ここからはTransport(RoundTripper)の仕事。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L140&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L140&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) send(req *Request, deadline time.Time) (*Response, error) {
    
    ...
    
    resp, err := send(req, c.transport(), deadline)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L208&#34;&gt;https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L208&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func send(ireq *Request, rt RoundTripper, deadline time.Time) (*Response, error) {
   
    ...
    
    resp, err := rt.RoundTrip(req)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;roundtrip&#34;&gt;RoundTrip&lt;/h3&gt;

&lt;p&gt;チャネルを通して接続先とやりとりする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L319&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L319&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (t *Transport) RoundTrip(req *Request) (*Response, error) {
    
    ...
    
    treq := &amp;amp;transportRequest{Request: req, trace: trace}
    
    ...
	
    cm, err := t.connectMethodForRequest(treq)
    pconn, err := t.getConn(treq, cm)
   
    ...
    
    resp, err = pconn.roundTrip(treq)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;writeとreadを同時に行っているのはサーバーがbodyのすべてを読む前にレスポンスを返すときのため。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L1823&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L1823&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (pc *persistConn) roundTrip(req *transportRequest) (resp *Response, err error) {
    
    ...
    
    pc.writech &amp;lt;- writeRequest{req, writeErrCh, continueCh} // pc.writeLoopで読まれる

    resc := make(chan responseAndError)
	pc.reqch &amp;lt;- requestAndChan{ // pc.readLoopで読まれる
		req:        req.Request,
		ch:         resc,
		addedGzip:  requestedGzip,
		continueCh: continueCh,
		callerGone: gone,
	}
    var re responseAndError
    
    ...
    
    case re = &amp;lt;-resc: // pc.readLoopで書き込まれる
		re.err = pc.mapRoundTripErrorFromReadLoop(req.Request, startBytesWritten, re.err)
		break WaitResponse
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pconn-getconn-dialconn&#34;&gt;pconn.getConn/dialConn&lt;/h3&gt;

&lt;p&gt;接続し、チャネルを読むループ(readLoop, writeLoop)を回す。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L865&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L865&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (t *Transport) getConn(treq *transportRequest, cm connectMethod) (*persistConn, error) {
    ...
    type dialRes struct {
		pc  *persistConn
		err error
	}
    dialc := make(chan dialRes)
    
    ...
    
    go func() {
		pc, err := t.dialConn(ctx, cm)
		dialc &amp;lt;- dialRes{pc, err}
	}()
    
    ...
    
    select {
	case v := &amp;lt;-dialc:
        if v.pc != nil {
            
            ...
			
            return v.pc, nil
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L967&#34;&gt;https://github.com/golang/go/blob/d986daec1375527ef78cd59d81d42be7406a9803/src/net/http/transport.go#L967&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (t *Transport) dialConn(ctx context.Context, cm connectMethod) (*persistConn, error) {
    pconn := &amp;amp;persistConn{
		t:             t,
		cacheKey:      cm.key(),
		reqch:         make(chan requestAndChan, 1), // roundTripで書かれて、readLoopで読まれる
		writech:       make(chan writeRequest, 1), // roundTripで書かれて、writeLoopで読まれる
		closech:       make(chan struct{}),
		writeErrCh:    make(chan error, 1),
		writeLoopDone: make(chan struct{}),
	}

    ...
    
    conn, err := t.dial(ctx, &amp;quot;tcp&amp;quot;, cm.addr())
	pconn.conn = conn
    
    ...
    
    go pconn.readLoop()
	go pconn.writeLoop()
	return pconn, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ライセンス&#34;&gt;ライセンス&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;Copyright (c) 2009 The Go Authors. All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

   * Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.
   * Redistributions in binary form must reproduce the above
copyright notice, this list of conditions and the following disclaimer
in the documentation and/or other materials provided with the
distribution.
   * Neither the name of Google Inc. nor the names of its
contributors may be used to endorse or promote products derived from
this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
&amp;quot;AS IS&amp;quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
          <link>https://www.sambaiz.net/article/52/</link>
          <pubDate>Sun, 29 Jan 2017 17:08:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/52/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;vm.max_map_count
(&lt;a href=&#34;http://www.atmarkit.co.jp/flinux/special/proctune/proctune02b.html&#34;&gt;バーチャルメモリにマッピングできる最大ページ数&lt;/a&gt;)
を262144以上にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sysctl vm.max_map_count
$ grep vm.max_map_count /etc/sysctl.conf
vm.max_map_count=262144
# sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-cap-add=IPC_LOCK&lt;/code&gt;でLock memory(スワップアウトしないようにする)を
&lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&#34;&gt;許可&lt;/a&gt;する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。
ただし、物理RAMの50%以下で、&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#compressed_oops&#34;&gt;32GB近辺の境界を超えないようにする&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p ~/do/elasticsearch/data
$ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \
--name elasticsearch \
-p 9200:9200 \
-e xpack.security.enabled=false \
-e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;quot;-Xms28g -Xmx28g&amp;quot; \
--cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \
--restart=always \
docker.elastic.co/elasticsearch/elasticsearch:5.1.2

$ docker volume ls
local               elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;問題なく起動しているか確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200 | jq
{
  &amp;quot;name&amp;quot;: &amp;quot;eqIkJ48&amp;quot;,
  &amp;quot;cluster_name&amp;quot;: &amp;quot;docker-cluster&amp;quot;,
  &amp;quot;cluster_uuid&amp;quot;: &amp;quot;Lsu_C7wORS6G-0m9PJ9sFQ&amp;quot;,
  &amp;quot;version&amp;quot;: {
    &amp;quot;number&amp;quot;: &amp;quot;5.1.2&amp;quot;,
    &amp;quot;build_hash&amp;quot;: &amp;quot;c8c4c16&amp;quot;,
    &amp;quot;build_date&amp;quot;: &amp;quot;2017-01-11T20:18:39.146Z&amp;quot;,
    &amp;quot;build_snapshot&amp;quot;: false,
    &amp;quot;lucene_version&amp;quot;: &amp;quot;6.3.0&amp;quot;
  },
  &amp;quot;tagline&amp;quot;: &amp;quot;You Know, for Search&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html&#34;&gt;dynamic mapping&lt;/a&gt;
を無効にする場合&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/_template/template_all?pretty&#39; -d&#39;
{
  &amp;quot;template&amp;quot;: &amp;quot;*&amp;quot;,
  &amp;quot;order&amp;quot;:0,
  &amp;quot;settings&amp;quot;: {
    &amp;quot;index.mapper.dynamic&amp;quot;: false 
  }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kuromojiを入れる場合&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec -it ***** bin/elasticsearch-plugin install analysis-kuromoji
$ docker restart  *****
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;grafanaで可視化する&#34;&gt;Grafanaで可視化する&lt;/h2&gt;

&lt;p&gt;前は&lt;a href=&#34;https://www.sambaiz.net/article/19/&#34;&gt;InfluxDBとつなげた&lt;/a&gt;が、Elasticsearchにも対応している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p /var/lib/grafana/plugins
$ docker run -itd --restart=always -p 3000:3000 -v grafana:/var/lib/grafana grafana/grafana
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.grafana.org/datasources/elasticsearch/&#34;&gt;http://docs.grafana.org/datasources/elasticsearch/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;admin/adminでログインして、data sourceを追加する。AccessはProxyにする。&lt;/p&gt;

&lt;p&gt;適当にデータを入れて表示してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/test_index?pretty&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;test_type&amp;quot;: { 
      &amp;quot;_all&amp;quot;:       { &amp;quot;enabled&amp;quot;: false  }, 
      &amp;quot;properties&amp;quot;: { 
        &amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot; },
        &amp;quot;age&amp;quot;:    { &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;  },
        &amp;quot;timestamp&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;epoch_millis&amp;quot; }
      }
    }
  }
}
&#39;

$ curl &#39;localhost:9200/_cat/indices?format=json&amp;amp;pretty&#39;
[
  {
    &amp;quot;health&amp;quot; : &amp;quot;yellow&amp;quot;,
    &amp;quot;status&amp;quot; : &amp;quot;open&amp;quot;,
    &amp;quot;index&amp;quot; : &amp;quot;test_index&amp;quot;,
    &amp;quot;uuid&amp;quot; : &amp;quot;kVbt2V-rS2m6vhplIkMKNg&amp;quot;,
    &amp;quot;pri&amp;quot; : &amp;quot;5&amp;quot;,
    &amp;quot;rep&amp;quot; : &amp;quot;1&amp;quot;,
    &amp;quot;docs.count&amp;quot; : &amp;quot;0&amp;quot;,
    &amp;quot;docs.deleted&amp;quot; : &amp;quot;0&amp;quot;,
    &amp;quot;store.size&amp;quot; : &amp;quot;260b&amp;quot;,
    &amp;quot;pri.store.size&amp;quot; : &amp;quot;260b&amp;quot;
  },
  ...
]

$ curl -XPOST &#39;localhost:9200/test_index/test_type?pretty&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;hoge fuga&amp;quot;,
    &amp;quot;age&amp;quot;: 24,
    &amp;quot;timestamp&amp;quot;: 1485676393044
}
&#39;

$ curl &#39;localhost:9200/test_index/test_type/_search?pretty&#39;
{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVnpOGrseo3fDHi0SK-P&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;name&amp;quot; : &amp;quot;hoge fuga&amp;quot;,
          &amp;quot;age&amp;quot; : 24,
          &amp;quot;timestamp&amp;quot; : 1485676393044
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/52.png&#34; alt=&#34;表示してみた&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのforward</title>
          <link>https://www.sambaiz.net/article/51/</link>
          <pubDate>Wed, 25 Jan 2017 22:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/51/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/high-availability#network-topology&#34;&gt;td-agent間でログをやりとりするとき&lt;/a&gt;
に使われるforwardについて。内部では&lt;a href=&#34;http://docs.fluentd.org/articles/in_forward#protocol&#34;&gt;MessagePackを使っている&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;forward-input&#34;&gt;forward input&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/in_forward&#34;&gt;http://docs.fluentd.org/articles/in_forward&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;受け取る側。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/etc/init.d/td-agent restart&lt;/code&gt;してfluent-catで送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat -h xx.xx.xx.xx test.tag
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/var/log/td-agent/td-agent.log&lt;/code&gt;に出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test.tag: {&amp;quot;hoge&amp;quot;:&amp;quot;fuga&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;forward-output&#34;&gt;forward output&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward&#34;&gt;http://docs.fluentd.org/articles/out_forward&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/buffer-plugin-overview&#34;&gt;http://docs.fluentd.org/articles/buffer-plugin-overview&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;送る側。&lt;/p&gt;

&lt;p&gt;ポートはデフォルトで24224で、イベントの送信にTCPを、heartbeatにUDP(heartbeat_typeで変えられる)を使う。&lt;/p&gt;

&lt;p&gt;flush_intervalははデフォルトで&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#flushinterval&#34;&gt;60秒&lt;/a&gt;。
確認のときは短くしておくと分かりやすい。
buffer_queueの一番上のチャンクがこの時間経過するか、サイズがbuffer_chunk_limitを超えると、一番下のチャンクが書き込まれ、新しいチャンクがpushされる。
chunkの数がbuffer_queue_limitに到達してしまうと新しいイベントは破棄されてしまうので
リソースを圧迫(buffer_chunk_limit * buffer_queue_limit)しない程度に十分大きな数にしておき、
スパイクや障害時に備えておく。
buffer_typeはデフォルトがmemory。fileだと&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#flushatshutdown&#34;&gt;flush_at_shutdownのデフォルトがfalse&lt;/a&gt;なので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type forward

  flush_interval 1s

  buffer_type file
  buffer_path /var/log/td-agent/forward-buf
  flush_at_shutdown true
  buffer_chunk_limit 256m

  &amp;lt;server&amp;gt;
    name log_server
    host xx.xx.xx.xx
    port 24224
  &amp;lt;/server&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;冗長化&#34;&gt;冗長化&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#ltservergt-at-least-one-is-required&#34;&gt;server&lt;/a&gt;は複数書くことができ、
それぞれにweight(デフォルトは60)を設定したり、
&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#standby&#34;&gt;standby&lt;/a&gt;を付けることでActive-Standbyの構成にすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type forward

  ...

  &amp;lt;server&amp;gt;
    name log_server
    host xx.xx.xx.xx
    port 24224
    weight 60
  &amp;lt;/server&amp;gt;

  &amp;lt;server&amp;gt;
    name log_server2
    host yy.yy.yy.yy
    port 24224
    weight 60
  &amp;lt;/server&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;片方のサーバーをtd-agentをstopしてstartしてみるとこんなログが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;detached forwarding server &#39;log_server2&#39; host=&amp;quot;yy.yy.yy.yy&amp;quot; port=24224 phi=16.06814271743242 phi_threshold=16
recovered forwarding server &#39;log_server2&#39; host=&amp;quot;yy.yy.yy.yy&amp;quot; port=24224
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみにtd-agentはrootで動かしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/sysconfig/td-agent 
TD_AGENT_USER=root
TD_AGENT_GROUP=root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/113/&#34;&gt;fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのinterface/structの埋め込み</title>
          <link>https://www.sambaiz.net/article/50/</link>
          <pubDate>Wed, 18 Jan 2017 01:39:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/50/</guid>
          <description>

&lt;p&gt;Goには継承が存在しない。その代わりstructを埋め込み、委譲することができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/doc/effective_go.html#embedding&#34;&gt;https://golang.org/doc/effective_go.html#embedding&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;挙動&#34;&gt;挙動&lt;/h2&gt;

&lt;h3 id=&#34;interfaceにinterfaceを埋め込む&#34;&gt;interfaceにinterfaceを埋め込む&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;type I interface {
	Hoge()
}

type J interface {
	Fuga()
}

type K interface {
	I
	J
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インタフェースKはIとJを合わせたものになる。IとJに重複する関数がある場合はエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type L struct {
}

func (l L) Hoge() {
	fmt.Println(&amp;quot;hoge&amp;quot;)
}
func (l L) Fuga() {
	fmt.Println(&amp;quot;fuga&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;var k K
k = L{}
k.Hoge()
k.Fuga()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;structにinterfaceを埋め込む&#34;&gt;structにinterfaceを埋め込む&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;type K interface {
	Hoge()
	Fuga()
}

type M struct {
	K
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;埋め込むと&lt;code&gt;m.Hoge()&lt;/code&gt;のように透過的にKを扱うことができるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m := M{L{}}
m.Hoge()
// m.K.Hoge() これでも呼べる
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;埋め込まないとこうなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type M struct {
	k K
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;m := M{L{}}
m.k.Hoge()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;structにstructを埋め込む&#34;&gt;structにstructを埋め込む&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;type A struct {
	name string
}

type B struct {
	A
}

func (a A) hoge() {
	fmt.Println(&amp;quot;hoge&amp;quot;, a.name)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上と同様、&lt;code&gt;b.name&lt;/code&gt;や、&lt;code&gt;b.hoge()&lt;/code&gt;のように扱える。
Aの関数も呼べて一見継承しているように見えるが、実際はAへの委譲となる。なのでhogeのレシーバーはA。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b := B{}
b.name = &amp;quot;a&amp;quot;
// b = B{A{name: &amp;quot;a&amp;quot;}} 
b.hoge()
// b.A.hoge()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、Bにもhogeを実装すると、&lt;code&gt;b.hoge()&lt;/code&gt;でこちらが呼ばれることになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b B) hoge() {
	fmt.Println(&amp;quot;fuga&amp;quot;, b.name)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;b := B{}
b.name = &amp;quot;piyo&amp;quot;
b.hoge() // =&amp;gt; fuga piyo
b.A.hoge() // =&amp;gt; hoge piyo
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;継承との違い&#34;&gt;継承との違い&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;type A struct {
	name string
}

type B struct {
	A
}

func (a A) hoge() {
	fmt.Println(&amp;quot;hoge&amp;quot;, a.name)
}

func (a A) fuga() {
	a.hoge()
}

// override?
func (b B) hoge() {
	fmt.Println(&amp;quot;fuga&amp;quot;, b.name)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もし、BがAを継承しているとするとb.fuga()内でhoge()を呼ぶと、オーバーライドした、Bをレシーバーとするhoge()が呼ばれ、&amp;rdquo;fuga&amp;rdquo;が出力されるはずだ。
しかし、fuga()のレシーバーはAなので、呼ばれるのはAをレシーバーとする方のhoge()となり、&amp;rdquo;hoge&amp;rdquo;が出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b := B{}
b.name = &amp;quot;piyo&amp;quot;
b.fuga() // =&amp;gt; hoge piyo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、type Aの変数にBを代入することもできない。&lt;/p&gt;

&lt;h2 id=&#34;用途を探る&#34;&gt;用途を探る&lt;/h2&gt;

&lt;h3 id=&#34;interfaceのデフォルト実装&#34;&gt;interfaceのデフォルト実装&lt;/h3&gt;

&lt;p&gt;interfaceのデフォルトの実装を用意したstructを埋めることで、各structでは差分だけを実装すればいいようにできる。
ただデフォルト実装が他のデフォルト実装の関数を呼んでいる場合、呼び先の関数だけ実装しても元々の関数の動作は変わらないので注意。
レシーバーを意識する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Student interface {
	Plus(x int, y int) int
	Minus(x int, y int) int
}

type defaultStudent struct{}

func (defaultStudent) Plus(x int, y int) int {
	return x + y
}

func (defaultStudent) Minus(x int, y int) int {
	return x - y
}

type BadStudent struct {
	defaultStudent
}

func (BadStudent) Minus(x int, y int) int {
	return 0
}

type GeniusStudent struct {
	defaultStudent
}

func (GeniusStudent) Plus(x int, y int) int {
	if ans, err := strconv.Atoi(fmt.Sprintf(&amp;quot;%d%d&amp;quot;, x, y)); err != nil {
		fmt.Errorf(&amp;quot;genius student fails to %d + %d&amp;quot;, x, y)
		return 0
	} else {
		return ans
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;publicな機能の追加&#34;&gt;Publicな機能の追加&lt;/h3&gt;

&lt;p&gt;Publicな関数を提供するstructを埋め込み、それを直接外からも呼べるようにする。&lt;/p&gt;

&lt;p&gt;試しに、&lt;code&gt;sync.RWMutex()&lt;/code&gt;を埋め込んでみた。これはゼロ値でロックしていない状態なので初期化する必要はない。
一見良さそうに見えるが、この例だとLockとUnlockは内側でのみ呼ぶことを想定していて、外からうっかり呼んでしまうとおかしなことになってしまうだめな例。まあでもこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Twin struct {
	num     int
	sameNum int
	sync.RWMutex
}

func (l *Twin) Set(n int) {
	l.Lock()
	l.num = n
	l.sameNum = n
	l.Unlock()
}

func (l *Twin) Check() (ok bool) {
	l.RLock()
	ok = l.num == l.sameNum
	l.RUnlock()
	return
}

func main() {

	twin := new(Twin)

	for i := 0; i &amp;lt; 1000; i++ {
		go twin.Set(i)
		if !twin.Check() {
			panic(&amp;quot;broken&amp;quot;)
		}
	}

	fmt.Println(&amp;quot;success&amp;quot;)

	twin.Unlock() // panic!
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;privateな共通処理をまとめる&#34;&gt;Privateな共通処理をまとめる&lt;/h3&gt;

&lt;p&gt;privateな共通処理を埋め込むことでDRYに書けるように試みる。&lt;/p&gt;

&lt;p&gt;まず、状態を持たないような処理の場合。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (defaultStudent) hoge() bool {
	return true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これはパッケージが適切に切られていれば&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func hoge() bool {
	return true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と変わらず、埋め込む必要はないと思う。埋め込むとレシーバーから補完が効いて探しやすいかもしれないけれど。&lt;/p&gt;

&lt;p&gt;一方、状態を持つような処理の場合。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (n defaultStudent) counter() int {
    n.counter += 1
    return n.counter
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは埋め込むか、明示的にフィールドを持つかのどちらかになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type BadStudent struct {
	defaultStudent
}

or 

type BadStudent struct {
	d defaultStudent
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回の場合、defaultStudentにPublicなデフォルト実装があってそれを使うので埋め込んだ方が自然なような気もするけど、
そうでなければ埋め込まない方が移譲していることが分かりやすいと思う。せいぜい数文字増えるだけだし。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/sonatard/items/2b4b70694fd680f6297c&#34;&gt;オブジェクト指向言語としてGolangをやろうとするとハマる点を整理してみる - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goのpanicとrecover</title>
          <link>https://www.sambaiz.net/article/49/</link>
          <pubDate>Tue, 17 Jan 2017 23:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/49/</guid>
          <description>

&lt;h2 id=&#34;panic&#34;&gt;panic&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/builtin/#panic&#34;&gt;https://golang.org/pkg/builtin/#panic&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;panicは現在のgoroutineの通常の実行を停止する組み込み関数。
&lt;a href=&#34;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/runtime/panic.go#L26&#34;&gt;index out of range&lt;/a&gt;や
&lt;a href=&#34;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/runtime/panic.go#L61&#34;&gt;invalid memory address or nil pointer dereference&lt;/a&gt;
のときなどでも呼ばれる。&lt;/p&gt;

&lt;p&gt;deferを実行して呼び出し元に戻り、panicの実行-&amp;gt;deferの実行-&amp;gt;呼び出し元に戻る、を繰り返して
最後まで戻ったらプログラムを終了し、panicに渡した引数と共にエラーをレポートする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	a()
}

func a() {
	defer fmt.Println(&amp;quot;a&amp;quot;)
	b()
	fmt.Println(&amp;quot;a2&amp;quot;)
}

func b() {
	defer fmt.Println(&amp;quot;b1&amp;quot;)
	panic(&amp;quot;b2&amp;quot;)
	defer fmt.Println(&amp;quot;b3&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;b1
a
panic: b2

goroutine 1 [running]:
panic(0x89840, 0xc42000a2c0)
	/*****/libexec/src/runtime/panic.go:500 +0x1a1
main.b()
	/*****/main.go:19 +0x107
main.a()
	/*****/main.go:13 +0xce
main.main()
	/*****/main.go:8 +0x14
exit status 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;recover&#34;&gt;recover&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/builtin/#recover&#34;&gt;https://golang.org/pkg/builtin/#recover&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;deferで呼ぶことによってpanicを停止させることができる組み込み関数。
panicの引数に渡した値を取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	fmt.Println(a())
	fmt.Println(&amp;quot;main&amp;quot;)
}

func a() (ret string) {
	defer func() {
		if err := recover(); err != nil {
			fmt.Println(&amp;quot;recover -&amp;gt;&amp;quot;, err)
			ret = &amp;quot;panicked&amp;quot;
		}
	}()
	b()
	fmt.Println(&amp;quot;a2&amp;quot;)
	return &amp;quot;ok&amp;quot;
}

func b() {
	defer fmt.Println(&amp;quot;b1&amp;quot;)
	panic(&amp;quot;b2&amp;quot;)
	defer fmt.Println(&amp;quot;b3&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;b1
recover -&amp;gt; b2
panicked
main
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常はpanicもrecoverもあまり使わず、errorを返すことでハンドリングする。&lt;/p&gt;

&lt;p&gt;ではどんな時に使われるかというと、例えばWebフレームワーク&lt;a href=&#34;https://github.com/labstack/echo&#34;&gt;echo&lt;/a&gt;のRecover middlewareは
panicをrecoverしてinternal server errorとしてレスポンスを返すようにしている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/labstack/echo/blob/a96c564fc34b3fcbc5a1a67eeb9402243cdac6b2/middleware/recover.go#L66&#34;&gt;https://github.com/labstack/echo/blob/a96c564fc34b3fcbc5a1a67eeb9402243cdac6b2/middleware/recover.go#L66&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/labstack/echo/blob/54fb1015c1a51aed1c8e5ef6bf9e643b1a079acb/context.go#L525&#34;&gt;https://github.com/labstack/echo/blob/54fb1015c1a51aed1c8e5ef6bf9e643b1a079acb/context.go#L525&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/labstack/echo/blob/b2c623b07dd1362011f2677147ffbbe48ea3b178/echo.go#L284&#34;&gt;https://github.com/labstack/echo/blob/b2c623b07dd1362011f2677147ffbbe48ea3b178/echo.go#L284&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
        // Echo instance
        e := echo.New()

        // Middleware
        e.Use(middleware.Logger())
        e.Use(middleware.Recover())

        // Route =&amp;gt; handler
        e.GET(&amp;quot;/&amp;quot;, func(c echo.Context) error {
                panic(&amp;quot;fail&amp;quot;)
                return c.String(http.StatusOK, &amp;quot;Hello, World!\n&amp;quot;)
        })

        // Start server
        e.Logger.Fatal(e.Start(&amp;quot;:1323&amp;quot;))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;message&amp;quot;:&amp;quot;Internal Server Error&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ではRecover middlewareを使わなかったらアプリケーションが終了するかというと、
net/httpのserveでもrecoverしてるのでここでひっかかる(レスポンスは返らない)。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/net/http/server.go#L2625&#34;&gt;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/net/http/server.go#L2625&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/net/http/server.go#L1718&#34;&gt;https://github.com/golang/go/blob/b2a3b54b9520ce869d79ac8bce836a540ba45d09/src/net/http/server.go#L1718&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo: http: panic serving [::1]:53992: AA
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/defer-panic-and-recover&#34;&gt;Defer, Panic, and Recover - The Go Blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OAuth2.0のメモ</title>
          <link>https://www.sambaiz.net/article/48/</link>
          <pubDate>Sun, 08 Jan 2017 02:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/48/</guid>
          <description>

&lt;h2 id=&#34;認可-authorization-と認証-authentication&#34;&gt;認可(Authorization)と認証(Authentication)&lt;/h2&gt;

&lt;p&gt;それぞれAuthZ、AuthNとも書かれる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;認可: リソースへのアクセスを許可する&lt;/li&gt;
&lt;li&gt;認証: ユーザーが何者かを検証する&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;oauth-2-0&#34;&gt;OAuth 2.0&lt;/h2&gt;

&lt;p&gt;認可のプロトコル。
それによってアクセスできるようになったリソースの情報をもとに認証を行ったりすることもあるが、
以下に示すImplicit Flowでそれをやると他のサービスのトークンで他人に成りすませてしまう問題があるため、
認証する場合はOAuth 2.0ベースの認証プロトコルのOpenID Connectを使うべき。
その場合もトークンを取得するまでの流れはほとんどOAuth 2.0通りなのでフローを理解しておいて無駄はない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/136/&#34;&gt;OpenID ConnectのIDトークンの内容と検証 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;authorization-code-flow&#34;&gt;Authorization Code Flow&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/48_authcode.png&#34; alt=&#34;シーケンス図&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OAuthクライアントがアプリケーションサーバーのときのフロー。&lt;/p&gt;

&lt;p&gt;まずユーザーがOAuth認可ページで認可する。
このリクエストには&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;client_id&lt;/li&gt;
&lt;li&gt;redirect_uri&lt;/li&gt;
&lt;li&gt;scope: アクセスできるリソースの種類&lt;/li&gt;
&lt;li&gt;response_type=code: 認可コードが返される&lt;/li&gt;
&lt;li&gt;state: CSRFを防ぐためのランダムで一意な文字列。アプリケーションサーバーが保持して、前後で一致するかチェックする&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;が含まれる。&lt;/p&gt;

&lt;p&gt;認可されると認可コードとstateを付けてredirect_uri(&lt;a href=&#34;https://tools.ietf.org/html/rfc6749#section-3.1.2.2&#34;&gt;事前に登録しておく&lt;/a&gt;)にリダイレクトするので、
アプリケーションサーバーは認可コードをアクセストークンに交換する。
この際、client_idとclient_secretも送る。&lt;/p&gt;

&lt;p&gt;オプションでリフレッシュトークンを含み、これを使うと期限が切れたとき新しいアクセストークンを取得できる。&lt;/p&gt;

&lt;p&gt;アクセストークンは通常Bearer Token(Authorization: Bearer ***)としてリクエストに含まれる。&lt;/p&gt;

&lt;h3 id=&#34;implicit-flow&#34;&gt;Implicit Flow&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/48_implicit.png&#34; alt=&#34;シーケンス図&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OAuthクライアントがアプリなどでclient_secretの機密性を保てない場合のフロー。&lt;/p&gt;

&lt;p&gt;認可コードは不要なので&lt;code&gt;response_type=token&lt;/code&gt;でリクエストし、アクセストークンをブラウザで取得する。
リフレッシュトークンは含まない。
他のサービスで発行された他人のトークンを使うことでなりすませてしまうので、
そのトークンがどのサービスに対して発行されたかを確認する術が特に用意されているのでなければ
認証に使ってはいけない。OpenID Connectでは署名されたIDトークンに発行されたサービスの情報が含まれている。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873115580/&#34;&gt;O&amp;rsquo;Reilly Japan - OAuth 2.0をはじめよう&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://oauth.jp/blog/2014/05/07/covert-redirect-in-implicit-flow/&#34;&gt;Implicit Flow では Covert Redirect で Token 漏れるね - OAuth.jp&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる</title>
          <link>https://www.sambaiz.net/article/47/</link>
          <pubDate>Wed, 04 Jan 2017 23:58:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/47/</guid>
          <description>&lt;p&gt;この関数のベンチマークを取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package cal

import (
	&amp;quot;math/big&amp;quot;
)

var cache = map[int]*big.Int{}

func resetCache() {
	cache = map[int]*big.Int{}
}

func Fibonacci(n int) *big.Int {

	if c := cache[n]; c != nil {
		return c
	}

	ret := new(big.Int)
	before := big.NewInt(1)
	for i := 1; i &amp;lt; n; i++ {
		tmp := new(big.Int).Add(ret, before)
		before = ret
		ret = tmp
		cache[i] = ret
	}
	cache[n] = ret
	return ret
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;引数にtesting.Bを取る、Benchmarkから始まる関数を書いて、b.N回ループさせる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package cal

import (
	&amp;quot;math/big&amp;quot;
	&amp;quot;testing&amp;quot;
)

func TestFibonacci(t *testing.T) {
	if f := Fibonacci(10); f.String() != big.NewInt(34).String() {
		t.Errorf(&amp;quot;%d != %d (expected)&amp;quot;, f, big.NewInt(34))
	}
}

func BenchmarkFibonacci(b *testing.B) {
	for i := 0; i &amp;lt; b.N; i++ {
		b.StopTimer()
		resetCache()
		b.StartTimer()
		Fibonacci(100)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;code&gt;go test -bench&lt;/code&gt;で実行するとベンチマークが取れる。さらに&lt;code&gt;-benchmem&lt;/code&gt;を付けるとメモリアロケーションの情報も出る。
また、&lt;code&gt;-cpuprofile&lt;/code&gt;でCPUのプロファイルを出力し、pprofに渡すことでどの部分で時間がかかっているかを調べることができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/cmd/go/#hdr-Description_of_testing_flags&#34;&gt;https://golang.org/cmd/go/#hdr-Description_of_testing_flags&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench Fibonacci -benchmem -o pprof/test.bin  -cpuprofile pprof/cpu.out ./cal
BenchmarkFibonacci-4   	   50000	     32788 ns/op	   13344 B/op	     211 allocs/op
PASS
ok  	github.com/sambaiz/try-pprof/cal	3.406s

$ go tool pprof --text pprof/test.bin pprof/cpu.out
3.80s of 3.83s total (99.22%)
Dropped 17 nodes (cum &amp;lt;= 0.02s)
      flat  flat%   sum%        cum   cum%
     2.31s 60.31% 60.31%      2.31s 60.31%  runtime.mach_semaphore_signal
     0.38s  9.92% 70.23%      0.38s  9.92%  runtime.mach_semaphore_timedwait
     0.32s  8.36% 78.59%      0.32s  8.36%  runtime.mach_semaphore_wait
     0.27s  7.05% 85.64%      0.27s  7.05%  runtime.usleep
     0.14s  3.66% 89.30%      0.14s  3.66%  runtime.deductSweepCredit
     0.09s  2.35% 91.64%      0.28s  7.31%  runtime.mallocgc
     0.04s  1.04% 92.69%      0.14s  3.66%  runtime.mapassign1
     0.04s  1.04% 93.73%      0.05s  1.31%  runtime.updatememstats
     0.03s  0.78% 94.52%      0.13s  3.39%  math/big.nat.add
     0.03s  0.78% 95.30%      0.03s  0.78%  runtime.aeshash64
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;graphvizをインストールすることでsvgのグラフを出すこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install graphviz
$ go tool pprof --svg pprof/test.bin pprof/cpu.out &amp;gt; pprof/test.svg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/47.png&#34; alt=&#34;svgで出力したもの&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>汎用シリアライズ方法(MessagePack/Protocol Buffers/FlatBuffers)</title>
          <link>https://www.sambaiz.net/article/46/</link>
          <pubDate>Fri, 30 Dec 2016 18:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/46/</guid>
          <description>

&lt;h2 id=&#34;messagepack-http-msgpack-org-とは&#34;&gt;&lt;a href=&#34;http://msgpack.org/&#34;&gt;MessagePack&lt;/a&gt;とは&lt;/h2&gt;

&lt;p&gt;JSONのように使うことができ、速くてサイズが小さい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;compact&amp;quot;:true,&amp;quot;スキーマ&amp;quot;:{&amp;quot;number&amp;quot;: 999, &amp;quot;string&amp;quot;: &amp;quot;aaa&amp;quot;}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;のjson(61bytes)をMessagePack(45bytes)に変換したのがこれ。見やすいように改行している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;82 
a7 63 6f 6d 70 61 63 74 c3 
ac e3 82 b9 e3 82 ad e3 83 bc e3 83 9e 
   82 
   a6 6e 75 6d 62 65 72 cd 03 e7 
   a6 73 74 72 69 6e 67 a3 61 61 61
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一行目の&lt;code&gt;82&lt;/code&gt;は&lt;a href=&#34;https://github.com/msgpack/msgpack/blob/master/spec.md#map-format-family&#34;&gt;要素数2のfixmap(要素数15まで)&lt;/a&gt;を表す。&lt;/p&gt;

&lt;p&gt;二行目の&lt;code&gt;a7&lt;/code&gt;が&lt;a href=&#34;https://github.com/msgpack/msgpack/blob/master/spec.md#str-format-family&#34;&gt;7バイトのfixstr(31bytesまで)&lt;/a&gt;で、
&lt;code&gt;63 6f 6d 70 61 63 74&lt;/code&gt;が&amp;rdquo;compact&amp;rdquo;。&lt;code&gt;c3&lt;/code&gt;は&lt;a href=&#34;https://github.com/msgpack/msgpack/blob/master/spec.md#bool-format-family&#34;&gt;true&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;三行目の&lt;code&gt;ac&lt;/code&gt;は12バイトのfixstrで、&lt;code&gt;e3 82 b9 e3 82 ad e3 83 bc e3 83 9e&lt;/code&gt;が&amp;rdquo;スキーマ&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;四行目はこれのvalueで、要素数2のfixmap(&lt;code&gt;82&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;五行目は6バイトのfixstr(&lt;code&gt;a6&lt;/code&gt;)、&amp;rdquo;number&amp;rdquo;(&lt;code&gt;6e 75 6d 62 65 72&lt;/code&gt;)、
&lt;code&gt;cd&lt;/code&gt;が&lt;a href=&#34;https://github.com/msgpack/msgpack/blob/master/spec.md#int-format-family&#34;&gt;uint16&lt;/a&gt;で、999(&lt;code&gt;03 e7&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;六行目は6バイトのfixstr(&lt;code&gt;a6&lt;/code&gt;)、&amp;rdquo;string&amp;rdquo;(&lt;code&gt;73 74 72 69 6e 67&lt;/code&gt;)、3バイトのfixstr(&lt;code&gt;a3&lt;/code&gt;)、&amp;rdquo;aaa&amp;rdquo;(&lt;code&gt;61 61 61&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;と、こんな感じで分かりやすいバイナリになっている。文字列が多いとあまりサイズが変わらない。&lt;/p&gt;

&lt;h3 id=&#34;使い方&#34;&gt;使い方&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/ugorji/go/codec
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mh := codec.MsgpackHandle{RawToString: true}
origin := serialize.Data{
	Title: &amp;quot;aaaa&amp;quot;,
}

func MessagePackEncode(mh codec.MsgpackHandle, origin Data) []byte {
	var encoded []byte

	enc := codec.NewEncoderBytes(&amp;amp;encoded, &amp;amp;mh)
	if err := enc.Encode(&amp;amp;origin); err != nil {
		panic(err)
	}

	return encoded
}

func MessagePackDecode(mh codec.MsgpackHandle, bytes []byte) Data {
	var decoded Data

	dec := codec.NewDecoderBytes(bytes, &amp;amp;mh)
	if err := dec.Decode(&amp;amp;decoded); err != nil {
		panic(err)
	}

	return decoded
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;protocol-buffers-https-developers-google-com-protocol-buffers-とは&#34;&gt;&lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol Buffers&lt;/a&gt;とは&lt;/h2&gt;

&lt;p&gt;Googleのシリアライズライブラリ。gRPCでも使われる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/12/&#34;&gt;Googleが作ったRPCフレームワークgRPCを使ってみた&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;message typeを&lt;code&gt;proto&lt;/code&gt;ファイルで定義する(proto3)。このファイルから各言語のコードを生成することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;syntax = &amp;quot;proto3&amp;quot;;

message SearchResponse {
  repeated Result results = 1;
}

message Result {
  string url = 1;
  string title = 2;
  repeated string snippets = 3;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それぞれのmessage typeには名前と型を持つユニークな数値のフィールドが含まれる。一度割り当てた数値のtypeは変更しないようにする。
&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#assigning-tags&#34;&gt;(Assigning Tags)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;repeated&lt;/code&gt;は0以上の任意の個数で、順番は保存される。
&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#specifying-field-rules&#34;&gt;(Specifying Field Rules)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;新しいコードがフィールドを追加してメッセージを送ると、古いコードは未知のフィールドを無視する。
逆に、古いコードがメッセージを送ると、
新しいコードの新しいフィールドには&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#default&#34;&gt;デフォルト値&lt;/a&gt;が入る。
&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#updating&#34;&gt;(Updating A Message Type)&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;使い方-1&#34;&gt;使い方&lt;/h3&gt;

&lt;p&gt;protoファイル。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;syntax = &amp;quot;proto3&amp;quot;;

message Data {
  string title = 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;goのコードを生成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install protobuf
$ protoc --version
libprotoc 3.1.0

$ go get github.com/golang/protobuf/protoc-gen-go

$ mkdir -p build/gen 
$ protoc --proto_path=proto --go_out=data proto/data.proto
$ ls data
data.pb.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;生成されたコード。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Code generated by protoc-gen-go.
// source: data.proto
// DO NOT EDIT!

/*
Package data is a generated protocol buffer package.

It is generated from these files:
	data.proto

It has these top-level messages:
	Data
*/
package data

import proto &amp;quot;github.com/golang/protobuf/proto&amp;quot;
import fmt &amp;quot;fmt&amp;quot;
import math &amp;quot;math&amp;quot;

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

type Data struct {
	Title string `protobuf:&amp;quot;bytes,1,opt,name=title&amp;quot; json:&amp;quot;title,omitempty&amp;quot;`
}

func (m *Data) Reset()                    { *m = Data{} }
func (m *Data) String() string            { return proto.CompactTextString(m) }
func (*Data) ProtoMessage()               {}
func (*Data) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }

func init() {
	proto.RegisterType((*Data)(nil), &amp;quot;Data&amp;quot;)
}

func init() { proto.RegisterFile(&amp;quot;data.proto&amp;quot;, fileDescriptor0) }

var fileDescriptor0 = []byte{
	// 67 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x09, 0x6e, 0x88, 0x02, 0xff, 0xe2, 0xe2, 0x4a, 0x49, 0x2c, 0x49,
	0xd4, 0x2b, 0x28, 0xca, 0x2f, 0xc9, 0x57, 0x92, 0xe1, 0x62, 0x71, 0x49, 0x2c, 0x49, 0x14, 0x12,
	0xe1, 0x62, 0x2d, 0xc9, 0x2c, 0xc9, 0x49, 0x95, 0x60, 0x54, 0x60, 0xd4, 0xe0, 0x0c, 0x82, 0x70,
	0x92, 0xd8, 0xc0, 0x8a, 0x8c, 0x01, 0x01, 0x00, 0x00, 0xff, 0xff, 0xf5, 0x0d, 0xbe, 0x9b, 0x32,
	0x00, 0x00, 0x00,
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/golang/protobuf/proto
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func ProtoBufEncode(origin data.Data) []byte {
	encoded, err := proto.Marshal(&amp;amp;origin)
	if err != nil {
		panic(err)
	}

	return encoded
}

func ProtoBufDecode(bytes []byte) data.Data {
	var decoded data.Data
	if err := proto.Unmarshal(bytes, &amp;amp;decoded); err != nil {
		panic(err)
	}

	return decoded
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;flatbuffers-http-google-github-io-flatbuffers&#34;&gt;&lt;a href=&#34;http://google.github.io/flatbuffers/&#34;&gt;FlatBuffers&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Googleの、ゲームなどパフォーマンスを要求するアプリケーションのためのシリアライズライブラリ。
データにアクセスする前にparseやunpackする必要がなく、オブジェクトごとのメモリ割り当てが必要。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;proto&lt;/code&gt;の代わりにこんな&lt;code&gt;schema&lt;/code&gt;ファイルを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace MyGame.Sample;
enum Color:byte { Red = 0, Green, Blue = 2 }
union Equipment { Weapon } // Optionally add more tables.
struct Vec3 {
  x:float;
  y:float;
  z:float;
}
table Monster {
  pos:Vec3; // Struct.
  mana:short = 150;
  hp:short = 100;
  name:string;
  friendly:bool = false (deprecated);
  inventory:[ubyte];  // Vector of scalars.
  color:Color = Blue; // Enum.
  weapons:[Weapon];   // Vector of tables.
  equipped:Equipment; // Union.
}
table Weapon {
  name:string;
  damage:short;
}
root_type Monster;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使い方-2&#34;&gt;使い方&lt;/h3&gt;

&lt;p&gt;schemaファイル。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace dataf;

table Data {
    title:string;
}

root_type Data;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;goのコードを生成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install flatbuffers

$ flatc --go fbs/dataf.fbs
$ ls dataf/
data.go

$ go get github.com/google/flatbuffers/go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;生成されたコード。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// automatically generated by the FlatBuffers compiler, do not modify

package dataf

import (
	flatbuffers &amp;quot;github.com/google/flatbuffers/go&amp;quot;
)

type data struct {
	_tab flatbuffers.Table
}

func GetRootAsdata(buf []byte, offset flatbuffers.UOffsetT) *data {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &amp;amp;data{}
	x.Init(buf, n+offset)
	return x
}

func (rcv *data) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *data) Title() []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.ByteVector(o + rcv._tab.Pos)
	}
	return nil
}

func dataStart(builder *flatbuffers.Builder) {
	builder.StartObject(1)
}
func dataAddTitle(builder *flatbuffers.Builder, title flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(title), 0)
}
func dataEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://rwinslow.com/posts/use-flatbuffers-in-golang/&#34;&gt;Tutorial: Use FlatBuffers in Go · Robert Winslow&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GoogleのkvsライブラリLevelDBを使う</title>
          <link>https://www.sambaiz.net/article/45/</link>
          <pubDate>Sat, 24 Dec 2016 21:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/45/</guid>
          <description>

&lt;h2 id=&#34;leveldbとは&#34;&gt;LevelDBとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/google/leveldb&#34;&gt;https://github.com/google/leveldb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Googleが作った高速なkey-valueストレージライブラリ。&lt;/p&gt;

&lt;p&gt;ChromeのIndexedDBや&lt;a href=&#34;https://prometheus.io/docs/operating/storage/&#34;&gt;prometheus&lt;/a&gt;などで使われている。&lt;/p&gt;

&lt;h3 id=&#34;特徴-https-github-com-google-leveldb-features&#34;&gt;&lt;a href=&#34;https://github.com/google/leveldb#features&#34;&gt;特徴&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Keyと任意のバイト配列のValue&lt;/li&gt;
&lt;li&gt;データはKeyでソートされる。ソートのための比較関数はオーバーライドできる。&lt;/li&gt;
&lt;li&gt;基本的な操作はPut, Get, Delete。&lt;/li&gt;
&lt;li&gt;複数の変更を一つのatomicなバッチで行える&lt;/li&gt;
&lt;li&gt;一環したデータのビューを取得するために、一時的なスナップショットを作成できる&lt;/li&gt;
&lt;li&gt;データを前にも後ろにもイテレーションできる&lt;/li&gt;
&lt;li&gt;データは&lt;a href=&#34;http://google.github.io/snappy/&#34;&gt;Snappy compression library&lt;/a&gt;で自動で圧縮される。&lt;/li&gt;
&lt;li&gt;ファイルシステムの操作など外部のアクティビティを仮想的なインタフェースを通して行うので、OSとのやりとりをカスタマイズできる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;制限-https-github-com-google-leveldb-limitations&#34;&gt;&lt;a href=&#34;https://github.com/google/leveldb#limitations&#34;&gt;制限&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;SQLデータベースではない。リレーショナルなデータモデルは持てないし、SQLやインデックスにも対応していない。&lt;/li&gt;
&lt;li&gt;一度に一つのプロセスしかDBにアクセスできない。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;キャッシュ-https-rawgit-com-google-leveldb-master-doc-index-html&#34;&gt;&lt;a href=&#34;https://rawgit.com/google/leveldb/master/doc/index.html&#34;&gt;キャッシュ&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;DBはファイルシステムのディレクトリに対応する名前を持ち、内容はそのディレクトリに保存される。&lt;/li&gt;
&lt;li&gt;各ファイルには圧縮したブロックが保存され、良く使うものについては非圧縮のブロックがキャッシュされる。&lt;/li&gt;
&lt;li&gt;ソートして隣接するキーは通常、同じブロックに配置される。ディスク転送とキャッシュはブロック単位。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;フィルタ&#34;&gt;フィルタ&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Getの際、不要なデータを読まなくていいようにフィルタ(Bloom Filter)を用いることができる。&lt;/li&gt;
&lt;li&gt;独自の比較関数(末尾のスペースを無視するなど)を使う場合、Bloom Filterを使うことができないことがあるので、その場合は独自のフィルタが必要。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;レベル-https-rawgit-com-google-leveldb-master-doc-impl-html&#34;&gt;&lt;a href=&#34;https://rawgit.com/google/leveldb/master/doc/impl.html&#34;&gt;レベル&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;最近の更新はログファイルに保存される。これが決められたサイズ(デフォルトでは約4MB)に達すると、sorted table(sst)に変換され、新しいログファイルが生成される。&lt;/li&gt;
&lt;li&gt;現在のログファイルのコピーがメモリ(memtable)にも乗って読み取りで参照される。&lt;/li&gt;
&lt;li&gt;sstはキーによってソートされたエントリーを保存する。エントリーはキーの値か、削除マーカー。&lt;/li&gt;
&lt;li&gt;sstはレベルによってまとめられる。ログファイルから変換されると、特別なyoungレベル(level-0とも呼ばれる)に配置される。&lt;/li&gt;
&lt;li&gt;youngファイルの数があるしきい値(現在4つ)を超えると全てのyoungファイルを全てのlevel-1ファイルとマージし、新しいlevel-1ファイルを生成する(2MBごとに1ファイル)。&lt;/li&gt;
&lt;li&gt;youngレベルのファイルにはキーが重複していることがある。しかし、他のレベルでは重複しないキーの範囲がある。&lt;/li&gt;
&lt;li&gt;level-L(L&amp;gt;=1)のファイルの合計サイズが&lt;code&gt;10^L MB&lt;/code&gt;を超えたとき、level-Lのファイルと、level-(L+1)の全てのファイルをマージし、新しいlevel-(L+1)ファイルを生成する。&lt;/li&gt;
&lt;li&gt;これによって、バルク読み込み/書き込みのみを使い、コストが高いシークを最小限にして、youngレベルから大きいレベルに更新を徐々にマイグレーションすることができる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;動かしてみる&#34;&gt;動かしてみる&lt;/h2&gt;

&lt;p&gt;LevelDBのgo実装。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/syndtr/goleveldb&#34;&gt;syndtr/goleveldb&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/syndtr/goleveldb/leveldb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まずDBを開く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// open
db, err := leveldb.OpenFile(&amp;quot;/Users/sambaiz/leveldb&amp;quot;, nil)
defer db.Close()
if err != nil {
    panic(err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;普通に5個(key0~4)、バッチで5個(key5~9)のデータを入れて、そのうち一つを消す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// put
for i := 0; i &amp;lt; 5; i++ {
    if err = db.Put([]byte(fmt.Sprintf(&amp;quot;key%d&amp;quot;, i)), []byte(fmt.Sprintf(&amp;quot;value%d&amp;quot;, i)), nil); err != nil {
        panic(err)
    }
}

// batch
batch := new(leveldb.Batch)
for i := 5; i &amp;lt; 10; i++ {
    batch.Put([]byte(fmt.Sprintf(&amp;quot;key%d&amp;quot;, i)), []byte(fmt.Sprintf(&amp;quot;value%d&amp;quot;, i)))
}
if err = db.Write(batch, nil); err != nil{
    panic(err)
}

// delete
if err = db.Delete([]byte(&amp;quot;key2&amp;quot;), nil); err != nil {
    panic(err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この時点でこんなファイルが生成され、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls
000001.log	CURRENT		LOCK		LOG		MANIFEST-000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;000001.logの中身はこんな感じになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ od -c 000001.log 
0000000    Z 221   @ 300 031  \0 001 001  \0  \0  \0  \0  \0  \0  \0 001
0000020   \0  \0  \0 001 004   k   e   y   0 006   v   a   l   u   e   0
0000040    o 037   = 373 031  \0 001 002  \0  \0  \0  \0  \0  \0  \0 001
0000060   \0  \0  \0 001 004   k   e   y   1 006   v   a   l   u   e   1
0000100  256 343   &amp;gt; 311 031  \0 001 003  \0  \0  \0  \0  \0  \0  \0 001
0000120   \0  \0  \0 001 004   k   e   y   2 006   v   a   l   u   e   2
0000140    = 006 330 341 031  \0 001 004  \0  \0  \0  \0  \0  \0  \0 001
0000160   \0  \0  \0 001 004   k   e   y   3 006   v   a   l   u   e   3
0000200  002 005   4 016 031  \0 001 005  \0  \0  \0  \0  \0  \0  \0 001
0000220   \0  \0  \0 001 004   k   e   y   4 006   v   a   l   u   e   4
0000240    d 240 344   {   M  \0 001 006  \0  \0  \0  \0  \0  \0  \0 005
0000260   \0  \0  \0 001 004   k   e   y   5 006   v   a   l   u   e   5
0000300  001 004   k   e   y   6 006   v   a   l   u   e   6 001 004   k
0000320    e   y   7 006   v   a   l   u   e   7 001 004   k   e   y   8
0000340  006   v   a   l   u   e   8 001 004   k   e   y   9 006   v   a
0000360    l   u   e   9   ! 233 277 371 022  \0 001  \v  \0  \0  \0  \0
0000400   \0  \0  \0 001  \0  \0  \0  \0 004   k   e   y   2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;取得するにはkeyを指定して&lt;code&gt;Get()&lt;/code&gt;したり、Iteratorを使う。
IteratorはSeekしたり、StartやLimitを設定したり、Prefixを指定して取ってくることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// get
fmt.Println(&amp;quot;-- get --&amp;quot;)
for i := 0; i &amp;lt; 10; i++ {
    var data []byte
    if data, err = db.Get([]byte(fmt.Sprintf(&amp;quot;key%d&amp;quot;, i)), nil); err != nil {
        fmt.Printf(&amp;quot;key%d: %s\n&amp;quot;, i, err.Error())
    } else {
        fmt.Printf(&amp;quot;key%d: %s\n&amp;quot;, i, string(data))
    }
}

// iterate
fmt.Println(&amp;quot;-- iterate --&amp;quot;)
iter := db.NewIterator(nil, nil)
for iter.Next() {
    key := iter.Key()
    value := iter.Value()
    fmt.Printf(&amp;quot;%s: %s\n&amp;quot;, string(key), string(value))
}
iter.Release()
if err = iter.Error(); err != nil {
    panic(err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- get --
key0: value0
key1: value1
key2: leveldb: not found
key3: value3
key4: value4
key5: value5
key6: value6
key7: value7
key8: value8
key9: value9
-- iterate --
key0: value0
key1: value1
key3: value3
key4: value4
key5: value5
key6: value6
key7: value7
key8: value8
key9: value9
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>gvmでGoのバージョン管理</title>
          <link>https://www.sambaiz.net/article/44/</link>
          <pubDate>Tue, 20 Dec 2016 20:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/44/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/moovweb/gvm&#34;&gt;moovweb/gvm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;必要なものはREADMEを見て入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)
$ source ${HOME}/.gvm/scripts/gvm
$ gvm install go1.7 -B
$ gvm use go1.7
$ go version
go version go1.7 linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;$GOPATH&lt;/code&gt;と&lt;code&gt;$GOROOT&lt;/code&gt;が書き変わる(&lt;code&gt;${HOME}/.gvm/pkgsets/go1.7/global/&lt;/code&gt;)ので注意。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>複数EC2インスタンスを立ち上げてvegetaで負荷試験する</title>
          <link>https://www.sambaiz.net/article/43/</link>
          <pubDate>Sun, 18 Dec 2016 20:52:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/43/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/tsenart/vegeta&#34;&gt;vegeta&lt;/a&gt;で負荷をかける。&lt;/p&gt;

&lt;h2 id=&#34;インスタンスを立ち上げるスクリプト&#34;&gt;インスタンスを立ち上げるスクリプト&lt;/h2&gt;

&lt;p&gt;コードはここ。 &lt;a href=&#34;https://github.com/sambaiz/loadtest&#34;&gt;sambaiz/loadtest&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;まずキーペアを作成し、EC2インスタンスを立ち上げて、全てのインスタンスが使えるようになるまで待つ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;aws ec2 create-key-pair --key-name LoadTestKeyPare --query &#39;KeyMaterial&#39; --output text &amp;gt; LoadTestKeyPare.pem
chmod 400 LoadTestKeyPare.pem
aws ec2 run-instances --image-id $AMI_ID --count $INSTANCE_NUM --instance-type t2.micro --key-name LoadTestKeyPare --security-group-ids $SECURITY_GROUP_IDS --subnet-id $SUBNET_ID
...
aws ec2 wait instance-status-ok --instance-ids $INSTANCE_IDS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このAMIは事前にPackerでつくったもの。vegetaをインストールしてファイルディスクリプタの上限を増やしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;aws_access_key&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;aws_secret_key&amp;quot;: &amp;quot;&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;,
    &amp;quot;access_key&amp;quot;: &amp;quot;{{user `aws_access_key`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `aws_secret_key`}}&amp;quot;,
    &amp;quot;region&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;,
    &amp;quot;source_ami&amp;quot;: &amp;quot;ami-0c11b26d&amp;quot;,
    &amp;quot;instance_type&amp;quot;: &amp;quot;t2.micro&amp;quot;,
    &amp;quot;ssh_username&amp;quot;: &amp;quot;ec2-user&amp;quot;,
    &amp;quot;ami_name&amp;quot;: &amp;quot;loadtest {{timestamp}}&amp;quot;
  }],
  &amp;quot;provisioners&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
    &amp;quot;inline&amp;quot;: [
      &amp;quot;wget https://github.com/tsenart/vegeta/releases/download/v6.1.1/vegeta-v6.1.1-linux-amd64.tar.gz&amp;quot;,
      &amp;quot;sudo tar xzf vegeta-v6.1.1-linux-amd64.tar.gz -C /usr/local/bin/&amp;quot;,
      &amp;quot;sudo sh -c \&amp;quot;echo &#39;* hard nofile 65536&#39; &amp;gt;&amp;gt; /etc/security/limits.conf\&amp;quot;&amp;quot;,
      &amp;quot;sudo sh -c \&amp;quot;echo &#39;* soft nofile 65536&#39; &amp;gt;&amp;gt; /etc/security/limits.conf\&amp;quot;&amp;quot;
    ]
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;立ち上がったインスタンスに対して&lt;a href=&#34;https://code.google.com/p/pdsh/&#34;&gt;pdsh&lt;/a&gt;で
各マシンでvegetaを実行させ($VEGETA_CMD)、結果のファイルを集めてreportのinputsで指定すると
まとめてレポートを出力してくれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pdsh -l ec2-user -w `echo &amp;quot;$PUBLIC_DNS_NAMES&amp;quot; |  paste -d, -s -` &amp;quot;$VEGETA_CMD &amp;gt; result.bin&amp;quot;

for machine in $PUBLIC_DNS_NAMES; do
  scp -i ./LoadTestKeyPare.pem -oStrictHostKeyChecking=no ec2-user@$machine:~/result.bin $machine
done

vegeta report -inputs=`echo $PUBLIC_DNS_NAMES |  paste -d, -s -`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;終わったら後片付けをする。trapでCtrl+C等での終了時もインスタンスが残らないようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cleanup() {
  echo &amp;quot;---- Clean up ----&amp;quot;
  aws ec2 terminate-instances --instance-ids $INSTANCE_IDS
  aws ec2 delete-key-pair --key-name LoadTestKeyPare
  rm -f LoadTestKeyPare.pem
  rm $PUBLIC_DNS_NAMES
}
trap cleanup EXIT SIGHUP SIGINT SIGQUIT SIGTERM
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実行する&#34;&gt;実行する&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ brew install awscli pdsh jq vegeta packer
$ aws configure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じのスクリプト(sample/sample.sh)から実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash

export INSTANCE_NUM=3

export AMI_ID=ami-*****
export SECURITY_GROUP_IDS=sg-*****
export SUBNET_ID=subnet-*****

export RESOURCES_DIR=res

# https://github.com/tsenart/vegeta#attack
export VEGETA_CMD=&#39;vegeta attack -targets=res/targets.txt -rate=1000 -duration=10s&#39;

sh run.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sample/res/targets.txt&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GET http://example.com/

POST http://example.com/
@res/post.json
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;何も指定しないとこんな感じ(-reporter=text)。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Requests      [total, rate]            10000, 1000.10
Duration      [total, attack, wait]    10.011642793s, 9.998999835s, 12.642958ms
Latencies     [mean, 50, 95, 99, max]  14.781775ms, 4.262304ms, 68.475899ms, 97.492882ms, 1.096072997s
Bytes In      [total, mean]            15285000, 1528.50
Bytes Out     [total, mean]            110000, 11.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:10000  
Error Set:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他にもjsonだったり、plotを指定するとレイテンシのグラフのhtmlが出力される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/43_plot.jpg&#34; alt=&#34;グラフ&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>SSHポートフォワーディングとnetstatのメモ</title>
          <link>https://www.sambaiz.net/article/42/</link>
          <pubDate>Sat, 17 Dec 2016 12:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/42/</guid>
          <description>

&lt;h2 id=&#34;sshポートフォワーディング&#34;&gt;SSHポートフォワーディング&lt;/h2&gt;

&lt;p&gt;ローカルの8080ポートを、example.comを通したexample2.comの80ポートに向ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh hoge@example.com -Nf -L 8080:example2.com:80 
$ curl localhost:8080 # =&amp;gt; example2.com:80
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-N&lt;/code&gt;: リモートでコマンドを実行しない&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-f&lt;/code&gt;: バックグラウンドで実行&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;netstat&#34;&gt;netstat&lt;/h2&gt;

&lt;p&gt;ネットワークの状態を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ netstat -ant
Proto Recv-Q Send-Q Local Address               Foreign Address             State      
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN 
...
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-a&lt;/code&gt;: non-listening(TCPではESTABLISHED状態)しているソケットだけではなく、listeningしている情報も出す&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-n&lt;/code&gt;: 数値のアドレスで表示する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-t&lt;/code&gt;: TCPで制限&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ファイルディスクリプタの上限を増やす</title>
          <link>https://www.sambaiz.net/article/41/</link>
          <pubDate>Thu, 08 Dec 2016 21:36:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/41/</guid>
          <description>

&lt;h2 id=&#34;ファイルディスクリプタとは&#34;&gt;ファイルディスクリプタとは&lt;/h2&gt;

&lt;p&gt;プロセスの外部とやりとりするための識別子。POSIXではint型で、0がstdin、1がstdout、2がstderrといったもの。
ファイルやデバイスに対するopen()や、
ネットワーク(INETドメインソケット)やホスト内(UNIXドメインソケット)で
通信するためのソケットを生成するsocket()などのシステムコールで生成される。&lt;/p&gt;

&lt;h2 id=&#34;ファイルディスクリプタの上限&#34;&gt;ファイルディスクリプタの上限&lt;/h2&gt;

&lt;p&gt;一つのプロセスがリソースを食いつぶさないように
使えるファイルディスクリプタの上限が決まっていて、&lt;code&gt;ulimit -n&lt;/code&gt;で確認できる。デフォルトは大体1024。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ulimit -n
1024
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;各プロセスの上限と使っているファイルディスクリプタはこれで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /proc/&amp;lt;プロセスID&amp;gt;/limits
...
Max open files            1024                 4096                 files     
...

$ ls -l /proc/&amp;lt;プロセスID&amp;gt;/fd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webサーバーのように同時にたくさん通信したりすると上限に達してしまい、&lt;code&gt;Too many open files&lt;/code&gt;になってしまうので増やす必要がある。&lt;/p&gt;

&lt;h3 id=&#34;etc-security-limits-conf-で変更する&#34;&gt;&lt;code&gt;/etc/security/limits.conf&lt;/code&gt;で変更する&lt;/h3&gt;

&lt;p&gt;PAM認証時(ログインするときなど)に適用されるので、サーバーの起動時に立ち上がったデーモンには使えない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/pam.d/sshd
...
session    required     pam_limits.so
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;全てのユーザー(&lt;code&gt;*&lt;/code&gt;)のプロセスが使える
ファイルディスクリプタ(nofile)のsoft(ユーザーが設定できる)とhard(rootが設定できる)上限を共に64000にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;* hard nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf
$ echo &amp;quot;* soft nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf
$ ulimit -n
64000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ulimit-n-で変更する&#34;&gt;&lt;code&gt;ulimit -n&lt;/code&gt;で変更する&lt;/h3&gt;

&lt;p&gt;シェルと、起動したプロセスで有効。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ulimit -n 64000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dockerコンテナでは&#34;&gt;dockerコンテナでは&lt;/h3&gt;

&lt;p&gt;run時に&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/run/#/set-ulimits-in-container---ulimit&#34;&gt;ulimitオプション&lt;/a&gt;で
&lt;code&gt;--ulimit nofile=11111&lt;/code&gt;のように指定することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -itd --ulimit nofile=11111 ubuntu
$ docker exec -it &amp;lt;id&amp;gt; /bin/bash -c &amp;quot;ulimit -n&amp;quot;
11111
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://open-groove.net/linux/memo-etcsecuritylimits-conf/&#34;&gt;/etc/security/limits.confに関するメモ | OpenGroove&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://staffblog.yumemi.jp/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%82%BF%E6%95%B0%E3%81%AE%E4%B8%8A%E9%99%90%E5%A4%89%E6%9B%B4%E3%81%A8limits-conf%E3%81%AE%E7%BD%A0-2/&#34;&gt;ファイルディスクリプタ数の上限変更とlimits.confの罠&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.koikikukan.com/archives/2013/03/14-005555.php&#34;&gt;Linuxのファイルディスクリプタ数を変更・確認する方法: 小粋空間&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/ファイル記述子&#34;&gt;ファイル記述子 - Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/kuni-nakaji/items/d11219e4ad7c74ece748&#34;&gt;調べなきゃ寝れない！と調べたら余計に寝れなくなったソケットの話 - Qiita&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Angular2とangular-cliでTODOを作る</title>
          <link>https://www.sambaiz.net/article/40/</link>
          <pubDate>Mon, 05 Dec 2016 00:48:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/40/</guid>
          <description>

&lt;p&gt;コード: &lt;a href=&#34;https://github.com/sambaiz/angular2-todo&#34;&gt;https://github.com/sambaiz/angular2-todo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/40.gif&#34; alt=&#34;動いているところ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;アプリケーションの作成と立ち上げ&#34;&gt;アプリケーションの作成と立ち上げ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/angular/angular-cli&#34;&gt;angular-cli&lt;/a&gt;をインストールしてサーバーを立ち上げるまで。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install angular-cli -g
$ ng -v
angular-cli: 1.0.0-beta.21
node: 5.12.0
os: darwin x64

$ ng new mytodo
$ cd mytodo
$ ng server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4200/&#34;&gt;http://localhost:4200/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;新しいコンポーネントを作る&#34;&gt;新しいコンポーネントを作る&lt;/h2&gt;

&lt;p&gt;新しいコンポーネントを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g component todo-list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでtodo-listディレクトリにコンポーネントクラスとテンプレートとCSS、テストとindexが出力される。&lt;/p&gt;

&lt;p&gt;また、app.module.ts(BootstrapするRoot Module)にも追加されている。
NgModuleのdeclartionsなどに入っているものは、各Componentで指定しなくても使えるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { BrowserModule } from &#39;@angular/platform-browser&#39;;
import { NgModule } from &#39;@angular/core&#39;;
import { FormsModule } from &#39;@angular/forms&#39;;
import { HttpModule } from &#39;@angular/http&#39;;

import { AppComponent } from &#39;./app.component&#39;;
import { TodoListComponent } from &#39;./todo-list/todo-list.component&#39;;

@NgModule({
  declarations: [
    AppComponent,
    TodoListComponent
  ],
  imports: [
    BrowserModule,
    FormsModule,
    HttpModule
  ],
  providers: [],
  bootstrap: [AppComponent]
})
export class AppModule { }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なので、この状態でAppComponentのtemplateに追加するだけでTodoListComponentが表示される。
このapp-todo-listというのはコンポーネントのselectorと対応している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;h1&amp;gt;
  {{title}}
&amp;lt;/h1&amp;gt;
&amp;lt;app-todo-list&amp;gt;&amp;lt;/app-todo-list&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;@Component({
  selector: &#39;app-todo-list&#39;,
  templateUrl: &#39;./todo-list.component.html&#39;,
  styleUrls: [&#39;./todo-list.component.css&#39;]
})
export class TodoListComponent {
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;todoリストを表示する&#34;&gt;TODOリストを表示する&lt;/h2&gt;

&lt;p&gt;TODOリストを入力として受け取って表示するコンポーネントを作る。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@Input&lt;/code&gt;で入力を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component, OnInit, Input } from &#39;@angular/core&#39;;

@Component({
  selector: &#39;app-todo-list&#39;,
  templateUrl: &#39;./todo-list.component.html&#39;,
  styleUrls: [&#39;./todo-list.component.css&#39;]
})
export class TodoListComponent implements OnInit {

  @Input() todos: string[] = [];

  constructor() { }

  ngOnInit() {
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;渡すときは&lt;code&gt;[@Inputの変数名]=&amp;quot;値&amp;quot;&lt;/code&gt;。分かりやすいように変数名を変えてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;app-todo-list [todos]=&amp;quot;todos_&amp;quot;&amp;gt;&amp;lt;/app-todo-list&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;import { Component } from &#39;@angular/core&#39;;

@Component({
  selector: &#39;app-root&#39;,
  templateUrl: &#39;./app.component.html&#39;,
  styleUrls: [&#39;./app.component.css&#39;]
})
export class AppComponent {
  title = &#39;app works!&#39;;
  todos_ = [&amp;quot;朝起きる&amp;quot;, &amp;quot;昼ご飯を食べる&amp;quot;, &amp;quot;夜ご飯を食べる&amp;quot;, &amp;quot;寝る&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;todosは&lt;code&gt;*ngFor&lt;/code&gt;でループさせて表示させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
  &amp;lt;li
    *ngFor=&amp;quot;let todo of todos&amp;quot;
  &amp;gt;
  {{todo}}
  &amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、出力する/しないを制御する&lt;code&gt;*ngIf&lt;/code&gt;もあって、
これらの頭に付いている
&lt;code&gt;*&lt;/code&gt;はStructural directivesの&lt;a href=&#34;https://angular.io/docs/dart/latest/guide/structural-directives.html#!#asterisk&#34;&gt;糖衣構文&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Directiveは&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;コンポーネント&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://angular.io/docs/dart/latest/guide/structural-directives.html&#34;&gt;Structual directives&lt;/a&gt; (DOM elementを追加したり削除したりする)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://angular.io/docs/dart/latest/guide/attribute-directives.html&#34;&gt;Attribute directives&lt;/a&gt; (Dom elementの見た目や挙動を変える)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;の3種類ある。&lt;/p&gt;

&lt;h2 id=&#34;todoを登録する&#34;&gt;TODOを登録する&lt;/h2&gt;

&lt;p&gt;登録する用のコンポーネントを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ng g component todo-form
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今度は&lt;code&gt;@Output&lt;/code&gt;で出力する方。
onCreateTodoでEventEmitterのnextに次の状態を渡してイベントを発火させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iimport { Component, OnInit, Output, EventEmitter } from &#39;@angular/core&#39;;

@Component({
  selector: &#39;app-todo-form&#39;,
  templateUrl: &#39;./todo-form.component.html&#39;,
  styleUrls: [&#39;./todo-form.component.css&#39;]
})
export class TodoFormComponent implements OnInit {

  @Output() createTodo = new EventEmitter();

  newTodo = &amp;quot;&amp;quot;;

  constructor() { }

  ngOnInit() {
  }

  onCreateTodo() {
    if(this.newTodo !== &amp;quot;&amp;quot;) this.createTodo.next(this.newTodo);
    this.newTodo = &amp;quot;&amp;quot;;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;フォームでは&lt;code&gt;(ngSubmit)&lt;/code&gt;でonsubmitイベント時にonCreateTodoが呼ばれるようにしている。
また、&lt;code&gt;[(ngModel)]=&amp;quot;newTodo&amp;quot;&lt;/code&gt;でnewTodoを
&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/template-syntax.html#!#ngModel&#34;&gt;Two-way binding&lt;/a&gt;して
フォームと変数の値を同期させる。これにはFormsModuleが必要で、既にRoot Moduleに含まれている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div&amp;gt;
  &amp;lt;form (ngSubmit)=&amp;quot;onCreateTodo()&amp;quot;&amp;gt;
    &amp;lt;input
      type=&amp;quot;text&amp;quot;
      name=&amp;quot;todo&amp;quot;
      [(ngModel)]=&amp;quot;newTodo&amp;quot;
    &amp;gt;
    &amp;lt;button
      type=&amp;quot;submit&amp;quot;
    &amp;gt;
    登録
    &amp;lt;/button&amp;gt;
  &amp;lt;/form&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;@Output&lt;/code&gt;はこんな感じでハンドリングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;app-todo-form (createTodo)=&amp;quot;onCreateTodo($event)&amp;quot;&amp;gt;&amp;lt;/app-todo-form&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;登録イベントが起きたらtodos_に追加していく。これでリストの方も更新される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component } from &#39;@angular/core&#39;;

@Component({
  selector: &#39;app-root&#39;,
  templateUrl: &#39;./app.component.html&#39;,
  styleUrls: [&#39;./app.component.css&#39;]
})
export class AppComponent {
  title = &#39;app works!&#39;;
  todos_ = [&amp;quot;朝起きる&amp;quot;, &amp;quot;昼ご飯を食べる&amp;quot;, &amp;quot;夜ご飯を食べる&amp;quot;, &amp;quot;寝る&amp;quot;]

  onCreateTodo(todo) {
    this.todos_.push(todo);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;apiを叩くサービスを作る&#34;&gt;APIを叩くサービスを作る&lt;/h2&gt;

&lt;p&gt;データを保存して取得する簡易的なAPIを用意した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var express = require(&#39;express&#39;)
var bodyParser = require(&#39;body-parser&#39;)
var app = express()
app.use(bodyParser());

data = []

app.get(&#39;/&#39;, function (req, res) {
  res.send(data)
})

app.post(&#39;/&#39;, function (req, res) {
  data.push(req.body)
  res.send(req.body)
})

app.listen(3000, function () {
  console.log(&#39;listening on port 3000&#39;)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir services
$ ng g service services/todo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サービスクラスとテストができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/server-communication.html&#34;&gt;HTTP Client - ts - GUIDE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Angularで用意されているHTTPクライアントは&lt;a href=&#34;https://github.com/ReactiveX/RxJS&#34;&gt;RxJS&lt;/a&gt;のObservableな値を返す。
これを扱うために&lt;code&gt;import &#39;rxjs/Rx&#39;&lt;/code&gt;するとサイズがとても大きくなってしまうので必要なものだけをimportする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import &#39;rxjs/add/operator/map&#39;;
import &#39;rxjs/add/operator/catch&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンストラクタのhttpはAngularによって
providerから&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/dependency-injection.html&#34;&gt;DI&lt;/a&gt;される。
Root Moduleのprovidersは空になっているが、HttpModuleで提供されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iimport { Injectable } from &#39;@angular/core&#39;;
import { Http, Response, Headers, RequestOptions } from &#39;@angular/http&#39;;
import { Observable }     from &#39;rxjs/Observable&#39;;

@Injectable()
export class TodoService {
  private apiUrl = &#39;http://localhost:3000&#39;;

  constructor(private http: Http) { }

  getTodos (): Observable&amp;lt;string[]&amp;gt; {
    return this.http.get(this.apiUrl)
                    .map(this.extractData)
                    .catch(this.handleError);
  }

  addTodo (todo: string): Observable&amp;lt;string&amp;gt; {
    let headers = new Headers({ &#39;Content-Type&#39;: &#39;application/json&#39; });
    let options = new RequestOptions({ headers: headers });

    return this.http.post(this.apiUrl, { todo }, options)
                    .map(this.extractData)
                    .catch(this.handleError);
  }

  private extractData(res: Response) {
    let body = res.json();
    return body || { };
  }

  private handleError (error: Response | any) {
    // In a real world app, we might use a remote logging infrastructure
    let errMsg: string;
    if (error instanceof Response) {
      const body = error.json() || &#39;&#39;;
      const err = body.error || JSON.stringify(body);
      errMsg = `${error.status} - ${error.statusText || &#39;&#39;} ${err}`;
    } else {
      errMsg = error.message ? error.message : error.toString();
    }
    console.error(errMsg);
    return Observable.throw(errMsg);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このサービスがDIされるようにprovidersに追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { BrowserModule } from &#39;@angular/platform-browser&#39;;
import { NgModule } from &#39;@angular/core&#39;;
import { FormsModule } from &#39;@angular/forms&#39;;
import { HttpModule } from &#39;@angular/http&#39;;

import { AppComponent } from &#39;./app.component&#39;;
import { TodoListComponent } from &#39;./todo-list/todo-list.component&#39;;
import { TodoFormComponent } from &#39;./todo-form/todo-form.component&#39;;

import { TodoService } from &#39;./services/todo.service&#39;;

// RxJS
import &#39;rxjs/add/operator/map&#39;;
import &#39;rxjs/add/operator/catch&#39;;

@NgModule({
  declarations: [
    AppComponent,
    TodoListComponent,
    TodoFormComponent
  ],
  imports: [
    BrowserModule,
    FormsModule,
    HttpModule
  ],
  providers: [TodoService],
  bootstrap: [AppComponent]
})
export class AppModule { }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サービスを使うようにする。ngOnInitはコンポーネントのプロパティが初期化されたあと一度だけ呼ばれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://angular.io/docs/ts/latest/guide/lifecycle-hooks.html&#34;&gt;Lifecycle Hooks - ts - GUIDE&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { Component, OnInit } from &#39;@angular/core&#39;;
import { TodoService } from &#39;./services/todo.service&#39;;

@Component({
  selector: &#39;app-root&#39;,
  templateUrl: &#39;./app.component.html&#39;,
  styleUrls: [&#39;./app.component.css&#39;]
})
export class AppComponent implements OnInit {
  title = &#39;app works!&#39;;
  todos_: string[] = []

  constructor(private todoService: TodoService) { }

  ngOnInit() {
    this.todoService.getTodos().subscribe(
                       todos =&amp;gt; this.todos_ = todos.map((t) =&amp;gt; t[&amp;quot;todo&amp;quot;]),
                       error =&amp;gt; this.todos_ = [&amp;quot;&amp;lt;error&amp;gt;&amp;quot;]);
  }

  onCreateTodo(todo: string) {
    this.todoService.addTodo(todo).subscribe(
                       todo =&amp;gt; this.todos_.push(todo[&amp;quot;todo&amp;quot;]),
                       error =&amp;gt; this.todos_ = [&amp;quot;&amp;lt;error&amp;gt;&amp;quot;]);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テストは気が向いたら書く。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OpenVPNサーバーPritunlをDockerで動かす</title>
          <link>https://www.sambaiz.net/article/39/</link>
          <pubDate>Fri, 02 Dec 2016 21:05:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/39/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://pritunl.com/&#34;&gt;Pritunl&lt;/a&gt;でVPNサーバーを立てる。&lt;/p&gt;

&lt;p&gt;Dockerfileはこんな感じ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/sambaiz/pritunl/&#34;&gt;https://hub.docker.com/r/sambaiz/pritunl/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM mongo:3.4

# https://docs.pritunl.com/docs/installation
RUN echo &#39;deb http://repo.pritunl.com/stable/apt jessie main&#39; &amp;gt; /etc/apt/sources.list.d/pritunl.list &amp;amp;&amp;amp; \
    apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 7568D9BB55FF9E5287D586017AE645C0CF8E292A &amp;amp;&amp;amp; \
    apt-get --assume-yes update &amp;amp;&amp;amp; \
    apt-get --assume-yes upgrade &amp;amp;&amp;amp; \
    apt-get --assume-yes install pritunl iptables

EXPOSE 80 443 12345/udp

CMD mongod --fork --logpath /data/db/mongod.log &amp;amp;&amp;amp; echo &#39;Setup Key:&#39; `pritunl setup-key` &amp;amp;&amp;amp; pritunl start
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -itd -p 80:80 -p 443:443 -p 12345:12345/udp --privileged sambaiz/pritunl
$ docker logs &amp;lt;id&amp;gt;
...
Setup Key: ***********
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--privileged&lt;/code&gt;を付けているのはStart Server時にこれで失敗しないように。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CalledProcessError: Command &#39;[&#39;sysctl&#39;, &#39;-w&#39;, &#39;net.ipv4.ip_forward=1&#39;]&#39; returned non-zero exit status 255
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;httpsでアクセスして、Setup Keyを入力すると初期設定が始まり、ログイン画面になる。
初期パスワードは&lt;code&gt;pritunl/pritunl&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;あとは、OrganizationとUser、Server(ポートはudpの12345にする)を登録し、ServerにOrganizationを紐付け、
ServerにRouteを追加して、アクセスしたいCIDRを入力したらStart Serverする。
ovpnファイルをダウンロードできる24時間有効のリンクを発行でき、これでクライアントに設定すると
RouteにVPNを通してアクセスできるようになる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>aws-sdk-goでs3にput/get</title>
          <link>https://www.sambaiz.net/article/38/</link>
          <pubDate>Wed, 30 Nov 2016 20:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/38/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/aws/aws-sdk-go&#34;&gt;aws-sdk-go&lt;/a&gt;でS3にputしてgetする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;bytes&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/aws/session&amp;quot;
	&amp;quot;github.com/aws/aws-sdk-go/service/s3&amp;quot;
)

const REGION = &amp;quot;ap-northeast-1&amp;quot;
const BUCKET_NAME = &amp;quot;faweijojio4f3e4&amp;quot;

func main() {

	sess, err := session.NewSession(aws.NewConfig().WithRegion(REGION))
	if err != nil {
		fmt.Println(err.Error())
		return
	}

	svc := s3.New(sess)

	// put
	data := []byte(&amp;quot;BBBBBB&amp;quot;)
	key := &amp;quot;AAA.txt&amp;quot;

	params := &amp;amp;s3.PutObjectInput{
		Bucket:        aws.String(BUCKET_NAME),
		Key:           aws.String(key),
		Body:          bytes.NewReader(data),
		ContentLength: aws.Int64(int64(len(data))),
		ContentType:   aws.String(&amp;quot;text/plain&amp;quot;),
	}
	if _, err = svc.PutObject(params); err != nil {
		fmt.Println(err.Error())
		return
	}

	// bucket list
	keys := []string{}
	err = svc.ListObjectsPages(&amp;amp;s3.ListObjectsInput{
		Bucket: aws.String(BUCKET_NAME),
	}, func(p *s3.ListObjectsOutput, last bool) (shouldContinue bool) {
		for _, obj := range p.Contents {
			keys = append(keys, *obj.Key)
			fmt.Println(*obj.Key)
		}
		return true
	})

	if err != nil {
		fmt.Println(err.Error())
		return
	}

	// get
	resp, err2 := svc.GetObject(&amp;amp;s3.GetObjectInput{
		Bucket: aws.String(BUCKET_NAME),
		Key:    aws.String(keys[0]),
	})
	if err2 != nil {
		fmt.Println(err2.Error())
		return
	}

	buf := new(bytes.Buffer)
	buf.ReadFrom(resp.Body)
	fmt.Println(keys[0] + &amp;quot; -&amp;gt; &amp;quot; + buf.String())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ AWS_ACCESS_KEY_ID=**** AWS_SECRET_ACCESS_KEY=**** go run main.go
AAA.txt
bbbb.txt
AAA.txt -&amp;gt; BBBBBB
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goでstructをリフレクションしてcsvを出力する</title>
          <link>https://www.sambaiz.net/article/37/</link>
          <pubDate>Mon, 28 Nov 2016 21:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/37/</guid>
          <description>&lt;p&gt;こんなstructとデータがあったら、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Result struct{
 Name string `col:&amp;quot;who&amp;quot;`
 Point int
}

x := Result{&amp;quot;sam&amp;quot;, 100}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;フィールド名と、値、タグはrefrectで取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x := Result{&amp;quot;sam&amp;quot;, 100}
v := reflect.ValueOf(x)
fmt.Println(v.Type().Field(0).Name) // -&amp;gt; Name
fmt.Println(v.Type().Field(1).Name) // -&amp;gt; Point
fmt.Println(v.Field(0).Interface()) // -&amp;gt; sam
fmt.Println(v.Field(1).Interface()) // -&amp;gt; 100
fmt.Println(v.Type().Field(0).Tag.Get(&amp;quot;col&amp;quot;)) // -&amp;gt; who
fmt.Println(v.Type().Field(1).Tag.Get(&amp;quot;col&amp;quot;)) // -&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらをencoding/csvで書く。&lt;/p&gt;

&lt;p&gt;ただ、引数を&lt;code&gt;[]interface{}&lt;/code&gt;にすると&lt;a href=&#34;https://golang.org/doc/faq#convert_slice_of_interface&#34;&gt;interface{}のスライスしか渡せない&lt;/a&gt;ので、
一旦&lt;code&gt;interface{}&lt;/code&gt;で受け取ってスライスにする。このときにもrefrectを使っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;encoding/csv&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;reflect&amp;quot;
	&amp;quot;strings&amp;quot;
)

type Result struct {
	Name  string `col:&amp;quot;who&amp;quot;`
	Point int
	Age   int `col:&amp;quot;-&amp;quot;` // ignore
}

const COLTAG = &amp;quot;col&amp;quot;

func main() {

	x := []Result{Result{&amp;quot;sam&amp;quot;, 100, 24}, Result{&amp;quot;tom&amp;quot;, 0, 100025}}

	file, err := os.OpenFile(&amp;quot;aaaa.csv&amp;quot;, os.O_WRONLY|os.O_CREATE, 0600)
	if err != nil {
		panic(err)
	}
	defer file.Close()

	WriteCSV(file, x)
}

// Convert interface{} to []interface{}
func toSlice(src interface{}) []interface{} {

	ret := []interface{}{}

	if v := reflect.ValueOf(src); v.Kind() == reflect.Slice {
		for i := 0; i &amp;lt; v.Len(); i++ {
			ret = append(ret, v.Index(i).Interface())
		}
	} else {
		ret = append(ret, v.Interface())
	}

	return ret
}

// Generate csv rows including header from interface{} slice or object
func genRows(src interface{}) [][]string {

	sl := toSlice(src)
	rows := make([][]string, 1)
	ignoreColIndex := map[int]bool{}

	for n, d := range sl {
		rows = append(rows, []string{})
		v := reflect.ValueOf(d)

		for i := 0; i &amp;lt; v.NumField(); i++ {
			if n == 0 {
				// Header
				colName := v.Type().Field(i).Tag.Get(COLTAG)
				if colName == &amp;quot;&amp;quot; {
					colName = strings.ToLower(v.Type().Field(i).Name)
				} else if colName == &amp;quot;-&amp;quot; {
					ignoreColIndex[i] = true
					continue
				}
				rows[0] = append(rows[0], colName)
			}

			if !ignoreColIndex[i] {
				rows[len(rows)-1] = append(rows[len(rows)-1], fmt.Sprint(v.Field(i).Interface()))
			}
		}
	}
	return rows
}

// Write csv file to path
func WriteCSV(file *os.File, data interface{}) {
	rows := genRows(data)

	writer := csv.NewWriter(file)
	for _, row := range rows {
		writer.Write(row)
	}
	writer.Flush()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;who,point
sam,100
tom,0
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>WebVRを動かす</title>
          <link>https://www.sambaiz.net/article/36/</link>
          <pubDate>Wed, 16 Nov 2016 00:46:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/36/</guid>
          <description>

&lt;h3 id=&#34;webvrとは&#34;&gt;WebVRとは&lt;/h3&gt;

&lt;p&gt;Webブラウザ上でVRアプリケーションを動かすためのAPI。
ヘッドマウントディスプレイの動きを3D空間上の動きに変換してくれる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/WebVR_API&#34;&gt;WebVR API - Web API インターフェイス | MDN&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ただし、まだほとんどのブラウザがVR APIをサポートしていないので、
実際は&lt;a href=&#34;https://github.com/googlevr/webvr-polyfill&#34;&gt;Polyfill&lt;/a&gt;で動かすことになる。&lt;/p&gt;

&lt;h3 id=&#34;動かしてみる&#34;&gt;動かしてみる&lt;/h3&gt;

&lt;p&gt;まず、&lt;a href=&#34;https://github.com/borismus/webvr-boilerplate&#34;&gt;webvr-boilerplate&lt;/a&gt;を動かしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm init
$ npm install node-static
$ git clone https://github.com/borismus/webvr-boilerplate.git
$ cd webvr-boilerplate/ &amp;amp;&amp;amp; npm install &amp;amp; cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;var static = require(&#39;node-static&#39;);

var fileServer = new static.Server(&#39;./webvr-boilerplate&#39;);

require(&#39;http&#39;).createServer(function (request, response) {
    request.addListener(&#39;end&#39;, function () {
        fileServer.serve(request, response);
    }).resume();
}).listen(8080);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:8080&#34;&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;を見ると箱が回っているのが映る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/36_webvr1.png&#34; alt=&#34;箱が回っている&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ただ、start_modeに3を指定してVRモードにしようとしたところ、&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:8080/index.html?start_mode=3&#34;&gt;http://localhost:8080/index.html?start_mode=3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PCのChromeから見ると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;base.js:191 Uncaught (in promise) Error: VRDisplay is not capable of presenting
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;というエラーが出てしまった。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Only enable VR mode if there&amp;rsquo;s a VR device attached or we are running the polyfill on mobile&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;と書いてあったので、Android端末から見てみたところ
Cardboardのマークが出てきて、それを押したら二眼の表示になった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/36_vrview.png&#34; alt=&#34;二眼で映っている&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;描画&#34;&gt;描画&lt;/h3&gt;

&lt;p&gt;webvr-boilerplateでは、描画に&lt;a href=&#34;https://threejs.org/&#34;&gt;Three.js&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;まずシーンやカメラを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var scene = new THREE.Scene();
var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、cameraをTHREE.VRControlsに渡す。この中でVR APIを呼んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var controls = new THREE.VRControls(camera);
controls.standing = true;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをupdateしていくことでVRデバイスにcameraが連動するようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;controls.update();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自分でVR APIを呼んでいるところもあって、
&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Navigator/getVRDisplays&#34;&gt;Navigator.getVRDisplays()&lt;/a&gt;で
VRDisplayを取得し、
&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/VRDevice/requestAnimationFrame&#34;&gt;VRDisplay.requestAnimationFrame()&lt;/a&gt;で、VRDisplayのリフレッシュレートでアニメーションさせるコールバックが呼ばれるようにしている。
このコールバックの中で&lt;code&gt;controls.update()&lt;/code&gt;を呼んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function setupStage() {
  navigator.getVRDisplays().then(function(displays) {
    if (displays.length &amp;gt; 0) {
      vrDisplay = displays[0];
      if (vrDisplay.stageParameters) {
        setStageDimensions(vrDisplay.stageParameters);
      }
      vrDisplay.requestAnimationFrame(animate);
    }
  });
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>JVMのヒープ領域とFull GC</title>
          <link>https://www.sambaiz.net/article/35/</link>
          <pubDate>Mon, 14 Nov 2016 23:46:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/35/</guid>
          <description>

&lt;h3 id=&#34;ヒープ領域&#34;&gt;ヒープ領域&lt;/h3&gt;

&lt;p&gt;ヒープ領域というのはメモリ上の動的に確保する領域のこと。
JVMでは、ヒープ領域のNew領域とOld領域、非ヒープ領域のPermanent領域が存在する(した)。&lt;/p&gt;

&lt;h3 id=&#34;permanent領域&#34;&gt;Permanent領域&lt;/h3&gt;

&lt;p&gt;ロードしたクラスやメソッドが入る。
Java8版のHotspotVM(OracleのJVM)ではMetaspace領域となり、ネイティブメモリに乗るようになったらしい。&lt;/p&gt;

&lt;h3 id=&#34;new領域&#34;&gt;New領域&lt;/h3&gt;

&lt;p&gt;New領域の中はさらに分かれている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Eden領域: オブジェクトが作られて最初に配置される。&lt;/li&gt;
&lt;li&gt;To領域(Survivor領域1): Edenが一杯になると、EdenとFromから送られる。&lt;/li&gt;
&lt;li&gt;From領域(Survivor領域0): Edenが一杯になると、Toから送られる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Edenが一杯になったときに不要なオブジェクトは破棄、必要なものは領域を移動させるのがScavenge GC。
つまり、Edenが一杯になるたびにToに飛んだオブジェクトはFromと往復し続ける。
ただし、MaxTenuringThresholdの回数を超えるとOld領域に送られることになる。&lt;/p&gt;

&lt;h3 id=&#34;old領域&#34;&gt;Old領域&lt;/h3&gt;

&lt;p&gt;Old領域も一杯になったらどうしようもないのでFull GCが走る。
Full GCでは全ての領域のオブジェクトをチェックして不要なものを探す。
これに集中するので他のことはできなくなり、時間もかかる。
Full GCばかり起きていたらまともに動かないので、
Old領域にまで行かないようにオブジェクトの寿命を短くするか、
ヒープ領域の大きさ(&lt;code&gt;-Xms&lt;/code&gt;, &lt;code&gt;-Xmx&lt;/code&gt;)を変えたりしてなるべく起きないようにしたい。&lt;/p&gt;

&lt;h3 id=&#34;どれくらいfull-gcしているかどうか&#34;&gt;どれくらいFull GCしているかどうか&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;-Xloggc&lt;/code&gt;でGCのログが出せる。&lt;code&gt;-XX:+UseGCLogFileRotation&lt;/code&gt;でローテーションしたりもできる。
あと手軽に&lt;code&gt;jps&lt;/code&gt;からの&lt;code&gt;jstat -gc &amp;lt;pid&amp;gt;&lt;/code&gt;、あるいはグラフで可視化できるようなやつでヒープ領域の状態を確認する。
&lt;code&gt;jstat&lt;/code&gt;の結果の意味は&lt;a href=&#34;https://docs.oracle.com/javase/jp/8/docs/technotes/tools/windows/jstat.html&#34;&gt;ここ&lt;/a&gt;に書いてある。
例えばFGCがフルGCイベントの数。&lt;/p&gt;

&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://d.hatena.ne.jp/ogin_s57/20120623/1340463194&#34;&gt;JVMとGCのしくみ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://equj65.net/tech/java8hotspot/&#34;&gt;Java8のHotSpotVMからPermanent領域が消えた理由とその影響 | ギークを目指して&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/i_matsui/items/aabbdaa169c6ae51ecb3&#34;&gt;Java開発の性能改善！ その２ GCログの解析とHeepの設定&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>API BlueprintでAPI仕様を書く</title>
          <link>https://www.sambaiz.net/article/34/</link>
          <pubDate>Thu, 10 Nov 2016 00:25:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/34/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://apiblueprint.org/&#34;&gt;API Blueprint&lt;/a&gt;というのはAPIの仕様を書くための言語で、
これを元にHTMLのドキュメントにしたり、モックサーバーを立てたりする&lt;a href=&#34;https://apiblueprint.org/tools.html&#34;&gt;ツール&lt;/a&gt;がある。&lt;/p&gt;

&lt;p&gt;最初にMetadataとして、API Blueprintのバージョンを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FORMAT: 1A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;基本的にはMarkdownのように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# テストAPI
テスト
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;頭にGroupと書くとグループができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Group echo
やまびこ
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;終わりに&lt;code&gt;[]&lt;/code&gt;で囲んでリソースを書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## echo [/echo]
やっほー
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アクション。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;### echo [POST]
叫ぶ

+ say (string) - 発声
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リクエスト例とレスポンス例はこんな感じ。&lt;a href=&#34;https://apiblueprint.org/documentation/advanced-tutorial.html#json-schema&#34;&gt;JSON Schemaを書くこともできる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+ Request (application/json)

    {
        &amp;quot;say&amp;quot;: &amp;quot;yahho&amp;quot;
    }

+ Response 200 (application/json)

  + Headers

    Hoge: Fuga

  + Body

    {
        &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;全体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FORMAT: 1A

# テストAPI
テスト

# Group echo
やまびこ

## echo [/echo]
やっほー

### echo [POST]
叫ぶ

+ say (string) - 発声

+ Request (application/json)

    {
        &amp;quot;say&amp;quot;: &amp;quot;yahho&amp;quot;
    }

+ Response 200 (application/json)

  + Headers

    Hoge: Fuga

  + Body

    {
        &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを使って、&lt;a href=&#34;https://github.com/danielgtaylor/aglio&#34;&gt;aglio&lt;/a&gt;でHTMLにしたり、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g aglio
$ aglio -i test.apib -o test.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/34_api_html.png&#34; alt=&#34;HTMLに出力したもの&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/localmed/api-mock&#34;&gt;api-mock&lt;/a&gt;でモックを立てたりすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g api-mock
$ api-mock --version
api-mock v0.3.2

$ api-mock test.apib
info:    Enabled Cross-Origin-Resource-Sharing (CORS)
info:    	Allow-Origin: *
info:    	Allow-Methods: GET, PUT, POST, PATCH, DELETE, TRACE, OPTIONS
info:    	Allow-Headers: Origin, X-Requested-With, Content-Type, Accept, Authorization, Referer, Prefer
info:    Listening on port 3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただnode v6でインストールしたらprotagonistのところで失敗してしまったので、5.12.0に下げて実行した。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/8/&#34;&gt;nでNode.jsのバージョン管理&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ n 5.12.0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X POST -H &amp;quot;Content-Type: application/json&amp;quot; -d &#39;{&amp;quot;say&amp;quot;: &amp;quot;ho&amp;quot;}&#39; &amp;quot;http://localhost:3000/echo&amp;quot;
{
    &amp;quot;echo&amp;quot;: &amp;quot;yahho&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>logrotateでログをローテーションする</title>
          <link>https://www.sambaiz.net/article/33/</link>
          <pubDate>Wed, 09 Nov 2016 22:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/33/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/Sirupsen/logrus&#34;&gt;logrus&lt;/a&gt;がローテーションする仕組みを持っていなかったので、
READMEに書いてあったlogrotateを使う。/etc/logrotate.dの中に設定ファイルを入れて、cronで回して使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM ubuntu:14.04

ADD logrotate /etc/logrotate.d/app
RUN echo &amp;quot;/usr/sbin/logrotate /etc/logrotate.conf&amp;quot; &amp;gt; /etc/cron.daily/logrotate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定ファイル(logrotate)はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/var/log/app.log {
  daily
  rotate 4
  missingok
  delaycompress
  dateext
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;daily&lt;/code&gt;で1日に1回、&lt;code&gt;rotate 4&lt;/code&gt;で過去4日分残し、
&lt;code&gt;missingok&lt;/code&gt;でファイルがなくてもエラーにせず、&lt;code&gt;delaycompress&lt;/code&gt;で圧縮するのをローテーションした次の回にして、
&lt;code&gt;dateext&lt;/code&gt;でローテーションしたファイルの末尾を数字ではなく日付にする。&lt;/p&gt;

&lt;p&gt;実際に動かして確かめる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logrotate&lt;/code&gt;を実行すると、&lt;code&gt;/var/lib/logrotate/status&lt;/code&gt;に過去に見た時間が入る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;aaaaa&amp;quot; &amp;gt; /var/log/app.log
$ logrotate /etc/logrotate.conf
$ cat /var/lib/logrotate/status
logrotate state -- version 2
...
&amp;quot;/var/log/app.log&amp;quot; 2016-11-9-11:0:0
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;強制的にローテーションさせてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;aaaa&amp;quot; &amp;gt; /var/log/app.log
$ logrotate -f /etc/logrotate.conf
$ ls /var/log | grep app
app.log
app.log-20161109

$ cat /var/log/app.log-20161109
aaaaa
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>td-agentをビルドしてfluentdのバージョンを上げる</title>
          <link>https://www.sambaiz.net/article/32/</link>
          <pubDate>Sun, 06 Nov 2016 11:17:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/32/</guid>
          <description>&lt;pre&gt;&lt;code&gt;$td-agent --version
td-agent 0.12.26
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;td-agentって書いてあるけど、これがfluentdのバージョンらしい。&lt;/p&gt;

&lt;p&gt;fluentdはv0.14から&lt;a href=&#34;http://www.fluentd.org/blog/fluentd-v0.14.0-has-been-released&#34;&gt;ナノ秒で時間を持つようになった。&lt;/a&gt;
ただ、現行のtd-agent(v2.3.2)は上の通り古いバージョンを使っている。
0.14になる&lt;a href=&#34;https://github.com/treasure-data/omnibus-td-agent/tree/td-agent-3&#34;&gt;td-agent-3&lt;/a&gt;はまだリリースされていないので、
自分でfluentdを&lt;a href=&#34;https://github.com/fluent/fluentd/releases/tag/v0.14.8&#34;&gt;v0.14.8&lt;/a&gt;に上げてビルドすることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM ubuntu:14.04

WORKDIR /tmp

RUN apt-get update &amp;amp;&amp;amp; \
    apt-get install -y git software-properties-common build-essential curl &amp;amp;&amp;amp; \
    add-apt-repository -y ppa:brightbox/ruby-ng &amp;amp;&amp;amp; \
    apt-get update &amp;amp;&amp;amp; \
    apt-get install -y ruby2.3 ruby2.3-dev &amp;amp;&amp;amp; \
    gem install bundler &amp;amp;&amp;amp; \
    git clone https://github.com/treasure-data/omnibus-td-agent

WORKDIR /tmp/omnibus-td-agent

RUN sed -ie &amp;quot;s/^default_version.*$/default_version &#39;3d1dd53f31d1fe49508f230a71a2b4c2ceb20f47&#39;/&amp;quot; config/software/fluentd.rb &amp;amp;&amp;amp; \
    sed -ie &amp;quot;s/^license_file.*$/license_file &#39;LICENSE&#39;/&amp;quot; config/projects/td-agent2.rb &amp;amp;&amp;amp; \
    bundle install --binstubs &amp;amp;&amp;amp; \
    bin/gem_downloader core_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader plugin_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader ui_gems.rb &amp;amp;&amp;amp; \
    git config --global user.email &amp;quot;root@example.com&amp;quot; &amp;amp;&amp;amp; \
    mkdir -p /opt/td-agent /var/cache/omnibus &amp;amp;&amp;amp; \
    bin/omnibus build td-agent2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;config/projects/td-agent2.rb&lt;/code&gt;を書き換えているのは、ビルド時に&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/var/lib/gems/2.3.0/gems/omnibus-5.5.0/lib/omnibus/licensing.rb:223:in `read&#39;: No such file or directory @ rb_sysopen - /tmp/omnibus-td-agent/https://raw.githubusercontent.com/treasure-data/omnibus-td-agent/master/LICENSE (Errno::ENOENT)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなエラーが出たため。&lt;a href=&#34;https://github.com/chef/omnibus/blob/v5.5.0/lib/omnibus/licensing.rb#L223&#34;&gt;licensing.rb&lt;/a&gt;を見てみたところ、相対パスを想定しているようだった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;g++: internal compiler error: Killed (program cc1plus)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;が出たらメモリが足りないかもしれない。&lt;/p&gt;

&lt;p&gt;ビルドが成功したらpkgにdebが出来ている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker cp &amp;lt;Container ID&amp;gt;:/tmp/omnibus-td-agent/pkg/td-agent_2.3.3-0_amd64.deb .
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ dpkg -i td-agent_2.3.3-0_amd64.deb
$ td-agent --version
td-agent 0.14.8
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>d3.jsで折れ線グラフを書くコードを読む</title>
          <link>https://www.sambaiz.net/article/31/</link>
          <pubDate>Thu, 03 Nov 2016 00:15:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/31/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://bl.ocks.org/mbostock/3883245&#34;&gt;http://bl.ocks.org/mbostock/3883245&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CSSと&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;

.axis--x path {
  display: none;
}

.line {
  fill: none;
  stroke: steelblue;
  stroke-width: 1.5px;
}

&amp;lt;/style&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;グラフを書くsvgとd3.js。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;svg width=&amp;quot;960&amp;quot; height=&amp;quot;500&amp;quot;&amp;gt;&amp;lt;/svg&amp;gt;
&amp;lt;script src=&amp;quot;https://d3js.org/d3.v4.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;var svg = d3.select(&amp;quot;svg&amp;quot;),
    margin = {top: 20, right: 20, bottom: 30, left: 50},
    width = +svg.attr(&amp;quot;width&amp;quot;) - margin.left - margin.right,
    height = +svg.attr(&amp;quot;height&amp;quot;) - margin.top - margin.bottom,
    g = svg.append(&amp;quot;g&amp;quot;).attr(&amp;quot;transform&amp;quot;, &amp;quot;translate(&amp;quot; + margin.left + &amp;quot;,&amp;quot; + margin.top + &amp;quot;)&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;d3.select&lt;/code&gt;でsvg要素を選択。widthとheightを取得したり、中にg(グループ)を入れてtransformでmarginを作っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;svg width=&amp;quot;960&amp;quot; height=&amp;quot;500&amp;quot;&amp;gt;&amp;lt;g transform=&amp;quot;translate(50,20)&amp;quot;&amp;gt;&amp;lt;/g&amp;gt;&amp;lt;/svg&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;svg.attr&lt;/code&gt;の前に+を付けるとnullの場合でも数値として扱える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; +null
0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;var parseTime = d3.timeParse(&amp;quot;%d-%b-%y&amp;quot;);

var x = d3.scaleTime()
    .rangeRound([0, width]);

var y = d3.scaleLinear()
    .rangeRound([height, 0]);

var line = d3.line()
    .x(function(d) { return x(d.date); })
    .y(function(d) { return y(d.close); });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;d3.scaleTime()&lt;/code&gt;や&lt;code&gt;d3.scaleLinear()&lt;/code&gt;は&lt;code&gt;domain&lt;/code&gt;で値域を指定し、&lt;code&gt;range&lt;/code&gt;の範囲にマッピングさせる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; d3.scaleLinear().rangeRound([0, 100]).domain([0, 66525])(33262)
50
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;d3.line()&lt;/code&gt;で点を結ぶ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; d3.line()
  .x(function(d) { return d.a; })
  .y(function(d) { return d.b; })([{a: 10, b: 20},{a: 20, b:10}])
M10,20L20,10
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;d3.tsv(&amp;quot;data.tsv&amp;quot;, function(d) {
  d.date = parseTime(d.date);
  d.close = +d.close;
  return d;
}, function(error, data) {
  if (error) throw error;

  x.domain(d3.extent(data, function(d) { return d.date; }));
  y.domain(d3.extent(data, function(d) { return d.close; }));

  g.append(&amp;quot;g&amp;quot;)
      .attr(&amp;quot;class&amp;quot;, &amp;quot;axis axis--x&amp;quot;)
      .attr(&amp;quot;transform&amp;quot;, &amp;quot;translate(0,&amp;quot; + height + &amp;quot;)&amp;quot;)
      .call(d3.axisBottom(x));

  g.append(&amp;quot;g&amp;quot;)
      .attr(&amp;quot;class&amp;quot;, &amp;quot;axis axis--y&amp;quot;)
      .call(d3.axisLeft(y))
    .append(&amp;quot;text&amp;quot;)
      .attr(&amp;quot;fill&amp;quot;, &amp;quot;#000&amp;quot;)
      .attr(&amp;quot;transform&amp;quot;, &amp;quot;rotate(-90)&amp;quot;)
      .attr(&amp;quot;y&amp;quot;, 6)
      .attr(&amp;quot;dy&amp;quot;, &amp;quot;0.71em&amp;quot;)
      .style(&amp;quot;text-anchor&amp;quot;, &amp;quot;end&amp;quot;)
      .text(&amp;quot;Price ($)&amp;quot;);

  g.append(&amp;quot;path&amp;quot;)
      .datum(data)
      .attr(&amp;quot;class&amp;quot;, &amp;quot;line&amp;quot;)
      .attr(&amp;quot;d&amp;quot;, line);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;tsvを読んで加工した後、&lt;code&gt;d3.extent&lt;/code&gt;で[最小値, 最大値]の配列を作ってdomainに渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;console.log(d3.extent([4, 1, 2, 4, 9, 3], function(d){ return d }))
[1, 9]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あと縦軸と横軸を書いてパスを書く。&lt;/p&gt;

&lt;p&gt;`&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>mp4をエンコードしてMPEG-DASHにして再生する</title>
          <link>https://www.sambaiz.net/article/30/</link>
          <pubDate>Sun, 30 Oct 2016 23:51:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/30/</guid>
          <description>

&lt;h2 id=&#34;mpeg-dashとは&#34;&gt;MPEG-DASHとは&lt;/h2&gt;

&lt;p&gt;HTTPで動画をストリーミングするための規格。似たようなのにAppleの独自規格であるHLSなどがある。&lt;/p&gt;

&lt;p&gt;サーバーはMPD(Media Presentation Description)ファイルと、セグメントに分けられた動画や音声ファイルを持っていて、
クライアントはMPDファイルをリクエストし、この内容をもとにセグメントをリクエストしていく。&lt;/p&gt;

&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ffmpeg.org/ffmpeg.html&#34;&gt;ffmpeg&lt;/a&gt;と
&lt;a href=&#34;https://gpac.wp.mines-telecom.fr/mp4box/&#34;&gt;MP4Box&lt;/a&gt;を使うので、これらを実行できるようにする。
Docker上で実行することもできて、その場合は以下のようにエイリアスを付けると便利。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ alias ffmpeg=&#39;docker run --rm -v `pwd`:/tmp/workdir jrottenberg/ffmpeg&#39;
$ alias MP4Box=&#39;docker run --rm -v `pwd`:/work sambaiz/mp4box&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;エンコード&#34;&gt;エンコード&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ffmpeg -i input.mp4 -vcodec libx264 -vb 448k -r 30 -x264opts no-scenecut -g 15 -acodec libfaac -ac 2 -ab 128k -frag_duration 5000000 -movflags empty_moov output.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;オプションの意味は多分こんな感じ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-vcodec libx264&lt;/code&gt;: 動画を&lt;a href=&#34;https://ja.wikipedia.org/wiki/H.264&#34;&gt;H.264&lt;/a&gt;にエンコードする&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-vb 448k&lt;/code&gt;: 動画のビットレート(bps)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-r 30&lt;/code&gt;: 動画のフレームレート(fps)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-x264opts no-scenecut&lt;/code&gt;: キーフレームの間隔を動画の内容によらず固定にする&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-g 15&lt;/code&gt;: キープレームの間隔。フレームレート(&lt;code&gt;-r&lt;/code&gt;) * フラグメントの時間(&lt;code&gt;-frag_duration&lt;/code&gt;) / キーフレームの間隔(&lt;code&gt;-g&lt;/code&gt;)が整数になるようにする。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-acodec libfaac&lt;/code&gt;: 音声を&lt;a href=&#34;https://ja.wikipedia.org/wiki/AAC&#34;&gt;AAC&lt;/a&gt;にエンコードする&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ac 2&lt;/code&gt;: 音声チャンネル数2(ステレオ)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ab 128k&lt;/code&gt;: 音声のビットレート(bps)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-frag_duration 5000000&lt;/code&gt;: フラグメント(セグメント)の時間(μs)。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-movflags empty_moov&lt;/code&gt;: 頭にmdat atom(データが含まれる)なしで、moov atom(メタ情報が含まれている)を書き始めるらしい。これにしないとMP4Boxに入れるときに失敗した。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ MP4Box -info -v input.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
[iso file] Current top box start before parsing 0
[iso file] Read Box type ftyp size 24 start 0
[iso file] Current top box start before parsing 24
[iso file] Read Box type free size 8 start 24
[iso file] Current top box start before parsing 32
[iso file] Read Box type mdat size 5216803 start 32 &amp;lt;--
[iso file] Current top box start before parsing 5216835
[iso file] Read Box type moov size 13332 start 5216835 &amp;lt;--
...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ MP4Box -info -v output.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[iso file] Current top box start before parsing 0
[iso file] Read Box type ftyp size 36 start 0
[iso file] Current top box start before parsing 36
[iso file] Read Box type moov size 1186 start 36 &amp;lt;--
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mpeg-dashにする&#34;&gt;MPEG-DASHにする&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ MP4Box -dash 5000 output.mp4
$ ls
input.mp4 output.mp4 output_dash.mpd output_dashinit.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;-dash&lt;/code&gt;はセグメントの時間。ただ、このmpdだと&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Multiplexed representations are intentionally not supported, as they are not compliant with the DASH-AVC/264 guidelines
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と出てしまい再生できない。中を見てみると、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Representation id=&amp;quot;1&amp;quot; mimeType=&amp;quot;video/mp4&amp;quot; codecs=&amp;quot;avc1.64000d,mp4a.40.2&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;240&amp;quot; frameRate=&amp;quot;30&amp;quot; sar=&amp;quot;1:1&amp;quot; audioSamplingRate=&amp;quot;44100&amp;quot; startWithSAP=&amp;quot;1&amp;quot; bandwidth=&amp;quot;564201&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;となっていて、動画と音声が一つのRepresentationになっているのがまずそうだったので、動画と音声を分けて実行した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ MP4Box -dash 5000 output.mp4#video output.mp4#audio
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;結果、できたmpdがこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;!-- MPD file Generated with GPAC version 0.6.1-rev14-g8eb0297-master  at 2016-10-30T14:47:02.962Z--&amp;gt;
&amp;lt;MPD xmlns=&amp;quot;urn:mpeg:dash:schema:mpd:2011&amp;quot; minBufferTime=&amp;quot;PT1.500S&amp;quot; type=&amp;quot;static&amp;quot; mediaPresentationDuration=&amp;quot;PT0H0M21.545S&amp;quot; maxSegmentDuration=&amp;quot;PT0H0M10.000S&amp;quot; profiles=&amp;quot;urn:mpeg:dash:profile:full:2011&amp;quot;&amp;gt;
 &amp;lt;ProgramInformation moreInformationURL=&amp;quot;http://gpac.sourceforge.net&amp;quot;&amp;gt;
  &amp;lt;Title&amp;gt;output_dash.mpd generated by GPAC&amp;lt;/Title&amp;gt;
 &amp;lt;/ProgramInformation&amp;gt;

 &amp;lt;Period duration=&amp;quot;PT0H0M21.545S&amp;quot;&amp;gt;
  &amp;lt;AdaptationSet segmentAlignment=&amp;quot;true&amp;quot; maxWidth=&amp;quot;320&amp;quot; maxHeight=&amp;quot;240&amp;quot; maxFrameRate=&amp;quot;30&amp;quot; par=&amp;quot;4:3&amp;quot; lang=&amp;quot;eng&amp;quot;&amp;gt;
   &amp;lt;Representation id=&amp;quot;1&amp;quot; mimeType=&amp;quot;video/mp4&amp;quot; codecs=&amp;quot;avc3.64000d&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;240&amp;quot; frameRate=&amp;quot;30&amp;quot; sar=&amp;quot;1:1&amp;quot; startWithSAP=&amp;quot;1&amp;quot; bandwidth=&amp;quot;437781&amp;quot;&amp;gt;
    &amp;lt;BaseURL&amp;gt;output_track1_dashinit.mp4&amp;lt;/BaseURL&amp;gt;
    &amp;lt;SegmentList timescale=&amp;quot;15360&amp;quot; duration=&amp;quot;153600&amp;quot;&amp;gt;
     &amp;lt;Initialization range=&amp;quot;0-1128&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;1129-556172&amp;quot; indexRange=&amp;quot;1129-1172&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;556173-1134265&amp;quot; indexRange=&amp;quot;556173-556216&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;1134266-1172888&amp;quot; indexRange=&amp;quot;1134266-1134309&amp;quot;/&amp;gt;
    &amp;lt;/SegmentList&amp;gt;
   &amp;lt;/Representation&amp;gt;
  &amp;lt;/AdaptationSet&amp;gt;
  &amp;lt;AdaptationSet segmentAlignment=&amp;quot;true&amp;quot; lang=&amp;quot;eng&amp;quot;&amp;gt;
   &amp;lt;Representation id=&amp;quot;2&amp;quot; mimeType=&amp;quot;audio/mp4&amp;quot; codecs=&amp;quot;mp4a.40.2&amp;quot; audioSamplingRate=&amp;quot;44100&amp;quot; startWithSAP=&amp;quot;1&amp;quot; bandwidth=&amp;quot;129622&amp;quot;&amp;gt;
    &amp;lt;AudioChannelConfiguration schemeIdUri=&amp;quot;urn:mpeg:dash:23003:3:audio_channel_configuration:2011&amp;quot; value=&amp;quot;2&amp;quot;/&amp;gt;
    &amp;lt;BaseURL&amp;gt;output_track2_dashinit.mp4&amp;lt;/BaseURL&amp;gt;
    &amp;lt;SegmentList timescale=&amp;quot;44100&amp;quot; duration=&amp;quot;441000&amp;quot;&amp;gt;
     &amp;lt;Initialization range=&amp;quot;0-1060&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;1061-163674&amp;quot; indexRange=&amp;quot;1061-1104&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;163675-326023&amp;quot; indexRange=&amp;quot;163675-163718&amp;quot;/&amp;gt;
      &amp;lt;SegmentURL mediaRange=&amp;quot;326024-349091&amp;quot; indexRange=&amp;quot;326024-326067&amp;quot;/&amp;gt;
    &amp;lt;/SegmentList&amp;gt;
   &amp;lt;/Representation&amp;gt;
  &amp;lt;/AdaptationSet&amp;gt;
 &amp;lt;/Period&amp;gt;
&amp;lt;/MPD&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;再生する&#34;&gt;再生する&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Dash-Industry-Forum/dash.js&#34;&gt;dash.js&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
     &amp;lt;script src=&amp;quot;http://cdn.dashjs.org/latest/dash.all.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
     &amp;lt;style&amp;gt;
         video {
             width: 640px;
             height: 360px;
          }
     &amp;lt;/style&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
     &amp;lt;div&amp;gt;
         &amp;lt;video data-dashjs-player autoplay src=&amp;quot;http://localhost:8080/output_dash.mpd&amp;quot; controls&amp;gt;&amp;lt;/video&amp;gt;
     &amp;lt;/div&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ローカルでサーバーを立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var static = require(&#39;node-static&#39;);

var fileServer = new static.Server(&#39;./public&#39;);

require(&#39;http&#39;).createServer(function (request, response) {
    request.addListener(&#39;end&#39;, function () {
        fileServer.serve(request, response);
    }).resume();
}).listen(8080);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.jstage.jst.go.jp/article/itej/67/2/67_109/_pdf&#34;&gt;次世代動画配信技術「MPEG-DASH」技術概要と標準化・関連技術動向&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/tomoyukilabs/items/c4eb7a829baac880797c&#34;&gt;FFmpegでHTML5 readyな動画ファイルを作成 (MP4, WebM) - Qiita&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://yebisupress.dac.co.jp/2015/11/04/profile%EF%BC%9Fatom%EF%BC%9Fmp4%E3%81%AE%E3%82%88%E3%81%8F%E3%82%8F%E3%81%8B%E3%82%89%E3%81%AA%E3%81%84%E3%81%82%E3%82%8C%E3%81%93%E3%82%8C%EF%BC%88atom%E7%B7%A8/&#34;&gt;profile？atom？mp4のよくわからないあれこれ（atom編)&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>剣を振るVRゲームを作った</title>
          <link>https://www.sambaiz.net/article/29/</link>
          <pubDate>Sun, 30 Oct 2016 19:05:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/29/</guid>
          <description>

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/29_game.png&#34; alt=&#34;ゲーム画像&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Tlonh7D5UzY&#34;&gt;プレイ動画&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://vr.google.com/intl/ja_jp/cardboard/&#34;&gt;Cardboard&lt;/a&gt;にAndroidを入れて、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/29_card.jpg&#34; alt=&#34;Cardboard&#34; /&gt;&lt;/p&gt;

&lt;p&gt;iPhoneをくくりつけた傘を動かすと、画面の剣も動くのでこれで敵を倒すゲーム。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/29_sword.jpg&#34; alt=&#34;iPhoneをくくりつけた傘&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;h3 id=&#34;剣-ios&#34;&gt;剣(iOS)&lt;/h3&gt;

&lt;p&gt;剣にくくりつけたiPhoneの傾きの値をUnity(Android)に送信している。
iOSはClassic Bluetoothを自由に使えないので、Androidと通信する場合はBLEを使う。
BLEは通常だと20byteしか一度に送れないので、これを超えないよう注意する必要がある。&lt;/p&gt;

&lt;p&gt;BLEで通信するところは&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/26&#34;&gt;iOS端末をBLEのPeripheralにする&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;で作ったので、端末の傾きを取得して送るだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import UIKit
import CoreMotion

class Motion{

    let peripheral: BLEPeripheral
    let accelHandler:CMDeviceMotionHandler
    let manager = CMMotionManager()

    public init(peripheral :BLEPeripheral, label :UILabel){
        self.peripheral = peripheral

        accelHandler = {
            (data: CMDeviceMotion?, error: Error?) -&amp;gt; Void in
            let str = String(format: &amp;quot;%.1f %.1f %.1f&amp;quot;,
                             arguments: [data!.attitude.pitch * 180 / M_PI,
                                         data!.attitude.roll * 180 / M_PI,
                                         data!.attitude.yaw * 180 / M_PI]
                )
            let res = peripheral.update(str.data(using: String.Encoding.utf8))
            label.text = str + &amp;quot; &amp;quot; + String(res)
        }
    }

    func start(){
        if manager.isDeviceMotionAvailable {
            manager.deviceMotionUpdateInterval = 1 / 12;
            manager.startDeviceMotionUpdates(to: OperationQueue.current!, withHandler: accelHandler)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ゲーム-unity-android&#34;&gt;ゲーム(Unity &amp;amp; Android)&lt;/h3&gt;

&lt;p&gt;オライリーから&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873117577/&#34;&gt;UnityによるVRアプリケーション開発――作りながら学ぶバーチャルリアリティ入門&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;という本が出ていたので買った。Unityの初歩的なところやBlenderとかも説明があるのでおすすめ。
とりあえず&lt;a href=&#34;https://developers.google.com/vr/unity/&#34;&gt;GoogleのSDK&lt;/a&gt;をimportして、
Prefabの&lt;code&gt;GvrViewerMain&lt;/code&gt;を置くと二眼のそれっぽい感じになる。&lt;/p&gt;

&lt;p&gt;スコアとかゲームオーバーの状態と処理。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine;
using UnityEngine.UI;
using System.Collections;

public class Game : MonoBehaviour {

	public static int score = 0;
	public static bool gameOver = false;
	public static bool killed = false;

	public Text gameOverText;
	public Text scoreText;
	public GameObject enemy;

	void Start () {
		gameOverText.enabled = false;
	}

	void Update () {
		scoreText.text = &amp;quot;Score: &amp;quot; + score;
		if (gameOver) gameOverText.enabled = true;
		if (killed) {
			nextLevel ();
			killed = false;
		}
	}

	public void nextLevel(){
		var old = enemy;
		var x = Random.Range (-10, 10);
		enemy = (GameObject) Instantiate (
			enemy, new Vector3(x, 0, Mathf.Sqrt(10 * 10 - x * x)), Quaternion.Euler(0, 0, 0));
		Destroy (old);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;敵の当たり判定。剣に当たったら爆発して次のが出てくる。
体(見えないCapsule Colliderを設定している)に当たるとゲームオーバー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine;
using UnityEngine.UI;
using System.Collections;

public class MonsterHit : MonoBehaviour {

	public GameObject killEffect;

	void OnCollisionEnter(Collision collision) {
		switch (collision.gameObject.name) {
		case &amp;quot;sword&amp;quot;:
			if (!Game.gameOver) {
				Game.score += 1;
				Instantiate (killEffect, transform.position, transform.rotation);
				Game.killed = true;
			}
			break;

		case &amp;quot;Body&amp;quot;:
			Game.gameOver = true;
			break;
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;敵を動かす。スコアが上がるとスピードも上がる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine;
using System.Collections;

public class MonsterMove : MonoBehaviour {

	private float moveRate;

	void Start () {
		moveRate = 0.0f;
	}

	void Update () {
		transform.position = Vector3.Lerp (transform.position, new Vector3 (0, 0, -1.5f), moveRate);
		moveRate += 0.0001f * (Game.score + 1);
		transform.LookAt (new Vector3 (0, 0, -1.5f));
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;センサーの値を受け取って、剣を動かす。ここで使っているネイティブライブラリは前作ったもの。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/27&#34;&gt;UnityでAndroidのBLEを使うネイティブプラグインを作る&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using UnityEngine;
using System.Collections;

public class SwordMotion : MonoBehaviour {

	private AndroidJavaObject ble;
	private Quaternion q;

	void Start () {
		ble = new AndroidJavaObject (&amp;quot;net.sambaiz.unity_ble.BLE&amp;quot;, this.gameObject.name, &amp;quot;received&amp;quot;);
		q = Quaternion.Euler (0, 0, 0);
	}

	void Update () {
		transform.rotation = q;
	}

	void received(string message){
		var motionData = message.Split (&#39; &#39;); // pitch roll yaw
		q = Quaternion.Euler (
				90 - float.Parse (motionData [0]),
				float.Parse (motionData [1]),
				0) ;
	}

	void OnApplicationPause (bool pauseStatus)
	{
		if (ble != null) {
			if (pauseStatus) {
				ble.Call (&amp;quot;onPause&amp;quot;);
			} else {
				ble.Call (&amp;quot;onActive&amp;quot;);
			}
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>gcloudのアカウント切り替えとkubectlのcontext変更</title>
          <link>https://www.sambaiz.net/article/28/</link>
          <pubDate>Tue, 25 Oct 2016 20:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/28/</guid>
          <description>

&lt;p&gt;いつも迷うのでまとめた。&lt;/p&gt;

&lt;h2 id=&#34;gcloudのアカウント一覧と切り替え&#34;&gt;gcloudのアカウント一覧と切り替え&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud auth list
$ gcloud config set account `ACCOUNT`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;configにprojectなども設定している場合はconfig自体を作成して切り替えた方が楽。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud config configurations create &amp;lt;name&amp;gt;
$ gcloud config configurations activate &amp;lt;name&amp;gt;
$ gcloud config list
...
Your active configuration is: [&amp;lt;name&amp;gt;]

$ gcloud config set account &amp;lt;accout&amp;gt;
$ gcloud config set project &amp;lt;project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubectlのcontext変更&#34;&gt;kubectlのcontext変更&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl config current-context
$ kubectl config view # contexts
$ kubectl config use-context minikube
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>UnityでAndroidのBLEを使うネイティブプラグインを作る</title>
          <link>https://www.sambaiz.net/article/27/</link>
          <pubDate>Sun, 23 Oct 2016 20:39:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/27/</guid>
          <description>

&lt;p&gt;UnityからBLEを使うためのネイティブプラグインを作る。&lt;/p&gt;

&lt;h2 id=&#34;android側&#34;&gt;Android側&lt;/h2&gt;

&lt;p&gt;まず、Activityなしのプロジェクトを作って、New ModuleからAndroid Libraryを選択。
これらのパッケージ名がUnityで使うものと被らないようにする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/Applications/Unity/PlaybackEngines/AndroidPlayer/Variations/mono/Release/Classes/classes.jar&lt;/code&gt;
をModuleの方のlibsに置く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import com.unity3d.player.UnityPlayer;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このjarは元々のやつとかぶってしまうので除外(build.gradleに追加)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;android.libraryVariants.all { variant -&amp;gt;
    variant.outputs.each { output -&amp;gt;
        output.packageLibrary.exclude(&#39;libs/classes.jar&#39;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Activiyは&lt;code&gt;UnityPlayer.currentActivity&lt;/code&gt;で取得でき、
Unity側のメソッドを呼ぶのも
&lt;code&gt;UnityPlayer.UnitySendMessage(mGameObjName, mCallBackName, new String(characteristic.getValue()));&lt;/code&gt;
のようにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class BLE {

    private final static String TAG = BLE.class.getSimpleName();
    private static final int REQUEST_ENABLE_BT = 1;
    private static final int MY_PERMISSION_RESPONSE = 2;

    private static final String PERIPHERAL_LOCAL_NAME = &amp;quot;my-ble&amp;quot;;
    private static final UUID PERIPHERAL_SERIVCE_UUID = UUID.fromString(&amp;quot;BF9CB85F-620C-4A67-BDD2-1A64213F74CA&amp;quot;);
    private static final UUID PERIPHERAL_CHARACTERISTIC_UUID = UUID.fromString(&amp;quot;5F83E23F-BCA1-42B3-B6F2-EA82BE46A93D&amp;quot;);
    private static final UUID CLIENT_CHARACTERISTIC_CONFIG = UUID.fromString(&amp;quot;00002902-0000-1000-8000-00805f9b34fb&amp;quot;);

    private String mGameObjName;
    private String mCallBackName;

    private BluetoothAdapter mBluetoothAdapter;
    private BluetoothGatt mBluetoothGatt;
    private BluetoothGattCharacteristic mCharacteristic;
    private Handler mHandler;

    // Stops scanning after 30 seconds.
    private static final long SCAN_PERIOD = 30000;

    public BLE(String gameObjName, String callBackName) {

        this.mGameObjName = gameObjName;
        this.mCallBackName = callBackName;

        mHandler = new Handler();

        if (!UnityPlayer.currentActivity.getPackageManager().hasSystemFeature(PackageManager.FEATURE_BLUETOOTH_LE)) {
            Toast.makeText(UnityPlayer.currentActivity, &amp;quot;BLEをサポートしていません&amp;quot;, Toast.LENGTH_SHORT).show();
            UnityPlayer.currentActivity.finish();
            return;
        }

        final BluetoothManager bluetoothManager =
                (BluetoothManager) UnityPlayer.currentActivity.getSystemService(Context.BLUETOOTH_SERVICE);
        mBluetoothAdapter = bluetoothManager.getAdapter();

        if (mBluetoothAdapter == null) {
            Toast.makeText(UnityPlayer.currentActivity, &amp;quot;Bluetoothをサポートしていません&amp;quot;, Toast.LENGTH_SHORT).show();
            UnityPlayer.currentActivity.finish();
            return;
        }

        onActive();
    }

    public void onActive() {
        Log.d(TAG, &amp;quot;onActive&amp;quot;);
        if (!mBluetoothAdapter.isEnabled()) {
            Intent enableBtIntent = new Intent(BluetoothAdapter.ACTION_REQUEST_ENABLE);
            UnityPlayer.currentActivity.startActivityForResult(enableBtIntent, REQUEST_ENABLE_BT);
        }

        scanLeDevice(true);
    }

    public void onPause() {
        Log.d(TAG, &amp;quot;onPause&amp;quot;);
        scanLeDevice(false);

        if(mCharacteristic != null){
            mBluetoothGatt.setCharacteristicNotification(
                    mCharacteristic,
                    false
            );
        }

        if(mBluetoothGatt != null) {
            mBluetoothGatt.close();
            mBluetoothGatt = null;
        }
    }

    private void scanLeDevice(final boolean enable) {
        if (enable) {
            mHandler.postDelayed(new Runnable() {
                @Override
                public void run() {
                    mBluetoothAdapter.stopLeScan(mLeScanCallback);
                }
            }, SCAN_PERIOD);

            mBluetoothAdapter.startLeScan(mLeScanCallback);
        } else {
            mBluetoothAdapter.stopLeScan(mLeScanCallback);
        }
    }

    private BluetoothAdapter.LeScanCallback mLeScanCallback =
            new BluetoothAdapter.LeScanCallback() {

                @Override
                public void onLeScan(final BluetoothDevice device, int rssi, byte[] scanRecord) {
                    if(PERIPHERAL_LOCAL_NAME.equals(device.getName())){
                        scanLeDevice(false);
                        connect(device);
                    }
                }
            };

    private boolean connect(BluetoothDevice device) {
        if (mBluetoothAdapter == null) {
            Log.w(TAG, &amp;quot;BluetoothAdapter not initialized or unspecified address.&amp;quot;);
            return false;
        }

        // Previously connected device.  Try to reconnect.
        if (mBluetoothGatt != null) {
            Log.d(TAG, &amp;quot;Trying to use an existing mBluetoothGatt for connection.&amp;quot;);
            if (mBluetoothGatt.connect()) {
                return true;
            } else {
                return false;
            }
        }

        mBluetoothGatt = device.connectGatt(UnityPlayer.currentActivity, false, mGattCallback);
        Log.d(TAG, &amp;quot;Trying to create a new connection.&amp;quot;);
        return true;
    }


    private final BluetoothGattCallback mGattCallback = new BluetoothGattCallback() {
        @Override
        public void onConnectionStateChange(BluetoothGatt gatt, int status, int newState) {
            if (newState == BluetoothProfile.STATE_CONNECTED) {

                scanLeDevice(false);
                Log.i(TAG, &amp;quot;Connected to GATT server.&amp;quot;);
                gatt.discoverServices();

            } else if (newState == BluetoothProfile.STATE_DISCONNECTED) {
                Log.i(TAG, &amp;quot;Disconnected from GATT server.&amp;quot;);
            } else{
                Log.i(TAG, &amp;quot;onConnectionStateChange:&amp;quot; + newState);
            }
        }

        @Override
        public void onServicesDiscovered(BluetoothGatt gatt, int status) {
            if (status == BluetoothGatt.GATT_SUCCESS) {
                mCharacteristic = gatt.getService(PERIPHERAL_SERIVCE_UUID).
                        getCharacteristic(PERIPHERAL_CHARACTERISTIC_UUID);

                gatt.setCharacteristicNotification(
                        mCharacteristic,
                        true
                );
                BluetoothGattDescriptor descriptor = mCharacteristic.getDescriptor(CLIENT_CHARACTERISTIC_CONFIG);
                descriptor.setValue(BluetoothGattDescriptor.ENABLE_NOTIFICATION_VALUE);
                mBluetoothGatt.writeDescriptor(descriptor);
            } else {
                Log.w(TAG, &amp;quot;onServicesDiscovered received: &amp;quot; + status);
            }
        }

        @Override
        public void onCharacteristicChanged(BluetoothGatt gatt,
                                            BluetoothGattCharacteristic characteristic) {
            UnityPlayer.UnitySendMessage(mGameObjName, mCallBackName, new String(characteristic.getValue()));
        }
    };

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Manifestに追加した分。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;uses-feature android:name=&amp;quot;android.hardware.bluetooth_le&amp;quot; android:required=&amp;quot;true&amp;quot;/&amp;gt;

&amp;lt;uses-permission android:name=&amp;quot;android.permission.BLUETOOTH&amp;quot; /&amp;gt;
&amp;lt;uses-permission android:name=&amp;quot;android.permission.BLUETOOTH_ADMIN&amp;quot; /&amp;gt;
&amp;lt;uses-permission android:name=&amp;quot;android.permission.ACCESS_COARSE_LOCATION&amp;quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できたらaarを生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./gradlew assembleRelease
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;build/outputs/aar/*-release.aar&lt;/code&gt;をUnityの&lt;code&gt;Assets/Plugins/Android/libs&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;あと、依存aarはこの中に含まれないようなのでそれもまとめてコピーする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;task copyLibs(type: Copy) {
    from configurations.compile
    into &#39;build/outputs/aar&#39;
    exclude { details -&amp;gt; details.file.name.endsWith(&amp;quot;.jar&amp;quot;) }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Manifetstのmergeに失敗したのでSDKVersionを合わせる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;compileSdkVersion 22

defaultConfig {
    minSdkVersion 19
    targetSdkVersion 22
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;unity側&#34;&gt;Unity側&lt;/h2&gt;

&lt;p&gt;こんな感じでインスタンスを作り、
&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/AndroidJavaObject.Call.html&#34;&gt;メソッドを呼べる&lt;/a&gt;。
ただし、unity editor上では&lt;code&gt;Init&#39;d AndroidJavaClass with null ptr!&lt;/code&gt;のエラーが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;plugin = new AndroidJavaObject(&amp;quot;net.sambaiz.unity_ble.BLE&amp;quot;, this.gameObject.name, &amp;quot;received&amp;quot;);

void received(string message){
	Debug.Log (&amp;quot;BLE:&amp;quot; + message);
}

void OnApplicationPause (bool pauseStatus)
{
	if (pauseStatus) {
		plugin.Call (&amp;quot;onPause&amp;quot;);
	} else {
		plugin.Call (&amp;quot;onActive&amp;quot;);
	}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>iOS端末をBLEのPeripheralにする</title>
          <link>https://www.sambaiz.net/article/26/</link>
          <pubDate>Sun, 23 Oct 2016 01:29:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/26/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://developer.apple.com/jp/documentation/CoreBluetoothPG.pdf&#34;&gt;CoreBluetoothプログラミングガイド&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;流れ&#34;&gt;流れ&lt;/h2&gt;

&lt;p&gt;まず、CoreBluetooth.frameworkを追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import CoreBluetooth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CBPeripheralManagerを生成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;peripheralManager = CBPeripheralManager(delegate: self, queue: nil)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stateが変化したらdelegateメソッドが呼ばれるので&lt;code&gt;.poweredOn&lt;/code&gt;であることを確認できれば
Managerの準備は完了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public func peripheralManagerDidUpdateState(_ peripheral: CBPeripheralManager){        
    switch (peripheral.state){
    case .poweredOn:
        print(&amp;quot;PeripheralManager state is ok&amp;quot;)
        ready = true

    default:
        print(&amp;quot;PeripheralManager state is ng:&amp;quot;, peripheral.state)
        ready = false
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Characteristicを作成。&lt;code&gt;CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify)&lt;/code&gt;で、
Centralが読みにくることも、通知を受け取ることもできるようにし、&lt;code&gt;CBAttributePermissions.readable&lt;/code&gt;でreadのみ許可する。
このvalueをnilにしておかないと、キャッシュされあとで変更できなくなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;characteristic = CBMutableCharacteristic(
    type: CHARACTERISTIC_UUID,
    properties: CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify),
    value:nil,
    permissions:CBAttributePermissions.readable)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このCharacteristicのServiceを作成し、Managerに登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let service = CBMutableService(type: SERVICE_UUID, primary: true)
service.characteristics = [characteristic]
peripheralManager!.add(service)
ready = true         
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;public func peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?){
    if(error != nil){
        print(&amp;quot;Add Service error:&amp;quot;, error)
    }else{
        print(&amp;quot;Add Service ok&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ServiceをAdvertiseする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;peripheral.startAdvertising([
    CBAdvertisementDataLocalNameKey: LOCAL_NAME,
    CBAdvertisementDataServiceUUIDsKey: [SERVICE_UUID]
    ])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;public func peripheralManagerDidStartAdvertising(_ peripheral: CBPeripheralManager, error: Error?){
    if(error != nil){
        print(&amp;quot;Start Advertising error:&amp;quot;, error)
    }else{
        print(&amp;quot;Start Advertising ok&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通知要求してきたCentralに向けて通知する。&lt;code&gt;onSubscribedCentrals: nil&lt;/code&gt;で全てのCentralに送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;peripheralManager!.updateValue(d, for: characteristic, onSubscribedCentrals: nil)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;読みにきたときのdelegateメソッド。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public func peripheralManager(_ peripheral: CBPeripheralManager, didReceiveRead request: CBATTRequest){
    if (request.characteristic.uuid.isEqual(self.characteristic.uuid)) {
        if let value = self.characteristic.value{
            if (request.offset &amp;gt; value.count) {
                peripheral.respond(to: request, withResult: CBATTError.invalidOffset)
                print(&amp;quot;Read fail: invalid offset&amp;quot;)
                return;
            }
        }

        request.value = self.characteristic.value?.subdata(
            in: Range(uncheckedBounds: (request.offset, (self.characteristic.value?.count)! - request.offset))
        )
        peripheral.respond(to: request, withResult: CBATTError.success)
        print(&amp;quot;Read success&amp;quot;)
    }else{
        print(&amp;quot;Read fail: wrong characteristic uuid:&amp;quot;, request.characteristic.uuid)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;全体&#34;&gt;全体&lt;/h2&gt;

&lt;p&gt;エラーハンドリングは適当だけど、とりあえず動くものができた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import CoreBluetooth

class BLEPeripheral : NSObject, CBPeripheralManagerDelegate {

    let CHARACTERISTIC_UUID = CBUUID(string:&amp;quot;5F83E23F-BCA1-42B3-B6F2-EA82BE46A93D&amp;quot;)
    let SERVICE_UUID = CBUUID(string:&amp;quot;BF9CB85F-620C-4A67-BDD2-1A64213F74CA&amp;quot;)
    let LOCAL_NAME = &amp;quot;my-ble&amp;quot;

    private var peripheralManager : CBPeripheralManager?
    private var characteristic: CBMutableCharacteristic
    private var ready = false

    public override init(){
        characteristic = CBMutableCharacteristic(
            type: CHARACTERISTIC_UUID,
            properties: CBCharacteristicProperties.read.union(CBCharacteristicProperties.notify),
            value:nil,
            permissions:CBAttributePermissions.readable)

        super.init()

        peripheralManager = CBPeripheralManager(delegate: self, queue: nil)
    }

    public func update(_ data: Data?) -&amp;gt; Bool {
        if(ready){
            if let d = data{
                characteristic.value = d
                return peripheralManager!.updateValue(d, for: characteristic, onSubscribedCentrals: nil)
            }else{
                print(&amp;quot;data is null&amp;quot;)
            }
        }else{
            print(&amp;quot;not ready&amp;quot;)
        }
        return false
    }



    /*
     CBPeripheralManagerDelegate
    */

    public func peripheralManagerDidUpdateState(_ peripheral: CBPeripheralManager){        
        switch (peripheral.state){
        case .poweredOn:
            print(&amp;quot;PeripheralManager state is ok&amp;quot;)

            let service = CBMutableService(type: SERVICE_UUID, primary: true)
            service.characteristics = [characteristic]
            peripheralManager!.add(service)
            ready = true

        default:
            print(&amp;quot;PeripheralManager state is ng:&amp;quot;, peripheral.state)
            ready = false
        }
    }

    public func peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?){
        if(error != nil){
            print(&amp;quot;Add Service error:&amp;quot;, error)
        }else{
            print(&amp;quot;Add Service ok&amp;quot;)
            peripheral.startAdvertising([
                CBAdvertisementDataLocalNameKey: LOCAL_NAME,
                CBAdvertisementDataServiceUUIDsKey: [SERVICE_UUID]
                ])
        }
    }

    public func peripheralManagerDidStartAdvertising(_ peripheral: CBPeripheralManager, error: Error?){
        if(error != nil){
            print(&amp;quot;Start Advertising error:&amp;quot;, error)
        }else{
            print(&amp;quot;Start Advertising ok&amp;quot;)
        }
    }

    public func peripheralManager(_ peripheral: CBPeripheralManager, didReceiveRead request: CBATTRequest){
        var value: Data?
        switch request.characteristic.uuid {
        case characteristic.uuid:
            value = characteristic.value

        default: break
        }

        if let v = value{
            if (request.offset &amp;gt; v.count) {
                peripheral.respond(to: request, withResult: CBATTError.invalidOffset)
                print(&amp;quot;Read fail: invalid offset&amp;quot;)
                return;
            }

            request.value = v.subdata(
                in: Range(uncheckedBounds: (request.offset, v.count - request.offset))
            )
            peripheral.respond(to: request, withResult: CBATTError.success)
            print(&amp;quot;Read success&amp;quot;)
        }else{
            print(&amp;quot;Read fail: wrong characteristic uuid:&amp;quot;, request.characteristic.uuid)
        }
    }

    public func peripheralManager(_ peripheral: CBPeripheralManager, central: CBCentral, didSubscribeTo characteristic: CBCharacteristic){
        print(&amp;quot;Subscribe to&amp;quot;, characteristic.uuid)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;現在の時間を1秒ごとに更新して通知がくることを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;timer = Timer.scheduledTimer(timeInterval: 1.0, target: self, selector: #selector(self.update), userInfo: nil, repeats: true)
timer!.fire()

public func update(){
    let now = String(format: &amp;quot;%.0f&amp;quot;, arguments: [Date().timeIntervalSince1970])
    peripheral.update(now.data(using: String.Encoding.utf8))
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>android-BluetoothLeGattを読む</title>
          <link>https://www.sambaiz.net/article/25/</link>
          <pubDate>Fri, 21 Oct 2016 14:10:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/25/</guid>
          <description>

&lt;p&gt;BLEのサンプルコード。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/googlesamples/android-BluetoothLeGatt&#34;&gt;https://github.com/googlesamples/android-BluetoothLeGatt&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;devicescanactivity&#34;&gt;DeviceScanActivity&lt;/h2&gt;

&lt;p&gt;BLEをサポートしているかチェックする。
&lt;a href=&#34;https://www.sambaiz.net/article/23&#34;&gt;BluetoothChat&lt;/a&gt;ではBluetoothAdapterを取得するのに
&lt;code&gt;BluetoothAdapter.getDefaultAdapter()&lt;/code&gt;のようにしていたが、
BLEをサポートしているような新しいバージョンでは、BluetoothManagerの&lt;code&gt;getAdapter()&lt;/code&gt;を使うらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    getActionBar().setTitle(R.string.title_devices);
    mHandler = new Handler();

    // Use this check to determine whether BLE is supported on the device.  Then you can
    // selectively disable BLE-related features.
    if (!getPackageManager().hasSystemFeature(PackageManager.FEATURE_BLUETOOTH_LE)) {
        Toast.makeText(this, R.string.ble_not_supported, Toast.LENGTH_SHORT).show();
        finish();
    }

    // Initializes a Bluetooth adapter.  For API level 18 and above, get a reference to
    // BluetoothAdapter through BluetoothManager.
    final BluetoothManager bluetoothManager =
            (BluetoothManager) getSystemService(Context.BLUETOOTH_SERVICE);
    mBluetoothAdapter = bluetoothManager.getAdapter();

    // Checks if Bluetooth is supported on the device.
    if (mBluetoothAdapter == null) {
        Toast.makeText(this, R.string.error_bluetooth_not_supported, Toast.LENGTH_SHORT).show();
        finish();
        return;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BluetoothChatと同様にBluetoothを有効にさせるのと、scanの開始。
&lt;code&gt;mBluetoothAdapter.startLeScan(mLeScanCallback)&lt;/code&gt;で
見つかったらcallbackの&lt;code&gt;onLeScan&lt;/code&gt;が呼ばれるのでデバイスリストに追加していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onResume() {
    super.onResume();

    // Ensures Bluetooth is enabled on the device.  If Bluetooth is not currently enabled,
    // fire an intent to display a dialog asking the user to grant permission to enable it.
    if (!mBluetoothAdapter.isEnabled()) {
        if (!mBluetoothAdapter.isEnabled()) {
            Intent enableBtIntent = new Intent(BluetoothAdapter.ACTION_REQUEST_ENABLE);
            startActivityForResult(enableBtIntent, REQUEST_ENABLE_BT);
        }
    }

    // Initializes list view adapter.
    mLeDeviceListAdapter = new LeDeviceListAdapter();
    setListAdapter(mLeDeviceListAdapter);
    scanLeDevice(true);
}

private void scanLeDevice(final boolean enable) {
    if (enable) {
        // Stops scanning after a pre-defined scan period.
        mHandler.postDelayed(new Runnable() {
            @Override
            public void run() {
                mScanning = false;
                mBluetoothAdapter.stopLeScan(mLeScanCallback);
                invalidateOptionsMenu();
            }
        }, SCAN_PERIOD);

        mScanning = true;
        mBluetoothAdapter.startLeScan(mLeScanCallback);
    } else {
        mScanning = false;
        mBluetoothAdapter.stopLeScan(mLeScanCallback);
    }
    invalidateOptionsMenu();
}

private BluetoothAdapter.LeScanCallback mLeScanCallback =
            new BluetoothAdapter.LeScanCallback() {
    @Override
    public void onLeScan(final BluetoothDevice device, int rssi, byte[] scanRecord) {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mLeDeviceListAdapter.addDevice(device);
                mLeDeviceListAdapter.notifyDataSetChanged();
            }
        });
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pause時はscanを止め、Listをクリアする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onPause() {
    super.onPause();
    scanLeDevice(false);
    mLeDeviceListAdapter.clear();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リストが選択されたら、scanを止め、そのデバイスの情報を渡してDeviceControlActivityを始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onListItemClick(ListView l, View v, int position, long id) {
    final BluetoothDevice device = mLeDeviceListAdapter.getDevice(position);
    if (device == null) return;
    final Intent intent = new Intent(this, DeviceControlActivity.class);
    intent.putExtra(DeviceControlActivity.EXTRAS_DEVICE_NAME, device.getName());
    intent.putExtra(DeviceControlActivity.EXTRAS_DEVICE_ADDRESS, device.getAddress());
    if (mScanning) {
        mBluetoothAdapter.stopLeScan(mLeScanCallback);
        mScanning = false;
    }
    startActivity(intent);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;devicecontrolactivity&#34;&gt;DeviceControlActivity&lt;/h2&gt;

&lt;p&gt;bindServiceでBluetoothLeServiceにServiceConnectionをバインドする。
Serviceと接続したらServiceConnectionの&lt;code&gt;onServiceConnected&lt;/code&gt;が呼ばれるので、
LocalBinderの&lt;code&gt;getService&lt;/code&gt;で取得し、初期化して対象のデバイスにconnectする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.android.com/guide/components/services.html?hl=ja&#34;&gt;Service&lt;/a&gt;は、
開始したコンポーネントや、ユーザーの操作に関係なく、バックグラウンドで動く。
サーバー/クライアントでいうサーバーで、複数のクライアントが同時にバインドでき、
その場合バインドしているクライアントが存在しなくなったら破棄される。
ホストプロセスのメインスレッドで実行される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.gatt_services_characteristics);

    final Intent intent = getIntent();
    mDeviceName = intent.getStringExtra(EXTRAS_DEVICE_NAME);
    mDeviceAddress = intent.getStringExtra(EXTRAS_DEVICE_ADDRESS);

    // Sets up UI references.
    ((TextView) findViewById(R.id.device_address)).setText(mDeviceAddress);
    mGattServicesList = (ExpandableListView) findViewById(R.id.gatt_services_list);
    mGattServicesList.setOnChildClickListener(servicesListClickListner);
    mConnectionState = (TextView) findViewById(R.id.connection_state);
    mDataField = (TextView) findViewById(R.id.data_value);

    getActionBar().setTitle(mDeviceName);
    getActionBar().setDisplayHomeAsUpEnabled(true);
    Intent gattServiceIntent = new Intent(this, BluetoothLeService.class);
    bindService(gattServiceIntent, mServiceConnection, BIND_AUTO_CREATE);
}

private final ServiceConnection mServiceConnection = new ServiceConnection() {

    @Override
    public void onServiceConnected(ComponentName componentName, IBinder service) {
        mBluetoothLeService = ((BluetoothLeService.LocalBinder) service).getService();
        if (!mBluetoothLeService.initialize()) {
            Log.e(TAG, &amp;quot;Unable to initialize Bluetooth&amp;quot;);
            finish();
        }
        // Automatically connects to the device upon successful start-up initialization.
        mBluetoothLeService.connect(mDeviceAddress);
    }

    @Override
    public void onServiceDisconnected(ComponentName componentName) {
        mBluetoothLeService = null;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BroadcastReceiverを登録して、対象デバイスに繋ぎに行く。
GATTのService(AndroidのServiceとは違うもの)やCharacteristicが見つかったら表示する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.bluetooth.com/specifications/gatt&#34;&gt;GATT(Generic Attribute Profile)&lt;/a&gt;
というのは、BLEで通信するときに使う階層化されたデータ構造の定義。
ProfileにはいくつかのServiceが含まれ、ServiceにはいくつかのCharacteristic、または他のServiceが含まれる。
Characteristicというのが値。ServiceやCharacteristicはUUIDで識別することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onResume() {
    super.onResume();
    registerReceiver(mGattUpdateReceiver, makeGattUpdateIntentFilter());
    if (mBluetoothLeService != null) {
        final boolean result = mBluetoothLeService.connect(mDeviceAddress);
        Log.d(TAG, &amp;quot;Connect request result=&amp;quot; + result);
    }
}

private final BroadcastReceiver mGattUpdateReceiver = new BroadcastReceiver() {
    @Override
    public void onReceive(Context context, Intent intent) {
        final String action = intent.getAction();
        if (BluetoothLeService.ACTION_GATT_CONNECTED.equals(action)) {
            mConnected = true;
            updateConnectionState(R.string.connected);
            invalidateOptionsMenu();
        } else if (BluetoothLeService.ACTION_GATT_DISCONNECTED.equals(action)) {
            mConnected = false;
            updateConnectionState(R.string.disconnected);
            invalidateOptionsMenu();
            clearUI();
        } else if (BluetoothLeService.ACTION_GATT_SERVICES_DISCOVERED.equals(action)) {
            // Show all the supported services and characteristics on the user interface.
            displayGattServices(mBluetoothLeService.getSupportedGattServices());
        } else if (BluetoothLeService.ACTION_DATA_AVAILABLE.equals(action)) {
            displayData(intent.getStringExtra(BluetoothLeService.EXTRA_DATA));
        }
    }
};

private static IntentFilter makeGattUpdateIntentFilter() {
    final IntentFilter intentFilter = new IntentFilter();
    intentFilter.addAction(BluetoothLeService.ACTION_GATT_CONNECTED);
    intentFilter.addAction(BluetoothLeService.ACTION_GATT_DISCONNECTED);
    intentFilter.addAction(BluetoothLeService.ACTION_GATT_SERVICES_DISCOVERED);
    intentFilter.addAction(BluetoothLeService.ACTION_DATA_AVAILABLE);
    return intentFilter;
}

private void displayGattServices(List&amp;lt;BluetoothGattService&amp;gt; gattServices) {
    if (gattServices == null) return;
    String uuid = null;
    String unknownServiceString = getResources().getString(R.string.unknown_service);
    String unknownCharaString = getResources().getString(R.string.unknown_characteristic);
    ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt; gattServiceData = new ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt;();
    ArrayList&amp;lt;ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt;&amp;gt; gattCharacteristicData
            = new ArrayList&amp;lt;ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt;&amp;gt;();
    mGattCharacteristics = new ArrayList&amp;lt;ArrayList&amp;lt;BluetoothGattCharacteristic&amp;gt;&amp;gt;();

    // Loops through available GATT Services.
    for (BluetoothGattService gattService : gattServices) {
        HashMap&amp;lt;String, String&amp;gt; currentServiceData = new HashMap&amp;lt;String, String&amp;gt;();
        uuid = gattService.getUuid().toString();
        currentServiceData.put(
                LIST_NAME, SampleGattAttributes.lookup(uuid, unknownServiceString));
        currentServiceData.put(LIST_UUID, uuid);
        gattServiceData.add(currentServiceData);

        ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt; gattCharacteristicGroupData =
                new ArrayList&amp;lt;HashMap&amp;lt;String, String&amp;gt;&amp;gt;();
        List&amp;lt;BluetoothGattCharacteristic&amp;gt; gattCharacteristics =
                gattService.getCharacteristics();
        ArrayList&amp;lt;BluetoothGattCharacteristic&amp;gt; charas =
                new ArrayList&amp;lt;BluetoothGattCharacteristic&amp;gt;();

        // Loops through available Characteristics.
        for (BluetoothGattCharacteristic gattCharacteristic : gattCharacteristics) {
            charas.add(gattCharacteristic);
            HashMap&amp;lt;String, String&amp;gt; currentCharaData = new HashMap&amp;lt;String, String&amp;gt;();
            uuid = gattCharacteristic.getUuid().toString();
            currentCharaData.put(
                    LIST_NAME, SampleGattAttributes.lookup(uuid, unknownCharaString));
            currentCharaData.put(LIST_UUID, uuid);
            gattCharacteristicGroupData.add(currentCharaData);
        }
        mGattCharacteristics.add(charas);
        gattCharacteristicData.add(gattCharacteristicGroupData);
    }

    SimpleExpandableListAdapter gattServiceAdapter = new SimpleExpandableListAdapter(
            this,
            gattServiceData,
            android.R.layout.simple_expandable_list_item_2,
            new String[] {LIST_NAME, LIST_UUID},
            new int[] { android.R.id.text1, android.R.id.text2 },
            gattCharacteristicData,
            android.R.layout.simple_expandable_list_item_2,
            new String[] {LIST_NAME, LIST_UUID},
            new int[] { android.R.id.text1, android.R.id.text2 }
    );
    mGattServicesList.setAdapter(gattServiceAdapter);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;BluetoothGattCharacteristic.PROPERTY_READ&lt;/code&gt;と
&lt;code&gt;BluetoothGattCharacteristic.PROPERTY_NOTIFY&lt;/code&gt;は
それぞれCharacteristicが読めることと、値が変化したときにPeripheralから通知が受けられることを表している。&lt;/p&gt;

&lt;p&gt;PeripheralというのはiBeaconのように、Advertising(見つかるようにする)し、接続される方。
それに対して接続する方をCentralという。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private final ExpandableListView.OnChildClickListener servicesListClickListner =
  new ExpandableListView.OnChildClickListener() {
      @Override
      public boolean onChildClick(ExpandableListView parent, View v, int groupPosition,
                                  int childPosition, long id) {
          if (mGattCharacteristics != null) {
              final BluetoothGattCharacteristic characteristic =
                      mGattCharacteristics.get(groupPosition).get(childPosition);
              final int charaProp = characteristic.getProperties();
              if ((charaProp | BluetoothGattCharacteristic.PROPERTY_READ) &amp;gt; 0) {
                  // If there is an active notification on a characteristic, clear
                  // it first so it doesn&#39;t update the data field on the user interface.
                  if (mNotifyCharacteristic != null) {
                      mBluetoothLeService.setCharacteristicNotification(
                              mNotifyCharacteristic, false);
                      mNotifyCharacteristic = null;
                  }
                  mBluetoothLeService.readCharacteristic(characteristic);
              }
              if ((charaProp | BluetoothGattCharacteristic.PROPERTY_NOTIFY) &amp;gt; 0) {
                  mNotifyCharacteristic = characteristic;
                  mBluetoothLeService.setCharacteristicNotification(
                          characteristic, true);
              }
              return true;
          }
          return false;
      }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BroadcastReceiverを外すのと、サービスのバインドをやめる処理。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onPause() {
    super.onPause();
    unregisterReceiver(mGattUpdateReceiver);
}

@Override
protected void onDestroy() {
    super.onDestroy();
    unbindService(mServiceConnection);
    mBluetoothLeService = null;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bluetoothleservice&#34;&gt;BluetoothLeService&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.android.com/reference/android/os/Binder.html&#34;&gt;Binder&lt;/a&gt;というのは
プロセス間通信(IPC; Inter-Process Communication)するためのもの。&lt;/p&gt;

&lt;p&gt;全てのクライアントのバインドが外れると&lt;code&gt;onUnbind&lt;/code&gt;が呼ばれるので、close処理をする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class LocalBinder extends Binder {
    BluetoothLeService getService() {
        return BluetoothLeService.this;
    }
}

@Override
public IBinder onBind(Intent intent) {
    return mBinder;
}

@Override
public boolean onUnbind(Intent intent) {
    // After using a given device, you should make sure that BluetoothGatt.close() is called
    // such that resources are cleaned up properly.  In this particular example, close() is
    // invoked when the UI is disconnected from the Service.
    close();
    return super.onUnbind(intent);
}

private final IBinder mBinder = new LocalBinder();

public void close() {
    if (mBluetoothGatt == null) {
        return;
    }
    mBluetoothGatt.close();
    mBluetoothGatt = null;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初期化処理。BluetoothAdapterを取得する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public boolean initialize() {
    // For API level 18 and above, get a reference to BluetoothAdapter through
    // BluetoothManager.
    if (mBluetoothManager == null) {
        mBluetoothManager = (BluetoothManager) getSystemService(Context.BLUETOOTH_SERVICE);
        if (mBluetoothManager == null) {
            Log.e(TAG, &amp;quot;Unable to initialize BluetoothManager.&amp;quot;);
            return false;
        }
    }

    mBluetoothAdapter = mBluetoothManager.getAdapter();
    if (mBluetoothAdapter == null) {
        Log.e(TAG, &amp;quot;Unable to obtain a BluetoothAdapter.&amp;quot;);
        return false;
    }

    return true;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;既に接続したことがあれば、そのBluetoothGattで再接続し、そうでなければ&lt;code&gt;connectGatt&lt;/code&gt;する。
callbackでは必要に応じてIntentをブロードキャストする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public boolean connect(final String address) {
    if (mBluetoothAdapter == null || address == null) {
        Log.w(TAG, &amp;quot;BluetoothAdapter not initialized or unspecified address.&amp;quot;);
        return false;
    }

    // Previously connected device.  Try to reconnect.
    if (mBluetoothDeviceAddress != null &amp;amp;&amp;amp; address.equals(mBluetoothDeviceAddress)
            &amp;amp;&amp;amp; mBluetoothGatt != null) {
        Log.d(TAG, &amp;quot;Trying to use an existing mBluetoothGatt for connection.&amp;quot;);
        if (mBluetoothGatt.connect()) {
            mConnectionState = STATE_CONNECTING;
            return true;
        } else {
            return false;
        }
    }

    final BluetoothDevice device = mBluetoothAdapter.getRemoteDevice(address);
    if (device == null) {
        Log.w(TAG, &amp;quot;Device not found.  Unable to connect.&amp;quot;);
        return false;
    }
    // We want to directly connect to the device, so we are setting the autoConnect
    // parameter to false.
    mBluetoothGatt = device.connectGatt(this, false, mGattCallback);
    Log.d(TAG, &amp;quot;Trying to create a new connection.&amp;quot;);
    mBluetoothDeviceAddress = address;
    mConnectionState = STATE_CONNECTING;
    return true;
}

private final BluetoothGattCallback mGattCallback = new BluetoothGattCallback() {
    @Override
    public void onConnectionStateChange(BluetoothGatt gatt, int status, int newState) {
        String intentAction;
        if (newState == BluetoothProfile.STATE_CONNECTED) {
            intentAction = ACTION_GATT_CONNECTED;
            mConnectionState = STATE_CONNECTED;
            broadcastUpdate(intentAction);
            Log.i(TAG, &amp;quot;Connected to GATT server.&amp;quot;);
            // Attempts to discover services after successful connection.
            Log.i(TAG, &amp;quot;Attempting to start service discovery:&amp;quot; +
                    mBluetoothGatt.discoverServices());

        } else if (newState == BluetoothProfile.STATE_DISCONNECTED) {
            intentAction = ACTION_GATT_DISCONNECTED;
            mConnectionState = STATE_DISCONNECTED;
            Log.i(TAG, &amp;quot;Disconnected from GATT server.&amp;quot;);
            broadcastUpdate(intentAction);
        }
    }

    @Override
    public void onServicesDiscovered(BluetoothGatt gatt, int status) {
        if (status == BluetoothGatt.GATT_SUCCESS) {
            broadcastUpdate(ACTION_GATT_SERVICES_DISCOVERED);
        } else {
            Log.w(TAG, &amp;quot;onServicesDiscovered received: &amp;quot; + status);
        }
    }

    @Override
    public void onCharacteristicRead(BluetoothGatt gatt,
                                     BluetoothGattCharacteristic characteristic,
                                     int status) {
        if (status == BluetoothGatt.GATT_SUCCESS) {
            broadcastUpdate(ACTION_DATA_AVAILABLE, characteristic);
        }
    }

    @Override
    public void onCharacteristicChanged(BluetoothGatt gatt,
                                        BluetoothGattCharacteristic characteristic) {
        broadcastUpdate(ACTION_DATA_AVAILABLE, characteristic);
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;private void broadcastUpdate(final String action) {
    final Intent intent = new Intent(action);
    sendBroadcast(intent);
}

private void broadcastUpdate(final String action,
                             final BluetoothGattCharacteristic characteristic) {
    final Intent intent = new Intent(action);

    // This is special handling for the Heart Rate Measurement profile.  Data parsing is
    // carried out as per profile specifications:
    // http://developer.bluetooth.org/gatt/characteristics/Pages/CharacteristicViewer.aspx?u=org.bluetooth.characteristic.heart_rate_measurement.xml
    if (UUID_HEART_RATE_MEASUREMENT.equals(characteristic.getUuid())) {
        int flag = characteristic.getProperties();
        int format = -1;
        if ((flag &amp;amp; 0x01) != 0) {
            format = BluetoothGattCharacteristic.FORMAT_UINT16;
            Log.d(TAG, &amp;quot;Heart rate format UINT16.&amp;quot;);
        } else {
            format = BluetoothGattCharacteristic.FORMAT_UINT8;
            Log.d(TAG, &amp;quot;Heart rate format UINT8.&amp;quot;);
        }
        final int heartRate = characteristic.getIntValue(format, 1);
        Log.d(TAG, String.format(&amp;quot;Received heart rate: %d&amp;quot;, heartRate));
        intent.putExtra(EXTRA_DATA, String.valueOf(heartRate));
    } else {
        // For all other profiles, writes the data formatted in HEX.
        final byte[] data = characteristic.getValue();
        if (data != null &amp;amp;&amp;amp; data.length &amp;gt; 0) {
            final StringBuilder stringBuilder = new StringBuilder(data.length);
            for(byte byteChar : data)
                stringBuilder.append(String.format(&amp;quot;%02X &amp;quot;, byteChar));
            intent.putExtra(EXTRA_DATA, new String(data) + &amp;quot;\n&amp;quot; + stringBuilder.toString());
        }
    }
    sendBroadcast(intent);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;切断する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void disconnect() {
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(TAG, &amp;quot;BluetoothAdapter not initialized&amp;quot;);
        return;
    }
    mBluetoothGatt.disconnect();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Characteristicを読む。結果は&lt;code&gt;BluetoothGattCallback#onCharacteristicRead&lt;/code&gt;で受け取る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void readCharacteristic(BluetoothGattCharacteristic characteristic) {
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(TAG, &amp;quot;BluetoothAdapter not initialized&amp;quot;);
        return;
    }
    mBluetoothGatt.readCharacteristic(characteristic);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Characteristicの通知を設定。
Descriptorというのは、Characteristicの値を説明するもので、通知を受け取れるようにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void setCharacteristicNotification(BluetoothGattCharacteristic characteristic,
                                          boolean enabled) {
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(TAG, &amp;quot;BluetoothAdapter not initialized&amp;quot;);
        return;
    }
    mBluetoothGatt.setCharacteristicNotification(characteristic, enabled);

    // This is specific to Heart Rate Measurement.
    if (UUID_HEART_RATE_MEASUREMENT.equals(characteristic.getUuid())) {
        BluetoothGattDescriptor descriptor = characteristic.getDescriptor(
                UUID.fromString(SampleGattAttributes.CLIENT_CHARACTERISTIC_CONFIG));
        descriptor.setValue(BluetoothGattDescriptor.ENABLE_NOTIFICATION_VALUE);
        mBluetoothGatt.writeDescriptor(descriptor);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GATTのサービスのリストを返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public List&amp;lt;BluetoothGattService&amp;gt; getSupportedGattServices() {
    if (mBluetoothGatt == null) return null;

    return mBluetoothGatt.getServices();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;android-6-0以降の端末で動かす&#34;&gt;Android 6.0以降の端末で動かす&lt;/h2&gt;

&lt;p&gt;Android6.0以降ではscanに位置情報のパーミッションが必要になったため、手を入れる必要がある。
&lt;a href=&#34;https://github.com/googlesamples/android-BluetoothLeGatt/pull/20&#34;&gt;プルリク&lt;/a&gt;は出てるのでそのうち入るかも。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;uses-permission android:name=&amp;quot;android.permission.ACCESS_COARSE_LOCATION&amp;quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SDK Versionが23以上だったら、さらにリクエストする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if (ContextCompat.checkSelfPermission(this, Manifest.permission.ACCESS_COARSE_LOCATION)
        != PackageManager.PERMISSION_GRANTED) {
    Log.w(&amp;quot;BleActivity&amp;quot;, &amp;quot;Location access not granted!&amp;quot;);
    ActivityCompat.requestPermissions(this,
            new String[]{Manifest.permission.ACCESS_COARSE_LOCATION},
            MY_PERMISSION_RESPONSE);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PackerでAMIを作る</title>
          <link>https://www.sambaiz.net/article/24/</link>
          <pubDate>Tue, 18 Oct 2016 22:37:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/24/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.packer.io/&#34;&gt;https://www.packer.io/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;いろんなプラットフォームのイメージを作ることができるツール。
これでfluentdのログサーバーのAMIを作る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install packer # mac
$ packer -v
0.10.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定ファイルはこんな感じ。&lt;code&gt;variables&lt;/code&gt;の値は&lt;code&gt;{{user ... }}&lt;/code&gt;のところで使われる。
&lt;code&gt;builders&lt;/code&gt;に作るイメージの情報を書いて、&lt;code&gt;provisioners&lt;/code&gt;で環境を作る。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;provisioners&lt;/code&gt;にはchefやansibleなども指定できるが、
継ぎ足し継ぎ足しで秘伝のタレ化したAMIも最初は、&lt;/p&gt;

&lt;p&gt;「コマンドいくつか実行するだけなのでとりあえず手作業で作った、後でなんとかする」&lt;/p&gt;

&lt;p&gt;なんてものもあったりして、
そういうものは無理にchefなどで始めず、手軽にshellでpacker buildするといいと思う。
手作業よりも楽だし、ソースが別にあるので使われていないAMIを消すのも簡単だ。&lt;/p&gt;

&lt;p&gt;fileではpermissionがないところに置くことができないので、一旦置いてshellで移動する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;aws_access_key&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;aws_secret_key&amp;quot;: &amp;quot;&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;,
    &amp;quot;access_key&amp;quot;: &amp;quot;{{user `aws_access_key`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `aws_secret_key`}}&amp;quot;,
    &amp;quot;region&amp;quot;: &amp;quot;ap-northeast-1&amp;quot;,
    &amp;quot;source_ami&amp;quot;: &amp;quot;ami-1a15c77b&amp;quot;,
    &amp;quot;instance_type&amp;quot;: &amp;quot;t2.small&amp;quot;,
    &amp;quot;ssh_username&amp;quot;: &amp;quot;ec2-user&amp;quot;,
    &amp;quot;ami_name&amp;quot;: &amp;quot;fluentd-logserver {{timestamp}}&amp;quot;
  }],
  &amp;quot;provisioners&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
    &amp;quot;source&amp;quot;: &amp;quot;td-agent.conf&amp;quot;,
    &amp;quot;destination&amp;quot;: &amp;quot;/home/ec2-user/td-agent.conf&amp;quot;
  },
  {
    &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
    &amp;quot;inline&amp;quot;: [
      &amp;quot;curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh&amp;quot;,
      &amp;quot;sudo mv /home/ec2-user/td-agent.conf /etc/td-agent/td-agent.conf&amp;quot;,
      &amp;quot;sudo /etc/init.d/td-agent restart&amp;quot;
    ]
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ packer validate fluentd-logserver.json
Template validated successfully.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;buildのとき&lt;code&gt;-var&lt;/code&gt;でvariablesを渡すことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ packer build \
    -var &#39;aws_access_key=YOUR ACCESS KEY&#39; \
    -var &#39;aws_secret_key=YOUR SECRET KEY&#39; \
    fluentd-logserver.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行すると実際にインスタンスを立ち上げ、AMIを作成し始める。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>android-bluetoothChatを読む</title>
          <link>https://www.sambaiz.net/article/23/</link>
          <pubDate>Sat, 15 Oct 2016 14:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/23/</guid>
          <description>

&lt;p&gt;Classic Bluetoothのサンプルコード。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/googlesamples/android-BluetoothChat&#34;&gt;https://github.com/googlesamples/android-BluetoothChat&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;mainactivity&#34;&gt;MainActivity&lt;/h2&gt;

&lt;p&gt;まず、MainActivity。&lt;/p&gt;

&lt;p&gt;Fragmentのcommitや、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    if (savedInstanceState == null) {
        FragmentTransaction transaction = getSupportFragmentManager().beginTransaction();
        BluetoothChatFragment fragment = new BluetoothChatFragment();
        transaction.replace(R.id.sample_content_fragment, fragment);
        transaction.commit();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;オプションメニューの設定をしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 最初だけ呼ばれる
@Override
public boolean onCreateOptionsMenu(Menu menu) {
    getMenuInflater().inflate(R.menu.main, menu);
    return true;
}

// 表示される度に呼ばれる
@Override
public boolean onPrepareOptionsMenu(Menu menu) {
    MenuItem logToggle = menu.findItem(R.id.menu_toggle_log);
    logToggle.setVisible(findViewById(R.id.sample_output) instanceof ViewAnimator);
    logToggle.setTitle(mLogShown ? R.string.sample_hide_log : R.string.sample_show_log);

    return super.onPrepareOptionsMenu(menu);
}

@Override
public boolean onOptionsItemSelected(MenuItem item) {
    switch(item.getItemId()) {
        case R.id.menu_toggle_log:
            mLogShown = !mLogShown;
            ViewAnimator output = (ViewAnimator) findViewById(R.id.sample_output);
            if (mLogShown) {
                output.setDisplayedChild(1);
            } else {
                output.setDisplayedChild(0);
            }　
            // メニューを再作成する(onCreateOptionsMenu, onPrepareOptionsMenuが呼ばれる)
            supportInvalidateOptionsMenu();
            return true;
    }
    return super.onOptionsItemSelected(item);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bluetoothchatfragment&#34;&gt;BluetoothChatFragment&lt;/h2&gt;

&lt;p&gt;onCreateではBluetoothAdapterを取得して、Bluetoothが使えるかどうかを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setHasOptionsMenu(true);
    // Get local Bluetooth adapter
    mBluetoothAdapter = BluetoothAdapter.getDefaultAdapter();

    // If the adapter is null, then Bluetooth is not supported
    if (mBluetoothAdapter == null) {
        FragmentActivity activity = getActivity();
        Toast.makeText(activity, &amp;quot;Bluetooth is not available&amp;quot;, Toast.LENGTH_LONG).show();
        activity.finish();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;onStartではもしBluetoothが有効でなければ有効にするよう要求し、有効になったらsetupする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onStart() {
    super.onStart();
    // If BT is not on, request that it be enabled.
    // setupChat() will then be called during onActivityResult
    if (!mBluetoothAdapter.isEnabled()) {
        Intent enableIntent = new Intent(BluetoothAdapter.ACTION_REQUEST_ENABLE);
        startActivityForResult(enableIntent, REQUEST_ENABLE_BT);
        // Otherwise, setup the chat session
    } else if (mChatService == null) {
        setupChat();
    }
}

public void onActivityResult(int requestCode, int resultCode, Intent data) {
    switch (requestCode) {
        case REQUEST_CONNECT_DEVICE_SECURE:
            // When DeviceListActivity returns with a device to connect
            if (resultCode == Activity.RESULT_OK) {
                connectDevice(data, true);
            }
            break;
        case REQUEST_CONNECT_DEVICE_INSECURE:
            // When DeviceListActivity returns with a device to connect
            if (resultCode == Activity.RESULT_OK) {
                connectDevice(data, false);
            }
            break;
        case REQUEST_ENABLE_BT:
            // When the request to enable Bluetooth returns
            if (resultCode == Activity.RESULT_OK) {
                // Bluetooth is now enabled, so set up a chat session
                setupChat();
            } else {
                // User did not enable Bluetooth or an error occurred
                Log.d(TAG, &amp;quot;BT not enabled&amp;quot;);
                Toast.makeText(getActivity(), R.string.bt_not_enabled_leaving,
                        Toast.LENGTH_SHORT).show();
                getActivity().finish();
            }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;onActivityResultではDeviceListActivityで、接続する端末を選択した結果もハンドリングしていて、connectDeviceを呼ぶ。
アドレスからmBluetoothAdapter.getRemoteDevice(address)でdeviceを取得して、これをサービスに渡して接続する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void connectDevice(Intent data, boolean secure) {
    // Get the device MAC address
    String address = data.getExtras()
            .getString(DeviceListActivity.EXTRA_DEVICE_ADDRESS);
    // Get the BluetoothDevice object
    BluetoothDevice device = mBluetoothAdapter.getRemoteDevice(address);
    // Attempt to connect to the device
    mChatService.connect(device, secure);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serviceのstartとstop。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onDestroy() {
    super.onDestroy();
    if (mChatService != null) {
        mChatService.stop();
    }
}

@Override
public void onResume() {
    super.onResume();

    // Performing this check in onResume() covers the case in which BT was
    // not enabled during onStart(), so we were paused to enable it...
    // onResume() will be called when ACTION_REQUEST_ENABLE activity returns.
    if (mChatService != null) {
        // Only if the state is STATE_NONE, do we know that we haven&#39;t started already
        if (mChatService.getState() == BluetoothChatService.STATE_NONE) {
            // Start the Bluetooth chat services
            mChatService.start();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;viewまわり。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container,
                         @Nullable Bundle savedInstanceState) {
    return inflater.inflate(R.layout.fragment_bluetooth_chat, container, false);
}

@Override
public void onViewCreated(View view, @Nullable Bundle savedInstanceState) {
    mConversationView = (ListView) view.findViewById(R.id.in);
    mOutEditText = (EditText) view.findViewById(R.id.edit_text_out);
    mSendButton = (Button) view.findViewById(R.id.button_send);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;setupChatでは会話用リストにAdapterをセットしたり、入力欄やボタンにリスナーを登録するほかに、ChatServiceを初期化する。
初期化する際に第二引数として渡すmHandlerでは、Serviceからのメッセージにより処理を行う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void setupChat() {
    Log.d(TAG, &amp;quot;setupChat()&amp;quot;);

    // Initialize the array adapter for the conversation thread
    mConversationArrayAdapter = new ArrayAdapter&amp;lt;String&amp;gt;(getActivity(), R.layout.message);

    mConversationView.setAdapter(mConversationArrayAdapter);

    // Initialize the compose field with a listener for the return key
    mOutEditText.setOnEditorActionListener(mWriteListener);

    // Initialize the send button with a listener that for click events
    mSendButton.setOnClickListener(new View.OnClickListener() {
        public void onClick(View v) {
            // Send a message using content of the edit text widget
            View view = getView();
            if (null != view) {
                TextView textView = (TextView) view.findViewById(R.id.edit_text_out);
                String message = textView.getText().toString();
                sendMessage(message);
            }
        }
    });

    // Initialize the BluetoothChatService to perform bluetooth connections
    mChatService = new BluetoothChatService(getActivity(), mHandler);

    // Initialize the buffer for outgoing messages
    mOutStringBuffer = new StringBuffer(&amp;quot;&amp;quot;);
}

private TextView.OnEditorActionListener mWriteListener = new TextView.OnEditorActionListener() {
  public boolean onEditorAction(TextView view, int actionId, KeyEvent event) {
      // If the action is a key-up event on the return key, send the message
      if (actionId == EditorInfo.IME_NULL &amp;amp;&amp;amp; event.getAction() == KeyEvent.ACTION_UP) {
          String message = view.getText().toString();
          sendMessage(message);
      }
      return true;
  }
};

private final Handler mHandler = new Handler() {
    @Override
    public void handleMessage(Message msg) {
        FragmentActivity activity = getActivity();
        switch (msg.what) {
            case Constants.MESSAGE_STATE_CHANGE:
                switch (msg.arg1) {
                    case BluetoothChatService.STATE_CONNECTED:
                        setStatus(getString(R.string.title_connected_to, mConnectedDeviceName));
                        mConversationArrayAdapter.clear();
                        break;
                    case BluetoothChatService.STATE_CONNECTING:
                        setStatus(R.string.title_connecting);
                        break;
                    case BluetoothChatService.STATE_LISTEN:
                    case BluetoothChatService.STATE_NONE:
                        setStatus(R.string.title_not_connected);
                        break;
                }
                break;
            case Constants.MESSAGE_WRITE:
                byte[] writeBuf = (byte[]) msg.obj;
                // construct a string from the buffer
                String writeMessage = new String(writeBuf);
                mConversationArrayAdapter.add(&amp;quot;Me:  &amp;quot; + writeMessage);
                break;
            case Constants.MESSAGE_READ:
                byte[] readBuf = (byte[]) msg.obj;
                // construct a string from the valid bytes in the buffer
                String readMessage = new String(readBuf, 0, msg.arg1);
                mConversationArrayAdapter.add(mConnectedDeviceName + &amp;quot;:  &amp;quot; + readMessage);
                break;
            case Constants.MESSAGE_DEVICE_NAME:
                // save the connected device&#39;s name
                mConnectedDeviceName = msg.getData().getString(Constants.DEVICE_NAME);
                if (null != activity) {
                    Toast.makeText(activity, &amp;quot;Connected to &amp;quot;
                            + mConnectedDeviceName, Toast.LENGTH_SHORT).show();
                }
                break;
            case Constants.MESSAGE_TOAST:
                if (null != activity) {
                    Toast.makeText(activity, msg.getData().getString(Constants.TOAST),
                            Toast.LENGTH_SHORT).show();
                }
                break;
        }
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デバイスを検出可能にするのと、DeviceListActivityを始めるメニュー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
public void onCreateOptionsMenu(Menu menu, MenuInflater inflater) {
    inflater.inflate(R.menu.bluetooth_chat, menu);
}

@Override
public boolean onOptionsItemSelected(MenuItem item) {
    switch (item.getItemId()) {
        case R.id.secure_connect_scan: {
            // Launch the DeviceListActivity to see devices and do scan
            Intent serverIntent = new Intent(getActivity(), DeviceListActivity.class);
            startActivityForResult(serverIntent, REQUEST_CONNECT_DEVICE_SECURE);
            return true;
        }
        case R.id.insecure_connect_scan: {
            // Launch the DeviceListActivity to see devices and do scan
            Intent serverIntent = new Intent(getActivity(), DeviceListActivity.class);
            startActivityForResult(serverIntent, REQUEST_CONNECT_DEVICE_INSECURE);
            return true;
        }
        case R.id.discoverable: {
            // Ensure this device is discoverable by others
            ensureDiscoverable();
            return true;
        }
    }
    return false;
}

private void ensureDiscoverable() {
    if (mBluetoothAdapter.getScanMode() !=
            BluetoothAdapter.SCAN_MODE_CONNECTABLE_DISCOVERABLE) {
        Intent discoverableIntent = new Intent(BluetoothAdapter.ACTION_REQUEST_DISCOVERABLE);
        discoverableIntent.putExtra(BluetoothAdapter.EXTRA_DISCOVERABLE_DURATION, 300);
        startActivity(discoverableIntent);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bluetoothchatservice&#34;&gt;BluetoothChatService&lt;/h2&gt;

&lt;p&gt;初期stateはSTATE_NONE。
setStateしたときにobtainMessageでstateが変わったときの処理をhandlerに行わせる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public BluetoothChatService(Context context, Handler handler) {
    mAdapter = BluetoothAdapter.getDefaultAdapter();
    mState = STATE_NONE;
    mHandler = handler;
}

private synchronized void setState(int state) {
    Log.d(TAG, &amp;quot;setState() &amp;quot; + mState + &amp;quot; -&amp;gt; &amp;quot; + state);
    mState = state;

    // Give the new state to the Handler so the UI Activity can update
    mHandler.obtainMessage(Constants.MESSAGE_STATE_CHANGE, state, -1).sendToTarget();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接続しようとしている、した、される処理はそれぞれ別スレッドで行われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public synchronized void start() {
    Log.d(TAG, &amp;quot;start&amp;quot;);

    // Cancel any thread attempting to make a connection
    if (mConnectThread != null) {
        mConnectThread.cancel();
        mConnectThread = null;
    }

    // Cancel any thread currently running a connection
    if (mConnectedThread != null) {
        mConnectedThread.cancel();
        mConnectedThread = null;
    }

    setState(STATE_LISTEN);

    // Start the thread to listen on a BluetoothServerSocket
    if (mSecureAcceptThread == null) {
        mSecureAcceptThread = new AcceptThread(true);
        mSecureAcceptThread.start();
    }
    if (mInsecureAcceptThread == null) {
        mInsecureAcceptThread = new AcceptThread(false);
        mInsecureAcceptThread.start();
    }
}

public synchronized void stop() {
    Log.d(TAG, &amp;quot;stop&amp;quot;);

    if (mConnectThread != null) {
        mConnectThread.cancel();
        mConnectThread = null;
    }

    if (mConnectedThread != null) {
        mConnectedThread.cancel();
        mConnectedThread = null;
    }

    if (mSecureAcceptThread != null) {
        mSecureAcceptThread.cancel();
        mSecureAcceptThread = null;
    }

    if (mInsecureAcceptThread != null) {
        mInsecureAcceptThread.cancel();
        mInsecureAcceptThread = null;
    }
    setState(STATE_NONE);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず、接続するためのConnectThread。コンストラクタでつなげるdeviceからsocketを作成し、
runで接続する。接続できたらconnectedを呼び、ConnectedThreadを始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private class ConnectThread extends Thread {
    private final BluetoothSocket mmSocket;
    private final BluetoothDevice mmDevice;
    private String mSocketType;

    public ConnectThread(BluetoothDevice device, boolean secure) {
        mmDevice = device;
        BluetoothSocket tmp = null;
        mSocketType = secure ? &amp;quot;Secure&amp;quot; : &amp;quot;Insecure&amp;quot;;

        // Get a BluetoothSocket for a connection with the
        // given BluetoothDevice
        try {
            if (secure) {
                tmp = device.createRfcommSocketToServiceRecord(
                        MY_UUID_SECURE);
            } else {
                tmp = device.createInsecureRfcommSocketToServiceRecord(
                        MY_UUID_INSECURE);
            }
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;Socket Type: &amp;quot; + mSocketType + &amp;quot;create() failed&amp;quot;, e);
        }
        mmSocket = tmp;
    }

    public void run() {
        Log.i(TAG, &amp;quot;BEGIN mConnectThread SocketType:&amp;quot; + mSocketType);
        setName(&amp;quot;ConnectThread&amp;quot; + mSocketType);

        // Always cancel discovery because it will slow down a connection
        mAdapter.cancelDiscovery();

        // Make a connection to the BluetoothSocket
        try {
            // This is a blocking call and will only return on a
            // successful connection or an exception
            mmSocket.connect();
        } catch (IOException e) {
            // Close the socket
            try {
                mmSocket.close();
            } catch (IOException e2) {
                Log.e(TAG, &amp;quot;unable to close() &amp;quot; + mSocketType +
                        &amp;quot; socket during connection failure&amp;quot;, e2);
            }
            connectionFailed();
            return;
        }

        // Reset the ConnectThread because we&#39;re done
        synchronized (BluetoothChatService.this) {
            mConnectThread = null;
        }

        // Start the connected thread
        connected(mmSocket, mmDevice, mSocketType);
    }

    public void cancel() {
        try {
            mmSocket.close();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;close() of connect &amp;quot; + mSocketType + &amp;quot; socket failed&amp;quot;, e);
        }
    }
}

public synchronized void connected(BluetoothSocket socket, BluetoothDevice
        device, final String socketType) {
    Log.d(TAG, &amp;quot;connected, Socket Type:&amp;quot; + socketType);

    // Cancel the thread that completed the connection
    if (mConnectThread != null) {
        mConnectThread.cancel();
        mConnectThread = null;
    }

    // Cancel any thread currently running a connection
    if (mConnectedThread != null) {
        mConnectedThread.cancel();
        mConnectedThread = null;
    }

    // Cancel the accept thread because we only want to connect to one device
    if (mSecureAcceptThread != null) {
        mSecureAcceptThread.cancel();
        mSecureAcceptThread = null;
    }
    if (mInsecureAcceptThread != null) {
        mInsecureAcceptThread.cancel();
        mInsecureAcceptThread = null;
    }

    // Start the thread to manage the connection and perform transmissions
    mConnectedThread = new ConnectedThread(socket, socketType);
    mConnectedThread.start();

    // Send the name of the connected device back to the UI Activity
    Message msg = mHandler.obtainMessage(Constants.MESSAGE_DEVICE_NAME);
    Bundle bundle = new Bundle();
    bundle.putString(Constants.DEVICE_NAME, device.getName());
    msg.setData(bundle);
    mHandler.sendMessage(msg);

    setState(STATE_CONNECTED);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ConnectedThreadではsocketからinputStreamとoutputStreamを取得し、
runでは読んでメッセージで渡し、writeで書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private class ConnectedThread extends Thread {
    private final BluetoothSocket mmSocket;
    private final InputStream mmInStream;
    private final OutputStream mmOutStream;

    public ConnectedThread(BluetoothSocket socket, String socketType) {
        Log.d(TAG, &amp;quot;create ConnectedThread: &amp;quot; + socketType);
        mmSocket = socket;
        InputStream tmpIn = null;
        OutputStream tmpOut = null;

        // Get the BluetoothSocket input and output streams
        try {
            tmpIn = socket.getInputStream();
            tmpOut = socket.getOutputStream();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;temp sockets not created&amp;quot;, e);
        }

        mmInStream = tmpIn;
        mmOutStream = tmpOut;
    }

    public void run() {
        Log.i(TAG, &amp;quot;BEGIN mConnectedThread&amp;quot;);
        byte[] buffer = new byte[1024];
        int bytes;

        // Keep listening to the InputStream while connected
        while (mState == STATE_CONNECTED) {
            try {
                // Read from the InputStream
                bytes = mmInStream.read(buffer);

                // Send the obtained bytes to the UI Activity
                mHandler.obtainMessage(Constants.MESSAGE_READ, bytes, -1, buffer)
                        .sendToTarget();
            } catch (IOException e) {
                Log.e(TAG, &amp;quot;disconnected&amp;quot;, e);
                connectionLost();
                // Start the service over to restart listening mode
                BluetoothChatService.this.start();
                break;
            }
        }
    }

    /**
     * Write to the connected OutStream.
     *
     * @param buffer The bytes to write
     */
    public void write(byte[] buffer) {
        try {
            mmOutStream.write(buffer);

            // Share the sent message back to the UI Activity
            mHandler.obtainMessage(Constants.MESSAGE_WRITE, -1, -1, buffer)
                    .sendToTarget();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;Exception during write&amp;quot;, e);
        }
    }

    public void cancel() {
        try {
            mmSocket.close();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;close() of connect socket failed&amp;quot;, e);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;AcceptThreadでは常に受け入れられる形にしておく。もしつながったらConnectThreadと同様にconnectedする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private class AcceptThread extends Thread {
    // The local server socket
    private final BluetoothServerSocket mmServerSocket;
    private String mSocketType;

    public AcceptThread(boolean secure) {
        BluetoothServerSocket tmp = null;
        mSocketType = secure ? &amp;quot;Secure&amp;quot; : &amp;quot;Insecure&amp;quot;;

        // Create a new listening server socket
        try {
            if (secure) {
                tmp = mAdapter.listenUsingRfcommWithServiceRecord(NAME_SECURE,
                        MY_UUID_SECURE);
            } else {
                tmp = mAdapter.listenUsingInsecureRfcommWithServiceRecord(
                        NAME_INSECURE, MY_UUID_INSECURE);
            }
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;Socket Type: &amp;quot; + mSocketType + &amp;quot;listen() failed&amp;quot;, e);
        }
        mmServerSocket = tmp;
    }

    public void run() {
        Log.d(TAG, &amp;quot;Socket Type: &amp;quot; + mSocketType +
                &amp;quot;BEGIN mAcceptThread&amp;quot; + this);
        setName(&amp;quot;AcceptThread&amp;quot; + mSocketType);

        BluetoothSocket socket = null;

        // Listen to the server socket if we&#39;re not connected
        while (mState != STATE_CONNECTED) {
            try {
                // This is a blocking call and will only return on a
                // successful connection or an exception
                socket = mmServerSocket.accept();
            } catch (IOException e) {
                Log.e(TAG, &amp;quot;Socket Type: &amp;quot; + mSocketType + &amp;quot;accept() failed&amp;quot;, e);
                break;
            }

            // If a connection was accepted
            if (socket != null) {
                synchronized (BluetoothChatService.this) {
                    switch (mState) {
                        case STATE_LISTEN:
                        case STATE_CONNECTING:
                            // Situation normal. Start the connected thread.
                            connected(socket, socket.getRemoteDevice(),
                                    mSocketType);
                            break;
                        case STATE_NONE:
                        case STATE_CONNECTED:
                            // Either not ready or already connected. Terminate new socket.
                            try {
                                socket.close();
                            } catch (IOException e) {
                                Log.e(TAG, &amp;quot;Could not close unwanted socket&amp;quot;, e);
                            }
                            break;
                    }
                }
            }
        }
        Log.i(TAG, &amp;quot;END mAcceptThread, socket Type: &amp;quot; + mSocketType);

    }

    public void cancel() {
        Log.d(TAG, &amp;quot;Socket Type&amp;quot; + mSocketType + &amp;quot;cancel &amp;quot; + this);
        try {
            mmServerSocket.close();
        } catch (IOException e) {
            Log.e(TAG, &amp;quot;Socket Type&amp;quot; + mSocketType + &amp;quot;close() of server failed&amp;quot;, e);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;connectでは、接続しようとしているならそれをキャンセル、接続したものがあるならsocketを閉じて
新しい接続を始める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public synchronized void connect(BluetoothDevice device, boolean secure) {
    Log.d(TAG, &amp;quot;connect to: &amp;quot; + device);

    // Cancel any thread attempting to make a connection
    if (mState == STATE_CONNECTING) {
        if (mConnectThread != null) {
            mConnectThread.cancel();
            mConnectThread = null;
        }
    }

    // Cancel any thread currently running a connection
    if (mConnectedThread != null) {
        mConnectedThread.cancel();
        mConnectedThread = null;
    }

    // Start the thread to connect with the given device
    mConnectThread = new ConnectThread(device, secure);
    mConnectThread.start();
    setState(STATE_CONNECTING);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;writeでは接続済みであることを確認後、connectedThreadの(参照を)コピーして、writeしている。
この間にmConnectedThreadにnullが代入されたりすることをsynchronizedで防ぐ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void write(byte[] out) {
    // Create temporary object
    ConnectedThread r;
    // Synchronize a copy of the ConnectedThread
    synchronized (this) {
        if (mState != STATE_CONNECTED) return;
        r = mConnectedThread;
    }
    // Perform the write unsynchronized
    r.write(out);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;devicelistactivity&#34;&gt;DeviceListActivity&lt;/h2&gt;

&lt;p&gt;検出可能にしている他端末を探し、選択する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;requestWindowFeature(Window.FEATURE_INDETERMINATE_PROGRESS)&lt;/code&gt;して、
&lt;code&gt;setProgressBarIndeterminateVisibility(true)&lt;/code&gt;すると右上にプログレスバーが表示できる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;new IntentFilter(BluetoothDevice.ACTION_FOUND)&lt;/code&gt;と
&lt;code&gt;new IntentFilter(BluetoothAdapter.ACTION_DISCOVERY_FINISHED)&lt;/code&gt;で
&lt;code&gt;registerReceiver(mReceiver, filter)&lt;/code&gt;して、
デバイスを見つけたときと探し終わったときにブロードキャストされてくるインテントを受信するレシーバーを登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);

    // Setup the window
    requestWindowFeature(Window.FEATURE_INDETERMINATE_PROGRESS);
    setContentView(R.layout.activity_device_list);

    // Set result CANCELED in case the user backs out
    setResult(Activity.RESULT_CANCELED);

    // Initialize the button to perform device discovery
    Button scanButton = (Button) findViewById(R.id.button_scan);
    scanButton.setOnClickListener(new View.OnClickListener() {
        public void onClick(View v) {
            doDiscovery();
            v.setVisibility(View.GONE);
        }
    });

    // Initialize array adapters. One for already paired devices and
    // one for newly discovered devices
    ArrayAdapter&amp;lt;String&amp;gt; pairedDevicesArrayAdapter =
            new ArrayAdapter&amp;lt;String&amp;gt;(this, R.layout.device_name);
    mNewDevicesArrayAdapter = new ArrayAdapter&amp;lt;String&amp;gt;(this, R.layout.device_name);

    // Find and set up the ListView for paired devices
    ListView pairedListView = (ListView) findViewById(R.id.paired_devices);
    pairedListView.setAdapter(pairedDevicesArrayAdapter);
    pairedListView.setOnItemClickListener(mDeviceClickListener);

    // Find and set up the ListView for newly discovered devices
    ListView newDevicesListView = (ListView) findViewById(R.id.new_devices);
    newDevicesListView.setAdapter(mNewDevicesArrayAdapter);
    newDevicesListView.setOnItemClickListener(mDeviceClickListener);

    // Register for broadcasts when a device is discovered
    IntentFilter filter = new IntentFilter(BluetoothDevice.ACTION_FOUND);
    this.registerReceiver(mReceiver, filter);

    // Register for broadcasts when discovery has finished
    filter = new IntentFilter(BluetoothAdapter.ACTION_DISCOVERY_FINISHED);
    this.registerReceiver(mReceiver, filter);

    // Get the local Bluetooth adapter
    mBtAdapter = BluetoothAdapter.getDefaultAdapter();

    // Get a set of currently paired devices
    Set&amp;lt;BluetoothDevice&amp;gt; pairedDevices = mBtAdapter.getBondedDevices();

    // If there are paired devices, add each one to the ArrayAdapter
    if (pairedDevices.size() &amp;gt; 0) {
        findViewById(R.id.title_paired_devices).setVisibility(View.VISIBLE);
        for (BluetoothDevice device : pairedDevices) {
            pairedDevicesArrayAdapter.add(device.getName() + &amp;quot;\n&amp;quot; + device.getAddress());
        }
    } else {
        String noDevices = getResources().getText(R.string.none_paired).toString();
        pairedDevicesArrayAdapter.add(noDevices);
    }
}

private void doDiscovery() {
    Log.d(TAG, &amp;quot;doDiscovery()&amp;quot;);

    // Indicate scanning in the title
    setProgressBarIndeterminateVisibility(true);
    setTitle(R.string.scanning);

    // Turn on sub-title for new devices
    findViewById(R.id.title_new_devices).setVisibility(View.VISIBLE);

    // If we&#39;re already discovering, stop it
    if (mBtAdapter.isDiscovering()) {
        mBtAdapter.cancelDiscovery();
    }

    // Request discover from BluetoothAdapter
    mBtAdapter.startDiscovery();
}

private final BroadcastReceiver mReceiver = new BroadcastReceiver() {
    @Override
    public void onReceive(Context context, Intent intent) {
        String action = intent.getAction();

        // When discovery finds a device
        if (BluetoothDevice.ACTION_FOUND.equals(action)) {
            // Get the BluetoothDevice object from the Intent
            BluetoothDevice device = intent.getParcelableExtra(BluetoothDevice.EXTRA_DEVICE);
            // If it&#39;s already paired, skip it, because it&#39;s been listed already
            if (device.getBondState() != BluetoothDevice.BOND_BONDED) {
                mNewDevicesArrayAdapter.add(device.getName() + &amp;quot;\n&amp;quot; + device.getAddress());
            }
            // When discovery is finished, change the Activity title
        } else if (BluetoothAdapter.ACTION_DISCOVERY_FINISHED.equals(action)) {
            setProgressBarIndeterminateVisibility(false);
            setTitle(R.string.select_device);
            if (mNewDevicesArrayAdapter.getCount() == 0) {
                String noDevices = getResources().getText(R.string.none_found).toString();
                mNewDevicesArrayAdapter.add(noDevices);
            }
        }
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;onDestroyで、探索をやめ、登録したレシーバーを外す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override
protected void onDestroy() {
    super.onDestroy();

    // Make sure we&#39;re not doing discovery anymore
    if (mBtAdapter != null) {
        mBtAdapter.cancelDiscovery();
    }

    // Unregister broadcast listeners
    this.unregisterReceiver(mReceiver);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接続先リストから選択されたら、アドレスを付けて結果を返す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private AdapterView.OnItemClickListener mDeviceClickListener
        = new AdapterView.OnItemClickListener() {
    public void onItemClick(AdapterView&amp;lt;?&amp;gt; av, View v, int arg2, long arg3) {
        // Cancel discovery because it&#39;s costly and we&#39;re about to connect
        mBtAdapter.cancelDiscovery();

        // Get the device MAC address, which is the last 17 chars in the View
        String info = ((TextView) v).getText().toString();
        String address = info.substring(info.length() - 17);

        // Create the result Intent and include the MAC address
        Intent intent = new Intent();
        intent.putExtra(EXTRA_DEVICE_ADDRESS, address);

        // Set result and finish this Activity
        setResult(Activity.RESULT_OK, intent);
        finish();
    }
};
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>静的ウェブサイトエンジンHugoに乗り換えた</title>
          <link>https://www.sambaiz.net/article/22/</link>
          <pubDate>Tue, 04 Oct 2016 22:21:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/22/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://gohugo.io/&#34;&gt;https://gohugo.io/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今までこのサイトはフロントのReactからLambda &amp;amp; API Gatewayで作った記事APIを呼ぶ構成になっていた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/1&#34;&gt;ホームページ作った&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;当初はページの描画をフロントに任せることで、
サーバーレス
(記事の情報をjsonで渡すAPI Gatewayと、S3の組み合わせ)
で作れると思っていたが、結果そんなに甘くはなく、サーバーサイドレンダリングするはめになる。
最初からレンダリングしたものを置いておけばいいと思った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/5&#34;&gt;webpack環境でredux&amp;amp;react-routerのページをサーバーサイドレンダリングする&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;そんなこんなでHugoに乗り換えることにした。
記事はmarkdownで管理していたので、これにメタ情報を加えるだけで移行できた。
タグで絞り込むこともできるようになったので良いと思う。
また、静的なページになったのでgithub pagesに置けるようにもなった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DeepDreaming with TensorFlowをやる(2)</title>
          <link>https://www.sambaiz.net/article/21/</link>
          <pubDate>Sat, 10 Sep 2016 14:46:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/21/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/20&#34;&gt;前回&lt;/a&gt;の続き。&lt;/p&gt;

&lt;h2 id=&#34;multiscale-image-generation&#34;&gt;Multiscale image generation&lt;/h2&gt;

&lt;p&gt;様々なスケールで勾配上昇させる。小さなスケールで上昇させたものをより大きなスケールでさらに上昇させていく。
ただ、壁紙のようなサイズを生成するような場合にそれを行うと、GPUのメモリを食いつぶしてしまう。
これを避けるために、画像を小さなタイルに分割し、それぞれ独立に勾配を計算する。
また、毎回画像をランダムにシフトしていくことで、タイルに見えることを避け、画像全体の品質を向上させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def tffunc(*argtypes):
    &#39;&#39;&#39;Helper that transforms TF-graph generating function into a regular one.
    See &amp;quot;resize&amp;quot; function below.
    &#39;&#39;&#39;
    placeholders = list(map(tf.placeholder, argtypes))
    def wrap(f):
        out = f(*placeholders)
        def wrapper(*args, **kw):
            return out.eval(dict(zip(placeholders, args)), session=kw.get(&#39;session&#39;))
        return wrapper
    return wrap

# Helper function that uses TF to resize an image
def resize(img, size):
    img = tf.expand_dims(img, 0)
    return tf.image.resize_bilinear(img, size)[0,:,:,:]
resize = tffunc(np.float32, np.int32)(resize)


def calc_grad_tiled(img, t_grad, tile_size=512):
    &#39;&#39;&#39;Compute the value of tensor t_grad over the image in a tiled way.
    Random shifts are applied to the image to blur tile boundaries over
    multiple iterations.&#39;&#39;&#39;
    sz = tile_size
    h, w = img.shape[:2]
    sx, sy = np.random.randint(sz, size=2)
    img_shift = np.roll(np.roll(img, sx, 1), sy, 0)
    grad = np.zeros_like(img)
    for y in range(0, max(h-sz//2, sz),sz):
        for x in range(0, max(w-sz//2, sz),sz):
            sub = img_shift[y:y+sz,x:x+sz]
            g = sess.run(t_grad, {t_input:sub})
            grad[y:y+sz,x:x+sz] = g
    return np.roll(np.roll(grad, -sx, 1), -sy, 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.image.resize_bilinear&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/image.html#resize_bilinear&#34;&gt;双線形補間によってリサイズする。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;numpy.roll&lt;/code&gt;は&lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/generated/numpy.roll.html&#34;&gt;配列を第三引数axisによってローリングする&lt;/a&gt;。
axisを指定しない場合、フラットなものとして扱われる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hoge = [[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]]

print(np.roll(hoge, 1))
# [[8 0 1]
#  [2 3 4]
#  [5 6 7]]

print(np.roll(hoge, 1, axis=0))
# [[6 7 8]
#  [0 1 2]
#  [3 4 5]]

print(np.roll(hoge, 1, axis=1))
# [[2 0 1]
#  [5 3 4]
#  [8 6 7]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;つまり、&lt;code&gt;calc_grad_tiled&lt;/code&gt;では、ランダムにローリングして、タイルに分割して勾配を求め、ローリングした分を戻して返している。
これと、画像サイズを&lt;code&gt;octave_scale&lt;/code&gt;倍にしていく以外は前回やったのと基本的に同じだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def render_multiscale(t_obj, img0=img_noise, iter_n=10, step=1.0, octave_n=3, octave_scale=1.4):
    t_score = tf.reduce_mean(t_obj) # defining the optimization objective
    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!

    img = img0.copy()
    for octave in range(octave_n):
        if octave&amp;gt;0:
            hw = np.float32(img.shape[:2])*octave_scale
            img = resize(img, np.int32(hw))
        for i in range(iter_n):
            g = calc_grad_tiled(img, t_grad)
            # normalizing the gradient, so the same step size should work
            g /= g.std()+1e-8         # for different layers and networks
            img += g*step
            print(&#39;.&#39;, end = &#39; &#39;)
        clear_output()
        showarray(visstd(img))

render_multiscale(T(layer)[:,:,:,channel])
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;laplacian-pyramid-gradient-normalization&#34;&gt;Laplacian Pyramid Gradient Normalization&lt;/h2&gt;

&lt;p&gt;結果の画像は、高い周波数(ピクセルの変化の度合が高い)が多く含まれている。
これを改善するための一つの方法として、毎回画像をぼかし、高周波数を抑え、画像を滑らかにするものがある。
ただ、この方法は良い画像にするためにより多くの繰り返しが必要になってしまう。
逆に、低周波数を上げるのは、ラプラシアンピラミッドを使う方法があって、これで勾配を正規化する。&lt;/p&gt;

&lt;p&gt;ラプラシアンピラミッドというのは、ガウシアンピラミッドにおける、ある解像度の画像と、
その一つレベルの高い(解像度1/2 * &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; = &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;)画像をアップサンプルしたものの差分だ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_pyramids/py_pyramids.html&#34;&gt;画像ピラミッド — OpenCV-Python Tutorials 1 documentation&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;k = np.float32([1,4,6,4,1])
k = np.outer(k, k)
# [[  1.   4.   6.   4.   1.]
#  [  4.  16.  24.  16.   4.]
#  [  6.  24.  36.  24.   6.]
#  [  4.  16.  24.  16.   4.]
#  [  1.   4.   6.   4.   1.]]

k5x5 = k[:,:,None,None]/k.sum()*np.eye(3, dtype=np.float32)

print(len(k5x5))
# 5

print(k5x5[0])
# [[[ 0.00390625  0.          0.        ]
#  [ 0.          0.00390625  0.        ]
#  [ 0.          0.          0.00390625]]

# [[ 0.015625    0.          0.        ]
#  [ 0.          0.015625    0.        ]
#  [ 0.          0.          0.015625  ]]

# [[ 0.0234375   0.          0.        ]
#  [ 0.          0.0234375   0.        ]
#  [ 0.          0.          0.0234375 ]]

# [[ 0.015625    0.          0.        ]
#  [ 0.          0.015625    0.        ]
#  [ 0.          0.          0.015625  ]]

# [[ 0.00390625  0.          0.        ]
#  [ 0.          0.00390625  0.        ]
#  [ 0.          0.          0.00390625]]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;numpy.outer&lt;/code&gt;は&lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/generated/numpy.outer.html&#34;&gt;外積を求める&lt;/a&gt;もので、
&lt;code&gt;numpy.eye&lt;/code&gt;は&lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html&#34;&gt;対角線が1で、それ以外は0の2次元行列を返す&lt;/a&gt;。
&lt;code&gt;k&lt;/code&gt;を指定すると、対角線の位置を変更できるが、指定していない場合はNxNの単位行列が返ることになる。
このフィルターで畳み込むことで、ラプラシアンピラミッドの1レベル高い画像に変換できる。
&lt;code&gt;tf.nn.conv2d_transpose&lt;/code&gt;は
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#conv2d_transpose&#34;&gt;畳み込みの逆処理&lt;/a&gt;のようなもので、
これでアップサンプルした画像と元画像の差分を取って、ラプラシアンピラミッドを生成している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def lap_split(img):
    &#39;&#39;&#39;Split the image into lo and hi frequency components&#39;&#39;&#39;
    with tf.name_scope(&#39;split&#39;):
        lo = tf.nn.conv2d(img, k5x5, [1,2,2,1], &#39;SAME&#39;)
        lo2 = tf.nn.conv2d_transpose(lo, k5x5*4, tf.shape(img), [1,2,2,1])
        hi = img-lo2
    return lo, hi

def lap_split_n(img, n):
    &#39;&#39;&#39;Build Laplacian pyramid with n splits&#39;&#39;&#39;
    levels = []
    for i in range(n):
        img, hi = lap_split(img)
        levels.append(hi)
    levels.append(img)
    return levels[::-1]

def lap_merge(levels):
    &#39;&#39;&#39;Merge Laplacian pyramid&#39;&#39;&#39;
    img = levels[0]
    for hi in levels[1:]:
        with tf.name_scope(&#39;merge&#39;):
            img = tf.nn.conv2d_transpose(img, k5x5*4, tf.shape(hi), [1,2,2,1]) + hi
    return img

def normalize_std(img, eps=1e-10):
    &#39;&#39;&#39;Normalize image by making its standard deviation = 1.0&#39;&#39;&#39;
    with tf.name_scope(&#39;normalize&#39;):
        std = tf.sqrt(tf.reduce_mean(tf.square(img)))
        return img/tf.maximum(std, eps)

def lap_normalize(img, scale_n=4):
    &#39;&#39;&#39;Perform the Laplacian pyramid normalization.&#39;&#39;&#39;
    img = tf.expand_dims(img,0)
    tlevels = lap_split_n(img, scale_n)
    tlevels = list(map(normalize_std, tlevels))
    out = lap_merge(tlevels)
    return out[0,:,:,:]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;lap_normalize&lt;/code&gt;で画像からラプラシアンピラミッドを生成し、それぞれで正規化してからマージして元の画像に戻す処理をしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def render_lapnorm(t_obj, img0=img_noise, visfunc=visstd,
                   iter_n=10, step=1.0, octave_n=3, octave_scale=1.4, lap_n=4):
    t_score = tf.reduce_mean(t_obj) # defining the optimization objective
    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!
    # build the laplacian normalization graph
    lap_norm_func = tffunc(np.float32)(partial(lap_normalize, scale_n=lap_n))

    img = img0.copy()
    for octave in range(octave_n):
        if octave&amp;gt;0:
            hw = np.float32(img.shape[:2])*octave_scale
            img = resize(img, np.int32(hw))
        for i in range(iter_n):
            g = calc_grad_tiled(img, t_grad)
            g = lap_norm_func(g)
            img += g*step
            print(&#39;.&#39;, end = &#39; &#39;)
        clear_output()
        showarray(visfunc(img))

render_lapnorm(T(layer)[:,:,:,channel])
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deepdream&#34;&gt;DeepDream&lt;/h2&gt;

&lt;p&gt;で、これがDeepDreamのアルゴリズム。
ラプラシアンピラミッドを生成して、リサイズの際に次のレベルのを足していっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def render_deepdream(t_obj, img0=img_noise,
                     iter_n=10, step=1.5, octave_n=4, octave_scale=1.4):
    t_score = tf.reduce_mean(t_obj) # defining the optimization objective
    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!

    # split the image into a number of octaves
    img = img0
    octaves = []
    for i in range(octave_n-1):
        hw = img.shape[:2]
        lo = resize(img, np.int32(np.float32(hw)/octave_scale))
        hi = img-resize(lo, hw)
        img = lo
        octaves.append(hi)

    # generate details octave by octave
    for octave in range(octave_n):
        if octave&amp;gt;0:
            hi = octaves[-octave]
            img = resize(img, hi.shape[:2])+hi
        for i in range(iter_n):
            g = calc_grad_tiled(img, t_grad)
            img += g*(step / (np.abs(g).mean()+1e-7))
            print(&#39;.&#39;,end = &#39; &#39;)
        clear_output()
        showarray(img/255.0)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>DeepDreaming with Tensorflowをやる(1)</title>
          <link>https://www.sambaiz.net/article/20/</link>
          <pubDate>Wed, 07 Sep 2016 01:06:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/20/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb&#34;&gt;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;例の通りまとめながら進めていく。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;このノートブックは、畳み込みニューラルネットワークによる画像生成の手法を説明するものだ。
ネットワークは入力画像へ変換させる配列のレイヤーの集合から成り立っている。
変換のパラメータは勾配降下法で変形しながら学習していく。
内部的な画像の表現は意味不明なように見えるが、可視化し、解釈することができる。&lt;/p&gt;

&lt;h3 id=&#34;loading-and-displaying-the-model-graph&#34;&gt;Loading and displaying the model graph&lt;/h3&gt;

&lt;p&gt;学習済みネットワークのprotobufファイルが用意されていて、これをダウンロードして使う。
ただ&lt;code&gt;gcr.io/tensorflow/tensorflow&lt;/code&gt;にwgetもunzipも入っていなかったので、中に入ってapt-getした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model_fn = &#39;tensorflow_inception_graph.pb&#39;

# creating TensorFlow session and loading the model
graph = tf.Graph()
sess = tf.InteractiveSession(graph=graph)
with tf.gfile.FastGFile(model_fn, &#39;rb&#39;) as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
t_input = tf.placeholder(np.float32, name=&#39;input&#39;) # define the input tensor
imagenet_mean = 117.0
t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)
tf.import_graph_def(graph_def, {&#39;input&#39;:t_preprocessed})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.gfile.FastGFile&lt;/code&gt;のドキュメントが見つからないので
&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/568092d4507996d8aff0c46d6c57488a26596dd5/tensorflow/python/platform/gfile.py#L218&#34;&gt;ソース&lt;/a&gt;
を探したところFile I/Oのラッパーのようだ。これでprotobufファイルを読み、ParseFromStringでGraphDefにする。&lt;/p&gt;

&lt;p&gt;さらにこれと入力データを&lt;code&gt;tf.import_graph_def&lt;/code&gt;に
渡すことで&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/framework.html#import_graph_def&#34;&gt;Graphに取り込む&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.expand_dims&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/array_ops.html#expand_dims&#34;&gt;値が1の次元を指定の場所に挿入する&lt;/a&gt;
もの。なんでそんなことをしたり、&lt;code&gt;imagenet_mean&lt;/code&gt;を引いているのかは説明がなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;layers = [op.name for op in graph.get_operations() if op.type==&#39;Conv2D&#39; and &#39;import/&#39; in op.name]
feature_nums = [int(graph.get_tensor_by_name(name+&#39;:0&#39;).get_shape()[-1]) for name in layers]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このlayersに入っているのはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import/conv2d0_pre_relu/conv
import/conv2d1_pre_relu/conv
import/conv2d2_pre_relu/conv
import/mixed3a_1x1_pre_relu/conv
import/mixed3a_3x3_bottleneck_pre_relu/conv
import/mixed3a_3x3_pre_relu/conv
import/mixed3a_5x5_bottleneck_pre_relu/conv
import/mixed3a_5x5_pre_relu/conv
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらのレイヤーのうち、&lt;code&gt;mixed4d_3x3_bottleneck_pre_relu&lt;/code&gt;を可視化してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;layer = &#39;mixed4d_3x3_bottleneck_pre_relu&#39;
channel = 139 # picking some feature channel to visualize

def T(layer):
    &#39;&#39;&#39;Helper for getting layer output tensor&#39;&#39;&#39;
    return graph.get_tensor_by_name(&amp;quot;import/%s:0&amp;quot;%layer)

render_naive(T(layer)[:,:,:,channel])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;mixed4d_3x3_bottleneck_pre_relu&#39;&lt;/code&gt;は144チャンネルのフィルターで、今回はそのうち139番目のチャンネルを選んでいる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(T(layer))
-&amp;gt; Tensor(&amp;quot;import/mixed4d_3x3_bottleneck_pre_relu:0&amp;quot;, shape=(?, ?, ?, 144), dtype=float32, device=/device:CPU:0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初期値はRGB100(グレー)にノイズを加えた画像。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# start with a gray image with a little noise
img_noise = np.random.uniform(size=(224,224,3)) + 100.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;スコアはそのチャンネルの値の平均で、これが高くなるように画像を変化させていく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def render_naive(t_obj, img0=img_noise, iter_n=20, step=1.0):
    t_score = tf.reduce_mean(t_obj) # defining the optimization objective
    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!

    img = img0.copy()
    for i in range(iter_n):
        g, score = sess.run([t_grad, t_score], {t_input:img})
        # normalizing the gradient, so the same step size should work
        g /= g.std()+1e-8         # for different layers and networks
        img += g*step
        print(score, end = &#39; &#39;)
    clear_output()
    showarray(visstd(img))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.gradients(ys,xs)&lt;/code&gt;で
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html#gradients&#34;&gt;xそれぞれで偏微分したyの和&lt;/a&gt;が得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a = tf.Variable(tf.constant([
            [1., 2.],
            [3., 4.]]))
b = tf.Variable(tf.constant([
            [2., 3.],
            [4., 5.]]))
c = tf.matmul(a, b)
​
grad = tf.gradients(c, a)[0]
init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)

    print(sess.run(c))
    # [[ 10.  13.]
    # [ 22.  29.]]

    print(sess.run(grad))
    # [[ 5.  9.]
    # [ 5.  9.]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;入力画像にこれをを加算していくと、その状態からスコアが上がるパラメータが増え、下がるパラメータが減るため、勾配を上っていくことになる。
スコアが上昇するに従って、そのフィルターによる模様が浮かんできた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/21&#34;&gt;続く&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Grafana/InfluxDB/Fluentdでログを可視化する</title>
          <link>https://www.sambaiz.net/article/19/</link>
          <pubDate>Wed, 31 Aug 2016 20:54:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/19/</guid>
          <description>

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/grafana-influxdb-fluentd&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;influxdb-https-github-com-influxdata-influxdb&#34;&gt;&lt;a href=&#34;https://github.com/influxdata/influxdb&#34;&gt;InfluxDB&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Golangで書かれた時系列データベース。今回使うのは&lt;code&gt;v0.13&lt;/code&gt;。前のバージョンと結構違うので注意。&lt;/p&gt;

&lt;p&gt;デフォルトでは無効になっている認証を&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.13/administration/authentication_and_authorization/#set-up-authentication&#34;&gt;有効にする&lt;/a&gt;ために設定ファイルを編集して設置する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install influxdb # OSX
$ influxd config &amp;gt; influxdb.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[http]
  ...
  auth-enabled = true
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;FROM influxdb:0.13

VOLUME /var/lib/influxdb
ADD influxdb.conf /
ENV INFLUXDB_CONFIG_PATH /influxdb.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -p 8083:8083 -p 8086:8086 myinfluxdb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;influxd&lt;/code&gt;コマンドや
&lt;code&gt;:8083&lt;/code&gt;のWebインタフェースの他に
&lt;code&gt;:8086&lt;/code&gt;に&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.13/concepts/api/&#34;&gt;HTTP API&lt;/a&gt;が用意されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -i -XPOST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE USER root WITH PASSWORD &#39;root&#39; WITH ALL PRIVILEGES&amp;quot;

$ curl -i -XPOST http://localhost:8086/query -u root:root --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot;
{&amp;quot;results&amp;quot;:[{}]}

# Line Protocol(https://docs.influxdata.com/influxdb/v0.13/write_protocols/line/)
$ curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; -u root:root --data-binary &#39;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&#39;
(204 No Content)

$ curl -GET &#39;http://localhost:8086/query?db=mydb&#39; -u root:root --data-urlencode &#39;q=SELECT * FROM &amp;quot;cpu_load_short&amp;quot;&#39; | jq
{
  &amp;quot;results&amp;quot;: [
    {
      &amp;quot;series&amp;quot;: [
        {
          &amp;quot;name&amp;quot;: &amp;quot;cpu_load_short&amp;quot;,
          &amp;quot;columns&amp;quot;: [
            &amp;quot;time&amp;quot;,
            &amp;quot;host&amp;quot;,
            &amp;quot;region&amp;quot;,
            &amp;quot;value&amp;quot;
          ],
          &amp;quot;values&amp;quot;: [
            [
              &amp;quot;2015-06-11T20:46:02Z&amp;quot;,
              &amp;quot;server01&amp;quot;,
              &amp;quot;us-west&amp;quot;,
              0.64
            ]
          ]
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fluent-plugin-influxdb-https-github-com-fangli-fluent-plugin-influxdb&#34;&gt;&lt;a href=&#34;https://github.com/fangli/fluent-plugin-influxdb&#34;&gt;fluent-plugin-influxdb&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;設定はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  type tail
  path      /usr/src/app/test.log
  pos_file  /etc/td-agent/test.log.pos
  tag       something.log
  format    json
&amp;lt;/source&amp;gt;

&amp;lt;match *.log&amp;gt;
  @type     influxdb
  host      influxdb
  port      8086
  dbname    mydb
  user      root
  password  root
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5秒ごとにランダムな値valueのログを出力し続ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from twisted.internet import task, reactor
import logging
import json
import random

INTERVAL = 5 # sec
logging.basicConfig(filename=&#39;test.log&#39;, format=&#39;%(message)s&#39;, level=logging.INFO)

def somethingHappend():
  data = {
    &amp;quot;value&amp;quot;: random.randint(0, 100),
    &amp;quot;event&amp;quot;: &amp;quot;something&amp;quot;
  }
  logging.info(json.dumps(data))  

if __name__ == &#39;__main__&#39;:
    instance = task.LoopingCall(somethingHappend)
    instance.start(INTERVAL)
    reactor.run()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;grafana-http-grafana-org&#34;&gt;&lt;a href=&#34;http://grafana.org/&#34;&gt;Grafana&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;可視化ツール。データソースとしてInfluxDB、Garaphite、Elasticsearchなどが使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://play.grafana.org/&#34;&gt;Demo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kibana(+Elasticsearch)だと
認証するのに&lt;a href=&#34;https://www.elastic.co/subscriptions&#34;&gt;有償&lt;/a&gt;のShieldプラグインが必要だが、
こちらは最初からできて手軽。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;これらのDockerイメージを作って、minikubeで立ち上げてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pods
NAME                        READY     STATUS    RESTARTS   AGE
grafana-1386260931-lq8wh    1/1       Running   0          2m
influxdb-2543054961-yj1bd   1/1       Running   0          2m
testapp-532457622-269qo     1/1       Running   0          2m

$ curl -i -XPOST http://192.168.99.100:30005/query?db=mydb -u root:root --data-urlencode &#39;q=SELECT * FROM &amp;quot;something.log&amp;quot; LIMIT 1&#39;
{&amp;quot;results&amp;quot;:[{&amp;quot;series&amp;quot;:[{&amp;quot;name&amp;quot;:&amp;quot;something.log&amp;quot;,&amp;quot;columns&amp;quot;:[&amp;quot;time&amp;quot;,&amp;quot;event&amp;quot;,&amp;quot;value&amp;quot;],&amp;quot;values&amp;quot;:[[&amp;quot;2016-08-31T08:38:37Z&amp;quot;,&amp;quot;something&amp;quot;,23]]}]}]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://192.168.99.100:30003&#34;&gt;http://192.168.99.100:30003&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;admin/adminでログインしてDataSourceに&lt;code&gt;http://192.168.99.100:30005&lt;/code&gt;のInfluxDBを設定すると、
Dashboardにグラフやテーブルなどを置いて表示させることができるようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/19_grafana.png&#34; alt=&#34;grafanaのDashboard&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;1秒以内に複数のログが発生する場合-2016-11-07&#34;&gt;1秒以内に複数のログが発生する場合 (2016-11-07)&lt;/h2&gt;

&lt;p&gt;時系列DBであるinfluxdbは同じタイムスタンプで複数のデータを持つことができない。
fluentdはv0.14からナノ秒でタイムスタンプを持つようになったので、これを利用することで1秒以内に発生するログも
正常に処理できるようになる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/32&#34;&gt;td-agentをビルドしてfluentdのバージョンを上げる&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;fluent-plugin-influxdbのtime_precisionはデフォルトでs(秒)になっているが、
これをns(ナノ秒)にしただけでは、(現時点では)秒のままのタイムスタンプが送られるのでうまくいかない。
そのため、以下のようにナノ秒を取れる場合はそれを使い、そうでない場合は無視するように修正した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nstime = time * (10 ** 9) + (defined?(Fluent::EventTime) ? time.nsec : 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/fangli/fluent-plugin-influxdb/pull/62&#34;&gt;プルリク&lt;/a&gt;は出した。
自分のプラグインはこんな感じで使うことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;td-agent-gem install specific_install &amp;amp;&amp;amp; \
td-agent-gem specific_install https://github.com/sambaiz/fluent-plugin-influxdb.git
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GKEで複数コンテナのアプリケーションを動かす</title>
          <link>https://www.sambaiz.net/article/18/</link>
          <pubDate>Fri, 26 Aug 2016 21:57:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/18/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/17&#34;&gt;前回&lt;/a&gt;は単一コンテナのアプリケーションを動かしたが、今回はコンテナ間でやり取りが発生するものを動かす。
流れとしては、クライアントからのリクエストを&lt;code&gt;GATEWAY&lt;/code&gt;サーバーで受け取り、&lt;code&gt;SERVICE&lt;/code&gt;サーバーにリクエストし、その結果を返すまで。&lt;/p&gt;

&lt;p&gt;プログラムは以下の通り、環境変数&lt;code&gt;TYPE&lt;/code&gt;の値によって挙動を変えていて、同じイメージを使い回す。コードは&lt;a href=&#34;https://github.com/sambaiz/gke-multi-container-app&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var http = require(&#39;http&#39;);
var handleRequest = function(request, response) {
  if(process.env.TYPE == &amp;quot;GATEWAY&amp;quot;){
    console.log(&#39;Passed.&#39;);
    var options = {
      host: &#39;service&#39;,
      port: 8080,
      method: &#39;GET&#39;
    };
    var req = http.request(options, function(res) {
      data = &amp;quot;&amp;quot;
      res.on(&#39;data&#39;, function (chunk) {
        data+=chunk;
      });

      res.on(&#39;end&#39;, () =&amp;gt; {
        response.writeHead(200);
        response.end(data);
      });
    });
    req.on(&#39;error&#39;, function(e) {
      response.writeHead(500)
      response.end(e.message);
    });
    req.end();
  }else{
    console.log(&#39;Received.&#39;);
    response.writeHead(200);
    response.end(&#39;ok&#39;);
  }
};
var www = http.createServer(handleRequest);
www.listen(8080);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをContainer RegistryにPushする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export PROJECT_ID=&amp;quot;gcp-test-141011&amp;quot;
$ docker build -t gcr.io/$PROJECT_ID/multitest:v1 .
$ gcloud docker push gcr.io/$PROJECT_ID/multitest:v1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ローカルで試すためにminikubeを起動。コンテキストがminikubeに設定される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ minikube start
$ kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;minikubeでContainer Registryから取得できるようにsecretを作成する。
ローカルでビルドしたimageを使うこともできる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/151/&#34;&gt;ローカルでビルドしたimageをminikubeで使う - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create secret docker-registry myregistrykey --docker-server=https://gcr.io --docker-username=oauth2accesstoken --docker-password=&amp;quot;$(gcloud auth print-access-token)&amp;quot; --docker-email=***
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず、以下の&lt;code&gt;service_deployment.yaml&lt;/code&gt;でDeploymentを作成する。
envのところで環境変数&lt;code&gt;TYPE&lt;/code&gt;を&lt;code&gt;SERVICE&lt;/code&gt;に設定した。
また、先ほど作成したsecretを&lt;code&gt;imagePullSecrets&lt;/code&gt;で指定し、
ローカルのminikube環境でContainer Registryから取得できるようにしている。
同様に&lt;code&gt;gateway_deployment.yaml&lt;/code&gt;でも作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: service
  labels:
    app: service
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: service
    spec:
      containers:
      - name: service
        image: gcr.io/gcp-test-141011/multitest:v1
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: TYPE
          value: SERVICE
        ports:
        - containerPort: 8080
      imagePullSecrets:
      - name: myregistrykey    
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f service_deployment.yaml
$ kubectl create -f gateway_deployment.yaml
$ kubectl get deployment
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
gateway   1         1         1            1           8m
service   1         1         1            1           28m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に、これを内部から呼べるようにするためのServiceを作成する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: service
  labels:
    app: service
spec:
  ports:
  - port: 8080
  selector:
    app: service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;GATEWAY&lt;/code&gt;の方は外に開くので、EXTERNAL IPが割り当てられるようにする。
ただ、minikubeでは&lt;code&gt;type: LoadBalancer&lt;/code&gt;に対応していないので代わりに&lt;code&gt;type: NodePort&lt;/code&gt;を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: gateway
  labels:
    app: gateway
spec:
  # type: LoadBalancer
  type: NodePort
  ports:
  - port: 8080
    nodePort: 30002
  selector:
    app: gateway
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f service_service.yaml
$ kubectl create -f gateway_service.yaml
$ kubectl get services
NAME            CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
gateway         10.0.0.176   &amp;lt;nodes&amp;gt;       8080/TCP   1h
service         10.0.0.111   &amp;lt;none&amp;gt;        8080/TCP   2d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;GATEWAY&lt;/code&gt;サーバーを越えて&lt;code&gt;SERVICE&lt;/code&gt;サーバーまで到達したことが確認できた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl 192.168.99.100:30002
ok

$ kubectl get pods
NAME                       READY     STATUS    RESTARTS   AGE
gateway-3043515563-a0tb5   1/1       Running   0          38m
service-2727435432-9glvb   1/1       Running   0          38m

$ kubectl logs service-2727435432-9glvb
Received.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一通り動いたのでこんなシェルスクリプトを書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash

context=`kubectl config current-context`
echo &amp;quot;${context}で実行します。よろしいですか[Y/N]&amp;quot;
read ANSWER
case $ANSWER in
    &amp;quot;Y&amp;quot; ) :;;
    * ) exit;;
esac
if [ $context = &amp;quot;minikube&amp;quot; ] ; then
  kubectl create -f yaml/gateway_service_minikube.yaml
  kubectl create -f yaml/service_deployment_minikube.yaml
  kubectl create -f yaml/gateway_deployment_minikube.yaml
else
  kubectl create -f yaml/gateway_service.yaml
  kubectl create -f yaml/service_deployment.yaml
  kubectl create -f yaml/gateway_deployment.yaml
fi
kubectl create -f yaml/service_service.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行するとこうなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud container clusters create multi-container-app
$ kubectl config current-context
gke_gcp-test-141011_asia-east1-b_multi-container-app

$ sh create.sh
gke_gcp-test-141011_asia-east1-b_multi-container-appで実行します。よろしいですか[Y/N]
Y
service &amp;quot;gateway&amp;quot; created
deployment &amp;quot;service&amp;quot; created
deployment &amp;quot;gateway&amp;quot; created
service &amp;quot;service&amp;quot; created

$ kubectl get service
NAME         CLUSTER-IP      EXTERNAL-IP       PORT(S)    AGE
gateway      10.83.254.5     104.199.206.147   8080/TCP   4m
service      10.83.255.118   &amp;lt;none&amp;gt;            8080/TCP   4m

$ curl 104.199.206.147:8080
ok
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Google Container Engine(GKE)で単一コンテナのアプリケーションを動かす</title>
          <link>https://www.sambaiz.net/article/17/</link>
          <pubDate>Sun, 21 Aug 2016 23:37:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/17/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://kubernetes.io/docs/hellonode/&#34;&gt;Kubernetes - Hello World Walkthrough&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;cloudsdkとkubectlのインストール&#34;&gt;CloudSDKとkubectlのインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/sdk/#Quick_Start&#34;&gt;Cloud SDKをインストール&lt;/a&gt;して&lt;code&gt;gloud&lt;/code&gt;コマンドを使えるようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud --version
Google Cloud SDK 122.0.0
$ gcloud components install kubectl
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;google-container-registryにpush&#34;&gt;Google Container RegistryにPush&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ export PROJECT_ID=&amp;quot;******&amp;quot;
$ docker build -t gcr.io/$PROJECT_ID/test:v1 .
$ gcloud docker push gcr.io/$PROJECT_ID/test:v1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プロジェクトの課金を有効にしていないとこんなエラーメッセージが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;denied: Unable to create the repository, please check that you have access to do so.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;clusterの作成&#34;&gt;Clusterの作成&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ gcloud config set core/project $PROJECT_ID
$ gcloud config set compute/zone asia-east1-b
$ gcloud container clusters create test-cluster
$ gcloud config set container/cluster test-cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Container Engine APIが有効になっていない場合はこうなる。
一度コンソールからContainer Engineを選ぶと、サービスの準備が始まって有効になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERROR: (gcloud.container.clusters.create) ResponseError: code=503, message=Project **** is not fully initialized with the default service accounts. Please try again later.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pod-とそのdeployment-の作成&#34;&gt;Pod(とそのDeployment)の作成&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl run test-node --image=gcr.io/$PROJECT_ID/test:v1 --port=8080
$ kubectl get deployments
NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
test-node   1         1         1            0           12s

$ kubectl get pods
NAME                         READY     STATUS              RESTARTS   AGE
test-node-1016577872-h7yiz   0/1       ContainerCreating   0          18s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;serviceを作成してクラスタの外からアクセスできるようにする&#34;&gt;Serviceを作成してクラスタの外からアクセスできるようにする&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;--type=&amp;quot;LoadBalancer&amp;quot;&lt;/code&gt;のServiceを作成すると外からアクセスできるようになる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/173/&#34;&gt;GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl expose deployment test-node --type=&amp;quot;LoadBalancer&amp;quot;
$ kubectl get services test-node
NAME        CLUSTER-IP     EXTERNAL-IP       PORT(S)    AGE
test-node   10.43.247.66   104.199.158.131   8080/TCP   1m
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;スケーリング&#34;&gt;スケーリング&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl scale deployment test-node --replicas=4
$ kubectl get deployment
NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
test-node   4         4         4            2           11m

$ kubectl get pods
NAME                         READY     STATUS              RESTARTS   AGE
test-node-1016577872-fso09   0/1       ContainerCreating   0          12s
test-node-1016577872-h7yiz   1/1       Running             0          11m
test-node-1016577872-sbdvl   1/1       Running             0          12s
test-node-1016577872-z9ji3   0/1       ContainerCreating   0          12s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;更新&#34;&gt;更新&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t gcr.io/$PROJECT_ID/test:v2 .
$ gcloud docker push gcr.io/$PROJECT_ID/test:v2
$ kubectl set image deployment/test-node test-node=gcr.io/$PROJECT_ID/test:v2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;削除&#34;&gt;削除&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl delete service,deployment test-node
$ gcloud container clusters delete test-cluster
$ gcloud config unset container/cluster
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>JenkinsのMultiple SCMs PluginからPipeline Pluginへの移行</title>
          <link>https://www.sambaiz.net/article/16/</link>
          <pubDate>Sat, 20 Aug 2016 16:18:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/16/</guid>
          <description>&lt;p&gt;Jenkins環境を作り直すことになり、
長らく使ってきた&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Multiple+SCMs+Plugin&#34;&gt;Multiple SCMs Plugin&lt;/a&gt;がDeprecatedなので、
&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Plugin&#34;&gt;Pipeline Plugin&lt;/a&gt;に移行することにした。&lt;/p&gt;

&lt;p&gt;プラグインをインストールすると、ジョブ作成時にPipelineを選択できるようになる。
Pipeline scriptの複数リポジトリを指定するところはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node {
   stage &#39;Checkout rep1&#39;
   git([url: &#39;git@rep1.git&#39;, branch: REP1_BRANCH])

   stage &#39;Checkout rep2&#39;
   dir(&#39;rep2&#39;) {
      git([url: &#39;git@rep2.git&#39;, branch: REP2_BRANCH])
   }

   stage &#39;Checkout rep3&#39;
   dir(&#39;subdir3/rep3&#39;) {
      git([url: &#39;git@rep3.git&#39;, branch: REP3_BRANCH])
   }

   stage &#39;Build&#39;
   ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まとめて入った&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Stage+View+Plugin&#34;&gt;Pipeline Stage View Plugin&lt;/a&gt;によって、
経過や変更などいろいろ見やすくなった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GolangでAPIとテストを書く(echo/dbr/glide/goose/mock)</title>
          <link>https://www.sambaiz.net/article/15/</link>
          <pubDate>Mon, 15 Aug 2016 04:07:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/15/</guid>
          <description>

&lt;p&gt;以下の記事を参考にして簡単なAPIとそのテストを書いてみた。コードは&lt;a href=&#34;https://github.com/sambaiz/go-api-with-test&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ameblo.jp/principia-ca/entry-12130127314.html&#34;&gt;Go言語でTestableなWebアプリケーションを目指して｜サイバーエージェント 公式エンジニアブログ&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;使った主なライブラリ-ツール&#34;&gt;使った主なライブラリ・ツール&lt;/h2&gt;

&lt;h3 id=&#34;echo-https-github-com-labstack-echo&#34;&gt;&lt;a href=&#34;https://github.com/labstack/echo&#34;&gt;echo&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;webフレームワーク。速いらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/labstack/echo
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    conn, err := dbr.Open(&amp;quot;mysql&amp;quot;, &amp;quot;root:@tcp(localhost:3306)/mboard&amp;quot;, nil)
    if err != nil {
        panic(err)
    }
    conn.SetMaxIdleConns(200)
    conn.SetMaxOpenConns(200)

    e := echo.New()

    // middlewares
    e.Use(middleware.Logger())
    e.Use(middleware.Recover())
    e.Use(middleware.CORSWithConfig(middleware.CORSConfig{
        AllowOrigins: []string{&amp;quot;*&amp;quot;},
        AllowMethods: []string{echo.GET, echo.PUT, echo.POST, echo.DELETE},
    }))

    // endpoints
    e.GET(&amp;quot;/&amp;quot;, func(c echo.Context) error {
		    return c.String(http.StatusOK, &amp;quot;Hello, World!&amp;quot;)
  	})
  	e.GET(&amp;quot;/messages&amp;quot;, func(c echo.Context) error {
  		  return handler.NewMessageWithSession(conn.NewSession(nil)).GetMessages(c)
  	})
  	e.POST(&amp;quot;/messages&amp;quot;, func(c echo.Context) error {
  		  return handler.NewMessageWithSession(conn.NewSession(nil)).CreateMessage(c)
  	})
    std := standard.New(&amp;quot;:1323&amp;quot;)
    std.SetHandler(e)
    gracehttp.Serve(std.Server)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dbr-https-github-com-gocraft-dbr&#34;&gt;&lt;a href=&#34;https://github.com/gocraft/dbr&#34;&gt;dbr&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;database/sql&lt;/code&gt;を強化したもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/gocraft/dbr
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;res, err := t.sess.InsertInto(&amp;quot;message&amp;quot;).Columns(&amp;quot;content&amp;quot;).Record(model.Message{Content: content}).Exec()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;glide-https-github-com-masterminds-glide&#34;&gt;&lt;a href=&#34;https://github.com/Masterminds/glide&#34;&gt;glide&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;パッケージ管理ツール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install glide
$ glide create
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で&lt;code&gt;glide.yaml&lt;/code&gt;が作られる。&lt;code&gt;glide get&lt;/code&gt;で&lt;code&gt;glide.yaml&lt;/code&gt;に追加していったり、
&lt;code&gt;glide install&lt;/code&gt;でvendor下にインストールしたりする。&lt;/p&gt;

&lt;h3 id=&#34;goose-https-bitbucket-org-liamstask-goose&#34;&gt;&lt;a href=&#34;https://bitbucket.org/liamstask/goose&#34;&gt;goose&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;DBマイグレーションツール。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;db/dbconf.yml&lt;/code&gt;に以下のようなyamlファイルを置いて&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;development:
  driver: mymysql
  open: tcp:localhost:3306*bbs_go/root/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;goose create&lt;/code&gt;でマイグレーションファイルを作成する。これはgoかsqlで書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get bitbucket.org/liamstask/goose/cmd/goose
$ goose create CreateMessages sql
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;
-- +goose Up
-- SQL in section &#39;Up&#39; is executed when this migration is applied
CREATE TABLE message (
  id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,
  content TEXT NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- +goose Down
-- SQL section &#39;Down&#39; is executed when this migration is rolled back
DROP TABLE message;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ goose up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/149/&#34;&gt;Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;テストの書き方&#34;&gt;テストの書き方&lt;/h2&gt;

&lt;p&gt;参考にした記事と同じく、handler, service, daoで構成し、
それぞれのコンストラクタの引数に直下のレイヤーのインタフェースを取ることでDIする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewMessage(tx dao.Tx, messageDao dao.Message) *MessageImpl {
	return &amp;amp;MessageImpl{tx: tx, messageDao: messageDao}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
テスト時には&lt;a href=&#34;https://github.com/golang/mock&#34;&gt;mock&lt;/a&gt;を渡す。
&lt;code&gt;mockgen&lt;/code&gt;でmockを生成し、以下のようにして入力と出力を指定することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/golang/mock/gomock
$ go get github.com/golang/mock/mockgen
$ mockgen -package dao -source message.go -destination message_mock.go
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ctl := gomock.NewController(t)
defer ctl.Finish()

message := model.Message{ID: 1, Content: &amp;quot;メッセージ&amp;quot;}
messageDaoMoc := dao.NewMockMessage(ctl)
messageDaoMoc.EXPECT().Create(message.Content).Return(int64(1), nil)
messageDaoMoc.EXPECT().FindById(message.ID).Return(&amp;amp;message, nil)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;何も指定しないと1回も呼ばれなかったり、2回以上呼ばれるとエラーになるが、
&lt;a href=&#34;https://godoc.org/github.com/golang/mock/gomock#Call.MinTimes&#34;&gt;MinTimes()&lt;/a&gt;などで柔軟に書くこともできる。
とはいえmockの内容によっては無理にgomockを使うと真にテストしたいことが埋もれてしまうことがあるので、
あくまでmockを作る選択肢の一つとして考えておくと良いと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>O&#39;Reillyの「マイクロサービスアーキテクチャ」を読んだ</title>
          <link>https://www.sambaiz.net/article/14/</link>
          <pubDate>Sat, 06 Aug 2016 18:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/14/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873117607/&#34;&gt;O&amp;rsquo;Reilly Japan - マイクロサービスアーキテクチャ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;設計、開発、テストや監視など一通りまとまっているマイクロサービスアーキテクチャの本。&lt;/p&gt;

&lt;p&gt;マイクロサービスアーキテクチャというのは、協調して動作する小規模で自律的なサービスでシステムを構成するもので、
一般的なモノリシック(一枚岩)システムのモジュールのように独立したサービスを作っていく。
自律的というのは、他には何も変更せずに、単独でサービスの変更やデプロイを行えるということ。&lt;/p&gt;

&lt;p&gt;メリットとしては&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;サービスごとに異なる技術を使うことができる&lt;/li&gt;
&lt;li&gt;一部のサービスで障害が発生しても、機能低下させて稼働し続けるシステムを構築できる&lt;/li&gt;
&lt;li&gt;性能を高める必要があるサービスだけをスケールでき、効率的にリソースを使うことができる&lt;/li&gt;
&lt;li&gt;デプロイのリスクを最小限に抑えることができるため、迅速に行うことができる&lt;/li&gt;
&lt;li&gt;レガシーなコードを捨て去る障壁が低い&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;などが挙げられていた。&lt;/p&gt;

&lt;p&gt;正しくサービスを切り分けるにはドメインの理解が必要で、「境界づけられたコンテキスト」が1つのサービスとなるようにする。
そのため、最初はモノシリックに進めることも推奨されていた。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;特に初めてのドメインでは、システムをマイクロサービスに分解するのが時期尚早だとコストがかかってしまう場合があります。いろいろな意味で、マイクロサービスに分解したい既存のコードベースがある方が、最初からマイクロサービスに取り組むよりもはるかに簡単です (3.3.3)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;実現する上で、DBの扱いが難しいと思った。
サービス間のDBの共有はスキーマの変更に弱く、技術の縛りが発生してしまうので避けなければならない。
一方で、DBを分割すると1つのトランザクションで完結しなくなり、どのように整合性を保っていくか。
そんな話が5章に書いてあって、いくつか方法は挙げられているが、いずれにせよ何かしらの制御をしなくてはいけないし、
データの取得の上でも一つのデータベースにあったほうが便利だったりする。
サービスの単位がデータに引きずられてしまうと、マイクロサービスとはいえないものが出来上がりそうだ。
きれいに分けられればいいけど実際どうなんだろう。&lt;/p&gt;

&lt;p&gt;すぐにマイクロサービスを採用するかは別としても、考え方として活かせそうなことが多かった。
実際にやってみて、また読み返して自分のものにしていこうと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Tensorflowの学習データを使ったAPIを作る</title>
          <link>https://www.sambaiz.net/article/13/</link>
          <pubDate>Fri, 05 Aug 2016 22:08:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/13/</guid>
          <description>

&lt;p&gt;チュートリアルのMNISTの学習データを使って、手書き数字画像のデータを受け取り、数字を返すAPIを作る。
コードは&lt;a href=&#34;https://github.com/sambaiz/tensorflow-use-api-sample&#34;&gt;ここ&lt;/a&gt;にある。&lt;/p&gt;

&lt;h2 id=&#34;学習して結果を保存する&#34;&gt;学習して結果を保存する&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/6&#34;&gt;前回&lt;/a&gt;の学習結果のcheckpointファイルを出力する。
&lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/train/Saver#save&#34;&gt;tf.train.Saver().save&lt;/a&gt;でnameで対応するVariableの値が保存できる。
また、その際&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/training/saver.py#L1560&#34;&gt;デフォルト&lt;/a&gt;で&lt;a href=&#34;https://www.tensorflow.org/api_guides/python/meta_graph&#34;&gt;MetaGraph&lt;/a&gt;もexportされ、これをimportすればGraphも復元することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

class Mnist:

    def __init__(self):

        g = tf.Graph()

        with g.as_default():

            W_conv1 = self._weight_variable([5, 5, 1, 32],  &amp;quot;W_conv1&amp;quot;)
            b_conv1 = self._bias_variable([32],  &amp;quot;b_conv1&amp;quot;)

            self._x = tf.placeholder(tf.float32, [None, 784])
            x_image = tf.reshape(self._x, [-1,28,28,1])

            h_conv1 = tf.nn.relu(self._conv2d(x_image, W_conv1) + b_conv1)
            h_pool1 = self._max_pool_2x2(h_conv1)

            W_conv2 = self._weight_variable([5, 5, 32, 64],  &amp;quot;W_conv2&amp;quot;)
            b_conv2 = self._bias_variable([64],  &amp;quot;b_conv2&amp;quot;)

            h_conv2 = tf.nn.relu(self._conv2d(h_pool1, W_conv2) + b_conv2)
            h_pool2 = self._max_pool_2x2(h_conv2)

            W_fc1 = self._weight_variable([7 * 7 * 64, 1024],  &amp;quot;W_fc1&amp;quot;)
            b_fc1 = self._bias_variable([1024],  &amp;quot;b_fc1&amp;quot;)

            h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

            self._keep_prob = tf.placeholder(tf.float32)
            h_fc1_drop = tf.nn.dropout(h_fc1, self._keep_prob)

            W_fc2 = self._weight_variable([1024, 10],  &amp;quot;W_fc2&amp;quot;)
            b_fc2 = self._bias_variable([10],  &amp;quot;b_fc2&amp;quot;)

            y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
            self._what_number = tf.argmax(y_conv, 1)

            self._y_ = tf.placeholder(tf.float32, [None, 10])
            cross_entropy = tf.reduce_mean(-tf.reduce_sum(self._y_ * tf.log(y_conv), reduction_indices=[1]))
            self._train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
            correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(self._y_,1))
            self._accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

            self.sess = tf.Session()
            init = tf.initialize_all_variables()
            self.sess.run(init)
            self._saver = tf.train.Saver()

    def save(self, ckpt_file_name):
        self._saver.save(self.sess, ckpt_file_name)

    def restore(self, ckpt_file_name):
        self._saver.restore(self.sess, ckpt_file_name)

    def what_number(self, image_array):
        return self.sess.run(self._what_number, feed_dict={self._x: image_array, self._keep_prob: 1.0})

    def train(self, num):
        if not hasattr(self, &amp;quot;_mnist&amp;quot;):
            self._mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)

        for i in range(num):
            batch = self._mnist.train.next_batch(50)
            if i%100 == 0:
              train_accuracy = self._accuracy.eval(session=self.sess, feed_dict={
                      self._x:batch[0], self._y_: batch[1], self._keep_prob: 1.0
                  })
              print(&amp;quot;step %d, training accuracy %g&amp;quot;%(i, train_accuracy))
            self.sess.run(self._train_step, feed_dict={self._x: batch[0], self._y_: batch[1], self._keep_prob: 0.5})

        print(&amp;quot;test accuracy %g&amp;quot;%self._accuracy.eval(session=self.sess, feed_dict={
                self._x: self._mnist.test.images, self._y_: self._mnist.test.labels, self._keep_prob: 1.0
            }))

    def close(self):
        self.sess.close()

    def _weight_variable(self, shape, name):
      initial = tf.truncated_normal(shape, stddev=0.1)
      return tf.Variable(initial, name=name)

    def _bias_variable(self, shape, name):
      initial = tf.constant(0.1, shape=shape)
      return tf.Variable(initial, name=name)

    def _conv2d(self, x, W):
      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;)

    def _max_pool_2x2(self, x):
      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1], padding=&#39;SAME&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;train&lt;/code&gt;で学習し、&lt;code&gt;save&lt;/code&gt;でチェックポイントファイルを保存できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from mnist import Mnist

mnist = Mnist()
mnist.train(20000)
mnist.save(&amp;quot;model.ckpt&amp;quot;)
mnist.close()
print(&amp;quot;done&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なので、例えばこんなDockerfileを書いて&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM gcr.io/tensorflow/tensorflow

ADD training.py /
ADD mnist.py /

CMD python /training.py &amp;amp;&amp;amp; /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しばらく待つ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t training .
$ docker run -itd training
$ docker logs -f &amp;lt;CONTAINER_ID&amp;gt;
$ docker cp &amp;lt;CONTAINER_ID&amp;gt;:/notebooks/model.ckpt .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;学習データを使う&#34;&gt;学習データを使う&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;tf.train.Saver().restore&lt;/code&gt;でチェックポイントファイルを読み、Variableの値を復元できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from flask import Flask, request, jsonify
import tensorflow as tf
from mnist import Mnist

app = Flask(__name__)

mnist = Mnist()
mnist.restore(&amp;quot;/model.ckpt&amp;quot;)

@app.route(&amp;quot;/&amp;quot;, methods=[&#39;POST&#39;])
def what_number():

    json = request.json
    if(json is None or &amp;quot;image&amp;quot; not in json or len(json[&amp;quot;image&amp;quot;]) != 784):
        return jsonify(error=&amp;quot;Need json includes image property which is 784(28 * 28) length, float([0, 1.0]) array&amp;quot;)
    else:
        result = list(mnist.what_number([json[&amp;quot;image&amp;quot;]]))
        return jsonify(result=result[0])

if __name__ == &amp;quot;__main__&amp;quot;:
    app.run(port=3000, host=&#39;0.0.0.0&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これもDockerで動かすならこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM gcr.io/tensorflow/tensorflow

ADD requirements.txt /tmp
ADD model.ckpt /
ADD training/mnist.py /
ADD app.py /

RUN pip install -q -r /tmp/requirements.txt

EXPOSE 3000

CMD [&amp;quot;python&amp;quot;, &amp;quot;/app.py&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t tensor_api .
$ docker run -itd -p 3000:3000 tensor_app
$ docker logs -f &amp;lt;CONTAINER_ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これに以下のようにして28*28の画像のデータを渡すと、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;image&amp;quot;: [ ..., 0.32941177, 0.72549021, 0.62352943, ...]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それが何の数字なのかが返ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;result&amp;quot;: 7
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;(追記 2018-07-25)&lt;/p&gt;

&lt;p&gt;この記事ではcheckpointをそのまま使っているが、モデルを公開する際はSaverをwrapしたSavedModelにするのが&lt;a href=&#34;https://github.com/tensorflow/tensorflow/tree/r1.9/tensorflow/python/saved_model#background&#34;&gt;標準的&lt;/a&gt;だ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/172/&#34;&gt;TensorFlowのモデルをsave/loadする - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Googleが作ったRPCフレームワークgRPCを使ってみた</title>
          <link>https://www.sambaiz.net/article/12/</link>
          <pubDate>Fri, 29 Jul 2016 22:00:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/12/</guid>
          <description>

&lt;blockquote&gt;
&lt;p&gt;A high performance, open source, general RPC framework that puts mobile and HTTP/2 first.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;what-is-grpc-http-www-grpc-io-docs-what-is-grpc&#34;&gt;&lt;a href=&#34;http://www.grpc.io/docs/#what-is-grpc&#34;&gt;What is gRPC?&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;gRPCを使うと、クライアントアプリケーションは直接ローカルのオブジェクトのように、他のマシンのサーバーアプリケーションのメソッドを呼ぶことができ、
分散したアプリケーションやサービスを簡単に作ることができる。
多くのRPCシステムと同様にgRPCはサービスを定義し、リモートから呼べるメソッドとそのパラメーターおよび返り値の型を記述するようになっている。
サーバーサイドではインタフェースを実装し、クライアントからの呼び出しをハンドリングするgRPCサーバーを実行する。
クライアントサイドではサーバーと同じメソッドを提供するスタブを持っている。&lt;/p&gt;

&lt;p&gt;gRPCクライアントとサーバーは様々な環境同士でやり取りすることができ、いくつもの言語でサポートされている。
そのため例えば、gRPCサーバーをJavaでクライアントをGoやPython、Rubyで作るのも可能だ。
加えて、最新のGoodle APIにはgRPCのインタフェースが存在するので、これらをアプリケーションに組み込むのも容易にできる。&lt;/p&gt;

&lt;h2 id=&#34;protobuf&#34;&gt;Protobuf&lt;/h2&gt;

&lt;p&gt;デフォルトではgRPCはprotobuf(protocol buffers)でやり取りする。
&lt;a href=&#34;https://github.com/google/protobuf&#34;&gt;protobuf&lt;/a&gt;というのは、
Googleによるオープンソースのシリアライズフォーマット。&lt;/p&gt;

&lt;p&gt;今回作るのは、同じ文字列を返すだけのEchoサーバーで、コードは&lt;a href=&#34;https://github.com/sambaiz/try-gRPC&#34;&gt;ここ&lt;/a&gt;にある。
以下のprotoファイルでは、&lt;code&gt;Echo&lt;/code&gt;というサービスは&lt;code&gt;RetEcho&lt;/code&gt;というメソッドを含み、
これは文字列&lt;code&gt;say&lt;/code&gt;を含む&lt;code&gt;EchoRequest&lt;/code&gt;に対して、文字列&lt;code&gt;ret&lt;/code&gt;を含む&lt;code&gt;EchoReply&lt;/code&gt;を返すということを表している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;syntax = &amp;quot;proto3&amp;quot;;

option java_package = &amp;quot;net.sambaiz.trygrpc.protos&amp;quot;;

package protos;

service Echo {
  rpc RetEcho (EchoRequest) returns (EchoReply) {}
}

message EchoRequest {
  string say = 1;
}

message EchoReply {
  string ret = 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;code&gt;protoc&lt;/code&gt;でコンパイルすると&lt;code&gt;echo.pb.go&lt;/code&gt;のようなコードが生成される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install --devel protobuf # install Install Protocol Compiler v3.0.0-beta-2
$ go get -u github.com/golang/protobuf/protoc-gen-go # Install Go Protobuf Runtime Installation
$ protoc --go_out=plugins=grpc:protos/. protos/*.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;サーバー&#34;&gt;サーバー&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ go get google.golang.org/grpc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;protoファイルに書いたRetEchoを実装し、サーバーを立ち上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;golang.org/x/net/context&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;net&amp;quot;
	&amp;quot;log&amp;quot;
	pb &amp;quot;github.com/sambaiz/try-gRPC/protos&amp;quot;
)

const (
	port = &amp;quot;:50051&amp;quot;
)

type server struct{}

func (s *server) RetEcho(ctx context.Context, in *pb.EchoRequest) (*pb.EchoReply, error) {
	return &amp;amp;pb.EchoReply{Ret: in.Say}, nil
}

func main() {
	lis, err := net.Listen(&amp;quot;tcp&amp;quot;, port)
	if err != nil {
		log.Fatalf(&amp;quot;failed to listen: %v&amp;quot;, err)
	}
	s := grpc.NewServer()
	pb.RegisterEchoServer(s, &amp;amp;server{})
	log.Printf(&amp;quot;server start localhost%s&amp;quot;, port)
	s.Serve(lis)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/174/&#34;&gt;GoのgRPC ServerのInterceptor(recovery/auth/zap/prometheus) - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;クライアント&#34;&gt;クライアント&lt;/h2&gt;

&lt;p&gt;サーバーに接続すると、他のメソッドと同じようにサーバー側の&lt;code&gt;RetEcho&lt;/code&gt;メソッドを呼び出すことができるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;log&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;golang.org/x/net/context&amp;quot;
	pb &amp;quot;github.com/sambaiz/try-gRPC/protos&amp;quot;

)

const (
	address = &amp;quot;localhost:50051&amp;quot;
)

func main() {
	conn, err := grpc.Dial(address, grpc.WithInsecure())
	if err != nil {
		log.Fatalf(&amp;quot;did not connect: %v&amp;quot;, err)
	}
	defer conn.Close()
	c := pb.NewEchoClient(conn)

	r, err := c.RetEcho(context.Background(), &amp;amp;pb.EchoRequest{Say: &amp;quot;hello&amp;quot;})
	if err != nil {
		log.Fatalf(&amp;quot;Error: %v&amp;quot;, err)
	}
	log.Printf(&amp;quot;Return: %s&amp;quot;, r.Ret)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最新のprotoファイルを共有すれば、どんな言語で書いても自分で型を定義したり、呼び出すロジックを書く必要がないし、
インタフェースが変わったときにコードレベルでエラーに気づけるのは通常のAPIリクエストと比較して良い点だと思う。
ロジックが複数のサーバーに渡る場合の負担を最小限にできるため、サービスを小さく作るマイクロサービスアーキテクチャで使われるが、性能や管理のしやすさなどの面でもメリット/デメリットはある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/14&#34;&gt;O&amp;rsquo;Reillyの「マイクロサービスアーキテクチャ」を読んだ - sambaiz-net&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLで大文字小文字を区別しないのを直す</title>
          <link>https://www.sambaiz.net/article/11/</link>
          <pubDate>Sun, 24 Jul 2016 22:12:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/11/</guid>
          <description>&lt;p&gt;Collationの話。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MySQL 5.6
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE sample (
  id SERIAL,
  name VARCHAR(30)
) ENGINE=InnoDB CHARACTER SET utf8mb4;

INSERT INTO sample (name) VALUES (&#39;tom&#39;),(&#39;Tom&#39;),(&#39;TOM&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このテーブルを&amp;rdquo;tom&amp;rdquo;で絞り込むとこうなる。大文字小文字を区別していない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SELECT * FROM sample2 WHERE name = &#39;tom&#39;;
+----+------+
| id | name |
+----+------+
|  1 | tom  |
|  2 | Tom  |
|  3 | TOM  |
+----+------+
3 rows in set (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/case-sensitivity.html&#34;&gt;MySQL :: MySQL 5.6 リファレンスマニュアル :: B.5.5.1 文字列検索での大文字/小文字の区別&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;単純な比較操作 (&amp;gt;=、&amp;gt;、=、&amp;lt;、&amp;lt;=、ソート、およびグループ化) は、各文字の「ソート値」に基づきます。
同じソート値を持つ文字は同じ文字として扱われます。たとえば、「e」 と 「é」 が対象の照合順序で同じソート値を持つ場合は、等しいと判断されます。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.mysql.com/doc/refman/5.6/ja/charset-mysql.html&#34;&gt;MySQL :: MySQL 5.6 リファレンスマニュアル :: 10.1.2 MySQL での文字セットと照合順序&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;照合順序名には、関連する文字セットの名前で始まる、通常は言語名を含む、
_ci (大文字と小文字を区別しない)、_cs (大文字と小文字を区別する)、_bin (バイナリ)
のいずれかで終わる、という規則が適用されます。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ciはcase-insensitive、csというのはcase-sensitiveの略だ。
照合順序(Collation)を&lt;code&gt;SHOW FULL COLUMNS FROM sample&lt;/code&gt;で確認したところ、確かに区別しない&lt;code&gt;utf8mb4_general_ci&lt;/code&gt;となっていた。
これは、文字コード&lt;code&gt;utf8mb4&lt;/code&gt;のデフォルトの照合順序だ。(&lt;code&gt;SHOW CHARACTER SET&lt;/code&gt;で確認できる)&lt;/p&gt;

&lt;p&gt;それなら&lt;code&gt;utf8mb4_general_cs&lt;/code&gt;というのがあるんだなと、&lt;code&gt;SHOW COLLATION LIKE &#39;utf8mb4%&#39;&lt;/code&gt;で確認してみたが、
そんなものはなかった。どうやら区別させるためには&lt;code&gt;utf8mb4_bin&lt;/code&gt;を使うのが正解みたいで、これをCOLLATEで指定してやるか、
カラム単位でBINARYとすると、照合順序が&lt;code&gt;utf8mb4_bin&lt;/code&gt;となり、期待通りの結果が得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE sample2 (
  id SERIAL,
  name VARCHAR(30)
) ENGINE=InnoDB CHARACTER SET utf8mb4 COLLATE utf8mb4_bin;

CREATE TABLE sample3 (
  id SERIAL,
  name VARCHAR(30) BINARY
) ENGINE=InnoDB CHARACTER SET utf8mb4;

ALTER TABLE sample MODIFY name VARCHAR(30) BINARY;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SELECT * FROM sample2 WHERE name = &#39;tom&#39;;
+----+------+
| id | name |
+----+------+
|  1 | tom  |
+----+------+
1 row in set (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>グラフデータベースNeo4jを触ってみた</title>
          <link>https://www.sambaiz.net/article/10/</link>
          <pubDate>Thu, 21 Jul 2016 09:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/10/</guid>
          <description>

&lt;p&gt;社内勉強会で&lt;a href=&#34;https://github.com/neo4j/neo4j&#34;&gt;オープンソース&lt;/a&gt;の
グラフデータベース&lt;a href=&#34;https://neo4j.com/&#34;&gt;Neo4j&lt;/a&gt;が紹介されていたので触ってみた。&lt;/p&gt;

&lt;h2 id=&#34;what-is-a-graph-database-https-neo4j-com-developer-graph-database&#34;&gt;&lt;a href=&#34;https://neo4j.com/developer/graph-database/&#34;&gt;What is a Graph Database?&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;つながりも含めたグラフとしてデータを扱うデータベース。
データセットのサイズによらず、複雑なつながりや、クエリをうまく扱える。
無数のデータの中から、関係ないデータを見ることなく多数のノードとつながりからなる必要なデータだけを取れる。&lt;/p&gt;

&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://neo4j.com/download/&#34;&gt;ここ&lt;/a&gt;からCommunity Editionを選んで
OSごとに用意されている実行ファイルをダウンロードしてくる。
ファイルを実行し、Startを押すとブラウザで開けるようになる。&lt;/p&gt;

&lt;h2 id=&#34;グラフ&#34;&gt;グラフ&lt;/h2&gt;

&lt;p&gt;グラフは以下の要素から構成される。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Node: データそのもので、まとめるためのラベルを複数付けられる&lt;/li&gt;
&lt;li&gt;Relationships: typeを持つ、Nodeのつながり&lt;/li&gt;
&lt;li&gt;Properties: NodeやRelationshipsが持てるkey-valueの値&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cypher&#34;&gt;Cypher&lt;/h2&gt;

&lt;p&gt;Neo4jで使うクエリ言語。&lt;/p&gt;

&lt;p&gt;まずはCREATE文でNodeを作る。Personはラベルだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE (ee:Person { name: &amp;quot;Emil&amp;quot;, from: &amp;quot;Sweden&amp;quot;, klout: 99 })
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CREATE文では使われていなかった謎のeeだが、MATCH文を見るとデータが格納される変数だということがわかる。
このeeは次のCREATE文でも参照できて、&lt;code&gt;(ee)-[:KNOWS {since: 2001}]-&amp;gt;(js)&lt;/code&gt;で
作ったNodeとのRelationshipsを張るのに使っている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MATCH (ee:Person) WHERE ee.name = &amp;quot;Emil&amp;quot; RETURN ee;

CREATE (js:Person { name: &amp;quot;Johan&amp;quot;, from: &amp;quot;Sweden&amp;quot;, learn: &amp;quot;surfing&amp;quot; }),
(ir:Person { name: &amp;quot;Ian&amp;quot;, from: &amp;quot;England&amp;quot;, title: &amp;quot;author&amp;quot; }),
(rvb:Person { name: &amp;quot;Rik&amp;quot;, from: &amp;quot;Belgium&amp;quot;, pet: &amp;quot;Orval&amp;quot; }),
(ally:Person { name: &amp;quot;Allison&amp;quot;, from: &amp;quot;California&amp;quot;, hobby: &amp;quot;surfing&amp;quot; }),
(ee)-[:KNOWS {since: 2001}]-&amp;gt;(js),(ee)-[:KNOWS {rating: 5}]-&amp;gt;(ir),
(js)-[:KNOWS]-&amp;gt;(ir),(js)-[:KNOWS]-&amp;gt;(rvb),
(ir)-[:KNOWS]-&amp;gt;(js),(ir)-[:KNOWS]-&amp;gt;(ally),
(rvb)-[:KNOWS]-&amp;gt;(ally)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のようにパターンマッチもできる。この例だとEmilの友達が取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MATCH (ee:Person)-[:KNOWS]-(friends)
WHERE ee.name = &amp;quot;Emil&amp;quot; RETURN ee, friends
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必ずしも変数に入れなくても良く、&lt;code&gt;()&lt;/code&gt;のように無視することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MATCH (js:Person)-[:KNOWS]-()-[:KNOWS]-(surfer)
WHERE js.name = &amp;quot;Johan&amp;quot; AND surfer.hobby = &amp;quot;surfing&amp;quot;
RETURN DISTINCT surfer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最短経路を取得するのも簡単だ。&lt;code&gt;[*1..4]&lt;/code&gt;にして、ホップ数に制限をかけたり、範囲を指定したりすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MATCH p=shortestPath(
  (bacon:Person {name:&amp;quot;Kevin Bacon&amp;quot;})-[*]-(meg:Person {name:&amp;quot;Meg Ryan&amp;quot;})
)
RETURN p
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もちろんSQLの&lt;code&gt;LIMIT&lt;/code&gt;や&lt;code&gt;ORDER BY&lt;/code&gt;、&lt;code&gt;GROUP BY&lt;/code&gt;相当のこともできる。
文法が直感的に分かりやすいものになっていて良いと思った。&lt;/p&gt;

&lt;h2 id=&#34;欠点&#34;&gt;欠点&lt;/h2&gt;

&lt;p&gt;とにかくSQLのJOIN地獄から脱出できそうなのが大きくて、それだけで採用したい気になってしまうが、
データの総量とは関係なく一つのNodeに大量にRelationshipsが付くと非常に遅くなるという問題があるらしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cyberagent.co.jp/technology/ca_tech/report/8980456.html&#34;&gt;【CyberAgent】技術情報／TechReport - テックレポート／MongoDB de GraphDB | 株式会社サイバーエージェント&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;なぜかというと隣接Node/RelationshipsのポインタをLinkedListで持っているからみたいだ。これは苦しい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://the.igreque.info/posts/2014-06-08-neo4j.html&#34;&gt;igreque : Info -&amp;gt; Neo4jについてちょちょいと調べたまとめ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;電車の路線のように一つのNodeに対して高々いくつかのRelationshipsしかつながらないことが分かっている場合には問題ないので、
そういうモデルを作るか、あるいはデータの数を絞るか、使うにあたって工夫が必要そうだ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesのチュートリアルをたどる</title>
          <link>https://www.sambaiz.net/article/9/</link>
          <pubDate>Mon, 18 Jul 2016 22:22:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/9/</guid>
          <description>

&lt;h2 id=&#34;kubernetesとは-http-kubernetes-io-docs-whatisk8s&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/whatisk8s/&#34;&gt;Kubernetesとは&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Kubernetes(発音は&lt;a href=&#34;https://cloudplatform.googleblog.com/2014/06/an-update-on-container-support-on-google-cloud-platform.html&#34;&gt;koo-ber-nay&amp;rsquo;-tace&lt;/a&gt;。
ギリシャ語で操舵手。)はGoogleによって開発が始められた、アプリケーションコンテナにおける自動デプロイ、スケーリング、操作を
自動化するOSS。K8sと略される。&lt;/p&gt;

&lt;h2 id=&#34;minikube-https-github-com-kubernetes-minikube&#34;&gt;&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;Minikube&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;K8sをローカルで試すために、MinikubeというVMの中で単一ノードのK8sクラスターを動かすツールを入れる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/minikube/releases/tag/v0.6.0&#34;&gt;v0.6.0&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.6.0/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ minikube start
Starting local Kubernetes cluster...

...

$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;2&amp;quot;, GitVersion:&amp;quot;v1.2.4&amp;quot;, GitCommit:&amp;quot;3eed1e3be6848b877ff80a93da3785d9034d0a4f&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;3&amp;quot;, GitVersion:&amp;quot;v1.3.0&amp;quot;, GitCommit:&amp;quot;283137936a498aed572ee22af6774b6fb6e9fd94&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pods-http-kubernetes-io-docs-user-guide-walkthrough-pods&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/#pods&#34;&gt;Pods&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;K8sではコンテナのグループをpodと呼ぶ。pod中のコンテナは共にデプロイされ、起動し、停止する。
また、グループとして複製される。&lt;/p&gt;

&lt;p&gt;Podの定義は以下のようにyamlで書かれる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.7.9
    ports:
    - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podの定義に望ましい状態を記述すると、Kubernatesはそれを見て現在の状態が一致しているかどうか確認する。
例えば、Podが作られたときに、コンテナがその中で動いている状態が望ましい状態だとすると、
コンテナが動かなくなったときに、Kubernatesは新しいものを再作成することで望ましい状態にする。&lt;/p&gt;

&lt;p&gt;podの作成とリストの取得のコマンドは以下の通り。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f nginx.yaml
$ kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          4s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl exec&lt;/code&gt;でps&lt;a href=&#34;http://kubernetes.io/docs/user-guide/getting-into-containers/&#34;&gt;コマンドを実行&lt;/a&gt;し、
podが動いていることを確認しようとしたがコマンドがなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl exec -it nginx ps
rpc error: code = 2 desc = &amp;quot;oci runtime error: exec failed: exec: \&amp;quot;ps\&amp;quot;: executable file not found in $PATH&amp;quot;error: error executing remote command: error executing command in container: Error executing in Docker Container: 126
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこでリクエストを投げるために&lt;code&gt;kubectl run&lt;/code&gt;で単一コンテナのDeploymentを&lt;a href=&#34;http://kubernetes.io/docs/user-guide/kubectl/kubectl_run/&#34;&gt;作成する&lt;/a&gt;。
Deploymentについては後で説明がある。
&lt;code&gt;--restart=Never&lt;/code&gt;でpodが存在しなくなったときに再起動しないようにし、&lt;code&gt;--env&lt;/code&gt;で環境変数としてnginxのpodのIPを渡している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl run busybox --image=busybox --restart=Never --tty -i --env &amp;quot;POD_IP=$(kubectl get pod nginx -o go-template={{.status.podIP}})&amp;quot;
busybox$ wget -qO- http://$POD_IP
busybox$ exit # Exit the busybox container

$ kubectl get deployments

$ kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          54m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--restart=Never&lt;/code&gt;なしで実行するとこうなる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl run busybox --image=busybox --tty -i --env &amp;quot;POD_IP=$(kubectl get pod nginx -o go-template={{.status.podIP}})&amp;quot;
busybox$ exit
Session ended, resume using &#39;kubectl attach busybox-985443498-9elny -c busybox -i -t&#39; command when the pod is running

$ kubectl get deployments
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
busybox   1         1         1            1           3m

$ kubectl get pods
NAME                      READY     STATUS    RESTARTS   AGE
busybox-985443498-9elny   1/1       Running   1          3m
nginx                     1/1       Running   0          59m

$ kubectl delete pods busybox-985443498-9elny
pod &amp;quot;busybox-985443498-9elny&amp;quot; deleted

$ kubectl get pods # Podsだけ削除しても新しいものが立ち上がってくる
NAME                      READY     STATUS              RESTARTS   AGE
busybox-985443498-4iyvx   0/1       ContainerCreating   0          1s
busybox-985443498-9elny   1/1       Terminating         1          13m
nginx                     1/1       Running             0          1h

$ kubectl delete deployment busybox

$ kubectl get pods # Deploymentを削除するとPodsも消える
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;volumes-http-kubernetes-io-docs-user-guide-walkthrough-volumes&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/#volumes&#34;&gt;Volumes&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;コンテナのファイルシステムはコンテナが生存しているときに限り有効なので、
永続化したいデータはコンテナの外に保存する必要がある。&lt;/p&gt;

&lt;p&gt;以下の例のように&lt;code&gt;volumes&lt;/code&gt;でvolumeを定義し、&lt;code&gt;volumeMounts&lt;/code&gt;でどこにマウントするか指定することができる。
&lt;code&gt;volumes&lt;/code&gt;には、そのPodがノードで実行されている間存在するディレクトリを作成して使う&lt;code&gt;EmptyDir&lt;/code&gt;か、
ノードのファイルシステムに既に存在するディレクトリを使う&lt;code&gt;HostPath&lt;/code&gt;を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: redis
spec:
  containers:
  - name: redis
    image: redis
    volumeMounts:
    - name: redis-persistent-storage
      mountPath: /data/redis
  volumes:
  - name: redis-persistent-storage
    emptyDir: {}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;labels-http-kubernetes-io-docs-user-guide-walkthrough-k8s201-labels&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/k8s201/#labels&#34;&gt;Labels&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;metadataとしてkey-valueのラベルを付けることができる。たくさんのPodをまとめたりするのに便利。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;metadata:
  name: nginx
  labels:
    app: nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubectl get pods -l app=nginx
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          2m
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deployments-http-kubernetes-io-docs-user-guide-walkthrough-k8s201-deployments&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/k8s201/#deployments&#34;&gt;Deployments&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;実行しているPodの維持と更新を管理するのが上でも出てきたDeploymentだ。
Deploymentの定義にはPodを作るためのテンプレートと維持するPod数を記述する。
pod名はDeployment名から生成されるのでtemplateには含めない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f deployment.yaml
$ kubectl get deployment
NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   2         2         2            2           3m

$ kubectl get pods -l app=nginx
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1159050644-ar3i7   1/1       Running   0          3m
nginx-deployment-1159050644-kdjly   1/1       Running   0          3m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl apply&lt;/code&gt;でDeploymentの変更を実行中のPodに適用する。
以下の例ではnginxのバージョンを上げている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.8
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl apply -f deployment-update.yaml
$ kubectl get pods
NAME                                READY     STATUS              RESTARTS   AGE
nginx-deployment-1159050644-kdjly   1/1       Running             0          30m
nginx-deployment-1771418926-pi3vy   0/1       ContainerCreating   0          7s
nginx-deployment-1771418926-ygoxl   0/1       ContainerCreating   0          7s

$ kubectl get pods
NAME                                READY     STATUS              RESTARTS   AGE
nginx-deployment-1771418926-pi3vy   0/1       ContainerCreating   0          12s
nginx-deployment-1771418926-ygoxl   1/1       Running             0          12s

$ kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1771418926-pi3vy   1/1       Running   0          15s
nginx-deployment-1771418926-ygoxl   1/1       Running   0          15s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;services-http-kubernetes-io-docs-user-guide-walkthrough-k8s201-services&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/k8s201/#services&#34;&gt;Services&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;アプリケーションのレイヤー間(例えばフロントエンドとバックエンド)の接続で使われるのがService。
以下のServiceは、8080番ポートで待ち、&lt;code&gt;app: nginx&lt;/code&gt;のラベルが付いているPodの80番ポートに向けるロードバランサーとして働く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  ports:
  - port: 8000
    targetPort: 80
    protocol: TCP
  selector:
    app: nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl create -f service.yaml
$ kubectl get services
NAME            CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
kubernetes      10.0.0.1     &amp;lt;none&amp;gt;        443/TCP    19h
nginx-service   10.0.0.90    &amp;lt;none&amp;gt;        8000/TCP   36s

$ export SERVICE_IP=$(kubectl get service nginx-service -o go-template=&#39;{{.spec.clusterIP}}&#39;)
$ export SERVICE_PORT=$(kubectl get service nginx-service -o go-template=&#39;{{(index .spec.ports 0).port}}&#39;)
$ echo &amp;quot;$SERVICE_IP:$SERVICE_PORT&amp;quot;
10.0.0.90:8000
$ kubectl run busybox --image=busybox --restart=Never --tty -i --env &amp;quot;SERVICE_IP=$SERVICE_IP,SERVICE_PORT=$SERVICE_PORT&amp;quot;
busybox$ wget -qO- http://$SERVICE_IP:$SERVICE_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;health-checking-http-kubernetes-io-docs-user-guide-walkthrough-k8s201-health-checking&#34;&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/walkthrough/k8s201/#health-checking&#34;&gt;Health Checking&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;livenessProbe&lt;/code&gt;にヘルスチェックの設定を含めることができる。
以下の例では、初期化のために30秒待った後、&lt;code&gt;/_status/healthz&lt;/code&gt;へのHTTP GETリクエストに対して
200~399以外のステータスコードが返るか、1秒以上かかった場合、コンテナを再起動する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: pod-with-healthcheck
spec:
  containers:
  - name: nginx
    image: nginx
    livenessProbe:
      httpGet:
        path: /_status/healthz
        port: 80
      initialDelaySeconds: 30
      timeoutSeconds: 1
    ports:
    - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Node.jsのバージョン管理</title>
          <link>https://www.sambaiz.net/article/8/</link>
          <pubDate>Fri, 15 Jul 2016 19:20:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/8/</guid>
          <description>

&lt;h2 id=&#34;n-https-github-com-tj-n&#34;&gt;&lt;a href=&#34;https://github.com/tj/n&#34;&gt;n&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;nodeが必要だけど手軽。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;n latest&lt;/code&gt;, &lt;code&gt;n stable&lt;/code&gt;, &lt;code&gt;n lts&lt;/code&gt;でバージョンが切り替わる。
バージョンを指定する場合、&lt;code&gt;n &amp;lt;version&amp;gt;&lt;/code&gt;でインストールし、&lt;code&gt;n&lt;/code&gt;でインストールされているバージョンの一覧から選択できる。
バージョンの削除は&lt;code&gt;n - &amp;lt;version&amp;gt;&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install -g n
$ n stable
$ node -v
v6.2.2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;nvm-https-github-com-creationix-nvm&#34;&gt;&lt;a href=&#34;https://github.com/creationix/nvm&#34;&gt;nvm&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;nodeが必要ない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.1/install.sh | bash
$ nvm install node
$ node -v
v7.7.2

$ nvm install 6
$ node -v
v6.10.0

$ nvm ls
        v6.10.0
-&amp;gt;       v7.7.2
default -&amp;gt; node (-&amp;gt; v7.7.2)
node -&amp;gt; stable (-&amp;gt; v7.7.2) (default)
stable -&amp;gt; 7.7 (-&amp;gt; v7.7.2) (default)
iojs -&amp;gt; N/A (default)
lts/* -&amp;gt; lts/boron (-&amp;gt; v6.10.0)
lts/argon -&amp;gt; v4.8.0 (-&amp;gt; N/A)
lts/boron -&amp;gt; v6.10.0

$ nvm use node
Now using node v7.7.2 (npm v4.1.2)

$ nvm use 6
Now using node v6.10.0 (npm v3.10.10)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Docker公式ドキュメント&#34;network コマンドを使う&#34;を読む</title>
          <link>https://www.sambaiz.net/article/7/</link>
          <pubDate>Fri, 15 Jul 2016 00:38:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/7/</guid>
          <description>&lt;pre&gt;&lt;code&gt;Docker version 1.12.0-rc2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;公式ドキュメント&lt;a href=&#34;http://docs.docker.jp/engine/userguide/networking/work-with-networks.html&#34;&gt;network コマンドを使う&lt;/a&gt;
の内容をまとめてみた。&lt;/p&gt;

&lt;p&gt;dockerには3つのデフォルトネットワークが存在する。&lt;code&gt;docker run&lt;/code&gt;時に&lt;code&gt;--net&lt;/code&gt;オプションでネットワークを指定しない限り、
docker0として表示されるbridgeネットワークにコンテナを接続する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
a3b712537566        bridge              bridge              local               
f6d86cb54edd        host                host                local               
33cb30b024d9        none                null                local            
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただし、後方互換性を維持するため、デフォルトのbridgeネットワークでは自動的に名前解決が行われない。&lt;/p&gt;

&lt;p&gt;これらのネットワークとは別にユーザー定義のネットワークを作成することもできる。
単一ホストの&lt;code&gt;bridge&lt;/code&gt;ネットワークと、複数ホストにまたがる&lt;code&gt;overlay&lt;/code&gt;ネットワークから選択でき、
何も指定しなかったら&lt;code&gt;bridge&lt;/code&gt;になる。&lt;code&gt;subnet&lt;/code&gt;を指定しなければ、
dockerデーモンがネットワークに対してサブネットを自動的に割り当てるが、
dockerが管理していないサブネットと重複するのを避けるために指定することが推奨されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker network create -d bridge --subnet 172.25.0.0/16 isolated_nw
$ docker network inspect isolated_nw
$ docker network rm isolated_nw  # 削除
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker network inspect&lt;/code&gt;で以下のようなネットワークの情報が得られる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[
    {
        &amp;quot;Name&amp;quot;: &amp;quot;isolated_nw&amp;quot;,
        &amp;quot;Id&amp;quot;: &amp;quot;c81547cf7ed897054ea645192c6c47dcf7a248e77bc8067609becab5330e417d&amp;quot;,
        &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;,
        &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;,
        &amp;quot;EnableIPv6&amp;quot;: false,
        &amp;quot;IPAM&amp;quot;: {
            &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;,
            &amp;quot;Options&amp;quot;: {},
            &amp;quot;Config&amp;quot;: [
                {
                    &amp;quot;Subnet&amp;quot;: &amp;quot;172.25.0.0/16&amp;quot;
                }
            ]
        },
        &amp;quot;Internal&amp;quot;: false,
        &amp;quot;Containers&amp;quot;: {},
        &amp;quot;Options&amp;quot;: {},
        &amp;quot;Labels&amp;quot;: {}
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動時に&lt;code&gt;--net&lt;/code&gt;オプションでネットワークに接続したり、
既に存在するコンテナを&lt;code&gt;docker network connect&lt;/code&gt;で接続することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --net=isolated_nw -itd --name=container1 --link container2:c2 busybox
$ docker network connect isolated_nw container1
$ docker network disconnect isolated_nw container1 # 切断
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上の&lt;code&gt;run&lt;/code&gt;によって同一ネットワークからこのコンテナへ、&lt;code&gt;ping container1&lt;/code&gt;が届くようになり、
このコンテナから同一ネットワークのconteiner2にc2というエイリアスが付くため、&lt;code&gt;ping c2&lt;/code&gt;が届くようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker attach container1
# ping c2
PING c2 (172.25.0.2): 56 data bytes
64 bytes from 172.25.0.2: seq=0 ttl=64 time=0.094 ms
...
CTRL-p CTRL-q
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この設定時点でcontainer2が存在しなかったとしてもエラーにならない。
また、この&lt;code&gt;--link&lt;/code&gt;によるエイリアスは所属するネットワーク全体に適用される。&lt;/p&gt;

&lt;p&gt;他にrunで指定している&lt;a href=&#34;http://docs.docker.jp/engine/reference/commandline/run.html&#34;&gt;オプション&lt;/a&gt;は以下の通り。
どれも良く使うもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-i コンテナの STDIN にアタッチ
-t 疑似ターミナル (pseudo-TTY) を割り当てる
-d コンテナをバックグラウンドで実行し、コンテナIDを表示
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--link&lt;/code&gt;は、コンテナ内におけるプライベートな名前解決のために、他のコンテナの&lt;code&gt;name&lt;/code&gt;に対してエイリアスを付けるものだったが、
これとは別に同一ネットワークの他のコンテナからの名前解決のために使われる、ネットワーク範囲のエイリアスを&lt;code&gt;--net-alias&lt;/code&gt;で付けることができる。
このエイリアスは同一ネットワークの複数のコンテナで同じものに設定でき、有効ないずれかのコンテナに名前解決される。
つまり、コンテナが停止するかネットワークから切断されると、同じネットワーク範囲のエイリアスを持った別のコンテナに名前解決されることになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --net=isolated_nw -itd --name=container3 --net-alias app busybox
$ docker run --net=isolated_nw -itd --name=container4 --net-alias app busybox
$ docker network connect --alias app isolated_nw container5 # connectで指定するとき
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow チュートリアル2(Deep MNIST for Experts)</title>
          <link>https://www.sambaiz.net/article/6/</link>
          <pubDate>Tue, 12 Jul 2016 21:16:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/6/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/3&#34;&gt;前回&lt;/a&gt;に引き続き、まとめながら進めていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html&#34;&gt;Deep MNIST for Experts&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;start-tensorflow-interactivesession&#34;&gt;Start TensorFlow InteractiveSession&lt;/h3&gt;

&lt;p&gt;今回は、前回のようにグラフを作成してからSessionを開始する代わりに
&lt;code&gt;InteractiveSession&lt;/code&gt;を使う。
グラフを作成し実行するのをインタラクティブに行うことができ、IPythonのような環境で便利だ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
sess = tf.InteractiveSession()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;build-a-multilayer-convolutional-network&#34;&gt;Build a Multilayer Convolutional Network&lt;/h3&gt;

&lt;p&gt;前回のシンプルなモデルではあまり良い結果が出なかった。
そこで、今回はもう少し良いモデルの畳み込みニューラルネットワークを作成する。&lt;/p&gt;

&lt;h3 id=&#34;weight-initialization&#34;&gt;Weight Initialization&lt;/h3&gt;

&lt;p&gt;勾配が0になるのを避けるために重みの初期化時にノイズを付ける。
&lt;code&gt;tf.truncated_normal&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/constant_op.html#truncated_normal&#34;&gt;正規分布で、μ±2σ範囲内のランダムな値を返す&lt;/a&gt;。
以下の例だと、&lt;code&gt;mean&lt;/code&gt;のデフォルトが0.0なので、正規分布 &lt;code&gt;N(0, 0.01)&lt;/code&gt;の、&lt;code&gt;-0.2&amp;lt;=x&amp;lt;=0.2&lt;/code&gt;な値がランダムに返ることになる。&lt;/p&gt;

&lt;p&gt;また、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0#ReLU.EF.BC.88.E3.83.A9.E3.83.B3.E3.83.97.E9.96.A2.E6.95.B0.EF.BC.89&#34;&gt;ReLU(Rectified Linear Unit, 正規化線形関数)&lt;/a&gt;ニューロンを使うので、&amp;rdquo;死んだニューロン&amp;rdquo;を避けるために、バイアスは小さな正の値で初期化する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/133/&#34;&gt;ニューラルネットワークと活性化関数 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;convolution-and-pooling&#34;&gt;Convolution and Pooling&lt;/h3&gt;

&lt;p&gt;TensorFlowに畳み込みとプーリングの関数が用意されている。&lt;/p&gt;

&lt;p&gt;畳み込みというのは、画像に対してフィルターを少しずつ動かしながら掛けていく処理のこと。&lt;a href=&#34;http://www.clg.niigata-u.ac.jp/~medimg/practice_medical_imaging/imgproc_scion/4filter/index.htm&#34;&gt;このページ&lt;/a&gt;が分かりやすい。
例えば、&lt;a href=&#34;https://en.wikipedia.org/wiki/Sobel_operator&#34;&gt;ソーベルフィルタ&lt;/a&gt;で輪郭になっているところを抽出するように、
フィルターの値によって、その区域における、ある特徴を際立たせたりすることができる。
今回はこのフィルターが重みとなり、際立たせたいのはその数字を識別するための特徴ということになる。
前回は画像を一次元の配列として扱い重みを学習していたので、縦の情報が失われていたが、この方法ではそれがない。&lt;/p&gt;

&lt;p&gt;プーリングというのは画像から区域ごとにサンプリングする処理のこと。最大プーリングや、平均プーリングなどの手法がある。
畳み込みのように順番に区域を見ていって、最大プーリングならそのうちの最大のものを採用し、他のものは無視する。
サイズが小さくなるだけではなく、ちょっとした位置のずれを吸収することができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;)

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding=&#39;SAME&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.nn.conv2d&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#conv2d&#34;&gt;畳み込みを行う。&lt;/a&gt;
主な入力は&lt;code&gt;[画像の数, 縦サイズ, 横サイズ, チャンネル数(色とか)]&lt;/code&gt;の画像と、
&lt;code&gt;[縦サイズ, 横サイズ, 入力チャンネル数, 出力チャンネル数]&lt;/code&gt;のフィルター。
&lt;code&gt;strides&lt;/code&gt;は一度にどれくらいフィルターを動かしていくかで、&lt;code&gt;strides[1]&lt;/code&gt;が縦、&lt;code&gt;strides[2]&lt;/code&gt;が横に動かす量。
&lt;code&gt;strides[0]&lt;/code&gt;と&lt;code&gt;strides[3]&lt;/code&gt;は1でなくてはならない。
&lt;code&gt;padding&lt;/code&gt;は&amp;rdquo;SAME&amp;rdquo;か&amp;rdquo;VALID&amp;rdquo;から選択できるパディングについての設定だ。詳細は
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#convolution&#34;&gt;ここ&lt;/a&gt;
に書いてある。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.nn.max_pool&lt;/code&gt;は&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#max_pool&#34;&gt;最大プーリングを行う。&lt;/a&gt;
&lt;code&gt;ksize&lt;/code&gt;は入力のそれぞれの次元に対応した見ていく区域のサイズ。&lt;code&gt;[1, 2, 2, 1]&lt;/code&gt;ならそれぞれの画像を&lt;code&gt;2*2&lt;/code&gt;ずつ見ていくことになる。&lt;/p&gt;

&lt;h3 id=&#34;first-convolutional-layer&#34;&gt;First Convolutional Layer&lt;/h3&gt;

&lt;p&gt;最初のレイヤーは、畳み込みと最大プーリングで構成される。
畳み込みはそれぞれ&lt;code&gt;5*5&lt;/code&gt;の32チャンネル出力のフィルターでされる。
つまり、重みであるフィルターは&lt;code&gt;[5, 5, 1, 32]&lt;/code&gt;のtensorということになる。
それぞれのチャンネルに対してのバイアスがb_conv1。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;画像に対して、畳み込みを適用するするために&lt;code&gt;tf.reshape&lt;/code&gt;で
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/api_docs/python/array_ops.html#reshape&#34;&gt;変形する&lt;/a&gt;
必要がある。-1というのは特別な値で、他の次元との積が合計が元のものと変わらないように決定される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = tf.placeholder(tf.float32, [None, 784])
x_image = tf.reshape(x, [-1,28,28,1])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで畳み込めるようになったので画像と重みを畳み込み、バイアスを足したものにReLUを適用した後、最大プーリングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;second-convolutional-layer&#34;&gt;Second Convolutional Layer&lt;/h3&gt;

&lt;p&gt;deepネットワークにするために最初のレイヤーのようなものをいくつか重ねる。
2番目のレイヤーでは64チャンネル出力のフィルターで畳み込みを行いプーリングする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;densely-connected-layer&#34;&gt;Densely Connected Layer&lt;/h3&gt;

&lt;p&gt;2つのレイヤーを経て元々&lt;code&gt;28*28&lt;/code&gt;だった画像は&lt;code&gt;7*7&lt;/code&gt;にまで削減された。
2つめのレイヤーの出力は64チャンネルだったので、&lt;code&gt;7*7*64&lt;/code&gt;次元のデータになっている。
このレイヤーでは、これらにそれぞれ1024のニューロンを結びつける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dropout&#34;&gt;Dropout&lt;/h3&gt;

&lt;p&gt;過学習を防ぐために訓練データごとにニューロンを何割か無視する
&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0#.E3.83.89.E3.83.AD.E3.83.83.E3.83.97.E3.82.A2.E3.82.A6.E3.83.88&#34;&gt;ドロップアウト&lt;/a&gt;
を行う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;readout-layer&#34;&gt;Readout Layer&lt;/h3&gt;

&lt;p&gt;最後にsoftmaxでそれぞれの数字である確率を求める。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;train-and-evaluate-the-model&#34;&gt;Train and Evaluate the Model&lt;/h3&gt;

&lt;p&gt;今回は前回使った&lt;code&gt;GradientDescentOptimizer&lt;/code&gt;よりも性能が高い&lt;code&gt;AdamOptimizer&lt;/code&gt;というのが使われている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
sess.run(tf.initialize_all_variables())
for i in range(20000):
  batch = mnist.train.next_batch(50)
  if i%100 == 0:
    train_accuracy = accuracy.eval(feed_dict={
        x:batch[0], y_: batch[1], keep_prob: 1.0})
    print(&amp;quot;step %d, training accuracy %g&amp;quot;%(i, train_accuracy))
  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})

print(&amp;quot;test accuracy %g&amp;quot;%accuracy.eval(feed_dict={
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行するとこんな出力が得られた。
かなり時間がかかったのでここで打ち切ったが、およそ99.2%の正解率になるらしい。
前回が92%だったのに比べてもすごく良い値に見える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;step 0, training accuracy 0.12
step 100, training accuracy 0.8
step 200, training accuracy 0.9
step 300, training accuracy 0.9
step 400, training accuracy 0.98
step 500, training accuracy 0.88
step 600, training accuracy 0.98
step 700, training accuracy 0.98
step 800, training accuracy 0.9
step 900, training accuracy 1
step 1000, training accuracy 0.98
step 1100, training accuracy 0.98
step 1200, training accuracy 1
step 1300, training accuracy 0.98
step 1400, training accuracy 0.94
step 1500, training accuracy 0.98
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>webpack環境でredux&amp;react-routerのページをサーバーサイドレンダリングする</title>
          <link>https://www.sambaiz.net/article/5/</link>
          <pubDate>Sun, 10 Jul 2016 03:08:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/5/</guid>
          <description>&lt;p&gt;このページをGoogleのSearch Consoleからクローラーがちゃんと見ているか確認してみたら、
なぜか真っ白のページが表示されていた・・・。とりあえずサーバーサイドレンダリングしてみることにした。
コードは&lt;a href=&#34;https://github.com/sambaiz/sambaiz.net/tree/v0.23&#34;&gt;github&lt;/a&gt;に上げてある。&lt;/p&gt;

&lt;p&gt;サーバーサイドとはいえ、css-loaderでcss moduleを使っているのでwebpackを使う必要があった。
まず、そのままのwebpackの設定で作ったものをserver.jsから呼ぶとエラーが出た。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;***/sambaiz-net/web/public/bundle.js:20933
	module.exports = self.fetch.bind(self);
ReferenceError: self is not defined
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこで、targetをnodeにしたサーバーサイド用にwebpackの設定を作成し、実行してみたところ&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.exports = {
	entry: &#39;./js/server.js&#39;,
	target: &#39;node&#39;,
	output: {
		path: path.join(__dirname, &#39;dist&#39;),
		filename: &#39;server.js&#39;,
		publicPath: &#39;/&#39;
	},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今度はこんなエラーが出たので&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERROR in ./~/iconv-lite/encodings/tables/gb18030-ranges.json
Module parse failed: ***/sambaiz-net/web/node_modules/iconv-lite/encodings/tables/gb18030-ranges.json Unexpected token (1:9)
You may need an appropriate loader to handle this file type.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;loadersに下の設定を追加した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{ test: /\.json$/, loader: &amp;quot;json-loader&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webpackには成功したが、serverを起動すると今度は以下のようなエラーが出た。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return /msie [6-9]\b/.test(window.navigator.userAgent.toLowerCase());
ReferenceError: window is not defined
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;style-loaderのコードだったので、
まず、フロント側のwebpackで
&lt;a href=&#34;https://github.com/webpack/extract-text-webpack-plugin&#34;&gt;extract-text-webpack-plugin&lt;/a&gt;を使ってcssを別に出力することにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;);
...
{
  test: /\.css$/,
  loader:  ExtractTextPlugin.extract(&#39;style&#39;, &#39;css?modules&#39;, &#39;postcss&#39;),
  include: __dirname
},
...
plugins: [
    new ExtractTextPlugin(&amp;quot;styles.css&amp;quot;)
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そして、サーバー側のwebpackでは&lt;a href=&#34;https://github.com/kriasoft/isomorphic-style-loader&#34;&gt;isomorphic-style-loader&lt;/a&gt;でなんとか動かして、
フロント側で出力したcssと対応するようにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;loaders: [&#39;isomorphic-style&#39;, &#39;css?modules&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでようやくwebpackまわりの問題は解決できたので、react-routerの方のコードを書いていく。&lt;/p&gt;

&lt;p&gt;reduxに関しては&lt;a href=&#34;http://redux.js.org/docs/recipes/ServerRendering.html&#34;&gt;ドキュメント&lt;/a&gt;通りに
描画した後のstoreをこんな感じでフロントに渡す。
そのほかに、同じ処理をサーバーとフロントで二度行わないようにするための値を追加する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;window.__INITIAL_STATE__ = ${JSON.stringify(state)}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;react-routerも以下のようにmatchとRouterContextを組み合わせるだけだ。
ただし、APIリクエスト等の非同期処理が含まれているので、レンダリングが完了したかどうか判断しなくてはならない。
そのため、storeの状態をsubscribeしてレンダリングの終了判定を都度チェックしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function render(req, res, isFinishLoading, title, description, fullUrl) {

  match({ routes, location: req.url }, (error, redirectLocation, renderProps) =&amp;gt; {

    let store = createStore();

    if (error) {
      res.status(500).send(error.message)
    } else if (redirectLocation) {
      res.redirect(302, redirectLocation.pathname + redirectLocation.search)
    } else if (renderProps) {

      const _render = () =&amp;gt;
        renderToString(&amp;lt;Provider store={store}&amp;gt;
          &amp;lt;RouterContext {...renderProps} /&amp;gt;
        &amp;lt;/Provider&amp;gt;)

      let unscribe = store.subscribe(() =&amp;gt; {
        if(isFinishLoading(store.getState()) === true){
          res.status(200).send(
            page(_render(), store.getState(), title, description, fullUrl)
          )
          unscribe();
        }
      })

      _render();

    } else {
      res.status(404).send(&#39;Not found&#39;)
    }
  })
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MySQLのUNIX_TIMESTAMPにある程度未来の日付を渡すと0になる</title>
          <link>https://www.sambaiz.net/article/4/</link>
          <pubDate>Mon, 04 Jul 2016 19:49:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/4/</guid>
          <description>&lt;p&gt;以下、MySQL5.6で遭遇した。&lt;/p&gt;

&lt;p&gt;MySQLの&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.6/ja/date-and-time-functions.html#function_unix-timestamp&#34;&gt;UNIX_TIMESTAMP&lt;/a&gt;は
DATETIME文字列などを引数にとり、UNIXタイムスタンプ(1970-01-01 00:00:00 UTCを起点とした経過秒数)を返す関数だ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SET SESSION time_zone = &#39;UTC&#39;;
mysql&amp;gt; select UNIX_TIMESTAMP(&#39;1970-01-01 00:00:00&#39;);
+---------------------------------------+
| UNIX_TIMESTAMP(&#39;1970-01-01 00:00:00&#39;) |
+---------------------------------------+
|                                     0 |
+---------------------------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただし、2038年1月19日3時14分7秒(UTC)以降を渡すと0になってしまう。
これはドキュメントにも書いてある通り範囲外だから。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select UNIX_TIMESTAMP(&#39;2038-01-19-03-14-07&#39;);
+---------------------------------------+
| UNIX_TIMESTAMP(&#39;2038-01-19-03-14-07&#39;) |
+---------------------------------------+
|                            2147483647 |
+---------------------------------------+
1 row in set (0.04 sec)

mysql&amp;gt; select UNIX_TIMESTAMP(&#39;2038-01-19-03-14-08&#39;);
+---------------------------------------+
| UNIX_TIMESTAMP(&#39;2038-01-19-03-14-08&#39;) |
+---------------------------------------+
|                                     0 |
+---------------------------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では、この境目は何かというと、32ビットで表せる符号付数値の最大値だ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; 2 ** 31
=&amp;gt; 2147483648
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これはMySQLに限らず、&lt;a href=&#34;https://ja.wikipedia.org/wiki/2038%E5%B9%B4%E5%95%8F%E9%A1%8C&#34;&gt;2038年問題&lt;/a&gt;と呼ばれているもので、
DATETIME型は&amp;rsquo;9999-12-31&amp;rsquo;までサポートしているのでこれ以降も表すことはできるが、&lt;code&gt;UNIX_TIMESTAMP&lt;/code&gt;しても正しい値は得られなくなる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>TensorFlow チュートリアルまで</title>
          <link>https://www.sambaiz.net/article/3/</link>
          <pubDate>Sun, 03 Jul 2016 23:37:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/3/</guid>
          <description>

&lt;p&gt;Googleが公開した人工知能ライブラリTensorFlowを使ってみる。
&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html&#34;&gt;セットアップ&lt;/a&gt;方法はいくつか提供されているが、Dockerで動かすことにした。
Jupyter Notebookが立ち上がるのですぐに試せて良い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:8888/tree&#34;&gt;http://localhost:8888/tree&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;公式のチュートリアルをまとめながら進めてみる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html&#34;&gt;MNIST For ML Beginners&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-mnist-data&#34;&gt;The MNIST Data&lt;/h3&gt;

&lt;p&gt;MNISTというのは0~9の書き数字の画像のデータセットのことで、これらを正しく分類するのが目的。&lt;/p&gt;

&lt;p&gt;それぞれの画像は一律28*28=784ピクセルで、それぞれのピクセルは0と1の間の数値(強さ)で表されている。
今回はこれの縦横を取っ払って784次元のベクトルとして扱っている。&lt;/p&gt;

&lt;p&gt;したがって、学習用の画像データは[55000, 784]のtensor(n次元の配列)で表される。
55000というのが画像の数で、784というのがそれぞれの画像の次元を意味している。&lt;/p&gt;

&lt;p&gt;それぞれの画像に対応した数字のラベルは[55000, 10]で表される。
10というのは、0~9それぞれに対応した次元のうち、一つだけ1で、それ以外が0という風に使われる。これをone-hot vectorという。&lt;/p&gt;

&lt;h3 id=&#34;softmax-regressions&#34;&gt;Softmax Regressions&lt;/h3&gt;

&lt;p&gt;Softmaxはいくつかの異なるもの(今回でいうと数字)に確率を割り当てる。&lt;/p&gt;

&lt;p&gt;画像が特定のクラス(0~9)に属するかどうか計算するために、ピクセルの強さに重みを付けた合計を計算する。
もし、そのピクセルがそのクラスに属さない根拠になるなら負の重みがかかり、属する根拠になるなら、正の重みがかかるようにする。
また合計にさらに入力と無関係なクラスごとに異なるバイアスを足す。&lt;/p&gt;

&lt;p&gt;全てのクラスで計算した値をsoftmax関数に入れ、それぞれ確率に変換する。この確率の和は1になるようになっている。&lt;/p&gt;

&lt;h3 id=&#34;implementing-the-regression&#34;&gt;Implementing the Regression&lt;/h3&gt;

&lt;p&gt;Pythonでは行列の積のような重い処理をするとき、NumPyのようなライブラリを使ってPythonの外で行うが、
外からPythonに戻るときにオーバーヘッドが発生してしまう。
TensorFlowでも重い処理を外で行うが、オーバーヘッドを避けるために、
単体の重い処理をPythonから独立して実行するのではなく、Pythonの外側で実行される関連した処理のグラフを記述させる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
x = tf.placeholder(tf.float32, [None, 784])
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
y = tf.nn.softmax(tf.matmul(x, W) + b)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tf.placeholder&lt;/code&gt;は実行時に与えられる値で、今回が画像データ。
W(重み)とb(バイアス)は学習する変数。
&lt;code&gt;tf.matmul(x, W) + b&lt;/code&gt;の部分が重みを付けた合計にバイアスを足したものに対応している。
matmulはmatrix multiple、つまり行列の積。&lt;/p&gt;

&lt;h3 id=&#34;training&#34;&gt;Training&lt;/h3&gt;

&lt;p&gt;機械学習では一般的に、悪いモデルとは何か定義し、それを最小化しようとする。
一般的で、良い損失関数としてクロスエントロピーがある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/134/&#34;&gt;自己情報量、エントロピー、KL情報量、クロスエントロピー - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;y_が正しい答えで、これとy(softmaxで求めた各数字の確率)の対数の積をを次元ごとにとり、それらの和を求めて-1を掛ける。
&lt;code&gt;reduction_indices=[1]&lt;/code&gt;というのは[784, 10]の10の方を指しているようだ。
全ての学習データにおいてこれを求め、さらにそれらの平均をとったものがクロスエントロピーになる。
この値はy_とyが離れていれば大きくなるので、なるべく小さくすることが良いモデルにするということになる。&lt;/p&gt;

&lt;p&gt;ではどうやってこの値を小さくするか、TensorFlowは関係する計算のグラフを持っているので、自動的に&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3&#34;&gt;バックプロパゲーション&lt;/a&gt;を使って、どの変数がクロスエントロピーに影響しているか効率的に特定することができる。&lt;/p&gt;

&lt;p&gt;以下のようにGradientDescent(勾配降下)Optimizerで0.5のleartning rateでクロスエントロピーが小さくなるように、変数を少しずつ変えていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/191/&#34;&gt;ロジスティック回帰の尤度と交差エントロピー誤差と勾配降下法 - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを使って学習していく。学習とテストに使うデータは&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/examples/tutorials/mnist/input_data.py&#34;&gt;これ&lt;/a&gt;
と&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&amp;quot;MNIST_data/&amp;quot;, one_hot=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行すれば用意できるようになっている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.Session()&lt;/code&gt;と&lt;code&gt;tf.run()&lt;/code&gt;はSessionを取得し、モデルを実行するもの。
変数は&lt;code&gt;tf.initialize_all_variables()&lt;/code&gt;で初期化する必要がある。
batch_xsが画像のピクセルデータで、batch_ysが正しい答え。
&lt;code&gt;sess.run()&lt;/code&gt;の&lt;code&gt;feed_dict={x: batch_xs, y_: batch_ys}&lt;/code&gt;はそれぞれ対応するplaceholderのところに与えられる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)
for i in range(1000):
  batch_xs, batch_ys = mnist.train.next_batch(100)
  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このような小さいランダムなデータを使うのはstochastic(確率的) trainingと呼ばれていて、
今回はstochastic gradient descent。
理想的には全てのデータを全ての訓練のステップで使いたいが、コストがかかるので代わりに毎回異なるサブセットを使うことで
同じ効果を得ている。&lt;/p&gt;

&lt;h3 id=&#34;evaluating-our-model&#34;&gt;Evaluating Our Model&lt;/h3&gt;

&lt;p&gt;モデルがどのくらい良いかを測る。&lt;/p&gt;

&lt;p&gt;以下のcorrect_predictionでは&lt;code&gt;tf.argmax&lt;/code&gt;で最も数値の大きい、つまり確率の高いラベルを取得し、これが正解のものと一致するかというのを
画像データごとに比較している。
結果、[True, False, True, True]であるなら、これを[1, 0, 1, 1]にキャストし、平均を取ったものがaccuracy、正解率となる。
そしてこの値をテスト用のデータで出力している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
&amp;gt; 0.9206
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この簡単なモデルだと正解率は92%になったが、実はこれは非常に悪いとのこと。
モデルにもう少し変更を加えるだけで97%になったりするらしい。&lt;/p&gt;

&lt;p&gt;続き: &lt;a href=&#34;https://www.sambaiz.net/article/6&#34;&gt;TensorFlow チュートリアル2(Deep MNIST for Experts)&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Reactで作ったページにTwitterCardsとOGPのメタデータを埋める</title>
          <link>https://www.sambaiz.net/article/2/</link>
          <pubDate>Sat, 02 Jul 2016 13:23:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/2/</guid>
          <description>&lt;p&gt;せっかくページを作ったので、SNSにシェアするときに見栄えをよくしようと思った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.sambaiz.net/images/2_ogp.jpg&#34; alt=&#34;Facebookに表示される例&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Twitter CardsやOGPのmetaタグを埋めるとTwitterやFacebookにURLを貼ったときに上のように表示されるようになる(上はFacebookの例)。そこで、&lt;a href=&#34;https://github.com/nfl/react-helmet&#34;&gt;react-helmet&lt;/a&gt;でこんな感じで動的に埋め込んだんだけど読んでくれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Helmet title={&#39;sambaiz.net&#39;}
        meta={[
            {&amp;quot;name&amp;quot;: &amp;quot;twitter:card&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;summary&amp;quot;},
            {&amp;quot;name&amp;quot;: &amp;quot;twitter:site&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;@sambaiz&amp;quot;},
            {&amp;quot;name&amp;quot;: &amp;quot;twitter:title&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;sambaiz.net&amp;quot;},
            {&amp;quot;name&amp;quot;: &amp;quot;twitter:description&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;僕のホームページ&amp;quot;},
            {&amp;quot;property&amp;quot;: &amp;quot;og:title&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;sambaiz.net&amp;quot;},
            {&amp;quot;property&amp;quot;: &amp;quot;og:type&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;blog&amp;quot;},
            {&amp;quot;property&amp;quot;: &amp;quot;og:image&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;http://d2wgaf7ubdj1mv.cloudfront.net/my.jpg&amp;quot;},
            {&amp;quot;property&amp;quot;: &amp;quot;og:url&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;https://www.sambaiz.net&amp;quot;}
        ]}
/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Googleのクローラーのように&lt;a href=&#34;https://webmasters.googleblog.com/2014/05/understanding-web-pages-better.html&#34;&gt;Javascriptを解釈してくれる&lt;/a&gt;
と思ってた。残念。&lt;/p&gt;

&lt;p&gt;しょうがないのでここだけサーバーサイドレンダリングすることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;use strict&#39;

import express from &#39;express&#39;
import path from &#39;path&#39;
import compression from &#39;compression&#39;

require(&#39;isomorphic-fetch&#39;);

var app = express()

app.use(compression())

// serve our static stuff
app.use(express.static(path.join(__dirname, &#39;..&#39;, &#39;..&#39;, &#39;public&#39;)))

app.get(&#39;/&#39;, function (req, res) {
  res.status(200).send(page(&#39;https://www.sambaiz.net&#39;, &#39;sambaiz.net&#39;, &#39;僕のホームページ&#39;));
})

app.get(&#39;/article/:articleId&#39;, function (req, res) {
  fetch(`https://zx9h12n6jb.execute-api.ap-northeast-1.amazonaws.com/api/articles/${req.params.articleId}`).then(function(response){
    if (response.status == 404) {
      res.status(404).send(&#39;not found&#39;)
    }else if(response.status != 200){
      res.status(response.status).send(`API error ${response.status}`)
    }else{
      return response.json();
    }
  }).then(function(json) {
    if(json){
      res.status(200).send(page(`https://www.sambaiz.net${req.url}`, json.title, &#39;書いた&#39;));
    }
  })
})

function page(fullUrl, title, description)  {
  return `
    &amp;lt;!doctype html&amp;gt;
    &amp;lt;html&amp;gt;
      &amp;lt;head&amp;gt;
        &amp;lt;title&amp;gt;${title}&amp;lt;/title&amp;gt;
        &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;
        &amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;twitter:card&amp;quot; content=&amp;quot;summary&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;twitter:site&amp;quot; content=&amp;quot;@sambaiz&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;twitter:title&amp;quot; content=&amp;quot;${title}&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;twitter:description&amp;quot; content=&amp;quot;${description}&amp;quot;&amp;gt;
        &amp;lt;meta property=&amp;quot;og:title&amp;quot; content=&amp;quot;${title}&amp;quot;&amp;gt;
        &amp;lt;meta property=&amp;quot;og:type&amp;quot; content=&amp;quot;blog&amp;quot;&amp;gt;
        &amp;lt;meta property=&amp;quot;og:image&amp;quot; content=&amp;quot;http://d2wgaf7ubdj1mv.cloudfront.net/my.jpg&amp;quot;&amp;gt;
        &amp;lt;meta property=&amp;quot;og:url&amp;quot; content=&amp;quot;${fullUrl}&amp;quot;&amp;gt;
      &amp;lt;/head&amp;gt;
      &amp;lt;body&amp;gt;
        &amp;lt;div id=&amp;quot;app&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
        &amp;lt;script src=&amp;quot;/bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
      &amp;lt;/body&amp;gt;
    &amp;lt;/html&amp;gt;
    `
}

var PORT = process.env.PORT || 8080

app.listen(PORT, function() {
  console.log(&#39;Production Express server running at localhost:&#39; + PORT)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと読まれているかは以下のページで確認できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cards-dev.twitter.com/validator&#34;&gt;Card validator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developers.facebook.com/tools/debug/&#34;&gt;Sharing Debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;が、&lt;a href=&#34;https://www.sambaiz.net/article/5&#34;&gt;結局全部サーバーサイドレンダリングすることになった。&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ブログを作った</title>
          <link>https://www.sambaiz.net/article/1/</link>
          <pubDate>Wed, 29 Jun 2016 23:43:00 &#43;0900</pubDate>
          <author>sambaiz</author>
          <guid>https://www.sambaiz.net/article/1/</guid>
          <description>&lt;p&gt;最近表に出るものを作っていなかったので、このサイトを作ってみた。&lt;/p&gt;

&lt;p&gt;表はReact/Reduxで、裏側はAWSのLambdaでサーバーレスに作ってある。
コードは&lt;a href=&#34;https://github.com/sambaiz/sambaiz.net&#34;&gt;github&lt;/a&gt;に公開してみた。&lt;/p&gt;

&lt;p&gt;これを期になるべくアウトプットしていこうと思う。大抵三日坊主なのだけれど。&lt;/p&gt;

&lt;p&gt;&amp;ndash;&lt;/p&gt;

&lt;p&gt;追記: 今はHugoに置き換わっている&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/22&#34;&gt;静的ウェブサイトエンジンHugoに乗り換えた&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
