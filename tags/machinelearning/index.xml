<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machinelearning on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/machinelearning/</link>
    <description>Recent content in machinelearning on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Thu, 16 Nov 2023 23:36:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/tags/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SageMaker Canvas の Custom models で AutoML のジョブをノーコードで実行する</title>
      <link>https://www.sambaiz.net/article/458/</link>
      <pubDate>Thu, 16 Nov 2023 23:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/458/</guid>
      <description>SageMaker Canvas は SageMaker JumpStart で提供されている学習済みモデルを利用できるインタフェースおよび、 AutoML の機能である SageMaker Autopilot を用いた学習ジョブを ノーコードで実行できる機能を</description>
    </item>
    <item>
      <title>OpenAIのGPTを国会会議録の総理大臣の発言でファインチューニングする</title>
      <link>https://www.sambaiz.net/article/452/</link>
      <pubDate>Mon, 11 Sep 2023 23:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/452/</guid>
      <description>OpenAI は GPT による会話文の生成や 文章をベクトルに変換するほかに 独自のデータセットによってモデルをファインチューニングする API を提供しており、 これを用</description>
    </item>
    <item>
      <title>SageMakerのHuggingFaceModelでOpenCALM-7BやELYZA-japanese-Llama-2-7bをTGIコンテナでデプロイし日本語の文章を生成する</title>
      <link>https://www.sambaiz.net/article/451/</link>
      <pubDate>Tue, 05 Sep 2023 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/451/</guid>
      <description>最近 CyberAgentによる商用利用可能な68億パラメータの日本語LLMである OpenCALM-7B や 東大松尾研発のELYZAによる Llama2 ベースの ELYZA-japanese-Llama-2-7b など日本語LL</description>
    </item>
    <item>
      <title>SageMakerのBatch Transformのパラメータの挙動をentrypointの関数の呼び出しと引数から確認する</title>
      <link>https://www.sambaiz.net/article/448/</link>
      <pubDate>Mon, 14 Aug 2023 18:16:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/448/</guid>
      <description>SageMaker の Batch Transform は単発のバッチ推論ジョブを実行する機能。 その際推論エンドポイントなどの場合と同じく呼ばれる Model の entrypoint の関数とその引数から、ジョブのパラメ</description>
    </item>
    <item>
      <title>SageMaker Inference Recommender でコスト最適なインスタンスタイプの推論エンドポイントを立てる</title>
      <link>https://www.sambaiz.net/article/447/</link>
      <pubDate>Thu, 15 Jun 2023 09:38:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/447/</guid>
      <description>SageMaker Inference Recommender は、 推論エンドポイントのインスタンスタイプや設定の候補を挙げてくれる機能。 SageMakerで学習したPyTorchのモデルをElas</description>
    </item>
    <item>
      <title>SageMaker Processing で前処理を行って Training で学習したモデルのパラメータや精度を Experiments で記録する</title>
      <link>https://www.sambaiz.net/article/442/</link>
      <pubDate>Thu, 04 May 2023 19:20:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/442/</guid>
      <description>SageMaker Experimentsは Processing での前処理や Training での学習に用いたパラメータやモデルの精度を記録する機能。 今回は前処理から学習までの流れを Experiments の Run とし</description>
    </item>
    <item>
      <title>Spark の MLlib で k-means法によるクラスタリングを行う</title>
      <link>https://www.sambaiz.net/article/446/</link>
      <pubDate>Sun, 09 Apr 2023 17:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/446/</guid>
      <description>Spark には MLlib という機械学習のライブラリがあり、 今回はその中の Kmeans によるクラスタリングを行う。 k-means法は各データのクラスタを事前に決めた数か</description>
    </item>
    <item>
      <title>最小二乗法(OLS)による線形回帰と決定係数</title>
      <link>https://www.sambaiz.net/article/395/</link>
      <pubDate>Fri, 11 Feb 2022 00:11:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/395/</guid>
      <description>最小二乗法(OLS)による線形回帰 線形回帰は時系列データに見られる前の時間との自己相関がないことを前提に $$ y = \alpha + \sum_i^n \beta_i x_i $$ のような線形関数で</description>
    </item>
    <item>
      <title>Glue DataBrewでデータを可視化して分析するProjectと機械学習の前処理を行うJobをCDKで作成する</title>
      <link>https://www.sambaiz.net/article/381/</link>
      <pubDate>Mon, 27 Sep 2021 16:42:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/381/</guid>
      <description>Glue DataBrewは、データを可視化してパラメータ間の相関を見たり、カテゴリー変数のエンコードや、欠損値や外れ値を置換する処理をコードなしで</description>
    </item>
    <item>
      <title>GoでAmazon Forecastに時系列データをimportしPredictorを作成して予測結果をS3にexportする</title>
      <link>https://www.sambaiz.net/article/380/</link>
      <pubDate>Mon, 20 Sep 2021 23:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/380/</guid>
      <description>以前コンソール上で実行したAmazon Forecastでの時系列データの学習、予測をGoで行う。全体のコードはGitHubにある。 Amazon Fore</description>
    </item>
    <item>
      <title>SageMaker Studioの使っていないKernelを自動でシャットダウンするsagemaker-studio-auto-shutdown-extension</title>
      <link>https://www.sambaiz.net/article/373/</link>
      <pubDate>Sun, 18 Jul 2021 23:09:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/373/</guid>
      <description>SageMaker Studioを使っているとインスタンスを明示的に立ち上げることがないので、シャットダウンするのを忘れて 無駄なインスタンスコストを発生させ続</description>
    </item>
    <item>
      <title>Amazon Forecastで時系列データの予測を行う</title>
      <link>https://www.sambaiz.net/article/327/</link>
      <pubDate>Sun, 21 Feb 2021 01:04:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/327/</guid>
      <description>Amazon Forecastは機械学習によって時系列データの予測を行うマネージドサービス。 ドメインやアルゴリズムを選んでデータを投入すればそれらしい出</description>
    </item>
    <item>
      <title>EKSにKubeflowをインストールする</title>
      <link>https://www.sambaiz.net/article/316/</link>
      <pubDate>Sun, 29 Nov 2020 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/316/</guid>
      <description>Kubernetes上で機械学習を行うためのツールキットKubeflowを EKSにインストールする。 m5.large * 4のクラスタをCDKで作成した。 CD</description>
    </item>
    <item>
      <title>時系列データのMAモデルとARモデル、その定常性と反転可能性</title>
      <link>https://www.sambaiz.net/article/285/</link>
      <pubDate>Fri, 14 Aug 2020 19:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/285/</guid>
      <description>時系列データにLjung-Box testを行い自己相関があることが分かったら、次はそれをモデルで表現したい。今回は自己相関を表す最も基本的な</description>
    </item>
    <item>
      <title>SageMakerでTensorFlowのモデルを学習させる</title>
      <link>https://www.sambaiz.net/article/293/</link>
      <pubDate>Mon, 10 Aug 2020 13:39:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/293/</guid>
      <description>以前PyTorchのモデルを学習させたが、そのTensorFlow版。 SageMakerでPyTorchのモデルを学習させる - sambaiz-net コード 全体の</description>
    </item>
    <item>
      <title>TensorFlow2のKeras APIでTitanicのモデルを作る</title>
      <link>https://www.sambaiz.net/article/291/</link>
      <pubDate>Sat, 08 Aug 2020 18:32:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/291/</guid>
      <description>データセット TensorFlow Datasetsの Titanicを使う。 $ pip install tensorflow-datasets tfds.load()して tf.data.Datasetを作る。 tf.data はCPUやG</description>
    </item>
    <item>
      <title>SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする</title>
      <link>https://www.sambaiz.net/article/290/</link>
      <pubDate>Sun, 26 Jul 2020 02:43:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/290/</guid>
      <description>学習させたモデルをSageMakerのホスティングサービスにデプロイする。 SageMakerでPyTorchのモデルを学習させる - sambaiz-net 推論時に</description>
    </item>
    <item>
      <title>SageMakerでPyTorchのモデルを学習させる</title>
      <link>https://www.sambaiz.net/article/287/</link>
      <pubDate>Fri, 24 Jul 2020 22:59:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/287/</guid>
      <description>AWSの機械学習サービスSageMakerでPyTorchのモデルを学習させる。 コード まず学習させるモデルとそれを呼び出すエントリーポイント</description>
    </item>
    <item>
      <title>VSCodeのRemote DevelopmentでSageMakerのコンテナ環境でモデルを開発する</title>
      <link>https://www.sambaiz.net/article/289/</link>
      <pubDate>Sun, 19 Jul 2020 19:34:04 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/289/</guid>
      <description>SageMakerで学習させるモデルを開発するにあたって、Notebooks上ではコードを書きづらいのでVS Codeで書いているのだが、ロー</description>
    </item>
    <item>
      <title>時系列データの定常性と定常過程、単位根過程</title>
      <link>https://www.sambaiz.net/article/279/</link>
      <pubDate>Sun, 05 Jul 2020 21:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/279/</guid>
      <description>時系列データを各時間\(t\)ごとの分布から抽出された確率変数\(R_t\)の列とみなすと、次の性質が定義される。 弱定常性(weak stationarity): 各分布</description>
    </item>
    <item>
      <title>KaggleのHouse Prices CompetitionをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/230/</link>
      <pubDate>Tue, 09 Jul 2019 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/230/</guid>
      <description>以前TitanicをやったXGBoostでHome Prices Competitionに挑戦する。 KaggleのTitanicのチュートリアルをXGBo</description>
    </item>
    <item>
      <title>ColabでKaggleのAPIを呼んで学習データのダウンロードと提出を行う</title>
      <link>https://www.sambaiz.net/article/229/</link>
      <pubDate>Tue, 09 Jul 2019 01:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/229/</guid>
      <description>Colabではランタイムがリセットされるたびにファイルが消えてしまうのでその度に学習データをアップロードするのが面倒。 そこでKaggle AP</description>
    </item>
    <item>
      <title>AWS DeepRacerを始める</title>
      <link>https://www.sambaiz.net/article/224/</link>
      <pubDate>Mon, 10 Jun 2019 23:06:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/224/</guid>
      <description>AWS DeepRacerは自走する1/18スケールのレーシングカーで、 SageMakerやRoboMakerなどを使って強化学習し、実機を走らせ</description>
    </item>
    <item>
      <title>カテゴリカル変数を変換するsklearnのLabel/OneHotEncoderとpandasのget_dummies</title>
      <link>https://www.sambaiz.net/article/220/</link>
      <pubDate>Mon, 06 May 2019 15:59:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/220/</guid>
      <description>次のデータを用いる。 data = [&amp;#34;tokyo&amp;#34;, &amp;#34;berlin&amp;#34;, &amp;#34;paris&amp;#34;, &amp;#34;amsterdam&amp;#34;, &amp;#34;paris&amp;#34;, &amp;#34;amsterdam&amp;#34;, &amp;#34;berlin&amp;#34;] partial_data = data[:4] preprocessing.LabelEncoder カテゴリカル変数を数値のラベルに変換する。 from sklearn import preprocessing le = preprocessing.LabelEncoder() le.fit(data) encoded = le.transform(partial_data) print(encoded) # [3 1 2 0] print(le.inverse_transform(encoded)) # [&amp;#39;tokyo&amp;#39; &amp;#39;berlin&amp;#39; &amp;#39;paris&amp;#39; &amp;#39;amsterdam&amp;#39;] preprocessing.OneHotEncoder One-hot v</description>
    </item>
    <item>
      <title>Box-Cox transformationで非正規分布のデータを正規分布に近づける</title>
      <link>https://www.sambaiz.net/article/218/</link>
      <pubDate>Tue, 30 Apr 2019 17:35:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/218/</guid>
      <description>Box-Cox Transormationは次の式による変換。λ=0のときはlog(x)。 λが1より大きい場合は小さな値の間隔が圧縮され、小さい場合は大き</description>
    </item>
    <item>
      <title>KaggleのHouse Prices CompetitionのKernelからデータの探り方を学ぶ</title>
      <link>https://www.sambaiz.net/article/216/</link>
      <pubDate>Mon, 08 Apr 2019 21:01:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/216/</guid>
      <description>Kaggleの家の売値を予測するCompetitionのKernelからデータの探り方を学ぶ。 Comprehensive data exploration with Python 正規化 予測する値であるSalePri</description>
    </item>
    <item>
      <title>HI-VAE(Heterogeneous-Incomple VAE)の論文を読んで処理を追う</title>
      <link>https://www.sambaiz.net/article/214/</link>
      <pubDate>Fri, 22 Mar 2019 20:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/214/</guid>
      <description>HI-VAE(Heterogeneous-Incomple VAE)は現実のデータセットにありがちな連続値と離散値が混ざっていたり欠損値を含んでいるものを扱えるようにしたVAE。 論文: Alfredo Nazabal, Pablo M. Olmos, Zoubin Ghahramani,</description>
    </item>
    <item>
      <title>VAEでエンコードしたMNISTの潜在空間をt-SNEで可視化する</title>
      <link>https://www.sambaiz.net/article/213/</link>
      <pubDate>Sun, 10 Mar 2019 19:03:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/213/</guid>
      <description>t-SNEは多次元のデータを2,3次元上にマッピングして可視化できるようにする手法の一つで、 Stochastic Neighbor Embedding(SNE, 確率的近傍埋め込み)という手法をベースに、</description>
    </item>
    <item>
      <title>PyTorchでVAEのモデルを実装してMNISTの画像を生成する</title>
      <link>https://www.sambaiz.net/article/212/</link>
      <pubDate>Thu, 07 Mar 2019 19:35:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/212/</guid>
      <description>PyTorchでVAEを実装しMNISTの画像を生成する。 生成モデルVAE(Variational Autoencoder) - sambaiz-net 学習データ datasetsのMNIS</description>
    </item>
    <item>
      <title>SageMaker NotebookでGitリポジトリにSSHでpush/pullできるようにする</title>
      <link>https://www.sambaiz.net/article/211/</link>
      <pubDate>Mon, 04 Mar 2019 22:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/211/</guid>
      <description>Sagemaker NotebookはAWSの機械学習のワークフローを提供するSageMakerの一部である マネージドなJupyter Notebooksで、可</description>
    </item>
    <item>
      <title>生成モデルGAN(Generative Adversarial Network)</title>
      <link>https://www.sambaiz.net/article/210/</link>
      <pubDate>Fri, 22 Feb 2019 23:38:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/210/</guid>
      <description>GAN(Generative Adversarial Network)は生成器Gと、データが本物かどうか識別する識別器Dを交互に最適化していく生成モデル。 データの評価は識別器によって行われる</description>
    </item>
    <item>
      <title>PyTorchでMNISTする</title>
      <link>https://www.sambaiz.net/article/205/</link>
      <pubDate>Sat, 19 Jan 2019 23:35:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/205/</guid>
      <description>PyTorchはFacebookによるOSSの機械学習フレームワーク。 TensorFlow(v1)よりも簡単に使うことができる。 TensorFlow 2.0では</description>
    </item>
    <item>
      <title>強化学習とDQN(Deep Q-network)</title>
      <link>https://www.sambaiz.net/article/202/</link>
      <pubDate>Tue, 18 Dec 2018 01:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/202/</guid>
      <description>強化学習というのは将来に得られる報酬を最大化するような行動を学習していくもの。 状態価値関数による学習 状態sのときに取る行動aを決定する方策(</description>
    </item>
    <item>
      <title>生成モデルVAE(Variational Autoencoder)</title>
      <link>https://www.sambaiz.net/article/201/</link>
      <pubDate>Tue, 11 Dec 2018 00:23:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/201/</guid>
      <description>生成モデルというのはデータの分布をモデリングしてそこから新しいデータを生成するもの。 VAEは入力xに対して何らかの分布を仮定し、例えばガウス</description>
    </item>
    <item>
      <title>Encoder-Decoder RNNのAttention</title>
      <link>https://www.sambaiz.net/article/200/</link>
      <pubDate>Sat, 01 Dec 2018 23:09:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/200/</guid>
      <description>Encoder-Decoder RNNは入力用のEncoderと出力用のDecoderの2つのLSTMを組み合わせたもので、EncoderのStateはDecoderに繋</description>
    </item>
    <item>
      <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</title>
      <link>https://www.sambaiz.net/article/199/</link>
      <pubDate>Tue, 27 Nov 2018 09:57:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/199/</guid>
      <description>TPU(Tensor Processing Unit)は Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。 一般的なGPU</description>
    </item>
    <item>
      <title>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する</title>
      <link>https://www.sambaiz.net/article/198/</link>
      <pubDate>Wed, 14 Nov 2018 02:52:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/198/</guid>
      <description>Batch Normalizationとは Deep Learningでは各層の学習を同時に行うため、前の層の変更によって各層の入力の分布が変わってしまうint</description>
    </item>
    <item>
      <title>TensorFlow&#43;numpyでData Augmentationして画像の学習データを増やす</title>
      <link>https://www.sambaiz.net/article/197/</link>
      <pubDate>Sun, 11 Nov 2018 15:10:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/197/</guid>
      <description>Data Augmentationは学習データを加工したものを学習データに加えることで数を増やすというもの。 加工したデータには通常元のものと同じラベ</description>
    </item>
    <item>
      <title>MLPと誤差逆伝搬法(Backpropagation)</title>
      <link>https://www.sambaiz.net/article/192/</link>
      <pubDate>Sun, 21 Oct 2018 19:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/192/</guid>
      <description>MLP(多層パーセプトロン)は入力層と出力層の間に隠れ層を重ねることによって、 ロジスティック回帰(単純パーセプトロン)ではできなかった非線形</description>
    </item>
    <item>
      <title>ロジスティック回帰の尤度と交差エントロピーと勾配降下法</title>
      <link>https://www.sambaiz.net/article/191/</link>
      <pubDate>Sun, 14 Oct 2018 23:28:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/191/</guid>
      <description>ロジスティック回帰 単純パーセプトロンの活性化関数を、0か1の値を取るステップ関数ではなく値域\((0,1)\)のシグモイド関数\(\sigm</description>
    </item>
    <item>
      <title>Destributed TensorFlowの流れとSavedModelの出力</title>
      <link>https://www.sambaiz.net/article/179/</link>
      <pubDate>Wed, 25 Jul 2018 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/179/</guid>
      <description>Distributed TensorFlow クラスタを組んでGraphを分散実行する。 クラスタは master: sessionを作成し、workerを制御する worker: 計算を行う ps(parameter server): 変数の値を持ち、更新</description>
    </item>
    <item>
      <title>TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー</title>
      <link>https://www.sambaiz.net/article/175/</link>
      <pubDate>Sun, 01 Jul 2018 23:50:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/175/</guid>
      <description>MonitoredSession deprecatedになったSupervisorの後継。 MonitoredTrainingSessionで学習用のMonitoredSes</description>
    </item>
    <item>
      <title>TensorFlowのモデルをsave/loadする</title>
      <link>https://www.sambaiz.net/article/172/</link>
      <pubDate>Fri, 22 Jun 2018 01:48:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/172/</guid>
      <description>SavedModelBuilderで モデルを言語に依存しないSavedModelのprotobufにして保存できる。 SavedModelには</description>
    </item>
    <item>
      <title>ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す</title>
      <link>https://www.sambaiz.net/article/169/</link>
      <pubDate>Sun, 10 Jun 2018 17:50:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/169/</guid>
      <description>ベイズ最適化で良いハイパーパラメータを総当りのグリッドサーチより効率的に探す。 ベイズ最適化はSMBO(Sequential Model-based Global Optimiz</description>
    </item>
    <item>
      <title>KaggleのTitanicのチュートリアルをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/168/</link>
      <pubDate>Sat, 02 Jun 2018 18:16:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/168/</guid>
      <description>XGBoostは高性能なGradient Boostingのライブラリ。 Boostingというのはアンサンブル学習の種類の一つで、ランダムフォ</description>
    </item>
    <item>
      <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
      <link>https://www.sambaiz.net/article/166/</link>
      <pubDate>Tue, 29 May 2018 09:33:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/166/</guid>
      <description>ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成し並列に学習するアンサンブル学習のBaggingという種類の手</description>
    </item>
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが</description>
    </item>
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、そ</description>
    </item>
    <item>
      <title>Lpノルムと正則化</title>
      <link>https://www.sambaiz.net/article/137/</link>
      <pubDate>Thu, 12 Oct 2017 23:48:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/137/</guid>
      <description>ノルムとは ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。 p(av) = |a| p(v): スケーラブル p(u + v) ≦ p(u) + p(v): 三角不等式を満たす p(v) ≧ 0: 負の値を取ら</description>
    </item>
    <item>
      <title>自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数</title>
      <link>https://www.sambaiz.net/article/134/</link>
      <pubDate>Mon, 25 Sep 2017 23:50:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/134/</guid>
      <description>自己情報量 P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。 log(P)+log(Q)=log(P*Q) より加法性がある。</description>
    </item>
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>活性化関数というのは各層での重み掛けバイアス足しのあとに適用する非線形の関数。 これはカーネル法のように空間を変換して線形分離できないデータを</description>
    </item>
    <item>
      <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
      <link>https://www.sambaiz.net/article/124/</link>
      <pubDate>Sun, 06 Aug 2017 23:54:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/124/</guid>
      <description>AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリSonnetを使う。 当初はPython2しか対応してい</description>
    </item>
  </channel>
</rss>
