<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machinelearning on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/machinelearning/</link>
    <description>Recent content in Machinelearning on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sat, 02 Jun 2018 18:16:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>KaggleのTitanicのチュートリアルをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/168/</link>
      <pubDate>Sat, 02 Jun 2018 18:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/168/</guid>
      <description>XGBoostは高性能なGradient Boostingのライブラリ。 Boostingというのはアンサンブル学習の種類の一つで、ランダムフォレストのように弱学習器をそれぞれ並列に学習するBaggingに対して、 前回の結果を引き継ぎながら順番に学習するもの。XGBoostではランダムフォレストと同様に決定木を弱学習器とする。
KaggleのTitanicのチュートリアルをランダムフォレストで解く
$ pip install xgboost  データの前処理はランダムフォレストと同じようにした。 パラメータの objective(目的関数)には二値分類なのでbinary:logisticを指定し、確率が返るのでroundして結果を出している。
import pandas as pd import xgboost as xgb from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int) df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1) return df def train(df): train_x = df.</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
      <link>https://www.sambaiz.net/article/166/</link>
      <pubDate>Tue, 29 May 2018 09:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/166/</guid>
      <description>ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成し並列に学習するアンサンブル学習のBaggingという種類の手法。 決定木なので特徴量の影響が分かりやすく、単一の決定木と比べて過学習を防ぐことができる。
KaggleのTitanicのチュートリアルをXGBoostで解く
train.csvとtest.csvをKaggleからダウンロードする。 csvにはタイタニックの乗客者リストが含まれ、test.csvには生還したかを表すSurvivedが抜けている。 これを予測するのがこのコンペティションの目的だ。
データのうちFareやAge、Embarkedは入っていないものがあって、これらの欠損値をどう扱うという問題がある。
df = pd.read_csv(&#39;./train.csv&#39;) print(len(df)) print(df.isnull().sum())  891 PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64  連続値をとるFareとAgeは平均を取り、Embarkedは欠損値用の値にしてみた。数値化できないものについては除いている。
def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).</description>
    </item>
    
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。 全体のコードはここ。
入力 以下の関数によって生成した1次元のデータ列。 これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。
def make_time_series_data(size): data = [] for i in range(size): data.append(sin(random.normalvariate(i,0.1)*0.1)) return np.reshape(np.array(data, dtype=np.float32), (size,1)) def make_batch(data, batch_size, num_steps, num_dimensions, name=None): epoch_size = data.size // (batch_size*num_steps*num_dimensions) data = np.lib.stride_tricks.as_strided( data, shape= (epoch_size, batch_size, num_steps+1, num_dimensions), strides=( 4*batch_size*num_steps*num_dimensions, 4*num_steps*num_dimensions, 4*num_dimensions, 4 # bytes ), writeable=False )  モデル input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。 lossはMSE(Mean squared error)。OptimizerはGradientDecentOptimizerを使っている。
チュートリアルでは自力で各time_stepの値を入れていたけど、 今回はdynamic_rnn()に任せている。
class Model(object):dc def __init__(self, config, is_training=False): # config self.</description>
    </item>
    
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。
RNN/LSTMとは RNNは入力に対して出力のほかに情報を次のステップに渡すネットワーク。 展開すると同じネットワークに単語を一つずつ入れていくように表現できる。
TensorflowではいくつかRNNの実装が用意されていて、このコードではそのうちのCudnnLSTMやBasicLSTMCell、LSTMBlockCellを選べるようになっている。cuDNNというのはNVIDIAのCUDAのDNNライブラリのこと。LSTMBlockCellはBasicLSTMCellより速い。
LSTM(Long Short Term Memory networks)はRNNの一種で、入力にtanhを通す通常のRNNの処理に加え、それぞれ重みを持ち、どの値を更新するか決定するinput gateや、どの値を忘れるかを決定するforget gate、何を出力するか決定するoutput gateを通す。 こちらはtanhではなく値域(0,1)のシグモイドを通したものを掛けていくので、0であれば情報は失われ、1であれば完全に残る。
動かしてみる $ git clone https://github.com/tensorflow/models.git $ cd models/tutorials/rnn/ptb/ $ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz $ tar xvf simple-examples.tgz $ python3 -m venv env $ . ./env/bin/activate $ pip install numpy tensorflow  $ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0 Epoch: 1 Learning rate: 1.000 0.004 perplexity: 5534.452 speed: 894 wps 0.104 perplexity: 845.383 speed: 1277 wps ... 0.803 perplexity: 316.</description>
    </item>
    
    <item>
      <title>Lpノルムと正則化</title>
      <link>https://www.sambaiz.net/article/137/</link>
      <pubDate>Thu, 12 Oct 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/137/</guid>
      <description>ノルムとは ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。
 p(av) = |a| p(v): スケーラブル p(u + v) ≦ p(u) + p(v): 三角不等式を満たす p(v) ≧ 0: 負の値を取らない p(v) = 0 &amp;lt;=&amp;gt; v=0: 距離が0 &amp;lt;=&amp;gt; 零ベクトル  以下の式で表されるノルムをLpノルムと呼ぶ。
L1ノルム(マンハッタン距離) 絶対値の和。座標軸方向にしか移動できない縛りでの距離。 StreetとAvenueが格子状になっているマンハッタンではタクシーが移動する距離はL1ノルムのようになる。
L2ノルム(ユークリッド距離) 2乗の和の平方根。普通の距離。
正則化(regularization) 機械学習で過学習を防ぐためのもの。 Lp正則化は重みのLpノルムをp乗してハイパーパラメータΛを掛けたものを正則化項として 素の損失関数に加える。これを最小化するのだから重みがペナルティとしてはたらく。 L1正則化ではΛが大きければいくつかの重みが0になって次元削減できるが、 L2正則化では重みに比例して小さくなるだけ。それぞれLasso回帰、Ridge回帰ともいう。 また、これらを割合で足して使うElasticNetというものもある。
参考 Norm (mathematics) - Wikipedia
RでL1 / L2正則化を実践する - 六本木で働くデータサイエンティストのブログ</description>
    </item>
    
    <item>
      <title>自己情報量、エントロピー、KL情報量、交差エントロピー</title>
      <link>https://www.sambaiz.net/article/134/</link>
      <pubDate>Mon, 25 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/134/</guid>
      <description>自己情報量 P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。
log(P)+log(Q)=log(P*Q)より加法性がある。 例えば、サイコロで1の目が2回連続で出る(P=1&amp;frasl;36)情報量(5.16bits)はサイコロで1の目が出る(P=1&amp;frasl;6)情報量(2.58bits)の2倍と等しい。 確率が高ければ高いほど自己情報量は小さくなり、P(ω)=1では0bitになる。
エントロピー 確率分布Pに従う確率変数Xのエントロピーは以下の式で定義される。情報量の平均。
これは情報を送る際に必要なビット数の平均の下限になっている。 例えば、Xが1~4の値を(0.8, 0.1, 0.06, 0.04)の確率でとるとする。 4通りなのだからそれぞれ2bits(00, 01, 10, 11)のコードで表すこともできるが、 ほとんど3や4は出ないのだからbit数を偏らせて(0, 10, 110, 111)のコードで表すと 0.8*1 + 0.1*2 + 0.06*3 + 0.04*3 = 1.3bitsまで減らすことができる。 この場合のエントロピーは1.01bitsで、これより小さくすることはできない。
カルバック・ライブラー情報量 離散確率分布PのQに対するカルバック・ライブラー情報量は以下の式で定義される。連続確率分布では積分する。 Qの自己情報量からPの自己情報量を引いて平均を取ったもの。ギブスの不等式より非負の値を取る。
交差エントロピー 離散確率分布PとQの交差エントロピーは以下の式で定義される。連続確率分布では積分する。 PのエントロピーにPのQに対するKL情報量を足したもの。
これはQの分布に最適化されたコードでPの分布の確率変数の情報を送ってしまった際に必要なビット数の平均の下限になっている。KL情報量が余分な分。
参考 Self-information - Wikipedia
Kullback–Leibler divergence - Wikipedia
情報理論を視覚的に理解する (3&amp;frasl;4) | コンピュータサイエンス | POSTD</description>
    </item>
    
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>ニューラルネットワークの活性化関数は各層での重み掛けバイアス足しのあとに適用する非線形の関数。 というのも、線形な計算を繰り返したところで
f(x) = ax + b g(x) = f(f(x)) = (a^2)x + (ab + b)  のように単一の線形関数で表現できてしまい、多層にする意味がないため。 また、バックプロバゲーション(誤差逆伝播法)のために微分できる必要もある。
Tensorflowでも以下の活性化関数が用意されている。
sigmoid y = 1 / (1 + exp(-x))。値域は(0,1)でシグマの語末系ςに似たS字を描く。 xが大きいときに微分係数が小さくなるため、何層もこの関数を適用するとき、バックプロバゲーションで微分係数を掛けた結果、勾配が消滅(Gradient vanishing)する問題があり、あまり使われないようだ。値域が(-1,1)で似たグラフを描くtanh(Hyperbolic tangent)もある。
softsign x/(1 + abs(x))。tanhと比べて漸近線に近づく速度が遅くなっている。 それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。
softplus log(1 + exp(x))。ReLUに続く。
ReLU(Rectified Linear Unit) max(0, x)。単純だけど最有力。Gradient vanishingも起きない。 softplusと比べてexpやlogを含まない分高速に計算できるので、 膨大で複雑なデータセットに対して多くの層を用いることができる。
0以下は等しく0になるため、トレーニング中に落ちてしまうとニューロンが死んでしまうことがある。 そのような場合は0以下のときy = exp(x) - 1にするELU(Exponential Linear Unit) などを使う。
参考 Activation functions and it’s types-Which is better?
最適化から見たディープラーニングの考え方
Understanding the difficulty of training deep feedforward neural networks</description>
    </item>
    
  </channel>
</rss>