<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machinelearning on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/machinelearning/</link>
    <description>Recent content in Machinelearning on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sat, 19 Jan 2019 23:35:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PyTorchでMNISTする</title>
      <link>https://www.sambaiz.net/article/205/</link>
      <pubDate>Sat, 19 Jan 2019 23:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/205/</guid>
      <description>PyTorchはFacebookによるOSSの機械学習フレームワーク。 TensorFlow(v1)よりも簡単に使うことができる。 TensorFlow 2.0ではPyTorchのようにDefine-by-runなeager executionがデフォルトになるのに加え、パッケージも整理されるようなのでいくらか近くなると思われる。
使い方 インストール Colabで動かす。まずpipでインストール。
!pip install torch torchvision  autograd(自動微分) Tensorは自身が作成された関数の参照.grad_fnを持ち、backward()が呼ばれるとbackpropしてrequires_grad=TrueなTensorの勾配を自動で計算し.gradに入れてくれる。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
import torch x = torch.randn(4, 4) y = torch.randn(4, 1) w = torch.randn(4, 1, requires_grad=True) b = torch.randn(1, requires_grad=True) y_pred = torch.matmul(x, w) + b loss = (y_pred - y).pow(2).sum() print(x.grad, w.grad) # None None loss.backward() print(x.grad, w.grad) # None tensor([...]) with torch.no_grad(): y_eval = torch.matmul(x, w) + b print(y_eval.requires_grad) # False  Module nnパッケージにLinearやConv2dといったModuleが実装されていて、次のように呼び出すとforward()が 呼ばれ順伝播する。</description>
    </item>
    
    <item>
      <title>強化学習とDQN(Deep Q-network)</title>
      <link>https://www.sambaiz.net/article/202/</link>
      <pubDate>Tue, 18 Dec 2018 01:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/202/</guid>
      <description>強化学習というのは将来に得られる報酬を最大化するような行動を学習していくもの。
状態価値関数による学習 状態sのときに取る行動aを決定する方策(Policy)をπ(s)、次の状態s&amp;rsquo;を予測するモデルをP(s,a,s&amp;rsquo;)、直後に得られる即時報酬r_{t+1}を予測するモデルをR(s,a)とすると、将来得られる報酬の期待値である状態価値関数Vπは次の式で再帰的に表すことができ、この形式をベルマン方程式という。 同じ報酬なら早くに得られた方が良いという考えから将来の報酬rは1ステップ遅れるたびに割引率γが掛けられる。
どんな状態においても状態価値関数を最大化させる最適方策π*を探すにあたり、定義通り将来の報酬を待つのではなく、即時報酬Rで状態価値関数Vを更新していく。これをTD(Temporal difference)学習という。
取り得る状態数が多いと収束するまでの時間が長くなる問題があって、これを価値関数の近似によって解消するのがDQN。
DQN (Deep Q-Network) DNNでQ学習を行う。Q学習というのは状態sのときに行動aしたときの報酬の期待値である行動価値関数Qを最大化させるように学習させるもので、 最も良かった行動でQを更新していく。 未知の行動を探索するかどうかはバンディットアルゴリズムのε-greedyによって確率的に決定し、学習が進むにつれて確率は下がっていく。
前もってランダムに行動と結果をサンプリングしておき学習の際に使う、ER(Experience Replay)というテクニックが使われる。 これによって実行回数が減るだけではなく、時系列的な相関を減らし効率的に学習させることができる。
またmain-networkとは別に、同じ形式のtarget-networkを作ってQ(s&amp;rsquo;=s_{t+1}, a)の値を出すのに使う。 target-networkのパラメータはmain-networkのものを定期的に同期させる以外では更新しないことで学習を安定させることができる。 これをFixed Target Q-Networkという。
参考 強化学習の基礎
第14回　深層強化学習DQN（Deep Q-Network）の解説｜Tech Book Zone Manatee</description>
    </item>
    
    <item>
      <title>生成モデルVAE(Variational Autoencoder)</title>
      <link>https://www.sambaiz.net/article/201/</link>
      <pubDate>Tue, 11 Dec 2018 00:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/201/</guid>
      <description>生成モデルというのはデータの分布をモデリングしてそこから新しいデータを生成するもの。 VAEは入力xに対して何らかの分布を仮定し、例えばガウス分布(正規分布)だとすると平均μと分散σを推論し、 これをz=μ+(σ・ε) (ε~N(0,1))の潜在変数に変換して生成モデルへの入力とし、その出力の尤度が最大化するように学習させる。
Variational Autoencoderという名前はこの分布を推論して生成する流れがAutoencoderの形式と似ているところから来ている。 Autoencoder(自己符号化器)というのはある入力をエンコードしてデコードしたときに入力と同じものを出力するように学習させたもので、 これによって次元削減された潜在変数zが得られる。
推論モデルの確率分布をq、生成モデルの確率分布をpとする。対数尤度log{p}を計算したいが潜在変数zが訓練データにないので周辺化する(1)。 これを変換していくと(2)のようになり、第二項のKL情報量は0以上の値になるので第一項のLを最大化することが対数尤度の最大化につながる。 このLをEvidence Lower Bound (ELBO)といい、推論モデルのパラメータφと生成モデルのパラメータθを交互に最適化して これを最大化させることで尤度の下界を引き上げていく。
自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net
生成モデルがベルヌーイ分布、p(z)が標準正規分布で、log{p}はzに対してモンテカルロサンプリングするとELBOは次のようになる。
ほかの生成モデルとしてGAN(Generative Adversarial Networks)があって、これはデータの分布を最初に仮定せずより近い分布から良いデータを生成するのを目指す。
参考 Kerasで学ぶAutoencoder
Carl Doersch (2016) Tutorial on Variational Autoencoders
Variational Autoencoder徹底解説 - Qiita</description>
    </item>
    
    <item>
      <title>Encoder-Decoder RNNのAttention</title>
      <link>https://www.sambaiz.net/article/200/</link>
      <pubDate>Sat, 01 Dec 2018 23:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/200/</guid>
      <description>Encoder-Decoder RNNは入力用のEncoderと出力用のDecoderの2つのLSTMを組み合わせたもので、EncoderのStateはDecoderに繋げる。
したがって入力データはDecoderに渡されるStateにまとめられることになるが、 出力ごとに入力時系列の重要な部分は異なるため、特定の部分に注目できるようにすると良い結果が期待できる。 次の論文ではAttention Layerを追加することでこれを行い翻訳の精度を向上させている。
Minh-Thang Luong, Hieu Pham, Christopher D. Manning (2015) Effective Approaches to Attention-based Neural Machine Translation
Attention LayerはEncoderの出力とDecoderの対象の出力からどの部分を重要とするかを表すAlign weights a(t)と Encoderの出力を掛けたものをContext vector c(t)として出力する。 scoreにはそのまま掛けたものや(h_{dec}h_{enc})、重みとDecoderの出力のみを掛ける(Wh_{dec})といったものが使われる。</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</title>
      <link>https://www.sambaiz.net/article/199/</link>
      <pubDate>Tue, 27 Nov 2018 09:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/199/</guid>
      <description>TPU(Tensor Processing Unit)は Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。 一般的なGPUと比べて15~30倍もの性能が出る らしく検索や翻訳などGoogleのサービスでも使われている。
TPUを使える環境として、無料で使えるJupyter NotebooksのGoogle Colabと GCPのCloud TPUがある。ColabのTPUも裏側ではCloud TPUが動いている。 Cloud TPUを直に使うとVMから接続して使うことになるので、TPUの料金に加えてVMの料金もかかる。
モデルのTPU対応 CNNのモデルをTPUEstimatorでTPUに対応させる。
EstimatorはTensorFlowの高レベルAPIで、 train()、 evaluate()、 predict()、 export_saved_model() といったモデルの学習から保存まで必要な機能を一通り提供する。
初めは比較的低レベルのAPIを使おうとしていたが、XLA(Accelerated Linear Algebra)によるコンパイルがうまくいかないなど様々な問題にあたって大変だったので使っておくと良いと思う。 それでもトライアンドエラーの繰り返しで、典型的なものはTroubleshootingにあるが、ないものは調べるなりしてなんとかやっていくしかない。
定数などの定義。BATCH_SIZEはCloud TPUのシャード数の8で割り切れる値にする必要がある。
import pandas as pd from sklearn.model_selection import train_test_split import tensorflow as tf import numpy as np flags = tf.app.flags flags.DEFINE_boolean(&#39;use_tpu&#39;, True, &#39;use tpu or not&#39;) tf.app.flags.DEFINE_string(&#39;f&#39;, &#39;&#39;, &#39;kernel&#39;) FLAGS = flags.FLAGS EPOCH_NUM = 100 BATCH_SIZE = 800 # must be divisible by number of replicas 8 EVAL_BATCH_SIZE = 800 SHARD_NUM = 8 # A single Cloud TPU has 8 shards.</description>
    </item>
    
    <item>
      <title>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する</title>
      <link>https://www.sambaiz.net/article/198/</link>
      <pubDate>Wed, 14 Nov 2018 02:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/198/</guid>
      <description>Batch Normalizationとは Deep Learningでは各層の学習を同時に行うため、前の層の変更によって各層の入力の分布が変わってしまうinternal covariate shiftという現象が起こり、そのためにパラメータの初期化をうまくやる必要があったり、学習率を大きくできず多くのステップを要する。 以下の論文で発表されたBatch Normalization(BN)は各層の入力を正規化して分布を固定することでこれを解決するというもの。 画像認識のコンテストILSVRC 2015で1位を取ったResNet(Residual Network)でも使われている。
Sergey Ioffe, Christian Szegedy (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
具体的にはWx+bと活性化関数の間にBNの層を入れる。μ、σ^2は入力xの平均と分散。 単に正規化するだけでは表現力が下がってしまうのでγとβでスケールやシフトできるようにする。これらの変数は他のパラメータと同様に学習させる。
TensorFlowでの確認 TensorFlowではbatch_normalization()がすでに実装されているのでこれを使う。
以下のCNNで学習率を高めに設定しBNありなしの結果を比較する。学習データはmnist。MonitoredSessionでcostをsummaryとして出力しTensorBoardで見られるようにしている。
TensorBoardでsummaryやグラフを見る - sambaiz-net
TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net
import pandas as pd import numpy as np import tensorflow as tf from sklearn.model_selection import train_test_split from sklearn.utils import shuffle from sklearn.metrics import accuracy_score train = pd.read_csv(&#39;./train.csv&#39;) (x_train, x_valid ,y_train, y_valid) = train_test_split( train.</description>
    </item>
    
    <item>
      <title>TensorFlow&#43;numpyでData Augmentationして画像の学習データを増やす</title>
      <link>https://www.sambaiz.net/article/197/</link>
      <pubDate>Sun, 11 Nov 2018 15:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/197/</guid>
      <description>Data Augmentationは学習データを加工したものを学習データに加えることで数を増やすというもの。 加工したデータには通常元のものと同じラベルが付くことになるが、 例えば画像を反転や回転させても元々のものと同じだと認識されるべきだとしたら妥当だ。 つまり、なんでもすれば良いわけではなくデータセットに応じた、元のデータと同じラベルが付くような加工をする必要があり、 裏を返せばそのような違いがあっても同じものであることをモデルに学習させることができる。
今回はData Augmentationで行われる加工をTensorFlowやnumpyの関数でおなじみLennaの画像に行う。
必要なパッケージと画像をimportする。Jupyter Notebooksで実行する。
%matplotlib inline from PIL import Image import matplotlib.pyplot as plt import numpy as np import tensorflow as tf im = Image.open(&amp;quot;lenna.png&amp;quot;, &amp;quot;r&amp;quot;)  Flipping  flip_left_right() random_flip_left_right() flip_up_down() random_flip_up_down()  左右と上下の反転。randomは1/2で反転する。
fliph = tf.image.flip_left_right(im) flipv = tf.image.flip_up_down(im) with tf.Session() as sess: results = sess.run([fliph, flipv]) plt.imshow(np.hstack(results))  Rotating  rot90()  反時計周りに90度回転させる。
rot90 = tf.image.rot90(im) with tf.Session() as sess: results = sess.</description>
    </item>
    
    <item>
      <title>MLPと誤差逆伝搬法(Backpropagation)</title>
      <link>https://www.sambaiz.net/article/192/</link>
      <pubDate>Sun, 21 Oct 2018 19:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/192/</guid>
      <description>MLP(多層パーセプトロン)は入力層と出力層の間に隠れ層を重ねることによって、 ロジスティック回帰(単純パーセプトロン)ではできなかった非線形分離をできるようにしたニューラルネットワークモデル。
ロジスティック回帰の尤度と交差エントロピー誤差と勾配降下法 - sambaiz-net
入出力がx、y、層の数がLでl層目での重みとバイアスをW^(l), b^(l)、活性化関数をf^(l)、活性化関数適用前後をu^(l)とh^(l)とし、入力層を0層目とすると各層での演算は以下の式で表される。
活性化関数は非線形で微分可能な関数で、計算速度や勾配消失の面でReLUが最有力。
ニューラルネットワークと活性化関数 - sambaiz-net
各層の最適なWとbを探すのにロジスティック回帰と同様に勾配降下法を使うことができる。 誤差関数は分類の場合は交差エントロピーが、回帰の場合は平均二乗誤差(MSE, Mean Squared Error) または外れ値に引っ張られづらくしたHuber損失などが使われる。
隠れ層の勾配はそれより後ろの層での演算が影響するので、入力から出力への順伝搬に対して 出力から入力への逆伝播で誤差の情報を前の層に伝播させていく。これを誤差逆伝播法(Backpropagation)という。
出力から遠くなればなるほど連鎖律が長くなっていくが、途中までは後ろの層と共通になっている。 ということで順伝搬時のhを保存しておき一つ後ろの層のWと誤差δを渡してやれば必要最小限の演算で済み、実行時間を短くすることができる。
参考 深層学習</description>
    </item>
    
    <item>
      <title>ロジスティック回帰の尤度と交差エントロピーと勾配降下法</title>
      <link>https://www.sambaiz.net/article/191/</link>
      <pubDate>Sun, 14 Oct 2018 23:28:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/191/</guid>
      <description>ロジスティック回帰 単純パーセプトロンの活性化関数を0/1のステップ関数ではなく0~1のシグモイド関数にしたモデルで、分類の確率を返すことができる。
ニューラルネットワークと活性化関数 - sambaiz-net
線形分離不可能な場合はうまくいかない。入力と出力の間に隠れ層があるMLPでは非線形分離もできる。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
尤度関数と交差エントロピー誤差関数 尤度(likelihood)関数はXという事象が観察されたときにC=tである尤もらしさを表す関数。 例えば、6面ダイスを2回振って両方1の目が出た(X)ときに1の目が出る確率が1/6&amp;copy;である尤度は(1&amp;frasl;6)*(1&amp;frasl;6)=1/36となる。
学習ではモデルのパラメータw,bを、各入力x(x1,x2,&amp;hellip;,xn)に対して正解であるC=tの尤度の和が最大になるように最適化していく。 通常のロジスティック回帰では二値分類を行うので正解データtは{0,1}とし、P(C=1) = 1-P(C=0)となる。
ただ、このままだと積になっていて計算しづらいので、対数を取って和にして、 損失として扱うため負の数にする。これを交差エントロピー誤差関数という。 この値を最小化させるということは尤度を最大化させることになる。
自己情報量、エントロピー、KL情報量、交差エントロピー - sambaiz-net
勾配降下法 誤差をw,bでそれぞれ偏微分したのを引いてパラメータを更新していき、 勾配が0になるような値を探す。
ηは学習率で正の小さな値にする。 大きすぎると収束しないが、小さすぎても収束に必要なステップ数が増え、さらに局所最適解で止まってしまう可能性が高まるので 最初は大きくして徐々に小さくしていったりする。
ほかに局所最適解で止まるのを避ける手法として、サンプル全体ではなく毎回異なる一部を使う(Minibatch)確率的勾配降下法(SGD: Stochastic Gradient Descent)や、SGDに慣性を追加したMomentumなどがある。
多クラスロジスティック回帰 活性化関数をsoftmax関数にすると多クラス分類できる。
多クラスの場合の正解データtは{0,1,2,&amp;hellip;}といったようにはせず 正解のindexだけ1でほかは0のone-hot vectorで表し、尤度関数、交差エントロピー誤差関数は以下のようになる。
偏微分するとこうなる。
あとは同様に勾配降下法でパラメータを更新していく。
参考 詳解 ディープラーニング ~TensorFlow・Kerasによる時系列データ処理~</description>
    </item>
    
    <item>
      <title>Destributed TensorFlowの流れとSavedModelの出力</title>
      <link>https://www.sambaiz.net/article/179/</link>
      <pubDate>Wed, 25 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/179/</guid>
      <description>Distributed TensorFlow クラスタを組んでGraphを分散実行する。
クラスタは
 master: sessionを作成し、workerを制御する worker: 計算を行う ps(parameter server): 変数の値を持ち、更新する  のjobからなり、gRPCの
 Master Service Worker Service  でやり取りする。
TensorFlow serverを立てる 各jobとURLのmapをClusterSpecにして jobとindexと併せてServerDefを作って Serverを立てる。
{ &amp;quot;master&amp;quot;: [ &amp;quot;check-tf-config-master-34z8-0:2222&amp;quot; ], &amp;quot;ps&amp;quot;: [ &amp;quot;check-tf-config-ps-34z8-0:2222&amp;quot;, &amp;quot;check-tf-config-ps-34z8-1:2222&amp;quot; ], &amp;quot;worker&amp;quot;: [ &amp;quot;check-tf-config-worker-34z8-0:2222&amp;quot;, &amp;quot;check-tf-config-worker-34z8-1:2222&amp;quot; ] }  cluster_spec_object = tf.train.ClusterSpec(cluster_spec) server_def = tf.train.ServerDef( cluster=cluster_spec_object.as_cluster_def(), protocol=&amp;quot;grpc&amp;quot;, job_name=job_name, # worker, master, ps task_index=0) server = tf.train.Server(server_def)  psのjobではserver.join()して待ち構える。
if job_name == &amp;quot;ps&amp;quot;: server.join() else: # build model  WorkerにGraphを割り当てる workerのdeviceにGraphを割り当てる。 deviceは/job:worker/replica:0/task:0/device:GPU:0 のようなフォーマットで表される。</description>
    </item>
    
    <item>
      <title>TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー</title>
      <link>https://www.sambaiz.net/article/175/</link>
      <pubDate>Sun, 01 Jul 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/175/</guid>
      <description>MonitoredSession
deprecatedになったSupervisorの後継。
MonitoredTrainingSessionで学習用のMonitoredSessionを生成する。 このコンストラクタの引数でcheckpoint_dirを渡すと内部でCheckpointSaverHookが 追加されるようになっていて、restoreしたり指定したタイミングでsaveしたりしてくれる。
なので今回明示的に渡すhooksは 指定したstepに到達したら止めてくれる、StopAtStepHookのみ。
should_stop()がTrueな状態でsession.run()しようとするとRun called even after should_stop requested.のエラーが出るため、 今回は新しいsessionを作ってAccuracyを返しているが、hookでやった方がrestoreする必要がないので良さそうだ。
Destributed TensorFlowの流れとSavedModelの出力 - sambaiz-net
全体のコードはここ。
def train(self, learning_rate, variable_default_stddev, bias_default, last_step=800): test_images = self.images[:500] test_labels = self.labels[:500] train_batch = Batch(self.images[500:], self.labels[500:]) with tf.Graph().as_default(): global_step=tf.train.get_or_create_global_step() g = MNIST_CNN(learning_rate, variable_default_stddev, bias_default).graph() saver = tf.train.Saver() savedir = &#39;./ckpt-{}-{}-{}&#39;.format(learning_rate, variable_default_stddev, bias_default) hooks = [ tf.train.StopAtStepHook(last_step=last_step) ] with tf.train.MonitoredTrainingSession( hooks=hooks, checkpoint_dir=savedir, save_checkpoint_secs = 300, ) as sess: sess.run(global_step) while not sess.should_stop(): # step = sess.</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをsave/loadする</title>
      <link>https://www.sambaiz.net/article/172/</link>
      <pubDate>Fri, 22 Jun 2018 01:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/172/</guid>
      <description>SavedModelBuilderで モデルを言語に依存しないSavedModelのprotobufにして保存できる。 SavedModelにはSaverによって出力されるCheckpointを共有する一つ以上のMetaGraphDefを含む。
import tensorflow as tf def build_signature(signature_inputs, signature_outputs): return tf.saved_model.signature_def_utils.build_signature_def( signature_inputs, signature_outputs, tf.saved_model.signature_constants.REGRESS_METHOD_NAME) def save(sess, export_dir, signature_def_map): builder = tf.saved_model.builder.SavedModelBuilder(export_dir) builder.add_meta_graph_and_variables( sess, [tf.saved_model.tag_constants.SERVING], signature_def_map=signature_def_map ) builder.save() import shutil import os.path export_dir = &amp;quot;./saved_model&amp;quot; if os.path.exists(export_dir): shutil.rmtree(export_dir) with tf.Graph().as_default(): a = tf.placeholder(tf.float32, name=&amp;quot;a&amp;quot;) b = tf.placeholder(tf.float32, name=&amp;quot;b&amp;quot;) c = tf.add(a, b, name=&amp;quot;c&amp;quot;) v = tf.placeholder(tf.float32, name=&amp;quot;v&amp;quot;) w = tf.Variable(0.0, name=&amp;quot;w&amp;quot;) x = w.assign(tf.add(v, w)) sv = tf.train.Supervisor() with sv.managed_session() as sess: print(sess.</description>
    </item>
    
    <item>
      <title>ベイズ最適化でランダムフォレストとXGBoostの良いハイパーパラメータを探す</title>
      <link>https://www.sambaiz.net/article/169/</link>
      <pubDate>Sun, 10 Jun 2018 17:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/169/</guid>
      <description>機械学習の良いハイパーパラメータを探す方法として、scikit-learnにもあるグリッドサーチがあるが、これは総当たりで試すもので時間がかかる。
それに対してベイズ最適化は、まず現在の最大値を超える確率や期待値を出力とする獲得関数を決めて、ガウス過程(GP)に従うと仮定する。 ガウス過程は回帰関数の確率モデルで、任意の入力(x1, x2, &amp;hellip; , xn)に対応する出力(y1, y2, &amp;hellip;, yn)がガウス分布(=正規分布)に従うというもの。 これによって予測されるまだ試していない入力での期待値や分散から次に試す値を決めて効率的に探すことができる。
今回はKaggleのTitanicのチュートリアルを、チューニングなしのランダムフォレストとXGBoostで解いたときの結果と比較して、ベイズ最適化によるハイパーパラメータで精度が向上するか確認する。
KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
ランダムフォレスト Pythonのベイズ最適化のライブラリ、BayesianOptimizationを使う。
$ pip install bayesian-optimization  RandomForestClassifierのハイパーパラメータ
 n_estimators: 木の数 min_samples_split: ノードを分割するのに必要な最小サンプル数 max_features: 分割するときに考慮する特徴量の割合  の値を探すため、BayesianOptimizationに最大化したい値(精度)とパラメータの範囲を渡す。
from sklearn.model_selection import cross_val_score from sklearn.ensemble import RandomForestClassifier from bayes_opt import BayesianOptimization import pandas as pd def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/168/</link>
      <pubDate>Sat, 02 Jun 2018 18:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/168/</guid>
      <description>XGBoostは高性能なGradient Boostingのライブラリ。 Boostingというのはアンサンブル学習の種類の一つで、ランダムフォレストのように弱学習器をそれぞれ並列に学習するBaggingに対して、 順番に前回までの結果を受けながら学習し、結果をまとめる際にそれぞれの重みを掛けるもの。 XGBoostではランダムフォレストと同様に決定木を弱学習器とする。
KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net
$ pip install xgboost  データの前処理はランダムフォレストと同じようにした。 パラメータの objective(目的関数)には二値分類なのでbinary:logisticを指定し、確率が返るのでroundして出力している。
import pandas as pd import xgboost as xgb from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int) df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1) return df def train(df): train_x = df.</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
      <link>https://www.sambaiz.net/article/166/</link>
      <pubDate>Tue, 29 May 2018 09:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/166/</guid>
      <description>ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成し並列に学習するアンサンブル学習のBaggingという種類の手法。 決定木なので特徴量の影響が分かりやすく、単一の決定木と比べて過学習を防ぐことができる。
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
train.csvとtest.csvをKaggleからダウンロードする。 csvにはタイタニックの乗客者リストが含まれ、test.csvには生還したかを表すSurvivedが抜けている。 これを予測するのがこのコンペティションの目的だ。
データのうちFareやAge、Embarkedは入っていないものがあって、これらの欠損値をどう扱うという問題がある。
df = pd.read_csv(&#39;./train.csv&#39;) print(len(df)) print(df.isnull().sum())  891 PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64  連続値をとるFareとAgeは平均を取り、Embarkedは欠損値用の値にしてみた。数値化できないものについては除いている。
def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).</description>
    </item>
    
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。 全体のコードはここ。
入力 以下の関数によって生成した1次元のデータ列。 これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。
def make_time_series_data(size): data = [] for i in range(size): data.append(sin(random.normalvariate(i,0.1)*0.1)) return np.reshape(np.array(data, dtype=np.float32), (size,1)) def make_batch(data, batch_size, num_steps, num_dimensions, name=None): epoch_size = data.size // (batch_size*num_steps*num_dimensions) data = np.lib.stride_tricks.as_strided( data, shape= (epoch_size, batch_size, num_steps+1, num_dimensions), strides=( 4*batch_size*num_steps*num_dimensions, 4*num_steps*num_dimensions, 4*num_dimensions, 4 # bytes ), writeable=False ) return data[:, :, :-1], data[:, :, 1:]  モデル input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。 lossはMSE(Mean squared error)。OptimizerはGradientDecentOptimizerを使っている。
チュートリアルでは自力で各time_stepの値を入れていたけど、 今回はdynamic_rnn()に任せている。</description>
    </item>
    
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。
RNN/LSTMとは RNNは入力に対して出力のほかに情報を次のステップに渡すことで時系列データで学習できるようにするネットワーク。 展開すると同じネットワークに単語を一つずつ入れていくように表現できる。
これを単純にMLPで実装しようとすると逆誤差伝搬する際に過去の層にも伝搬させる(BPTT: Backpropagation through time)必要があり、 時間を遡るほど活性化関数の微分係数が再帰的に繰り返し掛けられるため勾配が消失や爆発しやすくなってしまう。 また、時系列データのうちに発火したいものと発火したくないものが混在している場合、同じ重みにつながっているため更新を打ち消しあってしまう入力/出力重み衝突という問題もある。
これらを解決するのがLSTM(Long Short Term Memory networks)で、 勾配消失は活性化関数がxで重みが単位行列のニューロンのCEC(Constant Error Carousel)によって常に誤差に掛けられる係数を1にすることで防ぎ、 入力/出力重み衝突は必要な入出力を通したり不必要な情報は忘れさせるために値域(0,1)の値を掛けるinput gate、forget gate、output gateによって回避する。gateは入力と前回の出力によって制御される。
TensorflowではいくつかLSTMの実装が用意されていて、CudnnLSTMやBasicLSTMCell、LSTMBlockCellなどがある。 cuDNNというのはNVIDIAのCUDAのDNNライブラリのこと。 LSTMBlockCellはもう少し複雑なLSTMでBasicLSTMCellよりも速い。
動かしてみる $ git clone https://github.com/tensorflow/models.git $ cd models/tutorials/rnn/ptb/ $ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz $ tar xvf simple-examples.tgz $ python3 -m venv env $ . ./env/bin/activate $ pip install numpy tensorflow  $ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0 Epoch: 1 Learning rate: 1.000 0.004 perplexity: 5534.452 speed: 894 wps 0.</description>
    </item>
    
    <item>
      <title>Lpノルムと正則化</title>
      <link>https://www.sambaiz.net/article/137/</link>
      <pubDate>Thu, 12 Oct 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/137/</guid>
      <description>ノルムとは ノルムはベクトル空間の距離を表す、以下の条件を満たす関数p。
 p(av) = |a| p(v): スケーラブル p(u + v) ≦ p(u) + p(v): 三角不等式を満たす p(v) ≧ 0: 負の値を取らない p(v) = 0 &amp;lt;=&amp;gt; v=0: 距離が0 &amp;lt;=&amp;gt; 零ベクトル  以下の式で表されるノルムをLpノルムと呼ぶ。
L1ノルム(マンハッタン距離) 絶対値の和。座標軸方向にしか移動できない縛りでの距離。 StreetとAvenueが格子状になっているマンハッタンではタクシーが移動する距離はL1ノルムのようになる。
L2ノルム(ユークリッド距離) 2乗の和の平方根。普通の距離。
正則化(regularization) 機械学習で過学習を防ぐためのもの。 Lp正則化は重みのLpノルムをp乗してハイパーパラメータΛを掛けたものを正則化項として 素の損失関数に加える。これを最小化するのだから重みがペナルティとしてはたらく。 L1正則化ではΛが大きければいくつかの重みが0になって次元削減できるが、 L2正則化では重みに比例して小さくなるだけ。それぞれLasso回帰、Ridge回帰ともいう。 また、これらを割合で足して使うElasticNetというものもある。
参考 Norm (mathematics) - Wikipedia
RでL1 / L2正則化を実践する - 六本木で働くデータサイエンティストのブログ</description>
    </item>
    
    <item>
      <title>自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数</title>
      <link>https://www.sambaiz.net/article/134/</link>
      <pubDate>Mon, 25 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/134/</guid>
      <description>自己情報量 P(ω)の確率で起きる事象ωの自己情報量は以下の式で定義される。logの底を2にしてbitsで表すのが一般的。
log(P)+log(Q)=log(P*Q)より加法性がある。 例えば、サイコロで1の目が2回連続で出る(P=1&amp;frasl;36)情報量(5.16bits)はサイコロで1の目が出る(P=1&amp;frasl;6)情報量(2.58bits)の2倍と等しい。 確率が高ければ高いほど自己情報量は小さくなり、P(ω)=1では0bitになる。
エントロピー 確率分布Pに従う確率変数Xのエントロピーは以下の式で定義される。情報量の平均。
これは情報を送る際に必要なビット数の平均の下限になっている。 例えば、Xが1~4の値を(0.8, 0.1, 0.06, 0.04)の確率でとるとする。 4通りなのだからそれぞれ2bits(00, 01, 10, 11)のコードで表すこともできるが、 ほとんど3や4は出ないのだからbit数を偏らせて(0, 10, 110, 111)のコードで表すと 0.8*1 + 0.1*2 + 0.06*3 + 0.04*3 = 1.3bitsまで減らすことができる。 この場合のエントロピーは1.01bitsで、これより小さくすることはできない。
カルバック・ライブラー情報量 離散確率分布PのQに対するカルバック・ライブラー情報量は以下の式で定義される。連続確率分布では積分する。 Qの自己情報量からPの自己情報量を引いて平均を取ったもの。非負の値を取る。
交差エントロピー 離散確率分布PとQの交差エントロピーは以下の式で定義される。連続確率分布では積分する。 PのエントロピーにPのQに対するKL情報量を足したもの。
これはQの分布に最適化されたコードでPの分布の確率変数の情報を送ってしまった際に必要なビット数の平均の下限になっている。KL情報量が余分な分。機械学習の損失関数に使われる。
ロジスティック回帰と尤度関数/交差エントロピー誤差と勾配降下法 - sambaiz-net
参考 Self-information - Wikipedia
Kullback–Leibler divergence - Wikipedia
情報理論を視覚的に理解する (3&amp;frasl;4) | コンピュータサイエンス | POSTD</description>
    </item>
    
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>活性化関数というのは各層での重み掛けバイアス足しのあとに適用する非線形の関数。 これはカーネル法のように空間を変換して線形分離できないデータを線形分離できるようにするはたらきをする。 線形な関数を使うと層を重ねても結局線形のままで、空間もそのまま伸縮するだけなので目的を果たさない。
バックプロバゲーション(誤差逆伝播法)するために微分できる必要がある。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
Tensorflowでは以下の活性化関数が用意されている。
sigmoid 値域は(0,1)でシグマの語末系ςに似たS字を描く。 微分係数がそれほど大きくないので何層もこの関数を適用すると、バックプロバゲーションで微分係数を掛けていった結果、勾配が消失する問題がありあまり使われない。値域が(-1,1)で似たグラフを描くtanh(Hyperbolic tangent)もある。
softsign tanhと比べて漸近線に近づく速度が遅くなっている。 それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。
softplus ReLUに続く。
ReLU(Rectified Linear Unit) 単純だけど最有力。勾配消失も起きにくい。x=0で微分できないが0か1として扱われる。
def deriv_relu(x): return np.where(x &amp;gt; 0, 1, 0)  softplusと比べてexpやlogを含まない分高速に計算できるので、 膨大で複雑なデータセットに対して多くの層を用いることができる。
0以下は等しく0になるため、学習中に落ちてしまうとニューロンが死んでしまう。 これを避けるため0以下のときy = exp(x) - 1にするELU(Exponential Linear Unit) というのもある。
比較的起きにくいとはいえ、層を深くすると勾配消失する可能性は高まる。 活性化関数ごとに異なる重みの初期値によってこれを緩和でき、ReLUでは入力次元数によるHe Initializationというのが提案されている。
rng = np.random.RandomState(1234) n_in = 10 # 入力次元数 rng.uniform( low=-np.sqrt(6/n_in), high=+np.sqrt(6/n_in), size=5 ) # He Initialization  参考 Activation functions and it’s types-Which is better?</description>
    </item>
    
  </channel>
</rss>