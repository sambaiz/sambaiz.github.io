<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>elasticsearch on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/elasticsearch/</link>
    <description>Recent content in elasticsearch on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Tue, 01 Oct 2019 23:25:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/tags/elasticsearch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする</title>
      <link>https://www.sambaiz.net/article/241/</link>
      <pubDate>Tue, 01 Oct 2019 23:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/241/</guid>
      <description>Elastic Cloud on Kubernetes (ECK)で Kubernetesクラスタ上にElasticsearch, KibanaとAPM Serverを立ち上げ、外部のGo製APIサーバーのリクエストをトレースする。 クラスタはGKEで作成し、ノードプールはn2-highmem-4(2vCPU, 13GB)の3台にした。
インストール ElasticSearchやKibana, APM ServerのCRDやelastic-operatorなどをインストールする。
KubernetesのCustom Resource Definition(CRD)とCustom Controller - sambaiz-net
$ kubectl apply -f https://download.elastic.co/downloads/eck/0.9.0/all-in-one.yaml customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/trustrelationships.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created clusterrole.rbac.authorization.k8s.io/elastic-operator created clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created namespace/elastic-system created statefulset.apps/elastic-operator created secret/webhook-server-secret created serviceaccount/elastic-operator created $ kubectl get pod -n elastic-system NAME READY STATUS RESTARTS AGE elastic-operator-0 1/1 Running 1 91s $ kubectl -n elastic-system logs -f statefulset.apps/elastic-operator ... {&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1569230702.0881083,&amp;#34;logger&amp;#34;:&amp;#34;kubebuilder.controller&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;Starting workers&amp;#34;,&amp;#34;controller&amp;#34;:&amp;#34;elasticsearch-controller&amp;#34;,&amp;#34;worker count&amp;#34;:1} {&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1569230702.</description>
    </item>
    
    <item>
      <title>CuratorでElasticsearchの古いindexを削除する</title>
      <link>https://www.sambaiz.net/article/86/</link>
      <pubDate>Wed, 22 Mar 2017 00:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/86/</guid>
      <description>Curatorとは indexやsnapshotを管理するのに使えるツール。
インストール インストールする。
$ cat /etc/yum.repos.d/curator.repo [curator-4] name=CentOS/RHEL 7 repository for Elasticsearch Curator 4.x packages baseurl=http://packages.elastic.co/curator/4/centos/7 gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 $ yum install -y elasticsearch-curator $ curator --version curator, version 4.2.6 config configファイルを書く。
client: hosts: - 127.0.0.1 port: 9200 logging: loglevel: INFO logfile: logformat: default blacklist: [&amp;#39;elasticsearch&amp;#39;, &amp;#39;urllib3&amp;#39;] action 今回はindexを削除するのでdelete_indices。 対象はfilterで指定する。 logstash formatだとhogehoge-2017.01.01のようなindex名になるので%Y.%m.%d。okder than 3 daysのものを削除する。
actions: 1: action: delete_indices description: &amp;gt;- 3日前より古いhogehoge-* indexを消す filters: - filtertype: pattern kind: prefix value: hogehoge- - filtertype: age source: name direction: older timestring: &amp;#39;%Y.</description>
    </item>
    
    <item>
      <title>Elasticsearchで期間ごとの集計値を出す</title>
      <link>https://www.sambaiz.net/article/77/</link>
      <pubDate>Sun, 05 Mar 2017 01:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/77/</guid>
      <description>Bucket(SQLでいうGROUP BY)にまとめて(Bucket Aggreagtion)、集計(Metric Aggregation)する。
使うデータは作ったツールで生成したこんなの。
{&amp;#34;@timestamp&amp;#34;:1488635130,&amp;#34;os_name&amp;#34;:&amp;#34;linux&amp;#34;,&amp;#34;score&amp;#34;:82} Bucket Aggregations Date Range Aggregation date_rangeで期間のBucketを作る。この例だと今から10分前の00秒~今の分の00秒まで。
$ curl localhost:9200/hoge/_search -d&amp;#39; { &amp;#34;aggs&amp;#34;: { &amp;#34;range_10minutes&amp;#34;: { &amp;#34;date_range&amp;#34;: { &amp;#34;field&amp;#34;: &amp;#34;@timestamp&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;HH-mm-ssZ&amp;#34;, &amp;#34;ranges&amp;#34;: [ { &amp;#34;to&amp;#34;: &amp;#34;now/m&amp;#34;, &amp;#34;from&amp;#34;: &amp;#34;now-10m/m&amp;#34; } ] } } } }&amp;#39; | jq .aggregations { &amp;#34;range_10minutes&amp;#34;: { &amp;#34;buckets&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;15-17+0000-15-27+0000&amp;#34;, &amp;#34;from&amp;#34;: 1488640620000, &amp;#34;from_as_string&amp;#34;: &amp;#34;15-17+0000&amp;#34;, &amp;#34;to&amp;#34;: 1488641220000, &amp;#34;to_as_string&amp;#34;: &amp;#34;15-27+0000&amp;#34;, &amp;#34;doc_count&amp;#34;: 600 } ] } } Date Histogram Aggregation date_histogramで日付の間隔でBucketを作る。この例だと1分ごとにBucketが作られる。
$ curl localhost:9200/hoge/_search -d&amp;#39; { &amp;#34;aggs&amp;#34;: { &amp;#34;histogram_1minute&amp;#34;: { &amp;#34;date_histogram&amp;#34;: { &amp;#34;field&amp;#34;: &amp;#34;@timestamp&amp;#34;, &amp;#34;interval&amp;#34;: &amp;#34;1m&amp;#34; } } } }&amp;#39; | jq .</description>
    </item>
    
    <item>
      <title>ElasticsearchのCircuit Breaker</title>
      <link>https://www.sambaiz.net/article/71/</link>
      <pubDate>Fri, 24 Feb 2017 21:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/71/</guid>
      <description>ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net
ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。 表示されたエラーはこういうの。
&amp;#34;root_cause&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;circuit_breaking_exception&amp;#34;, &amp;#34;reason&amp;#34;: &amp;#34;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;#34;, &amp;#34;bytes_wanted&amp;#34;: 10464007168, &amp;#34;bytes_limit&amp;#34;: 8998512230 } ], これは1リクエストの集計などで使うメモリ量がしきい値をこえて Circuit Breakerが発動したということ。 メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。
情報はstatsのapiでも取得できる。
$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request { &amp;#34;limit_size_in_bytes&amp;#34;: 8998512230, &amp;#34;limit_size&amp;#34;: &amp;#34;8.3gb&amp;#34;, &amp;#34;estimated_size_in_bytes&amp;#34;: 10348347504, &amp;#34;estimated_size&amp;#34;: &amp;#34;9.6gb&amp;#34;, &amp;#34;overhead&amp;#34;: 1, &amp;#34;tripped&amp;#34;: 470 } 今回ひっかかったのはindices.breaker.request.limit。デフォルトではJVMのヒープメモリの60%になっているが、 これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。
$ curl -XPUT localhost:9200/_cluster/settings -d &amp;#39;{ &amp;#34;persistent&amp;#34; : { &amp;#34;indices.breaker.request.limit&amp;#34;: &amp;#34;80%&amp;#34;, &amp;#34;indices.breaker.total.limit&amp;#34;: &amp;#34;80%&amp;#34; } }&amp;#39; $ curl -XPUT localhost:9200/_cluster/settings -d &amp;#39;{ &amp;#34;persistent&amp;#34; : { &amp;#34;indices.</description>
    </item>
    
    <item>
      <title>Elasticsearchのmapping</title>
      <link>https://www.sambaiz.net/article/62/</link>
      <pubDate>Thu, 09 Feb 2017 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/62/</guid>
      <description>Dynamic mappingがあるので、自分で設定しなくてもデータは入るけど、 自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。 バージョンは5.2。
$ curl -XPOST &amp;#39;localhost:9200/test_hoge/fuga?pretty&amp;#39; -d&amp;#39; { &amp;#34;name&amp;#34;: 0 } &amp;#39; $ curl -XPOST &amp;#39;localhost:9200/test_hoge/fuga?pretty&amp;#39; -d&amp;#39; { &amp;#34;name&amp;#34;: &amp;#34;sambaiz&amp;#34; } &amp;#39; { &amp;#34;error&amp;#34; : { &amp;#34;root_cause&amp;#34; : [ { &amp;#34;type&amp;#34; : &amp;#34;mapper_parsing_exception&amp;#34;, &amp;#34;reason&amp;#34; : &amp;#34;failed to parse [name]&amp;#34; } ], &amp;#34;type&amp;#34; : &amp;#34;mapper_parsing_exception&amp;#34;, &amp;#34;reason&amp;#34; : &amp;#34;failed to parse [name]&amp;#34;, &amp;#34;caused_by&amp;#34; : { &amp;#34;type&amp;#34; : &amp;#34;number_format_exception&amp;#34;, &amp;#34;reason&amp;#34; : &amp;#34;For input string: \&amp;#34;sambaiz\&amp;#34;&amp;#34; } }, &amp;#34;status&amp;#34; : 400 } Mapping parameters index falseにするとindexしない。クエリで必要ないものはfalseにする。</description>
    </item>
    
    <item>
      <title>fluentdのrecord_transformerでログを加工する</title>
      <link>https://www.sambaiz.net/article/55/</link>
      <pubDate>Fri, 03 Feb 2017 21:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/55/</guid>
      <description>http://docs.fluentd.org/v0.12/articles/filter_record_transformer
追加したり、編集したり、削除したりできるフィルタ。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;filter hoge.log&amp;gt; @type record_transformer enable_ruby auto_typecast true remove_keys b,d &amp;lt;record&amp;gt; what_is_tag ${tag} what_is_a ${record[&amp;#34;a&amp;#34;]} what_is_c_of_b_add_1 ${record[&amp;#34;b&amp;#34;][&amp;#34;c&amp;#34;] + 1} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; &amp;lt;match hoge.log&amp;gt; @type stdout &amp;lt;/match&amp;gt; この例だとタグを値に持つ&amp;quot;what_is_tag&amp;quot;、aを値に持つ&amp;quot;what_is_a&amp;quot;、b.cの値に1を足す&amp;quot;what_is_c_of_b_add_1&amp;quot;が追加され、 bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。
auto_typecastをtrueにしないと&amp;quot;what_is_c_of_b_add_1&amp;quot;の値がstringになる。
$ echo &amp;#39;{&amp;#34;a&amp;#34;: &amp;#34;hoge&amp;#34;, &amp;#34;b&amp;#34;: {&amp;#34;c&amp;#34;: 1}, &amp;#34;d&amp;#34;: &amp;#34;fuga&amp;#34;}&amp;#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.log hoge.log: {&amp;#34;a&amp;#34;:&amp;#34;hoge&amp;#34;,&amp;#34;what_is_tag&amp;#34;:&amp;#34;hoge.log&amp;#34;,&amp;#34;what_is_a&amp;#34;:&amp;#34;hoge&amp;#34;,&amp;#34;what_is_c_of_b_add_1&amp;#34;:2} エラーが起きるとnullになるが、それ以外の処理はされる。
$ echo &amp;#39;{&amp;#34;a&amp;#34;: &amp;#34;hoge&amp;#34;, &amp;#34;b&amp;#34;: {&amp;#34;c&amp;#34;: &amp;#34;error!&amp;#34;}, &amp;#34;d&amp;#34;: &amp;#34;fuga&amp;#34;}&amp;#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.</description>
    </item>
    
    <item>
      <title>fluentdでElasticsearchに送る</title>
      <link>https://www.sambaiz.net/article/54/</link>
      <pubDate>Wed, 01 Feb 2017 21:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/54/</guid>
      <description>uken/fluent-plugin-elasticsearch
必要なものをいれていく。Amazon LinuxのAMIから。
 Failed to build gem native extension.  $ yum install -y ruby-devel  serverengine requires Ruby version &amp;gt;= 2.1.0.  rbenvでバージョンを上げる。
$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv $ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src $ echo &amp;#39;export PATH=&amp;#34;$HOME/.rbenv/bin:$PATH&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile $ ~/.rbenv/bin/rbenv init $ echo &amp;#39;eval &amp;#34;$(rbenv init -)&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile $ source ~/.bash_profile $ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build $ rbenv -v rbenv 1.1.0-2-g4f8925a  Ruby install aborted due to missing extensions  $ yum install -y openssl-devel readline-devel zlib-devel $ rbenv install -l 1.</description>
    </item>
    
    <item>
      <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
      <link>https://www.sambaiz.net/article/52/</link>
      <pubDate>Sun, 29 Jan 2017 17:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/52/</guid>
      <description>https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
vm.max_map_count (バーチャルメモリにマッピングできる最大ページ数) を262144以上にする。
$ sysctl vm.max_map_count $ grep vm.max_map_count /etc/sysctl.conf vm.max_map_count=262144 # sysctl -w vm.max_map_count=262144 30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。
-cap-add=IPC_LOCKでLock memory(スワップアウトしないようにする)を 許可する。
https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html
ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。 ただし、物理RAMの50%以下で、32GB近辺の境界を超えないようにする。
$ mkdir -p ~/do/elasticsearch/data $ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \ --name elasticsearch \ -p 9200:9200 \ -e xpack.security.enabled=false \ -e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;#34;-Xms28g -Xmx28g&amp;#34; \ --cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \ --restart=always \ docker.elastic.co/elasticsearch/elasticsearch:5.1.2 $ docker volume ls local elasticsearch 問題なく起動しているか確認する。
$ curl localhost:9200 | jq { &amp;#34;name&amp;#34;: &amp;#34;eqIkJ48&amp;#34;, &amp;#34;cluster_name&amp;#34;: &amp;#34;docker-cluster&amp;#34;, &amp;#34;cluster_uuid&amp;#34;: &amp;#34;Lsu_C7wORS6G-0m9PJ9sFQ&amp;#34;, &amp;#34;version&amp;#34;: { &amp;#34;number&amp;#34;: &amp;#34;5.</description>
    </item>
    
  </channel>
</rss>
