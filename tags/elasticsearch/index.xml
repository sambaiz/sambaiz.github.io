<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>elasticsearch on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/elasticsearch/</link>
    <description>Recent content in elasticsearch on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Tue, 01 Oct 2019 23:25:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/tags/elasticsearch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする</title>
      <link>https://www.sambaiz.net/article/241/</link>
      <pubDate>Tue, 01 Oct 2019 23:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/241/</guid>
      <description>Elastic Cloud on Kubernetes (ECK)で Kubernetesクラスタ上にElasticsearch, KibanaとAPM Serverを立ち上げ、外部のGo製APIサーバーのリクエストをトレースする。 クラスタはGKEで作成し、ノードプールはn2-highmem-4(2vCPU, 13GB)の3台にした。
インストール ElasticSearchやKibana, APM ServerのCRDやelastic-operatorなどをインストールする。
KubernetesのCustom Resource Definition(CRD)とCustom Controller - sambaiz-net
$ kubectl apply -f https://download.elastic.co/downloads/eck/0.9.0/all-in-one.yaml customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/trustrelationships.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created clusterrole.rbac.authorization.k8s.io/elastic-operator created clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created namespace/elastic-system created statefulset.apps/elastic-operator created secret/webhook-server-secret created serviceaccount/elastic-operator created $ kubectl get pod -n elastic-system NAME READY STATUS RESTARTS AGE elastic-operator-0 1/1 Running 1 91s $ kubectl -n elastic-system logs -f statefulset.apps/elastic-operator ... {&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1569230702.0881083,&amp;quot;logger&amp;quot;:&amp;quot;kubebuilder.controller&amp;quot;,&amp;quot;msg&amp;quot;:&amp;quot;Starting workers&amp;quot;,&amp;quot;controller&amp;quot;:&amp;quot;elasticsearch-controller&amp;quot;,&amp;quot;worker count&amp;quot;:1} {&amp;quot;level&amp;quot;:&amp;quot;info&amp;quot;,&amp;quot;ts&amp;quot;:1569230702.</description>
    </item>
    
    <item>
      <title>CuratorでElasticsearchの古いindexを削除する</title>
      <link>https://www.sambaiz.net/article/86/</link>
      <pubDate>Wed, 22 Mar 2017 00:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/86/</guid>
      <description>Curatorとは indexやsnapshotを管理するのに使えるツール。
インストール インストールする。
$ cat /etc/yum.repos.d/curator.repo [curator-4] name=CentOS/RHEL 7 repository for Elasticsearch Curator 4.x packages baseurl=http://packages.elastic.co/curator/4/centos/7 gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 $ yum install -y elasticsearch-curator $ curator --version curator, version 4.2.6 config configファイルを書く。
client: hosts: - 127.0.0.1 port: 9200 logging: loglevel: INFO logfile: logformat: default blacklist: [&#39;elasticsearch&#39;, &#39;urllib3&#39;] action 今回はindexを削除するのでdelete_indices。 対象はfilterで指定する。 logstash formatだとhogehoge-2017.01.01のようなindex名になるので%Y.%m.%d。okder than 3 daysのものを削除する。
actions: 1: action: delete_indices description: &amp;gt;- 3日前より古いhogehoge-* indexを消す filters: - filtertype: pattern kind: prefix value: hogehoge- - filtertype: age source: name direction: older timestring: &#39;%Y.</description>
    </item>
    
    <item>
      <title>Elasticsearchで期間ごとの集計値を出す</title>
      <link>https://www.sambaiz.net/article/77/</link>
      <pubDate>Sun, 05 Mar 2017 01:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/77/</guid>
      <description>Bucket(SQLでいうGROUP BY)にまとめて(Bucket Aggreagtion)、集計(Metric Aggregation)する。
使うデータは作ったツールで生成したこんなの。
{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82} Bucket Aggregations Date Range Aggregation date_rangeで期間のBucketを作る。この例だと今から10分前の00秒~今の分の00秒まで。
$ curl localhost:9200/hoge/_search -d&#39; { &amp;quot;aggs&amp;quot;: { &amp;quot;range_10minutes&amp;quot;: { &amp;quot;date_range&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;HH-mm-ssZ&amp;quot;, &amp;quot;ranges&amp;quot;: [ { &amp;quot;to&amp;quot;: &amp;quot;now/m&amp;quot;, &amp;quot;from&amp;quot;: &amp;quot;now-10m/m&amp;quot; } ] } } } }&#39; | jq .aggregations { &amp;quot;range_10minutes&amp;quot;: { &amp;quot;buckets&amp;quot;: [ { &amp;quot;key&amp;quot;: &amp;quot;15-17+0000-15-27+0000&amp;quot;, &amp;quot;from&amp;quot;: 1488640620000, &amp;quot;from_as_string&amp;quot;: &amp;quot;15-17+0000&amp;quot;, &amp;quot;to&amp;quot;: 1488641220000, &amp;quot;to_as_string&amp;quot;: &amp;quot;15-27+0000&amp;quot;, &amp;quot;doc_count&amp;quot;: 600 } ] } } Date Histogram Aggregation date_histogramで日付の間隔でBucketを作る。この例だと1分ごとにBucketが作られる。
$ curl localhost:9200/hoge/_search -d&#39; { &amp;quot;aggs&amp;quot;: { &amp;quot;histogram_1minute&amp;quot;: { &amp;quot;date_histogram&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;, &amp;quot;interval&amp;quot;: &amp;quot;1m&amp;quot; } } } }&#39; | jq .</description>
    </item>
    
    <item>
      <title>ElasticsearchのCircuit Breaker</title>
      <link>https://www.sambaiz.net/article/71/</link>
      <pubDate>Fri, 24 Feb 2017 21:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/71/</guid>
      <description>ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net
ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。 表示されたエラーはこういうの。
&amp;quot;root_cause&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;circuit_breaking_exception&amp;quot;, &amp;quot;reason&amp;quot;: &amp;quot;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;quot;, &amp;quot;bytes_wanted&amp;quot;: 10464007168, &amp;quot;bytes_limit&amp;quot;: 8998512230 } ], これは1リクエストの集計などで使うメモリ量がしきい値をこえて Circuit Breakerが発動したということ。 メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。
情報はstatsのapiでも取得できる。
$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request { &amp;quot;limit_size_in_bytes&amp;quot;: 8998512230, &amp;quot;limit_size&amp;quot;: &amp;quot;8.3gb&amp;quot;, &amp;quot;estimated_size_in_bytes&amp;quot;: 10348347504, &amp;quot;estimated_size&amp;quot;: &amp;quot;9.6gb&amp;quot;, &amp;quot;overhead&amp;quot;: 1, &amp;quot;tripped&amp;quot;: 470 } 今回ひっかかったのはindices.breaker.request.limit。デフォルトではJVMのヒープメモリの60%になっているが、 これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。
$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{ &amp;quot;persistent&amp;quot; : { &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;, &amp;quot;indices.breaker.total.limit&amp;quot;: &amp;quot;80%&amp;quot; } }&#39; $ curl -XPUT localhost:9200/_cluster/settings -d &#39;{ &amp;quot;persistent&amp;quot; : { &amp;quot;indices.</description>
    </item>
    
    <item>
      <title>Elasticsearchのmapping</title>
      <link>https://www.sambaiz.net/article/62/</link>
      <pubDate>Thu, 09 Feb 2017 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/62/</guid>
      <description>Dynamic mappingがあるので、自分で設定しなくてもデータは入るけど、 自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。 バージョンは5.2。
$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39; { &amp;quot;name&amp;quot;: 0 } &#39; $ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39; { &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot; } &#39; { &amp;quot;error&amp;quot; : { &amp;quot;root_cause&amp;quot; : [ { &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot; } ], &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;, &amp;quot;caused_by&amp;quot; : { &amp;quot;type&amp;quot; : &amp;quot;number_format_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;For input string: \&amp;quot;sambaiz\&amp;quot;&amp;quot; } }, &amp;quot;status&amp;quot; : 400 } Mapping parameters index falseにするとindexしない。クエリで必要ないものはfalseにする。</description>
    </item>
    
    <item>
      <title>fluentdのrecord_transformerでログを加工する</title>
      <link>https://www.sambaiz.net/article/55/</link>
      <pubDate>Fri, 03 Feb 2017 21:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/55/</guid>
      <description>http://docs.fluentd.org/v0.12/articles/filter_record_transformer
追加したり、編集したり、削除したりできるフィルタ。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;filter hoge.log&amp;gt; @type record_transformer enable_ruby auto_typecast true remove_keys b,d &amp;lt;record&amp;gt; what_is_tag ${tag} what_is_a ${record[&amp;quot;a&amp;quot;]} what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; &amp;lt;match hoge.log&amp;gt; @type stdout &amp;lt;/match&amp;gt; この例だとタグを値に持つ&amp;quot;what_is_tag&amp;quot;、aを値に持つ&amp;quot;what_is_a&amp;quot;、b.cの値に1を足す&amp;quot;what_is_c_of_b_add_1&amp;quot;が追加され、 bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。
auto_typecastをtrueにしないと&amp;quot;what_is_c_of_b_add_1&amp;quot;の値がstringになる。
$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: 1}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.log hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2} エラーが起きるとnullになるが、それ以外の処理はされる。
$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: &amp;quot;error!&amp;quot;}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.</description>
    </item>
    
    <item>
      <title>fluentdでElasticsearchに送る</title>
      <link>https://www.sambaiz.net/article/54/</link>
      <pubDate>Wed, 01 Feb 2017 21:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/54/</guid>
      <description>uken/fluent-plugin-elasticsearch
必要なものをいれていく。Amazon LinuxのAMIから。
 Failed to build gem native extension.  $ yum install -y ruby-devel  serverengine requires Ruby version &amp;gt;= 2.1.0.  rbenvでバージョンを上げる。
$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv $ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src $ echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile $ ~/.rbenv/bin/rbenv init $ echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile $ source ~/.bash_profile $ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build $ rbenv -v rbenv 1.1.0-2-g4f8925a  Ruby install aborted due to missing extensions  $ yum install -y openssl-devel readline-devel zlib-devel $ rbenv install -l 1.</description>
    </item>
    
    <item>
      <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
      <link>https://www.sambaiz.net/article/52/</link>
      <pubDate>Sun, 29 Jan 2017 17:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/52/</guid>
      <description>https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
vm.max_map_count (バーチャルメモリにマッピングできる最大ページ数) を262144以上にする。
$ sysctl vm.max_map_count $ grep vm.max_map_count /etc/sysctl.conf vm.max_map_count=262144 # sysctl -w vm.max_map_count=262144 30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。
-cap-add=IPC_LOCKでLock memory(スワップアウトしないようにする)を 許可する。
https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html
ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。 ただし、物理RAMの50%以下で、32GB近辺の境界を超えないようにする。
$ mkdir -p ~/do/elasticsearch/data $ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \ --name elasticsearch \ -p 9200:9200 \ -e xpack.security.enabled=false \ -e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;quot;-Xms28g -Xmx28g&amp;quot; \ --cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \ --restart=always \ docker.elastic.co/elasticsearch/elasticsearch:5.1.2 $ docker volume ls local elasticsearch 問題なく起動しているか確認する。
$ curl localhost:9200 | jq { &amp;quot;name&amp;quot;: &amp;quot;eqIkJ48&amp;quot;, &amp;quot;cluster_name&amp;quot;: &amp;quot;docker-cluster&amp;quot;, &amp;quot;cluster_uuid&amp;quot;: &amp;quot;Lsu_C7wORS6G-0m9PJ9sFQ&amp;quot;, &amp;quot;version&amp;quot;: { &amp;quot;number&amp;quot;: &amp;quot;5.</description>
    </item>
    
  </channel>
</rss>
