<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Elasticsearch on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/elasticsearch/</link>
    <description>Recent content in Elasticsearch on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Wed, 22 Mar 2017 00:10:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/elasticsearch/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>CuratorでElasticsearchの古いindexを削除する</title>
      <link>https://www.sambaiz.net/article/86/</link>
      <pubDate>Wed, 22 Mar 2017 00:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/86/</guid>
      <description>Curatorとは indexやsnapshotを管理するのに使えるツール。
インストール インストールする。
$ cat /etc/yum.repos.d/curator.repo [curator-4] name=CentOS/RHEL 7 repository for Elasticsearch Curator 4.x packages baseurl=http://packages.elastic.co/curator/4/centos/7 gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 $ yum install -y elasticsearch-curator $ curator --version curator, version 4.2.6  config configファイルを書く。
client: hosts: - 127.0.0.1 port: 9200 logging: loglevel: INFO logfile: logformat: default blacklist: [&#39;elasticsearch&#39;, &#39;urllib3&#39;]  action 今回はindexを削除するのでdelete_indices。 対象はfilterで指定する。 logstash formatだとhogehoge-2017.01.01のようなindex名になるので%Y.%m.%d。okder than 3 daysのものを削除する。
actions: 1: action: delete_indices description: &amp;gt;- 3日前より古いhogehoge-* indexを消す filters: - filtertype: pattern kind: prefix value: hogehoge- - filtertype: age source: name direction: older timestring: &#39;%Y.</description>
    </item>
    
    <item>
      <title>Elasticsearchで期間ごとの集計値を出す</title>
      <link>https://www.sambaiz.net/article/77/</link>
      <pubDate>Sun, 05 Mar 2017 01:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/77/</guid>
      <description>Bucket(SQLでいうGROUP BY)にまとめて(Bucket Aggreagtion)、集計(Metric Aggregation)する。
使うデータは作ったツールで生成したこんなの。
{&amp;quot;@timestamp&amp;quot;:1488635130,&amp;quot;os_name&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;score&amp;quot;:82}  Bucket Aggregations Date Range Aggregation date_rangeで期間のBucketを作る。この例だと今から10分前の00秒~今の分の00秒まで。
$ curl localhost:9200/hoge/_search -d&#39; { &amp;quot;aggs&amp;quot;: { &amp;quot;range_10minutes&amp;quot;: { &amp;quot;date_range&amp;quot;: { &amp;quot;field&amp;quot;: &amp;quot;@timestamp&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;HH-mm-ssZ&amp;quot;, &amp;quot;ranges&amp;quot;: [ { &amp;quot;to&amp;quot;: &amp;quot;now/m&amp;quot;, &amp;quot;from&amp;quot;: &amp;quot;now-10m/m&amp;quot; } ] } } } }&#39; | jq .aggregations  { &amp;quot;range_10minutes&amp;quot;: { &amp;quot;buckets&amp;quot;: [ { &amp;quot;key&amp;quot;: &amp;quot;15-17+0000-15-27+0000&amp;quot;, &amp;quot;from&amp;quot;: 1488640620000, &amp;quot;from_as_string&amp;quot;: &amp;quot;15-17+0000&amp;quot;, &amp;quot;to&amp;quot;: 1488641220000, &amp;quot;to_as_string&amp;quot;: &amp;quot;15-27+0000&amp;quot;, &amp;quot;doc_count&amp;quot;: 600 } ] } }  Date Histogram Aggregation date_histogramで日付の間隔でBucketを作る。この例だと1分ごとにBucketが作られる。</description>
    </item>
    
    <item>
      <title>ElasticsearchのCircuit Breaker</title>
      <link>https://www.sambaiz.net/article/71/</link>
      <pubDate>Fri, 24 Feb 2017 21:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/71/</guid>
      <description>ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net
ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。 表示されたエラーはこういうの。
&amp;quot;root_cause&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;circuit_breaking_exception&amp;quot;, &amp;quot;reason&amp;quot;: &amp;quot;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;quot;, &amp;quot;bytes_wanted&amp;quot;: 10464007168, &amp;quot;bytes_limit&amp;quot;: 8998512230 } ],  これは1リクエストの集計などで使うメモリ量がしきい値をこえて Circuit Breakerが発動したということ。 メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。
情報はstatsのapiでも取得できる。
$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request { &amp;quot;limit_size_in_bytes&amp;quot;: 8998512230, &amp;quot;limit_size&amp;quot;: &amp;quot;8.3gb&amp;quot;, &amp;quot;estimated_size_in_bytes&amp;quot;: 10348347504, &amp;quot;estimated_size&amp;quot;: &amp;quot;9.6gb&amp;quot;, &amp;quot;overhead&amp;quot;: 1, &amp;quot;tripped&amp;quot;: 470 }  今回ひっかかったのはindices.breaker.request.limit。デフォルトではJVMのヒープメモリの60%になっているが、 これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。
$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{ &amp;quot;persistent&amp;quot; : { &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;, &amp;quot;indices.</description>
    </item>
    
    <item>
      <title>Elasticsearchのmapping</title>
      <link>https://www.sambaiz.net/article/62/</link>
      <pubDate>Thu, 09 Feb 2017 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/62/</guid>
      <description>Dynamic mappingがあるので、自分で設定しなくてもデータは入るけど、 自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。 バージョンは5.2。
$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39; { &amp;quot;name&amp;quot;: 0 } &#39; $ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39; { &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot; } &#39; { &amp;quot;error&amp;quot; : { &amp;quot;root_cause&amp;quot; : [ { &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot; } ], &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;, &amp;quot;caused_by&amp;quot; : { &amp;quot;type&amp;quot; : &amp;quot;number_format_exception&amp;quot;, &amp;quot;reason&amp;quot; : &amp;quot;For input string: \&amp;quot;sambaiz\&amp;quot;&amp;quot; } }, &amp;quot;status&amp;quot; : 400 }  Mapping parameters index falseにするとindexしない。クエリで必要ないものはfalseにする。</description>
    </item>
    
    <item>
      <title>fluentdのrecord_transformerでログを加工する</title>
      <link>https://www.sambaiz.net/article/55/</link>
      <pubDate>Fri, 03 Feb 2017 21:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/55/</guid>
      <description>http://docs.fluentd.org/v0.12/articles/filter_record_transformer
追加したり、編集したり、削除したりできるフィルタ。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;filter hoge.log&amp;gt; @type record_transformer enable_ruby auto_typecast true remove_keys b,d &amp;lt;record&amp;gt; what_is_tag ${tag} what_is_a ${record[&amp;quot;a&amp;quot;]} what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; &amp;lt;match hoge.log&amp;gt; @type stdout &amp;lt;/match&amp;gt;  この例だとタグを値に持つ&amp;rdquo;what_is_tag&amp;rdquo;、aを値に持つ&amp;rdquo;what_is_a&amp;rdquo;、b.cの値に1を足す&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;が追加され、 bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。
auto_typecastをtrueにしないと&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;の値がstringになる。
$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: 1}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.log hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2}  エラーが起きるとnullになるが、それ以外の処理はされる。
$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: &amp;quot;error!&amp;quot;}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.</description>
    </item>
    
    <item>
      <title>fluentdでElasticsearchに送る</title>
      <link>https://www.sambaiz.net/article/54/</link>
      <pubDate>Wed, 01 Feb 2017 21:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/54/</guid>
      <description>uken/fluent-plugin-elasticsearch
必要なものをいれていく。Amazon LinuxのAMIから。
 Failed to build gem native extension.  $ yum install -y ruby-devel   serverengine requires Ruby version &amp;gt;= 2.1.0.  rbenvでバージョンを上げる。
$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv $ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src $ echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile $ ~/.rbenv/bin/rbenv init $ echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile $ source ~/.bash_profile $ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build  $ rbenv -v rbenv 1.</description>
    </item>
    
    <item>
      <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
      <link>https://www.sambaiz.net/article/52/</link>
      <pubDate>Sun, 29 Jan 2017 17:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/52/</guid>
      <description>https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
vm.max_map_count (バーチャルメモリにマッピングできる最大ページ数) を262144以上にする。
$ sysctl vm.max_map_count $ grep vm.max_map_count /etc/sysctl.conf vm.max_map_count=262144 # sysctl -w vm.max_map_count=262144  30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。
-cap-add=IPC_LOCKでLock memory(スワップアウトしないようにする)を 許可する。
https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html
ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。 ただし、物理RAMの50%以下で、32GB近辺の境界を超えないようにする。
$ mkdir -p ~/do/elasticsearch/data $ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \ --name elasticsearch \ -p 9200:9200 \ -e xpack.security.enabled=false \ -e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;quot;-Xms28g -Xmx28g&amp;quot; \ --cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \ --restart=always \ docker.elastic.co/elasticsearch/elasticsearch:5.1.2 $ docker volume ls local elasticsearch  問題なく起動しているか確認する。</description>
    </item>
    
  </channel>
</rss>