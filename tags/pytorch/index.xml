<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pytorch on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/pytorch/</link>
    <description>Recent content in pytorch on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 26 Jul 2020 02:43:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/pytorch/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてホスティングする</title>
      <link>https://www.sambaiz.net/article/290/</link>
      <pubDate>Sun, 26 Jul 2020 02:43:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/290/</guid>
      <description>学習させたモデルをSageMakerでホスティングする。
SageMakerでPyTorchのモデルを学習させる - sambaiz-net
推論時に呼ばれる関数 推論時には次の関数が呼ばれる。
 model_fn(model_dir): モデルをロードする input_fn(request_body, request_content_type): リクエストボディのデシリアライズ predict_fn(input_data, model): モデルで推論する output_fn(prediction, content_type): Content-Typeに応じたシリアライズ  input_fn() と output_fn() はJSON, CSV, NPYに対応した実装が、predict_fn() はモデルを呼び出す実装がデフォルトとして用意されていて、 model_fn() も後述するElastic Inferenceを使う場合model.ptというファイルをロードするデフォルト実装が使われる。 ただしその場合torch.jit.save()でTorchScriptとして保存してある必要がある。
今回は predict_fn() のみ実装した。
$ cat inference.py import torch def predict_fn(input_data, model): device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) model = model.to(device) input_data = input_data.to(device) model.eval() with torch.jit.optimized_execution(True, {&amp;quot;target_device&amp;quot;: &amp;quot;eia:0&amp;quot;}): output = model(input_data) return output.max(1, keepdim=True)[1] デプロイ Training jobによってモデルが保存されたS3のパスを取ってきてPyTorchModelを作る。
from sagemaker.pytorch.model import PyTorchModel training_job_name = &#39;pytorch-training-2020-07-25-08-41-45-674&#39; training_job = sess.</description>
    </item>
    
    <item>
      <title>SageMakerでPyTorchのモデルを学習させる</title>
      <link>https://www.sambaiz.net/article/287/</link>
      <pubDate>Fri, 24 Jul 2020 22:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/287/</guid>
      <description>AWSの機械学習サービスSageMakerでPyTorchのモデルを学習させる。
コード まず学習させるモデルとそれを呼び出すエントリーポイントになるコードを書く。全体のコードはGitHubにある。 実際の環境と同じSageMakerのコンテナをローカルで動かしてVSCodeのRemote Deploymentで接続して開発するとその場でデバッグできるし、いざ実行時に依存パッケージがないといったエラーを回避できて良い。
VSCodeのRemote DeploymentでSageMakerのコンテナ環境でモデルを開発する - sambaiz-net
モデル 以前作ったMNISTのモデルを使う。
PyTorchでMNISTする - sambaiz-net
$ cat model.py import torch from torch import nn, cuda import torch.nn.functional as F import torch.distributed as dist import torch.optim as optim class Model(nn.Module): def __init__(self, dropout): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 64, 5) # -&amp;gt; 24x24 self.pool1 = nn.MaxPool2d(2) # -&amp;gt; 12x12 self.conv2 = nn.Conv2d(64, 128, 5) # -&amp;gt; 8x8 self.dropout = nn.Dropout(p=dropout) self.dense = nn.</description>
    </item>
    
    <item>
      <title>PyTorchでVAEのモデルを実装してMNISTの画像を生成する</title>
      <link>https://www.sambaiz.net/article/212/</link>
      <pubDate>Thu, 07 Mar 2019 19:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/212/</guid>
      <description>PyTorchでVAEを実装しMNISTの画像を生成する。
生成モデルVAE(Variational Autoencoder) - sambaiz-net
学習データ datasetsのMNIST画像を使う。
from torchvision import datasets, transforms transform = transforms.Compose([ transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))]) dataset_train = datasets.MNIST( &#39;~/mnist&#39;, train=True, download=True, transform=transform) dataset_valid = datasets.MNIST( &#39;~/mnist&#39;, train=False, download=True, transform=transform) dataloader_train = utils.data.DataLoader(dataset_train, batch_size=1000, shuffle=True, num_workers=4) dataloader_valid = utils.data.DataLoader(dataset_valid, batch_size=1000, shuffle=True, num_workers=4) VAE それぞれ3層のEncoderとDecoder。
import torch import torch.nn as nn import torch.nn.functional as F device = &#39;cuda&#39; class VAE(nn.Module): def __init__(self, z_dim): super(VAE, self).__init__() self.dense_enc1 = nn.Linear(28*28, 200) self.</description>
    </item>
    
    <item>
      <title>PyTorchでMNISTする</title>
      <link>https://www.sambaiz.net/article/205/</link>
      <pubDate>Sat, 19 Jan 2019 23:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/205/</guid>
      <description>PyTorchはFacebookによるOSSの機械学習フレームワーク。 TensorFlow(v1)よりも簡単に使うことができる。 TensorFlow 2.0ではPyTorchのようにDefine-by-runなeager executionがデフォルトになるのに加え、パッケージも整理されるようなのでいくらか近くなると思われる。
使い方 インストール Colabで動かす。まずpipでインストール。
!pip install torch torchvision autograd(自動微分) Tensorは自身が作成された関数の参照.grad_fnを持ち、backward()が呼ばれるとbackpropしてrequires_grad=TrueなTensorの勾配を自動で計算し.gradに入れてくれる。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
import torch x = torch.randn(4, 4) y = torch.randn(4, 1) w = torch.randn(4, 1, requires_grad=True) b = torch.randn(1, requires_grad=True) y_pred = torch.matmul(x, w) + b loss = (y_pred - y).pow(2).sum() print(x.grad, w.grad) # None None loss.backward() print(x.grad, w.grad) # None tensor([...]) with torch.no_grad(): y_eval = torch.matmul(x, w) + b print(y_eval.requires_grad) # False Module nnパッケージにLinearやConv2dといったModuleが実装されていて、次のように呼び出すとforward()が 呼ばれ順伝播する。</description>
    </item>
    
  </channel>
</rss>