<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pytorch on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/pytorch/</link>
    <description>Recent content in Pytorch on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 26 Jul 2020 02:43:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/tags/pytorch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SageMakerで学習したPyTorchのモデルをElastic Inferenceを有効にしてデプロイする</title>
      <link>https://www.sambaiz.net/article/290/</link>
      <pubDate>Sun, 26 Jul 2020 02:43:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/290/</guid>
      <description>&lt;p&gt;学習させたモデルをSageMakerのホスティングサービスにデプロイする。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/287/&#34;&gt;SageMakerでPyTorchのモデルを学習させる - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;推論時に呼ばれる関数&#34;&gt;推論時に呼ばれる関数&lt;/h2&gt;&#xA;&lt;p&gt;推論時には次の関数が&lt;a href=&#34;https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#serve-a-pytorch-model&#34;&gt;呼ばれる&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;model_fn(model_dir): モデルをロードする&lt;/li&gt;&#xA;&lt;li&gt;input_fn(request_body, request_content_type): リクエストボディのデシリアライズ&lt;/li&gt;&#xA;&lt;li&gt;predict_fn(input_data, model): モデルで推論する&lt;/li&gt;&#xA;&lt;li&gt;output_fn(prediction, content_type): Content-Typeに応じたシリアライズ&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;input_fn()&lt;/code&gt; と &lt;code&gt;output_fn()&lt;/code&gt; はJSON, CSV, NPYに対応した実装が、&lt;code&gt;predict_fn()&lt;/code&gt; はモデルを呼び出す実装が&lt;a href=&#34;https://github.com/aws/sagemaker-pytorch-inference-toolkit/blob/4894d509f60ecd43d34356c9c571b9fb9e8b97ad/src/sagemaker_pytorch_serving_container/default_pytorch_inference_handler.py&#34;&gt;デフォルト&lt;/a&gt;として用意されていて、&#xA;&lt;code&gt;model_fn()&lt;/code&gt; も後述するElastic Inferenceを使う場合&lt;code&gt;model.pt&lt;/code&gt;というファイルをロードするデフォルト実装が使われる。&#xA;ただしその場合モデルが&lt;code&gt;torch.jit.save()&lt;/code&gt;で&lt;a href=&#34;https://pytorch.org/docs/stable/jit.html&#34;&gt;TorchScript&lt;/a&gt;として保存してある&lt;a href=&#34;https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#save-the-model&#34;&gt;必要がある&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SageMakerでPyTorchのモデルを学習させる</title>
      <link>https://www.sambaiz.net/article/287/</link>
      <pubDate>Fri, 24 Jul 2020 22:59:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/287/</guid>
      <description>&lt;p&gt;AWSの機械学習サービス&lt;a href=&#34;https://aws.amazon.com/jp/sagemaker/&#34;&gt;SageMaker&lt;/a&gt;でPyTorchのモデルを学習させる。&lt;/p&gt;&#xA;&lt;h2 id=&#34;コード&#34;&gt;コード&lt;/h2&gt;&#xA;&lt;p&gt;まず学習させるモデルとそれを呼び出すエントリーポイントになるコードを書く。全体のコードは&lt;a href=&#34;https://github.com/sambaiz/sagemaker-pytorch-mnist&#34;&gt;GitHub&lt;/a&gt;にある。&#xA;実際の環境と同じSageMakerのコンテナをローカルで動かしてVSCodeのRemote Developmentで接続して開発すると入っていないパッケージは警告が出たりして良い。&lt;/p&gt;</description>
    </item>
    <item>
      <title>PyTorchでVAEのモデルを実装してMNISTの画像を生成する</title>
      <link>https://www.sambaiz.net/article/212/</link>
      <pubDate>Thu, 07 Mar 2019 19:35:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/212/</guid>
      <description>&lt;p&gt;PyTorchでVAEを実装しMNISTの画像を生成する。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/201/&#34;&gt;生成モデルVAE(Variational Autoencoder) - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;学習データ&#34;&gt;学習データ&lt;/h2&gt;&#xA;&lt;p&gt;datasetsのMNIST画像を使う。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;from&lt;/span&gt; torchvision &lt;span style=&#34;color:#ff79c6&#34;&gt;import&lt;/span&gt; datasets, transforms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;transform &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; transforms&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;Compose([&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transforms&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;ToTensor(), &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transforms&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;Lambda(&lt;span style=&#34;color:#ff79c6&#34;&gt;lambda&lt;/span&gt; x: x&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;1&lt;/span&gt;))])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset_train &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;MNIST(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;~/mnist&amp;#39;&lt;/span&gt;, &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;True&lt;/span&gt;, &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    download&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;True&lt;/span&gt;, &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transform&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;transform)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset_valid &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;MNIST(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#39;~/mnist&amp;#39;&lt;/span&gt;, &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;False&lt;/span&gt;, &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    download&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;True&lt;/span&gt;, &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transform&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;transform)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataloader_train &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; utils&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;DataLoader(dataset_train,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                          batch_size&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;1000&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                          shuffle&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                          num_workers&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;4&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataloader_valid &lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt; utils&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#ff79c6&#34;&gt;.&lt;/span&gt;DataLoader(dataset_valid,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                          batch_size&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;1000&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                          shuffle&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                          num_workers&lt;span style=&#34;color:#ff79c6&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;4&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;vae&#34;&gt;VAE&lt;/h2&gt;&#xA;&lt;p&gt;それぞれ3層のEncoderとDecoder。&lt;/p&gt;</description>
    </item>
    <item>
      <title>PyTorchでMNISTする</title>
      <link>https://www.sambaiz.net/article/205/</link>
      <pubDate>Sat, 19 Jan 2019 23:35:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/205/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;はFacebookによるOSSの機械学習フレームワーク。&#xA;TensorFlow(v1)よりも簡単に使うことができる。&#xA;TensorFlow 2.0ではPyTorchのようにDefine-by-runなeager executionがデフォルトになるのに加え、パッケージも整理されるようなのでいくらか近くなると思われる。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
