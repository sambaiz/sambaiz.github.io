<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tensorflow on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/tensorflow/</link>
    <description>Recent content in Tensorflow on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Fri, 22 Jun 2018 01:48:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TensorFlowのモデルをsave/loadする</title>
      <link>https://www.sambaiz.net/article/172/</link>
      <pubDate>Fri, 22 Jun 2018 01:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/172/</guid>
      <description>SavedModelBuilderで モデルを言語に依存しないSavedModelのprotobufにして保存できる。
SaverのcheckpointがVariableの値のみを持つのに対して、 こちらは単体で復元できる。
Tensorflowの学習データを使ったAPIを作る - sambaiz-net
import tensorflow as tf def build_signature(signature_inputs, signature_outputs): return tf.saved_model.signature_def_utils.build_signature_def( signature_inputs, signature_outputs, tf.saved_model.signature_constants.REGRESS_METHOD_NAME) def save(sess, export_dir, signature_def_map): builder = tf.saved_model.builder.SavedModelBuilder(export_dir) builder.add_meta_graph_and_variables( sess, [tf.saved_model.tag_constants.SERVING], signature_def_map=signature_def_map ) builder.save() import shutil import os.path export_dir = &amp;quot;./saved_model&amp;quot; if os.path.exists(export_dir): shutil.rmtree(export_dir) with tf.Graph().as_default(): a = tf.placeholder(tf.float32, name=&amp;quot;a&amp;quot;) b = tf.placeholder(tf.float32, name=&amp;quot;b&amp;quot;) c = tf.add(a, b, name=&amp;quot;c&amp;quot;) v = tf.placeholder(tf.float32, name=&amp;quot;v&amp;quot;) w = tf.Variable(0.0, name=&amp;quot;w&amp;quot;) x = w.assign(tf.add(v, w)) sv = tf.</description>
    </item>
    
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。 全体のコードはここ。
入力 以下の関数によって生成した1次元のデータ列。 これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。
def make_time_series_data(size): data = [] for i in range(size): data.append(sin(random.normalvariate(i,0.1)*0.1)) return np.reshape(np.array(data, dtype=np.float32), (size,1)) def make_batch(data, batch_size, num_steps, num_dimensions, name=None): epoch_size = data.size // (batch_size*num_steps*num_dimensions) data = np.lib.stride_tricks.as_strided( data, shape= (epoch_size, batch_size, num_steps+1, num_dimensions), strides=( 4*batch_size*num_steps*num_dimensions, 4*num_steps*num_dimensions, 4*num_dimensions, 4 # bytes ), writeable=False ) return data[:, :, :-1], data[:, :, 1:]  モデル input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。 lossはMSE(Mean squared error)。OptimizerはGradientDecentOptimizerを使っている。
チュートリアルでは自力で各time_stepの値を入れていたけど、 今回はdynamic_rnn()に任せている。</description>
    </item>
    
    <item>
      <title>TensorBoardでsummaryやグラフを見る</title>
      <link>https://www.sambaiz.net/article/147/</link>
      <pubDate>Sun, 07 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/147/</guid>
      <description>TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
で読んだコードをTensorboardでみてみる。
8888がJupyter、6006がTensorboard。
$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow  コードをuploadするかJupyterからterminalを開いてcloneしてくる。
# apt-get update # apt-get install -y git wget # git clone https://github.com/tensorflow/models.git # cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz  logdirを指定して実行し、Tensorboardを起動。
flags.DEFINE_string(&amp;quot;save_path&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;Model output directory.&amp;quot;) sv = tf.train.Supervisor(logdir=FLAGS.save_path)  # tensorboard --logdir=models/tutorials/rnn/ptb  tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)による値がリアルタイムに表示される。
グラフのつながりや、各Operationの入出力やそのshapeを確認できる。</description>
    </item>
    
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。
RNN/LSTMとは RNNは入力に対して出力のほかに情報を次のステップに渡すネットワーク。 展開すると同じネットワークに単語を一つずつ入れていくように表現できる。
TensorflowではいくつかRNNの実装が用意されていて、このコードではそのうちのCudnnLSTMやBasicLSTMCell、LSTMBlockCellを選べるようになっている。cuDNNというのはNVIDIAのCUDAのDNNライブラリのこと。LSTMBlockCellはBasicLSTMCellより速い。
LSTM(Long Short Term Memory networks)はRNNの一種で、Cellは出力となるh(hidden state)のほかにC(Cell state)を持つ。 Cは前回のCをどの値を更新するか決定するinput gateに通し、その後に入力とhを、どの値を忘れるかを決定するforget gateに通して加えたものになる。 hはこのCと前回のhを何を出力するか決定するoutput gateに通したものになる。 これらで値域(0,1)のシグモイド関数が掛けられ、0であれば情報は失われ、1であれば完全に残る。
動かしてみる $ git clone https://github.com/tensorflow/models.git $ cd models/tutorials/rnn/ptb/ $ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz $ tar xvf simple-examples.tgz $ python3 -m venv env $ . ./env/bin/activate $ pip install numpy tensorflow  $ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0 Epoch: 1 Learning rate: 1.000 0.004 perplexity: 5534.452 speed: 894 wps 0.104 perplexity: 845.383 speed: 1277 wps .</description>
    </item>
    
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>ニューラルネットワークの活性化関数は各層での重み掛けバイアス足しのあとに適用する非線形の関数。 というのも、線形な計算を繰り返したところで
f(x) = ax + b g(x) = f(f(x)) = (a^2)x + (ab + b)  のように単一の線形関数で表現できてしまい、多層にする意味がないため。 また、バックプロバゲーション(誤差逆伝播法)のために微分できる必要もある。
Tensorflowでも以下の活性化関数が用意されている。
sigmoid y = 1 / (1 + exp(-x))。値域は(0,1)でシグマの語末系ςに似たS字を描く。 xが大きいときに微分係数が小さくなるため、何層もこの関数を適用するとき、バックプロバゲーションで微分係数を掛けた結果、勾配が消滅(Gradient vanishing)する問題があり、あまり使われないようだ。値域が(-1,1)で似たグラフを描くtanh(Hyperbolic tangent)もある。
softsign x/(1 + abs(x))。tanhと比べて漸近線に近づく速度が遅くなっている。 それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。
softplus log(1 + exp(x))。ReLUに続く。
ReLU(Rectified Linear Unit) max(0, x)。単純だけど最有力。Gradient vanishingも起きない。 softplusと比べてexpやlogを含まない分高速に計算できるので、 膨大で複雑なデータセットに対して多くの層を用いることができる。
0以下は等しく0になるため、トレーニング中に落ちてしまうとニューロンが死んでしまうことがある。 そのような場合は0以下のときy = exp(x) - 1にするELU(Exponential Linear Unit) などを使う。
参考 Activation functions and it’s types-Which is better?
最適化から見たディープラーニングの考え方
Understanding the difficulty of training deep feedforward neural networks</description>
    </item>
    
    <item>
      <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
      <link>https://www.sambaiz.net/article/124/</link>
      <pubDate>Sun, 06 Aug 2017 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/124/</guid>
      <description>AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリSonnetを使う。 当初はPython2しか対応していないようだったけど、今は3にも対応している。
準備 TensorFlowを使うライブラリはほかにもいくつかあるのだけど、 Kerasと比較してみると、 KerasがTensorFlowの部分を完全にラップしているのに対して、 Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。
SonnetとTensorFlowとPython3入りイメージをDockerHubに上げた。 Dockerfileはここ。
内容は基本的にREADME通りだけど、 configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。 あとは、TensorFlowのビルドに使われているGCCのバージョンが古いようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;を付けている。
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_  起動。
$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet $ docker logs sonnet ... Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=*****  Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。
import sonnet as snt import tensorflow as tf snt.resampler(tf.constant([0.]), tf.constant([0.])) # =&amp;gt; &amp;lt;tf.</description>
    </item>
    
    <item>
      <title>DeepDreaming with TensorFlowをやる(2)</title>
      <link>https://www.sambaiz.net/article/21/</link>
      <pubDate>Sat, 10 Sep 2016 14:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/21/</guid>
      <description>前回の続き。
Multiscale image generation 様々なスケールで勾配上昇させる。小さなスケールで上昇させたものをより大きなスケールでさらに上昇させていく。 ただ、壁紙のようなサイズを生成するような場合にそれを行うと、GPUのメモリを食いつぶしてしまう。 これを避けるために、画像を小さなタイルに分割し、それぞれ独立に勾配を計算する。 また、毎回画像をランダムにシフトしていくことで、タイルに見えることを避け、画像全体の品質を向上させる。
def tffunc(*argtypes): &#39;&#39;&#39;Helper that transforms TF-graph generating function into a regular one. See &amp;quot;resize&amp;quot; function below. &#39;&#39;&#39; placeholders = list(map(tf.placeholder, argtypes)) def wrap(f): out = f(*placeholders) def wrapper(*args, **kw): return out.eval(dict(zip(placeholders, args)), session=kw.get(&#39;session&#39;)) return wrapper return wrap # Helper function that uses TF to resize an image def resize(img, size): img = tf.expand_dims(img, 0) return tf.image.resize_bilinear(img, size)[0,:,:,:] resize = tffunc(np.float32, np.int32)(resize) def calc_grad_tiled(img, t_grad, tile_size=512): &#39;&#39;&#39;Compute the value of tensor t_grad over the image in a tiled way.</description>
    </item>
    
    <item>
      <title>DeepDreaming with Tensorflowをやる(1)</title>
      <link>https://www.sambaiz.net/article/20/</link>
      <pubDate>Wed, 07 Sep 2016 01:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/20/</guid>
      <description>https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb
例の通りまとめながら進めていく。
このノートブックは、畳み込みニューラルネットワークによる画像生成の手法を説明するものだ。 ネットワークは入力画像へ変換させる配列のレイヤーの集合から成り立っている。 変換のパラメータは勾配降下法で変形しながら学習していく。 内部的な画像の表現は意味不明なように見えるが、可視化し、解釈することができる。
Loading and displaying the model graph 学習済みネットワークのprotobufファイルが用意されていて、これをダウンロードして使う。 ただgcr.io/tensorflow/tensorflowにwgetもunzipも入っていなかったので、中に入ってapt-getした。
model_fn = &#39;tensorflow_inception_graph.pb&#39; # creating TensorFlow session and loading the model graph = tf.Graph() sess = tf.InteractiveSession(graph=graph) with tf.gfile.FastGFile(model_fn, &#39;rb&#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) t_input = tf.placeholder(np.float32, name=&#39;input&#39;) # define the input tensor imagenet_mean = 117.0 t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0) tf.import_graph_def(graph_def, {&#39;input&#39;:t_preprocessed})  tf.gfile.FastGFileのドキュメントが見つからないので ソース を探したところFile I/Oのラッパーのようだ。これでprotobufファイルを読み、ParseFromStringでGraphDefにする。
さらにこれと入力データをtf.import_graph_defに 渡すことでGraphに取り込む。
tf.expand_dimsは値が1の次元を指定の場所に挿入する もの。なんでそんなことをしたり、imagenet_meanを引いているのかは説明がなかった。
layers = [op.</description>
    </item>
    
    <item>
      <title>Tensorflowの学習データを使ったAPIを作る</title>
      <link>https://www.sambaiz.net/article/13/</link>
      <pubDate>Fri, 05 Aug 2016 22:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/13/</guid>
      <description>チュートリアルのMNISTの学習データを使って、手書き数字画像のデータを受け取り、数字を返すAPIを作る。 コードはここにある。
学習して結果を保存する 前回の学習結果のチェックポイントファイルを出力する。 tf.train.Saver().saveでnameで対応するVariableの値が保存できる。
今回は、学習側、アプリケーション側共にPythonを使うので、以下のようなクラスを作った。
追記(2018-06-22): SavedModelでモデルごと保存するとグラフのコードを共有する必要がないし言語にも依存しなくなる。
TensorFlowのモデルをsave/loadする - sambaiz-net
import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data class Mnist: def __init__(self): g = tf.Graph() with g.as_default(): W_conv1 = self._weight_variable([5, 5, 1, 32], &amp;quot;W_conv1&amp;quot;) b_conv1 = self._bias_variable([32], &amp;quot;b_conv1&amp;quot;) self._x = tf.placeholder(tf.float32, [None, 784]) x_image = tf.reshape(self._x, [-1,28,28,1]) h_conv1 = tf.nn.relu(self._conv2d(x_image, W_conv1) + b_conv1) h_pool1 = self._max_pool_2x2(h_conv1) W_conv2 = self._weight_variable([5, 5, 32, 64], &amp;quot;W_conv2&amp;quot;) b_conv2 = self._bias_variable([64], &amp;quot;b_conv2&amp;quot;) h_conv2 = tf.</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアル2(Deep MNIST for Experts)</title>
      <link>https://www.sambaiz.net/article/6/</link>
      <pubDate>Tue, 12 Jul 2016 21:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/6/</guid>
      <description>前回に引き続き、まとめながら進めていく。
Deep MNIST for Experts
Start TensorFlow InteractiveSession 今回は、前回のようにグラフを作成してからSessionを開始する代わりに InteractiveSessionを使う。 グラフを作成し実行するのをインタラクティブに行うことができ、IPythonのような環境で便利だ。
import tensorflow as tf sess = tf.InteractiveSession()  Build a Multilayer Convolutional Network 前回のシンプルなモデルでは、あまり良い結果が出なかった。 そこで、今回はもう少し洗練されたモデル、小さな畳み込みニューラルネットワークを作成する。
Weight Initialization このモデルを作成するためには、たくさんの重みとバイアスを作成する必要がある。
重みは、対称性を破り、勾配0を避けるために、少しのノイズで初期化すべきだ。
また、ReLU(Rectified Linear Unit, 正規化線形関数)ニューロンを使うので、&amp;rdquo;死んだニューロン&amp;rdquo;を避けるためにわずかな正の値のバイアスで初期化すると良い。
tf.truncated_normalは正規分布で、μ±2σ範囲内のランダムな値を返す。 以下の例だと、meanのデフォルトが0.0なので、正規分布 N(0, 0.01)の、-0.2&amp;lt;=x&amp;lt;=0.2な値がランダムに返ることになる。
def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)  Convolution and Pooling TensorFlowは柔軟な畳み込みとプーリングの手続きを提供している。
畳み込みというのは、画像に対してフィルターを少しずつ動かしながら掛けていく処理のことだ。このページが分かりやすい。 例えば、ソーベルフィルタで輪郭になっているところを抽出するように、 フィルターの値によって、その区域における、ある特徴を際立たせたりすることができる。 今回はこのフィルターが重みとなり、際立たせたいのはその数字を識別するための特徴ということになる。 前回は画像を一次元の配列として扱い重みを学習していたので、縦の情報が失われていたが、この方法ではそれがない。
プーリングというのは画像から区域ごとにサンプリングする処理だ。最大プーリングや、平均プーリングなどの手法がある。 畳み込みのように順番に区域を見ていって、最大プーリングならそのうちの最大のものを採用し、他のものは無視する。 サイズが小さくなるだけではなく、ちょっとした位置のずれを吸収することができる。
def conv2d(x, W): return tf.</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアルまで</title>
      <link>https://www.sambaiz.net/article/3/</link>
      <pubDate>Sun, 03 Jul 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/3/</guid>
      <description>Googleが公開した人工知能ライブラリTensorFlowを使ってみる。 セットアップ方法はいくつか提供されているが、Dockerで動かすことにした。 Jupyter Notebookが立ち上がるのですぐに試せて良い。
$ docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow  http://localhost:8888/tree
公式のチュートリアルをまとめながら進めてみる。
MNIST For ML Beginners
The MNIST Data MNISTというのは0~9の書き数字の画像のデータセットのことで、これらを正しく分類するのが目的。
それぞれの画像は一律28*28=784ピクセルで、それぞれのピクセルは0と1の間の数値(強さ)で表されている。 今回はこれの縦横を取っ払って784次元のベクトルとして扱っている。
したがって、学習用の画像データは[55000, 784]のtensor(n次元の配列)で表される。 55000というのが画像の数で、784というのがそれぞれの画像の次元を意味している。
それぞれの画像に対応した数字のラベルは[55000, 10]で表される。 10というのは、0~9それぞれに対応した次元のうち、一つだけ1で、それ以外が0という風に使われる。これをone-hot vectorという。
Softmax Regressions Softmaxはいくつかの異なるもの(今回でいうと数字)に確率を割り当てる。
画像が特定のクラス(0~9)に属するかどうか計算するために、ピクセルの強さに重みを付けた合計を計算する。 もし、そのピクセルがそのクラスに属さない根拠になるなら負の重みがかかり、属する根拠になるなら、正の重みがかかるようにする。 また合計にさらに入力と無関係なクラスごとに異なるバイアスを足す。
全てのクラスで計算した値をsoftmax関数に入れ、それぞれ確率に変換する。この確率の和は1になるようになっている。
Implementing the Regression Pythonでは行列の積のような重い処理をするとき、NumPyのようなライブラリを使ってPythonの外で行うが、 外からPythonに戻るときにオーバーヘッドが発生してしまう。 TensorFlowでも重い処理を外で行うが、オーバーヘッドを避けるために、 単体の重い処理をPythonから独立して実行するのではなく、Pythonの外側で実行される関連した処理のグラフを記述させる。
import tensorflow as tf x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b)  tf.placeholderは実行時に与えられる値で、今回が画像データ。 W(重み)とb(バイアス)は学習する変数。 tf.</description>
    </item>
    
  </channel>
</rss>