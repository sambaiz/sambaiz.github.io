<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tensorflow on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/tensorflow/</link>
    <description>Recent content in Tensorflow on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sat, 03 Nov 2018 18:03:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TensorFlowのtf.data API</title>
      <link>https://www.sambaiz.net/article/195/</link>
      <pubDate>Sat, 03 Nov 2018 18:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/195/</guid>
      <description>Importing Data | TensorFlow
入力データを準備してイテレータを作成するAPI。
Datasetの作成 from_tensor_slices()でDatasetを作成する。
dataset = tf.data.Dataset.from_tensor_slices( {&amp;quot;a&amp;quot;: tf.random_uniform([4]), &amp;quot;b&amp;quot;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)}) print(dataset.output_types) # {&#39;a&#39;: tf.float32, &#39;b&#39;: tf.int32} print(dataset.output_shapes) # {&#39;a&#39;: TensorShape([]), &#39;b&#39;: TensorShape([Dimension(100)])}  引数にnumpyのndarrayを渡すとtf.constant()で変換されてグラフに乗る。
dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3))) print(dataset.output_types) # &amp;lt;dtype: &#39;int64&#39;&amp;gt; print(dataset.output_shapes) # (3,)  データが1GBを超える場合グラフのシリアライズ上限を超えてしまうことがある。後述するinitializableイテレータの初期化時にndarrayを渡すとこれを避けられる。
tf.contrib.data.CsvDatasetでCSVからDatasetを作ることもできる。
$ cat file1.csv a,b,c,d 1,2,3,4 2,3,4,5 6,7,8,9  filenames = [&amp;quot;file1.csv&amp;quot;] record_defaults = [tf.float32] * 2 # Two required float columns dataset = tf.contrib.data.CsvDataset(filenames, record_defaults, header=True, select_cols=[1,3]) print(dataset.</description>
    </item>
    
    <item>
      <title>Destributed TensorFlowの流れとSavedModelの出力</title>
      <link>https://www.sambaiz.net/article/179/</link>
      <pubDate>Wed, 25 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/179/</guid>
      <description>Distributed TensorFlow クラスタを組んでGraphを分散実行する。
クラスタは
 master: sessionを作成し、workerを制御する worker: 計算を行う ps(parameter server): 変数の値を持ち、更新する  のjobからなり、gRPCの
 Master Service Worker Service  でやり取りする。
TensorFlow serverを立てる 各jobとURLのmapをClusterSpecにして jobとindexと併せてServerDefを作って Serverを立てる。
{ &amp;quot;master&amp;quot;: [ &amp;quot;check-tf-config-master-34z8-0:2222&amp;quot; ], &amp;quot;ps&amp;quot;: [ &amp;quot;check-tf-config-ps-34z8-0:2222&amp;quot;, &amp;quot;check-tf-config-ps-34z8-1:2222&amp;quot; ], &amp;quot;worker&amp;quot;: [ &amp;quot;check-tf-config-worker-34z8-0:2222&amp;quot;, &amp;quot;check-tf-config-worker-34z8-1:2222&amp;quot; ] }  cluster_spec_object = tf.train.ClusterSpec(cluster_spec) server_def = tf.train.ServerDef( cluster=cluster_spec_object.as_cluster_def(), protocol=&amp;quot;grpc&amp;quot;, job_name=job_name, # worker, master, ps task_index=0) server = tf.train.Server(server_def)  psのjobではserver.join()して待ち構える。
if job_name == &amp;quot;ps&amp;quot;: server.join() else: # build model  WorkerにGraphを割り当てる workerのdeviceにGraphを割り当てる。 deviceは/job:worker/replica:0/task:0/device:GPU:0 のようなフォーマットで表される。</description>
    </item>
    
    <item>
      <title>TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー</title>
      <link>https://www.sambaiz.net/article/175/</link>
      <pubDate>Sun, 01 Jul 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/175/</guid>
      <description>MonitoredSession
deprecatedになったSupervisorの後継。
MonitoredTrainingSessionで学習用のMonitoredSessionを生成する。 このコンストラクタの引数でcheckpoint_dirを渡すと内部でCheckpointSaverHookが 追加されるようになっていて、restoreしたり指定したタイミングでsaveしたりしてくれる。
なので今回明示的に渡すhooksは 指定したstepに到達したら止めてくれる、StopAtStepHookのみ。
should_stop()がTrueな状態でsession.run()しようとするとRun called even after should_stop requested.のエラーが出るため、 今回は新しいsessionを作ってAccuracyを返しているが、hookでやった方がrestoreする必要がないので良さそうだ。
Destributed TensorFlowの流れとSavedModelの出力 - sambaiz-net
全体のコードはここ。
def train(self, learning_rate, variable_default_stddev, bias_default, last_step=800): test_images = self.images[:500] test_labels = self.labels[:500] train_batch = Batch(self.images[500:], self.labels[500:]) with tf.Graph().as_default(): global_step=tf.train.get_or_create_global_step() g = MNIST_CNN(learning_rate, variable_default_stddev, bias_default).graph() saver = tf.train.Saver() savedir = &#39;./ckpt-{}-{}-{}&#39;.format(learning_rate, variable_default_stddev, bias_default) hooks = [ tf.train.StopAtStepHook(last_step=last_step) ] with tf.train.MonitoredTrainingSession( hooks=hooks, checkpoint_dir=savedir, save_checkpoint_secs = 300, ) as sess: sess.run(global_step) while not sess.should_stop(): # step = sess.</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをsave/loadする</title>
      <link>https://www.sambaiz.net/article/172/</link>
      <pubDate>Fri, 22 Jun 2018 01:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/172/</guid>
      <description>SavedModelBuilderで モデルを言語に依存しないSavedModelのprotobufにして保存できる。 SavedModelにはSaverによって出力されるCheckpointを共有する一つ以上のMetaGraphDefを含む。
import tensorflow as tf def build_signature(signature_inputs, signature_outputs): return tf.saved_model.signature_def_utils.build_signature_def( signature_inputs, signature_outputs, tf.saved_model.signature_constants.REGRESS_METHOD_NAME) def save(sess, export_dir, signature_def_map): builder = tf.saved_model.builder.SavedModelBuilder(export_dir) builder.add_meta_graph_and_variables( sess, [tf.saved_model.tag_constants.SERVING], signature_def_map=signature_def_map ) builder.save() import shutil import os.path export_dir = &amp;quot;./saved_model&amp;quot; if os.path.exists(export_dir): shutil.rmtree(export_dir) with tf.Graph().as_default(): a = tf.placeholder(tf.float32, name=&amp;quot;a&amp;quot;) b = tf.placeholder(tf.float32, name=&amp;quot;b&amp;quot;) c = tf.add(a, b, name=&amp;quot;c&amp;quot;) v = tf.placeholder(tf.float32, name=&amp;quot;v&amp;quot;) w = tf.Variable(0.0, name=&amp;quot;w&amp;quot;) x = w.assign(tf.add(v, w)) sv = tf.train.Supervisor() with sv.managed_session() as sess: print(sess.</description>
    </item>
    
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。 全体のコードはここ。
入力 以下の関数によって生成した1次元のデータ列。 これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。
def make_time_series_data(size): data = [] for i in range(size): data.append(sin(random.normalvariate(i,0.1)*0.1)) return np.reshape(np.array(data, dtype=np.float32), (size,1)) def make_batch(data, batch_size, num_steps, num_dimensions, name=None): epoch_size = data.size // (batch_size*num_steps*num_dimensions) data = np.lib.stride_tricks.as_strided( data, shape= (epoch_size, batch_size, num_steps+1, num_dimensions), strides=( 4*batch_size*num_steps*num_dimensions, 4*num_steps*num_dimensions, 4*num_dimensions, 4 # bytes ), writeable=False ) return data[:, :, :-1], data[:, :, 1:]  モデル input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。 lossはMSE(Mean squared error)。OptimizerはGradientDecentOptimizerを使っている。
チュートリアルでは自力で各time_stepの値を入れていたけど、 今回はdynamic_rnn()に任せている。</description>
    </item>
    
    <item>
      <title>TensorBoardでsummaryやグラフを見る</title>
      <link>https://www.sambaiz.net/article/147/</link>
      <pubDate>Sun, 07 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/147/</guid>
      <description>TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
で読んだコードをTensorboardでみてみる。
8888がJupyter、6006がTensorboard。
$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow  コードをuploadするかJupyterからterminalを開いてcloneしてくる。
# apt-get update # apt-get install -y git wget # git clone https://github.com/tensorflow/models.git # cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz  logdirを指定して実行し、Tensorboardを起動。
flags.DEFINE_string(&amp;quot;save_path&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;Model output directory.&amp;quot;) sv = tf.train.Supervisor(logdir=FLAGS.save_path)  # tensorboard --logdir=models/tutorials/rnn/ptb  tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)による値がリアルタイムに表示される。
グラフのつながりや、各Operationの入出力やそのshapeを確認できる。 name_scopeで分けておくと見やすい。</description>
    </item>
    
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。
RNN/LSTMとは RNNは入力に対して出力のほかに情報を次のステップに渡すネットワーク。 展開すると同じネットワークに単語を一つずつ入れていくように表現できる。
TensorflowではいくつかRNNの実装が用意されていて、このコードではそのうちのCudnnLSTMやBasicLSTMCell、LSTMBlockCellを選べるようになっている。cuDNNというのはNVIDIAのCUDAのDNNライブラリのこと。LSTMBlockCellはBasicLSTMCellより速い。
LSTM(Long Short Term Memory networks)はRNNの一種で、Cellは出力となるh(hidden state)のほかにC(Cell state)を持つ。 Cは前回のCをどの値を更新するか決定するinput gateに通し、その後に入力とhを、どの値を忘れるかを決定するforget gateに通して加えたものになる。 hはこのCと前回のhを何を出力するか決定するoutput gateに通したものになる。 これらで値域(0,1)のシグモイド関数が掛けられ、0であれば情報は失われ、1であれば完全に残る。
動かしてみる $ git clone https://github.com/tensorflow/models.git $ cd models/tutorials/rnn/ptb/ $ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz $ tar xvf simple-examples.tgz $ python3 -m venv env $ . ./env/bin/activate $ pip install numpy tensorflow  $ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0 Epoch: 1 Learning rate: 1.000 0.004 perplexity: 5534.452 speed: 894 wps 0.104 perplexity: 845.383 speed: 1277 wps .</description>
    </item>
    
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>活性化関数というのは各層での重み掛けバイアス足しのあとに適用する非線形の関数。 これはカーネル法のように空間を変換して線形分離できないデータを線形分離できるようにするはたらきをする。 線形な関数を使うと層を重ねても結局線形のままで、空間もそのまま伸縮するだけなので目的を果たさない。
バックプロバゲーション(誤差逆伝播法)するために微分できる必要がある。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
Tensorflowでは以下の活性化関数が用意されている。
sigmoid 値域は(0,1)でシグマの語末系ςに似たS字を描く。 微分係数がそれほど大きくないので何層もこの関数を適用すると、バックプロバゲーションで微分係数を掛けていった結果、勾配が消失する問題がありあまり使われない。値域が(-1,1)で似たグラフを描くtanh(Hyperbolic tangent)もある。
softsign tanhと比べて漸近線に近づく速度が遅くなっている。 それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。
softplus ReLUに続く。
ReLU(Rectified Linear Unit) 単純だけど最有力。勾配消失も起きにくい。x=0で微分できないが0か1として扱われる。
def deriv_relu(x): return np.where(x &amp;gt; 0, 1, 0)  softplusと比べてexpやlogを含まない分高速に計算できるので、 膨大で複雑なデータセットに対して多くの層を用いることができる。
0以下は等しく0になるため、学習中に落ちてしまうとニューロンが死んでしまう。 これを避けるため0以下のときy = exp(x) - 1にするELU(Exponential Linear Unit) というのもある。
比較的起きにくいとはいえ、層を深くすると勾配消失する可能性は高まる。 活性化関数ごとに異なる重みの初期値によってこれを緩和でき、ReLUでは入力次元数によるHe Initializationというのが提案されている。
rng = np.random.RandomState(1234) n_in = 10 # 入力次元数 rng.uniform( low=-np.sqrt(6/n_in), high=+np.sqrt(6/n_in), size=5 ) # He Initialization  参考 Activation functions and it’s types-Which is better?</description>
    </item>
    
    <item>
      <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
      <link>https://www.sambaiz.net/article/124/</link>
      <pubDate>Sun, 06 Aug 2017 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/124/</guid>
      <description>AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリSonnetを使う。 当初はPython2しか対応していないようだったけど、今は3にも対応している。
準備 TensorFlowを使うライブラリはほかにもいくつかあるのだけど、 Kerasと比較してみると、 KerasがTensorFlowの部分を完全にラップしているのに対して、 Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。
SonnetとTensorFlowとPython3入りイメージをDockerHubに上げた。 Dockerfileはここ。
内容は基本的にREADME通りだけど、 configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。 あとは、TensorFlowのビルドに使われているGCCのバージョンが古いようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;を付けている。
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_  起動。
$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet $ docker logs sonnet ... Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=*****  Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。
import sonnet as snt import tensorflow as tf snt.resampler(tf.constant([0.]), tf.constant([0.])) # =&amp;gt; &amp;lt;tf.</description>
    </item>
    
    <item>
      <title>DeepDreaming with TensorFlowをやる(2)</title>
      <link>https://www.sambaiz.net/article/21/</link>
      <pubDate>Sat, 10 Sep 2016 14:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/21/</guid>
      <description>前回の続き。
Multiscale image generation 様々なスケールで勾配上昇させる。小さなスケールで上昇させたものをより大きなスケールでさらに上昇させていく。 ただ、壁紙のようなサイズを生成するような場合にそれを行うと、GPUのメモリを食いつぶしてしまう。 これを避けるために、画像を小さなタイルに分割し、それぞれ独立に勾配を計算する。 また、毎回画像をランダムにシフトしていくことで、タイルに見えることを避け、画像全体の品質を向上させる。
def tffunc(*argtypes): &#39;&#39;&#39;Helper that transforms TF-graph generating function into a regular one. See &amp;quot;resize&amp;quot; function below. &#39;&#39;&#39; placeholders = list(map(tf.placeholder, argtypes)) def wrap(f): out = f(*placeholders) def wrapper(*args, **kw): return out.eval(dict(zip(placeholders, args)), session=kw.get(&#39;session&#39;)) return wrapper return wrap # Helper function that uses TF to resize an image def resize(img, size): img = tf.expand_dims(img, 0) return tf.image.resize_bilinear(img, size)[0,:,:,:] resize = tffunc(np.float32, np.int32)(resize) def calc_grad_tiled(img, t_grad, tile_size=512): &#39;&#39;&#39;Compute the value of tensor t_grad over the image in a tiled way.</description>
    </item>
    
    <item>
      <title>DeepDreaming with Tensorflowをやる(1)</title>
      <link>https://www.sambaiz.net/article/20/</link>
      <pubDate>Wed, 07 Sep 2016 01:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/20/</guid>
      <description>https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb
例の通りまとめながら進めていく。
このノートブックは、畳み込みニューラルネットワークによる画像生成の手法を説明するものだ。 ネットワークは入力画像へ変換させる配列のレイヤーの集合から成り立っている。 変換のパラメータは勾配降下法で変形しながら学習していく。 内部的な画像の表現は意味不明なように見えるが、可視化し、解釈することができる。
Loading and displaying the model graph 学習済みネットワークのprotobufファイルが用意されていて、これをダウンロードして使う。 ただgcr.io/tensorflow/tensorflowにwgetもunzipも入っていなかったので、中に入ってapt-getした。
model_fn = &#39;tensorflow_inception_graph.pb&#39; # creating TensorFlow session and loading the model graph = tf.Graph() sess = tf.InteractiveSession(graph=graph) with tf.gfile.FastGFile(model_fn, &#39;rb&#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) t_input = tf.placeholder(np.float32, name=&#39;input&#39;) # define the input tensor imagenet_mean = 117.0 t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0) tf.import_graph_def(graph_def, {&#39;input&#39;:t_preprocessed})  tf.gfile.FastGFileのドキュメントが見つからないので ソース を探したところFile I/Oのラッパーのようだ。これでprotobufファイルを読み、ParseFromStringでGraphDefにする。
さらにこれと入力データをtf.import_graph_defに 渡すことでGraphに取り込む。
tf.expand_dimsは値が1の次元を指定の場所に挿入する もの。なんでそんなことをしたり、imagenet_meanを引いているのかは説明がなかった。
layers = [op.</description>
    </item>
    
    <item>
      <title>Tensorflowの学習データを使ったAPIを作る</title>
      <link>https://www.sambaiz.net/article/13/</link>
      <pubDate>Fri, 05 Aug 2016 22:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/13/</guid>
      <description>チュートリアルのMNISTの学習データを使って、手書き数字画像のデータを受け取り、数字を返すAPIを作る。 コードはここにある。
学習して結果を保存する 前回の学習結果のcheckpointファイルを出力する。 tf.train.Saver().saveでnameで対応するVariableの値が保存できる。 また、その際デフォルトでMetaGraphもexportされ、これをimportすればGraphも復元することができる。
import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data class Mnist: def __init__(self): g = tf.Graph() with g.as_default(): W_conv1 = self._weight_variable([5, 5, 1, 32], &amp;quot;W_conv1&amp;quot;) b_conv1 = self._bias_variable([32], &amp;quot;b_conv1&amp;quot;) self._x = tf.placeholder(tf.float32, [None, 784]) x_image = tf.reshape(self._x, [-1,28,28,1]) h_conv1 = tf.nn.relu(self._conv2d(x_image, W_conv1) + b_conv1) h_pool1 = self._max_pool_2x2(h_conv1) W_conv2 = self._weight_variable([5, 5, 32, 64], &amp;quot;W_conv2&amp;quot;) b_conv2 = self._bias_variable([64], &amp;quot;b_conv2&amp;quot;) h_conv2 = tf.nn.relu(self._conv2d(h_pool1, W_conv2) + b_conv2) h_pool2 = self.</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアル2(Deep MNIST for Experts)</title>
      <link>https://www.sambaiz.net/article/6/</link>
      <pubDate>Tue, 12 Jul 2016 21:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/6/</guid>
      <description>前回に引き続き、まとめながら進めていく。
Deep MNIST for Experts
Start TensorFlow InteractiveSession 今回は、前回のようにグラフを作成してからSessionを開始する代わりに InteractiveSessionを使う。 グラフを作成し実行するのをインタラクティブに行うことができ、IPythonのような環境で便利だ。
import tensorflow as tf sess = tf.InteractiveSession()  Build a Multilayer Convolutional Network 前回のシンプルなモデルではあまり良い結果が出なかった。 そこで、今回はもう少し洗練されたモデル、小さな畳み込みニューラルネットワークを作成する。
Weight Initialization 勾配が0になるのを避けるために重みの初期化時にノイズを付ける。 tf.truncated_normalは正規分布で、μ±2σ範囲内のランダムな値を返す。 以下の例だと、meanのデフォルトが0.0なので、正規分布 N(0, 0.01)の、-0.2&amp;lt;=x&amp;lt;=0.2な値がランダムに返ることになる。
また、ReLU(Rectified Linear Unit, 正規化線形関数)ニューロンを使うので、&amp;rdquo;死んだニューロン&amp;rdquo;を避けるために、バイアスは小さな正の値で初期化する。
ニューラルネットワークと活性化関数 - sambaiz-net
def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)  Convolution and Pooling TensorFlowに畳み込みとプーリングの関数が用意されている。
畳み込みというのは、画像に対してフィルターを少しずつ動かしながら掛けていく処理のこと。このページが分かりやすい。 例えば、ソーベルフィルタで輪郭になっているところを抽出するように、 フィルターの値によって、その区域における、ある特徴を際立たせたりすることができる。 今回はこのフィルターが重みとなり、際立たせたいのはその数字を識別するための特徴ということになる。 前回は画像を一次元の配列として扱い重みを学習していたので、縦の情報が失われていたが、この方法ではそれがない。
プーリングというのは画像から区域ごとにサンプリングする処理のこと。最大プーリングや、平均プーリングなどの手法がある。 畳み込みのように順番に区域を見ていって、最大プーリングならそのうちの最大のものを採用し、他のものは無視する。 サイズが小さくなるだけではなく、ちょっとした位置のずれを吸収することができる。</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアルまで</title>
      <link>https://www.sambaiz.net/article/3/</link>
      <pubDate>Sun, 03 Jul 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/3/</guid>
      <description>Googleが公開した人工知能ライブラリTensorFlowを使ってみる。 セットアップ方法はいくつか提供されているが、Dockerで動かすことにした。 Jupyter Notebookが立ち上がるのですぐに試せて良い。
$ docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow  http://localhost:8888/tree
公式のチュートリアルをまとめながら進めてみる。
MNIST For ML Beginners
The MNIST Data MNISTというのは0~9の書き数字の画像のデータセットのことで、これらを正しく分類するのが目的。
それぞれの画像は一律28*28=784ピクセルで、それぞれのピクセルは0と1の間の数値(強さ)で表されている。 今回はこれの縦横を取っ払って784次元のベクトルとして扱っている。
したがって、学習用の画像データは[55000, 784]のtensor(n次元の配列)で表される。 55000というのが画像の数で、784というのがそれぞれの画像の次元を意味している。
それぞれの画像に対応した数字のラベルは[55000, 10]で表される。 10というのは、0~9それぞれに対応した次元のうち、一つだけ1で、それ以外が0という風に使われる。これをone-hot vectorという。
Softmax Regressions Softmaxはいくつかの異なるもの(今回でいうと数字)に確率を割り当てる。
画像が特定のクラス(0~9)に属するかどうか計算するために、ピクセルの強さに重みを付けた合計を計算する。 もし、そのピクセルがそのクラスに属さない根拠になるなら負の重みがかかり、属する根拠になるなら、正の重みがかかるようにする。 また合計にさらに入力と無関係なクラスごとに異なるバイアスを足す。
全てのクラスで計算した値をsoftmax関数に入れ、それぞれ確率に変換する。この確率の和は1になるようになっている。
Implementing the Regression Pythonでは行列の積のような重い処理をするとき、NumPyのようなライブラリを使ってPythonの外で行うが、 外からPythonに戻るときにオーバーヘッドが発生してしまう。 TensorFlowでも重い処理を外で行うが、オーバーヘッドを避けるために、 単体の重い処理をPythonから独立して実行するのではなく、Pythonの外側で実行される関連した処理のグラフを記述させる。
import tensorflow as tf x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b)  tf.placeholderは実行時に与えられる値で、今回が画像データ。 W(重み)とb(バイアス)は学習する変数。 tf.</description>
    </item>
    
  </channel>
</rss>