<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tensorflow on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/tensorflow/</link>
    <description>Recent content in tensorflow on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Mon, 10 Aug 2020 13:39:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SageMakerでTensorFlowのモデルを学習させる</title>
      <link>https://www.sambaiz.net/article/293/</link>
      <pubDate>Mon, 10 Aug 2020 13:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/293/</guid>
      <description>以前PyTorchのモデルを学習させたが、そのTensorFlow版。
SageMakerでPyTorchのモデルを学習させる - sambaiz-net
コード 全体のコードはGitHubにある。
モデル モデルはTitanicのを使う。
TensorFlow2のKeras APIでTitanicのモデルを作る - sambaiz-net
make_csv_dataset()はbatch_sizeが必須になっているが、 これをそのままfilter()しようとすると、ValueError: predicate return type must be convertible to a scalar boolean tensor.になってしまうのでunbatch()している。 SageMakerのServing containerを用いる場合はsave_format=&amp;quot;tf&amp;quot;にしてSavedModel形式で保存する必要がある。
$ cat model.py import tensorflow as tf import logging class Model: def __init__(self, logger: logging.Logger, dropout: float): self.logger = logger self.model = tf.keras.Sequential([ tf.keras.layers.DenseFeatures(self._feature_columns()), tf.keras.layers.Dense(128, activation=tf.nn.relu), tf.keras.layers.Dropout(dropout), tf.keras.layers.Dense(128, activation=tf.nn.relu), tf.keras.layers.Dense(2, activation=tf.nn.sigmoid), ]) self.model.compile(optimizer=&amp;#39;adam&amp;#39;, loss=&amp;#39;binary_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;]) def _feature_columns(self): return [ tf.feature_column.numeric_column(&amp;#39;age&amp;#39;), tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_identity(&amp;#39;sex&amp;#39;, 2)), tf.feature_column.numeric_column(&amp;#39;fare&amp;#39;) ] def _fill(self, feature: str, value): def __fill(x): if x[feature] == -1.</description>
    </item>
    
    <item>
      <title>TensorFlow2のKeras APIでTitanicのモデルを作る</title>
      <link>https://www.sambaiz.net/article/291/</link>
      <pubDate>Sat, 08 Aug 2020 18:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/291/</guid>
      <description>データセット TensorFlow Datasetsの Titanicを使う。
$ pip install tensorflow-datasets tfds.load()して tf.data.Datasetを作る。 tf.data はCPUやGPUがなるべくアイドル状態にならないようにする効率的な入力パイプラインを構築するAPI。
TensorFlowのtf.data API - sambaiz-net
import tensorflow as tf import tensorflow_datasets as tfds ds_train = tfds.load(&amp;#39;titanic&amp;#39;, split=&amp;#39;train&amp;#39;, shuffle_files=True) print(ds_train.element_spec) &amp;#39;&amp;#39;&amp;#39; {&amp;#39;features&amp;#39;: {&amp;#39;age&amp;#39;: TensorSpec(shape=(), dtype=tf.float32, name=None), &amp;#39;boat&amp;#39;: TensorSpec(shape=(), dtype=tf.string, name=None), &amp;#39;body&amp;#39;: TensorSpec(shape=(), dtype=tf.int32, name=None), &amp;#39;cabin&amp;#39;: TensorSpec(shape=(), dtype=tf.string, name=None), &amp;#39;embarked&amp;#39;: TensorSpec(shape=(), dtype=tf.int64, name=None), &amp;#39;fare&amp;#39;: TensorSpec(shape=(), dtype=tf.float32, name=None), &amp;#39;home.dest&amp;#39;: TensorSpec(shape=(), dtype=tf.string, name=None), &amp;#39;name&amp;#39;: TensorSpec(shape=(), dtype=tf.string, name=None), &amp;#39;parch&amp;#39;: TensorSpec(shape=(), dtype=tf.int32, name=None), &amp;#39;pclass&amp;#39;: TensorSpec(shape=(), dtype=tf.</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをTPUに対応させてColabで学習し実行時間を計測する</title>
      <link>https://www.sambaiz.net/article/199/</link>
      <pubDate>Tue, 27 Nov 2018 09:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/199/</guid>
      <description>TPU(Tensor Processing Unit)は Google開発のニューラルネットワークの学習に特化したASIC(Application Specific Integrated Circuit)。 一般的なGPUと比べて15~30倍もの性能が出る らしく検索や翻訳などGoogleのサービスでも使われている。
TPUを使える環境として、無料で使えるJupyter NotebooksのGoogle Colabと GCPのCloud TPUがある。ColabのTPUも裏側ではCloud TPUが動いている。 Cloud TPUを直に使うとVMから接続して使うことになるので、TPUの料金に加えてVMの料金もかかる。
モデルのTPU対応 CNNのモデルをTPUEstimatorでTPUに対応させる。
EstimatorはTensorFlowの高レベルAPIで、 train()、 evaluate()、 predict()、 export_saved_model() といったモデルの学習から保存まで必要な機能を一通り提供する。
初めは比較的低レベルのAPIを使おうとしていたが、XLA(Accelerated Linear Algebra)によるコンパイルがうまくいかないなど様々な問題にあたって大変だったので使っておくと良いと思う。 それでもトライアンドエラーの繰り返しで、典型的なものはTroubleshootingにあるが、ないものは調べるなりしてなんとかやっていくしかない。
定数などの定義。BATCH_SIZEはCloud TPUのシャード数の8で割り切れる値にする必要がある。
import pandas as pd from sklearn.model_selection import train_test_split import tensorflow as tf import numpy as np flags = tf.app.flags flags.DEFINE_boolean(&amp;#39;use_tpu&amp;#39;, True, &amp;#39;use tpu or not&amp;#39;) tf.app.flags.DEFINE_string(&amp;#39;f&amp;#39;, &amp;#39;&amp;#39;, &amp;#39;kernel&amp;#39;) FLAGS = flags.FLAGS EPOCH_NUM = 100 BATCH_SIZE = 800 # must be divisible by number of replicas 8 EVAL_BATCH_SIZE = 800 SHARD_NUM = 8 # A single Cloud TPU has 8 shards.</description>
    </item>
    
    <item>
      <title>Deep LearningのBatch Normalizationの効果をTensorFlowで確認する</title>
      <link>https://www.sambaiz.net/article/198/</link>
      <pubDate>Wed, 14 Nov 2018 02:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/198/</guid>
      <description>Batch Normalizationとは Deep Learningでは各層の学習を同時に行うため、前の層の変更によって各層の入力の分布が変わってしまうinternal covariate shiftという現象が起こり、そのためにパラメータの初期化をうまくやる必要があったり、学習率を大きくできず多くのステップを要する。 以下の論文で発表されたBatch Normalization(BN)は各層の入力を正規化して分布を固定することでこれを解決するというもの。 画像認識のコンテストILSVRC 2015で1位を取ったResNet(Residual Network)でも使われている。
Sergey Ioffe, Christian Szegedy (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
具体的にはWx+bと活性化関数の間にBNの層を入れる。μ、σ^2は入力xの平均と分散。 単に正規化するだけでは表現力が下がってしまうのでγとβでスケールやシフトできるようにする。これらの変数は他のパラメータと同様に学習させる。
TensorFlowでの確認 TensorFlowではbatch_normalization()がすでに実装されているのでこれを使う。
以下のCNNで学習率を高めに設定しBNありなしの結果を比較する。学習データはmnist。MonitoredSessionでcostをsummaryとして出力しTensorBoardで見られるようにしている。
TensorBoardでsummaryやグラフを見る - sambaiz-net
TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー - sambaiz-net
import pandas as pd import numpy as np import tensorflow as tf from sklearn.model_selection import train_test_split from sklearn.utils import shuffle from sklearn.metrics import accuracy_score train = pd.read_csv(&amp;#39;./train.csv&amp;#39;) (x_train, x_valid ,y_train, y_valid) = train_test_split( train.</description>
    </item>
    
    <item>
      <title>TensorFlow&#43;numpyでData Augmentationして画像の学習データを増やす</title>
      <link>https://www.sambaiz.net/article/197/</link>
      <pubDate>Sun, 11 Nov 2018 15:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/197/</guid>
      <description>Data Augmentationは学習データを加工したものを学習データに加えることで数を増やすというもの。 加工したデータには通常元のものと同じラベルが付くことになるが、 例えば画像を反転や回転させても元々のものと同じだと認識されるべきだとしたら妥当だ。 つまり、なんでもすれば良いわけではなくデータセットに応じた、元のデータと同じラベルが付くような加工をする必要があり、 裏を返せばそのような違いがあっても同じものであることをモデルに学習させることができる。
今回はData Augmentationで行われる加工をTensorFlowやnumpyの関数でおなじみLennaの画像に行う。
必要なパッケージと画像をimportする。Jupyter Notebooksで実行する。
%matplotlib inline from PIL import Image import matplotlib.pyplot as plt import numpy as np import tensorflow as tf im = Image.open(&amp;#34;lenna.png&amp;#34;, &amp;#34;r&amp;#34;) Flipping  flip_left_right() random_flip_left_right() flip_up_down() random_flip_up_down()  左右と上下の反転。randomは1/2で反転する。
fliph = tf.image.flip_left_right(im) flipv = tf.image.flip_up_down(im) with tf.Session() as sess: results = sess.run([fliph, flipv]) plt.imshow(np.hstack(results)) Rotating  rot90()  反時計周りに90度回転させる。
rot90 = tf.image.rot90(im) with tf.Session() as sess: results = sess.run([rot90]) plt.</description>
    </item>
    
    <item>
      <title>TensorFlowのtf.data API</title>
      <link>https://www.sambaiz.net/article/195/</link>
      <pubDate>Sat, 03 Nov 2018 18:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/195/</guid>
      <description>Importing Data | TensorFlow
データを読み込み変換してイテレートする入力パイプラインを作るAPI。 通常、学習にGPU/TPUを使う場合CPU処理の間はアイドル状態となりボトルネックになるが、 パイプライン処理を行うことでCPUとGPU/TPUがなるべくアイドル状態にならないようになり、 学習時間が短縮される。
Datasetの作成 from_tensor_slices()でDatasetを作成する。
dataset = tf.data.Dataset.from_tensor_slices( {&amp;#34;a&amp;#34;: tf.random_uniform([4]), &amp;#34;b&amp;#34;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)}) print(dataset.output_types) # {&amp;#39;a&amp;#39;: tf.float32, &amp;#39;b&amp;#39;: tf.int32} print(dataset.output_shapes) # {&amp;#39;a&amp;#39;: TensorShape([]), &amp;#39;b&amp;#39;: TensorShape([Dimension(100)])} 引数にnumpyのndarrayを渡すとtf.constant()で変換されてグラフに乗る。
dataset = tf.data.Dataset.from_tensor_slices(np.arange(9).reshape((3, 3))) print(dataset.output_types) # &amp;lt;dtype: &amp;#39;int64&amp;#39;&amp;gt; print(dataset.output_shapes) # (3,) データが1GBを超える場合グラフのシリアライズ上限を超えてしまうことがある。後述するinitializableイテレータの初期化時にndarrayを渡すとこれを避けられる。
tf.contrib.data.CsvDatasetでCSVからDatasetを作ることもできる。
$ cat file1.csv a,b,c,d 1,2,3,4 2,3,4,5 6,7,8,9 filenames = [&amp;#34;file1.csv&amp;#34;] record_defaults = [tf.float32] * 2 # Two required float columns dataset = tf.contrib.data.CsvDataset(filenames, record_defaults, header=True, select_cols=[1,3]) print(dataset.</description>
    </item>
    
    <item>
      <title>Destributed TensorFlowの流れとSavedModelの出力</title>
      <link>https://www.sambaiz.net/article/179/</link>
      <pubDate>Wed, 25 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/179/</guid>
      <description>Distributed TensorFlow クラスタを組んでGraphを分散実行する。
クラスタは
 master: sessionを作成し、workerを制御する worker: 計算を行う ps(parameter server): 変数の値を持ち、更新する  のjobからなり、gRPCの
 Master Service Worker Service  でやり取りする。
TensorFlow serverを立てる 各jobとURLのmapをClusterSpecにして jobとindexと併せてServerDefを作って Serverを立てる。
{ &amp;#34;master&amp;#34;: [ &amp;#34;check-tf-config-master-34z8-0:2222&amp;#34; ], &amp;#34;ps&amp;#34;: [ &amp;#34;check-tf-config-ps-34z8-0:2222&amp;#34;, &amp;#34;check-tf-config-ps-34z8-1:2222&amp;#34; ], &amp;#34;worker&amp;#34;: [ &amp;#34;check-tf-config-worker-34z8-0:2222&amp;#34;, &amp;#34;check-tf-config-worker-34z8-1:2222&amp;#34; ] } cluster_spec_object = tf.train.ClusterSpec(cluster_spec) server_def = tf.train.ServerDef( cluster=cluster_spec_object.as_cluster_def(), protocol=&amp;#34;grpc&amp;#34;, job_name=job_name, # worker, master, ps  task_index=0) server = tf.train.Server(server_def) psのjobではserver.join()して待ち構える。
if job_name == &amp;#34;ps&amp;#34;: server.join() else: # build model WorkerにGraphを割り当てる workerのdeviceにGraphを割り当てる。 deviceは/job:worker/replica:0/task:0/device:GPU:0 のようなフォーマットで表される。</description>
    </item>
    
    <item>
      <title>TensorFlowのMonitoredSessionとSessionRunHookとsummaryのエラー</title>
      <link>https://www.sambaiz.net/article/175/</link>
      <pubDate>Sun, 01 Jul 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/175/</guid>
      <description>MonitoredSession
deprecatedになったSupervisorの後継。
MonitoredTrainingSessionで学習用のMonitoredSessionを生成する。 このコンストラクタの引数でcheckpoint_dirを渡すと内部でCheckpointSaverHookが 追加されるようになっていて、restoreしたり指定したタイミングでsaveしたりしてくれる。
なので今回明示的に渡すhooksは 指定したstepに到達したら止めてくれる、StopAtStepHookのみ。
should_stop()がTrueな状態でsession.run()しようとするとRun called even after should_stop requested.のエラーが出るため、 今回は新しいsessionを作ってAccuracyを返しているが、hookでやった方がrestoreする必要がないので良さそうだ。
Destributed TensorFlowの流れとSavedModelの出力 - sambaiz-net
全体のコードはここ。
def train(self, learning_rate, variable_default_stddev, bias_default, last_step=800): test_images = self.images[:500] test_labels = self.labels[:500] train_batch = Batch(self.images[500:], self.labels[500:]) with tf.Graph().as_default(): global_step=tf.train.get_or_create_global_step() g = MNIST_CNN(learning_rate, variable_default_stddev, bias_default).graph() saver = tf.train.Saver() savedir = &amp;#39;./ckpt-{}-{}-{}&amp;#39;.format(learning_rate, variable_default_stddev, bias_default) hooks = [ tf.train.StopAtStepHook(last_step=last_step) ] with tf.train.MonitoredTrainingSession( hooks=hooks, checkpoint_dir=savedir, save_checkpoint_secs = 300, ) as sess: sess.run(global_step) while not sess.should_stop(): # step = sess.</description>
    </item>
    
    <item>
      <title>TensorFlowのモデルをsave/loadする</title>
      <link>https://www.sambaiz.net/article/172/</link>
      <pubDate>Fri, 22 Jun 2018 01:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/172/</guid>
      <description>SavedModelBuilderで モデルを言語に依存しないSavedModelのprotobufにして保存できる。 SavedModelにはSaverによって出力されるCheckpointを共有する一つ以上のMetaGraphDefを含む。
import tensorflow as tf def build_signature(signature_inputs, signature_outputs): return tf.saved_model.signature_def_utils.build_signature_def( signature_inputs, signature_outputs, tf.saved_model.signature_constants.REGRESS_METHOD_NAME) def save(sess, export_dir, signature_def_map): builder = tf.saved_model.builder.SavedModelBuilder(export_dir) builder.add_meta_graph_and_variables( sess, [tf.saved_model.tag_constants.SERVING], signature_def_map=signature_def_map ) builder.save() import shutil import os.path export_dir = &amp;#34;./saved_model&amp;#34; if os.path.exists(export_dir): shutil.rmtree(export_dir) with tf.Graph().as_default(): a = tf.placeholder(tf.float32, name=&amp;#34;a&amp;#34;) b = tf.placeholder(tf.float32, name=&amp;#34;b&amp;#34;) c = tf.add(a, b, name=&amp;#34;c&amp;#34;) v = tf.placeholder(tf.float32, name=&amp;#34;v&amp;#34;) w = tf.Variable(0.0, name=&amp;#34;w&amp;#34;) x = w.assign(tf.add(v, w)) sv = tf.train.Supervisor() with sv.managed_session() as sess: print(sess.</description>
    </item>
    
    <item>
      <title>TensorFlow/RNNで連続的な値の時系列データを予測する</title>
      <link>https://www.sambaiz.net/article/154/</link>
      <pubDate>Sun, 11 Feb 2018 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/154/</guid>
      <description>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
チュートリアルで扱ったのは語彙数分の単語、つまり離散的な値だったが、今回は連続的な値を取る場合のモデルを作る。 全体のコードはここ。
入力 以下の関数によって生成した1次元のデータ列。 これをstrideした最後のデータ、つまり時系列的に次に来るものを予測させる。
def make_time_series_data(size): data = [] for i in range(size): data.append(sin(random.normalvariate(i,0.1)*0.1)) return np.reshape(np.array(data, dtype=np.float32), (size,1)) def make_batch(data, batch_size, num_steps, num_dimensions, name=None): epoch_size = data.size // (batch_size*num_steps*num_dimensions) data = np.lib.stride_tricks.as_strided( data, shape= (epoch_size, batch_size, num_steps+1, num_dimensions), strides=( 4*batch_size*num_steps*num_dimensions, 4*num_steps*num_dimensions, 4*num_dimensions, 4 # bytes ), writeable=False ) return data[:, :, :-1], data[:, :, 1:] モデル input layerでLSTMのhidden_sizeに合わせて、output layerで予測値を得ている。 lossはMSE(Mean squared error)。OptimizerはGradientDecentOptimizerを使っている。
チュートリアルでは自力で各time_stepの値を入れていたけど、 今回はdynamic_rnn()に任せている。
class Model(object): def __init__(self, config, is_training=False): # config self.</description>
    </item>
    
    <item>
      <title>TensorBoardでsummaryやグラフを見る</title>
      <link>https://www.sambaiz.net/article/147/</link>
      <pubDate>Sun, 07 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/147/</guid>
      <description>TensorflowのRNN(LSTM)のチュートリアルのコードを読む - sambaiz-net
で読んだコードをTensorboardでみてみる。
8888がJupyter、6006がTensorboard。
$ docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow コードをuploadするかJupyterからterminalを開いてcloneしてくる。
# apt-get update # apt-get install -y git wget # git clone https://github.com/tensorflow/models.git # cd models/tutorials/rnn/ptb &amp;amp;&amp;amp; wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz &amp;amp;&amp;amp; tar xvf simple-examples.tgz logdirを指定して実行し、Tensorboardを起動。
flags.DEFINE_string(&amp;#34;save_path&amp;#34;, &amp;#34;.&amp;#34;, &amp;#34;Model output directory.&amp;#34;) sv = tf.train.Supervisor(logdir=FLAGS.save_path)  追記(2018-11-14): Supervisorはdeprecatedなので以下の記事でやっているようにMonitoredTrainingSessionを使うとよい。
Deep LearningのBatch Normalizationの効果をTensorFlowで確認する - sambaiz-net
 # tensorboard --logdir=models/tutorials/rnn/ptb tf.summary.scalar(&amp;quot;Training Loss&amp;quot;, m.cost)による値がリアルタイムに表示される。
グラフのつながりや、各Operationの入出力やそのshapeを確認できる。 name_scopeで分けておくと見やすい。</description>
    </item>
    
    <item>
      <title>TensorFlowのRNN(LSTM)のチュートリアルのコードを読む</title>
      <link>https://www.sambaiz.net/article/146/</link>
      <pubDate>Wed, 03 Jan 2018 21:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/146/</guid>
      <description>TensorflowのRNN(Recurrent Neural Networks)のチュートリアルのコードを読む。これは文章のそれまでの単語の履歴から、その次に続く単語を予測することで言語モデルを作るもの。
RNN/LSTMとは RNNは入力に対して出力のほかに情報を次のステップに渡すことで時系列データで学習できるようにするネットワーク。 展開すると同じネットワークに単語を一つずつ入れていくように表現できる。
これを単純にMLPで実装しようとすると逆誤差伝搬する際に過去の層にも伝搬させる(BPTT: Backpropagation through time)必要があり、 時間を遡るほど活性化関数の微分係数が再帰的に繰り返し掛けられるため勾配が消失や爆発しやすくなってしまう。 また、時系列データのうちに発火したいものと発火したくないものが混在している場合、同じ重みにつながっているため更新を打ち消しあってしまう入力/出力重み衝突という問題もある。
これらを解決するのがLSTM(Long Short Term Memory networks)で、 勾配消失は活性化関数がxで重みが単位行列のニューロンのCEC(Constant Error Carousel)によって常に誤差に掛けられる係数を1にすることで防ぎ、 入力/出力重み衝突は必要な入出力を通したり不必要な情報は忘れさせるために値域(0,1)の値を掛けるinput gate、forget gate、output gateによって回避する。gateは入力と前回の出力によって制御される。
TensorflowではいくつかLSTMの実装が用意されていて、CudnnLSTMやBasicLSTMCell、LSTMBlockCellなどがある。 cuDNNというのはNVIDIAのCUDAのDNNライブラリのこと。 LSTMBlockCellはもう少し複雑なLSTMでBasicLSTMCellよりも速い。
動かしてみる $ git clone https://github.com/tensorflow/models.git $ cd models/tutorials/rnn/ptb/ $ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz $ tar xvf simple-examples.tgz $ python3 -m venv env $ . ./env/bin/activate $ pip install numpy tensorflow $ python ptb_word_lm.py --data_path=simple-examples/data/ --num_gpus=0 Epoch: 1 Learning rate: 1.000 0.004 perplexity: 5534.452 speed: 894 wps 0.</description>
    </item>
    
    <item>
      <title>ニューラルネットワークと活性化関数</title>
      <link>https://www.sambaiz.net/article/133/</link>
      <pubDate>Mon, 18 Sep 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/133/</guid>
      <description>活性化関数というのは各層での重み掛けバイアス足しのあとに適用する非線形の関数。 これはカーネル法のように空間を変換して線形分離できないデータを線形分離できるようにするはたらきをする。 線形な関数を使うと層を重ねても結局線形のままで、空間もそのまま伸縮するだけなので目的を果たさない。
バックプロバゲーション(誤差逆伝播法)するために微分できる必要がある。
MLPと誤差逆伝搬法(Backpropagation) - sambaiz-net
Tensorflowでは以下の活性化関数が用意されている。
sigmoid 値域は(0,1)でシグマの語末系ςに似たS字を描く。 微分係数がそれほど大きくないので何層もこの関数を適用すると、バックプロバゲーションで微分係数を掛けていった結果、勾配が消失する問題がありあまり使われない。値域が(-1,1)で似たグラフを描くtanh(Hyperbolic tangent)もある。
softsign tanhと比べて漸近線に近づく速度が遅くなっている。 それほど性能は変わらないが、初期化においてロバストになるはたらきがあるようだ。
softplus ReLUに続く。
ReLU(Rectified Linear Unit) 単純だけど最有力。勾配消失も起きにくい。x=0で微分できないが0か1として扱われる。
def deriv_relu(x): return np.where(x &amp;gt; 0, 1, 0) softplusと比べてexpやlogを含まない分高速に計算できるので、 膨大で複雑なデータセットに対して多くの層を用いることができる。
0以下は等しく0になるため、学習中に落ちてしまうとニューロンが死んでしまう。 これを避けるため0以下のときy = exp(x) - 1にするELU(Exponential Linear Unit) というのもある。
比較的起きにくいとはいえ、層を深くすると勾配消失する可能性は高まる。 活性化関数ごとに異なる重みの初期値によってこれを緩和でき、ReLUでは入力次元数によるHe Initializationというのが提案されている。
rng = np.random.RandomState(1234) n_in = 10 # 入力次元数 rng.uniform( low=-np.sqrt(6/n_in), high=+np.sqrt(6/n_in), size=5 ) # He Initialization 参考 Activation functions and it’s types-Which is better?
最適化から見たディープラーニングの考え方
Understanding the difficulty of training deep feedforward neural networks</description>
    </item>
    
    <item>
      <title>DeepMindのTensorFlowライブラリSonnetを使う</title>
      <link>https://www.sambaiz.net/article/124/</link>
      <pubDate>Sun, 06 Aug 2017 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/124/</guid>
      <description>AlphaGoを開発したGoogle DeepMind社のTensorFlowライブラリSonnetを使う。 当初はPython2しか対応していないようだったけど、今は3にも対応している。
準備 TensorFlowを使うライブラリはほかにもいくつかあるのだけど、 Kerasと比較してみると、 KerasがTensorFlowの部分を完全にラップしているのに対して、 Sonnetは必要に応じてTensorFlowの関数も呼ぶ、比較的抽象度が低いライブラリのようだ。
SonnetとTensorFlowとPython3入りイメージをDockerHubに上げた。 Dockerfileはここ。
内容は基本的にREADME通りだけど、 configureのところで対話的に聞かれないように前もって環境変数で設定を与えている。 あとは、TensorFlowのビルドに使われているGCCのバージョンが古いようで、sonnetをimportするときに以下のエラーが出たため、bazelのオプションに--copt=&amp;quot;-D_GLIBCXX_USE_CXX11_ABI=0&amp;quot;を付けている。
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.5/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_S3_ 起動。
$ docker run -itd --name sonnet -p 6006:6006 -p 8888:8888 sambaiz/sonnet $ docker logs sonnet ... Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=***** Jupyter Notebookを開いてSonnetとTensorFlowがimportできることを確認する。
import sonnet as snt import tensorflow as tf snt.resampler(tf.constant([0.]), tf.constant([0.])) # =&amp;gt; &amp;lt;tf.Tensor &amp;#39;resampler/Resampler:0&amp;#39; shape=(1,) dtype=float32&amp;gt; MNIST TensorFlowのチュートリアルのデータを使って、畳み込みを行わない簡単なMNISTをやってみる。 このデータはtrain、validation、test用に最初から分かれていて、 それぞれピクセル濃度配列の画像データと、その画像がどの数字なのかを表すone-hot vectorのラベルを含んでいる。</description>
    </item>
    
    <item>
      <title>DeepDreaming with TensorFlowをやる(2)</title>
      <link>https://www.sambaiz.net/article/21/</link>
      <pubDate>Sat, 10 Sep 2016 14:46:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/21/</guid>
      <description>前回の続き。
Multiscale image generation 様々なスケールで勾配上昇させる。小さなスケールで上昇させたものをより大きなスケールでさらに上昇させていく。 ただ、壁紙のようなサイズを生成するような場合にそれを行うと、GPUのメモリを食いつぶしてしまう。 これを避けるために、画像を小さなタイルに分割し、それぞれ独立に勾配を計算する。 また、毎回画像をランダムにシフトしていくことで、タイルに見えることを避け、画像全体の品質を向上させる。
def tffunc(*argtypes): &amp;#39;&amp;#39;&amp;#39;Helper that transforms TF-graph generating function into a regular one. See &amp;#34;resize&amp;#34; function below. &amp;#39;&amp;#39;&amp;#39; placeholders = list(map(tf.placeholder, argtypes)) def wrap(f): out = f(*placeholders) def wrapper(*args, **kw): return out.eval(dict(zip(placeholders, args)), session=kw.get(&amp;#39;session&amp;#39;)) return wrapper return wrap # Helper function that uses TF to resize an image def resize(img, size): img = tf.expand_dims(img, 0) return tf.image.resize_bilinear(img, size)[0,:,:,:] resize = tffunc(np.float32, np.int32)(resize) def calc_grad_tiled(img, t_grad, tile_size=512): &amp;#39;&amp;#39;&amp;#39;Compute the value of tensor t_grad over the image in a tiled way.</description>
    </item>
    
    <item>
      <title>DeepDreaming with Tensorflowをやる(1)</title>
      <link>https://www.sambaiz.net/article/20/</link>
      <pubDate>Wed, 07 Sep 2016 01:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/20/</guid>
      <description>https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb
例の通りまとめながら進めていく。
 このノートブックは、畳み込みニューラルネットワークによる画像生成の手法を説明するものだ。 ネットワークは入力画像へ変換させる配列のレイヤーの集合から成り立っている。 変換のパラメータは勾配降下法で変形しながら学習していく。 内部的な画像の表現は意味不明なように見えるが、可視化し、解釈することができる。
Loading and displaying the model graph 学習済みネットワークのprotobufファイルが用意されていて、これをダウンロードして使う。 ただgcr.io/tensorflow/tensorflowにwgetもunzipも入っていなかったので、中に入ってapt-getした。
model_fn = &amp;#39;tensorflow_inception_graph.pb&amp;#39; # creating TensorFlow session and loading the model graph = tf.Graph() sess = tf.InteractiveSession(graph=graph) with tf.gfile.FastGFile(model_fn, &amp;#39;rb&amp;#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) t_input = tf.placeholder(np.float32, name=&amp;#39;input&amp;#39;) # define the input tensor imagenet_mean = 117.0 t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0) tf.import_graph_def(graph_def, {&amp;#39;input&amp;#39;:t_preprocessed}) tf.gfile.FastGFileのドキュメントが見つからないので ソース を探したところFile I/Oのラッパーのようだ。これでprotobufファイルを読み、ParseFromStringでGraphDefにする。
さらにこれと入力データをtf.import_graph_defに 渡すことでGraphに取り込む。
tf.expand_dimsは値が1の次元を指定の場所に挿入する もの。なんでそんなことをしたり、imagenet_meanを引いているのかは説明がなかった。
layers = [op.name for op in graph.</description>
    </item>
    
    <item>
      <title>Tensorflowの学習データを使ったAPIを作る</title>
      <link>https://www.sambaiz.net/article/13/</link>
      <pubDate>Fri, 05 Aug 2016 22:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/13/</guid>
      <description>チュートリアルのMNISTの学習データを使って、手書き数字画像のデータを受け取り、数字を返すAPIを作る。 コードはここにある。
学習して結果を保存する 前回の学習結果のcheckpointファイルを出力する。 tf.train.Saver().saveでnameで対応するVariableの値が保存できる。 また、その際デフォルトでMetaGraphもexportされ、これをimportすればGraphも復元することができる。
import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data class Mnist: def __init__(self): g = tf.Graph() with g.as_default(): W_conv1 = self._weight_variable([5, 5, 1, 32], &amp;#34;W_conv1&amp;#34;) b_conv1 = self._bias_variable([32], &amp;#34;b_conv1&amp;#34;) self._x = tf.placeholder(tf.float32, [None, 784]) x_image = tf.reshape(self._x, [-1,28,28,1]) h_conv1 = tf.nn.relu(self._conv2d(x_image, W_conv1) + b_conv1) h_pool1 = self._max_pool_2x2(h_conv1) W_conv2 = self._weight_variable([5, 5, 32, 64], &amp;#34;W_conv2&amp;#34;) b_conv2 = self._bias_variable([64], &amp;#34;b_conv2&amp;#34;) h_conv2 = tf.nn.relu(self._conv2d(h_pool1, W_conv2) + b_conv2) h_pool2 = self.</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアル2(Deep MNIST for Experts)</title>
      <link>https://www.sambaiz.net/article/6/</link>
      <pubDate>Tue, 12 Jul 2016 21:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/6/</guid>
      <description>前回に引き続き、まとめながら進めていく。
Deep MNIST for Experts
Start TensorFlow InteractiveSession 今回は、前回のようにグラフを作成してからSessionを開始する代わりに InteractiveSessionを使う。 グラフを作成し実行するのをインタラクティブに行うことができ、IPythonのような環境で便利だ。
import tensorflow as tf sess = tf.InteractiveSession() Build a Multilayer Convolutional Network 前回のシンプルなモデルではあまり良い結果が出なかった。 そこで、今回はもう少し良いモデルの畳み込みニューラルネットワークを作成する。
Weight Initialization 勾配が0になるのを避けるために重みの初期化時にノイズを付ける。 tf.truncated_normalは正規分布で、μ±2σ範囲内のランダムな値を返す。 以下の例だと、meanのデフォルトが0.0なので、正規分布 N(0, 0.01)の、-0.2&amp;lt;=x&amp;lt;=0.2な値がランダムに返ることになる。
また、ReLU(Rectified Linear Unit, 正規化線形関数)ニューロンを使うので、&amp;ldquo;死んだニューロン&amp;quot;を避けるために、バイアスは小さな正の値で初期化する。
ニューラルネットワークと活性化関数 - sambaiz-net
def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) Convolution and Pooling TensorFlowに畳み込みとプーリングの関数が用意されている。
畳み込みというのは、画像に対してフィルターを少しずつ動かしながら掛けていく処理のこと。このページが分かりやすい。 例えば、ソーベルフィルタで輪郭になっているところを抽出するように、 フィルターの値によって、その区域における、ある特徴を際立たせたりすることができる。 今回はこのフィルターが重みとなり、際立たせたいのはその数字を識別するための特徴ということになる。 前回は画像を一次元の配列として扱い重みを学習していたので、縦の情報が失われていたが、この方法ではそれがない。
プーリングというのは画像から区域ごとにサンプリングする処理のこと。最大プーリングや、平均プーリングなどの手法がある。 畳み込みのように順番に区域を見ていって、最大プーリングならそのうちの最大のものを採用し、他のものは無視する。 サイズが小さくなるだけではなく、ちょっとした位置のずれを吸収することができる。
def conv2d(x, W): return tf.</description>
    </item>
    
    <item>
      <title>TensorFlow チュートリアルまで</title>
      <link>https://www.sambaiz.net/article/3/</link>
      <pubDate>Sun, 03 Jul 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/3/</guid>
      <description>Googleが公開した人工知能ライブラリTensorFlowを使ってみる。 セットアップ方法はいくつか提供されているが、Dockerで動かすことにした。 Jupyter Notebookが立ち上がるのですぐに試せて良い。
$ docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow http://localhost:8888/tree
公式のチュートリアルをまとめながら進めてみる。
MNIST For ML Beginners
The MNIST Data MNISTというのは0~9の書き数字の画像のデータセットのことで、これらを正しく分類するのが目的。
それぞれの画像は一律28*28=784ピクセルで、それぞれのピクセルは0と1の間の数値(強さ)で表されている。 今回はこれの縦横を取っ払って784次元のベクトルとして扱っている。
したがって、学習用の画像データは[55000, 784]のtensor(n次元の配列)で表される。 55000というのが画像の数で、784というのがそれぞれの画像の次元を意味している。
それぞれの画像に対応した数字のラベルは[55000, 10]で表される。 10というのは、0~9それぞれに対応した次元のうち、一つだけ1で、それ以外が0という風に使われる。これをone-hot vectorという。
Softmax Regressions Softmaxはいくつかの異なるもの(今回でいうと数字)に確率を割り当てる。
画像が特定のクラス(0~9)に属するかどうか計算するために、ピクセルの強さに重みを付けた合計を計算する。 もし、そのピクセルがそのクラスに属さない根拠になるなら負の重みがかかり、属する根拠になるなら、正の重みがかかるようにする。 また合計にさらに入力と無関係なクラスごとに異なるバイアスを足す。
全てのクラスで計算した値をsoftmax関数に入れ、それぞれ確率に変換する。この確率の和は1になるようになっている。
Implementing the Regression Pythonでは行列の積のような重い処理をするとき、NumPyのようなライブラリを使ってPythonの外で行うが、 外からPythonに戻るときにオーバーヘッドが発生してしまう。 TensorFlowでも重い処理を外で行うが、オーバーヘッドを避けるために、 単体の重い処理をPythonから独立して実行するのではなく、Pythonの外側で実行される関連した処理のグラフを記述させる。
import tensorflow as tf x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b) tf.placeholderは実行時に与えられる値で、今回が画像データ。 W(重み)とb(バイアス)は学習する変数。 tf.matmul(x, W) + bの部分が重みを付けた合計にバイアスを足したものに対応している。 matmulはmatrix multiple、つまり行列の積。</description>
    </item>
    
  </channel>
</rss>
