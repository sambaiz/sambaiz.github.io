<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lambda on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/lambda/</link>
    <description>Recent content in Lambda on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 07 Jul 2019 17:10:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/lambda/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cognito UserPoolのPreSignUpで呼ばれるLambdaで登録ユーザーを制限する</title>
      <link>https://www.sambaiz.net/article/228/</link>
      <pubDate>Sun, 07 Jul 2019 17:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/228/</guid>
      <description>サードパーティのIdPからCognitoにSignUpできるようにする場合、特定のドメインのメールアドレスといったような制限をかけたいことがある。 これをPreSignUp時にチェックすることでUserPoolに入らないようにすることができる。
Lambda CognitoEventUserPoolsPreSignupを受け取って返す。
package main import ( &amp;quot;errors&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;github.com/aws/aws-lambda-go/events&amp;quot; &amp;quot;github.com/aws/aws-lambda-go/lambda&amp;quot; ) func handler(event events.CognitoEventUserPoolsPreSignup) (events.CognitoEventUserPoolsPreSignup, error) { fmt.Printf(&amp;quot;PreSignup of user: %s\n&amp;quot;, event.UserName) if event.Request.UserAttributes[&amp;quot;email&amp;quot;] != &amp;quot;godgourd@gmail.com&amp;quot; { return event, errors.New(&amp;quot;Forbidden&amp;quot;) } return event, nil } func main() { lambda.Start(handler) }  リソース UserPoolのLambdaConfigでトリガーを設定できる。 CognitoからLambdaを呼べるPermissionが必要。
UserPool: Type: AWS::Cognito::UserPool Properties: ... LambdaConfig: PreSignUp: !GetAtt PresignupLambdaFunction.Arn UserPoolLambdaInvokePermission: Type: AWS::Lambda::Permission Properties: Action: lambda:invokeFunction Principal: cognito-idp.amazonaws.com FunctionName: !GetAtt PresignupLambdaFunction.Arn SourceArn: arn:aws:cognito-idp:&amp;lt;region&amp;gt;:&amp;lt;account_id&amp;gt;:userpool/*  なおALBのActionでCognito認証を入れると登録失敗時に500エラーになってしまう。これを回避するには自前でやるしかないのかもしれない。</description>
    </item>
    
    <item>
      <title>LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす</title>
      <link>https://www.sambaiz.net/article/227/</link>
      <pubDate>Wed, 03 Jul 2019 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/227/</guid>
      <description>ALBのTargetとしてLambdaが選択できるようになり、 若干の時間課金が発生する代わりに柔軟にルーティングできるAPI Gatewayのように使えるようになった。 ActionとしてCognito認証を入れて認証に失敗したらログイン画面を表示させる。
API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く - sambaiz-net
ACMで証明書を発行する HTTPSでListenするため証明書が必要。 AWS Certificate Manager (ACM)でAWSで使える証明書を無料で発行でき参照できる。 外部で取ったドメインでもよい。 検証方法はDNSとメールとで選ぶことができて、DNSで行う場合Route53ならワンクリックで検証用のCNAMEレコードを作成できる。 検証までやや時間がかかるのでちゃんと通ってるかnslookupで確認しといた方がよい。
Application Load Balancer (ALB) 次の要素から構成されるL7のロードバランサー。
 Listener: 指定したプロトコルとポートでリクエストを受ける。 ListenerRule: パスやHeaderなどの値を条件にどのTargetGroupにルーティングするかのルール。
 TargetGroup: ルーティングする1つ以上のTarget。Instance, IP, Lambdaが選べる。  Ruleの作成 Serverless FrameworkではALBのenentを付けるだけでLambdaに向くRuleが作成されるが、そこにはCognitoを追加できなさそうなので使っていない。OnUnauthenticatedRequestで認証失敗時の挙動を選択できる。UserPoolとSecretありのClientはあらかじめ作っておく。コールバックURLにはhttps://&amp;lt;domain&amp;gt;/oauth2/idpresponseを追加する。
API Gatewayだとタイムアウトの上限が30秒なのに対してALBはLambdaの上限まで待てる。
$ cat serverless.yml service: alb-cognito-auth-example frameworkVersion: &amp;quot;&amp;gt;=1.28.0 &amp;lt;2.0.0&amp;quot; provider: name: aws runtime: go1.x region: ap-northeast-1 package: exclude: - ./** include: - ./bin/** functions: privateapi: handler: bin/privateapi timeout: 30 resources: Resources: ALBTargetGroup: DependsOn: InvokeLambdaPermissionForALB Type: AWS::ElasticLoadBalancingV2::TargetGroup Properties: Name: &amp;quot;private-lambda-target-group&amp;quot; TargetType: &amp;quot;lambda&amp;quot; Targets: - Id: !</description>
    </item>
    
    <item>
      <title>API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く</title>
      <link>https://www.sambaiz.net/article/226/</link>
      <pubDate>Wed, 03 Jul 2019 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/226/</guid>
      <description>ブラウザから直接API GatewayのエンドポイントにアクセスしたときにCognitoのTokenで認証し、失敗したらログイン画面を表示させる。 API GatewayでCognitoの認証をかける場合、AuthorizerでUserPoolを指定するのが最も簡単なパターンだが、 これだとHeaderにTokenを付けてアクセスする必要があり認証に失敗するとUnauthorizedが返る。
Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる - sambaiz-net
なおAPI GatewayではなくALBをLambdaの前段に挟めば今回やることが簡単に実現できる。
LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net
準備 UserPoolとClientを作成する。 CloudFormationで作成する場合SchemaのMutableのデフォルトがfalseなのに注意。変えると作り直される。
Resources: Userpool: Type: AWS::Cognito::UserPool Properties: AdminCreateUserConfig: AllowAdminCreateUserOnly: false Schema: - Mutable: true Name: email Required: true - Mutable: true Name: name Required: true UsernameAttributes: - email UserPoolName: testpool UserpoolClient: Type: AWS::Cognito::UserPoolClient Properties: UserPoolId: Ref: Userpool ClientName: testclient GenerateSecret: true  今回はフェデレーションでGoogleアカウントでログインできるようにする。 ややこしい用語であるがID Poolのフェデレーティッドアイデンティティとは異なる。
UserPoolのドメインや、GoogleのOAuth Client IDの発行とAttributes Mapping、Clientの設定はCloudFormationでできないので手でやる。 Attributes Mappingで変えられるがusernameは変更不可な値なのでsubのままにしておく。
設定が終わったら https://&amp;lt;user-pool-domain&amp;gt;/login?client_id=&amp;lt;client-id&amp;gt;&amp;amp;redirect_uri=&amp;lt;redirect-uri&amp;gt;&amp;amp;response_type=code にアクセスし、&amp;lt;redirect-uri&amp;gt;?</description>
    </item>
    
    <item>
      <title>DatadogのAWS integrationとAlertの設定をTerraformで行う</title>
      <link>https://www.sambaiz.net/article/219/</link>
      <pubDate>Sat, 04 May 2019 19:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/219/</guid>
      <description>DatadogのAWS integrationとAlertの設定をTerraformで行い、バージョン管理やレビューできるようにする。 全体のコードはGitHubに置いてある。
AWS Integration まずdatadog_integration_awsでAWS integrationの設定を作成してExternalIDを取得し、Policy/Roleを作成する。必要な権限はドキュメントを参照。
resource &amp;quot;datadog_integration_aws&amp;quot; &amp;quot;test&amp;quot; { account_id = &amp;quot;${var.aws_account_id}&amp;quot; role_name = &amp;quot;${var.aws_integration_role_name}&amp;quot; filter_tags = [&amp;quot;datadog:1&amp;quot;] } data &amp;quot;aws_iam_policy_document&amp;quot; &amp;quot;datadog_aws_integration_assume_role&amp;quot; { statement { actions = [&amp;quot;sts:AssumeRole&amp;quot;] principals { type = &amp;quot;AWS&amp;quot; identifiers = [&amp;quot;arn:aws:iam::464622532012:root&amp;quot;] } condition { test = &amp;quot;StringEquals&amp;quot; variable = &amp;quot;sts:ExternalId&amp;quot; values = [ &amp;quot;${datadog_integration_aws.test.external_id}&amp;quot;, ] } } }  Datadog providerにはないSlackなどその他のintegrationは手動で設定する必要がある。 また、Logも集める場合Serverless Application Repositoryから公式のDatadog-Log-Forwarderを入れて AWS IntegrationのところにLambdaのARNを入れるのも手動。
Alert datadog_monitorでAlertを作成する。 今回はLambdaの実行が失敗したときと、WARNという文字列が含まれるログが一定数出力されたときにAlertを飛ばすようにしてみた。 なおinfoやwarnといったログレベルはjsonのlevelフィールドに入れればデフォルトのpipelineでマップされるので通常は文字列比較などする必要はない。
初めに作るときは一度画面で意図通りアラートが飛ぶものを作成し、クエリなどをコピーするのが確実。
resource &amp;quot;datadog_monitor&amp;quot; &amp;quot;lambda-error-alert&amp;quot; { name = &amp;quot;lambda-error-alert&amp;quot; type = &amp;quot;metric alert&amp;quot; message = &amp;quot;Error occurred.</description>
    </item>
    
    <item>
      <title>AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する</title>
      <link>https://www.sambaiz.net/article/207/</link>
      <pubDate>Sun, 10 Feb 2019 16:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/207/</guid>
      <description>AWS SAM (Serverless Application Model)はAWS公式の サーバーレスアプリケーションのビルドツール。 CloudFormationのテンプレートを設定ファイルに書くことでLambda関数と共にイベントトリガーや他のリソースも含めてデプロイでき、 その点でServerless Frameworkと立ち位置が近いが、向こうがLambda以外のサーバーレス環境にも対応していたり、 プラグインによって機能拡張できるようになっている一方、こちらは比較的薄いツールになっている。 ただ、Serverless Application Repositoryで公開するにはSAMの形式にする必要があり、 Serverless FrameworkにもSAMのテンプレートを出力するプラグインがある。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
SAM CLIのインストール $ brew tap aws/tap $ brew install aws-sam-cli $ sam --version SAM CLI, version 0.11.0  init initすると次の構成のディレクトリが作られる。
$ sam init --runtime go1.x -n test-sam $ cd test-sam/ $ ls Makefile	README.md	hello-world	template.yaml  template.yamlの中に関数の設定やCloudFormationのテンプレートを書く。
$ cat template.yaml AWSTemplateFormatVersion: &#39;2010-09-09&#39; Transform: AWS::Serverless-2016-10-31 Description: &amp;gt; test-sam Sample SAM Template for test-sam # More info about Globals: https://github.</description>
    </item>
    
    <item>
      <title>CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う</title>
      <link>https://www.sambaiz.net/article/206/</link>
      <pubDate>Sun, 03 Feb 2019 17:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/206/</guid>
      <description>Aurora ServerlessはオートスケールするAuroraで、 使ったAurora Capacity Unit (ACU)によって料金が発生するため、 使用頻度が少なかったり変動するアプリケーションにおいて安くRDBを使うことができる。 インスタンスを立てると最低でも月3000円くらいかかるが、Serverlessだとほとんどストレージ分から運用することができて趣味でも使いやすい。 ただしLambdaと同様に常に同等のリソースを使っている状態だとインスタンスと比べて割高になる。
今回はLambdaで使う。 Serverlessと名前には付いているが用途としてはLambdaに限らず、 むしろコンテナの数が容易に増え得るLambdaは同時接続数が問題になるRDBと一般に相性が良くない。 現在Betaの、コネクションを張らずにHTTPSでクエリを投げられるData APIはこの問題を解消すると思われるが、トランザクションが張れなかったり、レスポンスサイズに制限があるようだ。今回はコンソール上から初期クエリを流すためにData APIを有効にしている。
他の選択肢として、DynamoDBは現状最有力で最近トランザクションもサポートされたがSQLのように複雑なクエリは投げられない。 Athenaはクエリは投げられるがそこそこ時間がかかるし、INSERT/UPDATEはできずクエリごとに料金が発生する。
Serverless Frameworkを使ってリソースを作成しデプロイする。リポジトリはここ。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
VPCの作成 Aurora Serverlessの制限の一つとしてVPC内からしか接続しかできないというものがある。ということでVPCから作成していく。以前Terraformで作ったのと同じリソースをCloudFormationで作る。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
LambdaをVPC内で動かすとコンテナ起動時にENIも作成するため立ち上がりの際時間がかかる。必要なら定期的に呼び出して削除されないようにする。 また、今回はテストのため/24でVPCを切っているが、小さいとENIのIPアドレスが枯渇する可能性がある。
 VPC  TestVPC: Type: AWS::EC2::VPC Properties: CidrBlock: 172.32.0.0/24 Tags: - Key: Name Value: test-vpc   Subnet  Aurora Serverlessのために少なくとも2つのサブネットが必要。
TestPublicSubnet: Type: AWS::EC2::Subnet Properties: VpcId: !Ref TestVPC CidrBlock: 172.32.0.0/25 AvailabilityZone: us-east-1d Tags: - Key: Name Value: test-public-subnet1 TestPrivateSubnet1: Type: AWS::EC2::Subnet Properties: VpcId: !</description>
    </item>
    
    <item>
      <title>AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する</title>
      <link>https://www.sambaiz.net/article/204/</link>
      <pubDate>Mon, 07 Jan 2019 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/204/</guid>
      <description>DBのパスワードやAPIトークンといった認証情報をバージョン管理するコードや設定ファイル上に書くとOSS化など公開範囲を広げるときにやや困るし漏れるリスクが高まるのでなるべく避けたい。 そこでSSMのParameter Storeに値を置き、実行時やデプロイ時に参照する。
SSMのParameter StoreとSecrets Manager Systems Manager (SSM)はAWSのリソースを可視化したり操作を自動化したりするサービス群で、 設定を持つParameter Storeはその一つ。値は暗号化して持つこともできる。 料金はかからない。
SSMのParameter Storeと似たような別のAWSのサービスに Secrets Managerというのがあって、RDSなどと連携してLambdaによって定期的に新しい値を生成しローテーションさせることができる。 ただし料金がシークレットの件数($0.4/月)とAPIコール($0.05/10000回)でかかる。
CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net
今はParamter StoreとSecrets Managerが統合されていて、Parameter StoreのAPIでどちらも参照できるようだ。 今回はローテーションしないので単純に料金がかからないParameter Storeの方に書き込むことにする。 ただし、Parameter Storeは現状一度に大量のリクエストが飛ぶような使い方をするとRate exceededになってしまう問題がある。
実行時の値取得 実行時に値を取得するのはこんな感じ。
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws/awserr&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/aws/session&amp;quot; &amp;quot;github.com/aws/aws-sdk-go/service/ssm&amp;quot; ) type Parameter struct { ssm *ssm.SSM } func newParameter(sess *session.Session) *Parameter { return &amp;amp;Parameter{ ssm: ssm.New(sess), } } func (s *Parameter) Get(name string, decrypt bool) (string, error) { param, err := s.</description>
    </item>
    
    <item>
      <title>Serverless FrameworkでLambdaをデプロイする</title>
      <link>https://www.sambaiz.net/article/155/</link>
      <pubDate>Sun, 11 Feb 2018 23:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/155/</guid>
      <description>Serverless FrameworkでLambda Functionをデプロイする。 Apexが基本的にFunction自体のデプロイしかしないのに対して、こちらはeventの設定なども諸々やってくれて強い。
ApexでLambdaをデプロイする - sambaiz-net
$ npm install -g serverless $ serverless version 1.26.0  ApexではFunctionごとにディレクトリが作られたが、ServerlessではServiceごとに作られ、 一つのService内で複数のFunctionを定義できる。handlerは同じでも異なっていてもよい。
Apexの形式の場合、共通の処理をWebpackなどで各Functionに持って来たり、 同じような処理の複数のFunctionを立てる際はコピーする必要があったが、 こちらは必要最小限の変更でそれらを行うことができる。
templateからServiceをcreateする。
$ serverless create --template aws-nodejs --path testservice $ ls testservice/ handler.js	serverless.yml  設定ファイルserverless.yml にはLambdaの基本的なもののほかに、VPCやevent、IAM Roleなども書けて、これらはdeploy時に作られるCloudFormationのstackによって管理される。必要なら生のCloudFormationの設定も書ける。
ApexでもTerraformによって管理することができるが、書くのはこちらの方がはるかに楽。
ApexでデプロイしたLambdaのトリガーをTerraformで管理する - sambaiz-net
$ cat sesrverless.yml service: testservice provider: name: aws profile: foobar region: ap-northeast-1 runtime: nodejs6.10 memorySize: 512 timeout: 10 functions: hello: handler: handler.hello events: - http: path: hello/world method: get cors: true  deployすると{service}-{stage}-{function}のFunctionが作られる。 今回の場合はtestservice-prd-test。stageをymlでも指定しなかった場合はデフォルト値のdevになる。</description>
    </item>
    
    <item>
      <title>DatadogのLambda Integrationで気象データを送ってアラートを飛ばす</title>
      <link>https://www.sambaiz.net/article/152/</link>
      <pubDate>Mon, 05 Feb 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/152/</guid>
      <description>最近朝が寒くて布団から出るのがつらい。雨や雪が降っていたら尚更のこと、それならそれで現状を把握する必要がある。 そこで、無料から使える気象API OpenWeatherMapのデータをdatadogに送って、特に寒い日や雨雪が降るような朝にはアラートを飛ばすことにした。
インスタンスが立っていたらDataDog AgentのDogStatsD経由で送ることができ、 そうでなければ通常はAPIを呼ぶことになるんだけど、Lambdaでは、AWS Integrationを設定すると有効になるLambda Integrationによって MONITORING|unix_epoch_timestamp|value|metric_type|my.metric.name|#tag1:value,tag2のフォーマットでconsole.logするだけでメトリクスが送られるようになっている。
const axios = require(&#39;axios&#39;); const CITY = &#39;Shibuya&#39;; const API_KEY = &#39;*****&#39;; const WEATHER_API = `http://api.openweathermap.org/data/2.5/weather?q=${CITY}&amp;amp;units=metric&amp;amp;appid=${API_KEY}`; const METRIC_COUNTER = &#39;counter&#39;; const METRIC_GAUGE = &#39;gauge&#39;; const monitor = (metricName, metricType, value, tags) =&amp;gt; { const unixEpochTimestamp = Math.floor(new Date().getTime()); console.log(`MONITORING|${unixEpochTimestamp}|${value}|${metricType}|${metricName}|#${tags.join(&#39;,&#39;)}`); }; exports.handler = async (event, context, callback) =&amp;gt; { const data = (await axios.get(WEATHER_API)).data const namePrefix = &#39;livinginfo.weather&#39; monitor(`${namePrefix}.temperature`, METRIC_GAUGE, data.main.temp, []) monitor(`${namePrefix}.</description>
    </item>
    
    <item>
      <title>ApexでデプロイしたLambdaのトリガーをTerraformで管理する</title>
      <link>https://www.sambaiz.net/article/144/</link>
      <pubDate>Sun, 12 Nov 2017 22:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/144/</guid>
      <description>Apexでfunctionをデプロイするとトリガーが登録されないのであとで追加することになる。 これを手作業で行うこともできるのだけど、せっかくなのでアプリケーションと一緒に管理したい。 そんなときのためにterraformコマンドをラップしたapex infraが用意されている。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
functionsと同列にinfrastructureディレクトリを作成してtfファイルを置く。 その下に環境ごとのディレクトリを作成することもできて、その場合は--envで指定した環境のものが使われる。
- functions - infrastructure main.tf variables.tf - modules - cloudwatch_schedule main.tf variables.tf project.json  functionをデプロイするとそのARNが変数で取れるようになる。
$ apex list --tfvars apex_function_hello=&amp;quot;arn:aws:lambda:ap-northeast-1:*****:function:usetf_hello&amp;quot;  今回設定するトリガーはCloudwatch Eventのスケジューリング。作成するリソースは以下の通り。
 aws_cloudwatch_event_ruleでイベントルール(今回はschedule)を作成 aws_cloudwatch_event_targetでルールにターゲット(今回はLambda)を設定 aws_lambda_permissionでルールに対象Lambdaをinvokeする権限を付ける  $ cat infrastructure/modules/cloudwatch_schefule/variables.tf variable &amp;quot;lambda_function_name&amp;quot; {} variable &amp;quot;lambda_function_arn&amp;quot; {} variable &amp;quot;schedule_expression&amp;quot; { description = &amp;quot;cloudwatch schedule expression e.g. \&amp;quot;cron(0/5 * * * ? *)\&amp;quot;&amp;quot; } $ cat infrastructure/modules/cloudwatch_schefule/main.tf resource &amp;quot;aws_cloudwatch_event_rule&amp;quot; &amp;quot;lambda&amp;quot; { name = &amp;quot;lambda_rule_${var.</description>
    </item>
    
    <item>
      <title>ApexでLambdaをデプロイする</title>
      <link>https://www.sambaiz.net/article/140/</link>
      <pubDate>Sun, 22 Oct 2017 16:06:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/140/</guid>
      <description>ApexでLambdaをデプロイする。 とても簡単に使えるし、変なこともしないので良い感じ。
Serverless Frameworkだとeventの設定までカバーできてより便利。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
インストール。ダウンロードして実行できるようにしている。
$ curl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh   IAMFullAccess AWSLambdaFullAccess  を付けたIAMのプロファイルを登録しておく。
$ aws configure --profile apex $ aws configure list --profile apex Name Value Type Location ---- ----- ---- -------- profile apex manual --profile access_key ****************OVGQ shared-credentials-file secret_key ****************oi5t shared-credentials-file region ap-northeast-1 config-file ~/.aws/config  apex initしてnameとdescriptionを入れるとIAMが登録され、 ディレクトリ構造が作られる。
$ apex init --profile apex Project name: try-apex Project description: test [+] creating IAM try-apex_lambda_function role [+] creating IAM try-apex_lambda_logs policy [+] attaching policy to lambda_function role.</description>
    </item>
    
    <item>
      <title>Lambda上でPuppeteer/Headless Chromeを動かすStarter Kitを作った</title>
      <link>https://www.sambaiz.net/article/132/</link>
      <pubDate>Sun, 10 Sep 2017 23:45:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/132/</guid>
      <description>PuppeteerでHeadless Chromeを動かすコードを Lambda上で動かすStarter Kitを作った。
puppeteer-lambda-starter-kit
Chromeの準備 Puppeteerのインストール時に落としてくるChromeをLambda上で動かそうとしても Lambdaにないshared libraryに依存しているため失敗する。
error while loading shared libraries: libpangocairo-1.0.so.0: cannot open shared object file: No such file or directory  Lambda上でHeadless Chromeを動かす例がないか調べたらserverless-chromeというのがあって、 Headless用の設定でChromeをビルドしていた。 ほかにはchromelessというのもあるけど これはserverless-chromeに 依存している。 最小構成でPuppeteerを使いたかったので、今回はこれらを使わず一から作ることにした。
serverless-chromeにもビルドしたものが置いてあるが、少しバージョンが古いようだったので最新版でビルドした。 基本的には書いてある 通りやればうまくいく。他のプロセスとのshared memoryとして/dev/shmを使っているのを、/tmpに置き換える ようにしないと、実行時のpage.goto()でFailed Provisional Load: ***, error_code: -12になる。
ビルドしたheadless_shellには問題になった依存は含まれていないようだ。
$ ldd headless_shell linux-vdso.so.1 =&amp;gt; (0x00007ffcb6fed000) libpthread.so.0 =&amp;gt; /lib64/libpthread.so.0 (0x00007f5f17dbe000) libdl.so.2 =&amp;gt; /lib64/libdl.so.2 (0x00007f5f17bba000) librt.so.1 =&amp;gt; /lib64/librt.so.1 (0x00007f5f179b1000) libnss3.so =&amp;gt; /usr/lib64/libnss3.so (0x00007f5f17692000) libnssutil3.so =&amp;gt; /usr/lib64/libnssutil3.so (0x00007f5f17466000) libsmime3.</description>
    </item>
    
    <item>
      <title>Node.jsでの文字コードの変換</title>
      <link>https://www.sambaiz.net/article/89/</link>
      <pubDate>Tue, 28 Mar 2017 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/89/</guid>
      <description>node-iconvを使う。
$ npm install iconv  SHIFT_JISからUTF-8への変換はこんな感じ。
const Iconv = require(&#39;iconv&#39;).Iconv; const before = new Buffer([ 0x8b, 0x8d, 0x8e, 0x4d, 0x26, 0x82, 0xb2, 0x94, 0xd1 ]); const iconv = new Iconv(&#39;SHIFT_JIS&#39;, &#39;UTF-8&#39;); console.log(`before: ${before.toString(&#39;hex&#39;)} ${before.toString()}`) const after = iconv.convert(before); console.log(`after: ${after.toString(&#39;hex&#39;)} ${after.toString()}`);  before: 8b8d8e4d2682b294d1 ���M&amp;amp;���� after: e7899be79abf26e38194e9a3af 牛皿&amp;amp;ご飯  文字コードによっては変換後に表せないことがある。 例えば、UTF-8からSHIFT_JISへの変換でサロゲートペア🍚を渡すと変換できず、エラーになる。
throw errnoException(&#39;EILSEQ&#39;, &#39;Illegal character sequence.&#39;);  //IGNOREを付けることで そのような文字があった場合でもエラーにしないようにできる。
const Iconv = require(&#39;iconv&#39;).Iconv; const before = &amp;quot;牛皿&amp;amp;🍚&amp;quot;; const iconv = new Iconv(&#39;UTF-8&#39;, &#39;SHIFT_JIS//IGNORE&#39;); console.</description>
    </item>
    
    <item>
      <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
      <link>https://www.sambaiz.net/article/73/</link>
      <pubDate>Sun, 26 Feb 2017 18:56:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/73/</guid>
      <description>aws-fluent-plugin-kinesisでKinesis Streamsに送り、Lambdaで読んでS3に保存する。 要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。
fluentdで送る $ td-agent-gem install fluent-plugin-kinesis  try_flush_intervalとqueued_chunk_flush_intervalはドキュメントには載っていないが、 以下のページによるとそれぞれqueueに次のchunkがないときとあるときのflushする間隔。 いずれもデフォルトは1だが、これを減らすことでもっと頻繁に吐き出されるようになるらしい。
Fluentd の out_forward と BufferedOutput
あとシャードに振り分けるためのpartition_key を指定できる。デフォルトはランダム。
&amp;lt;source&amp;gt; @type tail path /var/log/td-agent/hoge.log pos_file /etc/td-agent/log.pos tag hoge.log format json time_key timestamp # 2017-01-01T01:01:01+0900 time_format %Y-%m-%dT%H:%M:%S%z &amp;lt;/source&amp;gt; &amp;lt;match hoge.log&amp;gt; @type kinesis_streams region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt;  いくつか送ってみる。
for i in `seq 1 1000` do echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;, &amp;quot;timestamp&amp;quot;: &amp;quot;2017-01-01T01:01:01+0900&amp;quot;}&#39; &amp;gt;&amp;gt; /var/log/td-agent/hoge.</description>
    </item>
    
  </channel>
</rss>