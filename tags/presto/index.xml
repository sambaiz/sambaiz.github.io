<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>presto on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/presto/</link>
    <description>Recent content in presto on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 26 Dec 2021 22:03:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/tags/presto/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Redshift Serverlessと他のサーバーレス集計サービス、Glue Data Catalogのテーブルへのクエリ実行</title>
      <link>https://www.sambaiz.net/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/392/</guid>
      <description>Redshift Serverless Redshift Serverlessは今年のre:Inventで発表された、インスタンスを立てることなく従量課金でペタバイトスケールのDWHであるRedshiftを使える機能。 S3のデータを直接参照できるRedshift SpectrumやRDSへのFederated Query、機械学習のRedshift MLも使える。 分析のような不定期に発生する需要のためにインスタンスを立てておくのはコストの上でハードルが高かったのでこのアップデートは嬉しい。
料金は最低1分のオートスケールするRPU (2vCPU, 16GiBメモリ)時間とストレージに対してかかり、オレゴンリージョンなどが$0.45/RPU hourなのに対して東京はなぜか$0.70/RPU hourと少し割高な設定になっている。2vCPU, 15 GiBメモリのインスタンスdc2.largeがオンデマンドで$0.314/hourなので、利用頻度が少なかったり不定期なために平均40%以上リソースが使えていない場合のコストは抑えられそうだ。RIが最大まで効いている場合は$0.110/hourとなり15%まで閾値が下がるが、スケールを気にしなくて良いのは運用の上でもメリットがある。また、Redshift Spectrumのロード量に対する課金は発生しない。
他のサーバーレス集計サービス サーバーレスで集計を行える他のサービスとしてはPrestoのマネージドサービスであるAthenaやSparkのマネージドサービスであるGlueがあって、前者は手軽にクエリを実行できロード量による課金も分かりやすいが、実行時間や同時実行数などの制約があり、後者は時間のかかる集計も行うことができるがジョブを作る必要があってアドホックな実行にはあまり向かない。
これらはHive Metastoreに対応しており、その互換サービスであるGlue Data Catalogでスキーマを共有できるので用途に応じて使い分けることもできるが、使える文法に差があったり、同じクエリを実行しても異なる結果を返すことがあったりと、移植する際には注意する必要がある。
Athena(Presto)とGlue(Spark)で同じクエリを実行した際に異なる値が返る原因 - sambaiz-net
また、いずれもRDSに加えてDynamoDBやMongoDBなどのコネクタが用意されており、カスタムコネクタを用いることで他のデータソースにも接続することができる。
AthenaのFederated QueryでTPC-DS Connectorを用いてデータを生成する - sambaiz-net
GlueのカスタムコネクタでBigQueryに接続する - sambaiz-net
 同じく今年のre:Inventで発表されたEMR Serverlessもある。 巨大なデータに対して重い集計やrepartition()を行ったりするとOOMやNo space left on deviceになることがあるが、Glueだとスケールアップできないため物理的に解決が難しいことがあり、そのような場合はEMRを検討することになる。
サードパーティにも目を向ければ各クラウドにホストされるSnowflakeがある。コストやスケールの容易さのためにRedshiftからSnowflakeに移行した事例もあり良い評判を目にするが、立ち位置が近いRedshift Serverlessが発表されたことでこれからの技術選定に影響があるかもしれない。料金はプランによって単価が異なるSnowflake Creditとストレージに対してかかる。
他にはAnthosを用いてマルチクラウドでクエリエンジンを動かすBigQuery Omniもある。今年の10月にGAになったばかりで、対応リージョンがまだ少なく、料金も従量課金でないので他と同様に使うイメージではないが、データを転送することなくAWS上でBigQueryのクエリを実行できるのは待望の機能なので今後の動きが気になる。
Glue Data Catalogのテーブルにクエリを実行する CDKでData CatalogのDatabaseとTable、それらにアクセスできるRoleを作成する。
CDKでGlue Data CatalogのDatabase,Table,Partition,Crawlerを作成する - sambaiz-net
これも今年のre:Inventで発表があったが、ついにCDKのv2がstableになったのでv2で書く。 各サービスのパッケージ @aws-cdk/aws-xxx が aws-cdk-lib に統合され、alphaのものだけ旧パッケージ名に-alphaを付けたものになった。
$ npx aws-cdk@2.x init app --language typescript $ npm install --save aws-cdk-lib $ npm install --save @aws-cdk/aws-glue-alpha Redshift Serverlessで用いるRoleはPrincipalに redshift.</description>
    </item>
    
    <item>
      <title>Athena(Presto)とGlue(Spark)で同じクエリを実行した際に異なる値が返る原因</title>
      <link>https://www.sambaiz.net/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/370/</guid>
      <description>AWSではGlueのデータカタログでテーブルを共有して、 アドホックな集計は手軽にクエリを実行できるPrestoベースのAthena、 バッチ集計はリソースや時間の制約を回避できるSparkベースのGlueといったように併用することができる。
AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net
ANSI互換のSQLを実行するPrestoと デフォルトでHive互換のSpark SQLを実行するSparkで 使える文法に差があったりするものの、同じクエリが使い回せることもあって、そのような場合は同じ結果が返ってくることを期待してしまうが、 次のような挙動の違いによって大きく結果が異なってしまうことがある。
数値の型 Presto 0.198 以降ではデフォルトで小数リテラルをDECIMALとして扱うが、 Athena engine version 2 (Presto 0.217)では DOUBLEになる。engine version 1 (Presto 0.172)との互換のために parse-decimal-literals-as-double が渡されているのかもしれない。
SELECT typeof(1.2), /* double */ 1 / 3.0 * 10000000 /* 3333333.333333333 */ Spark 2.3 以降も小数リテラルをDECIMALとして扱い、Glue 2.0 (Spark 2.4.3) でもそうなっている。 DECIMALのscale(小数点以下の桁数)は最大6に制限される。
print(spark.sql(&amp;#34;&amp;#34;&amp;#34;SELECT 1.2&amp;#34;&amp;#34;&amp;#34;).dtypes) # [(&amp;#39;1.2&amp;#39;, &amp;#39;decimal(2,1)&amp;#39;)] print(spark.sql(&amp;#34;&amp;#34;&amp;#34;SELECT 1 / 3.0 * 10000000&amp;#34;&amp;#34;&amp;#34;).collect()) # [Row((CAST((CAST(CAST(1 AS DECIMAL(1,0)) AS DECIMAL(2,1)) / CAST(3.0 AS DECIMAL(2,1))) AS DECIMAL(14,6)) * CAST(CAST(10000000 AS DECIMAL(8,0)) AS DECIMAL(14,6)))=Decimal(&amp;#39;3333330.</description>
    </item>
    
    <item>
      <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
      <link>https://www.sambaiz.net/article/145/</link>
      <pubDate>Sun, 24 Dec 2017 23:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/145/</guid>
      <description>https://github.com/sambaiz/athena-admin
AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。
料金はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。 データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだけど都度locationを指定してADD PARTITIONを実行するのは大変。さらにスキーマを変更するのにもALTER TABLE ADD COLUMNSなどはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。
ではどうしようもないかというとMSCK REPAIR TABLEというのがあって、 これはS3のObjectのdt=YYYY-MM-DDのようなkey=valueのprefixを認識してパーティションを作るもの。作り直す際もこれ1クエリで終わる。それなら最初からそういう風に置けばよいのではというところだけど、勝手にYYYY/MM/DD/HHのprefixを付けてしまうFirehoseのようなのもある。
今回作ったathena-adminは以下のような定義ファイルから、 パーティションのkey=valueのprefixが付くように置き換えたり、変更があったらmigrationする。 このファイルを書き換えるだけで基本的にどうにかなるし、バージョン管理すればテーブル定義の変更を追うことができる。
{ &amp;#34;general&amp;#34;: { &amp;#34;athenaRegion&amp;#34;: &amp;#34;ap-northeast-1&amp;#34;, &amp;#34;databaseName&amp;#34;: &amp;#34;aaaa&amp;#34;, &amp;#34;saveDefinitionLocation&amp;#34;: &amp;#34;s3://saveDefinitionBucket/aaaa.json&amp;#34; }, &amp;#34;tables&amp;#34;: { &amp;#34;sample_data&amp;#34;: { &amp;#34;columns&amp;#34;: { &amp;#34;user_id&amp;#34;: &amp;#34;int&amp;#34;, &amp;#34;value&amp;#34;: { &amp;#34;score&amp;#34;: &amp;#34;int&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;string&amp;#34; } /* &amp;#34;struct&amp;lt;score:int,category:string&amp;gt;&amp;#34; のように書くこともできる */ }, &amp;#34;srcLocation&amp;#34;: &amp;#34;s3://src/location/&amp;#34;, &amp;#34;partition&amp;#34;: { &amp;#34;prePartitionLocation&amp;#34;: &amp;#34;s3://pre/partition/&amp;#34;, /* optional */ &amp;#34;regexp&amp;#34;: &amp;#34;(\\d{4})/(\\d{2})/(\\d{2})/&amp;#34;, /* optional */ &amp;#34;keys&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;dt&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;{1}-{2}-{3}&amp;#34;, /* optional */ } ] } } } } 使い方はこんな感じ。使い方によってはmigrate()だけ呼ぶこともあると思う。 replaceObjects()にはmatchedHandlerというのを渡すこともできて、 UTCからJSTに変換するといったこともできる。</description>
    </item>
    
  </channel>
</rss>
