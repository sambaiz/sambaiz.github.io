<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>presto on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/presto/</link>
    <description>Recent content in presto on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sat, 25 Dec 2021 23:55:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/tags/presto/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AthenaのFederated QueryでTPC-DS Connectorを用いてデータを生成する</title>
      <link>https://www.sambaiz.net/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/391/</guid>
      <description>AthenaのFederated Queryは データソースコネクタとなるLambdaを通してDynamoDBやRDSといったS3以外のデータソースにクエリを実行できる機能。
 今回はAWS公式のリポジトリにあるTPC-DS Connectorを用いて、意思決定支援(Decision Support)におけるデータベースのベンチマークであるTPC-DSのデータを生成する。
公式のリポジトリにあるとはいえカスタム扱いなので自分でビルドする必要がある。基本的にREADME通り進めれば良いが、jdk16ではビルドに失敗したのでjdk8を入れて実行した。
$ brew tap homebrew/cask-versions $ brew install --cask corretto8 export JAVA_HOME=`/usr/libexec/java_home -v 1.8` export PATH=${JAVA_HOME}/bin:${PATH} $ java -version openjdk version &amp;#34;1.8.0_312&amp;#34; OpenJDK Runtime Environment Corretto-8.312.07.1 (build 1.8.0_312-b07) OpenJDK 64-Bit Server VM Corretto-8.312.07.1 (build 25.312-b07, mixed mode) publish.shの引数でもリージョンを取るが、これとは別に.aws/configなどで指定されていないとAWS SDKの方で読めずに失敗する。
$ git clone https://github.com/awslabs/aws-athena-query-federation.git -b v2021.51.1 --depth 1 $ cd aws-athena-query-federation/ $ mvn clean install -DskipTests=true $ cd athena-tpcds/ $ mvn clean install -DskipTests=true # export AWS_REGION=us-west-2 $ .</description>
    </item>
    
    <item>
      <title>Athena(Presto)とGlue(Spark)で同じクエリを実行した際に異なる値が返る原因</title>
      <link>https://www.sambaiz.net/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/370/</guid>
      <description>AWSではGlueのデータカタログでテーブルを共有して、 アドホックな集計は手軽にクエリを実行できるPrestoベースのAthena、 バッチ集計はリソースや時間の制約を回避できるSparkベースのGlueといったように併用することができる。
AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する - sambaiz-net
ANSI互換のSQLを実行するPrestoと デフォルトでHive互換のSpark SQLを実行するSparkで 使える文法に差があったりするものの、同じクエリが使い回せることもあって、そのような場合は同じ結果が返ってくることを期待してしまうが、 次のような挙動の違いによって大きく結果が異なってしまうことがある。
数値の型 Presto 0.198 以降ではデフォルトで小数リテラルをDECIMALとして扱うが、 Athena engine version 2 (Presto 0.217)では DOUBLEになる。engine version 1 (Presto 0.172)との互換のために parse-decimal-literals-as-double が渡されているのかもしれない。
SELECT typeof(1.2), /* double */ 1 / 3.0 * 10000000 /* 3333333.333333333 */ Spark 2.3 以降も小数リテラルをDECIMALとして扱い、Glue 2.0 (Spark 2.4.3) でもそうなっている。 DECIMALのscale(小数点以下の桁数)は最大6に制限される。
print(spark.sql(&amp;#34;&amp;#34;&amp;#34;SELECT 1.2&amp;#34;&amp;#34;&amp;#34;).dtypes) # [(&amp;#39;1.2&amp;#39;, &amp;#39;decimal(2,1)&amp;#39;)] print(spark.sql(&amp;#34;&amp;#34;&amp;#34;SELECT 1 / 3.0 * 10000000&amp;#34;&amp;#34;&amp;#34;).collect()) # [Row((CAST((CAST(CAST(1 AS DECIMAL(1,0)) AS DECIMAL(2,1)) / CAST(3.0 AS DECIMAL(2,1))) AS DECIMAL(14,6)) * CAST(CAST(10000000 AS DECIMAL(8,0)) AS DECIMAL(14,6)))=Decimal(&amp;#39;3333330.</description>
    </item>
    
    <item>
      <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
      <link>https://www.sambaiz.net/article/145/</link>
      <pubDate>Sun, 24 Dec 2017 23:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/145/</guid>
      <description>https://github.com/sambaiz/athena-admin
AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。
料金はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。 データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだけど都度locationを指定してADD PARTITIONを実行するのは大変。さらにスキーマを変更するのにもALTER TABLE ADD COLUMNSなどはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。
ではどうしようもないかというとMSCK REPAIR TABLEというのがあって、 これはS3のObjectのdt=YYYY-MM-DDのようなkey=valueのprefixを認識してパーティションを作るもの。作り直す際もこれ1クエリで終わる。それなら最初からそういう風に置けばよいのではというところだけど、勝手にYYYY/MM/DD/HHのprefixを付けてしまうFirehoseのようなのもある。
今回作ったathena-adminは以下のような定義ファイルから、 パーティションのkey=valueのprefixが付くように置き換えたり、変更があったらmigrationする。 このファイルを書き換えるだけで基本的にどうにかなるし、バージョン管理すればテーブル定義の変更を追うことができる。
{ &amp;#34;general&amp;#34;: { &amp;#34;athenaRegion&amp;#34;: &amp;#34;ap-northeast-1&amp;#34;, &amp;#34;databaseName&amp;#34;: &amp;#34;aaaa&amp;#34;, &amp;#34;saveDefinitionLocation&amp;#34;: &amp;#34;s3://saveDefinitionBucket/aaaa.json&amp;#34; }, &amp;#34;tables&amp;#34;: { &amp;#34;sample_data&amp;#34;: { &amp;#34;columns&amp;#34;: { &amp;#34;user_id&amp;#34;: &amp;#34;int&amp;#34;, &amp;#34;value&amp;#34;: { &amp;#34;score&amp;#34;: &amp;#34;int&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;string&amp;#34; } /* &amp;#34;struct&amp;lt;score:int,category:string&amp;gt;&amp;#34; のように書くこともできる */ }, &amp;#34;srcLocation&amp;#34;: &amp;#34;s3://src/location/&amp;#34;, &amp;#34;partition&amp;#34;: { &amp;#34;prePartitionLocation&amp;#34;: &amp;#34;s3://pre/partition/&amp;#34;, /* optional */ &amp;#34;regexp&amp;#34;: &amp;#34;(\\d{4})/(\\d{2})/(\\d{2})/&amp;#34;, /* optional */ &amp;#34;keys&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;dt&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;{1}-{2}-{3}&amp;#34;, /* optional */ } ] } } } } 使い方はこんな感じ。使い方によってはmigrate()だけ呼ぶこともあると思う。 replaceObjects()にはmatchedHandlerというのを渡すこともできて、 UTCからJSTに変換するといったこともできる。</description>
    </item>
    
  </channel>
</rss>
