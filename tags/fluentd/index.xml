<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fluentd on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/fluentd/</link>
    <description>Recent content in fluentd on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sun, 25 Apr 2021 23:55:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/tags/fluentd/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>FluentdがどのようにMulti Process Workersで処理を実行しているのか実装を追う</title>
      <link>https://www.sambaiz.net/article/335/</link>
      <pubDate>Sun, 25 Apr 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/335/</guid>
      <description>Fluentdはv1.0から標準でマルチプロセス対応され、 指定した数のWorkerで処理が行われるようになった。
&amp;lt;system&amp;gt; workers 4 &amp;lt;/system&amp;gt; どのように実行しているのかv1.12.3の実装を見ていく。
Supervisor Multi Process Workersのドキュメントにもあるように、 Workerと通信するSupervisorというのが存在する。 具体的に何をしているかというとWorkerプロセスを作成するWorkerModuleを渡してサーバーを立てたり、SIGNALを送ったりしている。
# https://github.com/fluent/fluentd/blob/master/lib/fluent/supervisor.rb#L365-L377 module WorkerModule def spawn(process_manager) main_cmd = config[:main_cmd] env = { &amp;#39;SERVERENGINE_WORKER_ID&amp;#39; =&amp;gt; @worker_id.to_i.to_s, } @pm = process_manager.spawn(env, *main_cmd) end def after_start (config[:worker_pid] ||= {})[@worker_id] = @pm.pid end end # https://github.com/fluent/fluentd/blob/v1.12.3/lib/fluent/supervisor.rb#L808-L811 se = ServerEngine.create(ServerModule, WorkerModule){ Fluent::Supervisor.load_config(@config_path, params) } se.run # https://github.com/fluent/fluentd/blob/master/lib/fluent/supervisor.rb#L305-L317 def kill_worker if config[:worker_pid] pids = config[:worker_pid].clone config[:worker_pid].clear pids.each_value do |pid| if Fluent.windows? Process.kill :KILL, pid else Process.</description>
    </item>
    
    <item>
      <title>Kinesis Data Analyticsによる集計遅延箇所の特定</title>
      <link>https://www.sambaiz.net/article/324/</link>
      <pubDate>Sun, 07 Feb 2021 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/324/</guid>
      <description>Kinesis Data Analytics (KDA)はマッピングしたカラムに加えて、Kinesis Data Streams (KDS)に入った時間 APPROXIMATE_ARRIVAL_TIME とKDAのin-app STREAMに入った時間 ROWTIME をソースに含める。これらとログのタイムスタンプを合わせることで集計遅延が起きた際にどこが原因になっているかを特定することができる。
Log aggregatorでのタイムスタンプの付加 集計対象のログを集約サーバーを中継して送っている場合、そこでのタイムスタンプを付加しておくとバッファリングによる滞りを検知できる。 fluentdのmonitor_agentの値をDatadogなどに送って監視することもできるが、 集計ウィンドウが短い場合、collection_intervalの関係で、正確な状態を把握しづらいことがある。
fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する - sambaiz-net
レコードへの付加にはfluentdのコアに含まれているrecord_transformerを使うこともできるが、性能が良いfluent-plugin-record-modifierという選択肢もある。
fluentdのrecord_transformerでログを加工する - sambaiz-net
&amp;lt;filter test.log&amp;gt; @type record_modifier &amp;lt;record&amp;gt; ts_aggr ${Time.now().strftime(&amp;#39;%Y-%m-%dT%H:%M:%S.%L%z&amp;#39;)} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; また、ログのタイムスタンプをtime_keyとしている場合、keep_time_key trueにするか&amp;lt;inject&amp;gt;してKDSに送られるようにする。
fluentdのとでtime_formatを指定しなかった場合の挙動と内部処理 - sambaiz-net
TIMESTAMPのパース タイムスタンプ文字列をTIMESTAMP型のカラムにマッピングすることもできるが、2021-01-01T00:00:00.000+0900形式の文字列をマッピングしたところ、UTCで18時間後ろにずれた時間になってしまった。
そこで一度CHARにマッピングしてからフォーマットを明示してCHAR_TO_TIMESTAMP(&#39;&amp;lt;format_string&amp;gt;&#39;,&amp;ldquo;column_name&amp;rdquo;)することにした。 &amp;lt;format_string&amp;gt;はJavaのSimpleDateFormatで記述し、この例の場合はyyyy-MM-dd&#39;&#39;T&#39;&#39;HH:mm:ss.SSSZのようになる。
マッピングの変更後にSourcesの方に何も出てこなくなった場合は、クエリの方で問題が起きている可能性があるので、コンソール上でクエリを保存してみてエラーにならないか確認し、必要なら修正する。
クエリ Kinesis Data AnalyticsのSQL, Lambdaへの出力とCDKによるリソースの作成 - sambaiz-net
各タイムスタンプのMINを取って現在時刻との差を取れば、そのウインドウ集計対象のログのうち最も古いものの各箇所からのレイテンシが出せる。
CREATE OR REPLACE PUMP &amp;#34;TEST_PUMP&amp;#34; AS INSERT INTO &amp;#34;TEST_STREAM&amp;#34; (&amp;#34;min_ts&amp;#34;, &amp;#34;min_ts_kds&amp;#34;, &amp;#34;min_ts_kda&amp;#34;) SELECT STREAM MIN(CHAR_TO_TIMESTAMP(&amp;#39;yyyy-MM-dd&amp;#39;&amp;#39;T&amp;#39;&amp;#39;HH:mm:ss.SSSZ&amp;#39;, &amp;#34;ts&amp;#34;)) as min_ts, MIN(&amp;#34;APPROXIMATE_ARRIVAL_TIME&amp;#34;) as min_ts_kds, &amp;#34;ROWTIME&amp;#34; as min_ts_kda FROM &amp;#34;SOURCE_SQL_STREAM_001&amp;#34; GROUP BY STEP(&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;.</description>
    </item>
    
    <item>
      <title>fluentdの&lt;parse&gt;と&lt;inject&gt;でtime_formatを指定しなかった場合の挙動と内部処理</title>
      <link>https://www.sambaiz.net/article/322/</link>
      <pubDate>Sat, 23 Jan 2021 00:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/322/</guid>
      <description>挙動 fluent/fluentdのDockerイメージで試す。
$ vi fluent.conf &amp;lt;source&amp;gt; @type tail path /home/fluent/test.log pos_file /home/fluent/test.log.pos tag test.log &amp;lt;parse&amp;gt; @type json time_key ts time_type string &amp;lt;/parse&amp;gt; &amp;lt;/source&amp;gt; &amp;lt;match test.log&amp;gt; @type stdout &amp;lt;inject&amp;gt; time_key ts2 time_type string &amp;lt;/inject&amp;gt; &amp;lt;/match&amp;gt; $ touch test.log $ docker run -it --rm -v $(pwd)/fluent.conf:/fluentd/etc/fluent.conf -v $(pwd)/test.log:/home/fluent/test.log fluent/fluentd:v1.12-1 # echo &amp;#39;{&amp;#34;ts&amp;#34;: &amp;#34;2021-01-01T01:23:45&amp;#34;, &amp;#34;data&amp;#34;: 123}&amp;#39; &amp;gt;&amp;gt; test.log 2021-01-01 01:23:45.000000000 +0000 test.log: {&amp;#34;data&amp;#34;:123,&amp;#34;ts2&amp;#34;:&amp;#34;2021-01-01T01:23:45+00:00&amp;#34;} # echo &amp;#39;{&amp;#34;ts&amp;#34;: &amp;#34;2021-01-01T01:23:45&amp;#34;, &amp;#34;data&amp;#34;: 123}&amp;#39; &amp;gt;&amp;gt; test.log 2021-01-01 01:23:45.000000000 +0000 test.</description>
    </item>
    
    <item>
      <title>ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する</title>
      <link>https://www.sambaiz.net/article/221/</link>
      <pubDate>Thu, 09 May 2019 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/221/</guid>
      <description>DAEMONを動かすことはできず、 fluentd logdriverもサポートされていないFargateで、 サイドカーとしてFluentdのコンテナを動かしてアプリケーションのログをS3に送る。 全体のコードはGitHubにある。
FargateでECSを使う - sambaiz-net
Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net
Fluentd 必要なプラグインと設定ファイルを入れたイメージを作る。
FROMfluent/fluentd:v1.4-1 USERroot COPY ./fluent.conf /fluentd/etc/ # install plugin RUN apk add --update-cache --virtual .build-deps sudo build-base ruby-dev \  &amp;amp;&amp;amp; gem install fluent-plugin-s3 -v 1.0.0 --no-document \  &amp;amp;&amp;amp; gem install uuidtools \  &amp;amp;&amp;amp; gem sources --clear-all \  &amp;amp;&amp;amp; apk del .build-deps \  &amp;amp;&amp;amp; rm -rf /var/cache/apk/* \  /home/fluent/.gem/ruby/*/cache/*.gem # set timezone (Alpine) RUN apk --update-cache add tzdata &amp;amp;&amp;amp; \  cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime &amp;amp;&amp;amp; \  apk del tzdata &amp;amp;&amp;amp; \  rm -rf /var/cache/apk/* fluent.</description>
    </item>
    
    <item>
      <title>Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る</title>
      <link>https://www.sambaiz.net/article/159/</link>
      <pubDate>Tue, 13 Mar 2018 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/159/</guid>
      <description>Logging AgentをNodeレベルのDaemonSetとして動かすのではなく、Podの中にSidecar Containerとして動かす。その分リソースは食うけど、独立した設定で動かせる。
アプリケーション https://github.com/sambaiz/go-logging-sample
Goで定期的にログを出すサンプルコードを書いたのでこれを使う。 viperで設定を持ち、 zapでログを出力する。 あとSIGINTを拾ってSync()してGraceful Shutdownするようにしている。
Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net
multistage-buildして、GKEで動かすのでContainer Registryに上げる。
$ docker build -t go-logging-sample . $ docker tag go-logging-sample gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1 $ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample Fluentdの設定 fluent-plugin-bigqueryプラグインを使う。
projectとdataset、パーティションの日付分割テーブルに入れる場合は、auto_create_tableできないのでtableも作成しておく。
fluentdの設定はConfigMapで持つ。
apiVersion: v1 kind: ConfigMap metadata: name: fluentd-config data: fluent.conf: |&amp;lt;source&amp;gt; @type tail format json path /var/log/app.log pos_file /var/log/app.log.pos tag bigquery &amp;lt;/source&amp;gt; &amp;lt;match bigquery&amp;gt; @type bigquery method load &amp;lt;buffer time&amp;gt; @type file path /var/log/bigquery.*.buffer timekey 1d flush_at_shutdown true &amp;lt;/buffer&amp;gt; auth_method	compute_engine project &amp;lt;project-name&amp;gt; dataset &amp;lt;dataset-name&amp;gt; table &amp;lt;table-name&amp;gt;$%Y%m%d fetch_schema true ignore_unknown_values true	&amp;lt;/match&amp;gt; プラグイン入りのfluentdイメージもビルドして上げる。</description>
    </item>
    
    <item>
      <title>Fluentdのout_copyのstoreのエラーは他のstoreに影響する</title>
      <link>https://www.sambaiz.net/article/116/</link>
      <pubDate>Sat, 01 Jul 2017 18:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/116/</guid>
      <description>Fluentdのout_copyプラグインは 一つのeventを複数のoutputに渡すために使われる。 ただ、複数設定した中のstoreでエラーが起きると他のstoreにも影響してしまう。
例えばこんなの。
&amp;lt;source&amp;gt; @type dummy dummy {&amp;#34;hello&amp;#34;:&amp;#34;world&amp;#34;} tag dummy rate 1 &amp;lt;/source&amp;gt; &amp;lt;match dummy&amp;gt; @type copy &amp;lt;store&amp;gt; @type stdout &amp;lt;/store&amp;gt; &amp;lt;store&amp;gt; @type file path /var/log/td-agent/dummy buffer_queue_limit 0 buffer_chunk_limit 1k &amp;lt;/store&amp;gt; &amp;lt;/match&amp;gt; fileの方でqueue size exceeds limitになるとstdoutも出力されなくなってしまう。
ちなみに一旦relabelしてもだめ。
&amp;lt;source&amp;gt; @type dummy dummy {&amp;#34;hello&amp;#34;:&amp;#34;world&amp;#34;} tag dummy rate 1 &amp;lt;/source&amp;gt; &amp;lt;match dummy&amp;gt; @type copy &amp;lt;store&amp;gt; @type stdout &amp;lt;/store&amp;gt; &amp;lt;store&amp;gt; @type relabel @label @file &amp;lt;/store&amp;gt; &amp;lt;/match&amp;gt; &amp;lt;label @file&amp;gt; &amp;lt;match dummy&amp;gt; @type file path /var/log/td-agent/dummy buffer_queue_limit 0 buffer_chunk_limit 1k &amp;lt;/match&amp;gt; &amp;lt;/label&amp;gt; ドキュメントでも紹介されている、sonots氏のout_copy_exでは storeにignore_errorを付けるとrescueするようになっているので他に巻き込まれなくなる。</description>
    </item>
    
    <item>
      <title>fluentdのAggregatorをELBで負荷分散し、Blue/Green Deploymentする</title>
      <link>https://www.sambaiz.net/article/113/</link>
      <pubDate>Sun, 25 Jun 2017 00:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/113/</guid>
      <description>デプロイやスループットの調整を簡単にするため、BeanstalkでAggregatorを立ち上げた。
負荷分散 TCPの24224(設定による)が通るようにEC2,ELBのSGとリスナーの設定をする必要があって、 ELBのSGのアウトバウンドの設定が見落とされがち。ELBのクロスゾーン分散は有効になっている。
まず、ELBに3台、それぞれ別のAZ(1b, 1c, 1d)に配置されている状態でログを送り始めるとそれぞれ均等にログが届いた。 その状態から4台(1b * 2, 1c, 1d)にすると、2つのインスタンス(1b, 1c)のみに均等にログが届くようになった。 4台になると(1b, 1c)と(1b, 1d)に分けられてELBのノードがそれらの組に紐づいたということだと思う。 各ノードにはDNSラウンドロビンするようになっている。実際restartすると今度は別の組の方に送られた。
では、なぜ一度送り始めると同じ方にしか飛ばないかというと、forwardプラグインのexpire_dns_cacheがデフォルトでnilになっていて、 heartbeatが届いている間は無期限にDNSキャッシュするようになっているため。これに0(キャッシュしない)か秒数を指定すると、 その間隔で他の組のインスタンスにもログが届くようになった。 expire_dns_cacheしなくても複数のインスタンスからラウンドロビンされるため全体でいえば分散される。
heartbeat ELB配下のEC2を全て落としてもheartbeatに失敗しないため、standyに移行せずELBのバックエンド接続エラーになってログがロストしてしまうようだ。 ログにも出ず、以下のようにactive-standbyの設定をしてもstandbyに移行しない。 全てのインスタンスが同時に落ちるというのは滅多に起きないだろうけど、少なくとも検知できるようにはしておく。
&amp;lt;server&amp;gt; name td1 host autoscale-td1.us-east-1.elasticbeanstalk.com port 24224 &amp;lt;/server&amp;gt; &amp;lt;server&amp;gt; name td2 host autoscale-td2.us-east-1.elasticbeanstalk.com port 24224 standby &amp;lt;/server&amp;gt; Blue/Green Deployment Blue-Green Deploymentというのは、2つの系を用意し、activeでない方にデプロイし、 スワップして反映させるもの。ダウンタイムなしで問題が起きた際にもすぐに切り戻すことができる。 スワップして向き先を変えるにはexpire_dns_cacheを設定する必要がある。
Auto Scaling 増えるのはいいとして減るときに、 送り先で一時的に障害が起きていたりするとバッファをflushできずにログがロストする可能性がある。 それでいうとログの送り元でも同じことが起こりうるんだけど、通常Aggregatorにしか送らないので比較的問題になりにくい。
これを避けたい場合、Auto Scalingグループの設定で スケールインから保護を有効にして これから立ち上がるインスタンスはスケールインしなくすることができる。 それまでに立ち上がっていたインスタンスには適用されないので注意。
スケールインしないということは最大の台数で止まってしまうので、 ピークを過ぎたらスワップしてバッファが全て掃けたことを確認してからTerminateすることになる。 これを日常的にやるのは面倒なので、実際は予期しない流量の増加に備えて一応設定しておき、 普段はしきい値にひっかからないような最低台数で待ち構えておくことにするかな。
あとはヘルスチェックによって潰される可能性はなくもないけど、それはもうやむなし・・・。
参考 AWS ELBの社内向け構成ガイドを公開してみる 負荷分散編 – Cross-Zone Routingを踏まえて ｜ Developers.</description>
    </item>
    
    <item>
      <title>NorikraでログをJOINする</title>
      <link>https://www.sambaiz.net/article/111/</link>
      <pubDate>Thu, 15 Jun 2017 00:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/111/</guid>
      <description>NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net
適当なログを出すコードを書いた。
sambaiz/lottery-log
これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。 広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。
// lottery.log {&amp;#34;ts&amp;#34;:1497453504.6818597,&amp;#34;uid&amp;#34;:&amp;#34;b18c0d98-19b2-4e37-8fc4-6b00a4b728c3&amp;#34;,&amp;#34;prize&amp;#34;:855,&amp;#34;isWin&amp;#34;:true} // received.log {&amp;#34;ts&amp;#34;:1497453515.932101,&amp;#34;uid&amp;#34;:&amp;#34;bc4f578f-4a5f-47f1-a4e0-1ef0b43c316e&amp;#34;} クエリはこんな感じ。一つはlotteryログとreceivedログをuidでJOINするもので、 received_rateの計算にはサブクエリも使っている。 received_rateの計算で分母に小さな値を足しているのはNaNやInfinityにならないようにするため。 receivedログは最大30秒遅れて出力されるため、40秒前までのreceivedログをwin:timeで見ている。 これをtime_batchにしてしまうと期待通りの結果にならないので注意。
もう一つはJavaの関数でboolを0/1にして平均をとることでisWinがtrueである割合を出している。
$ docker exec norikra norikra-client query add lottery_agg &amp;#39; SELECT COUNT(*) as received_count, (COUNT(*) / (SELECT COUNT(*) + 0.00001 FROM lottery.win:time_batch(1 sec, 0).std:unique(uid))) as received_rate, AVG(prize) as prize_avg, SUM(prize) as prize_sum FROM lottery.win:time(40 sec).std:unique(uid) as a, received.win:time_batch(1 sec, 0).std:unique(uid) as b WHERE a.uid = b.uid&amp;#39; $ docker exec norikra norikra-client query add lottery_win_rate &amp;#39;SELECT avg(Boolean.</description>
    </item>
    
    <item>
      <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
      <link>https://www.sambaiz.net/article/109/</link>
      <pubDate>Sat, 10 Jun 2017 12:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/109/</guid>
      <description>NorikraはTD社のtagomoris氏が作った、 スキーマレスのストリーミングデータを処理するOSS。
モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだけど、 流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。
Norikraを立ち上げてクエリを実行する 公式で紹介されているDockerイメージがあったのでこれで動かしてみる。
$ docker run -e &amp;#34;TZ=Asia/Tokyo&amp;#34; -p 26578:26578 -p 26571:26571 -v `pwd`:/var/tmp/norikra:rw -d myfinder/docker-norikra norikra start --stats /var/tmp/norikra/stats.json -l /var/tmp/norikra ほかのオプションとして-Xmsや-XmxでJVMのヒープメモリの量を設定したり、Experimentalではあるけど--shutoffでヒープメモリが一杯になる前に弾いて OutOfMemoryを防ぐことができる。 また、Norikraのコアエンジンで使われているOSSの CEP (Complex event processing)エンジン、 Esper のパフォーマンスチューニングとして--microや--smallなどを渡すこともできるけど試していない。
公式サイトの例に従ってクライアントからデータを入れてクエリを実行してみる。
まずはtargetをopenする。targetというのはスキーマレスのイベントストリームのこと。 ここで定義したフィールドは必須になる。
$ norikra-client target open www path:string status:integer referer:string agent:string userid:integer $ norikra-client target list TARGET	AUTO_FIELD www	true 次にクエリを追加する。一見普通のSQLのように見えるけど、EsperのクエリであるEPL(Event Processing Language)。 ただしSELECTしか使えないのも含めてクエリにいくらかの制限がある。
このクエリではwin:time_batchで10秒のWindowを定義し、eventをgroup byして、その数をeventとして出力する。
$ norikra-client query add www.toppageviews &amp;#39;SELECT count(*) AS cnt FROM www.</description>
    </item>
    
    <item>
      <title>fluentdでKinesis streamsに送るときの性能確認</title>
      <link>https://www.sambaiz.net/article/108/</link>
      <pubDate>Mon, 05 Jun 2017 23:48:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/108/</guid>
      <description>localでのstreamsとproducerのbenchmark aws-fluent-plugin-kinesisの make benchmarkはlocalにDummyServerを立ち上げて送っている。
空でもいいのでroleをつけておく必要がある。
$ git clone https://github.com/awslabs/aws-fluent-plugin-kinesis.git $ cd aws-fluent-plugin-kinesis $ yum install -y ruby-devel gcc $ echo &amp;#39;gem &amp;#34;io-console&amp;#34;&amp;#39; &amp;gt;&amp;gt; Gemfile $ make $ make benchmark RATEを指定しなければデフォルトで秒間1000レコードが送られる設定。 fluentdを起動してから10秒後にプロセスをkillし、そのレコード数などを出力している。
t2.microでデフォルト(RATE=1000)で実行した結果がこれ。 固める分producerの方はややパフォーマンスが落ちる。
bundle exec rake benchmark TYPE=streams Results: requets: 20, raw_records: 9400, records: 9400 bundle exec rake benchmark TYPE=producer Results: requets: 14, raw_records: 1005, records: 8900 RATE=3000のとき。producerではraw_recordsが1/100、リクエスト数は1/5。 streamsだとシャードを増やしていく必要があるけど、producerの方は当分大丈夫そうだ。
bundle exec rake benchmark TYPE=streams Results: requets: 57, raw_records: 27600, records: 27600 bundle exec rake benchmark TYPE=producer Results: requets: 12, raw_records: 241, records: 25200 RATE=10000のとき。raw_records, requestの圧縮率はさらに上がり、 パフォーマンスの差が大きくなってきている。</description>
    </item>
    
    <item>
      <title>td-agent2.3.5のfluentdが0.14系になってしまっているのでソースからビルドする</title>
      <link>https://www.sambaiz.net/article/107/</link>
      <pubDate>Sun, 04 Jun 2017 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/107/</guid>
      <description>追記(2016-06-25): 現在は普通に入れても0.12系の2.3.5-1が入るようになっている。
 $ curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh $ td-agent --version td-agent 0.14.16 0.12系じゃない！？
$ yum list installed | grep td-agent td-agent.x86_64 2.3.5-0.el2017 @treasuredata どうやら2.3.5では0.14系になってしまっているよう。 そのあとにリリースされた2.3.5-1では直ってるみたいだけど、現時点ではrpmリポジトリに上がっていない。
しょうがないのでソースからビルドすることにした。 いずれにせよ各環境で同じバージョンのビルドに合わせるべきだとは思う。 Beanstalk環境の場合、AMIに固めていたとしても非Beanstalk AMIではyum updateされてしまうので注意が必要だ。
BeanstalkでのパッケージのバージョンがAMIでのバージョンと異なる原因 - sambaiz-net
前UbuntuでやったようにDockerでビルドする。今回はAmazon Linux向け。
td-agentをビルドしてfluentdのバージョンを上げる - sambaiz-net
https://hub.docker.com/r/sambaiz/docker-td-agent-build-amazon-linux/
FROMamazonlinux:2017.03 WORKDIR/tmp RUN yum -y update &amp;amp;&amp;amp; \  yum groupinstall -y &amp;#34;Development Tools&amp;#34; &amp;amp;&amp;amp; \  yum install -y ruby23 ruby23-devel &amp;amp;&amp;amp; \  gem install bundler io-console &amp;amp;&amp;amp; \  git clone https://github.</description>
    </item>
    
    <item>
      <title>FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ</title>
      <link>https://www.sambaiz.net/article/84/</link>
      <pubDate>Wed, 15 Mar 2017 23:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/84/</guid>
      <description>KPL(Kinesis Producer Library)とは Developing Amazon Kinesis Streams Producers Using the Amazon Kinesis Producer Library - Amazon Kinesis Streams
Kinesisに送るとき、自動リトライしてくれたり、レコードをまとめてスループットを向上してくれたりするアプリケーション。Protobufを使っている。 普通に送るとどんなに小さくてもシャード*1000レコード/秒しか最大でPUTできないのを、KPLを使ってまとめることで増やすことができる。
fluentdで送る aws-fluent-plugin-kinesisでkinesis_producerを指定するとKPLを使って送信する。
&amp;lt;kinesis_producer&amp;gt;の中にKPLの設定を書くことができる。
&amp;lt;kinesis_producer&amp;gt; record_max_buffered_time 10 &amp;lt;/kinesis_producer&amp;gt; record_max_bufferd_time はバッファされたレコードが送られるまでの最大時間(ms)。デフォルトは100ms。この時間が経つか、他のリミットに当たったらレコードは送られる。
 AggregationMaxCount: 一つのレコードにまとめる最大レコード数 AggregationMaxSize: まとめたレコードの最大バイト数 CollectionMaxCount: PutRecordsで送る最大アイテム数 CollectionMaxSize: PutRecordsで送るデータ量  CloudWatchに送るmetrics_levelはデフォルトでdetailedになっていて、 コンソールのメトリクスからstream名で検索すると KinesisProducerLibraryにUserRecordsPerKinesisRecordや、UserRecordsDataPut、BufferingTime、RequestTimeなどいろいろ表示される。
とりあえず試しにこんな設定で送ってみる。
&amp;lt;match hoge.log&amp;gt; @type kinesis_producer region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt; Lambdaで読む まとめられたレコードをkinesis-aggregationで分解して読む。 今回はNode.jsでやる。
$ npm install --save aws-kinesis-agg 注意する必要があるのはドキュメントの情報が古くて、 関数の引数が足りないこと。第二引数のcomputeChecksumsが抜けているので気付かないと一つずつずれていくことになる。</description>
    </item>
    
    <item>
      <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
      <link>https://www.sambaiz.net/article/73/</link>
      <pubDate>Sun, 26 Feb 2017 18:56:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/73/</guid>
      <description>aws-fluent-plugin-kinesisでKinesis Streamsに送り、Lambdaで読んでS3に保存する。 要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。
fluentdで送る $ td-agent-gem install fluent-plugin-kinesis try_flush_intervalとqueued_chunk_flush_intervalはドキュメントには載っていないが、 以下のページによるとそれぞれqueueに次のchunkがないときとあるときのflushする間隔。 いずれもデフォルトは1だが、これを減らすことでもっと頻繁に吐き出されるようになるらしい。
Fluentd の out_forward と BufferedOutput
あとシャードに振り分けるためのpartition_key を指定できる。デフォルトはランダム。
&amp;lt;source&amp;gt; @type tail path /var/log/td-agent/hoge.log pos_file /etc/td-agent/log.pos tag hoge.log format json time_key timestamp # 2017-01-01T01:01:01+0900 time_format %Y-%m-%dT%H:%M:%S%z &amp;lt;/source&amp;gt; &amp;lt;match hoge.log&amp;gt; @type kinesis_streams region ap-northeast-1 stream_name teststream include_time_key true flush_interval 1 buffer_chunk_limit 1m try_flush_interval 0.1 queued_chunk_flush_interval 0.01 num_threads 15 &amp;lt;/match&amp;gt; いくつか送ってみる。
for i in `seq 1 1000` do echo &amp;#39;{&amp;#34;hoge&amp;#34;: &amp;#34;fuga&amp;#34;, &amp;#34;timestamp&amp;#34;: &amp;#34;2017-01-01T01:01:01+0900&amp;#34;}&amp;#39; &amp;gt;&amp;gt; /var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する</title>
      <link>https://www.sambaiz.net/article/66/</link>
      <pubDate>Sun, 19 Feb 2017 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/66/</guid>
      <description>fluentdのmonitor_agent メトリクスをjsonで返すAPIを提供する。
&amp;lt;source&amp;gt; @type monitor_agent bind 0.0.0.0 port 24220 &amp;lt;/source&amp;gt; $ curl localhost:24220/api/plugins.json | jq { &amp;#34;plugins&amp;#34;: [ { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590d8c250&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;input&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;forward&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;forward&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;24222&amp;#34;, &amp;#34;bind&amp;#34;: &amp;#34;0.0.0.0&amp;#34; }, &amp;#34;output_plugin&amp;#34;: false, &amp;#34;retry_count&amp;#34;: null }, { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590d894c4&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;input&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;monitor_agent&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;monitor_agent&amp;#34;, &amp;#34;bind&amp;#34;: &amp;#34;0.0.0.0&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;24220&amp;#34; }, &amp;#34;output_plugin&amp;#34;: false, &amp;#34;retry_count&amp;#34;: null }, { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590dc1f2c&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;output&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>fluentd自身のログを拾う</title>
      <link>https://www.sambaiz.net/article/64/</link>
      <pubDate>Tue, 14 Feb 2017 21:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/64/</guid>
      <description>fluentdは自身のログもfluent.errorのようなタグでイベントとして流す。
バッファを0にして意図的にエラーを発生させてみる。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; # throw away &amp;lt;match fluent.info&amp;gt; @type null &amp;lt;/match&amp;gt; &amp;lt;match fluent.**&amp;gt; @type stdout &amp;lt;/match&amp;gt; # error! &amp;lt;match **&amp;gt; @type file path /var/log/td-agent/hoge.log buffer_chunk_limit 0 buffer_queue_limit 0 &amp;lt;/match&amp;gt; すると、こんなのがtd-agent.logに出力される。
fluent.error: {&amp;#34;error&amp;#34;:&amp;#34;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;#34;,&amp;#34;error_class&amp;#34;:&amp;#34;Fluent::BufferQueueLimitError&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;#34;} ただ、これだとaggregatorに集めたときにどのサーバーのfluentdに問題が発生してるのか分からない。 そこでホスト名を追加する。
fluentdのrecord_transformerでログを加工する - sambaiz.net
&amp;lt;filter fluent.**&amp;gt; @type record_transformer enable_ruby &amp;lt;record&amp;gt; hostname &amp;#34;#{Socket.gethostname}&amp;#34; tag ${tag} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; fluent.error: {&amp;#34;error&amp;#34;:&amp;#34;#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt;&amp;#34;,&amp;#34;error_class&amp;#34;:&amp;#34;Fluent::BufferQueueLimitError&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;forward error error=#&amp;lt;Fluent::BufferQueueLimitError: queue size exceeds limit&amp;gt; error_class=Fluent::BufferQueueLimitError&amp;#34;, &amp;#34;hostname&amp;#34;:&amp;#34;*****&amp;#34;,&amp;#34;tag&amp;#34;:&amp;#34;fluent.</description>
    </item>
    
    <item>
      <title>fluentdのrecord_transformerでログを加工する</title>
      <link>https://www.sambaiz.net/article/55/</link>
      <pubDate>Fri, 03 Feb 2017 21:14:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/55/</guid>
      <description>http://docs.fluentd.org/v0.12/articles/filter_record_transformer
追加したり、編集したり、削除したりできるフィルタ。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;filter hoge.log&amp;gt; @type record_transformer enable_ruby auto_typecast true remove_keys b,d &amp;lt;record&amp;gt; what_is_tag ${tag} what_is_a ${record[&amp;#34;a&amp;#34;]} what_is_c_of_b_add_1 ${record[&amp;#34;b&amp;#34;][&amp;#34;c&amp;#34;] + 1} &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt; &amp;lt;match hoge.log&amp;gt; @type stdout &amp;lt;/match&amp;gt; この例だとタグを値に持つ&amp;quot;what_is_tag&amp;quot;、aを値に持つ&amp;quot;what_is_a&amp;quot;、b.cの値に1を足す&amp;quot;what_is_c_of_b_add_1&amp;quot;が追加され、 bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。
auto_typecastをtrueにしないと&amp;quot;what_is_c_of_b_add_1&amp;quot;の値がstringになる。
$ echo &amp;#39;{&amp;#34;a&amp;#34;: &amp;#34;hoge&amp;#34;, &amp;#34;b&amp;#34;: {&amp;#34;c&amp;#34;: 1}, &amp;#34;d&amp;#34;: &amp;#34;fuga&amp;#34;}&amp;#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.log hoge.log: {&amp;#34;a&amp;#34;:&amp;#34;hoge&amp;#34;,&amp;#34;what_is_tag&amp;#34;:&amp;#34;hoge.log&amp;#34;,&amp;#34;what_is_a&amp;#34;:&amp;#34;hoge&amp;#34;,&amp;#34;what_is_c_of_b_add_1&amp;#34;:2} エラーが起きるとnullになるが、それ以外の処理はされる。
$ echo &amp;#39;{&amp;#34;a&amp;#34;: &amp;#34;hoge&amp;#34;, &amp;#34;b&amp;#34;: {&amp;#34;c&amp;#34;: &amp;#34;error!&amp;#34;}, &amp;#34;d&amp;#34;: &amp;#34;fuga&amp;#34;}&amp;#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log $ tail /var/log/td-agent/td-agent.</description>
    </item>
    
    <item>
      <title>fluentdでElasticsearchに送る</title>
      <link>https://www.sambaiz.net/article/54/</link>
      <pubDate>Wed, 01 Feb 2017 21:51:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/54/</guid>
      <description>uken/fluent-plugin-elasticsearch
必要なものをいれていく。Amazon LinuxのAMIから。
 Failed to build gem native extension.  $ yum install -y ruby-devel  serverengine requires Ruby version &amp;gt;= 2.1.0.  rbenvでバージョンを上げる。
$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv $ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src $ echo &amp;#39;export PATH=&amp;#34;$HOME/.rbenv/bin:$PATH&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile $ ~/.rbenv/bin/rbenv init $ echo &amp;#39;eval &amp;#34;$(rbenv init -)&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile $ source ~/.bash_profile $ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build $ rbenv -v rbenv 1.1.0-2-g4f8925a  Ruby install aborted due to missing extensions  $ yum install -y openssl-devel readline-devel zlib-devel $ rbenv install -l 1.</description>
    </item>
    
    <item>
      <title>fluentdのforward</title>
      <link>https://www.sambaiz.net/article/51/</link>
      <pubDate>Wed, 25 Jan 2017 22:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/51/</guid>
      <description>td-agent間でログをやりとりするとき に使われるforwardについて。内部ではMessagePackを使っている。
forward input http://docs.fluentd.org/articles/in_forward
受け取る側。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;match **&amp;gt; @type stdout &amp;lt;/match&amp;gt; /etc/init.d/td-agent restartしてfluent-catで送ってみる。
$ echo &amp;#39;{&amp;#34;hoge&amp;#34;: &amp;#34;fuga&amp;#34;}&amp;#39; | /opt/td-agent/embedded/bin/fluent-cat -h xx.xx.xx.xx test.tag /var/log/td-agent/td-agent.logに出力される。
test.tag: {&amp;#34;hoge&amp;#34;:&amp;#34;fuga&amp;#34;} forward output http://docs.fluentd.org/articles/out_forward
http://docs.fluentd.org/articles/buffer-plugin-overview
送る側。
ポートはデフォルトで24224で、イベントの送信にTCPを、heartbeatにUDP(heartbeat_typeで変えられる)を使う。
flush_intervalははデフォルトで60秒。 確認のときは短くしておくと分かりやすい。 buffer_queueの一番上のチャンクがこの時間経過するか、サイズがbuffer_chunk_limitを超えると、一番下のチャンクが書き込まれ、新しいチャンクがpushされる。 chunkの数がbuffer_queue_limitに到達してしまうと新しいイベントは破棄されてしまうので リソースを圧迫(buffer_chunk_limit * buffer_queue_limit)しない程度に十分大きな数にしておき、 スパイクや障害時に備えておく。 buffer_typeはデフォルトがmemory。fileだとflush_at_shutdownのデフォルトがfalseなので注意。
&amp;lt;source&amp;gt; @type forward port 24224 bind 0.0.0.0 &amp;lt;/source&amp;gt; &amp;lt;match **&amp;gt; @type forward flush_interval 1s buffer_type file buffer_path /var/log/td-agent/forward-buf flush_at_shutdown true buffer_chunk_limit 256m &amp;lt;server&amp;gt; name log_server host xx.</description>
    </item>
    
    <item>
      <title>td-agentをビルドしてfluentdのバージョンを上げる</title>
      <link>https://www.sambaiz.net/article/32/</link>
      <pubDate>Sun, 06 Nov 2016 11:17:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/32/</guid>
      <description>$td-agent --version td-agent 0.12.26 td-agentって書いてあるけど、これがfluentdのバージョンらしい。
fluentdはv0.14からナノ秒で時間を持つようになった。 ただ、現行のtd-agent(v2.3.2)は上の通り古いバージョンを使っている。 0.14になるtd-agent-3はまだリリースされていないので、 自分でfluentdをv0.14.8に上げてビルドすることにした。
FROMubuntu:14.04 WORKDIR/tmp RUN apt-get update &amp;amp;&amp;amp; \  apt-get install -y git software-properties-common build-essential curl &amp;amp;&amp;amp; \  add-apt-repository -y ppa:brightbox/ruby-ng &amp;amp;&amp;amp; \  apt-get update &amp;amp;&amp;amp; \  apt-get install -y ruby2.3 ruby2.3-dev &amp;amp;&amp;amp; \  gem install bundler &amp;amp;&amp;amp; \  git clone https://github.com/treasure-data/omnibus-td-agent WORKDIR/tmp/omnibus-td-agent RUN sed -ie &amp;#34;s/^default_version.*$/default_version &amp;#39;3d1dd53f31d1fe49508f230a71a2b4c2ceb20f47&amp;#39;/&amp;#34; config/software/fluentd.rb &amp;amp;&amp;amp; \  sed -ie &amp;#34;s/^license_file.*$/license_file &amp;#39;LICENSE&amp;#39;/&amp;#34; config/projects/td-agent2.rb &amp;amp;&amp;amp; \  bundle install --binstubs &amp;amp;&amp;amp; \  bin/gem_downloader core_gems.</description>
    </item>
    
  </channel>
</rss>
