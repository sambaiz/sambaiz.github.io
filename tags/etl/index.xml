<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Etl on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/etl/</link>
    <description>Recent content in Etl on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Wed, 23 Oct 2024 01:17:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/tags/etl/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Apache Beam による ETL のマネージドサービス Dataflow のサンプルコード Word Count を読んで実行する</title>
      <link>https://www.sambaiz.net/article/501/</link>
      <pubDate>Wed, 23 Oct 2024 01:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/501/</guid>
      <description>&lt;p&gt;GCP の Dataflow はデータ処理のパイプラインを構築する OSS &lt;a href=&#34;https://beam.apache.org/&#34;&gt;Apache Beam&lt;/a&gt; による、ストリーミングおよびバッチ ETL のマネージドサービス。PubSub から BigQuery にデータを流したり、機械学習を行ったりすることができる。&lt;a href=&#34;https://cloud.google.com/dataflow/pricing&#34;&gt;料金&lt;/a&gt;はジョブに実行したリソースやシャッフルしたデータ量に対してかかる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Livy を EMR on EKS にインストールしSparkmagic でローカルの Jupyter Notebook から Spark のジョブを実行する</title>
      <link>https://www.sambaiz.net/article/486/</link>
      <pubDate>Wed, 22 May 2024 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/486/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://livy.apache.org/&#34;&gt;Apache Livy&lt;/a&gt; は Spark クラスタとやり取りするための REST API を提供し、&lt;a href=&#34;https://github.com/jupyter-incubator/sparkmagic&#34;&gt;Sparkmagic&lt;/a&gt; はこの API を呼ぶことで Jupyter Notebooks からリモートの Spark クラスタでジョブを実行する。Athena for Apache Spark でも使われていて、インタラクティブにジョブを実行し結果を確認できるのはデバッグやアドホックなクエリを実行したりするのに便利だ。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Task nodes で EMR クラスタのスケールインを高速化する</title>
      <link>https://www.sambaiz.net/article/445/</link>
      <pubDate>Sun, 19 Mar 2023 22:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/445/</guid>
      <description>&lt;p&gt;EMR クラスタは YARN の ResourceManager などが動く Master (primary) node と、 Core nodes および Task nodes から&lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html&#34;&gt;構成される&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/427/&#34;&gt;Hadoop YARN によってアプリケーションにリソースが割り当てられる流れと割り当てられているリソース量の確認 - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>CDK で EKS クラスタを立ち上げ EMR on EKS に登録し Spark のジョブを動かす</title>
      <link>https://www.sambaiz.net/article/434/</link>
      <pubDate>Mon, 02 Jan 2023 14:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/434/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/emr-eks.html&#34;&gt;EMR on EKS&lt;/a&gt; は EKS 上で Spark アプリケーションを動かすための API や&lt;a href=&#34;https://aws.amazon.com/jp/blogs/big-data/amazon-emr-on-eks-widens-the-performance-gap-run-apache-spark-workloads-5-37-times-faster-and-at-4-3-times-lower-cost/&#34;&gt;パフォーマンス最適化された&lt;/a&gt;ランタイム、History Serverなどを提供するマネージドサービス。&#xA;通常の EMR が Hadoop クラスタの管理も行うのに対して、EMR on EKS はコンテナの起動のみを担う。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Airflow の Callback で複数の Task からなる処理のリトライを行う</title>
      <link>https://www.sambaiz.net/article/432/</link>
      <pubDate>Sun, 18 Dec 2022 17:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/432/</guid>
      <description>&lt;p&gt;EMR クラスタで処理を行う際、EmrAddStepsOperator で EMR クラスタに Step を追加した後、EmrStepSensor でその実行が終わるのを待つが、&#xA;Step の処理が失敗しても Failed するのは Sensor の方なので、リトライしても Step が再実行されないという問題がある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Airflow で 過去の Task への依存を表す</title>
      <link>https://www.sambaiz.net/article/429/</link>
      <pubDate>Wed, 30 Nov 2022 09:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/429/</guid>
      <description>&lt;p&gt;定期的な集計の際に過去の集計値が必要になることがあるが、そのようなワークフローを単純に定期実行すると、処理が間に合わなかったり失敗した際にそれ以後の処理が連鎖的に失敗してしまう。&#xA;Airflow では次の方法で過去の Task への依存を記述することができ、これによって過去の集計が終わるのを待ったり、失敗時に依存しているものだけをまとめて再実行することができる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>CDK で Amazon Managed Workflow for Apache Airflow (MWAA) の環境を作成しワークフローを実行する</title>
      <link>https://www.sambaiz.net/article/428/</link>
      <pubDate>Mon, 28 Nov 2022 19:34:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/428/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/managed-workflows-for-apache-airflow&#34;&gt;Amazon Managed Workflow for Apache Airflow (MWAA)&lt;/a&gt; は&#xA;&lt;a href=&#34;https://airflow.apache.org/&#34;&gt;Apache Airflow&lt;/a&gt; のマネージドサービス。&#xA;サーバーレスの Step Functions とは異なりインスタンス時間のコストが&lt;a href=&#34;https://aws.amazon.com/managed-workflows-for-apache-airflow/pricing/&#34;&gt;かかる&lt;/a&gt;が、&#xA;Airflow の豊富な機能や、AWSを含むサードパーティの &lt;a href=&#34;https://airflow.apache.org/docs/#providers-packagesdocsapache-airflow-providersindexhtml&#34;&gt;Providers packages&lt;/a&gt; が利用できる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Docker Compose で Apache Airflow を起動しワークフローを実行する</title>
      <link>https://www.sambaiz.net/article/425/</link>
      <pubDate>Sat, 19 Nov 2022 16:52:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/425/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://airflow.apache.org/&#34;&gt;Apache Airflow&lt;/a&gt;はワークフローのスケジューリングやパイプラインの可視化などを行うOSS。&#xA;スケーラブルで豊富な機能を持ち、&#xA;リポジトリに含まれている AWS や Slack といったサードパーティの &lt;a href=&#34;https://airflow.apache.org/docs/#providers-packagesdocsapache-airflow-providersindexhtml&#34;&gt;Providers packages&lt;/a&gt; に加えて、&#xA;自前の Operator を実装して拡張できるようになっている。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ScalaでSparkのアプリケーションを開発してGitHub ActionsでデプロイしEMRでリモートデバッグする</title>
      <link>https://www.sambaiz.net/article/420/</link>
      <pubDate>Fri, 21 Oct 2022 23:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/420/</guid>
      <description>&lt;p&gt;Spark は開発で用いられている Scala に加えて Java や Python のAPIを提供しており、技術スタックや他コンポーネントとの兼ね合いなどによって選択することができる。&lt;/p&gt;&#xA;&lt;p&gt;Python は データ分析や機械学習のスキルセットとの親和性の高さや Glue Studio 上で編集して実行できる手軽さがある一方、エラーが分かりづらく JVM と Python Worker 間でデータをやり取りする必要があるのでパフォーマンスの点でも不利。&#xA;また、JVM の制御の外である Python インタプリタが YARN などのリソースマネージャによって割り当てられた以上のメモリを確保してしまうと executor が kill されてしまう。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SparkをビルドしIntelliJでリモートデバッグする</title>
      <link>https://www.sambaiz.net/article/419/</link>
      <pubDate>Sun, 09 Oct 2022 19:06:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/419/</guid>
      <description>&lt;h2 id=&#34;コマンドラインでのビルド&#34;&gt;&lt;a href=&#34;https://spark.apache.org/docs/3.3.0/building-spark.html&#34;&gt;コマンドラインでのビルド&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ git clone &lt;span style=&#34;color:#6272a4&#34;&gt;--branch v3.3.0 --depth 1 https://github.com/apache/spark.git &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://asdf-vm.com/guide/getting-started.html#_3-install-asdf&#34;&gt;asdf&lt;/a&gt; で Java 8 をインストールする。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ brew install asdf&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ echo &lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;e &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;\n. $(brew --prefix asdf)/libexec/asdf.sh&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ${ZDOTDIR:&lt;span style=&#34;color:#ff79c6&#34;&gt;-~&lt;/span&gt;}&lt;span style=&#34;color:#ff79c6&#34;&gt;/&lt;/span&gt;.zshrc&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf &lt;span style=&#34;color:#6272a4&#34;&gt;--version&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#6272a4&#34;&gt;&lt;/span&gt;v0.&lt;span style=&#34;color:#bd93f9&#34;&gt;10&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;2&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf plugin&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;add&lt;/span&gt; java&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf list&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;all&lt;/span&gt; java&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf install java corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf &lt;span style=&#34;color:#ff79c6&#34;&gt;global&lt;/span&gt; java corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ echo &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;. ~/.asdf/plugins/java/set-java-home.zsh&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;~/&lt;/span&gt;.zprofile&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ java &lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;version&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;openjdk &lt;span style=&#34;color:#ff79c6&#34;&gt;version&lt;/span&gt; &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;1.8.0_342&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenJDK Runtime Environment Corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt; (build &lt;span style=&#34;color:#bd93f9&#34;&gt;1&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;_342&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;b07)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenJDK &lt;span style=&#34;color:#bd93f9&#34;&gt;64&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;Bit&lt;/span&gt; Server VM Corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt; (build &lt;span style=&#34;color:#bd93f9&#34;&gt;25&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;b07, mixed &lt;span style=&#34;color:#ff79c6&#34;&gt;mode&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ビルドが通ることを確認する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark SQLのJOIN時に余分なパーティションが読まれる例とDynamic Partition Pruning (DPP)</title>
      <link>https://www.sambaiz.net/article/417/</link>
      <pubDate>Sun, 11 Sep 2022 16:58:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/417/</guid>
      <description>&lt;h2 id=&#34;クエリの例&#34;&gt;クエリの例&lt;/h2&gt;&#xA;&lt;p&gt;Spark 3.1.1 ベースの Glue 3.0 で、TPC-DS (scale=1000) の sales テーブルと sales のIDでパーティションを切った store_sales テーブルを JOIN する次のクエリを実行すると 10 DPS で 1分4秒 かかった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athena v2でparquetをソースとしmapフィールドを持つテーブルのクエリが成功したり失敗したりする原因</title>
      <link>https://www.sambaiz.net/article/415/</link>
      <pubDate>Tue, 16 Aug 2022 21:26:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/415/</guid>
      <description>&lt;p&gt;次のようなmapのフィールドを含むログをjsonなどで出力し、Glue Studioでparquetに変換してAthenaでクエリを実行すると、ものによってクエリが成功したり失敗したりする。&lt;/p&gt;</description>
    </item>
    <item>
      <title>EMRでSparkを動かす際の設定</title>
      <link>https://www.sambaiz.net/article/414/</link>
      <pubDate>Sat, 13 Aug 2022 19:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/414/</guid>
      <description>&lt;p&gt;AWSでSparkのアプリケーションを動かすマネージドサービスにはEMRとGlueがあって、&#xA;Glueがサーバーレスで手軽にETLジョブを動かすことができる一方、EMRはリソースやパラメータを細かくチューニングすることができる。&#xA;裏を返せば設定が適切でないとリソースをフル活用できず、特にメモリについては余っているにもかかわらずOOMで失敗してしまうことがある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS CLIでEMRクラスタを立ち上げSparkのアプリケーションを実行する</title>
      <link>https://www.sambaiz.net/article/409/</link>
      <pubDate>Wed, 22 Jun 2022 00:05:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/409/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/emr/&#34;&gt;Amazon EMR&lt;/a&gt;はEC2やEKS上にSparkやHive, Prestoのクラスタを構築するサービス。&#xA;SparkのマネージドサービスであるGlueと比べると、Glueはサーバーレスで手軽にSparkによるETL処理をを行えるのに対して、EMRはスポットインスタンスなどを利用したコストパフォーマンスの良さと詳細なチューニングを行うことができるという特長があるが、&lt;a href=&#34;https://aws.amazon.com/jp/emr/serverless/&#34;&gt;EMR Serverless&lt;/a&gt;がリリースされたのでその差は少し縮まっているように感じる。Glueにはスキーマを指定する必要がない&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html&#34;&gt;DynamicFrame&lt;/a&gt;や前の続きから実行できるBookmarkといった便利な機能もあるが、重い処理を立て続けに実行するとコストが嵩んだりDPUなどのクォータに引っかかることもあるので適宜使い分けていきたい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athenaで他アカウントのテーブルを参照するために必要な設定</title>
      <link>https://www.sambaiz.net/article/405/</link>
      <pubDate>Tue, 17 May 2022 23:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/405/</guid>
      <description>&lt;div class=&#34;img_container&#34;&gt;&lt;a href=&#34;https://www.sambaiz.net/article/405/images/structure.png&#34;&gt;&#xA;    &lt;img style=&#34;max-width: 100%; width: auto; height: auto;&#34; src=&#34;https://www.sambaiz.net/article/405/images/structure_hu_6504d01ea0a575e6.png&#34; width=&#34;600&#34; height=&#34;197&#34; alt=&#34;構成&#34;&gt;&#xA;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/392/&#34;&gt;Redshift Serverlessと他のサーバーレス集計サービス、Glue Data Catalogのテーブルへのクエリ実行 - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;クエリを実行するBorrower Accountから、Data Catalogやデータが存在するOwner Accountのリソースにアクセスする必要がある。&#xA;他アカウントのリソースにアクセスする手段としてはアクセストークンやAssumeRoleによるものもあるが、&#xA;今回の場合クエリの実行に用いるRoleにBorrower AccountのAthenaの権限も必要なので、1つのRoleで両方のアカウントのリソースにアクセスできるようにする。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athenaのデータソースコネクタとユーザー定義関数(UDF)を実装する</title>
      <link>https://www.sambaiz.net/article/402/</link>
      <pubDate>Sat, 23 Apr 2022 18:09:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/402/</guid>
      <description>&lt;p&gt;AthenaにはLambdaをコネクタとしてS3以外のデータソースにアクセスできるFederate Queryという機能があって、&lt;a href=&#34;https://github.com/awslabs/aws-athena-query-federation&#34;&gt;公式のリポジトリ&lt;/a&gt;でBigQueryやSnowflakeなど様々なデータソースのコネクタが提供されているが自作することもできる。&#xA;今回は&lt;a href=&#34;https://github.com/awslabs/aws-athena-query-federation/tree/master/athena-example&#34;&gt;Example Connector&lt;/a&gt;を参考にしながら最低限のコネクタを実装しその動作を確認する。全体のコードは&lt;a href=&#34;https://github.com/sambaiz/athena-connector-udf-example&#34;&gt;GitHub&lt;/a&gt;にある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Redshift ServerlessとAthenaの性能をTPC-DSのクエリで比較する</title>
      <link>https://www.sambaiz.net/article/397/</link>
      <pubDate>Sun, 20 Feb 2022 01:49:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/397/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/392/&#34;&gt;Redshift Serverlessと他のサーバーレス集計サービス、Glue Data Catalogのテーブルへのクエリ実行 - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;現在PreviewのRedshift ServerlessとAthenaでデータベースのベンチマークであるTPC-DSのクエリを実行し性能を比較する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Redshift Serverlessと他のサーバーレス集計サービス、Glue Data Catalogのテーブルへのクエリ実行</title>
      <link>https://www.sambaiz.net/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/392/</guid>
      <description>&lt;h2 id=&#34;redshift-serverless&#34;&gt;Redshift Serverless&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/redshift/redshift-serverless/&#34;&gt;Redshift Serverless&lt;/a&gt;は今年のre:Inventで&lt;a href=&#34;https://www.youtube.com/watch?v=x0xmqJrAVM8&#34;&gt;発表された&lt;/a&gt;、インスタンスを立てることなく従量課金でペタバイトスケールのDWHであるRedshiftを使える機能。&#xA;S3のデータを直接参照できる&lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html&#34;&gt;Redshift Spectrum&lt;/a&gt;やRDSへの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/federated-overview.html&#34;&gt;Federated Query&lt;/a&gt;、機械学習の&lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/machine_learning.html&#34;&gt;Redshift ML&lt;/a&gt;も使える。&#xA;分析のような不定期に発生する需要のためにインスタンスを立てておくのはコストの上でハードルが高かったのでこのアップデートは嬉しい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AthenaのFederated QueryでTPC-DS Connectorを用いてデータを生成する</title>
      <link>https://www.sambaiz.net/article/391/</link>
      <pubDate>Sat, 25 Dec 2021 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/391/</guid>
      <description>&lt;p&gt;Athenaの&lt;a href=&#34;https://docs.aws.amazon.com/athena/latest/ug/connect-to-a-data-source.html&#34;&gt;Federated Query&lt;/a&gt;は&#xA;データソースコネクタとなるLambdaを通してDynamoDBやRDSといったS3以外のデータソースにクエリを実行できる機能。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sparkでstructをmapとして扱いexplodeで複数行に展開できるようにする</title>
      <link>https://www.sambaiz.net/article/384/</link>
      <pubDate>Wed, 13 Oct 2021 02:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/384/</guid>
      <description>&lt;p&gt;Sparkでschemaを指定せずjsonなどを&lt;a href=&#34;https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrameReader.json.html&#34;&gt;読み込むと&lt;/a&gt;次のように入力データから自動で決定される。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/415/&#34;&gt;Athena v2でparquetをソースとしmapフィールドを持つテーブルのクエリが成功したり失敗したりする原因 - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>SparkのWeb UIでJobのStageとExecutorによるTask分散、SQLのplanを確認する</title>
      <link>https://www.sambaiz.net/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/382/</guid>
      <description>&lt;p&gt;Spark の &lt;a href=&#34;https://spark.apache.org/docs/latest/web-ui.html&#34;&gt;Web UI&lt;/a&gt; は Job や Executor をモニタリングするためのツール。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/aws-samples/aws-glue-samples/tree/b76ad0583bdc66e9e5a903f9da3a953c9f6aac4f&#34;&gt;aws-glue-samples&lt;/a&gt;から maven:3.6-amazoncorretto-8 ベースでSparkを動かすDockerfileを持ってきて、&#xA;&lt;a href=&#34;https://spark.apache.org/docs/latest/monitoring.html&#34;&gt;History Server&lt;/a&gt;を&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui-history.html#monitor-spark-ui-history-local&#34;&gt;起動する&lt;/a&gt;。Glue で出力された EventLog のパスと認証情報を渡している。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Glue DataBrewでデータを可視化して分析するProjectと機械学習の前処理を行うJobをCDKで作成する</title>
      <link>https://www.sambaiz.net/article/381/</link>
      <pubDate>Mon, 27 Sep 2021 16:42:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/381/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/glue/features/databrew/&#34;&gt;Glue DataBrew&lt;/a&gt;は、データを可視化してパラメータ間の相関を見たり、カテゴリー変数のエンコードや、欠損値や外れ値を置換する処理をコードなしで実行できるマネージドサービス。Kaggleの&lt;a href=&#34;https://www.kaggle.com/c/house-prices-advanced-regression-techniques&#34;&gt;House Prices Competiton&lt;/a&gt;の学習データで試してみる。全体のコードは&lt;a href=&#34;https://github.com/sambaiz/cdk-databrew-sample&#34;&gt;GitHub&lt;/a&gt;にある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GlueのカスタムコネクタでBigQueryに接続する</title>
      <link>https://www.sambaiz.net/article/372/</link>
      <pubDate>Tue, 13 Jul 2021 21:02:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/372/</guid>
      <description>&lt;p&gt;GlueはConnectorによって様々なデータソースに対応していて、RDSやMongoDBなど標準で提供されているもの以外にも&#xA;&lt;a href=&#34;https://aws.amazon.com/jp/about-aws/whats-new/2020/12/aws-glue-launches-aws-glue-custom-connectors/&#34;&gt;カスタムコネクタ&lt;/a&gt;を用いることで接続できる。今回はMarketplaceで提供されているBigQueryのカスタムコネクタを用いてBigQueryのテーブルの内容をS3に出力するJobを作成する。&lt;/p&gt;&#xA;&lt;p&gt;GlueのETL JobをGUIで構築したりモニタリングできるサービス、Glue StudioからMarketplaceに飛んで&#xA;&lt;a href=&#34;https://aws.amazon.com/marketplace/pp/prodview-w2ranrogj3xmm?ref_=beagle&amp;amp;applicationId=GlueStudio&#34;&gt;AWS Glue Connector for Google BigQuery&lt;/a&gt;をSubscribeする。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athena(Presto)とGlue(Spark)で同じクエリを実行した際に異なる値が返る原因</title>
      <link>https://www.sambaiz.net/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/370/</guid>
      <description>&lt;p&gt;AWSではSQL-likeなクエリで集計を行うマネージドなサービスが複数あり、&#xA;アドホックな集計はGlueのデータカタログでテーブルを共有して手軽にクエリを実行できるPrestoベースのAthena、&#xA;重いバッチ集計はリソースや時間の制約を回避できるSparkベースのGlueといったように併用することができる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>CDKでGlue Data CatalogのDatabase,Table,Partition,Crawlerを作成する</title>
      <link>https://www.sambaiz.net/article/357/</link>
      <pubDate>Sun, 09 May 2021 01:52:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/357/</guid>
      <description>&lt;p&gt;CDKでGlue Data CatlogのDatabase,Table,Partition,Crawlerを作成する。&#xA;PartitionやCrawlerはまだL2 constructが&lt;a href=&#34;https://github.com/aws/aws-cdk/issues/8863&#34;&gt;存在しない&lt;/a&gt;。&lt;code&gt;storageDescriptor&lt;/code&gt;の設定は&lt;a href=&#34;https://github.com/aws/aws-cdk/blob/v1.102.0/packages/@aws-cdk/aws-glue/lib/table.ts#L267&#34;&gt;Tableの実装&lt;/a&gt;を参考にした。&lt;/p&gt;</description>
    </item>
    <item>
      <title>CDKでKinesis Data Analytics上にPyFlinkのコードをデプロイして動かす</title>
      <link>https://www.sambaiz.net/article/334/</link>
      <pubDate>Sat, 24 Apr 2021 23:48:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/334/</guid>
      <description>&lt;p&gt;KDAが&lt;a href=&#34;https://aws.amazon.com/jp/about-aws/whats-new/2021/03/amazon-kinesis-data-analytics-now-supports-python-with-apache-flink-v1-11/&#34;&gt;PyFlinkをサポート&lt;/a&gt;したのでCDKで構築して動かしてみる。&#xA;全体のコードは&lt;a href=&#34;https://github.com/sambaiz/cdk-kda-pyflink-sample&#34;&gt;GitHub&lt;/a&gt;にある。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/302/&#34;&gt;Kinesis Data AnalyticsのSQL, Lambdaへの出力とCDKによるリソースの作成 - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;今回動かすのは次の、KDSから流れてきたデータにクエリを実行し、その結果をS3に書き込む簡単なコード。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS GlueのJobのBookmarkを有効にして前回の続きから処理を行う</title>
      <link>https://www.sambaiz.net/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/333/</guid>
      <description>&lt;p&gt;GlueのJobの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-continuations.html&#34;&gt;Bookmark&lt;/a&gt;は&#xA;どこまで処理したかを記録し、次回はその続きから実行できるようにする機能。&#xA;1.0以前は対応していなかったParquetやORCも今は対応している。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athena(Presto)でWindow関数を用いた集計を行う</title>
      <link>https://www.sambaiz.net/article/328/</link>
      <pubDate>Wed, 24 Feb 2021 22:03:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/328/</guid>
      <description>&lt;p&gt;Athena(Presto)で&lt;code&gt;SUM()&lt;/code&gt;や&lt;code&gt;AVG()&lt;/code&gt;といった集計関数に&lt;code&gt;OVER&lt;/code&gt;を付けてWindow集計を行う。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://prestodb.io/docs/current/functions/window.html&#34;&gt;Window Functions — Presto 0.247 Documentation&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;次のテストデータを使う。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GoでAthenaのクエリを実行する</title>
      <link>https://www.sambaiz.net/article/309/</link>
      <pubDate>Sat, 14 Nov 2020 16:19:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/309/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/segmentio/go-athena&#34;&gt;segmentio/go-athena&lt;/a&gt;を使う。&lt;code&gt;database/sql&lt;/code&gt;のドライバーとして提供されていて、&#xA;&lt;a href=&#34;https://github.com/segmentio/go-athena/blob/dfa5f18189303b39c4ccc2f0c292947540214e63/conn.go#L60&#34;&gt;StartQueryExecution()&lt;/a&gt;と&#xA;&lt;a href=&#34;https://github.com/segmentio/go-athena/blob/dfa5f18189303b39c4ccc2f0c292947540214e63/conn.go#L86&#34;&gt;stateのポーリング&lt;/a&gt;、&#xA;&lt;a href=&#34;https://github.com/segmentio/go-athena/blob/dfa5f18189303b39c4ccc2f0c292947540214e63/value.go#L40&#34;&gt;値のキャスト&lt;/a&gt;を行う。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;package&lt;/span&gt; main&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;import&lt;/span&gt; (&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;database/sql&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;errors&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;github.com/aws/aws-sdk-go/service/sts&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;_ &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;github.com/segmentio/go-athena&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#50fa7b&#34;&gt;outputLocation&lt;/span&gt;() (&lt;span style=&#34;color:#8be9fd&#34;&gt;string&lt;/span&gt;, &lt;span style=&#34;color:#8be9fd&#34;&gt;error&lt;/span&gt;) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;svc &lt;span style=&#34;color:#ff79c6&#34;&gt;:=&lt;/span&gt; sts.&lt;span style=&#34;color:#50fa7b&#34;&gt;New&lt;/span&gt;(session.&lt;span style=&#34;color:#50fa7b&#34;&gt;Must&lt;/span&gt;(session.&lt;span style=&#34;color:#50fa7b&#34;&gt;NewSession&lt;/span&gt;()))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;result, err &lt;span style=&#34;color:#ff79c6&#34;&gt;:=&lt;/span&gt; svc.&lt;span style=&#34;color:#50fa7b&#34;&gt;GetCallerIdentity&lt;/span&gt;(&lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;amp;&lt;/span&gt;sts.GetCallerIdentityInput{})&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;if&lt;/span&gt; err &lt;span style=&#34;color:#ff79c6&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;, err&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;if&lt;/span&gt; result.Account &lt;span style=&#34;color:#ff79c6&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;||&lt;/span&gt; svc.Config.Region &lt;span style=&#34;color:#ff79c6&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;, errors.&lt;span style=&#34;color:#50fa7b&#34;&gt;New&lt;/span&gt;(&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;account or region is nil&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;return&lt;/span&gt; fmt.&lt;span style=&#34;color:#50fa7b&#34;&gt;Sprintf&lt;/span&gt;(&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;s3://aws-athena-query-results-%s-%s&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ff79c6&#34;&gt;*&lt;/span&gt;result.Account, &lt;span style=&#34;color:#ff79c6&#34;&gt;*&lt;/span&gt;svc.Config.Region), &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#50fa7b&#34;&gt;execute&lt;/span&gt;(query &lt;span style=&#34;color:#8be9fd&#34;&gt;string&lt;/span&gt;) (&lt;span style=&#34;color:#ff79c6&#34;&gt;*&lt;/span&gt;sql.Rows, &lt;span style=&#34;color:#8be9fd&#34;&gt;error&lt;/span&gt;) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;loc, err &lt;span style=&#34;color:#ff79c6&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#50fa7b&#34;&gt;outputLocation&lt;/span&gt;()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;if&lt;/span&gt; err &lt;span style=&#34;color:#ff79c6&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt;, err&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;db, err &lt;span style=&#34;color:#ff79c6&#34;&gt;:=&lt;/span&gt; sql.&lt;span style=&#34;color:#50fa7b&#34;&gt;Open&lt;/span&gt;(&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;athena&amp;#34;&lt;/span&gt;, fmt.&lt;span style=&#34;color:#50fa7b&#34;&gt;Sprintf&lt;/span&gt;(&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;db=default&amp;amp;output_location=%s&amp;#34;&lt;/span&gt;, loc))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;if&lt;/span&gt; err &lt;span style=&#34;color:#ff79c6&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt;, err&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;return&lt;/span&gt; db.&lt;span style=&#34;color:#50fa7b&#34;&gt;Query&lt;/span&gt;(query)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#50fa7b&#34;&gt;main&lt;/span&gt;() {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;rows, err &lt;span style=&#34;color:#ff79c6&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#50fa7b&#34;&gt;execute&lt;/span&gt;(&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;SELECT 1 as v, 2 as w FROM hoge.fuga&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;if&lt;/span&gt; err &lt;span style=&#34;color:#ff79c6&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;nil&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;panic&lt;/span&gt;(err)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#ff79c6&#34;&gt;for&lt;/span&gt; rows.&lt;span style=&#34;color:#50fa7b&#34;&gt;Next&lt;/span&gt;() {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;var&lt;/span&gt; v, w &lt;span style=&#34;color:#8be9fd&#34;&gt;int&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;rows.&lt;span style=&#34;color:#50fa7b&#34;&gt;Scan&lt;/span&gt;(&lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;amp;&lt;/span&gt;v, &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;amp;&lt;/span&gt;w)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;fmt.&lt;span style=&#34;color:#50fa7b&#34;&gt;Println&lt;/span&gt;(v, w)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Kinesis Data AnalyticsのSQL, Lambdaへの出力とCDKによるリソースの作成</title>
      <link>https://www.sambaiz.net/article/302/</link>
      <pubDate>Sat, 03 Oct 2020 19:44:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/302/</guid>
      <description>&lt;p&gt;Kinesis Data Analyticsで&lt;a href=&#34;https://docs.aws.amazon.com/kinesisanalytics/latest/dev/streaming-sql-concepts.html&#34;&gt;Streaming SQL&lt;/a&gt;を実行し、&#xA;Lambdaに送る。ほかの接続先としてData StreamやFirehoseがあり、フォーマットはJSONとCSVから選べる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>VSCodeのDocker開発コンテナでJupyter Notebookを開いてAthenaのクエリを実行し可視化する</title>
      <link>https://www.sambaiz.net/article/294/</link>
      <pubDate>Fri, 04 Sep 2020 19:34:04 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/294/</guid>
      <description>&lt;p&gt;ローカルでJupyter Notebookを動かすために以前は&lt;a href=&#34;https://hub.docker.com/r/jupyter/datascience-notebook/&#34;&gt;jupyter/datascience-notebook&lt;/a&gt;のイメージを立ち上げていた。&#xA;Notebookはエディタとしての機能に乏しいため通常のコードを書くのが大変だったのだが、&#xA;VSCodeのPython extensionにはJupyter notebookサポートが入っていてそのまま開けて実行できるのを知ったので移行することにした。&#xA;今回はVSCodeのDocker開発コンテナからNotebookを開いてAthenaのクエリを実行し可視化する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache SparkのRDD, DataFrame, DataSetとAction, Transformation</title>
      <link>https://www.sambaiz.net/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/208/</guid>
      <description>&lt;h2 id=&#34;sparkとは&#34;&gt;Sparkとは&lt;/h2&gt;&#xA;&lt;p&gt;ハイパフォーマンスな汎用分散処理システム。&#xA;HDFSやS3といった分散ストレージとHadoop YARNといったクラスタマネージャと共に使われる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する</title>
      <link>https://www.sambaiz.net/article/203/</link>
      <pubDate>Tue, 01 Jan 2019 17:50:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/203/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/glue/&#34;&gt;AWS Glue&lt;/a&gt;はマネージドなETL(Extract/Transform/Load)サービスで、&lt;a href=&#34;https://spark.apache.org/&#34;&gt;Spark&lt;/a&gt;を使ってS3などにあるデータを読み込み加工して変換出力したり、AthenaやRedshift Spectrumで参照できるデータカタログを提供する。&#xA;今回はS3のCSVを読み込んで加工し、列指向フォーマットParquetに変換しパーティションを切って出力、その後クローラを回してデータカタログにテーブルを作成してAthenaで参照できることを確認する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athenaのmigrationやpartitionするathena-adminを作った</title>
      <link>https://www.sambaiz.net/article/145/</link>
      <pubDate>Sun, 24 Dec 2017 23:31:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/145/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/athena-admin&#34;&gt;https://github.com/sambaiz/athena-admin&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;AthenaはS3をデータソースとするマネージドなデータ分析基盤。Prestoベースで標準SQLを実行できる。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/athena/pricing/&#34;&gt;料金&lt;/a&gt;はスキャンしたデータ量にかかり、$5/TB。1MB切り上げで、10MB以下のクエリは10MBになる。&#xA;データ量に対してかなり安く使えるものの、フルスキャンしてしまうとBigQueryと同様にお金が溶けてしまうので、大抵はパーティションを切ることになるのだが都度locationを指定して ADD PARTITION を実行するのは大変。さらにスキーマを変更するのにも ALTER TABLE ADD COLUMNS などはないのでテーブルを作り直すことになるが、当然パーティションも全部作り直すことになる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
      <link>https://www.sambaiz.net/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/128/</guid>
      <description>&lt;h2 id=&#34;hiveとは&#34;&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/Home#Home-ApacheHive&#34;&gt;Hiveとは&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;SQLを拡張したHiveQLでHDFSなどのデータソースにアクセスできるHadoopのデータウェアハウスソフトウェア。&#xA;クエリを送るとMapReduceやSpark、Tezのジョブが実行される。&#xA;耐障害性があり主にバッチ処理で用いられる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>NorikraでログをJOINする</title>
      <link>https://www.sambaiz.net/article/111/</link>
      <pubDate>Thu, 15 Jun 2017 00:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/111/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/109/&#34;&gt;NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;適当なログを出すコードを書いた。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/lottery-log&#34;&gt;sambaiz/lottery-log&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。&#xA;広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。&lt;/p&gt;</description>
    </item>
    <item>
      <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
      <link>https://www.sambaiz.net/article/109/</link>
      <pubDate>Sat, 10 Jun 2017 12:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/109/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://norikra.github.io/&#34;&gt;Norikra&lt;/a&gt;はTD社の&lt;a href=&#34;https://github.com/tagomoris&#34;&gt;tagomoris&lt;/a&gt;氏が作った、&#xA;スキーマレスのストリーミングデータを処理するOSS。&lt;/p&gt;&#xA;&lt;p&gt;モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだが、&#xA;流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。&lt;/p&gt;</description>
    </item>
    <item>
      <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
      <link>https://www.sambaiz.net/article/73/</link>
      <pubDate>Sun, 26 Feb 2017 18:56:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/73/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;でKinesis Streamsに送り、Lambdaで読んでS3に保存する。&#xA;要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kinesis Streams/Firehose/Analyticsを試す</title>
      <link>https://www.sambaiz.net/article/67/</link>
      <pubDate>Mon, 20 Feb 2017 21:15:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/67/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/&#34;&gt;https://aws.amazon.com/jp/kinesis/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;リアルタイムのストリーミングデータを扱うサービス群。&#xA;いまのところTokyoリージョンではKinesis Streamsしか使えない。&lt;/p&gt;&#xA;&lt;h3 id=&#34;kinesis-firehose&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/&#34;&gt;Kinesis Firehose&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;AWSのデータストアに送るストリーム。自分でデータを読む処理を書かなくてよく、スケーリングも勝手にやってくれるので簡単に使える。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
