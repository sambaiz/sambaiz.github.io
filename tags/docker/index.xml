<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/docker/</link>
    <description>Recent content in Docker on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Thu, 09 May 2019 23:54:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ECS FargateでSidecarのFluentdでログをS3に送る構成をCloudFormationで構築する</title>
      <link>https://www.sambaiz.net/article/221/</link>
      <pubDate>Thu, 09 May 2019 23:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/221/</guid>
      <description>DAEMONを動かすことはできず、 fluentd logdriverもサポートされていないFargateで、 サイドカーとしてFluentdのコンテナを動かしてアプリケーションのログをS3に送る。 全体のコードはGitHubにある。
FargateでECSを使う - sambaiz-net
Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る - sambaiz-net
Fluentd 必要なプラグインと設定ファイルを入れたイメージを作る。
FROM fluent/fluentd:v1.4-1 USER root COPY ./fluent.conf /fluentd/etc/ # install plugin RUN apk add --update-cache --virtual .build-deps sudo build-base ruby-dev \ &amp;amp;&amp;amp; gem install fluent-plugin-s3 -v 1.0.0 --no-document \ &amp;amp;&amp;amp; gem install uuidtools \ &amp;amp;&amp;amp; gem sources --clear-all \ &amp;amp;&amp;amp; apk del .build-deps \ &amp;amp;&amp;amp; rm -rf /var/cache/apk/* \ /home/fluent/.gem/ruby/*/cache/*.gem # set timezone (Alpine) RUN apk --update-cache add tzdata &amp;amp;&amp;amp; \ cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime &amp;amp;&amp;amp; \ apk del tzdata &amp;amp;&amp;amp; \ rm -rf /var/cache/apk/*  fluent.</description>
    </item>
    
    <item>
      <title>CircleCI 2.0でDocker imageをbuildしてタグを付けてContainer Registryに上げる</title>
      <link>https://www.sambaiz.net/article/183/</link>
      <pubDate>Wed, 22 Aug 2018 23:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/183/</guid>
      <description>(追記: 2019-04-13) 2.1からのOrbを使うと自分でjobを書かなくてもよくなる CircleCI 2.1からのOrbでdocker buildしてECRにpushし、Slackに通知させる - sambaiz-net
 masterにpushしたときと、リリースタグを切ったときにビルドされるようにする。
version: 2 jobs: build: docker: - image: google/cloud-sdk environment: GCP_PROJECT: &amp;lt;project_name&amp;gt; IMAGE_NAME: &amp;lt;image_name&amp;gt; steps: - checkout - setup_remote_docker: version: 18.05.0-ce - run: name: gcloud auth command: | echo $GCLOUD_SERVICE_KEY | base64 --decode &amp;gt; ${HOME}/gcloud-service-key.json gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json gcloud --quiet auth configure-docker - run: name: docker build &amp;amp; push command: | docker build -t asia.gcr.io/${GCP_PROJECT}/${IMAGE_NAME}:${CIRCLE_BUILD_NUM} . docker tag asia.</description>
    </item>
    
    <item>
      <title>MySQL InnoDBのロックの挙動</title>
      <link>https://www.sambaiz.net/article/158/</link>
      <pubDate>Sat, 03 Mar 2018 19:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/158/</guid>
      <description>https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html
トランザクション分離レベルはデフォルトのREPEATABLE-READ。
&amp;gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@GLOBAL.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+  準備 DBを立ち上げてテーブルとレコードを入れる。
$ cat schema_and_data.sql CREATE TABLE a ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, name VARCHAR(128) NOT NULL ); CREATE TABLE b ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, a_id BIGINT UNSIGNED NOT NULL, FOREIGN KEY (a_id) REFERENCES a (id) ); INSERT INTO a (id, name) VALUES (1, &#39;1&#39;); INSERT INTO a (id, name) VALUES (2, &#39;2&#39;); INSERT INTO a (id, name) VALUES (3, &#39;3&#39;); INSERT INTO a (id, name) VALUES (8, &#39;8&#39;); INSERT INTO a (id, name) VALUES (9, &#39;9&#39;); INSERT INTO a (id, name) VALUES (10, &#39;10&#39;); $ cat start.</description>
    </item>
    
    <item>
      <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
      <link>https://www.sambaiz.net/article/52/</link>
      <pubDate>Sun, 29 Jan 2017 17:08:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/52/</guid>
      <description>https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
vm.max_map_count (バーチャルメモリにマッピングできる最大ページ数) を262144以上にする。
$ sysctl vm.max_map_count $ grep vm.max_map_count /etc/sysctl.conf vm.max_map_count=262144 # sysctl -w vm.max_map_count=262144  30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。
-cap-add=IPC_LOCKでLock memory(スワップアウトしないようにする)を 許可する。
https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html
ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。 ただし、物理RAMの50%以下で、32GB近辺の境界を超えないようにする。
$ mkdir -p ~/do/elasticsearch/data $ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \ --name elasticsearch \ -p 9200:9200 \ -e xpack.security.enabled=false \ -e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;quot;-Xms28g -Xmx28g&amp;quot; \ --cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \ --restart=always \ docker.elastic.co/elasticsearch/elasticsearch:5.1.2 $ docker volume ls local elasticsearch  問題なく起動しているか確認する。</description>
    </item>
    
    <item>
      <title>ファイルディスクリプタの上限を増やす</title>
      <link>https://www.sambaiz.net/article/41/</link>
      <pubDate>Thu, 08 Dec 2016 21:36:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/41/</guid>
      <description>ファイルディスクリプタとは プロセスの外部とやりとりするための識別子。POSIXではint型で、0がstdin、1がstdout、2がstderrといったもの。 ファイルやデバイスに対するopen()や、 ネットワーク(INETドメインソケット)やホスト内(UNIXドメインソケット)で 通信するためのソケットを生成するsocket()などのシステムコールで生成される。
ファイルディスクリプタの上限 一つのプロセスがリソースを食いつぶさないように 使えるファイルディスクリプタの上限が決まっていて、ulimit -nで確認できる。デフォルトは大体1024。
$ ulimit -n 1024  各プロセスの上限と使っているファイルディスクリプタはこれで確認できる。
$ cat /proc/&amp;lt;プロセスID&amp;gt;/limits ... Max open files 1024 4096 files ... $ ls -l /proc/&amp;lt;プロセスID&amp;gt;/fd  webサーバーのように同時にたくさん通信したりすると上限に達してしまい、Too many open filesになってしまうので増やす必要がある。
/etc/security/limits.confで変更する PAM認証時(ログインするときなど)に適用されるので、サーバーの起動時に立ち上がったデーモンには使えない。
$ cat /etc/pam.d/sshd ... session required pam_limits.so ...  全てのユーザー(*)のプロセスが使える ファイルディスクリプタ(nofile)のsoft(ユーザーが設定できる)とhard(rootが設定できる)上限を共に64000にする。
$ echo &amp;quot;* hard nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf $ echo &amp;quot;* soft nofile 64000&amp;quot; &amp;gt;&amp;gt; /etc/security/limits.conf $ ulimit -n 64000  ulimit -nで変更する シェルと、起動したプロセスで有効。</description>
    </item>
    
    <item>
      <title>OpenVPNサーバーPritunlをDockerで動かす</title>
      <link>https://www.sambaiz.net/article/39/</link>
      <pubDate>Fri, 02 Dec 2016 21:05:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/39/</guid>
      <description>PritunlでVPNサーバーを立てる。
Dockerfileはこんな感じ。
https://hub.docker.com/r/sambaiz/pritunl/
FROM mongo:3.4 # https://docs.pritunl.com/docs/installation RUN echo &#39;deb http://repo.pritunl.com/stable/apt jessie main&#39; &amp;gt; /etc/apt/sources.list.d/pritunl.list &amp;amp;&amp;amp; \ apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 7568D9BB55FF9E5287D586017AE645C0CF8E292A &amp;amp;&amp;amp; \ apt-get --assume-yes update &amp;amp;&amp;amp; \ apt-get --assume-yes upgrade &amp;amp;&amp;amp; \ apt-get --assume-yes install pritunl iptables EXPOSE 80 443 12345/udp CMD mongod --fork --logpath /data/db/mongod.log &amp;amp;&amp;amp; echo &#39;Setup Key:&#39; `pritunl setup-key` &amp;amp;&amp;amp; pritunl start  $ docker run -itd -p 80:80 -p 443:443 -p 12345:12345/udp --privileged sambaiz/pritunl $ docker logs &amp;lt;id&amp;gt; .</description>
    </item>
    
    <item>
      <title>GKEで複数コンテナのアプリケーションを動かす</title>
      <link>https://www.sambaiz.net/article/18/</link>
      <pubDate>Fri, 26 Aug 2016 21:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/18/</guid>
      <description>前回は単一コンテナのアプリケーションを動かしたが、今回はコンテナ間でやり取りが発生するものを動かす。 流れとしては、クライアントからのリクエストをGATEWAYサーバーで受け取り、SERVICEサーバーにリクエストし、その結果を返すまで。
プログラムは以下の通り、環境変数TYPEの値によって挙動を変えていて、同じイメージを使い回す。コードはここ。
var http = require(&#39;http&#39;); var handleRequest = function(request, response) { if(process.env.TYPE == &amp;quot;GATEWAY&amp;quot;){ console.log(&#39;Passed.&#39;); var options = { host: &#39;service&#39;, port: 8080, method: &#39;GET&#39; }; var req = http.request(options, function(res) { data = &amp;quot;&amp;quot; res.on(&#39;data&#39;, function (chunk) { data+=chunk; }); res.on(&#39;end&#39;, () =&amp;gt; { response.writeHead(200); response.end(data); }); }); req.on(&#39;error&#39;, function(e) { response.writeHead(500) response.end(e.message); }); req.end(); }else{ console.log(&#39;Received.&#39;); response.writeHead(200); response.end(&#39;ok&#39;); } }; var www = http.createServer(handleRequest); www.listen(8080);  これをContainer RegistryにPushする。</description>
    </item>
    
    <item>
      <title>Google Container Engine(GKE)で単一コンテナのアプリケーションを動かす</title>
      <link>https://www.sambaiz.net/article/17/</link>
      <pubDate>Sun, 21 Aug 2016 23:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/17/</guid>
      <description>Kubernetes - Hello World Walkthrough
CloudSDKとkubectlのインストール Cloud SDKをインストールしてgloudコマンドを使えるようにする。
$ gcloud --version Google Cloud SDK 122.0.0 $ gcloud components install kubectl  Google Container RegistryにPush $ export PROJECT_ID=&amp;quot;******&amp;quot; $ docker build -t gcr.io/$PROJECT_ID/test:v1 . $ gcloud docker push gcr.io/$PROJECT_ID/test:v1  プロジェクトの課金を有効にしていないとこんなエラーメッセージが出る。
denied: Unable to create the repository, please check that you have access to do so.  Clusterの作成 $ gcloud config set core/project $PROJECT_ID $ gcloud config set compute/zone asia-east1-b $ gcloud container clusters create test-cluster $ gcloud config set container/cluster test-cluster  Container Engine APIが有効になっていない場合はこうなる。 一度コンソールからContainer Engineを選ぶと、サービスの準備が始まって有効になる。</description>
    </item>
    
    <item>
      <title>Kubernetesのチュートリアルをたどる</title>
      <link>https://www.sambaiz.net/article/9/</link>
      <pubDate>Mon, 18 Jul 2016 22:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/9/</guid>
      <description>Kubernetesとは Kubernetes(発音はkoo-ber-nay&amp;rsquo;-tace。 ギリシャ語で操舵手。)はGoogleによって開発が始められた、アプリケーションコンテナにおける自動デプロイ、スケーリング、操作を 自動化するOSS。K8sと略される。
Minikube K8sをローカルで試すために、MinikubeというVMの中で単一ノードのK8sクラスターを動かすツールを入れる。
v0.6.0
curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.6.0/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/  $ minikube start Starting local Kubernetes cluster... ... $ kubectl version Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;2&amp;quot;, GitVersion:&amp;quot;v1.2.4&amp;quot;, GitCommit:&amp;quot;3eed1e3be6848b877ff80a93da3785d9034d0a4f&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;} Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;3&amp;quot;, GitVersion:&amp;quot;v1.3.0&amp;quot;, GitCommit:&amp;quot;283137936a498aed572ee22af6774b6fb6e9fd94&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;}  Pods K8sではコンテナのグループをpodと呼ぶ。pod中のコンテナは共にデプロイされ、起動し、停止する。 また、グループとして複製される。
Podの定義は次のようにyamlで書かれる。
apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80  Podの定義に望ましい状態を記述すると、Kubernatesはそれを見て現在の状態が一致しているかどうか確認する。 例えば、Podが作られたときに、コンテナがその中で動いている状態が望ましい状態だとすると、 コンテナが動かなくなったときに、Kubernatesは新しいものを再作成することで望ましい状態にする。</description>
    </item>
    
    <item>
      <title>Docker公式ドキュメント&#34;network コマンドを使う&#34;を読む</title>
      <link>https://www.sambaiz.net/article/7/</link>
      <pubDate>Fri, 15 Jul 2016 00:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/7/</guid>
      <description>Docker version 1.12.0-rc2  公式ドキュメントnetwork コマンドを使う の内容をまとめてみた。
dockerには3つのデフォルトネットワークが存在する。docker run時に--netオプションでネットワークを指定しない限り、 docker0として表示されるbridgeネットワークにコンテナを接続する。
$ docker network ls NETWORK ID NAME DRIVER SCOPE a3b712537566 bridge bridge local f6d86cb54edd host host local 33cb30b024d9 none null local  ただし、後方互換性を維持するため、デフォルトのbridgeネットワークでは自動的に名前解決が行われない。
これらのネットワークとは別にユーザー定義のネットワークを作成することもできる。 単一ホストのbridgeネットワークと、複数ホストにまたがるoverlayネットワークから選択でき、 何も指定しなかったらbridgeになる。subnetを指定しなければ、 dockerデーモンがネットワークに対してサブネットを自動的に割り当てるが、 dockerが管理していないサブネットと重複するのを避けるために指定することが推奨されている。
$ docker network create -d bridge --subnet 172.25.0.0/16 isolated_nw $ docker network inspect isolated_nw $ docker network rm isolated_nw # 削除  docker network inspectで以下のようなネットワークの情報が得られる。
[ { &amp;quot;Name&amp;quot;: &amp;quot;isolated_nw&amp;quot;, &amp;quot;Id&amp;quot;: &amp;quot;c81547cf7ed897054ea645192c6c47dcf7a248e77bc8067609becab5330e417d&amp;quot;, &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;, &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;, &amp;quot;EnableIPv6&amp;quot;: false, &amp;quot;IPAM&amp;quot;: { &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;Options&amp;quot;: {}, &amp;quot;Config&amp;quot;: [ { &amp;quot;Subnet&amp;quot;: &amp;quot;172.</description>
    </item>
    
  </channel>
</rss>