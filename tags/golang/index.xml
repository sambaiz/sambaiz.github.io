<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>golang on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/golang/</link>
    <description>Recent content in golang on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Mon, 20 Sep 2021 23:26:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/tags/golang/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GoでAmazon Forecastに時系列データをimportしPredictorを作成して予測結果をS3にexportする</title>
      <link>https://www.sambaiz.net/article/380/</link>
      <pubDate>Mon, 20 Sep 2021 23:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/380/</guid>
      <description>以前コンソール上で実行したAmazon Forecastでの時系列データの学習、予測をGoで行う。全体のコードはGitHubにある。
Amazon Forecastで時系列データの予測を行う - sambaiz-net
Datasetの作成 以前と同じく電力消費量のデータセットを、予測対象の時系列データ(DatasetTypeTargetTimeSeries)として登録する。データの頻度は1時間でドメインはCustom。
func (f Forecast) CreateDataset(ctx context.Context, name string) (*string, error) { return f.skipIfAlreadyExists(&amp;#34;dataset&amp;#34;, name, func() (*string, error) { dataset, err := f.svc.CreateDataset(ctx, &amp;amp;forecast.CreateDatasetInput{ DatasetName: aws.String(name), DatasetType: types.DatasetTypeTargetTimeSeries, DataFrequency: aws.String(&amp;#34;H&amp;#34;), Domain: types.DomainCustom, Schema: &amp;amp;types.Schema{ Attributes: []types.SchemaAttribute{ { AttributeName: aws.String(&amp;#34;timestamp&amp;#34;), AttributeType: types.AttributeTypeTimestamp, }, { AttributeName: aws.String(&amp;#34;target_value&amp;#34;), AttributeType: types.AttributeTypeFloat, }, { AttributeName: aws.String(&amp;#34;item_id&amp;#34;), AttributeType: types.AttributeTypeString, }, }, }, }) if err != nil { return nil, err } return dataset.</description>
    </item>
    
    <item>
      <title>AWS X-rayでアプリケーションのリクエストをトレースし可視化する</title>
      <link>https://www.sambaiz.net/article/376/</link>
      <pubDate>Thu, 05 Aug 2021 02:32:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/376/</guid>
      <description>AWS X-rayはリクエストをトレースして、タイムラインやサービスマップを可視化、分析できるサービス。 サービスの数が増えると見えづらくなる、どこにどれくらいのトラフィックがあって、どこで問題が起きているのかといったことを一目で確認できる。
料金はトレースの記録と取得に対してかかり、SamplingRuleの設定によって抑えることができる。
今回はローカルにdocker-composeで立ち上げたWebサーバーからセグメントデータをxray-daemon経由で送り、コンソール上で取得できることを確認する。全体のコードはGitHubにある。
xray-daemonは次のようなフォーマットのデータを受け取りバッチで送るデーモン。
$ cat segment.txt {&amp;#34;format&amp;#34;: &amp;#34;json&amp;#34;, &amp;#34;version&amp;#34;: 1} {&amp;#34;trace_id&amp;#34;: &amp;#34;1-594aed87-ad72e26896b3f9d3a27054bb&amp;#34;, &amp;#34;id&amp;#34;: &amp;#34;6226467e3f845502&amp;#34;, &amp;#34;start_time&amp;#34;: 1498082657.37518, &amp;#34;end_time&amp;#34;: 1498082695.4042, &amp;#34;name&amp;#34;: &amp;#34;test.elasticbeanstalk.com&amp;#34;} $ cat segment.txt &amp;gt; /dev/udp/127.0.0.1/2000 ローカルで動かす場合は -o を付けてインスタンスメタデータを読みに行かないようにする必要がある。ドキュメントでは.awsを/rootにマウントしているが、そうすると送る際に NoCredentialProviders: no valid providers in chain. Deprecated. になってしまう。Dockerfileを見たところxrayユーザーで動かしていることが分かったので /home/xray にしている。
version: &amp;#34;3.9&amp;#34; services: xray-daemon: image: amazon/aws-xray-daemon:3.x ports: - &amp;#34;2000:2000/udp&amp;#34; command: - &amp;#34;-o&amp;#34; # Don&amp;#39;t check for EC2 instance metadata. volumes: - ~/.aws:/home/xray/.aws:ro environment: AWS_REGION: ap-northeast-1 app: build: . ports: - &amp;#34;8080:8080&amp;#34; volumes: - ~/.</description>
    </item>
    
    <item>
      <title>gomockのmockを入力とするmockが意図した出力を返さない理由</title>
      <link>https://www.sambaiz.net/article/375/</link>
      <pubDate>Tue, 27 Jul 2021 12:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/375/</guid>
      <description>interfaceを受け取るinterfaceを定義し、
package main type Foo interface { Shout() string } type Bar interface { Bar(foo Foo) string } gomockでmockgenする。
// Code generated by MockGen. DO NOT EDIT. // Source: main.go  // Package main is a generated GoMock package. package main import ( reflect &amp;#34;reflect&amp;#34; gomock &amp;#34;github.com/golang/mock/gomock&amp;#34; ) ... // MockBarMockRecorder is the mock recorder for MockBar. type MockBarMockRecorder struct { mock *MockBar } // NewMockBar creates a new mock instance.</description>
    </item>
    
    <item>
      <title>ReviewdogのGitHub ActionsでGoのlintをかけてPRに表示する</title>
      <link>https://www.sambaiz.net/article/363/</link>
      <pubDate>Thu, 03 Jun 2021 19:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/363/</guid>
      <description>Reviewdogはlinterの結果をPRにコメントしてくれるツール。 差分のみに適用することができるので段階的に改善していくこともできる。
Staticcheck StaticcheckはdeprecatedになったGolintのリポジトリで移行先として紹介されているlinter。
$ go install honnef.co/go/tools/cmd/staticcheck@latest $ staticcheck --version staticcheck 2021.1 (v0.2.0) 典型的なミスや非効率な書き方など様々な項目がチェックされる。
package main import ( &amp;#34;context&amp;#34; &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;strings&amp;#34; ) type Color int const ( Red Color = 1 // main.go:14:2: only the first constant in this group has an explicit type (SA9004)  Blue = 2 ) func f(ctx context.Context, str []byte) error { var m map[string]string m[&amp;#34;A&amp;#34;] = &amp;#34;default&amp;#34; // main.go:13:2: assignment to nil map (SA5000)  if err := json.</description>
    </item>
    
    <item>
      <title>Goのio packageのReader/Writer/Closer/Seeker interfaceとストリーム処理</title>
      <link>https://www.sambaiz.net/article/330/</link>
      <pubDate>Thu, 11 Mar 2021 20:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/330/</guid>
      <description>Goのio packageにはデータの読み書きに関わるインタフェース、Reader/Writer/Closer/Seeker およびこれらを組み合わせた ReadSeeker などが定義されている。
 io.Reader  最大でlen(p)バイトpに読み込んで、読み込んだバイト数を返す。 最後まで読んだらerrでio.EOFを返すが、これは最後のバイトと同時でもその後でも良いことになっている。
type Reader interface { Read(p []byte) (n int, err error) } var EOF = errors.New(&amp;#34;EOF&amp;#34;)  io.Writer  データを書き込み、そのバイト数を返す。全て書き込めなかった(len(p) != n)場合はエラーを返す必要がある。
type Writer interface { Write(p []byte) (n int, err error) }  io.Closer  2回以上呼んだときの挙動は規定されていない。
type Closer interface { Close() error }  io.Seeker  オフセットと起点を渡して読み書きする地点を変更し、Startからのオフセットを返す。
type Seeker interface { Seek(offset int64, whence int) (int64, error) } const ( SeekStart = 0 // seek relative to the origin of the file 	SeekCurrent = 1 // seek relative to the current offset 	SeekEnd = 2 // seek relative to the end ) ReaderとWriterを繋げてストリーム処理を行うことで、メモリ使用量を抑えることができる。 io.</description>
    </item>
    
    <item>
      <title>x/sync/semaphoreでgoroutineの数を制御する</title>
      <link>https://www.sambaiz.net/article/329/</link>
      <pubDate>Tue, 09 Mar 2021 21:00:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/329/</guid>
      <description>Goの特長の一つにgoroutineによる並列実行の容易さがあるが、 無尽蔵にgoroutineを生成するとパフォーマンスが悪化してしまうため、 都度go func()するのではなく、一定数走らせておいたgoroutineに処理を渡すなどして、その数を制御することがある。
Goroutineの数をworkerで抑制する - sambaiz-net
重み付きのセマフォを提供する準標準パッケージgolang.org/x/sync/semaphoreを用いると 容易にこれを行うことができる。
次のようにAcquire(context, weight)して、使い終わったらRelease(weight)する。 セマフォのWeightを使い切るとAcquire()でブロッキングされるので、1ずつAcquire()していった場合、goroutineの数は最大でもWeightの値で抑えられる。 x/sync/errgroupはGo()で非同期処理を実行し、エラーが返るか全ての処理が終わるまで Wait() する。errgroupを用いない場合、最後に最大WeightでAcquire()することで全ての処理が終わったことを確認する。
package main import ( &amp;#34;context&amp;#34; &amp;#34;errors&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;golang.org/x/sync/errgroup&amp;#34; &amp;#34;golang.org/x/sync/semaphore&amp;#34; ) func countWithSem(ctx context.Context, maxWorkers int64) { sem := semaphore.NewWeighted(maxWorkers) eg, ctx := errgroup.WithContext(ctx) for i := 0; i &amp;lt; 5; i++ { if err := sem.Acquire(ctx, 1); err != nil { fmt.Printf(&amp;#34;failed to acquire semaphore: %v\n&amp;#34;, err) break } func(i int) { eg.Go(func() error { defer sem.</description>
    </item>
    
    <item>
      <title>Amazon Forecastで時系列データの予測を行う</title>
      <link>https://www.sambaiz.net/article/327/</link>
      <pubDate>Sun, 21 Feb 2021 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/327/</guid>
      <description>Amazon Forecastは機械学習によって時系列データの予測を行うマネージドサービス。 ドメインやアルゴリズムを選んでデータを投入すればそれらしい出力が得られる。 まずこれで予測してみて、その結果をベースラインとしてSageMakerなどで自作したモデルを評価するといった使い方もできる。
SageMakerでPyTorchのモデルを学習させる - sambaiz-net
料金はデータストレージに$0.088/GB、学習に$0.24/hour、予測に$0.60/1000回かかる。
今回は開発者ガイドと同じく 電力消費量のデータセットを用いて動かしてみる。
$ head electricityusagedata.csv 2014-01-01 01:00:00,2.53807106598985,client_0 2014-01-01 01:00:00,23.648648648648624,client_1 2014-01-01 01:00:00,0.0,client_2 2014-01-01 01:00:00,144.81707317073176,client_3 ... データのインポート まずドメインを選んでDataset groupを作成する。Dataset groupには予測対象の時系列データに加えて、他の関連する時系列データやメタデータを含めることができる。
CSVをS3に置き、それを読めるRoleを渡してインポートする。データの間隔とカラムの順は元データと合致するように設定する。 タイムスタンプは yyyy-MM-dd か yyyy-MM-dd HH:mm:ss の形式である必要がある。
学習 インポートが終わるとTrain predictorできるようになる。 予測の間隔と期間を設定し、アルゴリズムを、AutoMLか、ARIMAやCNN-QRといったものの中からマニュアルで選んで学習を始める。
時系列データのMAモデルとARモデル、その定常性と反転可能性 - sambaiz-net
ハイパーパラメータの最適化や、国ごとの祝日や天気を考慮するオプションもある。
予測 学習が終わるとCreate a forecastして予測値を得られる。
Goでの取得はこんな感じ。
package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/forecastqueryservice&amp;#34; ) func main() { mySession := session.Must(session.NewSession()) svc := forecastqueryservice.New(mySession) ctx := context.TODO() output, err := svc.</description>
    </item>
    
    <item>
      <title>偽陽性を許容して空間効率良くキーの存在を確認するBloom filterとCuckoo filter</title>
      <link>https://www.sambaiz.net/article/326/</link>
      <pubDate>Wed, 17 Feb 2021 02:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/326/</guid>
      <description>例えばデータストアへのアクセス抑制のためにキーの存在を確認する際、 全てのキーを保持して探索すれば100%正しく判定できるが、キーが長く数が膨大になるとメモリの使用量が問題になることがある。 もし偽陽性が許容できるなら、次のフィルタを使うことで空間効率良くキーの存在を確認できる。
Bloom filter 1970年に考案されたフィルタで、 LevelDBやCassandraで使われている。
GoogleのkvsライブラリLevelDBを使う - sambaiz-net
初期値0のビット配列と、そのいずれかのビットにデータをマッピングするk個のハッシュ関数を定義し、 含めるデータを各ハッシュ関数に通して、マッピングされたビットを1に更新していく。 これにより、いずれかのハッシュ関数によって0のビットにマッピングされるデータは、必ずフィルタに含まれないことが分かる。 また、ビット配列のANDを取れば和集合のフィルタになる。
データの追加と存在の確認を、いずれも要素数に依存しないO(k)で行うことができるが、削除はできない。 0/1ではなくインクリメントしていくCounting filterという実装にすると空間効率は劣るが、デクリメントすることで削除できるようになる。
偽陽性率はビット配列長を大きくすると低くなり、データの数が増えると高くなる。 kはビット配列の情報量を最大化させる、つまり半分のビットが1になるように最適化する。
自己情報量、エントロピー、KL情報量、交差エントロピーと尤度関数 - sambaiz-net
Goのwillf/bloomで作成したBloom filterにデータを追加し存在を確認しているのが次のコード。 ハッシュ関数にはpybloomfiltermmap3などと同じくMurmurHash3が用いられている。
package main import ( &amp;#34;encoding/binary&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;github.com/willf/bitset&amp;#34; &amp;#34;github.com/willf/bloom&amp;#34; ) func bits(filter *bloom.BloomFilter) []uint64 { r, w := io.Pipe() ret := []uint64{} wg := &amp;amp;sync.WaitGroup{} wg.Add(1) go func() { var m, k uint64 if err := binary.Read(r, binary.BigEndian, &amp;amp;m); err != nil { panic(err) } if err := binary.</description>
    </item>
    
    <item>
      <title>GoのSheets API v4クライアントでSpreadsheetを読み書きする</title>
      <link>https://www.sambaiz.net/article/312/</link>
      <pubDate>Mon, 23 Nov 2020 22:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/312/</guid>
      <description>まずGCPのコンソールでプロジェクトを作成するか選んでGoogle Sheets APIを有効にする。 料金はかからないが、デフォルトのQuotaが、100秒ごとに100リクエスト/ユーザー、500リクエスト/プロジェクトとなっている。
OAuth 2.0で得たユーザーの権限でAPIを呼ぶこともできるが、今回はサービスアカウントを用いる。ロールは付与する必要はなく、対象のSheetの共有先に追加すればよい。 JWTの署名に用いる秘密鍵をダウンロードしておく。
OpenID ConnectのIDトークンの内容と検証 - sambaiz-net
全体のコードはGitHubにある。
クライアントの準備 サービスアカウントでアクセストークンを取得するにはJWTを認可サーバーに送る必要があるが、JWTをアクセストークンの代わりに用いることができるのでそうしている。
SpreadsheetIDはURLから得られる。
package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;os&amp;#34; &amp;#34;golang.org/x/oauth2/google&amp;#34; &amp;#34;google.golang.org/api/sheets/v4&amp;#34; ) type SheetClient struct { srv *sheets.Service spreadsheetID string } func NewSheetClient(ctx context.Context, spreadsheetID string) (*SheetClient, error) { b, err := ioutil.ReadFile(&amp;#34;secret.json&amp;#34;) if err != nil { return nil, err } // read &amp;amp; write permission 	jwt, err := google.JWTConfigFromJSON(b, &amp;#34;https://www.googleapis.com/auth/spreadsheets&amp;#34;) if err != nil { return nil, err } srv, err := sheets.</description>
    </item>
    
    <item>
      <title>GoでAthenaのクエリを実行する</title>
      <link>https://www.sambaiz.net/article/309/</link>
      <pubDate>Sat, 14 Nov 2020 16:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/309/</guid>
      <description>segmentio/go-athenaを使う。database/sqlのドライバーとして提供されていて、 StartQueryExecution()と stateのポーリング、 値のキャストを行う。
package main import ( &amp;#34;database/sql&amp;#34; &amp;#34;errors&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/sts&amp;#34; _ &amp;#34;github.com/segmentio/go-athena&amp;#34; ) func outputLocation() (string, error) { svc := sts.New(session.Must(session.NewSession())) result, err := svc.GetCallerIdentity(&amp;amp;sts.GetCallerIdentityInput{}) if err != nil { return &amp;#34;&amp;#34;, err } if result.Account == nil || svc.Config.Region == nil { return &amp;#34;&amp;#34;, errors.New(&amp;#34;account or region is nil&amp;#34;) } return fmt.Sprintf(&amp;#34;s3://aws-athena-query-results-%s-%s&amp;#34;, *result.Account, *svc.Config.Region), nil } func execute(query string) (*sql.Rows, error) { loc, err := outputLocation() if err !</description>
    </item>
    
    <item>
      <title>Go CompilerのFunction Inlining</title>
      <link>https://www.sambaiz.net/article/304/</link>
      <pubDate>Tue, 06 Oct 2020 22:12:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/304/</guid>
      <description>Go Compilerが行う、関数の処理をインラインに展開することで呼び出しコストを削減するFunction Inliningの話。 式の数が40未満でループやクロージャなどが含まれないシンプルな処理の関数が対象となる。
 (追記: 2021-02-17) Go 1.16でラベルのないループがInliningされるようになった
 まずは次の例で挙動を確認する。
package main import &amp;#34;fmt&amp;#34; func myfunc(a, b int) int { return a + b } func main() { fmt.Println(myfunc(1, 2)) } -gcflags に -m を渡してビルドすると最適化の内容が確認でき、2つ渡すとより詳細な出力が得られる。
$ go tool compile -help usage: compile [options] file.go... ... -m print optimization decisions myfunc()やfmt.Println()がInliningされたことや、myfunc(1, 2)がヒープに割り当てられたことなどが分かる。 ちなみにコストの低いスタックか、高いヒープのどちらに割り当てるかはEscape analysisによって決まる。
$ go build -gcflags &amp;#39;-m -m&amp;#39; main.go # command-line-arguments ./main.go:5:6: can inline myfunc with cost 4 as: func(int, int) int { return a + b } &amp;lt;---- .</description>
    </item>
    
    <item>
      <title>Goの実装に手を入れずにHTTPリクエストをmockするライブラリhttpmockとその仕組み</title>
      <link>https://www.sambaiz.net/article/296/</link>
      <pubDate>Tue, 08 Sep 2020 23:23:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/296/</guid>
      <description>jarcoal/httpmockは次のようなHTTPリクエストが飛ぶ関数に対して、
import ( &amp;#34;io/ioutil&amp;#34; &amp;#34;net/http&amp;#34; ) func Req() (string, error) { res, err := http.DefaultClient.Get(&amp;#34;https://google.com&amp;#34;) if err != nil { return &amp;#34;&amp;#34;, err } defer res.Body.Close() body, err := ioutil.ReadAll(res.Body) if err != nil { return &amp;#34;&amp;#34;, err } return string(body), nil } 次のように実装に手を入れずmockできるライブラリ。
import ( &amp;#34;testing&amp;#34; &amp;#34;github.com/jarcoal/httpmock&amp;#34; &amp;#34;github.com/stretchr/testify/assert&amp;#34; ) func TestReq(t *testing.T) { httpmock.Activate() defer httpmock.DeactivateAndReset() httpmock.RegisterResponder(&amp;#34;GET&amp;#34;, &amp;#34;https://google.com&amp;#34;, httpmock.NewStringResponder(200, &amp;#34;mocked&amp;#34;), ) res, err := Req() assert.Nil(t, err) assert.Equal(t, &amp;#34;mocked&amp;#34;, res) } 仕組みとしてはActivate()で http.</description>
    </item>
    
    <item>
      <title>nkfによる文字コードの判定とGoでのShiftJISの扱い</title>
      <link>https://www.sambaiz.net/article/295/</link>
      <pubDate>Mon, 07 Sep 2020 21:38:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/295/</guid>
      <description>file --mime で文字コードを判定しようとしたら charset=unknown-8bit と表示されてしまったので、nkf --guess したところShift_JISであることが分かった。
$ file --mime unknown.txt unknown.txt: text/plain; charset=unknown-8bit $ brew install nkf $ nkf --guess unknown.txt Shift_JIS (CRLF) このファイルをGoで扱うにはjapanese packageでエンコード/デコードする。 ShiftJISのほかにEUCJPとISO2022JPをサポートしている。
import ( &amp;#34;bytes&amp;#34; &amp;#34;golang.org/x/text/encoding/japanese&amp;#34; &amp;#34;golang.org/x/text/transform&amp;#34; ) transform.NewReader(bytes.NewReader(b), japanese.ShiftJIS.NewDecoder()) </description>
    </item>
    
    <item>
      <title>Goで参照型の変数に代入し値を変更したとき元の値に影響がある場合とない場合</title>
      <link>https://www.sambaiz.net/article/269/</link>
      <pubDate>Sat, 25 Apr 2020 22:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/269/</guid>
      <description>サンプル用struct。
package main import ( &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; ) type Data struct { Value string ValueP *string `json:&amp;#34;,omitempty&amp;#34;` Slice []Data `json:&amp;#34;,omitempty&amp;#34;` SliceP []*Data `json:&amp;#34;,omitempty&amp;#34;` } func NewData() *Data { return &amp;amp;Data{ Value: &amp;#34;no-changed&amp;#34;, ValueP: &amp;amp;[]string{&amp;#34;no-changed&amp;#34;}[0], Slice: []Data{ Data{ Value: &amp;#34;no-changed&amp;#34;, }, Data{ Value: &amp;#34;no-changed&amp;#34;, }, }, SliceP: []*Data{ &amp;amp;Data{ Value: &amp;#34;no-changed&amp;#34;, }, }, } } 参照を取って値を取る アドレスは変わらず、そのフィールドを書き換えると当然元々の値も書き換わる。 各要素が順番に代入されるfor-rangeでのループも他と同じく参照型でないなら変わらず、参照型なら変わる。
func main() { s := NewData() fmt.Printf(&amp;#34;%p %p %p\n&amp;#34;, s, s.ValueP, s.Slice) // 0xc00009a000 0xc000010240 0xc00009c000  s2tmp := &amp;amp;s s2 := *s2tmp fmt.</description>
    </item>
    
    <item>
      <title>Goのcipher packageに実装されている暗号利用モードのベンチマーク</title>
      <link>https://www.sambaiz.net/article/268/</link>
      <pubDate>Sun, 12 Apr 2020 23:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/268/</guid>
      <description>暗号利用モードはブロック長より長いメッセージに対してどのようにブロック暗号を適用するかのアルゴリズム。
ブロック暗号 ブロック暗号は固定長のブロックを暗号化/復号する共通鍵暗号で、入力と同じ長さの出力を返す暗号化/復号関数からなる。 アメリカ国立標準技術研究所（NIST) が標準暗号として採用したAES (Rijndael) が有名。 最も単純な暗号利用モードとして、メッセージをブロックに分割してそれぞれ独立に適用する Electronic Codebook (ECB) というのがあるが、 鍵とブロックが同じなら毎回同じ出力になってしまうため、メッセージのパターンが残ってしまうのとリプレイ攻撃に弱い問題があり使われない。 また、メッセージがブロック長の整数倍になるようにパディングが必要。
Goのcrypto/cipher packageに実装されている暗号化利用モード Goのcrypto/cipher packageには次の暗号化利用モードが実装されている。
$ go version go version go1.14 darwin/amd64 Cipher Block Chaining (CBC) メッセージをブロックに分割し、前段の暗号文(最初はランダムなIV)と入力ブロックのXORを取ったものが暗号文で、 これを復号関数にかけて前段の暗号文とのXORを取って復号する。IVは平文のまま暗号文の前に付けるなどする。 IVがないと最初のブロックが復号できず、暗号文の一部が破損すると次のブロックまで復号できない。 ECBと同様パディングが必要。最も広く使われているらしい。
最後のブロックの暗号文をMAC(Message Authentication Code)とするCBC-MACでは最初のブロックの改変を防ぐためIVが0固定で、 任意のメッセージの最初のブロックを他のメッセージのMACとXORを取って後ろに結合することで、それまでの影響を打ち消し任意のメッセージ単体のMACと同じ値にする Length extension attackが成立する。そのためメッセージを固定長にするかメッセージ長を先頭に入れるなどの対策が必要。
Goではパディングは自分でやる必要がある。
func (x *cbcEncrypter) CryptBlocks(dst, src []byte) { if len(src)%x.blockSize != 0 { panic(&amp;#34;crypto/cipher: input not full blocks&amp;#34;) } if len(dst) &amp;lt; len(src) { panic(&amp;#34;crypto/cipher: output smaller than input&amp;#34;) } if subtle.</description>
    </item>
    
    <item>
      <title>Goのツールのバージョンをgo.modで指定する</title>
      <link>https://www.sambaiz.net/article/263/</link>
      <pubDate>Sun, 22 Mar 2020 01:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/263/</guid>
      <description>依存moduleと同様にツールもバージョンを指定し、挙動や出力が変わらないようにする。
Tools as dependencies
まず次の tools.go のようなファイルを作ってimportし、 go mod tidy で消えないようにする。 build tagが付いているので通常のbuild時には影響を及ぼさない。
$ cat tools.go // +build tools  package pkg import ( _ &amp;#34;golang.org/x/lint/golint&amp;#34; ) 次にGOBINを変更して go install し指定したディレクトリにバイナリを持ってきてこれを実行する。
export GOBIN:=$(PWD)/bin $(GOBIN)/golint: go install golang.org/x/lint/golint .PHONY: test test: $(GOBIN)/golint go test -v ./pkg/... bin/golint ./pkg/... </description>
    </item>
    
    <item>
      <title>Go Modulesのreplaceでforkしたコードのimportを書き換えずにfork後のpackageに向ける</title>
      <link>https://www.sambaiz.net/article/262/</link>
      <pubDate>Sun, 01 Mar 2020 21:19:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/262/</guid>
      <description>Goはimportの際に相対パスやモジュール名ではなくgithub.com/foo/barのようなフルパスで指定するため、forkしたコードを使うと参照するpackageは元のままになってしまう。Go Modulesのreplace directiveを使うとコードを書き換えずに依存先を変えることができる。相対パスも使える。
When should I use the replace directive? · golang/go Wiki · GitHub
module example.com/me/hello require ( example.com/foo/bar v0.0.0 ) replace ( example.com/foo/bar/aaa =&amp;gt; ./ example.com/foo/bar/bbb =&amp;gt; example.com/hoge/bar/bbb v1.0.0 ) fork元のmodule。文字列を出力するだけのもの。
$ cat go-something/lib/lib.go package lib import &amp;#34;fmt&amp;#34; func Do() { fmt.Println(&amp;#34;this is original&amp;#34;) } $ cat go-something/main.go package main import &amp;#34;github.com/sambaiz/go-something/lib&amp;#34; func main() { lib.Do() } $ go run go-something/main.go this is original fork先のmodule。出力する文字列を変えている。
$ cat go-something-fork/lib/lib.go package lib import &amp;#34;fmt&amp;#34; func Do() { fmt.</description>
    </item>
    
    <item>
      <title>Go Modulesのproxyとsumdb</title>
      <link>https://www.sambaiz.net/article/261/</link>
      <pubDate>Sat, 29 Feb 2020 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/261/</guid>
      <description>Module Mirror and Checksum Database Launched - The Go Blog
Go1.13からデフォルトで使われるようになったGo Modulesのミラーとchecksumを返すサーバー。 Googleによって運営されている。
 proxy.golang.org index.golang.org: proxyで利用可能なmoduleとバージョンの一覧 sum.golang.org  $ curl &amp;#34;https://proxy.golang.org/github.com/labstack/echo/v4/@v/v4.1.14.mod&amp;#34; module github.com/labstack/echo/v4 go 1.12 require ( github.com/dgrijalva/jwt-go v3.2.0+incompatible github.com/labstack/gommon v0.3.0 github.com/mattn/go-colorable v0.1.4 // indirect github.com/mattn/go-isatty v0.0.11 // indirect github.com/stretchr/testify v1.4.0 github.com/valyala/fasttemplate v1.1.0 golang.org/x/crypto v0.0.0-20191227163750-53104e6ec876 golang.org/x/net v0.0.0-20191209160850-c0dbc17a3553 // indirect golang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8 // indirect golang.org/x/text v0.3.2 // indirect ) $ wget &amp;#34;https://proxy.golang.org/github.com/labstack/echo/v4/@v/v4.1.14.zip&amp;#34; $ curl &amp;#34;https://index.golang.org/index?since=2020-02-28T09:00:00.000000Z&amp;amp;limit=5&amp;#34; {&amp;#34;Path&amp;#34;:&amp;#34;github.com/openebs/api&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v0.0.0-20200228085622-f3442fff37bf&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:00:05.62813Z&amp;#34;} {&amp;#34;Path&amp;#34;:&amp;#34;github.com/dirkarnez/dirk-commons&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v0.0.0-20200228090031-1926f326c678&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:00:50.00608Z&amp;#34;} {&amp;#34;Path&amp;#34;:&amp;#34;github.com/jfrog-solutiontest/food&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v4.107.0+incompatible&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:01:10.76502Z&amp;#34;} {&amp;#34;Path&amp;#34;:&amp;#34;github.com/nexus49/dapr-components&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v0.0.0-20200228090009-67e985bdc953&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:01:15.618406Z&amp;#34;} {&amp;#34;Path&amp;#34;:&amp;#34;github.com/Krajiyah/ble-sdk&amp;#34;,&amp;#34;Version&amp;#34;:&amp;#34;v0.0.7-0.20200228090109-03b5ffe425a0&amp;#34;,&amp;#34;Timestamp&amp;#34;:&amp;#34;2020-02-28T09:01:23.38344Z&amp;#34;} $ curl &amp;#34;https://sum.</description>
    </item>
    
    <item>
      <title>Lambda環境でできない処理をECSで実行する</title>
      <link>https://www.sambaiz.net/article/245/</link>
      <pubDate>Mon, 28 Oct 2019 22:54:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/245/</guid>
      <description>以前cdkbotというツールを出した。これはGitHubのPRからCDKのデプロイなどを実行できるツールでlambda上で動いていた。
PR上でCDKのレビューやデプロイを行うツールcdkbotを作った - sambaiz-net
npmやgitといった外部コマンドを実行するため、layerにバイナリを詰めて上げていた。
Lambda上でnpm installできるLayerを作った - sambaiz-net
CDKにはローカルのDockerfileをbuildしてECRに上げてくれる ecs.ContainerImage.fromAsset()という関数があって、これに対応させるためlayerにdockerを追加してみたのだがrootが取れず動かない。 rootなしで動くudockerでdind(docker in docker)のイメージを動かしたりもしてみたがbuildはできなかった。
この他にもCloudFrontなどリソースによっては作成に時間がかかり、Lambdaのタイムアウト上限に到達する問題もあったので、lambda+API Gatewayでwebhookのリクエストだけ受け取り、ECSのTaskを立ち上げて処理を行わせることにした。
templateにECSまわりのものを追加したところ、Serverless Application Repository非対応ということで上げられなくなってしまった。
AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net
Taskへのパラメータの受け渡し runTaskのcontainerOverridesでコマンドの引数としてlambdaに来たリクエストをそのまま渡そうとしたところ、8192文字文字の上限に当たってしまったので SQSで受け渡すことにした。
sess := session.New() sqsSvc := sqs.New(sess) if _, err := sqsSvc.SendMessage(&amp;amp;sqs.SendMessageInput{ MessageBody: aws.String(string(payload)), QueueUrl: aws.String(os.Getenv(&amp;#34;OPERATION_QUEUE_URL&amp;#34;)), MessageGroupId: aws.String(&amp;#34;group&amp;#34;), }); err != nil { fmt.Println(err.Error()) return response{ StatusCode: http.StatusInternalServerError, }, err } 同時実行数を制限する アプリケーションの特性上、同時実行されないようにしたい。 そこで普段はTask0のServiceを作成し、実行するときは要求Taskを1にして、Queueが空になるまで実行させ、最後に0に戻すようにした。Taskがない場合は立ち上がりにやや時間がかかるが、元々Lambdaで動いていたこともあって常に料金が発生する常駐リソースをなるべく使いたくなかった。
sess := session.New() sqsSvc := sqs.New(sess) for { res, err := sqsSvc.</description>
    </item>
    
    <item>
      <title>goyaccでparserを生成しLispのcons,car,cdrの式を評価する</title>
      <link>https://www.sambaiz.net/article/244/</link>
      <pubDate>Tue, 15 Oct 2019 09:41:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/244/</guid>
      <description>GoでLispのcons,car,cdrの式を評価したい。 流れとしては字句解析器(lexer, tokenizer, scanner)でソースコードを分割しtoken列にして、構文解析器(parser)で構文木を作るなりして評価できるようにする。
$ brew install clisp $ clisp &amp;gt; (cons 1 ()) (1) &amp;gt; (cons () 1) (NIL . 1) &amp;gt; (car (cons 1 (cons 2 3))) 1 &amp;gt; (cdr (cons 1 (cons 2 3))) (2 . 3) Goの字句解析器と構文解析器 Goの字句解析器と構文解析器がGoが実装されているので見てみる。
go/scanner ソースコードを分割してgo/tokenにする。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;go/token&amp;#34; &amp;#34;go/scanner&amp;#34; ) func main() { var sc scanner.Scanner src := []byte(`(&amp;#34;A&amp;#34; + &amp;#34;B&amp;#34;) + &amp;#34;C&amp;#34;`) errorHandler := func(pos token.Position, msg string) { fmt.</description>
    </item>
    
    <item>
      <title>K8s上でElastic APMを動かして外部のGo製APIサーバーのリクエストをトレースする</title>
      <link>https://www.sambaiz.net/article/241/</link>
      <pubDate>Tue, 01 Oct 2019 23:25:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/241/</guid>
      <description>Elastic Cloud on Kubernetes (ECK)で Kubernetesクラスタ上にElasticsearch, KibanaとAPM Serverを立ち上げ、外部のGo製APIサーバーのリクエストをトレースする。 クラスタはGKEで作成し、ノードプールはn2-highmem-4(2vCPU, 13GB)の3台にした。
インストール ElasticSearchやKibana, APM ServerのCRDやelastic-operatorなどをインストールする。
KubernetesのCustom Resource Definition(CRD)とCustom Controller - sambaiz-net
$ kubectl apply -f https://download.elastic.co/downloads/eck/0.9.0/all-in-one.yaml customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/trustrelationships.elasticsearch.k8s.elastic.co created customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created clusterrole.rbac.authorization.k8s.io/elastic-operator created clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created namespace/elastic-system created statefulset.apps/elastic-operator created secret/webhook-server-secret created serviceaccount/elastic-operator created $ kubectl get pod -n elastic-system NAME READY STATUS RESTARTS AGE elastic-operator-0 1/1 Running 1 91s $ kubectl -n elastic-system logs -f statefulset.apps/elastic-operator ... {&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1569230702.0881083,&amp;#34;logger&amp;#34;:&amp;#34;kubebuilder.controller&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;Starting workers&amp;#34;,&amp;#34;controller&amp;#34;:&amp;#34;elasticsearch-controller&amp;#34;,&amp;#34;worker count&amp;#34;:1} {&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1569230702.</description>
    </item>
    
    <item>
      <title>Goのnet/http/pprofでCPUやMemoryをprofileする流れと内部実装</title>
      <link>https://www.sambaiz.net/article/238/</link>
      <pubDate>Mon, 16 Sep 2019 13:49:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/238/</guid>
      <description>Goのnet/http/pprofは pprofで可視化できるprofile.protoを返すAPIを提供するpackage。 profileを出力する方法はほかにもあるが、サーバーのような動き続けるアプリケーションのprofileを取るのに使う。
go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる - sambaiz-net
profileを取る import _ &amp;quot;net/http/pprof&amp;quot;してhttp.ListenAndServe()する。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; _ &amp;#34;net/http/pprof&amp;#34; &amp;#34;time&amp;#34; &amp;#34;golang.org/x/crypto/bcrypt&amp;#34; ) func handler(w http.ResponseWriter, r *http.Request) { for i := 0; i &amp;lt; 3; i++ { bcrypt.GenerateFromPassword([]byte(&amp;#34;PASSWORD&amp;#34;), bcrypt.DefaultCost) } arr := []int{} for i := 0; i &amp;lt; 10000; i++ { arr = append(arr, i) } fmt.Fprintf(w, &amp;#34;OK&amp;#34;) } func main() { http.HandleFunc(&amp;#34;/foo&amp;#34;, handler) fmt.Println(&amp;#34;Listening on :8080&amp;#34;) if err := http.</description>
    </item>
    
    <item>
      <title>PR上でCDKのレビューやデプロイを行うツールcdkbotを作った</title>
      <link>https://www.sambaiz.net/article/235/</link>
      <pubDate>Thu, 29 Aug 2019 22:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/235/</guid>
      <description>sambaiz/cdkbot
PRのコメントで/diffや/deployと打つとcdk diffやcdk deployが走る。 diffを見てレビューし、良ければ/deployでデプロイし完了するとmergeされる。
以前CircleCIでmerge時にdeployされる仕組みを作った。
CDK/CircleCI/GitHubでAWSリソース管理リポジトリを作る - sambaiz-net
ただ、この仕組みだと CFnの実行時エラーのためにデプロイできない状態のものがmasterブランチにmergeされてしまい、その修正のために何回も試行錯誤のPRを出すことになったり、 Stack間の依存がある場合リソースを削除するとcdk deployによって依存解決された順序だと失敗してしまうという問題があった。 cdkbotでは必要ならデプロイするStackを選べて、完了してからmergeすることでこれらの問題を解決した。 また、AWS外のCIにとても強い権限を与えていたがそれも必要なくなった。
単純にブランチの状態でデプロイしてしまうと古い状態に巻き戻ってしまう可能性があるので、内部でbaseブランチをmergeしていたり、 ラベルによってそのPRがデプロイ可能かどうかを制御していたりする。 最低限デプロイできるようになってから、この辺りの仕組みを整えるまでに存外に時間がかかった。
Serverless Application Repositoryに公開してあるので簡単にインストールできる。
AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する - sambaiz-net
 追記 (2019-10-26): ap-northeast-1に対応していないのと、ECSのリソースを作成できないため、Serverless Application Repositoryに公開するのはやめた。makeでインストールできる。 Lambda環境でできない処理をECSで実行する - sambaiz-net
 外部コマンド gitやnpmといった外部コマンドを実行する必要があるが、標準では入っていないのでLambda Layerで入れている。
Lambda上でnpm installできるLayerを作った - sambaiz-net
Go moduleのキャッシュ Dockerコンテナ内でテストを実行しているが、毎回go moduleの解決が走ることで時間はかかるし、テザリングの容量に大打撃を受けたので、 ローカルのキャッシュをコピーするようにした。
test: docker build -t cdkbot-npmbin ./npm-lambda-layer docker build -t cdkbot-test -f ./test/Dockerfile . docker rm -f cdkbot-test || true docker run -itd --name cdkbot-test cdkbot-test /bin/sh docker cp .</description>
    </item>
    
    <item>
      <title>Lambda上でnpm installできるLayerを作った</title>
      <link>https://www.sambaiz.net/article/233/</link>
      <pubDate>Tue, 23 Jul 2019 23:44:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/233/</guid>
      <description>Lambda上でnpm installするためにnpmとnode, npmrc入りのLambda Layerを作った。 GitHubにある。
Lambda Layerでバイナリやライブラリを切り出す - sambaiz-net
まずは/usr/bin/npmをそのまま入れて実行してみた。
FROMlambci/lambda-base:buildWORKDIR/optRUN curl -sL https://rpm.nodesource.com/setup_12.x | bash - &amp;amp;&amp;amp; \  yum install -y nodejs &amp;amp;&amp;amp; \  mkdir bin &amp;amp;&amp;amp; \  cp /usr/bin/node bin/node &amp;amp;&amp;amp; \  cp /usr/bin/npm bin/ &amp;amp;&amp;amp; \  zip -yr /tmp/npm-layer.zip ./*$ docker build -t npmbin . $ docker run npmbin cat /tmp/npm-layer.zip &amp;gt; npm-layer.zip &amp;amp;&amp;amp; unzip npm-layer.zip -d layer 相対パスでの参照に失敗したようだが対象のパスが見当たらない。
internal/modules/cjs/loader.js:628 throw err; ^ Error: Cannot find module &amp;#39;.</description>
    </item>
    
    <item>
      <title>Lambda Layerでバイナリやライブラリを切り出す</title>
      <link>https://www.sambaiz.net/article/232/</link>
      <pubDate>Mon, 22 Jul 2019 21:09:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/232/</guid>
      <description>Lambdaで実行したい外部コマンドがある場合、通常バイナリをパッケージに含めることになりデプロイに時間がかかってしまう。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;os/exec&amp;#34; &amp;#34;github.com/aws/aws-lambda-go/events&amp;#34; &amp;#34;github.com/aws/aws-lambda-go/lambda&amp;#34; ) func handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) { cmd := exec.Command(&amp;#34;git&amp;#34;, &amp;#34;clone&amp;#34;, &amp;#34;https://github.com/sambaiz/foobar.git&amp;#34;, &amp;#34;/tmp/repo&amp;#34;) output, err := cmd.CombinedOutput() if err != nil { return events.APIGatewayProxyResponse{ Body: fmt.Sprintf(&amp;#34;%s %s&amp;#34;, string(output), err.Error()), StatusCode: 500, }, nil } return events.APIGatewayProxyResponse{ Body: string(output), StatusCode: 200, }, nil } func main() { lambda.Start(handler) } exec: &amp;#34;git&amp;#34;: executable file not found in $PATH Lambda Layerを使うと ライブラリやバイナリを切り出すことができ、複数Functionで共有することもできる。 ディレクトリをzipにしてLayerに指定すると中身が/optに展開され、/opt/binにはPATHが、/opt/libにはLD_LIBRARY_PATHが通るほか、 言語ごとのパッケージ置き場がある。</description>
    </item>
    
    <item>
      <title>API GatewayでCognitoの認証をかけて必要ならログイン画面に飛ばす処理をGoで書く</title>
      <link>https://www.sambaiz.net/article/226/</link>
      <pubDate>Wed, 03 Jul 2019 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/226/</guid>
      <description>ブラウザから直接API GatewayのエンドポイントにアクセスしたときにCognitoのTokenで認証し、失敗したらログイン画面を表示させる。 API GatewayでCognitoの認証をかける場合、AuthorizerでUserPoolを指定するのが最も簡単なパターンだが、 これだとHeaderにTokenを付けてアクセスする必要があり認証に失敗するとUnauthorizedが返る。
Cognito UserPoolとAPI Gatewayで認証付きAPIを立てる - sambaiz-net
なおAPI GatewayではなくALBをLambdaの前段に挟めば今回やることが簡単に実現できる。
LambdaとALBでCognito認証をかけて失敗したらログイン画面に飛ばす - sambaiz-net
準備 UserPoolとClientを作成する。 CloudFormationで作成する場合SchemaのMutableのデフォルトがfalseで、変えると作り直されてしまうことに注意。
Resources: Userpool: Type: AWS::Cognito::UserPool Properties: AdminCreateUserConfig: AllowAdminCreateUserOnly: false Schema: - Mutable: true Name: email Required: true - Mutable: true Name: name Required: true UsernameAttributes: - email UserPoolName: testpool UserpoolClient: Type: AWS::Cognito::UserPoolClient Properties: UserPoolId: Ref: Userpool ClientName: testclient GenerateSecret: true その後、GoogleのOAuth Client IDを作成し、フェデレーションの設定を行ってGoogleアカウントでもログインできるようにした。 これはID Poolのフェデレーティッドアイデンティティとは異なる機能。 UserPoolのドメインや、外部IdPとのAttributes Mapping、Clientの設定はCloudFormationではできないので手で行う。
 追記 (2020-12-06): 今はCloudFormationで行えるようになっている。
CDKでCognito UserPoolとClientを作成しトリガーやFederationを設定する - sambaiz-net</description>
    </item>
    
    <item>
      <title>AWS SAMでLambdaの関数をデプロイしServerless Application Repositoryに公開する</title>
      <link>https://www.sambaiz.net/article/207/</link>
      <pubDate>Sun, 10 Feb 2019 16:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/207/</guid>
      <description>AWS SAM (Serverless Application Model)はAWS公式の サーバーレスアプリケーションのビルドツール。 CloudFormationのテンプレートを設定ファイルに書くことでLambda関数と共にイベントトリガーや他のリソースも含めてデプロイでき、 その点でServerless Frameworkと立ち位置が近いが、向こうがLambda以外のサーバーレス環境にも対応していたり、 プラグインによって機能拡張できるようになっている一方、こちらは比較的薄いツールになっている。 ただ、Serverless Application Repositoryで公開するにはSAMの形式にする必要があり、 Serverless FrameworkにもSAMのテンプレートを出力するプラグインがある。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
SAM CLIのインストール $ brew tap aws/tap $ brew install aws-sam-cli $ sam --version SAM CLI, version 0.11.0 init initすると次の構成のディレクトリが作られる。
$ sam init --runtime go1.x -n test-sam $ cd test-sam/ $ ls Makefile	README.md	hello-world	template.yaml template.yamlの中に関数の設定やCloudFormationのテンプレートを書く。
$ cat template.yaml AWSTemplateFormatVersion: &amp;#39;2010-09-09&amp;#39; Transform: AWS::Serverless-2016-10-31 Description: &amp;gt;test-sam Sample SAM Template for test-sam # More info about Globals: https://github.</description>
    </item>
    
    <item>
      <title>CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う</title>
      <link>https://www.sambaiz.net/article/206/</link>
      <pubDate>Sun, 03 Feb 2019 17:31:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/206/</guid>
      <description>Aurora ServerlessはオートスケールするAuroraで、 使ったAurora Capacity Unit (ACU)によって料金が発生するため、 使用頻度が少なかったり変動するアプリケーションにおいて安くRDBを使うことができる。 インスタンスを立てると最低でも月3000円くらいかかるが、Serverlessだとほとんどストレージ分から運用することができて趣味でも使いやすい。 ただしLambdaと同様に常に同等のリソースを使っている状態だとインスタンスと比べて割高になる。
今回はLambdaで使う。 Serverlessと名前には付いているが用途としてはLambdaに限らず、 むしろコンテナの数が容易に増え得るLambdaは同時接続数が問題になるRDBと一般に相性が良くない。 現在Betaの、コネクションを張らずにHTTPSでクエリを投げられるData APIはこの問題を解消すると思われるが、トランザクションが張れなかったり、レスポンスサイズに制限があるようだ。今回はコンソール上から初期クエリを流すためにData APIを有効にしている。
他の選択肢として、DynamoDBは現状最有力で最近トランザクションもサポートされたがSQLのように複雑なクエリは投げられない。 Athenaはクエリは投げられるがそこそこ時間がかかるし、INSERT/UPDATEはできずクエリごとに料金が発生する。
Serverless Frameworkを使ってリソースを作成しデプロイする。リポジトリはここ。
Serverless FrameworkでLambdaをデプロイする - sambaiz-net
VPCの作成 Aurora Serverlessの制限の一つとしてVPC内からしか接続しかできないというものがある。ということでVPCから作成していく。以前Terraformで作ったのと同じリソースをCloudFormationで作る。
TerraformでVPCを管理するmoduleを作る - sambaiz-net
LambdaをVPC内で動かすとコンテナ起動時にENIも作成するため立ち上がりの際時間がかかる。必要なら定期的に呼び出して削除されないようにする。 また、今回はテストのため/24でVPCを切っているが、小さいとENIのIPアドレスが枯渇する可能性がある。
 VPC  TestVPC: Type: AWS::EC2::VPC Properties: CidrBlock: 172.32.0.0/24 Tags: - Key: Name Value: test-vpc  Subnet  Aurora Serverlessのために少なくとも2つのサブネットが必要。
TestPublicSubnet: Type: AWS::EC2::Subnet Properties: VpcId: !Ref TestVPC CidrBlock: 172.32.0.0/25 AvailabilityZone: us-east-1d Tags: - Key: Name Value: test-public-subnet1 TestPrivateSubnet1: Type: AWS::EC2::Subnet Properties: VpcId: !</description>
    </item>
    
    <item>
      <title>AWS Systems Manager (SSM)のParameter Storeに認証情報を置き参照する</title>
      <link>https://www.sambaiz.net/article/204/</link>
      <pubDate>Mon, 07 Jan 2019 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/204/</guid>
      <description>DBのパスワードやAPIトークンといった認証情報をバージョン管理するコードや設定ファイル上に書くとOSS化など公開範囲を広げるときにやや困るし漏れるリスクが高まるのでなるべく避けたい。 そこでSSMのParameter Storeに値を置き、実行時やデプロイ時に参照する。
SSMのParameter StoreとSecrets Manager Systems Manager (SSM)はAWSのリソースを可視化したり操作を自動化したりするサービス群で、 設定を持つParameter Storeはその一つ。値は暗号化して持つこともできる。 料金はかからない。
SSMのParameter Storeと似たような別のAWSのサービスに Secrets Managerというのがあって、RDSなどと連携してLambdaによって定期的に新しい値を生成しローテーションさせることができる。 ただし料金がシークレットの件数($0.4/月)とAPIコール($0.05/10000回)でかかる。
CloudFormationでVPCを作成してLambdaをデプロイしAurora Serverlessを使う - sambaiz-net
今はParamter StoreとSecrets Managerが統合されていて、Parameter StoreのAPIでどちらも参照できるようだ。 今回はローテーションしないので単純に料金がかからないParameter Storeの方に書き込むことにする。 ただし、Parameter Storeは現状一度に大量のリクエストが飛ぶような使い方をするとRate exceededになってしまう問題がある。
実行時の値取得 実行時に値を取得するのはこんな感じ。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/awserr&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/ssm&amp;#34; ) type Parameter struct { ssm *ssm.SSM } func newParameter(sess *session.Session) *Parameter { return &amp;amp;Parameter{ ssm: ssm.New(sess), } } func (s *Parameter) Get(name string, decrypt bool) (string, error) { param, err := s.</description>
    </item>
    
    <item>
      <title>Goで高速にJSONを扱うライブラリeasyjsonとfastjson</title>
      <link>https://www.sambaiz.net/article/193/</link>
      <pubDate>Wed, 24 Oct 2018 01:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/193/</guid>
      <description>easyjson easyjsonは次のようなstructごとのコードを自動生成してReflectionなしで高速にJSON Marshal/Unmarshalできるようにするライブラリ。
$ go get -u github.com/mailru/easyjson/... $ cat struct.go package a type Foo struct { A string `json:&amp;#34;a,omitempty&amp;#34;` B *Bar } type Bar struct { C []int `json:&amp;#34;c&amp;#34;` D map[string]int `json:&amp;#34;d&amp;#34;` } $ easyjson -all struct.go $ cat struct_easyjson.go ... func easyjson9f2eff5fEncodeGithubComSambaizBenchjsonA(out *jwriter.Writer, in Foo) { out.RawByte(&amp;#39;{&amp;#39;) first := true _ = first if in.A != &amp;#34;&amp;#34; { const prefix string = &amp;#34;,\&amp;#34;a\&amp;#34;:&amp;#34; if first { first = false out.</description>
    </item>
    
    <item>
      <title>MySQLのtime_zoneとgo-sql-driver/mysqlの設定</title>
      <link>https://www.sambaiz.net/article/189/</link>
      <pubDate>Tue, 02 Oct 2018 22:22:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/189/</guid>
      <description>MySQLのtime_zoneとgo-sql-driver/mysqlの設定による挙動を確認する。
&amp;gt; select version(); +-----------+  | version() | +-----------+  | 5.7.21 | +-----------+ タイムゾーンがロードされていない場合はロードする。
&amp;gt; select count(*) from mysql.time_zone \\G; *************************** 1. row *************************** count(*): 0 $ mysql_tzinfo_to_sql /usr/share/zoneinfo/ | mysql -u root mysql time_zoneはデフォルト値のSYSTEM。つまりJSTで、my.cnfのdefault-time-zoneで変更できる。 NOW()もJSTの時間を返している。
&amp;gt; show variables like &amp;#39;%time_zone%&amp;#39;; +------------------+--------+ | Variable_name | Value | +------------------+--------+ | system_time_zone | JST | | time_zone | SYSTEM | +------------------+--------+  &amp;gt; SELECT NOW(); mysql&amp;gt; SELECT NOW() \G; *************************** 1.</description>
    </item>
    
    <item>
      <title>KubernetesのCustom Resource Definition(CRD)とCustom Controller</title>
      <link>https://www.sambaiz.net/article/182/</link>
      <pubDate>Thu, 09 Aug 2018 23:59:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/182/</guid>
      <description>K8sではDeploymentを作成したときにReplicaSetも作成されるようにしたり、 Load Balancer Serviceを作成したときにGCPなどその環境に応じたLoad Balancerも作成されるようにしたりするため、Controllerがそれらを監視してAPIを呼んでいる。
GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress - sambaiz-net
Controllerは単なるAPIを呼ぶアプリケーションなので自分でCustom Controllerを作成してDeploymentとしてデプロイすることもできる。 また、監視する対象もpodsやdeploymentsといった標準のAPIだけではなく、 Custom Resource で拡張したものを使うことができる。
特定のアプリケーションのためのControllerはOperatorとも呼ばれる。
CustomResourceDefinition(CRD) Custom Resourceを定義する。
apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: crontabs.stable.example.com spec: # REST APIで使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt; group: stable.example.com version: v1 # Namespaced か Cluster scope: Namespaced names: # 複数形 URLに使われる /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;/&amp;lt;plural&amp;gt; plural: crontabs # 単数形 CLIなどで使われる singular: crontab # manifestで使う kind: CronTab shortNames: - ct $ kubectl create -f crd.yaml $ kubectl get crd NAME AGE crontabs.</description>
    </item>
    
    <item>
      <title>GCPのCloud Pub/Sub</title>
      <link>https://www.sambaiz.net/article/180/</link>
      <pubDate>Thu, 26 Jul 2018 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/180/</guid>
      <description>スケーラビリティに優れるメッセージングミドルウェア。 データはPullするだけではなくhttpsのエンドポイントにPushすることもでき、Cloud Dataflowを通してBigQueryやCloud MLに繋げることもできる。GAEのTaskQueueのように遅延させる機能は今のところない。
GAEのTaskQueue - sambaiz-net
料金はPublish/Pull/Pushしたデータ容量による。1TB送ると$60くらい。
Goのクライアントライブラリで動かしてみる。 まずTopicを作成して50件Publishした後、Subsriptionを作成して、再び50件Publishする。 Publishできるデータは10MB未満。
topic, err := client.CreateTopic(ctx, topicName) if err != nil { panic(err) } var wg sync.WaitGroup for i := 0; i &amp;lt; 50; i++ { wg.Add(1) go func() { if _, err := topic.Publish(ctx, &amp;amp;pubsub.Message{Data: []byte(strconv.Itoa(i))}).Get(ctx); err != nil { log.Fatalf(&amp;#34;Publish error: %s&amp;#34;, err.Error()) } else { log.Printf(&amp;#34;Publish successful: %d&amp;#34;, i) } wg.Done() }() wg.Wait() } log.Printf(&amp;#34;Create Subscription&amp;#34;) sub := createSubscription(ctx, client, topic, subscriptionName) for i := 50; i &amp;lt; 100; i++ { wg.</description>
    </item>
    
    <item>
      <title>GAEのTaskQueue</title>
      <link>https://www.sambaiz.net/article/178/</link>
      <pubDate>Sun, 15 Jul 2018 16:03:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/178/</guid>
      <description>GCPのマネージドなQueueサービスとしてGAEのTaskQueueがあることを教えてもらったので動かしてみる。 PushQueueとPullQueueがあって、それぞれおおよそAWSのSNSとSQSに相当する。PushQueueの場合はHTTPのリクエストとしてGAEのサービスに投げられる。PullQueueはCloud Tasks APIを使えばGAE外からも使えるらしいがまだalpha。
設定ファイルqueue.yamlはこんな感じ。bucket_sizeは最大同時実行数で空いていたらrateで埋められていく。
queue: - name: default rate: 10/m bucket_size: 5 retry_parameters: min_backoff_seconds: 10 max_backoff_seconds: 300 bucket_sizeの最大は500なのでこれ以上の性能が必要な場合は複数のQueueに分けるか Cloud Pub/Subを使うことになる。ただし、At-Least-Onceなのでレコードが重複しても問題ないように作る必要がある。SQSも同じ。
GCPのCloud Pub/Sub - sambaiz-net
アプリケーション /にアクセスすると2つのTaskをdefaultのTaskQueueにDelay25秒でPOSTする。 Taskによるリクエストは/workerで受け、30%の確率で500エラーを返すようにしている。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;net/url&amp;#34; &amp;#34;strconv&amp;#34; &amp;#34;time&amp;#34; &amp;#34;google.golang.org/appengine&amp;#34; &amp;#34;google.golang.org/appengine/log&amp;#34; &amp;#34;google.golang.org/appengine/taskqueue&amp;#34; ) func main() { http.HandleFunc(&amp;#34;/&amp;#34;, handler) http.HandleFunc(&amp;#34;/worker&amp;#34;, handlerQueue) appengine.Main() } func handler(w http.ResponseWriter, r *http.Request) { ctx := appengine.NewContext(r) // POST body: name=a%26&amp;amp;value=20 	t := taskqueue.NewPOSTTask(&amp;#34;/worker&amp;#34;, map[string][]string{&amp;#34;name&amp;#34;: {&amp;#34;a&amp;amp;&amp;#34;}, &amp;#34;time&amp;#34;: {strconv.</description>
    </item>
    
    <item>
      <title>WebSocketでの通信内容をWiresharkで見る</title>
      <link>https://www.sambaiz.net/article/177/</link>
      <pubDate>Tue, 10 Jul 2018 23:40:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/177/</guid>
      <description>Webで双方向通信するためのプロトコル、WebSocketでの通信内容をWiresharkで見る。
アプリケーション サーバー package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;golang.org/x/net/websocket&amp;#34; ) type Payload struct { A string } func Handler(ws *websocket.Conn) { ctx, cancel := context.WithCancel(context.Background()) go func() { var payload Payload for { err := websocket.JSON.Receive(ws, &amp;amp;payload) if err != nil { if err == io.EOF { fmt.Println(&amp;#34;connection closed&amp;#34;) } else { fmt.Println(err) } cancel() break } fmt.Println(payload.A) } }() websocket.JSON.Send(ws, Payload{A: &amp;#34;a&amp;#34;}) select { case &amp;lt;-ctx.Done(): } } func main() { http.</description>
    </item>
    
    <item>
      <title>GoのgRPC ServerのInterceptor(recovery/auth/zap/prometheus)</title>
      <link>https://www.sambaiz.net/article/174/</link>
      <pubDate>Tue, 26 Jun 2018 23:50:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/174/</guid>
      <description>grpc-goはInterceptor(Middleware)でhandlerの前後で処理を行うことができる。 UnaryとStreamでシグネチャが異なる。
type UnaryServerInterceptor func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (resp interface{}, err error) type StreamServerInterceptor func(srv interface{}, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error func UnaryServerInterceptor(opts ...Option) grpc.UnaryServerInterceptor { return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) { resp, err := handler(newCtx, req) fmt.Println(resp) return resp, err } } 今回は良く使うgo-grpc-middlewareの
 recovery auth zap prometehus  Interceptorの挙動を確認する。
proto UnaryなRPCとBidirectional streaming(client, server共にstream)なRPCを一つずつ用意する。
$ cat protos/sample/service.</description>
    </item>
    
    <item>
      <title>GKEでのService(ClusterIP/NodePort/LoadBalancer)とIngress</title>
      <link>https://www.sambaiz.net/article/173/</link>
      <pubDate>Sat, 23 Jun 2018 15:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/173/</guid>
      <description>疎通確認用アプリケーション GETでは200を返し、POSTではURLにGETリクエストを送ってステータスコードを返す。
package main import ( &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;net/http&amp;#34; ) type PostBody struct { URL string `json:&amp;#34;url&amp;#34;` } func handler(w http.ResponseWriter, r *http.Request) { if r.Method == http.MethodGet { fmt.Fprintln(w, &amp;#34;ok&amp;#34;) } else if r.Method == http.MethodPost { data, err := ioutil.ReadAll(r.Body) if err != nil { w.WriteHeader(http.StatusInternalServerError) fmt.Fprintln(w, err.Error()) return } p := PostBody{} if err := json.Unmarshal(data, &amp;amp;p); err != nil { w.WriteHeader(http.StatusBadRequest) fmt.Fprintln(w, err.Error()) return } resp, err := http.</description>
    </item>
    
    <item>
      <title>Kubernetesの1PodでAppとfluentdコンテナを動かしてBigQueryに送る</title>
      <link>https://www.sambaiz.net/article/159/</link>
      <pubDate>Tue, 13 Mar 2018 01:04:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/159/</guid>
      <description>Logging AgentをNodeレベルのDaemonSetとして動かすのではなく、Podの中にSidecar Containerとして動かす。その分リソースは食うけど、独立した設定で動かせる。
アプリケーション https://github.com/sambaiz/go-logging-sample
Goで定期的にログを出すサンプルコードを書いたのでこれを使う。 viperで設定を持ち、 zapでログを出力する。 あとSIGINTを拾ってSync()してGraceful Shutdownするようにしている。
Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる - sambaiz-net
multistage-buildして、GKEで動かすのでContainer Registryに上げる。
$ docker build -t go-logging-sample . $ docker tag go-logging-sample gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample:v1 $ gcloud docker -- push gcr.io/&amp;lt;project_id&amp;gt;/go-logging-sample Fluentdの設定 fluent-plugin-bigqueryプラグインを使う。
projectとdataset、パーティションの日付分割テーブルに入れる場合は、auto_create_tableできないのでtableも作成しておく。
fluentdの設定はConfigMapで持つ。
apiVersion: v1 kind: ConfigMap metadata: name: fluentd-config data: fluent.conf: |&amp;lt;source&amp;gt; @type tail format json path /var/log/app.log pos_file /var/log/app.log.pos tag bigquery &amp;lt;/source&amp;gt; &amp;lt;match bigquery&amp;gt; @type bigquery method load &amp;lt;buffer time&amp;gt; @type file path /var/log/bigquery.*.buffer timekey 1d flush_at_shutdown true &amp;lt;/buffer&amp;gt; auth_method	compute_engine project &amp;lt;project-name&amp;gt; dataset &amp;lt;dataset-name&amp;gt; table &amp;lt;table-name&amp;gt;$%Y%m%d fetch_schema true ignore_unknown_values true	&amp;lt;/match&amp;gt; プラグイン入りのfluentdイメージもビルドして上げる。</description>
    </item>
    
    <item>
      <title>xorm reverseでDBスキーマからGoのstructを生成する</title>
      <link>https://www.sambaiz.net/article/153/</link>
      <pubDate>Sat, 10 Feb 2018 15:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/153/</guid>
      <description>GoのORMのxormにはxorm reverseというDBのスキーマから以下のようなテンプレートに沿ったGoのstructなどを生成するツールがある。
package {{.Model}} import ( {{range .Imports}}&amp;#34;{{.}}&amp;#34;{{end}} ) {{range .Tables}} type {{Mapper .Name}} struct { {{$table := .}} {{range .Columns}}	{{Mapper .Name}}	{{Type .}} {{end}} } {{end}} リポジトリにあるテンプレートにxorm用テンプレートとgo用のテンプレートが用意されているように、単体で使うこともできる。 また、テンプレートを書く言語としてもGo以外にC++もサポートしている。
xormのcmdとドライバをインストール。
$ go get github.com/go-xorm/cmd/xorm $ go get github.com/go-sql-driver/mysql $ xorm Version: 0.2.0524 様々な型のカラムを含むテーブルで試す。
$ cat schema.sql CREATE TABLE table1 ( n_tinyint TINYINT, n_int INT, n_int_unsigned INT UNSIGNED NOT NULL DEFAULT 1, n_bigint BIGINT, n_float FLOAT, n_double DOUBLE, d_date DATE, d_datetime DATETIME, s_char CHAR(64), s_varchar VARCHAR(64), s_text TEXT, s_json JSON, b_binary BLOB, e_enum ENUM(&amp;#39;aaa&amp;#39;, &amp;#39;bbb&amp;#39;, &amp;#39;ccc&amp;#39;) ) $ cat setup.</description>
    </item>
    
    <item>
      <title>Gooseリポジトリのmerge時にバージョンを上げmigrationボタンをSlackに出す</title>
      <link>https://www.sambaiz.net/article/149/</link>
      <pubDate>Fri, 19 Jan 2018 09:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/149/</guid>
      <description>GooseはGo製のDB Migrationツール。
コード
こんなリポジトリを作成し、各自ブランチを切ってGoose形式のup/downのSQLを書き、終わったらPullRequestを出す。
goose/ .keep .circleci/config.yml create_test_table.sql $ cat create_test_table.sql -- +goose Up -- SQL in this section is executed when the migration is applied. CREATE TABLE testtable ( id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT, n INT NOT NULL, c VARCHAR (20) NOT NULL UNIQUE ); -- +goose Down -- SQL in this section is executed when the migration is rolled back. DROP TABLE testtable; 無事Approveされ、mergeされるとCircleCIが走り、 SQLをgooseディレクトリの中にバージョンを付けて移し、 SlackにpostMessageするエンドポイントにリクエストを飛ばす。
ここでバージョンを作成することによって、並列で作業し、レビューなどの関係で適用順が前後しても修正する必要をなくしている。ただ、pushされる前に複数のブランチを連続でmergeする場合うまく動かないのでそれはなんとかする必要がある。</description>
    </item>
    
    <item>
      <title>Golangの高速なロガーzapとlumberjackでログを出力してrotateさせる</title>
      <link>https://www.sambaiz.net/article/104/</link>
      <pubDate>Sat, 27 May 2017 16:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/104/</guid>
      <description>https://github.com/uber-go/zap
$ go get -u go.uber.org/zap $ go get -u gopkg.in/natefinch/lumberjack.v2 速さの秘訣 Go言語のLogger「zap」は何故高速に構造化されたログを出力する事が出来るのか｜株式会社CAリワード
reflectionとallocationの回避。
一度allocateしたBufferやEncoderは sync.Poolで使い回している。 このPoolはまさにallocateされたアイテムを再利用するためのもので、GCの負担を緩和させることができる。 Poolのアイテムは勝手に削除されることがあり、もし参照しか持っていなかったらそのままdeallocateされる。
https://github.com/uber-go/zap/blob/v1.4.0/buffer/pool.go#L34
func NewPool() Pool { return Pool{p: &amp;amp;sync.Pool{ New: func() interface{} { return &amp;amp;Buffer{bs: make([]byte, 0, _size)} }, }} } 使い方 現状ドキュメントが乏しいのでコードから探っていく必要がある。 まずはQuick Startから。
zap.NewProduction()はNewProductionConfig().Build(options...)のショートカット。 ConfigをBuildしてLoggerを取得し、InfoやErrorで書く流れ。
logger, _ := zap.NewProduction() defer logger.Sync() logger.Info(&amp;#34;Hoge&amp;#34;, // Structured context as strongly-typed Field values.  zap.Int(&amp;#34;attempt&amp;#34;, 3), zap.Duration(&amp;#34;backoff&amp;#34;, time.Second), ) {&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1495870212.3378785,&amp;#34;caller&amp;#34;:&amp;#34;zap-log/main.go:36&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;Hoge&amp;#34;,&amp;#34;attempt&amp;#34;:3,&amp;#34;backoff&amp;#34;:1} NewProductionConfig()の内容はこんな感じ。ここからOutputPathを書き換えるとファイルに出力されるようにできる。
config := zap.Config{ Level: zap.</description>
    </item>
    
    <item>
      <title>godocのメモ</title>
      <link>https://www.sambaiz.net/article/91/</link>
      <pubDate>Wed, 05 Apr 2017 22:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/91/</guid>
      <description>https://godoc.org/golang.org/x/tools/cmd/godoc
コメントからドキュメントを生成する。
$ godoc cmd/fmt Printf func Printf(format string, a ...interface{}) (n int, err error) Printf formats according to a format specifier and writes to standard output. It returns the number of bytes written and any write error encountered. $ godoc -src cmd/fmt Printf // Printf formats according to a format specifier and writes to standard output. // It returns the number of bytes written and any write error encountered. func Printf(format string, a .</description>
    </item>
    
    <item>
      <title>一定間隔でjsonデータを作って送り続けるCLIツールを作った</title>
      <link>https://www.sambaiz.net/article/76/</link>
      <pubDate>Sat, 04 Mar 2017 23:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/76/</guid>
      <description>Elasticsearchにリアルタイムなテストデータを投入するために、一定間隔でjsonを作って送り続けるCLIツールを作った。Go製。 urfave/cliを使った。
sambaiz/sendjson
こんなindexにデータを入れてみる。
$ curl -XPUT &amp;#39;http://localhost:9200/hoge&amp;#39; -d&amp;#39; { &amp;#34;mappings&amp;#34;: { &amp;#34;test_type&amp;#34;: { &amp;#34;_all&amp;#34;: { &amp;#34;enabled&amp;#34;: false }, &amp;#34;properties&amp;#34;: { &amp;#34;os_name&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;keyword&amp;#34; }, &amp;#34;score&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;byte&amp;#34; }, &amp;#34;@timestamp&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;date&amp;#34;, &amp;#34;format&amp;#34;: &amp;#34;epoch_second&amp;#34; } } } } } &amp;#39; こんな感じでキーに対してtypeと入る値を定義するとそれっぽいデータができて送られていく。
$ go install github.com/sambaiz/sendjson $ sendjson --interval 0.5s --duration 10s --url http://localhost:9200/hoge/test_type &amp;#39; { &amp;#34;os_name&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;or&amp;#34;: [&amp;#34;windows&amp;#34;, &amp;#34;mac&amp;#34;, &amp;#34;linux&amp;#34;, &amp;#34;ios&amp;#34;, &amp;#34;android&amp;#34;]}, &amp;#34;score&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;integer&amp;#34;, &amp;#34;min&amp;#34;: 0, &amp;#34;max&amp;#34;: 100}, &amp;#34;@timestamp&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;time&amp;#34;, &amp;#34;time_format&amp;#34;: &amp;#34;unix_epoch&amp;#34;} }&amp;#39; {&amp;#34;@timestamp&amp;#34;:1488635130,&amp;#34;os_name&amp;#34;:&amp;#34;linux&amp;#34;,&amp;#34;score&amp;#34;:82} {&amp;#34;@timestamp&amp;#34;:1488635130,&amp;#34;os_name&amp;#34;:&amp;#34;windows&amp;#34;,&amp;#34;score&amp;#34;:9} {&amp;#34;@timestamp&amp;#34;:1488635131,&amp;#34;os_name&amp;#34;:&amp;#34;windows&amp;#34;,&amp;#34;score&amp;#34;:73} {&amp;#34;@timestamp&amp;#34;:1488635131,&amp;#34;os_name&amp;#34;:&amp;#34;ios&amp;#34;,&amp;#34;score&amp;#34;:50} {&amp;#34;@timestamp&amp;#34;:1488635132,&amp;#34;os_name&amp;#34;:&amp;#34;windows&amp;#34;,&amp;#34;score&amp;#34;:69} .</description>
    </item>
    
    <item>
      <title>Goroutineの数をworkerで抑制する</title>
      <link>https://www.sambaiz.net/article/74/</link>
      <pubDate>Mon, 27 Feb 2017 23:10:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/74/</guid>
      <description>Goのnet/httpとKeep-Alive - sambaiz.netでやったように、 あるエンドポイントに連続してGoroutineでリクエストを投げると、リクエスト数を増やしたときにタイムアウトが頻発するようになった。
まず、2000リクエストを投げてみた結果。
[RESULT] request: 2000, ok: 2000, ng: 0, time(ms) 138 一応全部捌けてはいるけど、おおよそ同時にリクエストを送っているのにタイムアウト(100ms)時間を超えてしまっている。これをさらに3000に増やしてみる。
[RESULT] request: 3000, ok: 13, ng: 2987, time(ms) 372 ほぼ全滅してしまった・・・。時間もおかしいのでGoroutineでの処理に遅延が発生しているようだ。 そこで、都度Goroutineを生成してリクエストを投げるのではなく、 一定数のWorkerに処理させることで、同時に作られるGoroutineの数を抑制する。
type Req struct { Okch chan int Ngch chan int } func startWorker(ctx context.Context, num int) (requestch chan *Req) { requestch = make(chan *Req) for i := 0; i &amp;lt; num; i++ { go func() { for { select { case req := &amp;lt;-requestch: request(req.</description>
    </item>
    
    <item>
      <title>fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する</title>
      <link>https://www.sambaiz.net/article/66/</link>
      <pubDate>Sun, 19 Feb 2017 23:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/66/</guid>
      <description>fluentdのmonitor_agent メトリクスをjsonで返すAPIを提供する。
&amp;lt;source&amp;gt; @type monitor_agent bind 0.0.0.0 port 24220 &amp;lt;/source&amp;gt; $ curl localhost:24220/api/plugins.json | jq { &amp;#34;plugins&amp;#34;: [ { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590d8c250&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;input&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;forward&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;forward&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;24222&amp;#34;, &amp;#34;bind&amp;#34;: &amp;#34;0.0.0.0&amp;#34; }, &amp;#34;output_plugin&amp;#34;: false, &amp;#34;retry_count&amp;#34;: null }, { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590d894c4&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;input&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;monitor_agent&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;monitor_agent&amp;#34;, &amp;#34;bind&amp;#34;: &amp;#34;0.0.0.0&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;24220&amp;#34; }, &amp;#34;output_plugin&amp;#34;: false, &amp;#34;retry_count&amp;#34;: null }, { &amp;#34;plugin_id&amp;#34;: &amp;#34;object:3f8590dc1f2c&amp;#34;, &amp;#34;plugin_category&amp;#34;: &amp;#34;output&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;config&amp;#34;: { &amp;#34;@type&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/var/log/td-agent/hoge.</description>
    </item>
    
    <item>
      <title>Goのselectの中断処理(close, context)</title>
      <link>https://www.sambaiz.net/article/65/</link>
      <pubDate>Thu, 16 Feb 2017 20:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/65/</guid>
      <description>close(chan) closeしたチャネルを読むとゼロ値になるので、selectで待っているやつにまとめて送れる。
func main() { done := make(chan bool) wg := new(sync.WaitGroup) waitTillDone(wg, done) waitTillDone(wg, done) // こんなことしなくていい 	// done &amp;lt;- true 	// done &amp;lt;- true  close(done) wg.Wait() } func waitTillDone(wg *sync.WaitGroup, done &amp;lt;-chan bool) { wg.Add(1) go func() { select { case v := &amp;lt;-done: fmt.Println(v) // false (ゼロ値) 	wg.Done() } }() } context key-valueの値を渡せるほかにキャンセルやタイムアウトの仕組みをもつ。
ctx := context.Background() // empty context ctx, cancel = context.WithCancel(ctx) ctx, cancel = context.</description>
    </item>
    
    <item>
      <title>GoでDynamoDBを使う</title>
      <link>https://www.sambaiz.net/article/63/</link>
      <pubDate>Sun, 12 Feb 2017 23:15:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/63/</guid>
      <description>テーブルを作成する プライマリキー テーブルの操作のガイドライン - Amazon DynamoDB
プライマリキーとしてパーティションキー(ハッシュキー)とオプションのソートキー(レンジキー)を設定する。 DynamoDBはこのパーティションキーに基づいて、複数のパーティションに分散して保存する。 テーブルにプロビジョニングされたスループット性能はパーティション間で均等に使われるので、 ソートキーを設定する場合にこれを最大限に活用するためには、 あるパーティションにリクエストが集中しないよう、パーティションキーに特定の値ばかり集中しないようなフィールドを 選ぶ必要がある。
セカンダリインデックス パーティションキーのグローバルセカンダリインデックス(GSI)と ソートキーのローカルセカンダリインデックス(LSI)がある。 射影されるフィールドを選択でき、ここに含まれないフィールドは返さない。 ただし、すべてをインデックスに書き込むのはコストが高いのでなるべく絞る。
キャパシティユニット  1読み込みキャパシティユニット: 4kbを超えないデータを1秒に1~2回(整合性による)読み込める 1書き込みキャパシティユニット: 1kbを超えないデータを1秒に1回書き込める  ユニットに応じて1時間あたりで課金される。
未使用のキャパシティがある場合、最大5分保持してバーストに備えてくれる。
読み書きする aws-sdk-goを直接使ってもいいけど、簡単に扱えるラッパー guregu/dynamo を使うことにした。
type Data struct { ID int64 `dynamo:&amp;#34;id&amp;#34;` Name string Age int } db := dynamo.New(session.New(), &amp;amp;aws.Config{Region: aws.String(&amp;#34;ap-northeast-1&amp;#34;)}) table := db.Table(&amp;#34;testtable&amp;#34;) Create &amp;amp; Update d := Data{ID: 1, Name: &amp;#34;hogefuga&amp;#34;, Age: 123} if err := table.Put(d).Run(); err != nil { return err } if err := table.</description>
    </item>
    
    <item>
      <title>Goのnet/httpとKeep-Alive</title>
      <link>https://www.sambaiz.net/article/61/</link>
      <pubDate>Tue, 07 Feb 2017 22:42:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/61/</guid>
      <description>Keep-AliveするとTCPコネクションを使い回し、名前解決やコネクション(3 way handshake)を毎回行わなくてよくなる。 Goのnet/httpではデフォルトでKeep-Aliveが 有効になっているが、 全体と同一ホストでそれぞれKeep-Aliveするコネクション数が制限される。 これらの値はClientのTransportが持っていて、 これがnullだとDefaultTransportが参照されるので、意識しなければこの値が使われる。
 MaxIdleConns: DefaultTransportでは100になっている。0にすると無制限。 MaxIdleConnsPerHost: デフォルト値は2。0にするとデフォルト値が使われる。  同一のホストに同時にたくさんリクエストする場合、2だとほとんど意味を持たない。これを増やして比較してみた。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;time&amp;#34; ) var client = http.Client{ Timeout: time.Millisecond * 100, } const TOTAL_REQUEST_NUM = 3000 const TARGET_URL = &amp;#34;*****&amp;#34; func main() { http.DefaultTransport.(*http.Transport).MaxIdleConns = 0 http.DefaultTransport.(*http.Transport).MaxIdleConnsPerHost = 3000 okChan := make(chan int, TOTAL_REQUEST_NUM) ngChan := make(chan int, TOTAL_REQUEST_NUM) var okCount = 0 var ngCount = 0 // connect and keep-alive 	for i := 0; i &amp;lt; TOTAL_REQUEST_NUM; i++ { go request(okChan, ngChan) } for { select { case &amp;lt;-okChan: okCount++ case &amp;lt;-ngChan: ngCount++ } if okCount+ngCount == TOTAL_REQUEST_NUM { break } } okCount = 0 ngCount = 0 startNs := time.</description>
    </item>
    
    <item>
      <title>Goのnet/http.Client.Doの内部実装をたどったメモ</title>
      <link>https://www.sambaiz.net/article/53/</link>
      <pubDate>Mon, 30 Jan 2017 20:55:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/53/</guid>
      <description>package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;io/ioutil&amp;#34; ) var client = http.Client{} func main() { req, err := http.NewRequest(&amp;#34;GET&amp;#34;, &amp;#34;http://example.com&amp;#34;, nil) if err != nil{ panic(err) } resp, err := client.Do(req) if err != nil{ panic(err) } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil{ panic(err) } fmt.Println(string(body)) } Client TransportがTCPコネクションをキャッシュするのでClientは使い回すべき。複数のgoroutineでコンカレントに使っても大丈夫。
https://github.com/golang/go/blob/964639cc338db650ccadeafb7424bc8ebb2c0f6c/src/net/http/client.go#L36
type Client struct { // nilならDefaultTransportが使われる  Transport RoundTripper // nilなら10回で止まる  CheckRedirect func(req *Request, via []*Request) error // nilならcookieは無視される  Jar CookieJar Timeout time.</description>
    </item>
    
    <item>
      <title>Goのinterface/structの埋め込み</title>
      <link>https://www.sambaiz.net/article/50/</link>
      <pubDate>Wed, 18 Jan 2017 01:39:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/50/</guid>
      <description>Goには継承が存在しない。その代わりstructを埋め込み、委譲することができる。
https://golang.org/doc/effective_go.html#embedding
挙動 interfaceにinterfaceを埋め込む type I interface { Hoge() } type J interface { Fuga() } type K interface { I J } インタフェースKはIとJを合わせたものになる。IとJに重複する関数がある場合はエラーになる。
type L struct { } func (l L) Hoge() { fmt.Println(&amp;#34;hoge&amp;#34;) } func (l L) Fuga() { fmt.Println(&amp;#34;fuga&amp;#34;) } var k K k = L{} k.Hoge() k.Fuga() structにinterfaceを埋め込む type K interface { Hoge() Fuga() } type M struct { K } 埋め込むとm.Hoge()のように透過的にKを扱うことができるようになる。
m := M{L{}} m.Hoge() // m.</description>
    </item>
    
    <item>
      <title>Goのpanicとrecover</title>
      <link>https://www.sambaiz.net/article/49/</link>
      <pubDate>Tue, 17 Jan 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/49/</guid>
      <description>panic https://golang.org/pkg/builtin/#panic
panicは現在のgoroutineの通常の実行を停止する組み込み関数。 index out of rangeや invalid memory address or nil pointer dereference のときなどでも呼ばれる。
deferを実行して呼び出し元に戻り、panicの実行-&amp;gt;deferの実行-&amp;gt;呼び出し元に戻る、を繰り返して 最後まで戻ったらプログラムを終了し、panicに渡した引数と共にエラーをレポートする。
func main() { a() } func a() { defer fmt.Println(&amp;#34;a&amp;#34;) b() fmt.Println(&amp;#34;a2&amp;#34;) } func b() { defer fmt.Println(&amp;#34;b1&amp;#34;) panic(&amp;#34;b2&amp;#34;) defer fmt.Println(&amp;#34;b3&amp;#34;) } b1 a panic: b2 goroutine 1 [running]: panic(0x89840, 0xc42000a2c0) /*****/libexec/src/runtime/panic.go:500 +0x1a1 main.b() /*****/main.go:19 +0x107 main.a() /*****/main.go:13 +0xce main.main() /*****/main.go:8 +0x14 exit status 2 recover https://golang.org/pkg/builtin/#recover
deferで呼ぶことによってpanicを停止させることができる組み込み関数。 panicの引数に渡した値を取得できる。
func main() { fmt.Println(a()) fmt.</description>
    </item>
    
    <item>
      <title>go testでベンチマークを取ってpprofで時間がかかっている箇所を調べる</title>
      <link>https://www.sambaiz.net/article/47/</link>
      <pubDate>Wed, 04 Jan 2017 23:58:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/47/</guid>
      <description>この関数のベンチマークを取る。
package cal import ( &amp;#34;math/big&amp;#34; ) var cache = map[int]*big.Int{} func resetCache() { cache = map[int]*big.Int{} } func Fibonacci(n int) *big.Int { if c := cache[n]; c != nil { return c } ret := new(big.Int) before := big.NewInt(1) for i := 1; i &amp;lt; n; i++ { tmp := new(big.Int).Add(ret, before) before = ret ret = tmp cache[i] = ret } cache[n] = ret return ret } 引数にtesting.Bを取る、Benchmarkから始まる関数を書いて、b.N回ループさせる。</description>
    </item>
    
    <item>
      <title>GoogleのkvsライブラリLevelDBを使う</title>
      <link>https://www.sambaiz.net/article/45/</link>
      <pubDate>Sat, 24 Dec 2016 21:18:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/45/</guid>
      <description>LevelDBとは https://github.com/google/leveldb
Googleが作った高速なkey-valueストレージライブラリ。
ChromeのIndexedDBやprometheusなどで使われている。
特徴  Keyと任意のバイト配列のValue データはKeyでソートされる。ソートのための比較関数はオーバーライドできる。 基本的な操作はPut, Get, Delete。 複数の変更を一つのatomicなバッチで行える 一環したデータのビューを取得するために、一時的なスナップショットを作成できる データを前にも後ろにもイテレーションできる データはSnappy compression libraryで自動で圧縮される。 ファイルシステムの操作など外部のアクティビティを仮想的なインタフェースを通して行うので、OSとのやりとりをカスタマイズできる。  制限  SQLデータベースではない。リレーショナルなデータモデルは持てないし、SQLやインデックスにも対応していない。 一度に一つのプロセスしかDBにアクセスできない。  キャッシュ  DBはファイルシステムのディレクトリに対応する名前を持ち、内容はそのディレクトリに保存される。 各ファイルには圧縮したブロックが保存され、良く使うものについては非圧縮のブロックがキャッシュされる。 ソートして隣接するキーは通常、同じブロックに配置される。ディスク転送とキャッシュはブロック単位。  フィルタ  Getの際、不要なデータを読まなくていいようにフィルタ(Bloom Filter)を用いることができる。 独自の比較関数(末尾のスペースを無視するなど)を使う場合、Bloom Filterを使うことができないことがあるので、その場合は独自のフィルタが必要。  レベル  最近の更新はログファイルに保存される。これが決められたサイズ(デフォルトでは約4MB)に達すると、sorted table(sst)に変換され、新しいログファイルが生成される。 現在のログファイルのコピーがメモリ(memtable)にも乗って読み取りで参照される。 sstはキーによってソートされたエントリーを保存する。エントリーはキーの値か、削除マーカー。 sstはレベルによってまとめられる。ログファイルから変換されると、特別なyoungレベル(level-0とも呼ばれる)に配置される。 youngファイルの数があるしきい値(現在4つ)を超えると全てのyoungファイルを全てのlevel-1ファイルとマージし、新しいlevel-1ファイルを生成する(2MBごとに1ファイル)。 youngレベルのファイルにはキーが重複していることがある。しかし、他のレベルでは重複しないキーの範囲がある。 level-L(L&amp;gt;=1)のファイルの合計サイズが10^L MBを超えたとき、level-Lのファイルと、level-(L+1)の全てのファイルをマージし、新しいlevel-(L+1)ファイルを生成する。 これによって、バルク読み込み/書き込みのみを使い、コストが高いシークを最小限にして、youngレベルから大きいレベルに更新を徐々にマイグレーションすることができる。  動かしてみる LevelDBのgo実装。
syndtr/goleveldb
$ go get github.com/syndtr/goleveldb/leveldb まずDBを開く。
// open db, err := leveldb.OpenFile(&amp;#34;/Users/sambaiz/leveldb&amp;#34;, nil) defer db.Close() if err != nil { panic(err) } 普通に5個(key0~4)、バッチで5個(key5~9)のデータを入れて、そのうち一つを消す。</description>
    </item>
    
    <item>
      <title>gvmでGoのバージョン管理</title>
      <link>https://www.sambaiz.net/article/44/</link>
      <pubDate>Tue, 20 Dec 2016 20:52:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/44/</guid>
      <description>moovweb/gvm
必要なものはREADMEを見て入れる。
$ bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) $ source ${HOME}/.gvm/scripts/gvm $ gvm install go1.7 -B $ gvm use go1.7 $ go version go version go1.7 linux/amd64 $GOPATHと$GOROOTが書き変わる(${HOME}/.gvm/pkgsets/go1.7/global/)ので注意。</description>
    </item>
    
    <item>
      <title>aws-sdk-goでs3にput/get</title>
      <link>https://www.sambaiz.net/article/38/</link>
      <pubDate>Wed, 30 Nov 2016 20:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/38/</guid>
      <description>aws-sdk-goでS3にputしてgetする。
package main import ( &amp;#34;bytes&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/aws/session&amp;#34; &amp;#34;github.com/aws/aws-sdk-go/service/s3&amp;#34; ) const REGION = &amp;#34;ap-northeast-1&amp;#34; const BUCKET_NAME = &amp;#34;faweijojio4f3e4&amp;#34; func main() { sess, err := session.NewSession(aws.NewConfig().WithRegion(REGION)) if err != nil { fmt.Println(err.Error()) return } svc := s3.New(sess) // put 	data := []byte(&amp;#34;BBBBBB&amp;#34;) key := &amp;#34;AAA.txt&amp;#34; params := &amp;amp;s3.PutObjectInput{ Bucket: aws.String(BUCKET_NAME), Key: aws.String(key), Body: bytes.NewReader(data), ContentLength: aws.Int64(int64(len(data))), ContentType: aws.String(&amp;#34;text/plain&amp;#34;), } if _, err = svc.PutObject(params); err != nil { fmt.Println(err.Error()) return } // bucket list 	keys := []string{} err = svc.</description>
    </item>
    
    <item>
      <title>Goでstructをリフレクションしてcsvを出力する</title>
      <link>https://www.sambaiz.net/article/37/</link>
      <pubDate>Mon, 28 Nov 2016 21:29:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/37/</guid>
      <description>こんなstructとデータがあったら、
type Result struct{ Name string `col:&amp;#34;who&amp;#34;` Point int } x := Result{&amp;#34;sam&amp;#34;, 100} フィールド名と、値、タグはrefrectで取れる。
x := Result{&amp;#34;sam&amp;#34;, 100} v := reflect.ValueOf(x) fmt.Println(v.Type().Field(0).Name) // -&amp;gt; Name fmt.Println(v.Type().Field(1).Name) // -&amp;gt; Point fmt.Println(v.Field(0).Interface()) // -&amp;gt; sam fmt.Println(v.Field(1).Interface()) // -&amp;gt; 100 fmt.Println(v.Type().Field(0).Tag.Get(&amp;#34;col&amp;#34;)) // -&amp;gt; who fmt.Println(v.Type().Field(1).Tag.Get(&amp;#34;col&amp;#34;)) // -&amp;gt; これらをencoding/csvで書く。
ただ、引数を[]interface{}にするとinterface{}のスライスしか渡せないので、 一旦interface{}で受け取ってスライスにする。このときにもrefrectを使っている。
package main import ( &amp;#34;encoding/csv&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;os&amp;#34; &amp;#34;reflect&amp;#34; &amp;#34;strings&amp;#34; ) type Result struct { Name string `col:&amp;#34;who&amp;#34;` Point int Age int `col:&amp;#34;-&amp;#34;` // ignore } const COLTAG = &amp;#34;col&amp;#34; func main() { x := []Result{Result{&amp;#34;sam&amp;#34;, 100, 24}, Result{&amp;#34;tom&amp;#34;, 0, 100025}} file, err := os.</description>
    </item>
    
    <item>
      <title>GolangでAPIとテストを書く(echo/dbr/glide/goose/mock)</title>
      <link>https://www.sambaiz.net/article/15/</link>
      <pubDate>Mon, 15 Aug 2016 04:07:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/15/</guid>
      <description>以下の記事を参考にして簡単なAPIとそのテストを書いてみた。コードはここ。
Go言語でTestableなWebアプリケーションを目指して｜サイバーエージェント 公式エンジニアブログ
使った主なライブラリ・ツール echo webフレームワーク。速いらしい。
$ go get -u github.com/labstack/echo func main() { conn, err := dbr.Open(&amp;#34;mysql&amp;#34;, &amp;#34;root:@tcp(localhost:3306)/mboard&amp;#34;, nil) if err != nil { panic(err) } conn.SetMaxIdleConns(200) conn.SetMaxOpenConns(200) e := echo.New() // middlewares  e.Use(middleware.Logger()) e.Use(middleware.Recover()) e.Use(middleware.CORSWithConfig(middleware.CORSConfig{ AllowOrigins: []string{&amp;#34;*&amp;#34;}, AllowMethods: []string{echo.GET, echo.PUT, echo.POST, echo.DELETE}, })) // endpoints  e.GET(&amp;#34;/&amp;#34;, func(c echo.Context) error { return c.String(http.StatusOK, &amp;#34;Hello, World!&amp;#34;) }) e.GET(&amp;#34;/messages&amp;#34;, func(c echo.Context) error { return handler.NewMessageWithSession(conn.NewSession(nil)).GetMessages(c) }) e.POST(&amp;#34;/messages&amp;#34;, func(c echo.Context) error { return handler.</description>
    </item>
    
  </channel>
</rss>
