<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/spark/</link>
    <description>Recent content in Spark on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Mon, 05 May 2025 18:56:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Snowflake の Spark コネクタでクエリを実行する</title>
      <link>https://www.sambaiz.net/article/534/</link>
      <pubDate>Mon, 05 May 2025 18:56:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/534/</guid>
      <description>&lt;p&gt;アプリケーションから Snowflake のデータを参照する方法として JDBC で接続する &lt;a href=&#34;https://docs.snowflake.com/en/user-guide/spark-connector&#34;&gt;Spark コネクター&lt;/a&gt;や &lt;a href=&#34;https://docs.snowflake.com/en/developer-guide/snowpark/index&#34;&gt;Snowpark API&lt;/a&gt; がある。いずれの場合も基本的には Snowflake のコンピューティングリソースを用いてクエリが遅延評価されるが、Spark の UDF など変換できない処理は &lt;a href=&#34;https://docs.snowflake.com/en/user-guide/spark-connector-use#pushdown&#34;&gt;Spark クラスタ側で実行される&lt;/a&gt;のに対して、Snowpark API は全ての処理が Snowflake 側で行われることが保証されておりクラスタを立てなくてもよいという点で推奨されている。ただ、Snowflake 外に大きなデータがあるなど Spark で処理する場合は Spark の Dataframe を返す Spark コネクターが便利。&lt;/p&gt;</description>
    </item>
    <item>
      <title>EMR Serverless から S3 Tables に Iceberg テーブルを作成しデータを書き込んで Athena からクエリする</title>
      <link>https://www.sambaiz.net/article/528/</link>
      <pubDate>Tue, 18 Feb 2025 20:47:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/528/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables.html&#34;&gt;S3 Tables&lt;/a&gt; は re:Invent 2024 で&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/aws-weekly-20241202-1/&#34;&gt;発表された&lt;/a&gt; Iceberg テーブルに特化したストレージ。併せて発表されたオブジェクトの最終変更日時などのメタデータをクエリできる &lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/userguide/metadata-tables-schema.html&#34;&gt;S3 Metadata&lt;/a&gt; も S3 Tables へ書き込む。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/523/&#34;&gt;Spark で Iceberg テーブルを作成しスキーマや write mode を変更してデータを書き込みメタデータの内容を確認する - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>EMR Studio の Jupyter Notebook から EMR Serverless で Spark の MLlib を動かす</title>
      <link>https://www.sambaiz.net/article/527/</link>
      <pubDate>Tue, 11 Feb 2025 14:52:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/527/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio.html&#34;&gt;EMR Studio&lt;/a&gt; はEMR クラスタで実行される Jupyter Notebook ベースの IDE。クラスタや S3 の料金はかかるがこれ自体は無料。&lt;a href=&#34;https://aws.amazon.com/emr/serverless&#34;&gt;EMR Serverless&lt;/a&gt; で動かすことで常時クラスタを立てておくことなく手軽に使うことができる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Iceberg テーブルを Glue Data Catalog に登録して Athena や Snowflake からクエリする</title>
      <link>https://www.sambaiz.net/article/525/</link>
      <pubDate>Thu, 30 Jan 2025 20:31:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/525/</guid>
      <description>&lt;p&gt;Glue Data Catalog に Iceberg テーブルを登録すると、他のテーブルと同様に Athena や EMR などから参照できるほか、Snowflake ではスキーマを渡すことなく &lt;a href=&#34;https://docs.snowflake.com/en/user-guide/tables-iceberg&#34;&gt;ICEBERG TABLE&lt;/a&gt; を作成することができ、メタデータの二重管理を避けることができる。また自動で &lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/enable-compaction.html&#34;&gt;compaction したり&lt;/a&gt;、ジョブの失敗時に生まれるメタデータから参照されていない&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/enable-orphan-file-deletion.html&#34;&gt;orphan files を掃除したり&lt;/a&gt;する機能まである。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark で Iceberg テーブルを作成しスキーマや write mode を変更してデータを書き込みメタデータの内容を確認する</title>
      <link>https://www.sambaiz.net/article/523/</link>
      <pubDate>Sat, 25 Jan 2025 23:18:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/523/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://iceberg.apache.org/&#34;&gt;Apache Iceberg&lt;/a&gt; は大規模なデータの処理を効率的に行えるようにするオープンなテーブルフォーマットで &lt;a href=&#34;https://trino.io/docs/current/connector/iceberg.html&#34;&gt;Trino&lt;/a&gt;、&lt;a href=&#34;https://docs.snowflake.com/en/user-guide/tables-iceberg&#34;&gt;Snowflake&lt;/a&gt; など様々なシステムから利用できる。ACID なトランザクション、元データを書き換えることなくテーブルのスキーマを変更できる Schema Evolution、タイムトラベルに加え、Hive の day=xxxx/ のような物理構造に依存せず day(event_ts) や month(event_ts) といったテーブルには含まれない論理的な値によって PARTITION BY する &lt;a href=&#34;https://iceberg.apache.org/docs/latest/partitioning/#icebergs-hidden-partitioning&#34;&gt;Hidden Partitioning&lt;/a&gt; によって、パーティションの粒度を意識することなく WHERE event_ts BETWEEN 2025-01-01 AND 2025-03-01 のようにクエリでき、またクエリを壊すことなく粒度を変更する &lt;a href=&#34;https://iceberg.apache.org/docs/latest/evolution/#partition-evolution&#34;&gt;Partition evolution&lt;/a&gt; を行うこともできる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>カーディナリティを確率的に推定する HyperLogLog&#43;&#43; で膨大なデータに対する count-distinct での OOM を回避する</title>
      <link>https://www.sambaiz.net/article/497/</link>
      <pubDate>Mon, 02 Sep 2024 21:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/497/</guid>
      <description>&lt;p&gt;アクセスログのユーザー数などユニークな要素数を数える際 count(distinct column_name) のようなクエリを実行することがある。データが膨大な場合、通常の count() はデータを分割して合算することでスケールさせることができるが、distinct する場合はその方法が取れずメモリ不足によって極端に処理が遅くなったり、最悪 OOM で失敗してしまいどうしようもなくなってしまうことがある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark の Broadcast variables や Accumulator で Executor に変数を共有する</title>
      <link>https://www.sambaiz.net/article/494/</link>
      <pubDate>Thu, 22 Aug 2024 09:39:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/494/</guid>
      <description>&lt;p&gt;Executor に変数を共有する仕組みとして &lt;a href=&#34;https://spark.apache.org/docs/3.5.1/rdd-programming-guide.html#broadcast-variables&#34;&gt;Broadcast variables&lt;/a&gt; と &lt;a href=&#34;https://spark.apache.org/docs/3.5.1/rdd-programming-guide.html#accumulators&#34;&gt;Accumulator&lt;/a&gt; がある。&lt;/p&gt;&#xA;&lt;p&gt;Broadcast variables はノードにキャッシュされる read-only な変数。Stageごとに共通で必要なデータは自動で broadcast され、Task の実行前にデシリアライズされるが、複数の stage で必要なデータがある場合やデシリアライズされた状態で持っておきたい場合、 SparkContext.broadcast() で明示的に変数を broadcast することが有効にはたらく。&lt;/p&gt;</description>
    </item>
    <item>
      <title>LivyのREST APIを呼んでSparkジョブを実行する</title>
      <link>https://www.sambaiz.net/article/489/</link>
      <pubDate>Wed, 29 May 2024 23:27:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/489/</guid>
      <description>&lt;p&gt;Livy の &lt;a href=&#34;https://livy.apache.org/docs/latest/rest-api.html&#34;&gt;REST API&lt;/a&gt; を呼んで Spark ジョブを実行してみる。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/486/&#34;&gt;Livy を EMR on EKS にインストールしSparkmagic でローカルの Jupyter Notebook から Spark のジョブを実行する - sambaiz-net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;まず &lt;a href=&#34;https://livy.apache.org/docs/latest/rest-api.html#session&#34;&gt;Session&lt;/a&gt; を作成し idle 状態になるまで待つ。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Livy を EMR on EKS にインストールしSparkmagic でローカルの Jupyter Notebook から Spark のジョブを実行する</title>
      <link>https://www.sambaiz.net/article/486/</link>
      <pubDate>Wed, 22 May 2024 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/486/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://livy.apache.org/&#34;&gt;Apache Livy&lt;/a&gt; は Spark クラスタとやり取りするための REST API を提供し、&lt;a href=&#34;https://github.com/jupyter-incubator/sparkmagic&#34;&gt;Sparkmagic&lt;/a&gt; はこの API を呼ぶことで Jupyter Notebooks からリモートの Spark クラスタでジョブを実行する。Athena for Apache Spark でも使われていて、インタラクティブにジョブを実行し結果を確認できるのはデバッグやアドホックなクエリを実行したりするのに便利だ。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark の MLlib で k-means法によるクラスタリングを行う</title>
      <link>https://www.sambaiz.net/article/446/</link>
      <pubDate>Sun, 09 Apr 2023 17:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/446/</guid>
      <description>&lt;p&gt;Spark には &lt;a href=&#34;https://spark.apache.org/docs/latest/ml-guide.html&#34;&gt;MLlib&lt;/a&gt; という機械学習のライブラリがあり、&#xA;今回はその中の &lt;a href=&#34;https://spark.apache.org/docs/latest/ml-clustering.html#k-means&#34;&gt;Kmeans&lt;/a&gt; によるクラスタリングを行う。&#xA;k-means法は各データのクラスタを事前に決めた数からランダムに決めて、クラスタごとに中心を取ってから、各データのクラスタを最も近い中心のクラスタに変更する、というのを収束するまで繰り返すという手法。&#xA;Kmeans には収束が早い k-means++法が実装されており、distanceMeasure はデフォルトで euclidean となっている。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Task nodes で EMR クラスタのスケールインを高速化する</title>
      <link>https://www.sambaiz.net/article/445/</link>
      <pubDate>Sun, 19 Mar 2023 22:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/445/</guid>
      <description>&lt;p&gt;EMR クラスタは YARN の ResourceManager などが動く Master (primary) node と、 Core nodes および Task nodes から&lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html&#34;&gt;構成される&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/427/&#34;&gt;Hadoop YARN によってアプリケーションにリソースが割り当てられる流れと割り当てられているリソース量の確認 - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athena for Apache Spark の Notebook で DataFrame.toPandas().plot() した際の日本語が文字化けしないようにする</title>
      <link>https://www.sambaiz.net/article/438/</link>
      <pubDate>Mon, 06 Feb 2023 23:58:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/438/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/athena/latest/ug/notebooks-spark.html&#34;&gt;Athena for Apache Spark&lt;/a&gt; は re:Invent 2022 で発表された マネージドでサーバーレスな Jupyter Notebook からインタラクティブに Spark による分析が行える機能。&#xA;Athena は アドホックに SQL を実行して分析できる手軽さと、サーバーレスによって使ってない時間帯は料金がかからない利点があったが、&#xA;重いクエリを実行すると scale factor やタイムアウトによって失敗することがあったので今回 Spark が動かせるようになり用途の幅の広がりを感じる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>CDK で EKS クラスタを立ち上げ EMR on EKS に登録し Spark のジョブを動かす</title>
      <link>https://www.sambaiz.net/article/434/</link>
      <pubDate>Mon, 02 Jan 2023 14:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/434/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/emr-eks.html&#34;&gt;EMR on EKS&lt;/a&gt; は EKS 上で Spark を動かす機能。&#xA;通常の EMR が Hadoop クラスタの管理も行うのに対して、EMR on EKS はコンテナの起動のみを担う。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/409/&#34;&gt;AWS CLIでEMRクラスタを立ち上げSparkのアプリケーションを実行する - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>ScalaでSparkのアプリケーションを開発してGitHub ActionsでデプロイしEMRでリモートデバッグする</title>
      <link>https://www.sambaiz.net/article/420/</link>
      <pubDate>Fri, 21 Oct 2022 23:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/420/</guid>
      <description>&lt;p&gt;Spark は開発で用いられている Scala に加えて Java や Python のAPIを提供しており、技術スタックや他コンポーネントとの兼ね合いなどによって選択することができる。&lt;/p&gt;&#xA;&lt;p&gt;Python は データ分析や機械学習のスキルセットとの親和性の高さや Glue Studio 上で編集して実行できる手軽さがある一方、エラーが分かりづらく JVM と Python Worker 間でデータをやり取りする必要があるのでパフォーマンスの点でも不利。&#xA;また、JVM の制御の外である Python インタプリタが YARN などのリソースマネージャによって割り当てられた以上のメモリを確保してしまうと executor が kill されてしまう。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SparkをビルドしIntelliJでリモートデバッグする</title>
      <link>https://www.sambaiz.net/article/419/</link>
      <pubDate>Sun, 09 Oct 2022 19:06:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/419/</guid>
      <description>&lt;h2 id=&#34;コマンドラインでのビルド&#34;&gt;&lt;a href=&#34;https://spark.apache.org/docs/3.3.0/building-spark.html&#34;&gt;コマンドラインでのビルド&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ git clone &lt;span style=&#34;color:#6272a4&#34;&gt;--branch v3.3.0 --depth 1 https://github.com/apache/spark.git &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://asdf-vm.com/guide/getting-started.html#_3-install-asdf&#34;&gt;asdf&lt;/a&gt; で Java 8 をインストールする。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ brew install asdf&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ echo &lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;e &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;\n. $(brew --prefix asdf)/libexec/asdf.sh&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ${ZDOTDIR:&lt;span style=&#34;color:#ff79c6&#34;&gt;-~&lt;/span&gt;}&lt;span style=&#34;color:#ff79c6&#34;&gt;/&lt;/span&gt;.zshrc&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf &lt;span style=&#34;color:#6272a4&#34;&gt;--version&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#6272a4&#34;&gt;&lt;/span&gt;v0.&lt;span style=&#34;color:#bd93f9&#34;&gt;10&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;2&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf plugin&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;add&lt;/span&gt; java&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf list&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;all&lt;/span&gt; java&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf install java corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ asdf &lt;span style=&#34;color:#ff79c6&#34;&gt;global&lt;/span&gt; java corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ echo &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;. ~/.asdf/plugins/java/set-java-home.zsh&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ff79c6&#34;&gt;~/&lt;/span&gt;.zprofile&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ java &lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;version&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;openjdk &lt;span style=&#34;color:#ff79c6&#34;&gt;version&lt;/span&gt; &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;1.8.0_342&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenJDK Runtime Environment Corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt; (build &lt;span style=&#34;color:#bd93f9&#34;&gt;1&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;0&lt;/span&gt;_342&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;b07)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenJDK &lt;span style=&#34;color:#bd93f9&#34;&gt;64&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;Bit&lt;/span&gt; Server VM Corretto&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#bd93f9&#34;&gt;8&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;07&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;3&lt;/span&gt; (build &lt;span style=&#34;color:#bd93f9&#34;&gt;25&lt;/span&gt;.&lt;span style=&#34;color:#bd93f9&#34;&gt;342&lt;/span&gt;&lt;span style=&#34;color:#ff79c6&#34;&gt;-&lt;/span&gt;b07, mixed &lt;span style=&#34;color:#ff79c6&#34;&gt;mode&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ビルドが通ることを確認する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark SQLのJOIN時に余分なパーティションが読まれる例とDynamic Partition Pruning (DPP)</title>
      <link>https://www.sambaiz.net/article/417/</link>
      <pubDate>Sun, 11 Sep 2022 16:58:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/417/</guid>
      <description>&lt;h2 id=&#34;クエリの例&#34;&gt;クエリの例&lt;/h2&gt;&#xA;&lt;p&gt;Spark 3.1.1 ベースの Glue 3.0 で、TPC-DS (scale=1000) の sales テーブルと sales のIDでパーティションを切った store_sales テーブルを JOIN する次のクエリを実行すると 10 DPS で 1分4秒 かかった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>EMRクラスタで動かしたSparkのログをFluent BitでNew Relicに集約する</title>
      <link>https://www.sambaiz.net/article/416/</link>
      <pubDate>Sun, 04 Sep 2022 14:44:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/416/</guid>
      <description>&lt;p&gt;Cluster modeでSpark jobを動かすとログが step/ 下に出力されないためコンソール上でもログを確認しづらいのでNew Relicに集約してみる。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/409/&#34;&gt;AWS CLIでEMRクラスタを立ち上げSparkのアプリケーションを実行する - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>EMRでSparkを動かす際の設定</title>
      <link>https://www.sambaiz.net/article/414/</link>
      <pubDate>Sat, 13 Aug 2022 19:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/414/</guid>
      <description>&lt;p&gt;AWSでSparkのアプリケーションを動かすマネージドサービスにはEMRとGlueがあって、&#xA;Glueがサーバーレスで手軽にETLジョブを動かすことができる一方、EMRはリソースやパラメータを細かくチューニングすることができる。&#xA;裏を返せば設定が適切でないとリソースをフル活用できず、特にメモリについては余っているにもかかわらずOOMで失敗してしまうことがある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS CLIでEMRクラスタを立ち上げSparkのアプリケーションを実行する</title>
      <link>https://www.sambaiz.net/article/409/</link>
      <pubDate>Wed, 22 Jun 2022 00:05:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/409/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/emr/&#34;&gt;Amazon EMR&lt;/a&gt;はEC2やEKS上にSparkやHive, Prestoのクラスタを構築するサービス。&#xA;SparkのマネージドサービスであるGlueと比べると、Glueはサーバーレスで手軽にSparkによるETL処理をを行えるのに対して、EMRはスポットインスタンスなどを利用したコストパフォーマンスの良さと詳細なチューニングを行うことができるという特長があるが、&lt;a href=&#34;https://aws.amazon.com/jp/emr/serverless/&#34;&gt;EMR Serverless&lt;/a&gt;がリリースされたのでその差は少し縮まっているように感じる。Glueにはスキーマを指定する必要がない&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html&#34;&gt;DynamicFrame&lt;/a&gt;や前の続きから実行できるBookmarkといった便利な機能もあるが、重い処理を立て続けに実行するとコストが嵩んだりDPUなどのクォータに引っかかることもあるので適宜使い分けていきたい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Redshift Serverlessと他のサーバーレス集計サービス、Glue Data Catalogのテーブルへのクエリ実行</title>
      <link>https://www.sambaiz.net/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/392/</guid>
      <description>&lt;h2 id=&#34;redshift-serverless&#34;&gt;Redshift Serverless&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/redshift/redshift-serverless/&#34;&gt;Redshift Serverless&lt;/a&gt;は今年のre:Inventで&lt;a href=&#34;https://www.youtube.com/watch?v=x0xmqJrAVM8&#34;&gt;発表された&lt;/a&gt;、インスタンスを立てることなく従量課金でペタバイトスケールのDWHであるRedshiftを使える機能。&#xA;S3のデータを直接参照できる&lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html&#34;&gt;Redshift Spectrum&lt;/a&gt;やRDSへの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/federated-overview.html&#34;&gt;Federated Query&lt;/a&gt;、機械学習の&lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/machine_learning.html&#34;&gt;Redshift ML&lt;/a&gt;も使える。&#xA;分析のような不定期に発生する需要のためにインスタンスを立てておくのはコストの上でハードルが高かったのでこのアップデートは嬉しい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sparkでstructをmapとして扱いexplodeで複数行に展開できるようにする</title>
      <link>https://www.sambaiz.net/article/384/</link>
      <pubDate>Wed, 13 Oct 2021 02:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/384/</guid>
      <description>&lt;p&gt;Sparkでschemaを指定せずjsonなどを&lt;a href=&#34;https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrameReader.json.html&#34;&gt;読み込むと&lt;/a&gt;次のように入力データから自動で決定される。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/415/&#34;&gt;Athena v2でparquetをソースとしmapフィールドを持つテーブルのクエリが成功したり失敗したりする原因 - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>SparkのWeb UIでJobのStageとExecutorによるTask分散、SQLのplanを確認する</title>
      <link>https://www.sambaiz.net/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/382/</guid>
      <description>&lt;p&gt;Spark の &lt;a href=&#34;https://spark.apache.org/docs/latest/web-ui.html&#34;&gt;Web UI&lt;/a&gt; は Job や Executor をモニタリングするためのツール。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/aws-samples/aws-glue-samples/tree/b76ad0583bdc66e9e5a903f9da3a953c9f6aac4f&#34;&gt;aws-glue-samples&lt;/a&gt;から maven:3.6-amazoncorretto-8 ベースでSparkを動かすDockerfileを持ってきて、&#xA;&lt;a href=&#34;https://spark.apache.org/docs/latest/monitoring.html&#34;&gt;History Server&lt;/a&gt;を&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui-history.html#monitor-spark-ui-history-local&#34;&gt;起動する&lt;/a&gt;。Glue で出力された EventLog のパスと認証情報を渡している。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GlueのカスタムコネクタでBigQueryに接続する</title>
      <link>https://www.sambaiz.net/article/372/</link>
      <pubDate>Tue, 13 Jul 2021 21:02:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/372/</guid>
      <description>&lt;p&gt;GlueはConnectorによって様々なデータソースに対応していて、RDSやMongoDBなど標準で提供されているもの以外にも&#xA;&lt;a href=&#34;https://aws.amazon.com/jp/about-aws/whats-new/2020/12/aws-glue-launches-aws-glue-custom-connectors/&#34;&gt;カスタムコネクタ&lt;/a&gt;を用いることで接続できる。今回はMarketplaceで提供されているBigQueryのカスタムコネクタを用いてBigQueryのテーブルの内容をS3に出力するJobを作成する。&lt;/p&gt;&#xA;&lt;p&gt;GlueのETL JobをGUIで構築したりモニタリングできるサービス、Glue StudioからMarketplaceに飛んで&#xA;&lt;a href=&#34;https://aws.amazon.com/marketplace/pp/prodview-w2ranrogj3xmm?ref_=beagle&amp;amp;applicationId=GlueStudio&#34;&gt;AWS Glue Connector for Google BigQuery&lt;/a&gt;をSubscribeする。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athena(Presto)とGlue(Spark)で同じクエリを実行した際に異なる値が返る原因</title>
      <link>https://www.sambaiz.net/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/370/</guid>
      <description>&lt;p&gt;AWSではSQL-likeなクエリで集計を行うマネージドなサービスが複数あり、&#xA;アドホックな集計はGlueのデータカタログでテーブルを共有して手軽にクエリを実行できるPrestoベースのAthena、&#xA;重いバッチ集計はリソースや時間の制約を回避できるSparkベースのGlueといったように併用することができる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS GlueのJobのBookmarkを有効にして前回の続きから処理を行う</title>
      <link>https://www.sambaiz.net/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/333/</guid>
      <description>&lt;p&gt;GlueのJobの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-continuations.html&#34;&gt;Bookmark&lt;/a&gt;は&#xA;どこまで処理したかを記録し、次回はその続きから実行できるようにする機能。&#xA;1.0以前は対応していなかったParquetやORCも今は対応している。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache SparkのRDD, DataFrame, DataSetとAction, Transformation</title>
      <link>https://www.sambaiz.net/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/208/</guid>
      <description>&lt;h2 id=&#34;sparkとは&#34;&gt;Sparkとは&lt;/h2&gt;&#xA;&lt;p&gt;ハイパフォーマンスな汎用分散処理システム。&#xA;HDFSやS3といった分散ストレージとHadoop YARNといったクラスタマネージャと共に使われる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する</title>
      <link>https://www.sambaiz.net/article/203/</link>
      <pubDate>Tue, 01 Jan 2019 17:50:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/203/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/glue/&#34;&gt;AWS Glue&lt;/a&gt;はマネージドなETL(Extract/Transform/Load)サービスで、&lt;a href=&#34;https://spark.apache.org/&#34;&gt;Spark&lt;/a&gt;を使ってS3などにあるデータを読み込み加工して変換出力したり、AthenaやRedshift Spectrumで参照できるデータカタログを提供する。&#xA;今回はS3のCSVを読み込んで加工し、列指向フォーマットParquetに変換しパーティションを切って出力、その後クローラを回してデータカタログにテーブルを作成してAthenaで参照できることを確認する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
      <link>https://www.sambaiz.net/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/128/</guid>
      <description>&lt;h2 id=&#34;hiveとは&#34;&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/Home#Home-ApacheHive&#34;&gt;Hiveとは&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;SQLを拡張したHiveQLでHDFSなどのデータソースにアクセスできるHadoopのデータウェアハウスソフトウェア。&#xA;クエリを送るとMapReduceやSpark、Tezのジョブが実行される。&#xA;耐障害性があり主にバッチ処理で用いられる。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
