<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/spark/</link>
    <description>Recent content in Spark on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Mon, 02 Sep 2024 21:08:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>カーディナリティを確率的に推定する HyperLogLog&#43;&#43; で膨大なデータに対する count-distinct での OOM を回避する</title>
      <link>https://www.sambaiz.net/article/497/</link>
      <pubDate>Mon, 02 Sep 2024 21:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/497/</guid>
      <description>&lt;p&gt;アクセスログのユーザー数などユニークな要素数を数える際 count(distinct column_name) のようなクエリを実行することがある。データが膨大な場合、通常の count() はデータを分割して合算することでスケールさせることができるが、distinct する場合はその方法が取れずメモリ不足によって極端に処理が遅くなったり、最悪 OOM で失敗してしまいどうしようもなくなってしまうことがある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark の Broadcast variables や Accumulator で Executor に変数を共有する</title>
      <link>https://www.sambaiz.net/article/494/</link>
      <pubDate>Thu, 22 Aug 2024 09:39:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/494/</guid>
      <description>&lt;p&gt;Executor に変数を共有する仕組みとして &lt;a href=&#34;https://spark.apache.org/docs/3.5.1/rdd-programming-guide.html#broadcast-variables&#34;&gt;Broadcast variables&lt;/a&gt; と &lt;a href=&#34;https://spark.apache.org/docs/3.5.1/rdd-programming-guide.html#accumulators&#34;&gt;Accumulator&lt;/a&gt; がある。&lt;/p&gt;&#xA;&lt;p&gt;Broadcast variables はノードにキャッシュされる read-only な変数。Stageごとに共通で必要なデータは自動で broadcast され、Task の実行前にデシリアライズされるが、複数の stage で必要なデータがある場合やデシリアライズされた状態で持っておきたい場合、 SparkContext.broadcast() で明示的に変数を broadcast することが有効にはたらく。&lt;/p&gt;</description>
    </item>
    <item>
      <title>LivyのREST APIを呼んでSparkジョブを実行する</title>
      <link>https://www.sambaiz.net/article/489/</link>
      <pubDate>Wed, 29 May 2024 23:27:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/489/</guid>
      <description>&lt;p&gt;Livy の &lt;a href=&#34;https://livy.apache.org/docs/latest/rest-api.html&#34;&gt;REST API&lt;/a&gt; を呼んで Spark ジョブを実行してみる。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/486/&#34;&gt;Livy を EMR on EKS にインストールしSparkmagic でローカルの Jupyter Notebook から Spark のジョブを実行する - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Livy を EMR on EKS にインストールしSparkmagic でローカルの Jupyter Notebook から Spark のジョブを実行する</title>
      <link>https://www.sambaiz.net/article/486/</link>
      <pubDate>Wed, 22 May 2024 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/486/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://livy.apache.org/&#34;&gt;Apache Livy&lt;/a&gt; は Spark クラスタとやり取りするための REST API を提供し、&lt;a href=&#34;https://github.com/jupyter-incubator/sparkmagic&#34;&gt;Sparkmagic&lt;/a&gt; はこの API を呼ぶことで Jupyter Notebooks からリモートの Spark クラスタでジョブを実行する。Athena for Apache Spark でも使われていて、インタラクティブにジョブを実行し結果を確認できるのはデバッグやアドホックなクエリを実行したりするのに便利だ。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark の MLlib で k-means法によるクラスタリングを行う</title>
      <link>https://www.sambaiz.net/article/446/</link>
      <pubDate>Sun, 09 Apr 2023 17:08:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/446/</guid>
      <description>&lt;p&gt;Spark には &lt;a href=&#34;https://spark.apache.org/docs/latest/ml-guide.html&#34;&gt;MLlib&lt;/a&gt; という機械学習のライブラリがあり、&#xA;今回はその中の &lt;a href=&#34;https://spark.apache.org/docs/latest/ml-clustering.html#k-means&#34;&gt;Kmeans&lt;/a&gt; によるクラスタリングを行う。&#xA;k-means法は各データのクラスタを事前に決めた数からランダムに決めて、クラスタごとに中心を取ってから、各データのクラスタを最も近い中心のクラスタに変更する、というのを収束するまで繰り返すという手法。&#xA;Kmeans には収束が早い k-means++法が実装されており、distanceMeasure はデフォルトで euclidean となっている。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Task nodes で EMR クラスタのスケールインを高速化する</title>
      <link>https://www.sambaiz.net/article/445/</link>
      <pubDate>Sun, 19 Mar 2023 22:51:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/445/</guid>
      <description>&lt;p&gt;EMR クラスタは YARN の ResourceManager などが動く Master (primary) node と、 Core nodes および Task nodes から&lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html&#34;&gt;構成される&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athena for Apache Spark の Notebook で DataFrame.toPandas().plot() した際の日本語が文字化けしないようにする</title>
      <link>https://www.sambaiz.net/article/438/</link>
      <pubDate>Mon, 06 Feb 2023 23:58:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/438/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/athena/latest/ug/notebooks-spark.html&#34;&gt;Athena for Apache Spark&lt;/a&gt; は re:Invent 2022 で発表された マネージドでサーバーレスな Jupyter Notebook からインタラクティブに Spark による分析が行える機能。&#xA;Athena は アドホックに SQL を実行して分析できる手軽さと、サーバーレスによって使ってない時間帯は料金がかからない利点があったが、&#xA;重いクエリを実行すると scale factor やタイムアウトによって失敗することがあったので今回 Spark が動かせるようになり用途の幅の広がりを感じる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>CDK で EKS クラスタを立ち上げ EMR on EKS に登録し Spark のジョブを動かす</title>
      <link>https://www.sambaiz.net/article/434/</link>
      <pubDate>Mon, 02 Jan 2023 14:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/434/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/emr-eks.html&#34;&gt;EMR on EKS&lt;/a&gt; は EKS 上で Spark を動かす機能。&#xA;通常の EMR が Hadoop クラスタの管理も行うのに対して、EMR on EKS はコンテナの起動のみを担う。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/409/&#34;&gt;AWS CLIでEMRクラスタを立ち上げSparkのアプリケーションを実行する - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>ScalaでSparkのアプリケーションを開発してGitHub ActionsでデプロイしEMRでリモートデバッグする</title>
      <link>https://www.sambaiz.net/article/420/</link>
      <pubDate>Fri, 21 Oct 2022 23:36:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/420/</guid>
      <description>&lt;p&gt;Spark は開発で用いられている Scala に加えて Java や Python のAPIを提供しており、技術スタックや他コンポーネントとの兼ね合いなどによって選択することができる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SparkをビルドしIntelliJでリモートデバッグする</title>
      <link>https://www.sambaiz.net/article/419/</link>
      <pubDate>Sun, 09 Oct 2022 19:06:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/419/</guid>
      <description>&lt;h2 id=&#34;コマンドラインでのビルドhttpssparkapacheorgdocs330building-sparkhtml&#34;&gt;&lt;a href=&#34;https://spark.apache.org/docs/3.3.0/building-spark.html&#34;&gt;コマンドラインでのビルド&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ git clone &lt;span style=&#34;color:#6272a4&#34;&gt;--branch v3.3.0 --depth 1 https://github.com/apache/spark.git &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Spark SQLのJOIN時に余分なパーティションが読まれる例とDynamic Partition Pruning (DPP)</title>
      <link>https://www.sambaiz.net/article/417/</link>
      <pubDate>Sun, 11 Sep 2022 16:58:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/417/</guid>
      <description>&lt;h2 id=&#34;クエリの例&#34;&gt;クエリの例&lt;/h2&gt;&#xA;&lt;p&gt;Spark 3.1.1 ベースの Glue 3.0 で、TPC-DS (scale=1000) の sales テーブルと sales のIDでパーティションを切った store_sales テーブルを JOIN する次のクエリを実行すると 10 DPS で 1分4秒 かかった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>EMRクラスタで動かしたSparkのログをFluent BitでNew Relicに集約する</title>
      <link>https://www.sambaiz.net/article/416/</link>
      <pubDate>Sun, 04 Sep 2022 14:44:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/416/</guid>
      <description>&lt;p&gt;Cluster modeでSpark jobを動かすとログが step/ 下に出力されないためコンソール上でもログを確認しづらいのでNew Relicに集約してみる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>EMRでSparkを動かす際の設定</title>
      <link>https://www.sambaiz.net/article/414/</link>
      <pubDate>Sat, 13 Aug 2022 19:53:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/414/</guid>
      <description>&lt;p&gt;AWSでSparkのアプリケーションを動かすマネージドサービスにはEMRとGlueがあって、&#xA;Glueがサーバーレスで手軽にETLジョブを動かすことができる一方、EMRはリソースやパラメータを細かくチューニングすることができる。&#xA;裏を返せば設定が適切でないとリソースをフル活用できず、特にメモリについては余っているにもかかわらずOOMで失敗してしまうことがある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS CLIでEMRクラスタを立ち上げSparkのアプリケーションを実行する</title>
      <link>https://www.sambaiz.net/article/409/</link>
      <pubDate>Wed, 22 Jun 2022 00:05:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/409/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/emr/&#34;&gt;Amazon EMR&lt;/a&gt;はEC2やEKS上にSparkやHive, Prestoのクラスタを構築するサービス。&#xA;SparkのマネージドサービスであるGlueと比べると、Glueはサーバーレスで手軽にSparkによるETL処理をを行えるのに対して、EMRはスポットインスタンスなどを利用したコストパフォーマンスの良さと詳細なチューニングを行うことができるという特長があるが、&lt;a href=&#34;https://aws.amazon.com/jp/emr/serverless/&#34;&gt;EMR Serverless&lt;/a&gt;がリリースされたのでその差は少し縮まっているように感じる。Glueにはスキーマを指定する必要がない&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html&#34;&gt;DynamicFrame&lt;/a&gt;や前の続きから実行できるBookmarkといった便利な機能もあるが、重い処理を立て続けに実行するとコストが嵩んだりDPUなどのクォータに引っかかることもあるので適宜使い分けていきたい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Redshift Serverlessと他のサーバーレス集計サービス、Glue Data Catalogのテーブルへのクエリ実行</title>
      <link>https://www.sambaiz.net/article/392/</link>
      <pubDate>Sun, 26 Dec 2021 22:03:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/392/</guid>
      <description>&lt;h2 id=&#34;redshift-serverless&#34;&gt;Redshift Serverless&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/redshift/redshift-serverless/&#34;&gt;Redshift Serverless&lt;/a&gt;は今年のre:Inventで&lt;a href=&#34;https://www.youtube.com/watch?v=x0xmqJrAVM8&#34;&gt;発表された&lt;/a&gt;、インスタンスを立てることなく従量課金でペタバイトスケールのDWHであるRedshiftを使える機能。&#xA;S3のデータを直接参照できる&lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html&#34;&gt;Redshift Spectrum&lt;/a&gt;やRDSへの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/federated-overview.html&#34;&gt;Federated Query&lt;/a&gt;、機械学習の&lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/machine_learning.html&#34;&gt;Redshift ML&lt;/a&gt;も使える。&#xA;分析のような不定期に発生する需要のためにインスタンスを立てておくのはコストの上でハードルが高かったのでこのアップデートは嬉しい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sparkでstructをmapとして扱いexplodeで複数行に展開できるようにする</title>
      <link>https://www.sambaiz.net/article/384/</link>
      <pubDate>Wed, 13 Oct 2021 02:30:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/384/</guid>
      <description>&lt;p&gt;Sparkでschemaを指定せずjsonなどを&lt;a href=&#34;https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrameReader.json.html&#34;&gt;読み込むと&lt;/a&gt;次のように入力データから自動で決定される。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SparkのWeb UIでJobのStageとExecutorによるTask分散、SQLのplanを確認する</title>
      <link>https://www.sambaiz.net/article/382/</link>
      <pubDate>Thu, 30 Sep 2021 13:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/382/</guid>
      <description>&lt;p&gt;Spark の &lt;a href=&#34;https://spark.apache.org/docs/latest/web-ui.html&#34;&gt;Web UI&lt;/a&gt; は Job や Executor をモニタリングするためのツール。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/aws-samples/aws-glue-samples/tree/b76ad0583bdc66e9e5a903f9da3a953c9f6aac4f&#34;&gt;aws-glue-samples&lt;/a&gt;から maven:3.6-amazoncorretto-8 ベースでSparkを動かすDockerfileを持ってきて、&#xA;&lt;a href=&#34;https://spark.apache.org/docs/latest/monitoring.html&#34;&gt;History Server&lt;/a&gt;を&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui-history.html#monitor-spark-ui-history-local&#34;&gt;起動する&lt;/a&gt;。Glue で出力された EventLog のパスと認証情報を渡している。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GlueのカスタムコネクタでBigQueryに接続する</title>
      <link>https://www.sambaiz.net/article/372/</link>
      <pubDate>Tue, 13 Jul 2021 21:02:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/372/</guid>
      <description>&lt;p&gt;GlueはConnectorによって様々なデータソースに対応していて、RDSやMongoDBなど標準で提供されているもの以外にも&#xA;&lt;a href=&#34;https://aws.amazon.com/jp/about-aws/whats-new/2020/12/aws-glue-launches-aws-glue-custom-connectors/&#34;&gt;カスタムコネクタ&lt;/a&gt;を用いることで接続できる。今回はMarketplaceで提供されているBigQueryのカスタムコネクタを用いてBigQueryのテーブルの内容をS3に出力するJobを作成する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Athena(Presto)とGlue(Spark)で同じクエリを実行した際に異なる値が返る原因</title>
      <link>https://www.sambaiz.net/article/370/</link>
      <pubDate>Sat, 03 Jul 2021 23:13:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/370/</guid>
      <description>&lt;p&gt;AWSではSQL-likeなクエリで集計を行うマネージドなサービスが複数あり、&#xA;アドホックな集計はGlueのデータカタログでテーブルを共有して手軽にクエリを実行できるPrestoベースのAthena、&#xA;重いバッチ集計はリソースや時間の制約を回避できるSparkベースのGlueといったように併用することができる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS GlueのJobのBookmarkを有効にして前回の続きから処理を行う</title>
      <link>https://www.sambaiz.net/article/333/</link>
      <pubDate>Fri, 16 Apr 2021 20:00:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/333/</guid>
      <description>&lt;p&gt;GlueのJobの&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-continuations.html&#34;&gt;Bookmark&lt;/a&gt;は&#xA;どこまで処理したかを記録し、次回はその続きから実行できるようにする機能。&#xA;1.0以前は対応していなかったParquetやORCも今は対応している。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache SparkのRDD, DataFrame, DataSetとAction, Transformation</title>
      <link>https://www.sambaiz.net/article/208/</link>
      <pubDate>Wed, 13 Feb 2019 21:17:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/208/</guid>
      <description>&lt;h2 id=&#34;sparkとは&#34;&gt;Sparkとは&lt;/h2&gt;&#xA;&lt;p&gt;ハイパフォーマンスな汎用分散処理システム。&#xA;HDFSやS3といった分散ストレージとHadoop YARNといったクラスタマネージャと共に使われる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS GlueでCSVを加工しParquetに変換してパーティションを切りAthenaで参照する</title>
      <link>https://www.sambaiz.net/article/203/</link>
      <pubDate>Tue, 01 Jan 2019 17:50:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/203/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/glue/&#34;&gt;AWS Glue&lt;/a&gt;はマネージドなETL(Extract/Transform/Load)サービスで、&lt;a href=&#34;https://spark.apache.org/&#34;&gt;Spark&lt;/a&gt;を使ってS3などにあるデータを読み込み加工して変換出力したり、AthenaやRedshift Spectrumで参照できるデータカタログを提供する。&#xA;今回はS3のCSVを読み込んで加工し、列指向フォーマットParquetに変換しパーティションを切って出力、その後クローラを回してデータカタログにテーブルを作成してAthenaで参照できることを確認する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cloudera Docker ImageでHiveの実行環境を立ち上げてJSONのログにクエリを実行する</title>
      <link>https://www.sambaiz.net/article/128/</link>
      <pubDate>Thu, 24 Aug 2017 09:22:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/128/</guid>
      <description>&lt;h2 id=&#34;hiveとはhttpscwikiapacheorgconfluencedisplayhivehomehome-apachehive&#34;&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/Home#Home-ApacheHive&#34;&gt;Hiveとは&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;SQLを拡張したHiveQLでHDFSなどのデータソースにアクセスできるHadoopのデータウェアハウスソフトウェア。&#xA;クエリを送るとMapReduceやSpark、Tezのジョブが実行される。&#xA;耐障害性があり主にバッチ処理で用いられる。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
