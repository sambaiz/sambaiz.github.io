<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Iceberg on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/iceberg/</link>
    <description>Recent content in Iceberg on sambaiz-net</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Fri, 18 Jul 2025 09:39:00 +0900</lastBuildDate>
    <atom:link href="https://www.sambaiz.net/tags/iceberg/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>dbt-athena で Iceberg テーブルの作成とスキーマの更新のみを行う</title>
      <link>https://www.sambaiz.net/article/539/</link>
      <pubDate>Fri, 18 Jul 2025 09:39:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/539/</guid>
      <description>&lt;p&gt;現状 AWS で Iceberg を扱うにあたりテーブルをどう管理していくか悩ましい状態にある。というのも CDK (CloudFormation) で Iceberg テーブルを更新すると Iceberg テーブルとして扱われなくなる&lt;a href=&#34;https://github.com/aws-cloudformation/cloudformation-coverage-roadmap/issues/1919&#34;&gt;問題&lt;/a&gt;があるからだ。Athena Notebooks から Spark で作成するのが一番手軽だが、もう少しレビューやデプロイの観点で運用に乗りやすそうな方法を探していたところ、dbt 公式の Athena アダプタである &lt;a href=&#34;https://docs.getdbt.com/docs/core/connect-data-platform/athena-setup&#34;&gt;dbt-athena&lt;/a&gt; に辿り着いた。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kinesis Data Firehose で Iceberg テーブルにストリーミング書き込みを行う</title>
      <link>https://www.sambaiz.net/article/535/</link>
      <pubDate>Sat, 10 May 2025 13:06:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/535/</guid>
      <description>&lt;p&gt;ファイルを置くだけで読むことができる通常のテーブルと異なり、Iceberg テーブルはメタデータを更新するために INSERT する必要がある。これをバッチ処理で行うと最新のデータが読めるまでにラグが発生してしまうので、ラグを最小限にするため Kinesis Data Streams などを介して自前でストリーミング処理することもできるが、&lt;a href=&#34;https://docs.aws.amazon.com/firehose/latest/dev/apache-iceberg-destination.html&#34;&gt;Firehose の出力先として Iceberg テーブルを設定する&lt;/a&gt;と容易に書き込むことができる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>dbt で BigQuery tables for Apache Iceberg を作成し Snowflake から読む</title>
      <link>https://www.sambaiz.net/article/531/</link>
      <pubDate>Sun, 20 Apr 2025 23:55:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/531/</guid>
      <description>&lt;p&gt;Snowflake から BigQuery に入っているデータを読む際、直接アクセスすることはできないためSnowflake のテーブルに入れ直すか GCS にエクスポートなどする必要がある。ただ、前者に関しては単一ソースでなくなることによるデータやスキーマの乖離の心配があり、いずれの場合も BigQuery と併用する場合データの保存コストが二重でかかってしまう。後者の場合は BigQuery ストレージに保存するのではなく外部テーブルとして運用する方法もあるが書き込むのに Spark のような外部エンジンが必要になる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>EMR Serverless から S3 Tables に Iceberg テーブルを作成しデータを書き込んで Athena からクエリする</title>
      <link>https://www.sambaiz.net/article/528/</link>
      <pubDate>Tue, 18 Feb 2025 20:47:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/528/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables.html&#34;&gt;S3 Tables&lt;/a&gt; は re:Invent 2024 で&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/aws-weekly-20241202-1/&#34;&gt;発表された&lt;/a&gt; Iceberg テーブルに特化したストレージ。併せて発表されたオブジェクトの最終変更日時などのメタデータをクエリできる &lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/userguide/metadata-tables-schema.html&#34;&gt;S3 Metadata&lt;/a&gt; も S3 Tables へ書き込む。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sambaiz.net/article/523/&#34;&gt;Spark で Iceberg テーブルを作成しスキーマや write mode を変更してデータを書き込みメタデータの内容を確認する - sambaiz-net&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Iceberg テーブルを Glue Data Catalog に登録して Athena や Snowflake からクエリする</title>
      <link>https://www.sambaiz.net/article/525/</link>
      <pubDate>Thu, 30 Jan 2025 20:31:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/525/</guid>
      <description>&lt;p&gt;Glue Data Catalog に Iceberg テーブルを登録すると、他のテーブルと同様に Athena や EMR などから参照できるほか、Snowflake ではスキーマを渡すことなく &lt;a href=&#34;https://docs.snowflake.com/en/user-guide/tables-iceberg&#34;&gt;ICEBERG TABLE&lt;/a&gt; を作成することができ、メタデータの二重管理を避けることができる。また自動で &lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/enable-compaction.html&#34;&gt;compaction したり&lt;/a&gt;、ジョブの失敗時に生まれるメタデータから参照されていない&lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/enable-orphan-file-deletion.html&#34;&gt;orphan files を掃除したり&lt;/a&gt;する機能まである。従来の Hive パーティションでは Glue Data Catalog にパーティション情報を登録し GetPartitions API で取得するため、パーティションが多いとレイテンシやスロットリングが問題になるが、Iceberg はパーティション情報を manifest ファイルとして S3 に保持するため、この問題を回避できる。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark で Iceberg テーブルを作成しスキーマや write mode を変更してデータを書き込みメタデータの内容を確認する</title>
      <link>https://www.sambaiz.net/article/523/</link>
      <pubDate>Sat, 25 Jan 2025 23:18:00 +0900</pubDate>
      <guid>https://www.sambaiz.net/article/523/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://iceberg.apache.org/&#34;&gt;Apache Iceberg&lt;/a&gt; は大規模なデータの処理を効率的に行えるようにするオープンなテーブルフォーマットで &lt;a href=&#34;https://trino.io/docs/current/connector/iceberg.html&#34;&gt;Trino&lt;/a&gt;、&lt;a href=&#34;https://docs.snowflake.com/en/user-guide/tables-iceberg&#34;&gt;Snowflake&lt;/a&gt; など様々なシステムから利用できる。ACID なトランザクション、元データを書き換えることなくテーブルのスキーマを変更できる Schema Evolution、タイムトラベルに加え、Hive の day=xxxx/ のような物理構造に依存せず day(event_ts) や month(event_ts) といったテーブルには含まれない論理的な値によって PARTITION BY する &lt;a href=&#34;https://iceberg.apache.org/docs/latest/partitioning/#icebergs-hidden-partitioning&#34;&gt;Hidden Partitioning&lt;/a&gt; によって、パーティションの粒度を意識することなく WHERE event_ts BETWEEN 2025-01-01 AND 2025-03-01 のようにクエリでき、またクエリを壊すことなく粒度を変更する &lt;a href=&#34;https://iceberg.apache.org/docs/latest/evolution/#partition-evolution&#34;&gt;Partition evolution&lt;/a&gt; を行うこともできる。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
