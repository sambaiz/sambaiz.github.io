<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sambaiz-net</title>
    <link>http://sambaiz.net/tags/log/index.xml</link>
    <language>ja</language>
    <author>sambaiz</author>
    <rights>(C) 2017</rights>
    <updated>0001-01-01 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>NorikraでログをJOINする</title>
          <link>http://sambaiz.net/article/111/</link>
          <pubDate>Thu, 15 Jun 2017 00:17:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/111/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://sambaiz.net/article/109/&#34;&gt;NorikraとFluentdで流れてきたログをリアルタイムに集計する - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;適当なログを出すコードを書いた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sambaiz/lottery-log&#34;&gt;sambaiz/lottery-log&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;これは以下のようなlottery.logを出力し続け、数秒後に一定確率で同じuidのreceived.logを出力するもの。
広告的に言えば、lotteryがimpで、receivedがclickといった感じかな。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// lottery.log
{&amp;quot;ts&amp;quot;:1497453504.6818597,&amp;quot;uid&amp;quot;:&amp;quot;b18c0d98-19b2-4e37-8fc4-6b00a4b728c3&amp;quot;,&amp;quot;prize&amp;quot;:855,&amp;quot;isWin&amp;quot;:true}
// received.log
{&amp;quot;ts&amp;quot;:1497453515.932101,&amp;quot;uid&amp;quot;:&amp;quot;bc4f578f-4a5f-47f1-a4e0-1ef0b43c316e&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリはこんな感じ。一つはlotteryログとreceivedログをuidでJOINするもので、
もう一つはJavaの関数でboolを0/1にして平均をとることでisWinがtrueである割合を出している。
received_rateも出したかったのだけど、うまい書き方が思いつかなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec norikra norikra-client query add lottery_agg &#39;SELECT COUNT(*) as received_count, AVG(prize) as prize_avg, SUM(prize) as prize_sum FROM lottery.win:time_batch(1 min).std:unique(uid) as a, received.win:time_batch(1 sec).std:unique(uid) as b WHERE a.uid = b.uid&#39;

$ docker exec norikra norikra-client query add lottery_win_rate &#39;SELECT avg(Boolean.compare(isWin, false)) as win_rate FROM lottery.win:time_batch(1 sec)&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、このクエリの結果をElasticsearchに送って可視化してみたのがこれ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type tail
  path /var/log/lottery.log
  pos_file /etc/td-agent/log.pos
  tag event.lottery
  format json
&amp;lt;/source&amp;gt;

&amp;lt;source&amp;gt;
  @type tail
  path /var/log/received.log
  pos_file /etc/td-agent/log.pos
  tag event.received
  format json
&amp;lt;/source&amp;gt;

&amp;lt;match event.*&amp;gt;
  @type   norikra
  norikra localhost:26571
  
  remove_tag_prefix event # event.*の部分が
  target_map_tag    yes   # targetになる

  &amp;lt;default&amp;gt;
    auto_field false 
  &amp;lt;/default&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;source&amp;gt;
  @type   norikra
  norikra localhost:26571
  &amp;lt;fetch&amp;gt;
    method   event
    target   lottery_agg
    tag      string data.lottery_agg
    interval 1m
  &amp;lt;/fetch&amp;gt;
  &amp;lt;fetch&amp;gt;
    method   event
    target   lottery_win_rate
    tag      string data.lottery_win_rate
    interval 1m
  &amp;lt;/fetch&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match data.lottery_agg&amp;gt;
  @type elasticsearch
  host 172.31.5.20
  port 9200
  logstash_prefix lottery
  type_name lottery_agg
  logstash_format true
&amp;lt;/match&amp;gt;

&amp;lt;match data.lottery_win_rate&amp;gt;
  @type elasticsearch
  host 172.31.5.20
  port 9200
  logstash_prefix lottery
  type_name lottery_win_rate
  logstash_format true
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/111v.png&#34; alt=&#34;可視化したもの&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>NorikraとFluentdで流れてきたログをリアルタイムに集計する</title>
          <link>http://sambaiz.net/article/109/</link>
          <pubDate>Sat, 10 Jun 2017 12:00:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/109/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://norikra.github.io/&#34;&gt;Norikra&lt;/a&gt;はTD社の&lt;a href=&#34;https://github.com/tagomoris&#34;&gt;tagomoris&lt;/a&gt;氏が作った、
スキーマレスのストリーミングデータを処理するOSS。&lt;/p&gt;

&lt;p&gt;モチベーションとしてはfluentdでElasticsearchにログを送って可視化していたのだけど、
流量が増えてきてピーク帯に耐えられなくなってしまったため、前もって集計してから送ることで流量を減らそうというもの。&lt;/p&gt;

&lt;h2 id=&#34;norikraを立ち上げてクエリを実行する&#34;&gt;Norikraを立ち上げてクエリを実行する&lt;/h2&gt;

&lt;p&gt;公式で紹介されているDockerイメージがあったのでこれで動かしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -e &amp;quot;TZ=Asia/Tokyo&amp;quot; -p 26578:26578 -p 26571:26571 -v `pwd`:/var/tmp/norikra:rw -d myfinder/docker-norikra norikra start --stats /var/tmp/norikra/stats.json -l /var/tmp/norikra 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;公式サイトの例に従ってクライアントからデータを入れてクエリを実行してみる。&lt;/p&gt;

&lt;p&gt;まずはtargetをopenする。targetというのはスキーマレスのイベントストリームのこと。
ここで定義したフィールドは必須になる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client target open www path:string status:integer referer:string agent:string userid:integer
$ norikra-client target list
TARGET	AUTO_FIELD
www	true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にクエリを追加する。一見普通のSQLのように見えるけど、Norikraのコアエンジンで使われているOSSの
&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%A4%87%E5%90%88%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E5%87%A6%E7%90%86&#34;&gt;CEP&lt;/a&gt;
(Complex event processing)エンジン、
&lt;a href=&#34;http://www.espertech.com/products/esper.php&#34;&gt;Esper&lt;/a&gt;のクエリ、EPL(Event Processing Language)。
ただしSELECTしか使えないのも含めてクエリにいくらかの制限がある。&lt;/p&gt;

&lt;p&gt;このクエリでは&lt;code&gt;win:time_batch&lt;/code&gt;で10秒のWindowを定義し、eventをgroup byして、その数をeventとして出力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client query add www.toppageviews &#39;SELECT count(*) AS cnt FROM www.win:time_batch(10 sec) WHERE path=&amp;quot;/&amp;quot; AND status=200&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;eventを流す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/login&amp;quot;, &amp;quot;status&amp;quot;:301, &amp;quot;referer&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリの値をfetchする。送るのが遅くてgroup byされなかったけどこんな感じ。
eventがこなかったはじめのWindowは0が出力されるが、それ以降のWindowでは出力されない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ norikra-client event fetch www.toppageviews
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 20:58:13&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:42:33&amp;quot;,&amp;quot;cnt&amp;quot;:1}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:42:43&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:13&amp;quot;,&amp;quot;cnt&amp;quot;:1}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:23&amp;quot;,&amp;quot;cnt&amp;quot;:0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 21:43:33&amp;quot;,&amp;quot;cnt&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとWeb-uiが用意されていて、クエリを追加したり、targetやクエリの一覧、メモリの使用量やサーバーログなどが取得できる。デフォルトでは26578ポート。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/109-norikra.png&#34; alt=&#34;web-ui&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;クエリ-epl-http-norikra-github-io-query-html&#34;&gt;&lt;a href=&#34;http://norikra.github.io/query.html&#34;&gt;クエリ(EPL)&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;windowなし&#34;&gt;Windowなし&lt;/h3&gt;

&lt;p&gt;上の例では&lt;code&gt;time_batch&lt;/code&gt;でWindowを定義したけど、定義しないクエリを追加してみる。
以下のようなクエリを登録し、再びeventを流してfetchすると流した分が全てとれる。
ただし、このようなクエリはfetchされないと大量のoutput eventが溜まる可能性がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT path, status AS cnt FROM www WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-nowin
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 23:06:12&amp;quot;,&amp;quot;cnt&amp;quot;:200,&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/07 23:09:10&amp;quot;,&amp;quot;cnt&amp;quot;:200,&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-time-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-time-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-time-batch&#34;&gt;win:time_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;10 sec&lt;/code&gt;のように秒以外にも&lt;code&gt;msec&lt;/code&gt;、&lt;code&gt;min&lt;/code&gt;、&lt;code&gt;hour&lt;/code&gt;、どう使うか想像できないけど&lt;code&gt;year&lt;/code&gt;まで指定でき、
&lt;code&gt;10 minutes 30 seconds&lt;/code&gt;みたいに組み合わせることも&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl_clauses.html#epl-syntax-time-periods&#34;&gt;できる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;また、第二引数にミリ秒を渡すと出力するタイミングを指定できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) AS cnt FROM www.win:time_batch(1min, 0L) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-tb-opts
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 00:43:00&amp;quot;,&amp;quot;cnt&amp;quot;:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-ext-timed-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-ext-time-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-ext-time-batch&#34;&gt;win:ext_timed_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;来た時間ではなくフィールドのUNIXミリ秒を参照するWindow。時系列順にソートされている必要があって、
tagomoris氏いわく&lt;a href=&#34;https://twitter.com/tagomoris/status/486851407140507648&#34;&gt;おすすめしない&lt;/a&gt;とのこと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) AS cnt FROM www.win:ext_timed_batch(timestamp, 1 min) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3, &amp;quot;timestamp&amp;quot;:1496852100000 }&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3, &amp;quot;timestamp&amp;quot;:1496852200000 }&#39; | norikra-client event send www
$ norikra-client event fetch www.toppageviews-ext_timed
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 01:19:02&amp;quot;,&amp;quot;cnt&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-length-batch-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-length-batch&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-length-batch&#34;&gt;win:length_batch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;event数のWindow。毎回渡した数ずつ集計できると思いきや、数が集まらなければfetchできず、
それ以上集まったらfetchできるようだ。使いづらいような気がする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT avg(userid) as nosense FROM www.win:length_batch(2) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat

$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat

$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:2}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-lenbat
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:42:20&amp;quot;,&amp;quot;nosense&amp;quot;:2.0}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;win-length-http-www-espertech-com-esper-release-5-2-0-esper-reference-html-epl-views-html-view-win-length&#34;&gt;&lt;a href=&#34;http://www.espertech.com/esper/release-5.2.0/esper-reference/html/epl-views.html#view-win-length&#34;&gt;win:length&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;こっちは渡した数スライドして集計するもの。Windowなしのときと同様、大量に溜まる可能性がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT avg(userid) as nosense FROM www.win:length(2) WHERE path=&amp;quot;/&amp;quot; AND status=200
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:3}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:1}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:5}&#39; | norikra-client event send www
$ echo &#39;{&amp;quot;path&amp;quot;:&amp;quot;/&amp;quot;, &amp;quot;status&amp;quot;:200, &amp;quot;referer&amp;quot;:&amp;quot;&amp;quot;, &amp;quot;agent&amp;quot;:&amp;quot;MSIE&amp;quot;, &amp;quot;userid&amp;quot;:4}&#39; | norikra-client event send www
$ norikra-client event fetch www.length-len
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:11&amp;quot;,&amp;quot;nosense&amp;quot;:3.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:22&amp;quot;,&amp;quot;nosense&amp;quot;:2.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:32&amp;quot;,&amp;quot;nosense&amp;quot;:3.0}
{&amp;quot;time&amp;quot;:&amp;quot;2017/06/08 20:58:45&amp;quot;,&amp;quot;nosense&amp;quot;:4.5}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他にもいろいろあるし、JOINやサブクエリも使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://sambaiz.net/article/111/&#34;&gt;NorikraでログをJOINする - sambaiz-net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;fluentdとやり取りする&#34;&gt;fluentdとやり取りする&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/norikra/fluent-plugin-norikra&#34;&gt;fluent-plugin-norikra&lt;/a&gt;でNorikraサーバーにeventを送り、
eventを受け取ってファイルに出力する。&lt;/p&gt;

&lt;p&gt;c4.large(2コア,メモリ3.75GiB)でDockerでNorikraを立ち上げ、以下の設定でtd-agentを実行した。
&lt;code&gt;auto_field&lt;/code&gt;は来たeventのフィールドを自動でtargetに登録するかの設定で、
true(デフォルト)にするとどんなフィールドが来ているかNorikra上で確認することができる。
falseにしてもクエリで使う分は自動で登録される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag event.dummy
  rate 1000
&amp;lt;/source&amp;gt;
   
&amp;lt;match event.*&amp;gt;
  @type   norikra
  norikra localhost:26571
  
  remove_tag_prefix event # event.*の部分が
  target_map_tag    yes   # targetになる

  &amp;lt;default&amp;gt;
    auto_field false 
  &amp;lt;/default&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;source&amp;gt;
  @type   norikra
  norikra localhost:26571
  &amp;lt;fetch&amp;gt;
    method   event
    # norikra-client query add dummy_count_1sec &#39;SELECT COUNT(*) AS count FROM dummy.win:time_batch(1 sec)&#39;
    target   dummy_count_1sec
    tag      string data.dummy_count_1sec
 #  tag      field FIELDNAME : tag by value with specified field name in output event
    interval 1m
  &amp;lt;/fetch&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;match data.*&amp;gt;
  @type file
  path /var/log/td-agent/dummy_count
  time_slice_format %Y%m%d%H
  time_slice_wait 10s
  time_format %Y%m%dT%H%M%S%z
  compress gzip
  symlink_path /var/log/td-agent/dummy_count
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Norikraのスループットは以下の要素が影響する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;number of targets
number of queries
how complex queries are
how complex UDFs are
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、目安としてはこんな感じらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10 queries
2,000 events per seconds
5% usage of 4core CPU
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1target、単純な1クエリなら秒間10000送ってみても問題なかった。
あまり現実的なケースではないけど限界を目指してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail -f dummy_count
20170609T212717+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212718+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212719+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212720+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212721+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212722+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212723+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212724+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212725+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
20170609T212726+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:10000}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 8256 root      20   0 1878m 249m  19m S 29.3  6.6   6:46.94 java
 9812 root      20   0  296m  68m 6288 S 20.0  1.8   2:38.08 ruby  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秒間40000送ってみるとカウントがおかしい。
dummyの方の限界かと思ってnorikraを外してみたらおおよそ数が合ったので
Norikraサーバーかやり取りの部分で処理が追いついていないようだ。
一旦rateを下げてみたところ20000あたりを境目にこうなってしまった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail -f dummy_count
20170609T222018+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:31248}
20170609T222019+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:27468}
20170609T222020+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:35309}
20170609T222021+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:31944}
20170609T222022+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:22805}
20170609T222023+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:30716}
20170609T222024+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:33617}
20170609T222025+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:28740}
20170609T222026+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:32058}
20170609T222027+0900	data.dummy_count_1sec	{&amp;quot;count&amp;quot;:27253}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CPUの使用量をみてみると、ほぼ限界まで使用されていた。
fluentdはrubyの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B0%E3%83%AD%E3%83%BC%E3%83%90%E3%83%AB%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%97%E3%83%AA%E3%82%BF%E3%83%AD%E3%83%83%E3%82%AF&#34;&gt;GIL&lt;/a&gt;
(Global Interpreter Lock = GVL(Giant VM Lock))のため同時に&lt;a href=&#34;https://docs.ruby-lang.org/ja/2.3.0/doc/spec=2fthread.html&#34;&gt;1ネイティブスレッドしか動かせず&lt;/a&gt;、1コアしかCPUを使えないが、
jrubyで動くNorikraは残りのコアを使うことができる。
今回はtargetもクエリも一つだし、データ量も小さいためかメモリにはまだ余裕があった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
11378 root      20   0  350m 111m 6336 S 96.1  3.0   1:53.03 ruby
8256 root      20   0 1892m 642m  19m S 84.2 17.1  34:36.38 java   
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;HEAP MEMORY USED: 244MB (55.8%), COMMITTED: 437MB, MAX: 437MBStorm
NON-HEAP MEMORY USED: 51MB (23.8%), COMMITTED: 81MB, MAX: 214MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1Gbps、1Mevent/sを超えるような高トラフィックではStormなどのフレームワークを使えとのこと。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでKinesis streamsに送るときの性能確認</title>
          <link>http://sambaiz.net/article/108/</link>
          <pubDate>Mon, 05 Jun 2017 23:48:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/108/</guid>
          <description>

&lt;h2 id=&#34;localでのstreamsとproducerのbenchmark&#34;&gt;localでのstreamsとproducerのbenchmark&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;の
&lt;code&gt;make benchmark&lt;/code&gt;はlocalにDummyServerを&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis/blob/v1.1.3/benchmark/task.rake#L18&#34;&gt;立ち上げて&lt;/a&gt;送っている。&lt;/p&gt;

&lt;p&gt;空でもいいのでroleをつけておく必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/awslabs/aws-fluent-plugin-kinesis.git
$ cd aws-fluent-plugin-kinesis
$ yum install -y ruby-devel gcc
$ echo &#39;gem &amp;quot;io-console&amp;quot;&#39; &amp;gt;&amp;gt; Gemfile
$ make
$ make benchmark
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATEを指定しなければデフォルトで&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis/blob/v1.1.3/benchmark/task.rake#L19&#34;&gt;秒間1000レコード&lt;/a&gt;が送られる設定。
fluentdを起動してから10秒後にプロセスをkillし、そのレコード数などを出力している。&lt;/p&gt;

&lt;p&gt;t2.microでデフォルト(RATE=1000)で実行した結果がこれ。
固める分producerの方はややパフォーマンスが落ちる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 20, raw_records: 9400, records: 9400
bundle exec rake benchmark TYPE=producer
Results: requets: 14, raw_records: 1005, records: 8900
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATE=3000のとき。producerではraw_recordsが1/100、リクエスト数は1/5。
streamsだとシャードを増やしていく必要があるけど、producerの方は当分大丈夫そうだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 57, raw_records: 27600, records: 27600
bundle exec rake benchmark TYPE=producer
Results: requets: 12, raw_records: 241, records: 25200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RATE=10000のとき。raw_records, requestの圧縮率はさらに上がり、
パフォーマンスの差が大きくなってきている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bundle exec rake benchmark TYPE=streams
Results: requets: 177, raw_records: 88000, records: 88000
bundle exec rake benchmark TYPE=producer
Results: requets: 26, raw_records: 385, records: 75000
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実際にkinesis-streamsに送ってみる&#34;&gt;実際にkinesis streamsに送ってみる&lt;/h2&gt;

&lt;p&gt;ap-northeast-1でシャードは3のKinesis streamsにt2.microインスタンス1台から送る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type dummy
  dummy {&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}
  tag dummy
  rate 1000
&amp;lt;/source&amp;gt;

&amp;lt;source&amp;gt;
  @type monitor_agent
  bind 0.0.0.0
  port 24220
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type kinesis_streams
  region ap-northeast-1
  stream_name test

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;秒間3000まではほとんどキューにたまらず送れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:24220/api/plugins.json | jq
{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 0,
      &amp;quot;buffer_total_queued_size&amp;quot;: 17500,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4000にするとそのうちretryが発生してしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
     &amp;quot;buffer_queue_length&amp;quot;: 60,
      &amp;quot;buffer_total_queued_size&amp;quot;: 56544178,
      &amp;quot;retry_count&amp;quot;: 5,
      &amp;quot;retry&amp;quot;: {
        &amp;quot;steps&amp;quot;: 5,
        &amp;quot;next_time&amp;quot;: &amp;quot;2017-06-05 14:05:38 +0000&amp;quot;
      }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たしかにスループットが超過している。スペック通りだ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/108.png&#34; alt=&#34;書き込みスループットの超過&#34; /&gt;&lt;/p&gt;

&lt;p&gt;次に30シャードにしてみる。一度にシャード数は倍から半分にしかできないので作り直し。&lt;/p&gt;

&lt;p&gt;これに秒間30000を送ってみると、キューにいくらか溜まった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 7,
      &amp;quot;buffer_total_queued_size&amp;quot;: 7752600,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに倍にして60シャード。これに秒間60000で送ってみる。キューに溜まるものの増え続けはしないのでなんとか送れてそうだ。
td-agentのプロセスがCPUを99%使っているので、このインスタンスではこの辺が限界かもしれない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 15,
      &amp;quot;buffer_total_queued_size&amp;quot;: 16105807,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ついでにus-east-1にも30シャードのStreamsを作成して30000送ってみたところ、キューに溜まる量が格段に増えた。
早くFirehoseやAnalyticsが東京リージョンにも来てほしい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  ...
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3fc0dfac66a8&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;kinesis_streams&amp;quot;,
      ...
      &amp;quot;buffer_queue_length&amp;quot;: 50,
      &amp;quot;buffer_total_queued_size&amp;quot;: 52432436,
      &amp;quot;retry_count&amp;quot;: 0,
      &amp;quot;retry&amp;quot;: {}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ</title>
          <link>http://sambaiz.net/article/84/</link>
          <pubDate>Wed, 15 Mar 2017 23:00:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/84/</guid>
          <description>

&lt;h2 id=&#34;kpl-kinesis-producer-library-とは&#34;&gt;KPL(Kinesis Producer Library)とは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-kpl.html&#34;&gt;Developing Amazon Kinesis Streams Producers Using the Amazon Kinesis Producer Library - Amazon Kinesis Streams&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kinesisに送るとき、自動リトライしてくれたり、レコードをまとめてスループットを向上してくれたりするアプリケーション。Protobufを使っている。
普通に送るとどんなに小さくてもシャード*1000レコード/秒しか最大でPUTできないのを、KPLを使ってまとめることで増やすことができる。&lt;/p&gt;

&lt;h2 id=&#34;fluentdで送る&#34;&gt;fluentdで送る&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;で&lt;code&gt;kinesis_producer&lt;/code&gt;を指定するとKPLを使って送信する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;kinesis_producer&amp;gt;&lt;/code&gt;の中にKPLの設定を書くことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;kinesis_producer&amp;gt;
    record_max_buffered_time 10
&amp;lt;/kinesis_producer&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L239&#34;&gt;record_max_bufferd_time&lt;/a&gt;
はバッファされたレコードが送られるまでの最大時間(ms)。デフォルトは100ms。この時間が経つか、他のリミットに当たったらレコードは送られる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L30&#34;&gt;AggregationMaxCount&lt;/a&gt;: 一つのレコードにまとめる最大レコード数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L44&#34;&gt;AggregationMaxSize&lt;/a&gt;: まとめたレコードの最大バイト数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L54&#34;&gt;CollectionMaxCount&lt;/a&gt;: PutRecordsで送る最大アイテム数&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L67&#34;&gt;CollectionMaxSize&lt;/a&gt;: PutRecordsで送るデータ量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CloudWatchに送る&lt;a href=&#34;https://github.com/awslabs/amazon-kinesis-producer/blob/v0.10.2/java/amazon-kinesis-producer-sample/default_config.properties#L158&#34;&gt;metrics_level&lt;/a&gt;はデフォルトでdetailedになっていて、
コンソールのメトリクスからstream名で検索すると
&lt;code&gt;KinesisProducerLibrary&lt;/code&gt;に&lt;code&gt;UserRecordsPerKinesisRecord&lt;/code&gt;や、&lt;code&gt;UserRecordsDataPut&lt;/code&gt;、&lt;code&gt;BufferingTime&lt;/code&gt;、&lt;code&gt;RequestTime&lt;/code&gt;などいろいろ表示される。&lt;/p&gt;

&lt;p&gt;とりあえず試しにこんな設定で送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match hoge.log&amp;gt;
  @type kinesis_producer
  region ap-northeast-1
  stream_name teststream
  include_time_key true

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lambdaで読む&#34;&gt;Lambdaで読む&lt;/h2&gt;

&lt;p&gt;まとめられたレコードを&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation&#34;&gt;kinesis-aggregation&lt;/a&gt;で分解して読む。
今回は&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation/tree/master/node&#34;&gt;Node.js&lt;/a&gt;でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ npm install --save aws-kinesis-agg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意する必要があるのは&lt;a href=&#34;https://github.com/awslabs/kinesis-aggregation/issues/16&#34;&gt;ドキュメントの情報が古く&lt;/a&gt;て、
関数の引数が足りないこと。第二引数のcomputeChecksumsが抜けているので気付かないと一つずつずれていくことになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;use strict&#39;;

const agg = require(&#39;aws-kinesis-agg&#39;);

exports.handler = (event, context, callback) =&amp;gt; {
    Promise.all(
        event.Records.map(
            (record) =&amp;gt; deaggregate(record)
        )
    ).then(
        (records) =&amp;gt; {
            // LambdaのNode.jsはまだ4.3なのでSpread operatorが使えない・・・
            // const message = `${[].concat(...records).length} came in`; 
            let sumCount = 0;
            records.forEach((r) =&amp;gt; sumCount += r.length);
            const message = `${records.length} aggregated records and ${sumCount} records come in`; 
            console.log(message);
            callback(null, message);
        },
        (err) =&amp;gt; callback(err)
    );
};

function deaggregate(record){
    return new Promise((resolve, reject) =&amp;gt; {
        agg.deaggregateSync(record.kinesis, true, (err, userRecords) =&amp;gt; {
            if (err) {
                reject(err);
            } else {
                resolve(userRecords);
            }
        });
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;175レコードが10レコードにまとめられた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10 aggregated records and 175 records come in
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/high-throughput-messaging-system-with-kinesis-kpl-fluentd-lambda/&#34;&gt;Kinesis Producer Library(KPL)とfluentdとLambdaを連携してKinesisのスループットを上げる ｜ Developers.IO&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでKinesis Streamsに送ってLambdaで読んでS3に保存する</title>
          <link>http://sambaiz.net/article/73/</link>
          <pubDate>Sun, 26 Feb 2017 18:56:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/73/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis&#34;&gt;aws-fluent-plugin-kinesis&lt;/a&gt;でKinesis Streamsに送り、Lambdaで読んでS3に保存する。
要するにFirehoseのようなことをやりたいのだけれどTokyoリージョンにまだ来ないので自分でやる。&lt;/p&gt;

&lt;h2 id=&#34;fluentdで送る&#34;&gt;fluentdで送る&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-kinesis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;try_flush_interval&lt;/code&gt;と&lt;code&gt;queued_chunk_flush_interval&lt;/code&gt;はドキュメントには載っていないが、
以下のページによるとそれぞれqueueに次のchunkがないときとあるときのflushする間隔。
いずれもデフォルトは1だが、これを減らすことでもっと頻繁に吐き出されるようになるらしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sonots/fluentd-scr/blob/master/02_out_forward_buffered.md&#34;&gt;Fluentd の out_forward と BufferedOutput&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;あとシャードに振り分けるための&lt;a href=&#34;https://github.com/awslabs/aws-fluent-plugin-kinesis#partition_key&#34;&gt;partition_key&lt;/a&gt;
を指定できる。デフォルトはランダム。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type tail
  path /var/log/td-agent/hoge.log
  pos_file /etc/td-agent/log.pos
  tag hoge.log
  format json

  time_key timestamp
  # 2017-01-01T01:01:01+0900
  time_format %Y-%m-%dT%H:%M:%S%z
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type kinesis_streams
  region ap-northeast-1
  stream_name teststream
  include_time_key true

  flush_interval 1
  buffer_chunk_limit 1m
  try_flush_interval 0.1
  queued_chunk_flush_interval 0.01
  num_threads 15
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;いくつか送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in `seq 1 1000`
do
  echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;, &amp;quot;timestamp&amp;quot;: &amp;quot;2017-01-01T01:01:01+0900&amp;quot;}&#39; &amp;gt;&amp;gt; /var/log/td-agent/hoge.log
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kinesisのシャードが足りないと詰まってしまうので注意。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://sambaiz.net/article/84/&#34;&gt;FluentdとKPL(Kinesis Producer Library)でログをまとめてスループットを稼ぐ - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;lambdaで読む&#34;&gt;Lambdaで読む&lt;/h2&gt;

&lt;p&gt;Lambdaのトリガーの設定でKinesisを選ぶと、バッチサイズや開始位置を設定できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/73-lambda-kinesis.png&#34; alt=&#34;トリガーの設定&#34; /&gt;&lt;/p&gt;

&lt;p&gt;コードはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;use strict&#39;;

const zlib = require(&#39;zlib&#39;);
const aws = require(&#39;aws-sdk&#39;);
const s3 = new aws.S3({ apiVersion: &#39;2006-03-01&#39; });
const BUCKET_NAME = process.env.BUCKET_NAME; // 環境変数で設定する

exports.handler = (event, context, callback) =&amp;gt; {

    const data = event.Records.map((record) =&amp;gt; new Buffer(record.kinesis.data, &#39;base64&#39;).toString()).join(&amp;quot;\n&amp;quot;);
    const key = new Date().toISOString();
    
    putS3(key, data, true).then(
        (data) =&amp;gt; callback(null, `Successfully processed ${event.Records.length} records.`),
        (err) =&amp;gt; callback(err, null)
    );
};

function putS3(key, data, gzip){    
    return new Promise((resolve, reject) =&amp;gt; {
        
        const params = {
            Bucket: BUCKET_NAME,
            Key: key
        };

        if(gzip){
            params.Body = zlib.gzipSync(data);
            params.ContentEncoding = &amp;quot;gzip&amp;quot;;
        }else{
            params.Body = data;
        }
        
        s3.putObject(params, (err, data) =&amp;gt; {
            if (err) reject(err);
            else resolve(data);
        });
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;トリガーを有効にするとイベントが発火してS3に保存されるようになった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ElasticsearchのCircuit Breaker</title>
          <link>http://sambaiz.net/article/71/</link>
          <pubDate>Fri, 24 Feb 2017 21:45:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/71/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://sambaiz.net/article/52/&#34;&gt;ElasticsearchをDockerで動かしてGrafanaで可視化する - sambaiz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ESに送られるデータの量が増えてくるとGrafanaのDashboardにグラフが表示されなくなってしまった。
表示されたエラーはこういうの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;root_cause&amp;quot;: [
    {
        &amp;quot;type&amp;quot;: &amp;quot;circuit_breaking_exception&amp;quot;,
        &amp;quot;reason&amp;quot;: &amp;quot;[request] Data too large, data for [] would be larger than limit of [8998512230/8.3gb]&amp;quot;,
        &amp;quot;bytes_wanted&amp;quot;: 10464007168,
        &amp;quot;bytes_limit&amp;quot;: 8998512230
    }
],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは1リクエストの集計などで使うメモリ量がしきい値をこえて
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/circuit-breaker.html&#34;&gt;Circuit Breaker&lt;/a&gt;が発動したということ。
メモリを食いつぶしてOutOfMemoryになる前に焼き切れるようになっている。&lt;/p&gt;

&lt;p&gt;情報は&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/cluster-nodes-stats.html&#34;&gt;stats&lt;/a&gt;のapiでも取得できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request
{
  &amp;quot;limit_size_in_bytes&amp;quot;: 8998512230,
  &amp;quot;limit_size&amp;quot;: &amp;quot;8.3gb&amp;quot;,
  &amp;quot;estimated_size_in_bytes&amp;quot;: 10348347504,
  &amp;quot;estimated_size&amp;quot;: &amp;quot;9.6gb&amp;quot;,
  &amp;quot;overhead&amp;quot;: 1,
  &amp;quot;tripped&amp;quot;: 470
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回ひっかかったのは&lt;code&gt;indices.breaker.request.limit&lt;/code&gt;。デフォルトではJVMのヒープメモリの60%になっているが、
これを80%にまで緩和する。併せてparent-levelのbreakerも上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{
    &amp;quot;persistent&amp;quot; : {
        &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;,
        &amp;quot;indices.breaker.total.limit&amp;quot;: &amp;quot;80%&amp;quot;
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_cluster/settings -d &#39;{
    &amp;quot;persistent&amp;quot; : {
        &amp;quot;indices.breaker.request.limit&amp;quot;: &amp;quot;80%&amp;quot;,
        &amp;quot;indices.breaker.total.limit&amp;quot;: &amp;quot;80%&amp;quot;
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必要なメモリ量を上回ったのでひとまずは返せるようになった。
これは一時しのぎで、定常的に大量にメモリが必要なリクエストを処理する必要があるなら、そもそもメモリが足りないので増やさなければならない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200/_nodes/stats | jq .nodes[].breakers.request
{
  &amp;quot;limit_size_in_bytes&amp;quot;: 11998016307,
  &amp;quot;limit_size&amp;quot;: &amp;quot;11.1gb&amp;quot;,
  &amp;quot;estimated_size_in_bytes&amp;quot;: 10473078896,
  &amp;quot;estimated_size&amp;quot;: &amp;quot;9.7gb&amp;quot;,
  &amp;quot;overhead&amp;quot;: 1,
  &amp;quot;tripped&amp;quot;: 470
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kinesis Streams/Firehose/Analyticsを試す</title>
          <link>http://sambaiz.net/article/67/</link>
          <pubDate>Mon, 20 Feb 2017 21:15:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/67/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/&#34;&gt;https://aws.amazon.com/jp/kinesis/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;リアルタイムのストリーミングデータを扱うサービス群。
いまのところTokyoリージョンではKinesis Streamsしか使えない。&lt;/p&gt;

&lt;h3 id=&#34;kinesis-firehose-https-aws-amazon-com-jp-kinesis-firehose&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/&#34;&gt;Kinesis Firehose&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;AWSのデータストアに送るストリーム。自分でデータを読む処理を書かなくてよく、スケーリングも勝手にやってくれるので簡単に使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/faqs/&#34;&gt;https://aws.amazon.com/jp/kinesis/firehose/faqs/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: 送信先とは何ですか?
送信先はデータが配信されるデータストアです。Amazon Kinesis Firehose では、
現在送信先として Amazon S3、Amazon Redshift、Amazon Elasticsearch Service がサポートされています。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/firehose/pricing/&#34;&gt;料金&lt;/a&gt;は取り込まれたデータ量による。&lt;/p&gt;

&lt;p&gt;今回はS3に送ってみる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/64-create-firehose.png&#34; alt=&#34;firehose作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;圧縮方法を設定したり、Lambdaを噛ませたりすることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/64-create-firehose2.png&#34; alt=&#34;firehose作成2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;StatusがActiveになったら&lt;a href=&#34;http://docs.aws.amazon.com/firehose/latest/dev/writing-with-agents.html&#34;&gt;Kinesis Agent&lt;/a&gt;で送ってみる。
CloudWatchとFirehoseにPutする権限が必要。Firehoseはkinesis:ではなくfirehose:なので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install –y aws-kinesis-agent
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/etc/aws-kinesis/agent.json&lt;/code&gt;を編集する。リージョンごとのエンドポイントは
&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/general/latest/gr/rande.html#fh_region&#34;&gt;ここ&lt;/a&gt;
にある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;awsAccessKeyId&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;awsSecretAccessKey&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;firehose.endpoint&amp;quot;: &amp;quot;https://firehose.us-east-1.amazonaws.com&amp;quot;, 
    &amp;quot;flows&amp;quot;: [
        {
            &amp;quot;filePattern&amp;quot;: &amp;quot;/tmp/hoge.log&amp;quot;, 
            &amp;quot;deliveryStream&amp;quot;: &amp;quot;hogefugastream&amp;quot;
        }
    ] 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service aws-kinesis-agent start
$ sudo chkconfig aws-kinesis-agent on
$ echo &amp;quot;aaa&amp;quot; &amp;gt;&amp;gt; /tmp/hoge.log
$ tail /var/log/aws-kinesis-agent/aws-kinesis-agent.log
com.amazon.kinesis.streaming.agent.Agent [INFO] Agent: Progress: 2 records parsed (168 bytes), 
and 2 records sent successfully to destinations. Uptime: 300044ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;S3に保存されているのを確認。&lt;/p&gt;

&lt;h3 id=&#34;kinesis-streams-https-aws-amazon-com-jp-kinesis-streams&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/streams/&#34;&gt;Kinesis Streams&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;用途を制限しないストリーム。データは保持期間の間、何度でも読むことができるので、
とりあえず必要なだけシャードを増やしてデータを入れておけばどうにかなる。
データを扱う側はそれぞれ独立に必要なタイミングで必要なだけpullするため、スケールするにあたってその先は別に考えることができ、
高負荷なシステムのlog aggregatorとして使われる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/streams/pricing/&#34;&gt;料金&lt;/a&gt;は&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;時間単位のシャード速度： 1シャードは最大1000件/秒の1MB/秒の入力と2MB/秒の出力能力がある。&lt;/li&gt;
&lt;li&gt;PUTペイロードユニット: 追加する25KBのチャンクの数。5KBでも1チャンク。&lt;/li&gt;
&lt;li&gt;データ保持期間: デフォルトで24時間。7日まで延長可能。シャード時間ごとに課金。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;による。&lt;/p&gt;

&lt;p&gt;ストリーム作成時はシャード数を入れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/64-create-streams.png&#34; alt=&#34;streams作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Firehoseと同じくKinesis Agentで送ってみる。
エンドポイントは&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/general/latest/gr/rande.html#ak_region&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;awsAccessKeyId&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;awsSecretAccessKey&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;kinesis.endpoint&amp;quot;: &amp;quot;https://kinesis.us-east-1.amazonaws.com&amp;quot;, 
    &amp;quot;flows&amp;quot;: [
        {
            &amp;quot;filePattern&amp;quot;: &amp;quot;/tmp/hoge.log&amp;quot;, 
            &amp;quot;kinesisStream&amp;quot;: &amp;quot;fugafugastream&amp;quot;
        }
    ] 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;aws-cliでデータを&lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/streams/latest/dev/fundamental-stream.html#get-records&#34;&gt;取得する&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;まず、シャードイテレーターを取得する。有効時間は300秒。
&lt;a href=&#34;http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax&#34;&gt;TRIM_HORIZON&lt;/a&gt;
で最も古い方からデータを取得していく。SequenceNumberを指定して途中から読むこともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws kinesis get-shard-iterator --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON --stream-name fugafugastream
{
    &amp;quot;ShardIterator&amp;quot;: &amp;quot;AAAAAAAAAAFjKI0neNqY2N5HzGljYFCzoFqpQsdncdC6xE+ylnqvZpmusNfyViY3hBSS8WQXa67gvtkF0f2eKzxQ/Fd7SXZG8Inkb8l1UDF5t+jHgErA28gVSWyT4uYxTzzbnhm9AhcbztyQrjqehYcjEfpWIz5XmhY9K3Kjp0Crygy+OYNSS5PoQFcB1PZ7xMFE8zLTxJXLv1ANRu0Q+1m/JFxKQ3WS&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このシャードイテレータを使ってget-recordsする。データはBase64で入っているのでデコードして確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ aws kinesis get-records --shard-iterator AAAAAAAAAAFjKI0neNqY2N5HzGljYFCzoFqpQsdncdC6xE+ylnqvZpmusNfyViY3hBSS8WQXa67gvtkF0f2eKzxQ/Fd7SXZG8Inkb8l1UDF5t+jHgErA28gVSWyT4uYxTzzbnhm9AhcbztyQrjqehYcjEfpWIz5XmhY9K3Kjp0Crygy+OYNSS5PoQFcB1PZ7xMFE8zLTxJXLv1ANRu0Q+1m/JFxKQ3WS
{
    &amp;quot;Records&amp;quot;: [
        {
            &amp;quot;Data&amp;quot;: &amp;quot;YWFhCg==&amp;quot;, 
            &amp;quot;PartitionKey&amp;quot;: &amp;quot;999679.8130737302&amp;quot;, 
            &amp;quot;ApproximateArrivalTimestamp&amp;quot;: 1487082145.518, 
            &amp;quot;SequenceNumber&amp;quot;: &amp;quot;49570460043263608661463102123405561406360875697772167170&amp;quot;
        }, 
        ...
    ], 
    &amp;quot;NextShardIterator&amp;quot;: &amp;quot;AAAAAAAAAAE08GRdLF1d76L1wCyLIiuAgpSEkKZSkUEO0VdUt3EOfdm1oOSXA1Xc4+tJPkSmB8g5NaQqDPRS/67u5IXermTUiAj6g2lgvDCGCqWFcYMAxIwIKZjKluCPQjL9kRaUqfVAaElRoKjp4Gv7JmuBDjKpxsbF2yk4uJJDAcevqH/VVkala8UbdhTweGyFgf9VhP/ljzXlrqkZ8wbD0eFwtZ3x&amp;quot;, 
    &amp;quot;MillisBehindLatest&amp;quot;: 0
}

$ echo &amp;quot;YWFhCg==&amp;quot; | base64 -d
aaa
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kinesis-analytics-https-aws-amazon-com-jp-kinesis-analytics&#34;&gt;&lt;a href=&#34;https://aws.amazon.com/jp/kinesis/analytics/&#34;&gt;Kinesis Analytics&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;SourceとなるKinesis Streamsか、Firehoseを指定し、SQLを実行できる。そして必要なら次のストリームに入れることができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/64-create-analytics.png&#34; alt=&#34;analytics作成&#34; /&gt;&lt;/p&gt;

&lt;p&gt;今回はSourceとしてjsonで株価のデータが入っているDemo streamを使う。
いくつかSQLテンプレートが用意されていて、その中のContinuous Filterを選択。
Streamに入ってきたものをTECHで絞って出力する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- ** Continuous Filter ** 
-- Performs a continuous filter based on a WHERE condition.
--          .----------.   .----------.   .----------.              
--          |  SOURCE  |   |  INSERT  |   |  DESTIN. |              
-- Source--&amp;gt;|  STREAM  |--&amp;gt;| &amp;amp; SELECT |--&amp;gt;|  STREAM  |--&amp;gt;Destination
--          |          |   |  (PUMP)  |   |          |              
--          &#39;----------&#39;   &#39;----------&#39;   &#39;----------&#39;               
-- STREAM (in-application): a continuously updated entity that you can SELECT from and INSERT into like a TABLE
-- PUMP: an entity used to continuously &#39;SELECT ... FROM&#39; a source STREAM, and INSERT SQL results into an output STREAM
-- Create output stream, which can be used to send to a destination
CREATE OR REPLACE STREAM &amp;quot;DESTINATION_SQL_STREAM&amp;quot; (ticker_symbol VARCHAR(4), sector VARCHAR(12), change REAL, price REAL);
-- Create pump to insert into output 
CREATE OR REPLACE PUMP &amp;quot;STREAM_PUMP&amp;quot; AS INSERT INTO &amp;quot;DESTINATION_SQL_STREAM&amp;quot;
-- Select all columns from source stream
SELECT STREAM ticker_symbol, sector, change, price
FROM &amp;quot;SOURCE_SQL_STREAM_001&amp;quot;
-- LIKE compares a string to a string pattern (_ matches all char, % matches substring)
-- SIMILAR TO compares string to a regex, may use ESCAPE
WHERE sector SIMILAR TO &#39;%TECH%&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/64-run-analytics.png&#34; alt=&#34;analytics実行&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのmonitor_agentのデータをGoでGoogle Stackdriverに送って監視する</title>
          <link>http://sambaiz.net/article/66/</link>
          <pubDate>Sun, 19 Feb 2017 23:55:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/66/</guid>
          <description>

&lt;h2 id=&#34;fluentdのmonitor-agent-http-docs-fluentd-org-v0-12-articles-monitoring&#34;&gt;&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/monitoring&#34;&gt;fluentdのmonitor_agent&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;メトリクスをjsonで返すAPIを提供する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type monitor_agent
  bind 0.0.0.0
  port 24220
&amp;lt;/source&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:24220/api/plugins.json | jq
{
  &amp;quot;plugins&amp;quot;: [
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d8c250&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;forward&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;forward&amp;quot;,
        &amp;quot;port&amp;quot;: &amp;quot;24222&amp;quot;,
        &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: false,
      &amp;quot;retry_count&amp;quot;: null
    },
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590d894c4&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;input&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;monitor_agent&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;monitor_agent&amp;quot;,
        &amp;quot;bind&amp;quot;: &amp;quot;0.0.0.0&amp;quot;,
        &amp;quot;port&amp;quot;: &amp;quot;24220&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: false,
      &amp;quot;retry_count&amp;quot;: null
    },
    {
      &amp;quot;plugin_id&amp;quot;: &amp;quot;object:3f8590dc1f2c&amp;quot;,
      &amp;quot;plugin_category&amp;quot;: &amp;quot;output&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
      &amp;quot;config&amp;quot;: {
        &amp;quot;@type&amp;quot;: &amp;quot;file&amp;quot;,
        &amp;quot;path&amp;quot;: &amp;quot;/var/log/td-agent/hoge.log&amp;quot;,
        &amp;quot;buffer_path&amp;quot;: &amp;quot;/var/log/td-agent/hoge.log.*&amp;quot;
      },
      &amp;quot;output_plugin&amp;quot;: true,
      &amp;quot;buffer_queue_length&amp;quot;: 0,
      &amp;quot;buffer_total_queued_size&amp;quot;: 0,
      &amp;quot;retry_count&amp;quot;: 0
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをもとにStackdriverで異常を検知できるようにする。&lt;/p&gt;

&lt;h2 id=&#34;google-stackdriver-https-cloud-google-com-stackdriver&#34;&gt;&lt;a href=&#34;https://cloud.google.com/stackdriver/&#34;&gt;Google Stackdriver&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GoogleがStackdriverを買収して改造したもの。GCPだけではなくAWSのリソースも監視できる。
まだBeta。&lt;/p&gt;

&lt;h2 id=&#34;ec2インスタンスを監視する-https-cloud-google-com-monitoring-quickstart-aws-configure-sd-acct&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/quickstart-aws#configure-sd-acct&#34;&gt;EC2インスタンスを監視する&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;GCPのメニューのSTACKDRIVER -&amp;gt; モニタリングで、プロジェクトを指定してStackdriverアカウントを作成する。&lt;/p&gt;

&lt;p&gt;今回はEC2で動いているfluentdを監視するので指示に従ってクロスアカウントアクセスのロールを作成、
Role ARNを入力してAWSアカウントと接続すると、
StackdriverのResouces-&amp;gt;InstancesでCPUの使用率などは確認できるが、
EC2にAgentを入れると詳細な情報を取得できる。&lt;/p&gt;

&lt;p&gt;GCPのメニューのサービスアカウントから接続したAWSアカウントを選択し、
Project-&amp;gt;編集者とLogging-&amp;gt;ログ書き込みロールのサービスアカウントを作成する。
新しい秘密鍵の提供にチェックを入れて、JSONのキーをダウンロードする。
これをEC2の&lt;code&gt;/etc/google/auth/application_default_credentials.json&lt;/code&gt;に置いて
&lt;code&gt;chown root:root&lt;/code&gt;、&lt;code&gt;chmod 400&lt;/code&gt;する。&lt;/p&gt;

&lt;p&gt;Monitoring AgentとLogging Agentをインストールし、
&lt;code&gt;stackdriver-collectd&lt;/code&gt;と&lt;code&gt;google-fluentd&lt;/code&gt;のプロセスがあれば正常。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -O https://repo.stackdriver.com/stack-install.sh
sudo bash stack-install.sh --write-gcm

curl -sSO https://dl.google.com/cloudagents/install-logging-agent.sh
sudo bash install-logging-agent.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;メモリの使用量やTCPコネクション数などがとれていることを確認する。
Googleのドキュメントには見つからなかったけど、
旧Stackdriverと同様、&lt;code&gt;stackdriver_monitor: false&lt;/code&gt;のタグを付けると
&lt;a href=&#34;https://support.stackdriver.com/customer/portal/articles/1491785-collecting-data-from-specific-resources-only&#34;&gt;監視対象から外れる&lt;/a&gt;
っぽい。&lt;/p&gt;

&lt;h2 id=&#34;カスタムメトリクスを送る-https-cloud-google-com-monitoring-custom-metrics&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/&#34;&gt;カスタムメトリクスを送る&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;MetricDescriptorを作成し、これにTimeSeriesデータを書き込んでいく。&lt;/p&gt;

&lt;h3 id=&#34;metricdescriptorの作成-https-cloud-google-com-monitoring-custom-metrics-creating-metrics-monitoring-create-metric-protocol&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#monitoring-create-metric-protocol&#34;&gt;MetricDescriptorの作成&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors&#34;&gt;MetricDescriptor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;typeは&lt;code&gt;custom.googleapis.com/&lt;/code&gt;
から&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#custom_metric_names&#34;&gt;始める&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors#MetricKind&#34;&gt;metricKind&lt;/a&gt;
にはGAUGEのほかに変化量をとるDELTA、累積するCUMULATIVEを指定できる。&lt;/p&gt;

&lt;p&gt;labelはフィルタリングのためのもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;fluentd buffer_queue_length&amp;quot;,
  &amp;quot;displayName&amp;quot;: &amp;quot;fluentd-buffer_queue_length&amp;quot;,
  &amp;quot;type&amp;quot;: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
  &amp;quot;metricKind&amp;quot;: &amp;quot;GAUGE&amp;quot;,
  &amp;quot;valueType&amp;quot;: &amp;quot;INT64&amp;quot;,
  &amp;quot;labels&amp;quot;: [
    {
      &amp;quot;key&amp;quot;: &amp;quot;plugin_type&amp;quot;,
      &amp;quot;valueType&amp;quot;: &amp;quot;STRING&amp;quot;,
      &amp;quot;description&amp;quot;: &amp;quot;The type of the plugin&amp;quot;
    },
  ],
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをGoで登録する。&lt;/p&gt;

&lt;p&gt;gcpのほうのprojectでProject-&amp;gt;編集者のサービスアカウントを作成してパスを
環境変数&lt;code&gt;GOOGLE_APPLICATION_CREDENTIALS&lt;/code&gt;に入れて
&lt;a href=&#34;https://developers.google.com/identity/protocols/application-default-credentials&#34;&gt;Default Credential&lt;/a&gt;
にする。&lt;/p&gt;

&lt;p&gt;必要なパッケージをgo get。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get google.golang.org/api/monitoring/v3
$ go get golang.org/x/oauth2/google
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;func main() {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		panic(err)
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		panic(err)
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/*****&amp;quot;

		requestBody = &amp;amp;monitoring.MetricDescriptor{
			Description: &amp;quot;fluentd buffer_queue_length&amp;quot;,
			DisplayName: &amp;quot;fluentd-buffer_queue_length&amp;quot;,
			Type:        &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
			MetricKind:  &amp;quot;GAUGE&amp;quot;,
			ValueType:   &amp;quot;INT64&amp;quot;,
			Labels: []*monitoring.LabelDescriptor{
				&amp;amp;monitoring.LabelDescriptor{
					Key:         &amp;quot;plugin_type&amp;quot;,
					ValueType:   &amp;quot;STRING&amp;quot;,
					Description: &amp;quot;The type of the plugin&amp;quot;,
				},
			},
		}
	)

	response, err := client.Projects.MetricDescriptors.Create(name, requestBody).Context(ctx).Do()
	if err != nil {
		panic(err)
	}

	fmt.Println(&amp;quot;done&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;登録されたことをlistで確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;response, err := client.Projects.MetricDescriptors.List(name).Context(ctx).Do()
if err != nil {
  panic(err)
}

for _, v := range response.MetricDescriptors {
  fmt.Println(v.DisplayName)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;API Request Count
Agent Memory Usage
Stream Space Used
...
fluentd-buffer_queue_length
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;timeseriesの書き込み-https-cloud-google-com-monitoring-custom-metrics-creating-metrics-monitoring-write-timeseries-protocol&#34;&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/custom-metrics/creating-metrics#monitoring-write-timeseries-protocol&#34;&gt;TimeSeriesの書き込み&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/TimeSeries&#34;&gt;TimeSeries&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;metricのtypeはMetricDescriptorのtypeと対応する。
pointsのendTimeはRFC3339のUTC文字列で渡す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
 &amp;quot;timeSeries&amp;quot;: [
  {
   &amp;quot;metric&amp;quot;: {
    &amp;quot;type&amp;quot;: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
    &amp;quot;labels&amp;quot;: {
     &amp;quot;plugin_type&amp;quot;: &amp;quot;file&amp;quot;
    }
   },
   &amp;quot;resource&amp;quot;: {
    &amp;quot;type&amp;quot;: &amp;quot;aws_ec2_instance&amp;quot;,
    &amp;quot;labels&amp;quot;: {
     &amp;quot;project_id&amp;quot;: &amp;quot;*****&amp;quot;,
     &amp;quot;instance_id&amp;quot;: &amp;quot;*****&amp;quot;,
     &amp;quot;region&amp;quot;: &amp;quot;aws:ap-northeast-1&amp;quot;,
     &amp;quot;aws_account&amp;quot;: &amp;quot;*****&amp;quot;
    }
   },
   &amp;quot;points&amp;quot;: [
    {
     &amp;quot;interval&amp;quot;: {
      &amp;quot;endTime&amp;quot;: &amp;quot;2016-06-01T10:00:00-04:00&amp;quot;
     },
     &amp;quot;value&amp;quot;: {
      &amp;quot;int64Value&amp;quot;: 0
     }
    }
   ]
  }
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;resourceのtypeは
&lt;a href=&#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/monitoredResourceDescriptors/list#MonitoredResourceDescriptor&#34;&gt;MonitoredResourceDescriptor&lt;/a&gt;
と対応していて、
&lt;a href=&#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/monitoredResourceDescriptors/list&#34;&gt;list&lt;/a&gt;で確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
 &amp;quot;resourceDescriptors&amp;quot;: [
   {
   &amp;quot;type&amp;quot;: &amp;quot;aws_ec2_instance&amp;quot;,
   &amp;quot;displayName&amp;quot;: &amp;quot;Amazon EC2 Instance&amp;quot;,
   &amp;quot;description&amp;quot;: &amp;quot;A VM instance in Amazon EC2.&amp;quot;,
   &amp;quot;labels&amp;quot;: [
    {
     &amp;quot;key&amp;quot;: &amp;quot;project_id&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The identifier of the GCP project under which data is stored for the AWS account specified in the aws_account label (e.g., my-project).&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;instance_id&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The VM instance identifier assigned by AWS.&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;region&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The AWS region in which the VM is running. Supported AWS region values are listed by service at http://docs.aws.amazon.com/general/latest/gr/rande.html. The value supplied for this label must be prefixed with &#39;aws:&#39; (for example, &#39;aws:us-east-1&#39; is a valid value while &#39;us-east-1&#39; is not).&amp;quot;
    },
    {
     &amp;quot;key&amp;quot;: &amp;quot;aws_account&amp;quot;,
     &amp;quot;description&amp;quot;: &amp;quot;The AWS account number under which the VM is running.&amp;quot;
    }
   ]
  },
  ...
 ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;書くコード。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func writeFluentdBufferQueueLength() error {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		return err
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		return err
	}

	now := time.Now().UTC().Format(time.RFC3339)

	resource := &amp;amp;monitoring.MonitoredResource{
		Type: &amp;quot;aws_ec2_instance&amp;quot;,
		Labels: map[string]string{
			&amp;quot;project_id&amp;quot;:  &amp;quot;*****&amp;quot;,
			&amp;quot;instance_id&amp;quot;: &amp;quot;*****&amp;quot;,
			&amp;quot;region&amp;quot;:      &amp;quot;aws:ap-northeast-1&amp;quot;,
			&amp;quot;aws_account&amp;quot;: &amp;quot;*****&amp;quot;,
		},
	}

	metrics, err := fetchFluentdMetrics()
	if err != nil {
		return err
	}

	timeSeries := []*monitoring.TimeSeries{}

	for _, v := range metrics.Plugins {
		if v.OutputPlugin {

			fmt.Printf(&amp;quot;send %s\n&amp;quot;, v.Type)

			timeSeries = append(
				timeSeries,
				&amp;amp;monitoring.TimeSeries{
					Metric: &amp;amp;monitoring.Metric{
						Type: &amp;quot;custom.googleapis.com/fluentd/buffer_queue_length&amp;quot;,
						Labels: map[string]string{
							&amp;quot;plugin_type&amp;quot;: v.Type,
						},
					},
					Resource: resource,
					Points: []*monitoring.Point{
						&amp;amp;monitoring.Point{
							Interval: &amp;amp;monitoring.TimeInterval{
								EndTime: now,
							},
							Value: &amp;amp;monitoring.TypedValue{
								Int64Value: int64p(v.BufferQueueLength),
							},
						},
					},
				},
			)
		}
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/try-stackdriver-159110&amp;quot;

		requestBody = &amp;amp;monitoring.CreateTimeSeriesRequest{
			TimeSeries: timeSeries,
		}
	)

	_, err = client.Projects.TimeSeries.Create(name, requestBody).Context(ctx).Do()
	if err != nil {
		return err
	}

	fmt.Println(&amp;quot;done&amp;quot;)

	return nil
}

const fluentdMonitorEndpoint = &amp;quot;http://localhost:24220/api/plugins.json&amp;quot;

type fluentdMetrics struct {
	Plugins []fluentdMetricsPlugin `json:&amp;quot;plugins&amp;quot;`
}
type fluentdMetricsPlugin struct {
	Type              string `json:&amp;quot;type&amp;quot;`
	OutputPlugin      bool   `json:&amp;quot;output_plugin&amp;quot;`
	BufferQueueLength int64  `json:&amp;quot;buffer_queue_length&amp;quot;`
}

// monitor_agentからfluentdのメトリクスを取得する
func fetchFluentdMetrics() (*fluentdMetrics, error) {

	resp, err := http.Get(fluentdMonitorEndpoint)
	if err != nil {
		return nil, err
	}

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}

	var ret fluentdMetrics

	if err := json.Unmarshal(body, &amp;amp;ret); err != nil {
		return nil, err
	}

	return &amp;amp;ret, nil
}

// int64 -&amp;gt; *int64
func int64p(n int64) *int64 {
	return &amp;amp;n
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを&lt;a href=&#34;https://github.com/jasonlvhit/gocron&#34;&gt;gocron&lt;/a&gt;などで定期的に実行させる。&lt;/p&gt;

&lt;p&gt;読むコード。確認用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func readFluentdBufferQueueLength() error {
	ctx := context.Background()
	httpClient, err := google.DefaultClient(ctx, monitoring.CloudPlatformScope)
	if err != nil {
		return err
	}
	client, err := monitoring.New(httpClient)
	if err != nil {
		return err
	}

	var (
		// The project on which to execute the request. The format is `&amp;quot;projects/{project_id_or_number}&amp;quot;`.
		name = &amp;quot;projects/*****&amp;quot;
	)

	start := time.Now().Add(time.Hour * -3).UTC().Format(time.RFC3339)
	now := time.Now().UTC().Format(time.RFC3339)

	filter := &amp;quot;metric.type = \&amp;quot;custom.googleapis.com/fluentd/buffer_queue_length\&amp;quot;&amp;quot;
	resp, err := client.Projects.TimeSeries.List(name).
		IntervalStartTime(start).
		IntervalEndTime(now).
		Filter(filter).Context(ctx).Do()
	if err != nil {
		return err
	}

	for _, v := range resp.TimeSeries {
		fmt.Println(v.Metric.Type)
		for _, p := range v.Points {
			fmt.Println(*(p.Value.Int64Value))
		}
	}

	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと届いていれば
Resource-&amp;gt;Metrics Explorerでもcustom/fluentd/buffer_queue_lengthを確認できる。&lt;/p&gt;

&lt;p&gt;これでAlertを設定できるようになった。TargetのResource TypeはCustom Metrics。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/66.png&#34; alt=&#34;Alertの設定&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Elasticsearchのmapping</title>
          <link>http://sambaiz.net/article/62/</link>
          <pubDate>Thu, 09 Feb 2017 21:00:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/62/</guid>
          <description>

&lt;p&gt;Dynamic mappingがあるので、自分で設定しなくてもデータは入るけど、
自分でやるとindexやanalyzerなどの設定が詳細にできるし、意図しないmappingを避けることもできる。
バージョンは5.2。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: 0 
}
&#39;

$ curl -XPOST &#39;localhost:9200/test_hoge/fuga?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot;
}
&#39;

{
  &amp;quot;error&amp;quot; : {
    &amp;quot;root_cause&amp;quot; : [
      {
        &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;,
        &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;
      }
    ],
    &amp;quot;type&amp;quot; : &amp;quot;mapper_parsing_exception&amp;quot;,
    &amp;quot;reason&amp;quot; : &amp;quot;failed to parse [name]&amp;quot;,
    &amp;quot;caused_by&amp;quot; : {
      &amp;quot;type&amp;quot; : &amp;quot;number_format_exception&amp;quot;,
      &amp;quot;reason&amp;quot; : &amp;quot;For input string: \&amp;quot;sambaiz\&amp;quot;&amp;quot;
    }
  },
  &amp;quot;status&amp;quot; : 400
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mapping-parameters-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-params-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-params.html&#34;&gt;Mapping parameters&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;index-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-index-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-index.html&#34;&gt;index&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;falseにするとindexしない。クエリで必要ないものはfalseにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;index&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;store-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-store-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-store.html&#34;&gt;store&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;デフォルトでフィールドはindexされるがstoreはされず、metaの&lt;code&gt;_source&lt;/code&gt;としてオリジナルのJSONがstoreされている。
サイズの大きなフィールドがあるなど、選んでstoreする場合はtrueにする。stored_fieldsで必要なものだけとってくることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;store&amp;quot;: true }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;meta-fields-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-fields-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-fields.html&#34;&gt;Meta fields&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;all-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-all-field-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-all-field.html&#34;&gt;_all&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;全てのフィールドをスペースでつなげた一つの文字列にしてanalyzeし、indexする。storeはされない。&lt;/p&gt;

&lt;p&gt;フィールドの区別なく検索できたりするけどindexするのにコストがかかるので必要ないならfalseにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;_all&amp;quot;: { &amp;quot;enabled&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;source-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-source-field-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-source-field.html&#34;&gt;_source&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;オリジナルのJSONを含み、indexはされずstoreされる。&lt;/p&gt;

&lt;p&gt;無効にするとストレージを節約できるが、
まずは&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/index-modules.html#index-codec&#34;&gt;compression level&lt;/a&gt;を上げてみる。
無効にするとupdateやreindexができなくなったりするので有効のままにしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;_source&amp;quot;: { &amp;quot;enabled&amp;quot;: false }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;analysis-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-analysis-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analysis.html&#34;&gt;analysis&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;textをどのようにanalyzeするか。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analyzer-anatomy.html&#34;&gt;Analyzer&lt;/a&gt;は
Character filtersで文字列を加工してTokenizerでトークンに分割してからToken filtersでトークンを取り除いたり変更したりするもの。
自分でこれらを組み合わせて&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/analysis-custom-analyzer.html&#34;&gt;定義する&lt;/a&gt;こともできる。&lt;/p&gt;

&lt;p&gt;日本語のAnalyzerとして&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/plugins/5.2/analysis-kuromoji.html&#34;&gt;kuromoji&lt;/a&gt;がある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/elasticsearch-plugin install analysis-kuromoji
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;kuromoji&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XGET &#39;localhost:9200/_analyze?pretty&#39; -d &#39;
{
  &amp;quot;analyzer&amp;quot; : &amp;quot;kuromoji&amp;quot;,
  &amp;quot;text&amp;quot; : &amp;quot;Character filtersで文字列を加工します&amp;quot;
}&#39;

{
  &amp;quot;tokens&amp;quot; : [
    {
      &amp;quot;token&amp;quot; : &amp;quot;character&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 0,
      &amp;quot;end_offset&amp;quot; : 9,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 0
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;filters&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 10,
      &amp;quot;end_offset&amp;quot; : 17,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 1
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;文字&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 18,
      &amp;quot;end_offset&amp;quot; : 20,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 3
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;列&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 20,
      &amp;quot;end_offset&amp;quot; : 21,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 4
    },
    {
      &amp;quot;token&amp;quot; : &amp;quot;加工&amp;quot;,
      &amp;quot;start_offset&amp;quot; : 22,
      &amp;quot;end_offset&amp;quot; : 24,
      &amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
      &amp;quot;position&amp;quot; : 6
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;datatype-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-mapping-types-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-types.html&#34;&gt;datatype&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;文字列-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-string-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/string.html&#34;&gt;文字列&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;5.Xからstringは廃止され
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/text.html&#34;&gt;text&lt;/a&gt;と
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/keyword.html&#34;&gt;keyword&lt;/a&gt;になった。&lt;/p&gt;

&lt;p&gt;textはメールの文章のようなfull-textの値で、ある単語がそれぞれの文章に含まれるかということを調べることができる。
メールアドレスのようなデータの場合はkeywordを使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;email&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;数値-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-number-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/number.html&#34;&gt;数値&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;long(64bit), integer(32bit), short(16bit, ~32767), byte(8bit, ~127), double, floatとか。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;age&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;short&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;日付-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-date-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/date.html&#34;&gt;日付&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;date&amp;quot;: {
  &amp;quot;type&amp;quot;:   &amp;quot;date&amp;quot;,
  &amp;quot;format&amp;quot;: &amp;quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;boolean-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-boolean-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/boolean.html&#34;&gt;Boolean&lt;/a&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;success&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;object-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-object-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/object.html&#34;&gt;Object&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;propertiesの中に書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: {
  &amp;quot;properties&amp;quot;: {
    &amp;quot;fuga&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;nested-https-www-elastic-co-guide-en-elasticsearch-reference-5-2-nested-html&#34;&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/nested.html&#34;&gt;nested&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;objectの配列。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: {
  &amp;quot;type&amp;quot;: &amp;quot;nested&amp;quot;
  &amp;quot;properties&amp;quot;: {
    &amp;quot;fuga&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;boolean&amp;quot; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;hoge&amp;quot;: [{&amp;quot;fuga&amp;quot;: true}]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;登録&#34;&gt;登録&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/test_index?pretty&#39; -d&#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;test_type&amp;quot;: { 
      &amp;quot;_all&amp;quot;:       { &amp;quot;enabled&amp;quot;: false  }, 
      &amp;quot;properties&amp;quot;: { 
        &amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;, &amp;quot;store&amp;quot;: true },
        &amp;quot;description&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;kuromoji&amp;quot; },
        &amp;quot;memo&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;index&amp;quot;: false }
      }
    }
  }
}
&#39;

$ curl -XPOST &#39;localhost:9200/test_index/test_type?pretty&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;sambaiz&amp;quot;,
    &amp;quot;description&amp;quot;: &amp;quot;青い海&amp;quot;,
    &amp;quot;memo&amp;quot;: &amp;quot;白い空&amp;quot;
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logstashのようにindex名に日付が付いているような場合は
&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/indices-templates.html&#34;&gt;indices-template&lt;/a&gt;で設定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT localhost:9200/_template/hogefuga-template -d &#39;
{
  &amp;quot;template&amp;quot; : &amp;quot;hogefuga-*&amp;quot;,
  &amp;quot;mappings&amp;quot; : {
    ...
  }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;取得&#34;&gt;取得&lt;/h2&gt;

&lt;p&gt;まずはデータが入っていることを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/test_index/test_type/_search?pretty&#39;
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVodMAubr8EtIroFs0eP&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;name&amp;quot; : &amp;quot;sambaiz&amp;quot;,
          &amp;quot;description&amp;quot; : &amp;quot;青い海&amp;quot;,
          &amp;quot;memo&amp;quot; : &amp;quot;白い空&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stored_fieldsを付けてリクエスト。_sourceが含まれず、storeがtrueなnameだけが返ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/test_index/_search?pretty&amp;amp;stored_fields=name,description,memo&#39;
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVodMAubr8EtIroFs0eP&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;fields&amp;quot; : {
          &amp;quot;name&amp;quot; : [
            &amp;quot;sambaiz&amp;quot;
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリを付けてリクエスト。indexされてないmemoではひっかからない。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_index/test_type/_search?pretty&#39; -d &#39;
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;query_string&amp;quot;:{
      &amp;quot;default_field&amp;quot; : &amp;quot;description&amp;quot;,
      &amp;quot;query&amp;quot;: &amp;quot;青い海&amp;quot;
    }
  }
}&#39;

{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPOST &#39;localhost:9200/test_index/test_type/_search?pretty&#39; -d &#39;
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;query_string&amp;quot;:{
      &amp;quot;default_field&amp;quot; : &amp;quot;memo&amp;quot;,
      &amp;quot;query&amp;quot;: &amp;quot;白い空&amp;quot;
    }
  }
}&#39;

{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 0,
    &amp;quot;max_score&amp;quot; : null,
    &amp;quot;hits&amp;quot; : [ ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing/&#34;&gt;Elasticsearchのインデキシングに関するパフォーマンス検討 - @johtaniの日記 2nd&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのrecord_transformerでログを加工する</title>
          <link>http://sambaiz.net/article/55/</link>
          <pubDate>Fri, 03 Feb 2017 21:14:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/55/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/filter_record_transformer&#34;&gt;http://docs.fluentd.org/v0.12/articles/filter_record_transformer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;追加したり、編集したり、削除したりできるフィルタ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;filter hoge.log&amp;gt;
  @type record_transformer
  enable_ruby
  auto_typecast true
  remove_keys b,d

  &amp;lt;record&amp;gt;
    what_is_tag ${tag}
    what_is_a ${record[&amp;quot;a&amp;quot;]}
    what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1}
  &amp;lt;/record&amp;gt;
&amp;lt;/filter&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この例だとタグを値に持つ&amp;rdquo;what_is_tag&amp;rdquo;、aを値に持つ&amp;rdquo;what_is_a&amp;rdquo;、b.cの値に1を足す&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;が追加され、
bとdが削除される。一旦まっさらにして入れるものだけを指定することもできる。&lt;/p&gt;

&lt;p&gt;auto_typecastをtrueにしないと&amp;rdquo;what_is_c_of_b_add_1&amp;rdquo;の値がstringになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: 1}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ tail /var/log/td-agent/td-agent.log
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーが起きるとnullになるが、それ以外の処理はされる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;hoge&amp;quot;, &amp;quot;b&amp;quot;: {&amp;quot;c&amp;quot;: &amp;quot;error!&amp;quot;}, &amp;quot;d&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ tail /var/log/td-agent/td-agent.log
[warn]: failed to expand `record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1` error_class=TypeError error=&amp;quot;no implicit conversion of Fixnum into String&amp;quot;
...
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:null}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;フィルタ適用前と後をそれぞれoutputしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match hoge.log&amp;gt;
  @type copy

  &amp;lt;store&amp;gt;
    @type stdout
  &amp;lt;/store&amp;gt;
 
  &amp;lt;store&amp;gt;
    @type relabel
    @label @fuga
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;

&amp;lt;label @fuga&amp;gt;
  &amp;lt;filter hoge.log&amp;gt;
    @type record_transformer
    enable_ruby
    auto_typecast true
    remove_keys b,d
  
    &amp;lt;record&amp;gt;
      what_is_tag ${tag}
      what_is_a ${record[&amp;quot;a&amp;quot;]}
      what_is_c_of_b_add_1 ${record[&amp;quot;b&amp;quot;][&amp;quot;c&amp;quot;] + 1}
    &amp;lt;/record&amp;gt;
  &amp;lt;/filter&amp;gt;

  &amp;lt;match hoge.log&amp;gt;
    @type stdout
  &amp;lt;/match&amp;gt;
&amp;lt;/label&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;b&amp;quot;:{&amp;quot;c&amp;quot;:1},&amp;quot;d&amp;quot;:&amp;quot;fuga&amp;quot;}
hoge.log: {&amp;quot;a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_tag&amp;quot;:&amp;quot;hoge.log&amp;quot;,&amp;quot;what_is_a&amp;quot;:&amp;quot;hoge&amp;quot;,&amp;quot;what_is_c_of_b_add_1&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdでElasticsearchに送る</title>
          <link>http://sambaiz.net/article/54/</link>
          <pubDate>Wed, 01 Feb 2017 21:51:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/54/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/uken/fluent-plugin-elasticsearch&#34;&gt;uken/fluent-plugin-elasticsearch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;必要なものをいれていく。Amazon LinuxのAMIから。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Failed to build gem native extension.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ yum install -y ruby-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;serverengine requires Ruby version &amp;gt;= 2.1.0.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/rbenv/rbenv&#34;&gt;rbenv&lt;/a&gt;でバージョンを上げる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/rbenv/rbenv.git ~/.rbenv
$ cd ~/.rbenv &amp;amp;&amp;amp; src/configure &amp;amp;&amp;amp; make -C src
$ echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
$ ~/.rbenv/bin/rbenv init
$ echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
$ source ~/.bash_profile
$ git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ rbenv -v
rbenv 1.1.0-2-g4f8925a
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Ruby install aborted due to missing extensions&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ yum install -y openssl-devel readline-devel zlib-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ rbenv install -l
1.8.5-p113
1.8.5-p114
1.8.5-p115
...

$ rbenv install 2.4.0
$ rbenv global 2.4.0
$ ruby -v
ruby 2.4.0p0 (2016-12-24 revision 57164) [x86_64-linux]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ td-agent-gem install fluent-plugin-elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;td-agent.confはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type elasticsearch
  host *****
  port 9200
  index_name test_index
  type_name test_type
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ curl *****:9200/test_index/test_type/_search?pretty
{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVn5puy79PEDL_x5e_u3&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;a&amp;quot; : &amp;quot;b&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;logstash formatでも入れてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match hoge.log&amp;gt;
  @type elasticsearch
  host *****
  port 9200
  logstash_format true
  logstash_prefix aaaa
  type_name test_type
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat hoge.log
$ curl *****:9200/aaaa-2017.02.02/_search?pretty
{
  &amp;quot;took&amp;quot; : 1,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;aaaa-2017.02.02&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVn_FyQP7q9Gyu5HC4Mq&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;a&amp;quot; : &amp;quot;b&amp;quot;,
          &amp;quot;@timestamp&amp;quot; : &amp;quot;2017-02-02T22:49:33+09:00&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;forwardと同じく
&lt;a href=&#34;http://docs.fluentd.org/v0.12/articles/buffer-plugin-overview&#34;&gt;Buffered Output plugin&lt;/a&gt;を
&lt;a href=&#34;https://github.com/uken/fluent-plugin-elasticsearch#buffered-output-options&#34;&gt;継承しているので&lt;/a&gt;
buffer_typeのデフォルトはmemory。必要ならfileにする。いずれにせよスパイクなどでbuffer_queue_limitを超えないように余裕をもっておく。
また、buffer_chunk_limitがElasticsearchのhttp.max_content_length(デフォルト100mb)を超えないようにする。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ElasticsearchをDockerで動かしてGrafanaで可視化する</title>
          <link>http://sambaiz.net/article/52/</link>
          <pubDate>Sun, 29 Jan 2017 17:08:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/52/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;vm.max_map_count
(&lt;a href=&#34;http://www.atmarkit.co.jp/flinux/special/proctune/proctune02b.html&#34;&gt;バーチャルメモリにマッピングできる最大ページ数&lt;/a&gt;)
を262144以上にする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sysctl vm.max_map_count
$ grep vm.max_map_count /etc/sysctl.conf
vm.max_map_count=262144
# sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;30日トライアル後、有償ライセンスが必要になるxpackのsecurity(旧sheild)がデフォルトで有効になっているのでfalseにしている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-cap-add=IPC_LOCK&lt;/code&gt;でLock memory(スワップアウトしないようにする)を
&lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&#34;&gt;許可&lt;/a&gt;する。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/heap-size.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ES_HEAP_SIZEでヒープ領域を設定する。デフォルトでは2GB。多いほどキャッシュに使用できる。
ただし、物理RAMの50%以下で、&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#compressed_oops&#34;&gt;32GB近辺の境界を超えないようにする&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p ~/do/elasticsearch/data
$ docker run -itd -v elasticsearch:/usr/share/elasticsearch/data \
--name elasticsearch \
-p 9200:9200 \
-e xpack.security.enabled=false \
-e bootstrap.memory_lock=true -e cluster.name=hogehoge-cluster -e ES_JAVA_OPTS=&amp;quot;-Xms28g -Xmx28g&amp;quot; \
--cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 \
--restart=always \
docker.elastic.co/elasticsearch/elasticsearch:5.1.2

$ docker volume ls
local               elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;問題なく起動しているか確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:9200 | jq
{
  &amp;quot;name&amp;quot;: &amp;quot;eqIkJ48&amp;quot;,
  &amp;quot;cluster_name&amp;quot;: &amp;quot;docker-cluster&amp;quot;,
  &amp;quot;cluster_uuid&amp;quot;: &amp;quot;Lsu_C7wORS6G-0m9PJ9sFQ&amp;quot;,
  &amp;quot;version&amp;quot;: {
    &amp;quot;number&amp;quot;: &amp;quot;5.1.2&amp;quot;,
    &amp;quot;build_hash&amp;quot;: &amp;quot;c8c4c16&amp;quot;,
    &amp;quot;build_date&amp;quot;: &amp;quot;2017-01-11T20:18:39.146Z&amp;quot;,
    &amp;quot;build_snapshot&amp;quot;: false,
    &amp;quot;lucene_version&amp;quot;: &amp;quot;6.3.0&amp;quot;
  },
  &amp;quot;tagline&amp;quot;: &amp;quot;You Know, for Search&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html&#34;&gt;dynamic mapping&lt;/a&gt;
を無効にする場合&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/_template/template_all?pretty&#39; -d&#39;
{
  &amp;quot;template&amp;quot;: &amp;quot;*&amp;quot;,
  &amp;quot;order&amp;quot;:0,
  &amp;quot;settings&amp;quot;: {
    &amp;quot;index.mapper.dynamic&amp;quot;: false 
  }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kuromojiを入れる場合&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec -it ***** bin/elasticsearch-plugin install analysis-kuromoji
$ docker restart  *****
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;grafanaで可視化する&#34;&gt;Grafanaで可視化する&lt;/h2&gt;

&lt;p&gt;前は&lt;a href=&#34;http://sambaiz.net/article/19/&#34;&gt;InfluxDBとつなげた&lt;/a&gt;が、Elasticsearchにも対応している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p /var/lib/grafana/plugins
$ docker run -itd --restart=always -p 3000:3000 -v grafana:/var/lib/grafana grafana/grafana
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.grafana.org/datasources/elasticsearch/&#34;&gt;http://docs.grafana.org/datasources/elasticsearch/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;admin/adminでログインして、data sourceを追加する。AccessはProxyにする。&lt;/p&gt;

&lt;p&gt;適当にデータを入れて表示してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -XPUT &#39;localhost:9200/test_index?pretty&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;test_type&amp;quot;: { 
      &amp;quot;_all&amp;quot;:       { &amp;quot;enabled&amp;quot;: false  }, 
      &amp;quot;properties&amp;quot;: { 
        &amp;quot;name&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot; },
        &amp;quot;age&amp;quot;:    { &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;  },
        &amp;quot;timestamp&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot;, &amp;quot;format&amp;quot;: &amp;quot;epoch_millis&amp;quot; }
      }
    }
  }
}
&#39;

$ curl &#39;localhost:9200/_cat/indices?format=json&amp;amp;pretty&#39;
[
  {
    &amp;quot;health&amp;quot; : &amp;quot;yellow&amp;quot;,
    &amp;quot;status&amp;quot; : &amp;quot;open&amp;quot;,
    &amp;quot;index&amp;quot; : &amp;quot;test_index&amp;quot;,
    &amp;quot;uuid&amp;quot; : &amp;quot;kVbt2V-rS2m6vhplIkMKNg&amp;quot;,
    &amp;quot;pri&amp;quot; : &amp;quot;5&amp;quot;,
    &amp;quot;rep&amp;quot; : &amp;quot;1&amp;quot;,
    &amp;quot;docs.count&amp;quot; : &amp;quot;0&amp;quot;,
    &amp;quot;docs.deleted&amp;quot; : &amp;quot;0&amp;quot;,
    &amp;quot;store.size&amp;quot; : &amp;quot;260b&amp;quot;,
    &amp;quot;pri.store.size&amp;quot; : &amp;quot;260b&amp;quot;
  },
  ...
]

$ curl -XPOST &#39;localhost:9200/test_index/test_type?pretty&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &amp;quot;name&amp;quot;: &amp;quot;hoge fuga&amp;quot;,
    &amp;quot;age&amp;quot;: 24,
    &amp;quot;timestamp&amp;quot;: 1485676393044
}
&#39;

$ curl &#39;localhost:9200/test_index/test_type/_search?pretty&#39;
{
  &amp;quot;took&amp;quot; : 2,
  &amp;quot;timed_out&amp;quot; : false,
  &amp;quot;_shards&amp;quot; : {
    &amp;quot;total&amp;quot; : 5,
    &amp;quot;successful&amp;quot; : 5,
    &amp;quot;failed&amp;quot; : 0
  },
  &amp;quot;hits&amp;quot; : {
    &amp;quot;total&amp;quot; : 1,
    &amp;quot;max_score&amp;quot; : 1.0,
    &amp;quot;hits&amp;quot; : [
      {
        &amp;quot;_index&amp;quot; : &amp;quot;test_index&amp;quot;,
        &amp;quot;_type&amp;quot; : &amp;quot;test_type&amp;quot;,
        &amp;quot;_id&amp;quot; : &amp;quot;AVnpOGrseo3fDHi0SK-P&amp;quot;,
        &amp;quot;_score&amp;quot; : 1.0,
        &amp;quot;_source&amp;quot; : {
          &amp;quot;name&amp;quot; : &amp;quot;hoge fuga&amp;quot;,
          &amp;quot;age&amp;quot; : 24,
          &amp;quot;timestamp&amp;quot; : 1485676393044
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/52.png&#34; alt=&#34;表示してみた&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>fluentdのforward</title>
          <link>http://sambaiz.net/article/51/</link>
          <pubDate>Wed, 25 Jan 2017 22:25:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/51/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/high-availability#network-topology&#34;&gt;td-agent間でログをやりとりするとき&lt;/a&gt;
に使われるforwardについて。内部では&lt;a href=&#34;http://docs.fluentd.org/articles/in_forward#protocol&#34;&gt;MessagePackを使っている&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;forward-input&#34;&gt;forward input&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/in_forward&#34;&gt;http://docs.fluentd.org/articles/in_forward&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;受け取る側。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/etc/init.d/td-agent restart&lt;/code&gt;してfluent-catで送ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &#39;{&amp;quot;hoge&amp;quot;: &amp;quot;fuga&amp;quot;}&#39; | /opt/td-agent/embedded/bin/fluent-cat -h xx.xx.xx.xx test.tag
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/var/log/td-agent/td-agent.log&lt;/code&gt;に出力される。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test.tag: {&amp;quot;hoge&amp;quot;:&amp;quot;fuga&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;forward-output&#34;&gt;forward output&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward&#34;&gt;http://docs.fluentd.org/articles/out_forward&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/buffer-plugin-overview&#34;&gt;http://docs.fluentd.org/articles/buffer-plugin-overview&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;送る側。&lt;/p&gt;

&lt;p&gt;ポートはデフォルトで24224で、イベントの送信にTCPを、heartbeatにUDP(heartbeat_typeで変えられる)を使う。&lt;/p&gt;

&lt;p&gt;flush_intervalははデフォルトで&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#flushinterval&#34;&gt;60秒&lt;/a&gt;。
確認のときは短くしておくと分かりやすい。
buffer_queueの一番上のチャンクがこの時間経過するか、サイズがbuffer_chunk_limitを超えると、一番下のチャンクが書き込まれ、新しいチャンクがpushされる。
chunkの数がbuffer_queue_limitに到達してしまうと新しいイベントは破棄されてしまうので
リソースを圧迫(buffer_chunk_limit * buffer_queue_limit)しない程度に十分大きな数にしておき、
スパイクや障害時に備えておく。
buffer_typeはデフォルトがmemory。fileだと&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#flushatshutdown&#34;&gt;flush_at_shutdownのデフォルトがfalse&lt;/a&gt;なので注意。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type forward

  flush_interval 1s

  buffer_type file
  buffer_path /var/log/td-agent/forward-buf
  flush_at_shutdown true
  buffer_chunk_limit 256m

  &amp;lt;server&amp;gt;
    name log_server
    host xx.xx.xx.xx
    port 24224
  &amp;lt;/server&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;冗長化&#34;&gt;冗長化&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#ltservergt-at-least-one-is-required&#34;&gt;server&lt;/a&gt;は複数書くことができ、
それぞれにweight(デフォルトは60)を設定したり、
&lt;a href=&#34;http://docs.fluentd.org/articles/out_forward#standby&#34;&gt;standby&lt;/a&gt;を付けることでActive-Standbyの構成にすることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type forward
  port 24224
  bind 0.0.0.0
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  @type forward

  ...

  &amp;lt;server&amp;gt;
    name log_server
    host xx.xx.xx.xx
    port 24224
    weight 60
  &amp;lt;/server&amp;gt;

  &amp;lt;server&amp;gt;
    name log_server2
    host yy.yy.yy.yy
    port 24224
    weight 60
  &amp;lt;/server&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;片方のサーバーをtd-agentをstopしてstartしてみるとこんなログが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;detached forwarding server &#39;log_server2&#39; host=&amp;quot;yy.yy.yy.yy&amp;quot; port=24224 phi=16.06814271743242 phi_threshold=16
recovered forwarding server &#39;log_server2&#39; host=&amp;quot;yy.yy.yy.yy&amp;quot; port=24224
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみにtd-agentはrootで動かしている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/sysconfig/td-agent 
TD_AGENT_USER=root
TD_AGENT_GROUP=root
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>logrotateでログをローテーションする</title>
          <link>http://sambaiz.net/article/33/</link>
          <pubDate>Wed, 09 Nov 2016 22:15:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/33/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://github.com/Sirupsen/logrus&#34;&gt;logrus&lt;/a&gt;がローテーションする仕組みを持っていなかったので、
READMEに書いてあったlogrotateを使う。/etc/logrotate.dの中に設定ファイルを入れて、cronで回して使う。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM ubuntu:14.04

ADD logrotate /etc/logrotate.d/app
RUN echo &amp;quot;/usr/sbin/logrotate /etc/logrotate.conf&amp;quot; &amp;gt; /etc/cron.daily/logrotate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定ファイル(logrotate)はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/var/log/app.log {
  daily
  rotate 4
  missingok
  delaycompress
  dateext
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;daily&lt;/code&gt;で1日に1回、&lt;code&gt;rotate 4&lt;/code&gt;で過去4日分残し、
&lt;code&gt;missingok&lt;/code&gt;でファイルがなくてもエラーにせず、&lt;code&gt;delaycompress&lt;/code&gt;で圧縮するのをローテーションした次の回にして、
&lt;code&gt;dateext&lt;/code&gt;でローテーションしたファイルの末尾を数字ではなく日付にする。&lt;/p&gt;

&lt;p&gt;実際に動かして確かめる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logrotate&lt;/code&gt;を実行すると、&lt;code&gt;/var/lib/logrotate/status&lt;/code&gt;に過去に見た時間が入る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;aaaaa&amp;quot; &amp;gt; /var/log/app.log
$ logrotate /etc/logrotate.conf
$ cat /var/lib/logrotate/status
logrotate state -- version 2
...
&amp;quot;/var/log/app.log&amp;quot; 2016-11-9-11:0:0
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;強制的にローテーションさせてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;aaaa&amp;quot; &amp;gt; /var/log/app.log
$ logrotate -f /etc/logrotate.conf
$ ls /var/log | grep app
app.log
app.log-20161109

$ cat /var/log/app.log-20161109
aaaaa
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>td-agentをビルドしてfluentdのバージョンを上げる</title>
          <link>http://sambaiz.net/article/32/</link>
          <pubDate>Sun, 06 Nov 2016 11:17:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/32/</guid>
          <description>&lt;pre&gt;&lt;code&gt;$td-agent --version
td-agent 0.12.26
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;td-agentって書いてあるけど、これがfluentdのバージョンらしい。&lt;/p&gt;

&lt;p&gt;fluentdはv0.14から&lt;a href=&#34;http://www.fluentd.org/blog/fluentd-v0.14.0-has-been-released&#34;&gt;ナノ秒で時間を持つようになった。&lt;/a&gt;
ただ、現行のtd-agent(v2.3.2)は上の通り古いバージョンを使っている。
0.14になる&lt;a href=&#34;https://github.com/treasure-data/omnibus-td-agent/tree/td-agent-3&#34;&gt;td-agent-3&lt;/a&gt;はまだリリースされていないので、
自分でfluentdを&lt;a href=&#34;https://github.com/fluent/fluentd/releases/tag/v0.14.8&#34;&gt;v0.14.8&lt;/a&gt;に上げてビルドすることにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM ubuntu:14.04

WORKDIR /tmp

RUN apt-get update &amp;amp;&amp;amp; \
    apt-get install -y git software-properties-common build-essential curl &amp;amp;&amp;amp; \
    add-apt-repository -y ppa:brightbox/ruby-ng &amp;amp;&amp;amp; \
    apt-get update &amp;amp;&amp;amp; \
    apt-get install -y ruby2.3 ruby2.3-dev &amp;amp;&amp;amp; \
    gem install bundler &amp;amp;&amp;amp; \
    git clone https://github.com/treasure-data/omnibus-td-agent

WORKDIR /tmp/omnibus-td-agent

RUN sed -ie &amp;quot;s/^default_version.*$/default_version &#39;3d1dd53f31d1fe49508f230a71a2b4c2ceb20f47&#39;/&amp;quot; config/software/fluentd.rb &amp;amp;&amp;amp; \
    sed -ie &amp;quot;s/^license_file.*$/license_file &#39;LICENSE&#39;/&amp;quot; config/projects/td-agent2.rb &amp;amp;&amp;amp; \
    bundle install --binstubs &amp;amp;&amp;amp; \
    bin/gem_downloader core_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader plugin_gems.rb &amp;amp;&amp;amp; \
    bin/gem_downloader ui_gems.rb &amp;amp;&amp;amp; \
    git config --global user.email &amp;quot;root@example.com&amp;quot; &amp;amp;&amp;amp; \
    mkdir -p /opt/td-agent /var/cache/omnibus &amp;amp;&amp;amp; \
    bin/omnibus build td-agent2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;config/projects/td-agent2.rb&lt;/code&gt;を書き換えているのは、ビルド時に&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/var/lib/gems/2.3.0/gems/omnibus-5.5.0/lib/omnibus/licensing.rb:223:in `read&#39;: No such file or directory @ rb_sysopen - /tmp/omnibus-td-agent/https://raw.githubusercontent.com/treasure-data/omnibus-td-agent/master/LICENSE (Errno::ENOENT)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなエラーが出たため。&lt;a href=&#34;https://github.com/chef/omnibus/blob/v5.5.0/lib/omnibus/licensing.rb#L223&#34;&gt;licensing.rb&lt;/a&gt;を見てみたところ、相対パスを想定しているようだった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;g++: internal compiler error: Killed (program cc1plus)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;が出たらメモリが足りないかもしれない。&lt;/p&gt;

&lt;p&gt;ビルドが成功したらpkgにdebが出来ている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker cp &amp;lt;Container ID&amp;gt;:/tmp/omnibus-td-agent/pkg/td-agent_2.3.3-0_amd64.deb .
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ dpkg -i td-agent_2.3.3-0_amd64.deb
$ td-agent --version
td-agent 0.14.8
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Grafana/InfluxDB/Fluentdでログを可視化する</title>
          <link>http://sambaiz.net/article/19/</link>
          <pubDate>Wed, 31 Aug 2016 20:54:00 &#43;0900</pubDate>
          <author></author>
          <guid>http://sambaiz.net/article/19/</guid>
          <description>

&lt;p&gt;コードは&lt;a href=&#34;https://github.com/sambaiz/grafana-influxdb-fluentd&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;influxdb-https-github-com-influxdata-influxdb&#34;&gt;&lt;a href=&#34;https://github.com/influxdata/influxdb&#34;&gt;InfluxDB&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Golangで書かれた時系列データベース。今回使うのは&lt;code&gt;v0.13&lt;/code&gt;。前のバージョンと結構違うので注意。&lt;/p&gt;

&lt;p&gt;デフォルトでは無効になっている認証を&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.13/administration/authentication_and_authorization/#set-up-authentication&#34;&gt;有効にする&lt;/a&gt;ために設定ファイルを編集して設置する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install influxdb # OSX
$ influxd config &amp;gt; influxdb.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[http]
  ...
  auth-enabled = true
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;FROM influxdb:0.13

VOLUME /var/lib/influxdb
ADD influxdb.conf /
ENV INFLUXDB_CONFIG_PATH /influxdb.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -p 8083:8083 -p 8086:8086 myinfluxdb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;influxd&lt;/code&gt;コマンドや
&lt;code&gt;:8083&lt;/code&gt;のWebインタフェースの他に
&lt;code&gt;:8086&lt;/code&gt;に&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.13/concepts/api/&#34;&gt;HTTP API&lt;/a&gt;が用意されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -i -XPOST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE USER root WITH PASSWORD &#39;root&#39; WITH ALL PRIVILEGES&amp;quot;

$ curl -i -XPOST http://localhost:8086/query -u root:root --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot;
{&amp;quot;results&amp;quot;:[{}]}

# Line Protocol(https://docs.influxdata.com/influxdb/v0.13/write_protocols/line/)
$ curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; -u root:root --data-binary &#39;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&#39;
(204 No Content)

$ curl -GET &#39;http://localhost:8086/query?db=mydb&#39; -u root:root --data-urlencode &#39;q=SELECT * FROM &amp;quot;cpu_load_short&amp;quot;&#39; | jq
{
  &amp;quot;results&amp;quot;: [
    {
      &amp;quot;series&amp;quot;: [
        {
          &amp;quot;name&amp;quot;: &amp;quot;cpu_load_short&amp;quot;,
          &amp;quot;columns&amp;quot;: [
            &amp;quot;time&amp;quot;,
            &amp;quot;host&amp;quot;,
            &amp;quot;region&amp;quot;,
            &amp;quot;value&amp;quot;
          ],
          &amp;quot;values&amp;quot;: [
            [
              &amp;quot;2015-06-11T20:46:02Z&amp;quot;,
              &amp;quot;server01&amp;quot;,
              &amp;quot;us-west&amp;quot;,
              0.64
            ]
          ]
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fluent-plugin-influxdb-https-github-com-fangli-fluent-plugin-influxdb&#34;&gt;&lt;a href=&#34;https://github.com/fangli/fluent-plugin-influxdb&#34;&gt;fluent-plugin-influxdb&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;設定はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  type tail
  path      /usr/src/app/test.log
  pos_file  /etc/td-agent/test.log.pos
  tag       something.log
  format    json
&amp;lt;/source&amp;gt;

&amp;lt;match *.log&amp;gt;
  @type     influxdb
  host      influxdb
  port      8086
  dbname    mydb
  user      root
  password  root
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5秒ごとにランダムな値valueのログを出力し続ける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from twisted.internet import task, reactor
import logging
import json
import random

INTERVAL = 5 # sec
logging.basicConfig(filename=&#39;test.log&#39;, format=&#39;%(message)s&#39;, level=logging.INFO)

def somethingHappend():
  data = {
    &amp;quot;value&amp;quot;: random.randint(0, 100),
    &amp;quot;event&amp;quot;: &amp;quot;something&amp;quot;
  }
  logging.info(json.dumps(data))  

if __name__ == &#39;__main__&#39;:
    instance = task.LoopingCall(somethingHappend)
    instance.start(INTERVAL)
    reactor.run()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;grafana-http-grafana-org&#34;&gt;&lt;a href=&#34;http://grafana.org/&#34;&gt;Grafana&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;可視化ツール。データソースとしてInfluxDB、Garaphite、Elasticsearchなどが使える。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://play.grafana.org/&#34;&gt;Demo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kibana(+Elasticsearch)だと
認証するのに&lt;a href=&#34;https://www.elastic.co/subscriptions&#34;&gt;有償&lt;/a&gt;のShieldプラグインが必要だが、
こちらは最初からできて手軽。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;これらのDockerイメージを作って、minikubeで立ち上げてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get pods
NAME                        READY     STATUS    RESTARTS   AGE
grafana-1386260931-lq8wh    1/1       Running   0          2m
influxdb-2543054961-yj1bd   1/1       Running   0          2m
testapp-532457622-269qo     1/1       Running   0          2m

$ curl -i -XPOST http://192.168.99.100:30005/query?db=mydb -u root:root --data-urlencode &#39;q=SELECT * FROM &amp;quot;something.log&amp;quot; LIMIT 1&#39;
{&amp;quot;results&amp;quot;:[{&amp;quot;series&amp;quot;:[{&amp;quot;name&amp;quot;:&amp;quot;something.log&amp;quot;,&amp;quot;columns&amp;quot;:[&amp;quot;time&amp;quot;,&amp;quot;event&amp;quot;,&amp;quot;value&amp;quot;],&amp;quot;values&amp;quot;:[[&amp;quot;2016-08-31T08:38:37Z&amp;quot;,&amp;quot;something&amp;quot;,23]]}]}]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://192.168.99.100:30003&#34;&gt;http://192.168.99.100:30003&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;admin/adminでログインしてDataSourceに&lt;code&gt;http://192.168.99.100:30005&lt;/code&gt;のInfluxDBを設定すると、
Dashboardにグラフやテーブルなどを置いて表示させることができるようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sambaiz.net/images/19_grafana.png&#34; alt=&#34;grafanaのDashboard&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;1秒以内に複数のログが発生する場合-2016-11-07&#34;&gt;1秒以内に複数のログが発生する場合 (2016-11-07)&lt;/h2&gt;

&lt;p&gt;時系列DBであるinfluxdbは同じタイムスタンプで複数のデータを持つことができない。
fluentdはv0.14からナノ秒でタイムスタンプを持つようになったので、これを利用することで1秒以内に発生するログも
正常に処理できるようになる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://sambaiz.net/article/32&#34;&gt;td-agentをビルドしてfluentdのバージョンを上げる&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;fluent-plugin-influxdbのtime_precisionはデフォルトでs(秒)になっているが、
これをns(ナノ秒)にしただけでは、(現時点では)秒のままのタイムスタンプが送られるのでうまくいかない。
そのため、以下のようにナノ秒を取れる場合はそれを使い、そうでない場合は無視するように修正した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nstime = time * (10 ** 9) + (defined?(Fluent::EventTime) ? time.nsec : 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/fangli/fluent-plugin-influxdb/pull/62&#34;&gt;プルリク&lt;/a&gt;は出した。
自分のプラグインはこんな感じで使うことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;td-agent-gem install specific_install &amp;amp;&amp;amp; \
td-agent-gem specific_install https://github.com/sambaiz/fluent-plugin-influxdb.git
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    

  </channel>
</rss>
