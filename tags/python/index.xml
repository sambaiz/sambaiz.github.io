<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/python/</link>
    <description>Recent content in Python on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Sat, 02 Jun 2018 18:16:00 +0900</lastBuildDate>
    
	<atom:link href="https://www.sambaiz.net/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>KaggleのTitanicのチュートリアルをXGBoostで解く</title>
      <link>https://www.sambaiz.net/article/168/</link>
      <pubDate>Sat, 02 Jun 2018 18:16:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/168/</guid>
      <description>XGBoostは高性能なGradient Boostingのライブラリ。 Boostingというのはアンサンブル学習の種類の一つで、ランダムフォレストのように弱学習器をそれぞれ並列に学習するBaggingに対して、 順番に前回までの結果を受けながら学習し、結果をまとめる際にそれぞれの重みを掛けるもの。 XGBoostではランダムフォレストと同様に決定木を弱学習器とする。
KaggleのTitanicのチュートリアルをランダムフォレストで解く - sambaiz-net
$ pip install xgboost  データの前処理はランダムフォレストと同じようにした。 パラメータの objective(目的関数)には二値分類なのでbinary:logisticを指定し、確率が返るのでroundして出力している。
import pandas as pd import xgboost as xgb from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).astype(int) df = df.drop([&#39;Cabin&#39;,&#39;Name&#39;,&#39;PassengerId&#39;,&#39;Ticket&#39;],axis=1) return df def train(df): train_x = df.</description>
    </item>
    
    <item>
      <title>KaggleのTitanicのチュートリアルをランダムフォレストで解く</title>
      <link>https://www.sambaiz.net/article/166/</link>
      <pubDate>Tue, 29 May 2018 09:33:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/166/</guid>
      <description>ランダムフォレストはデータや特徴量をランダムにサンプリングして決定木を複数生成し並列に学習するアンサンブル学習のBaggingという種類の手法。 決定木なので特徴量の影響が分かりやすく、単一の決定木と比べて過学習を防ぐことができる。
KaggleのTitanicのチュートリアルをXGBoostで解く - sambaiz-net
train.csvとtest.csvをKaggleからダウンロードする。 csvにはタイタニックの乗客者リストが含まれ、test.csvには生還したかを表すSurvivedが抜けている。 これを予測するのがこのコンペティションの目的だ。
データのうちFareやAge、Embarkedは入っていないものがあって、これらの欠損値をどう扱うという問題がある。
df = pd.read_csv(&#39;./train.csv&#39;) print(len(df)) print(df.isnull().sum())  891 PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64  連続値をとるFareとAgeは平均を取り、Embarkedは欠損値用の値にしてみた。数値化できないものについては除いている。
def preprocess(df): df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Fare&#39;].mean()) df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean()) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;Unknown&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2, &#39;Unknown&#39;: 3} ).</description>
    </item>
    
    <item>
      <title>Pythonのasyncioで非同期にリクエストを飛ばす</title>
      <link>https://www.sambaiz.net/article/162/</link>
      <pubDate>Sat, 14 Apr 2018 13:37:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/162/</guid>
      <description>Pythonのasyncioはイベントループを回してシングルスレッドで並行に非同期処理を行う。 マルチスレッドで並列に実行するのがthreadingで、 マルチプロセスで並列に実行するのがmultiprocessing。
import asyncio async def sleep(s): await asyncio.sleep(s) print(s) return s loop = asyncio.get_event_loop() loop.run_until_complete(sleep(5)) coros = [sleep(3), sleep(2)] futures = asyncio.gather(*coros) loop.run_until_complete(futures) print(futures.result()) loop.close()  $ python main.py 5 2 3 [3, 2]  get_event_loop() でイベントループを取得し、 gather()で処理をまとめたりして、 run_until_complete()で Futureの完了を待ち、 結果を取得してイベントループをclose()している。
async defを付けた関数はCoroutineとなり、 ensure_future()でFutureのサブクラスの、イベントループで実行させるTaskにすることができる。 run_until_complete()はそのままCoroutineを投げてもensure_future()でwrapしてくれる。
httpクライアントrequestsはBlockingするようなので、asyncioに対応しているaiohttpを使ってリクエストしてみる。
import aiohttp import asyncio import async_timeout async def fetch(session, url): print(&amp;quot;{} start&amp;quot;.format(url)) async with async_timeout.timeout(10): async with session.get(url) as response: text = await response.</description>
    </item>
    
    <item>
      <title>Kubernetes,Helmで負荷試験ツールLocustを立てる</title>
      <link>https://www.sambaiz.net/article/161/</link>
      <pubDate>Sun, 18 Mar 2018 22:35:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/161/</guid>
      <description>OSSの負荷試験ツールLocustをK8sクラスタに立てる。 K8sならworkerの増減も簡単だし、HelmのChartもあるので立てるのも楽。
LocustはPython製で、以下のようなコードで処理を書くことができる。
@task(10)のように括弧の中に数字を書いて実行される割合を偏らせることもできる。 異なるTaskSetに対応するユーザーを複数作ることもできて、こちらもweightで重みを付けられる。 ユーザー数はあとでWeb上から入力する。
$ mkdir tasks $ cat tasks/tasks.py from locust import HttpLocust, TaskSet, task class ElbTasks(TaskSet): @task def task1(self): with client.get(&amp;quot;/&amp;quot;, catch_response=True) as response: if response.content != &amp;quot;Success&amp;quot;: response.failure(&amp;quot;Got wrong response&amp;quot;) class ElbWarmer(HttpLocust): task_set = ElbTasks min_wait = 1000 max_wait = 3000  stableにChartはあるが、今のところtasksの中を書き換えなくてはいけないようなので、forkしてきてtasksの中を書き換え、helm repo addするためにpackageして、これを参照するindex.yamlを生成した。
$ helm package . $ helm repo index . $ ls locust-0.1.2.tgz index.yaml index.yaml	locust-0.1.2.tgz $ cat index.yaml apiVersion: v1 entries: locust: .</description>
    </item>
    
    <item>
      <title>Pythonのインタラクティブな可視化ライブラリBokehでグラフを描く</title>
      <link>https://www.sambaiz.net/article/129/</link>
      <pubDate>Sat, 26 Aug 2017 18:02:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/129/</guid>
      <description>Pythonの可視化というとmatplotlibや、 そのラッパーのseaborn、 データ解析ライブラリのPandasにもそういう機能があるけど、 これらが表示するのが静止画なのに対して、BokehはD3.jsで描画し、 拡大したりスクロールしたり、動的に何か表示することができる。Bokehはカメラのボケ。 似たようなのにPlotlyというのもあるけど、 こちらはPandasと同じpydata.orgドメインで、スターが多い。
jupyter/datascience-notebookイメージにもBokehがインストールされている。
$ docker run -d -p 8888:8888 jupyter/datascience-notebook start-notebook.sh  簡単なグラフを描く output_notebookでJupytor Notebokに出力する。ファイルに出力する場合はouput_fileを呼ぶ。
from bokeh.plotting import figure from bokeh.io import output_notebook, show output_notebook()  figure()でplotするFigureオブジェクトを作成する。
p = figure( title=&amp;quot;Hoge&amp;quot;, x_axis_label=&#39;x&#39;, y_axis_label=&#39;y&#39;, y_axis_type=&amp;quot;log&amp;quot; )  line()で線をつないでcircle()で円を描く。
x = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0] y0 = [i**2 for i in x] y1 = [10**i for i in x] y2 = [10**(i**2) for i in x] p.</description>
    </item>
    
    <item>
      <title>PythonのLintとFormatter</title>
      <link>https://www.sambaiz.net/article/125/</link>
      <pubDate>Fri, 11 Aug 2017 14:57:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/125/</guid>
      <description>YAPF スタイルに沿って整形してくれる、Goでいうgo fmtみたいなもの。 デフォルトはPython公式のスタイルガイドPEP8でフォーマットされる。
$ pip install yapf  VSCodeでPythonを書くときは、 Pythonプラグイン を入れてこんな設定をWorkspaceのconfigに入れておいて、 保存した時にフォーマットがかかるようにすると快適。
&amp;quot;editor.formatOnSave&amp;quot;: true, &amp;quot;python.formatting.provider&amp;quot;: &amp;quot;yapf&amp;quot;  Lint YAPFでフォーマットされた以下のコードにLintをかける。
class FizzBuzz: def __init__(self, start=0): self.num = start def __iter__(self): return self def __next__(self): self.num += 1 if self.num % 15 == 0: return &amp;quot;FizzBuzz&amp;quot; if self.num % 3 == 0: return &amp;quot;Fizz&amp;quot; if self.num % 5 == 0: return &amp;quot;Buzz&amp;quot; return self.num if __name__ == &amp;quot;__main__&amp;quot;: fizzBuzz = FizzBuzz() for i in range(100): print(next(fizzBuzz))  Pylint PythonプラグインではデフォルトでPylintが使われる。</description>
    </item>
    
  </channel>
</rss>