<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>statistics on sambaiz-net</title>
    <link>https://www.sambaiz.net/tags/statistics/</link>
    <description>Recent content in statistics on sambaiz-net</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>sambaiz-net</copyright>
    <lastBuildDate>Fri, 11 Feb 2022 00:11:00 +0900</lastBuildDate><atom:link href="https://www.sambaiz.net/tags/statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>最小二乗法(OLS)による線形回帰と決定係数</title>
      <link>https://www.sambaiz.net/article/395/</link>
      <pubDate>Fri, 11 Feb 2022 00:11:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/395/</guid>
      <description>最小二乗法(OLS)による線形回帰 線形回帰は時系列データに見られる前の時間との自己相関がないことを前提に
$$ y = \beta_0 + \sum_i^n \beta_i x_i $$
のような線形関数で表される回帰方程式によって\(y\)を説明変数\(x\)で説明するモデルを作る。
時系列データのMAモデルとARモデル、その定常性と反転可能性 - sambaiz-net
\(x\)が一つの場合は単回帰分析といい、複数の場合は重回帰分析という。 単回帰分析では母集団\(X, Y\)の関係を次の母回帰方程式で表す。 全ての要素が単一の直線上にあることはほとんどないので誤差項\(\varepsilon_i\)が含まれている。
$$ Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i $$
 この誤差項\(\varepsilon_i\)の二乗の和\(S\)が最小となるように係数の値を決めるのが最小二乗法(OLS; Ordinary Least Squares)となる。
$$ S = \sum \varepsilon_i^2 = \sum (Y_i - \beta_0 - \beta_1 X_i)^2 $$
一次の偏微分が0となる次の連立方程式を解いてそのような最小二乗推定量\(\hat{\beta_0},\hat{\beta_1}\)を求める。
$$ \begin{align*} \frac{\partial S}{\partial \beta_0} &amp;amp;= -2 \sum (Y_i - \beta_0 - \beta_1 X_i) = 0 \\ \frac{\partial S}{\partial \beta_1} &amp;amp;= -2 \sum (Y_i - \beta_0 - \beta_1 X_i) X_i = 0 \end{align*} $$</description>
    </item>
    
    <item>
      <title>2種の母集団の比較を行う2標本問題での統計量</title>
      <link>https://www.sambaiz.net/article/394/</link>
      <pubDate>Tue, 25 Jan 2022 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/394/</guid>
      <description>男性の身長と女性の身長といった異なる分布の2種の母集団について、その独立な標本から母集団の比較を行う問題を2標本問題(two-sample problem)という。
平均\(\mu_1\)分散\(\sigma_1^2\)の母集団と平均\(\mu_2\)分散\(\sigma_2^2\)の母集団からそれぞれ\(m,n\)個の標本を取って、その平均が\(\bar{X_1}, \bar{X_2}\)のとき、 \(\bar{X_1}, \bar{X_2}\)は独立なので分散の加法性\(V[X \pm Y] = V[X] + V[Y]\)が成り立ち、中心極限定理より正規分布になるので、\(\bar{X_1} - \bar{X_2}\)の分布は\(N(\mu_1 - \mu_2, \frac{\sigma_1^2}{m} + \frac{\sigma_2^2}{n} )\)となる。
確率分布(二項分布/ポアソン分布/正規分布/t分布/カイ二乗分布) - sambaiz-net
もし母分散が未知だが等しい場合は次のプールした分散を用いる。
$$ s^2 = \frac{\Sigma (X_i - \bar{X})^2 + \Sigma (Y_i - \bar{Y})^2}{m+n-2} = \frac{(m-1)s_1^2 + (n-1)s_2^2}{m+n-2} $$
このとき次の統計量は自由度\(m+n-2\)の\(\chi^2\)分布に従う。
$$ \frac{(m+n-2)s^2}{\sigma^2} = \frac{(m-1)s_1^2 + (n-1)s_2^2}{\sigma^2} $$
したがって、標準化変換した\(Z\)を
$$ Z = \frac{(\bar{X} - \bar{Y}) - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma^2}{m} + \frac{\sigma^2}{n}}} $$
\(\sqrt{\frac{\frac{(m+n-2)s^2}{\sigma^2}}{m+n-2}}\)で割ると自由度\(m+n-2\)のt分布となり、未知の母分散\(\sigma^2\)が消せる。
$$ t = \frac{Z}{\sqrt{\frac{\frac{(m+n-2)s^2}{\sigma^2}}{m+n-2}}} = \frac{(\bar{X} - \bar{Y}) - (\mu_1 - \mu_2)}{\sqrt{\frac{s^2}{m} + \frac{s^2}{n}}} $$</description>
    </item>
    
    <item>
      <title>時系列データのMAモデルとARモデル、その定常性と反転可能性</title>
      <link>https://www.sambaiz.net/article/285/</link>
      <pubDate>Fri, 14 Aug 2020 19:30:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/285/</guid>
      <description>時系列データにLjung-Box testを行い自己相関があることが分かったら、次はそれをモデルで表現したい。今回は自己相関を表す最も基本的なモデルであるMAモデルとARモデルを見ていく。これらを組み合わせたものがARMAモデルで、階差に対するARMAモデルがARIMAモデル。
Pythonで時系列データを検定(Shapiro-Wilk test, runs test, Ljung-Box test)する - sambaiz-net
MAモデル q次のMA(Moving Average; 移動平均)モデルMA(q)は次の式で表される。\(c\)は定数で\(\theta\)はパラメータ、\(\varepsilon\)は分散\(\sigma^2\)のホワイトノイズ。ホワイトノイズというのは期待値が0で\(lag=0\)以外での自己共分散も0である定常過程で、定義から自己相関も0になるので何の傾向もなく動く。期待値が0のiid(independent and identically distributed; 同一の分布の独立なデータ)系列はホワイトノイズであるが、ホワイトノイズがiid系列であるとは限らない。
時系列データの定常性と定常過程、単位根過程 - sambaiz-net
$$ y_t = c + \varepsilon_t + \sum_{i=1}^q \theta_i \varepsilon_{t-i} $$
過去の項と共通部分\(\varepsilon\)を持つことで自己相関が表されている。したがって共通部分を持たないq次以降の項の自己相関は0になってしまうが、次数を上げるとパラメータ\(\theta\)の数が増えてしまう。
期待値\(E\)と自己共分散\(\gamma\)、自己相関\(\rho\)は次の通りで常に定常性を持つ。
$$ \begin{align*} E[y_t] &amp;amp;= c \\ \gamma_k &amp;amp;= (\theta_k + \theta_1 \theta_{k+1} + \cdots + \theta_{q-k}\theta_q) \sigma^2 \ (\rm{if}\ k \le q \ \rm{otherwise}\ 0) \\ \rho_k &amp;amp;= \frac {\theta_k + \theta_1 \theta_{k+1} + \cdots + \theta_{q-k}\theta_q}{1 + \theta_1^2 + \cdots + \theta_q^2} \ (\rm{if}\ k \le q \ \rm{otherwise}\ 0) \end{align*} $$</description>
    </item>
    
    <item>
      <title>時系列データの定常性と定常過程、単位根過程</title>
      <link>https://www.sambaiz.net/article/279/</link>
      <pubDate>Sun, 05 Jul 2020 21:26:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/279/</guid>
      <description>時系列データを各時間\(t\)ごとの分布から抽出された確率変数\(R_t\)の列とみなすと、次の性質が定義される。
 弱定常性(weak stationarity): 各分布の平均\(E(R_t) = \mu\)が\(t\)に依らず一定で、\(lag=k\) のデータとの共分散である自己共分散 \(Cov(R_t, R_{t-k}) = E[(R_t - E(R_t))(R_{t-k} - E(R_{t-k}))] = \gamma_k\) がlagのみに依存する(つまり分散 \(\gamma_0\) も一定) 強定常性(strict stationarity): 任意の\(t,k\)に対する \((R_t, R_{t+1}, &amp;hellip;, R_{t+k})\) の同時分布が同一  つまり弱定常性を持つデータは、一定の平均のまわりの一定の振れ幅の中で、それ以前の値にlagに応じた影響を受けながら推移することになる。単に定常性と言う場合この弱定常性のことを指す。
同一の分布でなくても平均と分散、自己共分散が一定ならば弱定常性の条件は満たされるため、弱定常性のみを持ち強定常性を持たないことはある。 逆に強定常性を持つ場合は弱定常性も持ちそうだが、強定常性の条件は平均や分散(1次と2次のモーメント)を必須としないので必ずしも正しくなく、 平均と分散が定義されないコーシー分布では弱定常性を持たないことになる。
確率変数の列を確率過程(stochastic process)と呼び、定常性を持つものを定常過程(stationary process)と呼ぶ。 また、それ自体は定常過程でなく、差分系列 \(\Delta R_t = R_t - R_{t-1}\) が定常過程であるものを単位根過程(unit root process)と呼ぶ。 単位根という用語はAR特性方程式の根に1が含まれることに由来しているらしい。
時系列データのMAモデルとARモデル、その定常性と反転可能性 - sambaiz-net
参考 現場ですぐ使える時系列データ分析～データサイエンティストのための基礎知識〜
CHAPTER 4. STATIONARY TS MODELS
定常性についてのまとめ ｜ Developers.IO
第１章「離散時間確率過程」</description>
    </item>
    
    <item>
      <title>Pythonで時系列データを検定(Shapiro-Wilk test, runs test, Ljung-Box test)する</title>
      <link>https://www.sambaiz.net/article/273/</link>
      <pubDate>Sun, 21 Jun 2020 01:20:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/273/</guid>
      <description>統計的仮説検定 - sambaiz-net
テストデータ Dominick&amp;rsquo;s datasetのビールの週売上データを使う。 UPC(Universal Product Code)に対応する商品データと、店(STORE)で週(WEEK)に売れた数(MOVE)と価格(PRICE)、収益(PROFIT)を含むMovementデータがCSVで提供されている。
  これらをカレントディレクトリに置いてJupyter Notebookを立ち上げる。
$ docker run -p 8888:8888 -v `pwd`:/home/jovyan/work jupyter/datascience-notebook start-notebook.sh ロードしてplotしてみる。
import pandas as pd df = pd.read_csv(&amp;#39;./wber.csv&amp;#39;, usecols=[&amp;#39;STORE&amp;#39;, &amp;#39;WEEK&amp;#39;, &amp;#39;UPC&amp;#39;, &amp;#39;MOVE&amp;#39;, &amp;#39;PRICE&amp;#39;, &amp;#39;PROFIT&amp;#39;]) agg = df[df[&amp;#39;STORE&amp;#39;] == 5].groupby([&amp;#39;WEEK&amp;#39;]).sum().loc[:, [&amp;#39;MOVE&amp;#39;, &amp;#39;PROFIT&amp;#39;]] agg.plot()   この内、中央の区間の値や差分に対してα=0.05で検定する。
Shapiro-Wilk test 帰無仮説は&amp;quot;正規分布に従っている&amp;quot;。p&amp;gt;αとなり帰無仮説は棄却されず、正規分布に従うとみなせる。
from scipy import stats W, p = stats.shapiro(agg[&amp;#39;PROFIT&amp;#39;].loc[230:310]) print(f&amp;#39;p={p:.3f}&amp;#39;) # p=0.183 runs test 帰無仮説は&amp;quot;2値の数列の値がランダムである&amp;quot;。runというのは数列の連続して増加/減少している部分のことで、帰無仮説が正しい場合数列に含まれるrunの数は次の平均と分散の正規分布に従う。
updown = agg[&amp;#39;PROFIT&amp;#39;].loc[230:310].diff().map(lambda x: x &amp;gt; 0) Np = updown.</description>
    </item>
    
    <item>
      <title>統計的仮説検定</title>
      <link>https://www.sambaiz.net/article/271/</link>
      <pubDate>Sun, 10 May 2020 23:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/271/</guid>
      <description>統計的仮説検定(statistical hypothesis test)は母集団に対するある仮説が妥当だと言えるか標本から判断する手法。 棄却(reject)されることが期待される帰無仮説(null hypothesis)\(H_0\)と、それに相対する本命の対立仮説(alternative hypothesis)\(H_1\)を立て、 検定統計量を出し、帰無仮説が真である場合での確率分布でそれより外れた値が観測される確率であるp値が、設定した有意水準\(α\)(0.05にすることが多い)を下回れば帰無仮説が棄却され対立仮説が採択(accept)される。
有意水準はあくまで帰無仮説を棄却できるかのラインなので、それを上回ったからといって積極的に採択できるわけではない。 帰無仮説が真であるのに、たまたま棄却域の値が出ることで棄却してしまう場合を第一種の誤りといい、 逆に帰無仮説が偽であるのに採択してしまう場合を第二種の誤りという。 前者が起きる確率は有意水準αと等しく、\(α\)を小さくして棄却域を狭めると後者の確率βが大きくなる。 第二種の誤りを犯さない確率\(1-β\)を検出力といい、これが大きいほど厳しい検定と言える。
検定には母集団が特定の分布に従うと仮定しそのパラメータである平均や分散などを用いるパラメトリックな手法と、そうでないノンパラメトリックな手法がある。 パラメトリックな手法の方が検出力は高いが、標本数が小さい場合は分布を仮定することが難しいためノンパラメトリックな手法の方が適している。
t検定 正規分布を仮定するパラメトリックな手法。ちなみに正規分布かどうかの検定としてShapiro–Wilkの検定などがある。
Pythonで時系列データを検定(Shapiro-Wilk test, runs test, Ljung-Box test)する - sambaiz-net
t検定では平均\(\mu\)の正規表現に従う\(n\)個の標本から計算される次の確率変数\(t\)が、自由度\(n-1\)のt分布に従うことを利用する。もし十分な標本数があるか母分散が分かっているなら標準化変換した\(Z\)を用いてZ検定を行うことになる。
$$ t = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}} $$
確率分布(二項分布/ポアソン分布/正規分布/t分布/カイ二乗分布) - sambaiz-net
標本 (1.1, 1.5, 1.2, 1.3, 1.4) に対して帰無仮説&amp;quot;平均1.0の正規分布に従う&amp;quot;で検定してみる。
$$ \begin{align*} n &amp;amp;= 5 \\ \bar{X} &amp;amp;= \sqrt{1.1 + 1.5 + 1.2 + 1.3 + 1.4}{5} = 1.3 \\ s^2 &amp;amp;= \sqrt{(1.1 - 1.3)^2 + (1.5 - 1.</description>
    </item>
    
    <item>
      <title>確率分布(二項分布/ポアソン分布/正規分布/t分布/カイ二乗分布)</title>
      <link>https://www.sambaiz.net/article/138/</link>
      <pubDate>Sun, 15 Oct 2017 01:53:00 +0900</pubDate>
      
      <guid>https://www.sambaiz.net/article/138/</guid>
      <description>二項分布 確率\(p\)で起きる事象が\(n\)回の試行で\(x\)回起きる確率関数の離散的確率分布\(B[n,p]\)。 期待値は\(np\)で、分散は\(np(1-p)\)。
$$ f(x) = {}_nC_x p^x (1-p)^{n-x} \quad (0 \leqq x \leqq n) $$
 ポアソン分布 試行回数\(n\)が多いと二項分布の\({}_nC_x\)の部分の計算が困難になってしまうが、もし\(p\)が小さければ代わりにポアソン分布で近似することができる。 \(n = 50\)ぐらいのとき\(np \leqq 5\)以下が目安。期待値も分散も\(np=\mu\)。
$$ f(x) = \lim_{n \to \infty, p \to 0} {}_nC_x p^x (1-p)^{n-x} = \frac{\mu^x}{x!}e^{-\mu} $$
 正規分布 正規分布は平均値\(\mu\)を最大値とし、左右対称な釣鐘型をしている連続的確率分布\(N[μ,\sigma^2]\)。 二項分布の\(n\)を大きくしていくと正規分布に近づいていき、\(p = 0.5\)であれば、\(n = 10\)の二項分布\(B[10,0.5]\)でも\(N[5,2.5]\)の良い近似が得られる。逆に\(n\)が大きな二項分布の近似として正規分布を用いることもできる。
$$ f(x) = \frac{1}{\sqrt{2\pi}\sigma} \exp(-\frac{(x-\mu)^2}{2\sigma^2}) $$
 \(N[0,1]\)を標準正規分布と呼び、非標準分布に従う確率変数\(x\)を、標準正規分布に従う\(z\)に変換することを標準化変換という。
$$ z = \frac{x - \mu}{\sigma} $$
標準正規分布だと確率変数が\(z\)よりも小さくなる確率
$$ \int_{-\infty}^{z} f(x) dx $$
の値をまとめた正規分布表を用いて信頼区間を求めることができるようになる。
また、母平均\(μ\)、母分散\(\sigma^2\)の任意な分布から\(n\)個の標本をとったときの平均\(\bar{X}\)は\(N[\mu, \frac{\sigma^2}{n}]\)に従う。言い換えれば、標本平均と母平均の誤差は\(N[0, \frac{\sigma^2}{n}]\)となる。これを中心極限定理という。 この分布の分散の平方根\(\frac{\sigma}{\sqrt{n}}\)を標準誤差(SE)と呼ぶ。この分布を標準化変換すると次のようになる。</description>
    </item>
    
  </channel>
</rss>
